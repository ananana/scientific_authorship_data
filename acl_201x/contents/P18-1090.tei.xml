<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zeng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">MOE Key Lab of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="979" to="988"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>979</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The goal of sentiment-to-sentiment &quot;trans-lation&quot; is to change the underlying sentiment of a sentence while keeping its content. The main challenge is the lack of parallel data. To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutral-ization module and an emotionalization module. We evaluate our approach on two review datasets, Yelp and Amazon. Experimental results show that our approach significantly outperforms the state-of-the-art systems. Especially, the proposed method substantially improves the content preservation performance. The BLEU score is improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets, respectively. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment-to-sentiment "translation" requires the system to change the underlying sentiment of a sentence while preserving its non-emotional se- mantic content as much as possible. It can be re- garded as a special style transfer task that is impor- tant in Natural Language Processing (NLP) ( <ref type="bibr" target="#b6">Hu et al., 2017;</ref><ref type="bibr" target="#b18">Shen et al., 2017;</ref><ref type="bibr" target="#b3">Fu et al., 2018)</ref>. It has broad applications, including review senti- ment transformation, news rewriting, etc. Yet the lack of parallel training data poses a great obstacle to a satisfactory performance.</p><p>Recently, several related studies for language style transfer ( <ref type="bibr" target="#b6">Hu et al., 2017;</ref><ref type="bibr" target="#b18">Shen et al., 2017)</ref> have been proposed. However, when applied * Equal Contribution. <ref type="bibr">1</ref> The released code can be found in https://github.com/lancopku/unpaired-sentiment-translation to the sentiment-to-sentiment "translation" task, most existing studies only change the underlying sentiment and fail in keeping the semantic con- tent. For example, given "The food is delicious" as the source input, the model generates "What a bad movie" as the output. Although the sentiment is successfully transformed from positive to neg- ative, the output text focuses on a different topic. The reason is that these methods attempt to im- plicitly separate the emotional information from the semantic information in the same dense hidden vector, where all information is mixed together in an uninterpretable way. Due to the lack of super- vised parallel data, it is hard to only modify the underlying sentiment without any loss of the non- emotional semantic information.</p><p>To tackle the problem of lacking parallel data, we propose a cycled reinforcement learning ap- proach that contains two parts: a neutralization module and an emotionalization module. The neutralization module is responsible for extracting non-emotional semantic information by explicitly filtering out emotional words. The advantage is that only emotional words are removed, which does not affect the preservation of non-emotional words. The emotionalization module is responsi- ble for adding sentiment to the neutralized seman- tic content for sentiment-to-sentiment translation.</p><p>In cycled training, given an emotional sentence with sentiment s, we first neutralize it to the non- emotional semantic content, and then force the emotionalization module to reconstruct the origi- nal sentence by adding the sentiment s. Therefore, the emotionalization module is taught to add senti- ment to the semantic context in a supervised way. By adding opposite sentiment, we can achieve the goal of sentiment-to-sentiment translation. Be- cause of the discrete choice of neutral words, the gradient is no longer differentiable over the neu- tralization module. Thus, we use policy gradient, one of the reinforcement learning methods, to re- ward the output of the neutralization module based on the feedback from the emotionalization mod- ule. We add different sentiment to the semantic content and use the quality of the generated text as reward. The quality is evaluated by two useful metrics: one for identifying whether the generated text matches the target sentiment; one for evalu- ating the content preservation performance. The reward guides the neutralization module to better identify non-emotional words. In return, the im- proved neutralization module further enhances the emotionalization module.</p><p>Our contributions are concluded as follows:</p><p>• For sentiment-to-sentiment translation, we propose a cycled reinforcement learning ap- proach. It enables training with unpaired data, in which only reviews and sentiment la- bels are available.</p><p>• Our approach tackles the bottleneck of keep- ing semantic information by explicitly sepa- rating sentiment information from semantic content.</p><p>• Experimental results show that our approach significantly outperforms the state-of-the-art systems, especially in content preservation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Style transfer in computer vision has been stud- ied <ref type="bibr" target="#b7">(Johnson et al., 2016;</ref><ref type="bibr" target="#b4">Gatys et al., 2016;</ref><ref type="bibr" target="#b9">Liao et al., 2017;</ref><ref type="bibr" target="#b1">Li et al., 2017;</ref><ref type="bibr" target="#b27">Zhu et al., 2017)</ref>. The main idea is to learn the mapping between two im- age domains by capturing shared representations or correspondences of higher-level structures. There have been some studies on unpaired lan- guage style transfer recently. <ref type="bibr" target="#b6">Hu et al. (2017)</ref> pro- pose a new neural generative model that combines variational auto-encoders (VAEs) and holistic at- tribute discriminators for effective imposition of style semantic structures. <ref type="bibr" target="#b3">Fu et al. (2018)</ref> pro- pose to use an adversarial network to make sure that the input content does not have style informa- tion. <ref type="bibr" target="#b18">Shen et al. (2017)</ref> focus on separating the underlying content from style information. They learn an encoder that maps the original sentence to style-independent content and a style-dependent decoder for rendering. However, their evalua- tions only consider the transferred style accuracy. We argue that content preservation is also an in- dispensable evaluation metric. However, when applied to the sentiment-to-sentiment translation task, the previously mentioned models share the same problem. They have the poor preservation of non-emotional semantic content.</p><p>In this paper, we propose a cycled reinforce- ment learning method to improve sentiment-to- sentiment translation in the absence of parallel data. The key idea is to build supervised train- ing pairs by reconstructing the original sentence. A related study is "back reconstruction" in ma- chine translation <ref type="bibr" target="#b5">(He et al., 2016;</ref><ref type="bibr" target="#b21">Tu et al., 2017)</ref>. They couple two inverse tasks: one is for trans- lating a sentence in language A to a sentence in language B; the other is for translating a sentence in language B to a sentence in language A. Dif- ferent from the previous work, we do not intro- duce the inverse task, but use collaboration be- tween the neutralization module and the emotion- alization module.</p><p>Sentiment analysis is also related to our <ref type="bibr">work (Socher et al., 2011;</ref><ref type="bibr" target="#b16">Pontiki et al., 2015;</ref><ref type="bibr" target="#b17">Rosenthal et al., 2017;</ref><ref type="bibr" target="#b0">Chen et al., 2017;</ref><ref type="bibr" target="#b11">Ma et al., 2017</ref><ref type="bibr" target="#b13">Ma et al., , 2018b</ref>). The task usually involves detecting whether a piece of text expresses positive, nega- tive, or neutral sentiment. The sentiment can be general or about a specific topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cycled Reinforcement Learning for</head><p>Unpaired Sentiment-to-Sentiment Translation</p><p>In this section, we introduce our proposed method. An overview is presented in Section 3.1. The de- tails of the neutralization module and the emo- tionalization module are shown in Section 3.2 and Section 3.3. The cycled reinforcement learning mechanism is introduced in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>The proposed approach contains two modules: a neutralization module and an emotionalization module, as shown in <ref type="figure">Figure 1</ref>. The neutraliza- tion module first extracts non-emotional seman- tic content, and then the emotionalization module attaches sentiment to the semantic content. Two modules are trained by the proposed cycled rein- forcement learning method. The proposed method requires the two modules to have initial learning ability. Therefore, we propose a novel pre-training method, which uses a self-attention based senti- ment classifier (SASC). A sketch of cycled rein- forcement learning is shown in Algorithm 1. The  <ref type="figure">Figure 1</ref>: An illustration of the two modules.</p><p>Lower: The neutralization module removes emo- tional words and extracts non-emotional semantic information. Upper: The emotionalization mod- ule adds sentiment to the semantic content. The proposed self-attention based sentiment classifier is used to guide the pre-training.</p><p>details are introduced as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neutralization Module</head><p>The neutralization module N θ is used for explic- itly filtering out emotional information. In this paper, we consider this process as an extraction problem. The neutralization module first identifies non-emotional words and then feeds them into the emotionalization module. We use a single Long- short Term Memory Network (LSTM) to generate the probability of being neutral or being polar for every word in a sentence. Given an emotional in- put sequence x = (x 1 , x 2 , . . . , x T ) of T words from Γ, the vocabulary of words, this module is responsible for producing a neutralized sequence. Since cycled reinforcement learning requires the modules with initial learning ability, we pro- pose a novel pre-training method to teach the neutralization module to identify non-emotional words. We construct a self-attention based sen- timent classifier and use the learned attention weight as the supervisory signal. The motivation comes from the fact that, in a well-trained senti- ment classification model, the attention weight re- flects the sentiment contribution of each word to Algorithm 1 The cycled reinforcement learning method for training the neutralization module N θ and the emotionalization module E φ .</p><p>1: Initialize the neutralization module N θ , the emotional- ization module E φ with random weights θ, φ 2: Pre-train N θ using MLE based on Eq. 6 3: Pre-train E φ using MLE based on Eq. 7 4: for each iteration i = 1, 2, ..., M do 5:</p><p>Sample a sequence x with sentiment s from X 6:</p><p>Generate a neutralized sequencê x based on N θ 7:</p><p>GivenˆxGivenˆ Givenˆx and s, generate an output based on E φ 8:</p><p>Compute the gradient of E φ based on Eq. 8 9:</p><p>Compute the reward R1 based on Eq. 11 10:</p><p>¯ s = the opposite sentiment 11:</p><p>GivenˆxGivenˆ Givenˆx and ¯ s, generate an output based on E φ 12:</p><p>Compute the reward R2 based on Eq. 11 13:</p><p>Compute the combined reward Rc based on Eq. 10 14:</p><p>Compute the gradient of N θ based on Eq. 9 15:</p><p>Update model parameters θ, φ 16: end for some extent. Emotional words tend to get higher attention weights while neutral words usually get lower weights. The details of sentiment classifier are described as follows.</p><p>Given an input sequence x, a sentiment label y is produced as</p><formula xml:id="formula_0">y = sof tmax(W · c) (1)</formula><p>where W is a parameter. The term c is computed as a weighted sum of hidden vectors:</p><formula xml:id="formula_1">c = T i=0 α i h i (2)</formula><p>where α i is the weight of h i . The term h i is the output of LSTM at the i-th word. The term α i is computed as</p><formula xml:id="formula_2">α i = exp(e i ) T i=0 exp(e i )<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">e i = f (h i , h T )</formula><p>is an alignment model. We consider the last hidden state h T as the context vector, which contains all information of an input sequence. The term e i evaluates the contribution of each word for sentiment classification.</p><p>Our experimental results show that the proposed sentiment classifier achieves the accuracy of 89% and 90% on two datasets. With high classifica- tion accuracy, the attention weight produced by the classifier is considered to adequately capture the sentiment information of each word.</p><p>To extract non-emotional words based on con- tinuous attention weights, we map attention weights to discrete values, 0 and 1. Since the dis- crete method is not the key part is this paper, we only use the following method for simplification.</p><p>We first calculate the averaged attention value in a sentence as</p><formula xml:id="formula_4">¯ α = 1 T T i=0 α i<label>(4)</label></formula><p>where ¯ α is used as the threshold to distinguish non-emotional words from emotional words. The discrete attention weight is calculated asˆα</p><formula xml:id="formula_5">asˆ asˆα i = 1, if α i ≤ ¯ α 0, if α i &gt; ¯ α<label>(5)</label></formula><p>wherê α i is treated as the identifier. For pre-training the neutralization module, we build the training pair of input text x and a discrete attention weight sequencê α. The cross entropy loss is computed as</p><formula xml:id="formula_6">L θ = − T i=1 P N θ ( ˆ α i |x i )<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Emotionalization Module</head><p>The emotionalization module E φ is responsible for adding sentiment to the neutralized semantic content. In our work, we use a bi-decoder based encoder-decoder framework, which contains one encoder and two decoders. One decoder adds the positive sentiment and the other adds the negative sentiment. The input sentiment signal determines which decoder to use. Specifically, we use the seq2seq model <ref type="bibr" target="#b20">(Sutskever et al., 2014</ref>) for im- plementation. Both the encoder and decoder are LSTM networks. The encoder learns to compress the semantic content into a dense vector. The de- coder learns to add sentiment based on the dense vector. Given the neutralized semantic content and the target sentiment, this module is responsible for producing an emotional sequence. For pre-training the emotionalization module, we first generate a neutralized input sequencê x by removing emotional words identified by the pro- posed sentiment classifier. Given the training pair of a neutralized sequencê x and an original sen- tence x with sentiment s, the cross entropy loss is computed as</p><formula xml:id="formula_7">L φ = − T i=1 P E φ (x i |ˆx|ˆx i , s)<label>(7)</label></formula><p>where a positive example goes through the posi- tive decoder and a negative example goes through the negative decoder. We also explore a simpler method for pre- training the emotionalization module, which uses the product between a continuous vector 1 − α and a word embedding sequence as the neutralized content where α represents an attention weight sequence. Experimental results show that this method achieves much lower results than explic- itly removing emotional words based on discrete attention weights. Thus, we do not choose this method in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Cycled Reinforcement Learning</head><p>Two modules are trained by the proposed cycled method. The neutralization module first neutral- izes an emotional input to semantic content and then the emotionalization module is forced to re- construct the original sentence based on the source sentiment and the semantic content. Therefore, the emotionalization module is taught to add senti- ment to the semantic content in a supervised way. Because of the discrete choice of neutral words, the loss is no longer differentiable over the neu- tralization module. Therefore, we formulate it as a reinforcement learning problem and use policy gradient to train the neutralization module. The detailed training process is shown as follows.</p><p>We refer the neutralization module N θ as the first agent and the emotionalization module E φ as the second one. Given a sentence x associated with sentiment s, the termˆxtermˆ termˆx represents the mid- dle neutralized context extracted byˆαbyˆ byˆα, which is generated by P N θ ( ˆ α|x). In cycled training, the original sentence can be viewed as the supervision for training the second agent. Thus, the gradient for the second agent is</p><formula xml:id="formula_8">φ J(φ) = φ log(P E φ (x|ˆxx|ˆx, s))<label>(8)</label></formula><p>We denote ¯ x as the output generated by P E φ (¯ x|ˆxx|ˆx, s). We also denote y as the output gen- erated by P E φ (y|ˆxy|ˆx, ¯ s) where ¯ s represents the op- posite sentiment. Given ¯ x and y, we first calcu- late rewards for training the neutralized module, R 1 and R 2 . The details of calculation process will be introduced in Section 3.4.1. Then, we optimize parameters through policy gradient by maximiz- ing the expected reward to train the neutralization module. It guides the neutralization module to identify non-emotional words better. In return, the improved neutralization module further enhances the emotionalization module.</p><p>According to the policy gradient theo- rem <ref type="bibr" target="#b23">(Williams, 1992)</ref>, the gradient for the first agent is</p><formula xml:id="formula_9">θ J(θ) = E[R c · θ log(P N θ ( ˆ α|x))] (9)</formula><p>where R c is calculated as</p><formula xml:id="formula_10">R c = R 1 + R 2<label>(10)</label></formula><p>Based on Eq. 8 and Eq. 9, we use the sampling approach to estimate the expected reward. This cycled process is repeated until converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Reward</head><p>The reward consists of two parts, sentiment con- fidence and BLEU. Sentiment confidence evalu- ates whether the generated text matches the target sentiment. We use a pre-trained classifier to make the judgment. Specially, we use the proposed self- attention based sentiment classifier for implemen- tation. The BLEU ( <ref type="bibr" target="#b15">Papineni et al., 2002</ref>) score is used to measure the content preservation per- formance. Considering that the reward should en- courage the model to improve both metrics, we use the harmonic mean of sentiment confidence and BLEU as reward, which is formulated as</p><formula xml:id="formula_11">R = (1 + β 2 ) 2 · BLEU · Conf id (β 2 · BLEU ) + Conf id<label>(11)</label></formula><p>where β is a harmonic weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we evaluate our method on two re- view datasets. We first introduce the datasets, the training details, the baselines, and the evaluation metrics. Then, we compare our approach with the state-of-the-art systems. Finally, we show the ex- perimental results and provide the detailed analy- sis of the key components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Unpaired Datasets</head><p>We conduct experiments on two review datasets that contain user ratings associated with each re- view. Following previous work <ref type="bibr" target="#b18">(Shen et al., 2017)</ref>, we consider reviews with rating above three as positive reviews and reviews below three as neg- ative reviews. The positive and negative reviews are not paired. Since our approach focuses on sentence-level sentiment-to-sentiment translation where sentiment annotations are provided at the document level, we process the two datasets with the following steps. First, following previous work <ref type="bibr" target="#b18">(Shen et al., 2017</ref>), we filter out the reviews that exceed 20 words. Second, we construct text- sentiment pairs by extracting the first sentence in a review associated with its sentiment label, be- cause the first sentence usually expresses the core idea. Finally, we train a sentiment classifier and filter out the text-sentiment pairs with the classi- fier confidence below 0.8. Specially, we use the proposed self-attention based sentiment classifier for implementation. The details of the processed datasets are introduced as follows.</p><p>Yelp Review Dataset (Yelp): This dataset is provided by Yelp Dataset Challenge. <ref type="bibr">2</ref> The pro- cessed Yelp dataset contains 400K, 10K, and 3K pairs for training, validation, and testing, respec- tively.</p><p>Amazon Food Review Dataset (Amazon): This dataset is provided by <ref type="bibr" target="#b14">McAuley and Leskovec (2013)</ref>. It consists of amounts of food reviews from Amazon. <ref type="bibr">3</ref> The processed Ama- zon dataset contains 230K, 10K, and 3K pairs for training, validation, and testing, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>We tune hyper-parameters based on the perfor- mance on the validation sets. The self-attention based sentiment classifier is trained for 10 epochs on two datasets. We set β for calculating reward to 0.5, hidden size to 256, embedding size to 128, vocabulary size to 50K, learning rate to 0.6, and batch size to 64. We use the Adagrad (Duchi et al., 2011) optimizer. All of the gradients are clipped when the norm exceeds 2. Before cycled train- ing, the neutralization module and the emotional- ization module are pre-trained for 1 and 4 epochs on the yelp dataset, for 3 and 5 epochs on the Ama- zon dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>We compare our proposed method with the follow- ing state-of-the-art systems.</p><p>Cross-Alignment Auto-Encoder (CAAE): This method is proposed by <ref type="bibr" target="#b18">Shen et al. (2017)</ref>. They propose a method that uses refined align- ment of latent representations in hidden layers to perform style transfer. We treat this model as a baseline and adapt it by using the released code.</p><p>Multi-Decoder with Adversarial Learning (MDAL): This method is proposed by <ref type="bibr" target="#b3">Fu et al. (2018)</ref>. They use a multi-decoder model with ad- versarial learning to separate style representations and content representations in hidden layers. We adapt this model by using the released code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>We conduct two evaluations in this work, includ- ing an automatic evaluation and a human evalua- tion. The details of evaluation metrics are shown as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Automatic Evaluation</head><p>We quantitatively measure sentiment transforma- tion by evaluating the accuracy of generating des- ignated sentiment. For a fair comparison, we do not use the proposed sentiment classification model. Following previous work <ref type="bibr" target="#b18">(Shen et al., 2017;</ref><ref type="bibr" target="#b6">Hu et al., 2017)</ref>, we instead use a state- of-the-art sentiment classifier <ref type="bibr" target="#b22">(Vieira and Moura, 2017)</ref>, called TextCNN, to automatically evalu- ate the transferred sentiment accuracy. TextCNN achieves the accuracy of 89% and 88% on two datasets. Specifically, we generate sentences given sentiment s, and use the pre-trained sentiment classifier to assign sentiment labels to the gener- ated sentences. The accuracy is calculated as the percentage of the predictions that match the senti- ment s.</p><p>To evaluate the content preservation perfor- mance, we use the BLEU score ( <ref type="bibr" target="#b15">Papineni et al., 2002</ref>) between the transferred sentence and the source sentence as an evaluation metric. BLEU is a widely used metric for text generation tasks, such as machine translation, summarization, etc. The metric compares the automatically produced text with the reference text by computing overlap- ping lexical n-gram units.</p><p>To evaluate the overall performance, we use the geometric mean of ACC and BLEU as an evalua- tion metric. The G-score is one of the most com- monly used "single number" measures in Informa- tion Retrieval, Natural Language Processing, and Machine Learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Human Evaluation</head><p>While the quantitative evaluation provides indi- cation of sentiment transfer quality, it can not evaluate the quality of transferred text accurately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yelp</head><p>ACC BLEU G-score CAAE <ref type="bibr" target="#b18">(Shen et al., 2017)</ref>   Therefore, we also perform a human evaluation on the test set. We randomly choose 200 items for the human evaluation. Each item contains the trans- formed sentences generated by different systems given the same source sentence. The items are distributed to annotators who have no knowledge about which system the sentence is from. They are asked to score the transformed text in terms of sentiment and semantic similarity. Sentiment rep- resents whether the sentiment of the source text is transferred correctly. Semantic similarity eval- uates the context preservation performance. The score ranges from 1 to 10 (1 is very bad and 10 is very good).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experimental Results</head><p>Automatic evaluation results are shown in <ref type="table" target="#tab_2">Table 1</ref>. ACC evaluates sentiment transformation. BLEU evaluates semantic content preservation. G-score represents the geometric mean of ACC and BLEU. CAAE and MDAL achieve much lower BLEU scores, 1.17 and 1.64 on the Yelp dataset, 0.56 and 0.27 on the Amazon dataset. The low BLEU scores indicate the worrying content preservation performance to some extent. Even with the desired sentiment, the irrelevant generated text leads to worse overall performance. In general, these two systems work more like sentiment-aware language models that generate text only based on the target sentiment and neglect the source input. The main reason is that these two systems attempt to sep- arate emotional information from non-emotional content in a hidden layer, where all information is complicatedly mixed together. It is difficult to only modify emotional information without any loss of non-emotional semantic content. In comparison, our proposed method achieves the best overall performance on the two datasets,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Yelp</head><p>Sentiment Semantic G-score CAAE <ref type="bibr" target="#b18">(Shen et al., 2017)</ref> 7.67 3.87 5.45 MDAL ( <ref type="bibr" target="#b3">Fu et al., 2018)</ref> 7.12 3.68 5.12 Proposed Method 6.99 5.08 5.96 Amazon Sentiment Semantic G-score CAAE <ref type="bibr" target="#b18">(Shen et al., 2017)</ref> 8.61 3.15 5.21 MDAL ( <ref type="bibr" target="#b3">Fu et al., 2018)</ref> 7.93 3.22 5.05 Proposed Method 7.92 4.67 6.08 <ref type="table">Table 2</ref>: Human evaluations of the proposed method and baselines. Sentiment evaluates senti- ment transformation. Semantic evaluates content preservation.</p><p>demonstrating the ability of learning knowledge from unpaired data. This result is attributed to the improved BLEU score. The BLEU score is largely improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets. The score improve- ments mainly come from the fact that we separate emotional information from semantic content by explicitly filtering out emotional words. The ex- tracted content is preserved and fed into the emo- tionalization module. Given the overall quality of transferred text as the reward, the neutralization module is taught to extract non-emotional seman- tic content better. <ref type="table">Table 2</ref> shows the human evaluation results. It can be clearly seen that the proposed method ob- viously improves semantic preservation. The se- mantic score is increased from 3.87 to 5.08 on the Yelp dataset, and from 3.22 to 4.67 on the Amazon dataset. In general, our proposed model achieves the best overall performance. Furthermore, it also needs to be noticed that with the large improve- ment in content preservation, the sentiment accu- racy of the proposed method is lower than that of CAAE on the two datasets. It shows that simulta- neously promoting sentiment transformation and content preservation remains to be studied further.</p><p>By comparing two evaluation results, we find that there is an agreement between the human evaluation and the automatic evaluation. It indi- cates the usefulness of automatic evaluation met- rics. However, we also notice that the human eval- uation has a smaller performance gap between the baselines and the proposed method than the auto- matic evaluation. It shows the limitation of auto- matic metrics for giving accurate results. For eval- uating sentiment transformation, even with a high accuracy, the sentiment classifier sometimes gen- erates noisy results, especially for those neutral sentences (e.g., "I ate a cheese sandwich"). For evaluating content preservation, the BLEU score Input: I would strongly advise against using this com- pany. CAAE: I love this place for a great experience here. MDAL: I have been a great place was great. Proposed Method: I would love using this company. Input: The service was nearly non-existent and ex- tremely rude. CAAE: The best place in the best area in vegas. MDAL: The food is very friendly and very good. Proposed Method: The service was served and com- pletely fresh. Input: Asked for the roast beef and mushroom sub, only received roast beef. CAAE: We had a great experience with. MDAL: This place for a great place for a great food and best. Proposed Method: Thanks for the beef and spring bbq. Input: Worst cleaning job ever! CAAE: Great food and great service! MDAL: Great food, food! Proposed Method: Excellent outstanding job ever! Input: Most boring show I've ever been. CAAE: Great place is the best place in town. MDAL: Great place I've ever ever had. Proposed Method: Most amazing show I've ever been. Input: Place is very clean and the food is delicious. CAAE: Don't go to this place. MDAL: This place wasn't worth the worst place is hor- rible. Proposed Method: Place is very small and the food is terrible. Input: Really satisfied with experience buying clothes. CAAE: Don't go to this place. MDAL: Do not impressed with this place. Proposed Method: Really bad experience. <ref type="table" target="#tab_3">Table 3</ref>: Examples generated by the proposed ap- proach and baselines on the Yelp dataset. The two baselines change not only the polarity of exam- ples, but also the semantic content. In comparison, our approach changes the sentiment of sentences with higher semantic similarity.</p><p>is computed based on the percentage of overlap- ping n-grams between the generated text and the reference text. However, the overlapping n-grams contain not only content words but also function words, bringing the noisy results. In general, ac- curate automatic evaluation metrics are expected in future work.  <ref type="table">Table 4</ref>: Performance of key components in the proposed approach. "NM" denotes the neutraliza- tion module. "Cycled RL" represents cycled rein- forcement learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Incremental Analysis</head><p>In this section, we conduct a series of experiments to evaluate the contributions of our key compo- nents. The results are shown in <ref type="table">Table 4</ref>.</p><p>We treat the emotionalization module as a base- line where the input is the original emotional sen- tence. The emotionalization module achieves the highest BLEU score but with much lower senti- ment transformation accuracy. The encoding of the original sentiment leads to the emotional hid- den vector that influences the decoding process and results in worse sentiment transformation per- formance.</p><p>It can be seen that the method with all compo- nents achieves the best performance. First, we find that the method that only uses cycled reinforce- ment learning performs badly because it is hard to guide two randomly initialized modules to teach each other. Second, the pre-training method brings a slight improvement in overall performance. The G-score is improved from 32.77 to 34.66 and from 26.46 to 27.87 on the two datasets. The bottle- neck of this method is the noisy attention weight because of the limited sentiment classification ac- curacy. Third, the method that combines cycled reinforcement learning and pre-training achieves the better performance than using one of them. Pre-training gives the two modules initial learning ability. Cycled training teaches the two modules to improve each other based on the feedback signals. Specially, the G-score is improved from 34.66 to 42.38 and from 27.87 to 31.45 on the two datasets. Finally, by comparing the methods with and with- out the neutralization module, we find that the neu- tralization mechanism improves a lot in sentiment transformation with a slight reduction on content preservation. It proves the effectiveness of explic- Michael is absolutely wonderful. I would strongly advise against using this company. Horrible experience! Worst cleaning job ever! Most boring show i 've ever been. Hainan chicken was really good. I really don't understand all the negative reviews for this dentist. Smells so weird in there. The service was nearly non-existent and extremely rude. Furthermore, to analyze the neutralization abil- ity in the proposed method, we randomly sample several examples, as shown in <ref type="table" target="#tab_4">Table 5</ref>. It can be clearly seen that emotional words are removed ac- curately almost without loss of non-emotional in- formation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Error Analysis</head><p>Although the proposed method outperforms the state-of-the-art systems, we also observe sev- eral failure cases, such as sentiment-conflicted sentences (e.g., "Outstanding and bad service"), neutral sentences (e.g., "Our first time here"). Sentiment-conflicted sentences indicate that the original sentiment is not removed completely. This problem occurs when the input contains emo- tional words that are unseen in the training data, or the sentiment is implicitly expressed. Han- dling complex sentiment expressions is an impor- tant problem for future work. Neutral sentences demonstrate that the decoder sometimes fails in adding the target sentiment and only generates text based on the semantic content. A better sentiment- aware decoder is expected to be explored in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we focus on unpaired sentiment- to-sentiment translation and propose a cycled re- inforcement learning approach that enables train- ing in the absence of parallel training data. We conduct experiments on two review datasets. Ex- perimental results show that our method substan- tially outperforms the state-of-the-art systems, es- pecially in terms of semantic preservation. For fu- ture work, we would like to explore a fine-grained version of sentiment-to-sentiment translation that not only reverses sentiment, but also changes the strength of sentiment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Automatic evaluations of the proposed 
method and baselines. ACC evaluates sentiment 
transformation. BLEU evaluates content preserva-
tion. G-score is the geometric mean of ACC and 
BLEU. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 presents</head><label>3</label><figDesc>the examples generated by different systems on the Yelp dataset. The two baselines change not only the polarity of exam- ples, but also the semantic content. In compari- son, our method precisely changes the sentiment of sentences (and paraphrases slightly to ensure fluency), while keeping the semantic content un- changed.</figDesc><table>Yelp 
ACC BLEU G-score 
Emotionalization Module 
41.84 25.66 32.77 
+ NM + Cycled RL 
85.71 1.08 9.62 
+ NM + Pre-training 
70.61 17.02 34.66 
+ NM + Cycled RL + Pre-training 80.00 22.46 42.38 
Amazon 
ACC BLEU G-score 
Emotionalization Module 
57.28 12.22 26.46 
+ NM + Cycled RL 
64.16 8.03 22.69 
+ NM + Pre-training 
69.61 11.16 27.87 
+ NM + Cycled RL + Pre-training 70.37 14.06 31.45 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Analysis of the neutralization module. 
Words in red are removed by the neutralization 
module. 

itly separating sentiment information from seman-
tic content. 
</table></figure>

			<note place="foot" n="2"> https://www.yelp.com/dataset/ challenge 3 http://amazon.com</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by National Natu-ral Science Foundation of China (No. 61673028), National High Technology Research and Devel-opment Program of <ref type="bibr">China (863 Program, No. 2015AA015404)</ref>, and the National Thousand Young Talents Program. Xu Sun is the corre-sponding author of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving sentiment analysis via sentence type classification using bilstm-crf and CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="221" to="230" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to generate product reviews from attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="623" to="632" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Style transfer in text: Exploration and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxin</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoye</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-27" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dual learning for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="820" to="828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Controllable text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="694" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Demystifying neural style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-19" />
			<biblScope unit="page" from="2230" to="2236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Visual attribute transfer through deep image analogy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sing Bing</forename><surname>Kang</surname></persName>
		</author>
		<idno>120:1-120:15</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Decoding-history-based adaptive control of attention for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1802.01812</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cascading multiway attentions for document-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-11-27" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="634" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Query and output: Generating words by querying distributed word representations for paraphrase generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<idno>abs/1803.01465</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A hierarchical end-to-end model for jointly improving text summarization and sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<idno>abs/1805.01089</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International World Wide Web Conference, WWW &apos;13</title>
		<meeting><address><addrLine>Rio de Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-05-13" />
			<biblScope unit="page" from="897" to="908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Philadelphia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Usa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002-07-06" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval@NAACLHLT 2015</title>
		<meeting>the 9th International Workshop on Semantic Evaluation, SemEval@NAACLHLT 2015<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-04" />
			<biblScope unit="page" from="486" to="495" />
		</imprint>
	</monogr>
	<note>Suresh Manandhar, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semeval-2017 task 4: Sentiment analysis in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017-08-03" />
			<biblScope unit="page" from="502" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Style transfer from non-parallel text by cross-alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianxiao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff Chiung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning<address><addrLine>Bellevue, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06-28" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-813" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural machine translation with reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence, February 4-9<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3097" to="3103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An analysis of convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">Paulo</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albuquerque</forename><surname>Vieira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raimundo Santos</forename><surname>Moura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">XLIII 2017</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">DP-GAN: diversity-promoting generative adversarial network for generating informative and diversified text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuancheng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingzhen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1802.01345</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards automatic generation of product reviews from aspectsentiment scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation</title>
		<meeting>the 10th International Conference on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Automatic transferring between ancient chinese and contemporary chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1803.01557</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="2242" to="2251" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
