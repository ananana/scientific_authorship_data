<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Top-Down BTG Parsing for Machine Translation Preordering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuji</forename><surname>Nakagawa</surname></persName>
							<email>tnaka@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Japan Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient Top-Down BTG Parsing for Machine Translation Preordering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="208" to="218"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an efficient incremental top-down parsing method for preordering based on Bracketing Transduction Grammar (BTG). The BTG-based preordering framework (Neubig et al., 2012) can be applied to any language using only parallel text, but has the problem of computational efficiency. Our top-down parsing algorithm allows us to use the early update technique easily for the latent variable structured Perceptron algorithm with beam search, and solves the problem. Experimental results showed that the top-down method is more than 10 times faster than a method using the CYK algorithm. A phrase-based machine translation system with the top-down method had statistically significantly higher BLEU scores for 7 language pairs without relying on supervised syntactic parsers, compared to baseline systems using existing preorder-ing methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The difference of the word order between source and target languages is one of major problems in phrase-based statistical machine translation. In or- der to cope with the issue, many approaches have been studied. Distortion models consider word re- ordering in decoding time using such as distance ( <ref type="bibr" target="#b19">Koehn et al., 2003)</ref> and lexical information <ref type="bibr" target="#b39">(Tillman, 2004</ref>). Another direction is to use more com- plex translation models such as hierarchical mod- els <ref type="bibr" target="#b4">(Chiang, 2007)</ref>. However, these approaches suffer from the long-distance reordering issue and computational complexity.</p><p>Preordering (reordering-as-preprocessing) ( <ref type="bibr" target="#b46">Xia and McCord, 2004;</ref><ref type="bibr" target="#b6">Collins et al., 2005</ref>) is another approach for tackling the problem, which modifies the word order of an input sentence in a source lan- guage to have the word order in a target language <ref type="figure" target="#fig_0">(Figure 1(a)</ref>).</p><p>Various methods for preordering have been studied, and a method based on Bracketing Trans- duction Grammar (BTG) was proposed by <ref type="bibr" target="#b30">Neubig et al. (2012)</ref>. It reorders source sentences by han- dling sentence structures as latent variables. The method can be applied to any language using only parallel text. However, the method has the prob- lem of computational efficiency.</p><p>In this paper, we propose an efficient incremen- tal top-down BTG parsing method which can be applied to preordering. Model parameters can be learned using latent variable Perceptron with the early update technique ( <ref type="bibr" target="#b5">Collins and Roark, 2004</ref>), since the parsing method provides an easy way for checking the reachability of each parser state to valid final states. We also try to use forced-decoding instead of word alignment based on Expectation Maximization (EM) algorithms in order to create better training data for preorder- ing. In experiments, preordering using the top- down parsing algorithm was faster and gave higher BLEU scores than BTG-based preordering using the CYK algorithm. Compared to existing pre- ordering methods, our method had better or com- parable BLEU scores without using supervised parsers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preordering for Machine Translation</head><p>Many preordering methods which use syntactic parse trees have been proposed, because syntac- tic information is useful for determining the word order in a target language, and it can be used to restrict the search space against all the possible permutations. Preordering methods using manu- ally created rules on parse trees have been stud- ied ( <ref type="bibr" target="#b6">Collins et al., 2005;</ref><ref type="bibr" target="#b36">Xu et al., 2009</ref>), but linguistic knowledge for a language pair is nec- essary to create such rules. Preordering methods which automatically create reordering rules or uti- lize statistical classifiers have also been studied ( <ref type="bibr" target="#b46">Xia and McCord, 2004;</ref><ref type="bibr" target="#b24">Li et al., 2007;</ref><ref type="bibr" target="#b12">Genzel, 2010;</ref><ref type="bibr" target="#b42">Visweswariah et al., 2010;</ref><ref type="bibr" target="#b28">Miceli Barone and Attardi, 2013;</ref><ref type="bibr" target="#b23">Lerner and Petrov, 2013;</ref><ref type="bibr" target="#b16">Jehl et al., 2014</ref>). These meth- ods rely on source-side parse trees and cannot be applied to languages where no syntactic parsers are available.</p><p>There are preordering methods that do not need parse trees. They are usually trained only on auto- matically word-aligned parallel text. It is possible to mine parallel text from the Web ( <ref type="bibr" target="#b41">Uszkoreit et al., 2010;</ref><ref type="bibr" target="#b0">Antonova and Misyurev, 2011)</ref>, and the preordering systems can be trained without man- ually annotated language resources. <ref type="bibr" target="#b40">Tromble and Eisner (2009)</ref> studied preordering based on a Lin- ear Ordering Problem by defining a pairwise pref- erence matrix. <ref type="bibr" target="#b18">Khalilov and Sima'an (2010)</ref> pro- posed a method which swaps adjacent two words using a maximum entropy model. <ref type="bibr" target="#b43">Visweswariah et al. (2011)</ref> regarded the preordering problem as a Traveling Salesman Problem (TSP) and applied TSP solvers for obtaining reordered words. These methods do not consider sentence structures.</p><p>DeNero and Uszkoreit (2011) presented a pre- ordering method which builds a monolingual pars- ing model and a tree reordering model from par- allel text. <ref type="bibr" target="#b30">Neubig et al. (2012)</ref> proposed to train a discriminative BTG parser for preordering di- rectly from word-aligned parallel text by handling underlying parse trees with latent variables. This method is explained in detail in the next subsec- tion. These two methods can use sentence struc- tures for designing feature functions to score per- mutations.  <ref type="bibr" target="#b45">(Wu, 1997</ref>) is a binary synchronous context-free grammar with only one non-terminal symbol, and has three types of rules ( <ref type="figure" target="#fig_1">Figure 2</ref>): Straight which keeps the order of child nodes, Inverted which reverses the order, and Terminal which generates a terminal symbol. <ref type="bibr">1</ref> BTG can express word reordering. For exam- ple, the word reordering in <ref type="figure" target="#fig_0">Figure 1</ref>(a) can be rep- resented with the BTG parse tree in <ref type="figure" target="#fig_0">Figure 1</ref>(b). 2 Therefore, the task to reorder an input source sen- tence can be solved as a BTG parsing task to find an appropriate BTG tree.</p><p>In order to find the best BTG tree among all the possible ones, a score function is defined. Let Φ(m) denote the vector of feature functions for the BTG tree node m, and Λ denote the vector of feature weights. Then, for a given source sentence x, the best BTG treê z and the reordered sentence x ′ can be obtained as follows:</p><formula xml:id="formula_0">ˆ z = argmax z∈Z(x) ∑ m∈N odes(z) Λ · Φ(m), (1) x ′ = P roj(ˆ z),<label>(2)</label></formula><p>where Z(x) is the set of all the possible BTG trees for x, N odes(z) is the set of all the nodes in the tree z, and P roj(z) is the function which gener- ates a reordered sentence from the BTG tree z. The method was shown to improve transla- tion performance. However, it has a problem of processing speed. The CYK algorithm, whose computational complexity is O(n 3 ) for a sen- 1 Although Terminal produces a pair of source and target words in the original BTG (Wu, 1997), the target-side words are ignored here because both the input and the output of pre- ordering systems are in the source language. In (Wu, 1997), (DeNero and Uszkoreit, 2011) and ( <ref type="bibr" target="#b30">Neubig et al., 2012</ref>), Ter- minal can produce multiple words. Here, we produce only one word. <ref type="bibr">2</ref> There may be more than one BTG tree which repre- sents the same word reordering (e.g., the word reordering C3B2A1 to A1B2C3 has two possible BTG trees), and there are permutations which cannot be represented with BTG (e.g., B2D4A1C3 to A1B2C3D4, which is called the 2413 pattern).  tence of length n, is used to find the best parse tree. Furthermore, due to the use of a complex loss function, the complexity at training time is O(n 5 ) ( <ref type="bibr" target="#b30">Neubig et al., 2012)</ref>. Since the compu- tational cost is prohibitive, some techniques like cube pruning and cube growing have been applied <ref type="bibr" target="#b30">(Neubig et al., 2012;</ref><ref type="bibr" target="#b29">Na and Lee, 2013)</ref>. In this study, we propose a top-down parsing algorithm in order to achieve fast BTG-based preordering.</p><formula xml:id="formula_1">(0) ⟨[[0, 5)], [], 0⟩ (1) ⟨[[0, 2), [2, 5)], [(2, S)], v1⟩ (2) ⟨[[0, 2), [3, 5)], [(2, S), (3, I)], v2⟩ (3) ⟨[[0, 2)], [(2, S), (3, I), (4, I)], v3⟩ (4) ⟨[], [(2, S), (3, I), (4, I), (1, S)], v4⟩</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preordering with Incremental</head><p>Top-Down BTG Parsing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parsing Algorithm</head><p>We explain an incremental top-down BTG parsing algorithm using <ref type="figure" target="#fig_2">Figure 3</ref>, which illustrates how a parse tree is built for the example sentence in <ref type="figure" target="#fig_0">Fig- ure 1</ref>. At the beginning, a tree (span) which covers all the words in the sentence is considered. Then, a span which covers more than one word is split in each step, and the node type (Straight or In- verted) for the splitting point is determined. The algorithm terminates after (n − 1) iterations for a sentence with n words, because there are (n − 1) positions which can be split. We consider that the incremental parser has a parser state in each step, and define the state as a triple ⟨P, C, v⟩. P is a stack of unre- solved spans. A span denoted by [p, q) covers the words x p · · · x q−1 for an input word sequence x = x 0 · · · x |x|−1 . C is a list of past parser ac- tions. A parser action denoted by (r, o) represents the action to split a span at the position between x r−1 and x r with the node type o ∈ {S, I}, where S and I indicate Straight and Inverted respectively. v is the score of the state, which is the sum of the Input: Sentence x, feature weights Λ, beam width k. Output: BTG parse tree.</p><p>1:</p><formula xml:id="formula_2">S0 ← {⟨[[0, |x|)], [], 0⟩ } // Initial state. 2: for i := 1, · · · , |x| − 1 do 3: S ← {} // Set of the next states. 4: foreach s ∈ Si−1 do 5: S ← S ∪ τx,Λ(s) // Generate next states. 6: Si ← T op k (S)</formula><p>// Select k-best states. 7: ˆ s = argmax s∈S |x|−1 Score(s) 8: return T ree(ˆ s) 9: function τx,Λ(⟨P, C, v⟩) 10: [p, q) ← P.pop() 11: S ← {} 12: for r := p + 1, · · · , q do 13:</p><formula xml:id="formula_3">P ′ ← P 14:</formula><p>if r − p &gt; 1 then 15:</p><formula xml:id="formula_4">P ′ .push([p, r)) 16:</formula><p>if q − r &gt; 1 then 17:</p><formula xml:id="formula_5">P ′ .push([r, q)) 18: v S ← v + Λ · Φ(x, C, p, q, r, S) 19: v I ← v + Λ · Φ(x, C, p, q, r, I) 20:</formula><p>C S ← C; C S .append((r, S)) 21:  <ref type="table" target="#tab_0">Table 1</ref> shows the parser state for each step in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><formula xml:id="formula_6">C I ← C; C I .append((r, I)) 22: S ← S ∪ {⟨P ′ , C S , v S ⟩, ⟨P ′ , C I , v I ⟩} 23: return S</formula><p>The top-down parsing method can be used with beam search as shown in <ref type="figure" target="#fig_3">Figure 4</ref>. τ x,Λ (s) is a function which returns the set of all the possi- ble next states for the state s. T op k (S) returns the top k states from S in terms of their scores, Score(s) returns the score of the state s, and T ree(s) returns the BTG parse tree constructed from s. Φ(x, C, p, q, r, o) is the feature vector for the node created by splitting the span [p, q) at r with the node type o, and is explained in Sec- tion 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Algorithm</head><p>Model parameters Λ are estimated from training examples. We assume that each training example consists of a sentence x and its word order in a target language y = y 0 · · · y |x|−1 , where y i is the position of x i in the target language. For exam- ple, the example sentence in <ref type="figure" target="#fig_0">Figure 1</ref>(a) will have y = 0, 1, 4, 3, 2. y can have ambiguities. Multiple words can be reordered to the same position on the target side. The words whose target positions are unknown are indicated by position −1, and we consider such words can appear at any position. <ref type="bibr">3</ref> For example, the word alignment in <ref type="figure" target="#fig_5">Figure 5</ref> gives the target side word positions y = −1, 2, 1, 0, 0.</p><p>Statistical syntactic parsers are usually trained on tree-annotated corpora. However, corpora an- notated with BTG parse trees are unavailable, and only the gold standard permutation y is available. <ref type="bibr" target="#b30">Neubig et al. (2012)</ref> proposed to train BTG parsers for preordering by regarding BTG trees behind word reordering as latent variables, and we use latent variable Perceptron ( <ref type="bibr" target="#b36">Sun et al., 2009</ref>) to- gether with beam search. In latent variable Percep- tron, among the examples whose latent variables are compatible with a gold standard label, the one with the highest score is picked up as a positive example. Such an approach was used for pars- ing with multiple correct actions <ref type="bibr" target="#b13">(Goldberg and Elhadad, 2010;</ref><ref type="bibr" target="#b35">Sartorio et al., 2013)</ref>. <ref type="figure" target="#fig_6">Figure 6</ref> describes the training algorithm. 4 Φ(x, s) is the feature vector for all the nodes in the partial parse tree at the state s, and τ x,Λ,y (s) is the set of all the next states for the state s. The algorithm adopts the early update technique ( <ref type="bibr" target="#b5">Collins and Roark, 2004</ref>) which terminates incre- mental parsing if a correct state falls off the beam, and there is no possibility to obtain a correct out- put. <ref type="bibr" target="#b14">Huang et al. (2012)</ref> proposed the violation- fixing Perceptron framework which is guaranteed to converge even if inexact search is used, and also showed that early update is a special case of the framework. We define that a parser state is valid if the state can reach a final state whose BTG parse tree is compatible with y. Since this is a latent variable setting in which multiple states can reach correct final states, early update occurs when all the valid states fall off the beam ( <ref type="bibr" target="#b26">Ma et al., 2013;</ref><ref type="bibr" target="#b50">Yu et al., 2013)</ref>. In order to use early up- date, we need to check the validity of each parser <ref type="bibr">3</ref> In ( <ref type="bibr" target="#b30">Neubig et al., 2012)</ref>, the positions of such words were fixed by heuristics. In this study, the positions are not fixed, and all the possibilities are considered by latent variables. <ref type="bibr">4</ref> Although the simple Perceptron algorithm is used for ex- planation, we actually used the Passive Aggressive algorithm <ref type="bibr" target="#b7">(Crammer et al., 2006</ref>) with the parameter averaging tech- nique <ref type="bibr" target="#b10">(Freund and Schapire, 1999</ref>). state. We extend the parser state to the four tu- ple ⟨P, A, v, w⟩, where w ∈ {true, false} is the validity of the state. We remove training exam- ples which cannot be represented with BTG be- forehand and set w of the initial state to true. The function V alid(s) in <ref type="figure" target="#fig_6">Figure 6</ref> returns the validity of state s. One advantage of the top-down pars- ing algorithm is that it is easy to track the validity of each state. The validity of a state can be cal- culated using the following property, and we can implement the function τ x,Λ,y (s) by modifying the function τ x,Λ (s) in <ref type="figure" target="#fig_3">Figure 4</ref>. </p><formula xml:id="formula_7">∀i ∈ {p, · · · , r − 1} y i = −1 ∨ ∀i ∈ {r, · · · , q − 1} y i = −1 ∨ ( o = S ∧ max i=p,··· ,r−1 y i ̸ =−1 y i ≤ min i=r,··· ,q−1 y i ̸ =−1 y i ) ∨ ( o = I ∧ max i=r,··· ,q−1 y i ̸ =−1 y i ≤ min i=p,··· ,r−1 y i ̸ =−1 y i ) .<label>(3)</label></formula><p>Proof. Let π i denote the position of x i after re- ordering by BTG parsing. If Condition (3) does not hold, there are i and j which satisfy π i &lt; π j ∧ y i &gt; y j ∧ y i ̸ = −1 ∧ y j ̸ = −1, and π i and π j are not compatible with y. Therefore, s ′ is valid only if Condition (3) holds. When Condition (3) holds, a valid permutation can be obtained if the spans [p, r) and [r, q) are BTG-parsable. They are BTG-parsable as shown below. Let us assume that y does not have am- biguities. The class of the permutations which can be represented by BTG is known as separable permutations in combinatorics. It can be proven <ref type="bibr" target="#b2">(Bose et al., 1998</ref>) that a permutation is a sepa- rable permutation if and only if it contains nei- ther the 2413 nor the 3142 patterns. Since s is valid, y is a separable permutation. y does not con- tain the 2413 nor the 3142 patterns, and any sub- sequence of y also does not contain the patterns. Thus, [p, r) and [r, q) are separable permutations. The above argument holds even if y has ambigui- ties (duplicated positions or unaligned words). In such a case, we can always make a word order y ′ which specializes y and has no ambiguities (e.g., y ′ = 2, 1.0, 0.0, 0.1, 1.1 for y = −1, 1, 0, 0, 1), because s is valid, and there is at least one BTG parse tree which licenses y. Any subsequence in For dependency parsing and constituent pars- ing, incremental bottom-up parsing methods have been studied <ref type="bibr" target="#b48">(Yamada and Matsumoto, 2003;</ref><ref type="bibr" target="#b31">Nivre, 2004;</ref><ref type="bibr" target="#b13">Goldberg and Elhadad, 2010;</ref><ref type="bibr" target="#b34">Sagae and Lavie, 2005</ref>). Our top-down approach is contrastive to the bottom-up approaches. In the bottom-up approaches, spans which cover individ- ual words are considered at the beginning, then they are merged into larger spans in each step, and a span which covers all the words is obtained at the end. In the top-down approach, a span which covers all the words is considered at the begin- ning, then spans are split into smaller spans in each step, and spans which cover individual words are obtained at the end. The top-down BTG pars- ing method has the advantage that the validity of parser states can be easily tracked.</p><p>The computational complexity of the top-down parsing algorithm is O(kn 2 ) for sentence length n and beam width k, because in Line 5 of <ref type="figure" target="#fig_3">Figure 4</ref>, which is repeated at most k(n − 1) times, at most 2(n − 1) parser states are generated, and their scores are calculated. The learning algorithm uses the same decoding algorithm as in the parsing phase, and has the same time complexity. Note that the validity of a parser state can be calculated in O(1) by pre-calculating min i=p,··· ,r∧y i ̸ =−1 y i , max i=p,··· ,r∧y i ̸ =−1 y i , min i=r,··· ,q−1∧y i ̸ =−1 y i , and max i=r,··· ,q−1∧y i ̸ =−1 y i for all r for the span [p, q) when it is popped from the stack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Features</head><p>We assume that each word x i in a sentence has three attributes: word surface form x w i , part-of- speech (POS) tag x p i and word class x c i (Sec- tion 4.1 explains how x p i and x c i are obtained). <ref type="table" target="#tab_1">Table 2</ref> lists the features generated for the node which is created by splitting the span [p, q) with the action (r, o). o' is the node type of the par- ent node, d ∈ {left, right} indicates whether this node is the left-hand-side or the right-hand-side child of the parent node, and Balance(p, q, r) re- Input: Training data {⟨x l , y l ⟩} L−1 l=0 , number of iterations T , beam width k. Output: Feature weights Λ.</p><p>1: Λ ← 0 2: for t := 0, · · · , T − 1 do 3:</p><formula xml:id="formula_8">for l := 0, · · · , L − 1 do 4: S0 ← {⟨[[0, |x l |)], [], 0, true⟩} 5: for i := 1, · · · , |x l | − 1 do 6: S ← {} 7:</formula><p>foreach s ∈ Si−1 do 8:</p><p>S ← S ∪ τ x l ,Λ,y l (s) 9:</p><p>Si ← T op k (S) 10: ˆ s ← argmax s∈S Score(s) 11:</p><p>s * ← argmax s∈S∧V alid(s) Score(s) 12:</p><p>if s * / ∈ Si then 13:</p><p>break // Early update. 14:</p><p>ifˆsifˆ ifˆs ̸ = s * then 15:  <ref type="formula" target="#formula_0">2012)</ref>, and the additional feature tem- plates are extended features that we introduce in this study. The top-down parser is fast, and allows us to use a larger number of features.</p><formula xml:id="formula_9">Λ ← Λ + Φ(x l , s * ) − Φ(x l , ˆ s) 16: return Λ</formula><p>In order to make the feature generation efficient, the attributes of all the words are converted to their 64-bit hash values beforehand, and concatenating the attributes is executed not as string manipula- tion but as faster integer calculation to generate a hash value by merging two hash values. The hash values are used as feature names. Therefore, when accessing feature weights stored in a hash table using the feature names as keys, the keys can be used as their hash values. This technique is differ- ent from the hashing trick ( <ref type="bibr" target="#b11">Ganchev and Dredze, 2008)</ref> which directly uses hash values as indices, and no noticeable differences in accuracy were ob- served by using this technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training Data for Preordering</head><p>As described in Section 3.2, each training example has y which represents correct word positions after reordering. However, only word alignment data is generally available, and we need to convert it to y. Let A i denote the set of indices of the target- side words which are aligned to the source-side word x i . We define an order relation between two words: Then, we sort x using the order relation and as- sign the position of x i in the sorted result to y i . If there are two words x i and x j in x which sat- isfy neither x i ≤ x j nor x j ≤ x i (that is, x does not make a totally ordered set with the order rela- tion), then x cannot be sorted, and the example is removed from the training data. −1 is assigned to the words which do not have aligned target words.</p><formula xml:id="formula_10">x i ≤ x j ⇔ ∀a ∈ A i \ A j , ∀b ∈ A j a ≤ b ∧ ∀a ∈ A i , ∀b ∈ A j \ A i a ≤ b. (4) Baseline Feature Template o(q − p), oBalance(p, q, r), ox w p−1 , ox w p , ox w r−1 , ox w r , ox w q−1 , ox w q , ox w p x w q−1 , ox w r−1 x w r , ox p p−1 , ox p p , ox p r−1 , ox p r , ox p q−1 , ox p q , ox p p x p q−1 , ox p r−1 x p r , ox c p−1 , ox c p , ox c r−1 , ox c r , ox c q−1 , ox c q , ox c p x c q−1 , ox c r−1 x c r . Additional Feature Template o min(r − p, 5) min(q − r, 5), oo ′ , oo ′ d, ox w p−1 x w p , ox w p x w r−1 , ox w p x w r , ox w r−1 x w q−1 , ox w r x w q−1 , ox w q−1 x w q ,</formula><note type="other">ox w r−2 x w r−1 x w r , ox w p x w r−1 x w r , ox w r−1 x w r x w q−1 , ox w r−1 x w r x w r+1 , ox w p x w r−1 x w r x</note><formula xml:id="formula_11">w q−1 , oo ′ dx w p , oo ′ dx w r−1 , oo ′ dx w r , oo ′ dx w q−1 , oo ′ dx w p x w q−1 , ox p p−1 x p p , ox p p x p r−1 , ox p p x p r , ox p r−1 x p q−1 , ox p r x p q−1 , ox p q−1 x p q , ox p r−2 x p r−1 x p r , ox p p x p r−1 x p r , ox p r−1 x p r x p q−1 , ox p r−1 x p r x p r+1 , ox p p x p r−1 x p r x p q−1 , oo ′ dx p p , oo ′ dx p r−1 , oo ′ dx p r , oo ′ dx p q−1 , oo ′ dx p p x p q−1 , ox c p−1 x c p , ox c p x c r−1 , ox c p x c r , ox c r−1 x c q−1 , ox c r x c q−1 , ox c q−1 x c q , ox c r−2 x c r−1 x c r , ox c p x c r−1 x c r , ox c r−1 x c r x c q−1 , ox c r−1 x c r x c r+1 , ox c p x c r−1 x c r x c q−1 , oo ′ dx c p , oo ′ dx c r−1 , oo ′ dx c r , oo ′ dx c q−1 , oo ′ dx c p x c q−1 .</formula><p>Two words x i and x j are regarded to have the same position if x i ≤ x j and x j ≤ x i . The quality of training data is important to make accurate preordering systems, but automat- ically word-aligned data by EM algorithms tend to have many wrong alignments. We use forced- decoding in order to make training data for pre- ordering. Given a parallel sentence pair and a phrase table, forced-decoding tries to translate the source sentence to the target sentence, and pro- duces phrase alignments. We train the parameters for forced-decoding using the same parallel data used for training the final translation system. In- frequent phrase translations are pruned when the phrase table is created, and forced-decoding does not always succeed for the parallel sentences in the training data. Forced-decoding tends to succeed for shorter sentences, and the phrase-alignment data obtained by forced-decoding is biased to con- tain more shorter sentences. Therefore, we apply the following processing for the output of forced- decoding to make training data for preordering:</p><p>1. Remove sentences which contain less than 3 or more than 50 words.</p><p>2. Remove sentences which contain less than 3 phrase alignments.</p><p>3. Remove sentences if they contain word 5- grams which appear in other sentences in or- der to drop boilerplates. 4. Lastly, randomly resample sentences from the pool of filtered sentences to make the distribution of the sentence lengths follow a normal distribution with the mean of 20 and the standard deviation of 8. The parame- ters were determined from randomly sampled sentences from the Web.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We conduct experiments for 12 language pairs: Dutch (nl)-English (en), en-nl, en-French (fr), en- Japanese (ja), en-Spanish (es), fr-en, Hindi (hi)-en, ja-en, Korean (ko)-en, Turkish (tr)-en, Urdu (ur)- en and Welsh (cy)-en. We use a phrase-based statistical machine trans- lation system which is similar to ( <ref type="bibr" target="#b32">Och and Ney, 2004</ref>). The decoder adopts the regular distance distortion model, and also incorporates a maxi- mum entropy based lexicalized phrase reordering model ( <ref type="bibr" target="#b51">Zens and Ney, 2006</ref>). The distortion limit is set to 5 words. Word alignments are learned using 3 iterations of IBM Model-1 ( <ref type="bibr" target="#b3">Brown et al., 1993</ref>) and 3 iterations of the HMM alignment model ( <ref type="bibr" target="#b44">Vogel et al., 1996)</ref>. Lattice-based mini- mum error rate training (MERT) ( <ref type="bibr" target="#b27">Macherey et al., 2008</ref>) is applied to optimize feature weights. 5- gram language models trained on sentences col- lected from various sources are used.</p><p>The translation system is trained with parallel sentences automatically collected from the Web. The parallel data for each language pair consists of around 400 million source and target words. In order to make the development data for MERT and test data (3,000 and 5,000 sentences respectively for each language), we created parallel sentences by randomly collecting English sentences from the Web, and translating them by humans into each language.</p><p>As an evaluation metric for translation quality, BLEU ( <ref type="bibr" target="#b33">Papineni et al., 2002</ref>) is used. As intrin- sic evaluation metrics for preordering, Fuzzy Re- ordering Score (FRS) <ref type="bibr" target="#b38">(Talbot et al., 2011</ref>) and <ref type="bibr">Kendall's τ (Kendall, 1938;</ref><ref type="bibr" target="#b1">Birch et al., 2010;</ref><ref type="bibr" target="#b15">Isozaki et al., 2010</ref>) are used. Let ρ i denote the po- sition in the input sentence of the (i+1)-th token in a preordered word sequence excluding unaligned words in the gold-standard evaluation data. For   <ref type="table">Table 4</ref>: Performance of preordering for various training data. Bold BLEU scores indicate no statistically significant difference at p &lt; 0.05 from the best system <ref type="bibr" target="#b20">(Koehn, 2004</ref>).</p><note type="other">en-ja ja-en Training</note><p>example, the preordering result "New York I to went" for the gold-standard data in <ref type="figure" target="#fig_5">Figure 5</ref> has ρ = 3, 4, 2, 1. Then FRS and τ are calculated as follows:</p><formula xml:id="formula_12">F RS = B |ρ| + 1 ,<label>(5)</label></formula><formula xml:id="formula_13">B = |ρ|−2 ∑ i=0 δ(y ρ i =y ρ i+1 ∨ y ρ i +1=y ρ i+1 ) + δ(y ρ 0 =0) + δ(y ρ |ρ|−1 = max i y i ), (6) τ = ∑ |ρ|−2 i=0 ∑ |ρ|−1 j=i+1 δ(y ρ i ≤ y ρ j ) 1 2 |ρ|(|ρ| − 1) ,<label>(7)</label></formula><p>where δ(X) is the Kronecker's delta function which returns 1 if X is true or 0 otherwise. These scores are calculated for each sentence, and are av- eraged over all sentences in test data. As above, FRS can be calculated as the precision of word bi- grams (B is the number of the word bigrams which exist both in the system output and the gold stan- dard data). This formulation is equivalent to the original formulation based on chunk fragmenta- tion by <ref type="bibr" target="#b38">Talbot et al. (2011)</ref>. Equation (6) takes into account the positions of the beginning and the ending words ( <ref type="bibr" target="#b30">Neubig et al., 2012</ref>). Kendall's τ is equivalent to the (normalized) crossing alignment link score used by <ref type="bibr" target="#b12">Genzel (2010)</ref>. We prepared three types of training data for learning model parameters of BTG-based pre- ordering:</p><p>Manual-8k Manually word-aligned 8,000 sen- tence pairs. EM-10k, EM-100k These are the data obtained with the EM-based word alignment learn- ing.</p><p>From the word alignment result for phrase translation extraction described above, 10,000 and 100,000 sentence pairs were randomly sampled. Before the sam- pling, the data filtering procedure 1 and 3 in Section 3.4 were applied, and also sen- tences were removed if more than half of source words do not have aligned target words. Word alignment was obtained by symmetrizing source-to-target and target-to- source word alignment with the INTERSEC- TION heuristic. <ref type="bibr">5</ref> Forced-10k, Forced-100k These are 10,000 and 100,000 word-aligned sentence pairs ob- tained with forced-decoding as described in Section 3.4.</p><p>As test data for intrinsic evaluation of preordering, we manually word-aligned 2,000 sentence pairs for en-ja and ja-en. Several preordering systems were prepared in order to compare the following six systems:</p><p>No-Preordering This is a system without pre- ordering. Manual-Rules This system uses the preordering method based on manually created rules (Xu    <ref type="bibr">, 2009</ref>). We made 43 precedence rules for en-ja, and 24 for ja-en. Auto-Rules This system uses the rule-based pre- ordering method which automatically learns the rules from word-aligned data using the Variant 1 learning algorithm described in <ref type="bibr" target="#b12">(Genzel, 2010)</ref>. 27 to 36 rules were automat- ically learned for each language pair. Classifier This system uses the preordering method based on statistical classifiers ( <ref type="bibr" target="#b23">Lerner and Petrov, 2013)</ref>, and the 2-step algorithm was implemented. Lader This system uses Latent Derivation Re- orderer ( <ref type="bibr" target="#b30">Neubig et al., 2012)</ref>, which is a BTG-based preordering system using the CYK algorithm. <ref type="bibr">6</ref> The basic feature templates in <ref type="table" target="#tab_1">Table 2</ref>   <ref type="table" target="#tab_1">Table 2</ref> are obtained by us- ing Brown clusters ( <ref type="bibr" target="#b21">Koo et al., 2008</ref>) (the number of classes is set to 256). For both Lader and Top- Down, the beam width is set to 20, and the number of training iterations of online learning is set to 20. The CPU time shown in this paper is measured using Intel Xeon 3.20GHz with 32GB RAM. <ref type="table" target="#tab_3">Table 3</ref> shows the training time and preordering speed together with the intrinsic evaluation met- rics. In this experiment, both Top-Down and Lader were trained using the EM-100k data. Compared to Lader, Top-Down was faster: more than 20 times in training, and more than 10 times in pre- ordering. Top-down had higher preordering ac- curacy in FRS and τ for en-ja. Although Lader uses sophisticated loss functions, Top-Down uses a larger number of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Training and Preordering Speed</head><p>Top-Down (Basic feats.) is the top-down method using only the basic feature templates in <ref type="table" target="#tab_1">Table 2</ref>. It was much faster but less accurate than Top-Down using the additional features. Top- Down (Basic feats.) and Lader use exactly the same features. However, there are differences in the two systems, and they had different accuracies. Top-Down uses the beam search-based top-down method for parsing and the Passive-Aggressive al- gorithm for parameter estimation, and Lader uses the CYK algorithm with cube pruning and an on-line SVM algorithm. Especially, Lader optimizes FRS in the default setting, and it may be the reason that Lader had higher FRS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Performance of Preordering for</head><p>Various Training Data <ref type="table">Table 4</ref> shows the preordering accuracy and BLEU scores when Top-Down was trained with various data. The best BLEU score for Top-Down was ob- tained by using manually annotated data for en- ja and 100k forced-decoding data for ja-en. The performance was improved by increasing the data size. <ref type="table" target="#tab_5">Table 5</ref> shows the BLEU score of each system for 12 language pairs. Some blank fields mean that the results are unavailable due to the lack of rules or dependency parsers. For all the language pairs, Top-Down had higher BLEU scores than Lader. For ja-en and ur-en, using Forced-100k instead of EM-100k for Top-Down improved the BLEU scores by more than 0.6, but it did not always im- proved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">End-to-End Evaluation for Various Language Pairs</head><p>Manual-Rules performed the best for en-ja, but it needs manually created rules and is difficult to be applied to many language pairs. Auto- Rules and Classifier had higher scores than No- Preordering except for fr-en, but cannot be applied to the languages with no available dependency parsers. Top-Down (Forced-100k) can be applied to any language, and had statistically significantly better BLEU scores than No-Preordering, Manual- Rules, Auto-Rules, Classifier and Lader for 7 lan- guage pairs (en-fr, fr-en, hi-en, ja-en, ko-en, tr-en and ur-en), and similar performance for other lan- guage pairs except for en-ja, without dependency parsers trained with manually annotated data.</p><p>In all the experiments so far, the decoder was allowed to reorder even after preordering was car- ried out. In order to see the performance without reordering after preordering, we conducted exper- iments by setting the distortion limit to 0. <ref type="table" target="#tab_6">Table 6</ref> shows the results. The effect of the distortion lim- its varies for language pairs and preordering meth- ods. The BLEU scores of Top-Down were not af- fected largely even when relying only on preorder- ing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a top-down BTG pars- ing method for preordering. The method in- crementally builds parse trees by splitting larger spans into smaller ones. The method provides an easy way to check the validity of each parser state, which allows us to use early update for latent vari- able Perceptron with beam search. In the exper- iments, it was shown that the top-down parsing method is more than 10 times faster than a CYK- based method. The top-down method had better BLEU scores for 7 language pairs without relying on supervised syntactic parsers compared to other preordering methods. Future work includes devel- oping a bottom-up BTG parser with latent vari- ables, and comparing the results to the top-down parser.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of preordering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Bracketing transduction grammar. 2.2 BTG-based Preordering Neubig et al. (2012) proposed a BTG-based preordering method. Bracketing Transduction Grammar (BTG) (Wu, 1997) is a binary synchronous context-free grammar with only one non-terminal symbol, and has three types of rules (Figure 2): Straight which keeps the order of child nodes, Inverted which reverses the order, and Terminal which generates a terminal symbol. 1 BTG can express word reordering. For example, the word reordering in Figure 1(a) can be represented with the BTG parse tree in Figure 1(b). 2 Therefore, the task to reorder an input source sentence can be solved as a BTG parsing task to find an appropriate BTG tree. In order to find the best BTG tree among all the possible ones, a score function is defined. Let Φ(m) denote the vector of feature functions for the BTG tree node m, and Λ denote the vector of feature weights. Then, for a given source sentence x, the best BTG treê z and the reordered sentence x ′ can be obtained as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Top-down BTG parsing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Top-down BTG parsing with beam search. scores for the nodes constructed so far. Parsing starts with the initial state ⟨[[0, |x|)], [], 0⟩, because there is one span covering all the words at the beginning. In each step, a span is popped from the top of the stack, and a splitting point in the span and its node type are determined. The new spans generated by the split are pushed onto the stack if their lengths are greater than 1, and the action is added to the list. On termination, the parser has the final state ⟨[], [c 0 , · · · , c |x|−2 ], v⟩, because the stack is empty and there are (|x| − 1) actions in total. The parse tree can be obtained from the list of actions. Table 1 shows the parser state for each step in Figure 3. The top-down parsing method can be used with beam search as shown in Figure 4. τ x,Λ (s) is a function which returns the set of all the possible next states for the state s. T op k (S) returns the top k states from S in terms of their scores, Score(s) returns the score of the state s, and T ree(s) returns the BTG parse tree constructed from s. Φ(x, C, p, q, r, o) is the feature vector for the node created by splitting the span [p, q) at r with the node type o, and is explained in Section 3.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Lemma 1 .</head><label>1</label><figDesc>When a valid state s, which has [p, q) in the top of the stack, transitions to a state s ′ by the action (r, o), s ′ is also valid if and only if the following condition holds:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: An example of word reordering with ambiguities. y ′ is a separable permutation, and [p, r) and [r, q) are separable permutations. Therefore, s ′ is valid if Condition (3) holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: A training algorithm for latent variable Perceptron with beam search. turns a value among {'&lt;', '=', '&gt;'} according to the relation of the lengths of [p, r) and [r, q). The baseline feature templates are those used by Neubig et al. (2012), and the additional feature templates are extended features that we introduce in this study. The top-down parser is fast, and allows us to use a larger number of features. In order to make the feature generation efficient, the attributes of all the words are converted to their 64-bit hash values beforehand, and concatenating the attributes is executed not as string manipulation but as faster integer calculation to generate a hash value by merging two hash values. The hash values are used as feature names. Therefore, when accessing feature weights stored in a hash table using the feature names as keys, the keys can be used as their hash values. This technique is different from the hashing trick (Ganchev and Dredze, 2008) which directly uses hash values as indices, and no noticeable differences in accuracy were observed by using this technique.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Parser states in top-down parsing.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Feature templates.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Speed and accuracy of preordering.</head><label>3</label><figDesc></figDesc><table>en-ja 
ja-en 
FRS 
τ 
BLEU 
FRS 
τ 
BLEU 
Top-Down 
(Manual-8k) 81.57 90.44 
18.13 
79.26 86.47 
14.26 
(EM-10k) 74.79 85.87 
17.07 
72.51 82.65 
14.55 
(EM-100k) 77.83 87.78 
17.66 
74.60 83.78 
14.84 
(Forced-10k) 76.10 87.45 
16.98 
75.36 83.96 
14.78 
(Forced-100k) 78.76 89.22 
17.88 
76.58 85.25 
15.54 
Lader 
(EM-100k) 75.41 86.85 
17.40 
74.89 82.15 
14.59 
No-Preordering 
46.17 65.07 
13.80 
59.35 65.30 
10.31 
Manual-Rules 
80.59 90.30 
18.68 
73.65 81.72 
14.02 
Auto-Rules 
64.13 84.17 
16.80 
60.60 75.49 
12.59 
Classifier 
80.89 90.61 
18.53 
74.24 82.83 
13.90 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 5 : BLEU score comparison.</head><label>5</label><figDesc></figDesc><table>Distortion 
No-
Manual-Auto-Classifier 
Lader 
Top-Down 
Top-Down 
Limit 
Preordering 
Rules 
Rules 
(EM-100k) (EM-100k) (Forced-100k) 
en-ja 
5 
13.80 
18.68 
16.80 
18.53 
17.40 
17.66 
17.88 
en-ja 
0 
11.99 
18.34 
16.87 
18.31 
16.95 
17.36 
17.88 
ja-en 
5 
10.31 
14.02 
12.59 
13.90 
14.59 
14.84 
15.54 
ja-en 
0 
10.03 
12.43 
11.33 
13.09 
14.38 
14.72 
15.34 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc>BLEU scores for different distortion limits. et al.</figDesc><table></table></figure>

			<note place="foot" n="5"> In our preliminary experiments, the UNION and GROWDIAG-FINAL heuristics were also applied to generate the training data for preordering, but INTERSECTION performed the best.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building a Web-Based Parallel Corpus and Filtering Out Machine-Translated Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Antonova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Misyurev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web</title>
		<meeting>the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metrics for MT Evaluation: Evaluating Reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pattern matching for permutations. Information Processing Letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prosenjit</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">F</forename><surname>Buss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Lubiw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="277" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
		<title level="m">The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="263" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hierarchical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental Parsing with the Perceptron Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Clause Restructuring for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivona</forename><surname>Kucerova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shai Shalev-Shwartz, and Yoram Singer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Online Passive-Aggressive Algorithms</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inducing Sentence Structure from Parallel Corpora for Reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on</title>
		<meeting>the 2011 Conference on</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<title level="m">Natural Language Processing</title>
		<imprint>
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large Margin Classification Using the Perceptron Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="277" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Small Statistical Models by Random Feature Mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-08: HLT Workshop on Mobile Language Processing</title>
		<meeting>the ACL-08: HLT Workshop on Mobile Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="19" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatically Learning Source-side Reordering Rules for Large Scale Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Genzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="376" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An Efficient Algorithm for Easy-first Non-directional Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="742" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structured Perceptron with Inexact Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suphan</forename><surname>Fayong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="142" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic Evaluation of Translation Quality for Distant Language Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="944" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Source-side Preordering for Translation using Logistic Regression and Depthfirst Branch-and-Bound Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Jehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="239" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A New Measure of Rank Correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Source reordering using MaxEnt classifiers and supertags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Khalilov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference of the European Association for Machine Translation</title>
		<meeting>the 14th Annual Conference of the European Association for Machine Translation</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Statistical Significance Tests for Machine Translation Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simple Semi-supervised Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th International Conference on Machine Learning</title>
		<meeting>the 18th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Source-Side Classifier Preordering for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="513" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Probabilistic Approach to Syntax-based Reordering for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Ho</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="720" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Easy-First POS Tagging and Dependency Parsing with Beam Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="110" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Lattice-based Minimum Error Rate Training for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Thayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="725" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pre-Reordering for Machine Translation Using Transition-Based Walks on Dependency Parse Trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miceli</forename><surname>Valerio Antonio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Barone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Attardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Workshop on Statistical Machine Translation</title>
		<meeting>the 8th Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Discriminative Reordering Parser for IWSLT 2013</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwidong</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong-Hyeok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop for Spoken Language Translation</title>
		<meeting>the 10th International Workshop for Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="83" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Inducing a Discriminative Parser to Optimize Machine Translation Reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="843" to="853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Incrementality in Deterministic Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together</title>
		<meeting>the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The Alignment Template Approach to Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="449" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A Classifier-Based Parser with Linear Run-Time Complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Parsing Technology</title>
		<meeting>the 9th International Workshop on Parsing Technology</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Transition-Based Dependency Parser Using a Dynamic Parsing Strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Sartorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="135" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Latent Variable Perceptron Algorithm for Structured Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Okanohara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Joint Conference on Artificial Intelligence</title>
		<meeting>the 21st International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Token and Type Constraints for Cross-Lingual Part-of-Speech Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A Lightweight Evaluation Framework for Machine Translation Reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Ichikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Katz-Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masakazu</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Statistical Machine Translation</title>
		<meeting>the 6th Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="12" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Unigram Orientation Model for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2004 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="101" to="104" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning Linear Ordering Problems for Better Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Tromble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1007" to="1016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Large Scale Parallel Document Mining for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashok</forename><forename type="middle">C</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Dubiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1101" to="1109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Syntax Based Reordering with Automatically Derived Rules for Improved Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Visweswariah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Navratil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1119" to="1127" />
		</imprint>
	</monogr>
	<note>Vijil Chenthamarakshan, and Nandakishore Kambhatla</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A Word Reordering Model for Improved Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Visweswariah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajakrishnan</forename><surname>Rajkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Gandhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananthakrishnan</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Navratil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="486" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">HMM-based Word Alignment in Statistical Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference on Computational Linguistics</title>
		<meeting>the 16th Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="836" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improving a Statistical MT System with Automatically Learned Rewrite Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Computational Linguistics</title>
		<meeting>the 20th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="508" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Using a Dependency Parser to Improve SMT for Subject-Object-Verb Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeho</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="245" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Statistical Dependency Analysis with Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Parsing Technologies</title>
		<meeting>the 8th International Workshop on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A Ranking-based Approach to Word Reordering for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="912" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Max-Violation Perceptron and Forced Decoding for Scalable MT Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1112" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Discriminative Reordering Models for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on the Workshop on Statistical Machine Translation</title>
		<meeting>on the Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Transition-based Dependency Parsing with Rich Non-local Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Short Papers</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="188" to="193" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
