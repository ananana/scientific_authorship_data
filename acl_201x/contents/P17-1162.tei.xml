<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Balakrishnan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihail</forename><surname>Eric</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<title level="a" type="main">Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1766" to="1776"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1162</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both struc-tured knowledge and unstructured language , we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Current task-oriented dialogue systems ( <ref type="bibr" target="#b32">Young et al., 2013;</ref><ref type="bibr" target="#b28">Wen et al., 2017;</ref><ref type="bibr" target="#b4">Dhingra et al., 2017)</ref> require a pre-defined dialogue state (e.g., slots such as food type and price range for a restau- rant searching task) and a fixed set of dialogue acts (e.g., request, inform). However, human conversa- tion often requires richer dialogue states and more nuanced, pragmatic dialogue acts. Recent open- domain chat systems ( <ref type="bibr" target="#b24">Shang et al., 2015;</ref><ref type="bibr" target="#b23">Serban et al., 2015b;</ref><ref type="bibr" target="#b25">Sordoni et al., 2015;</ref><ref type="bibr" target="#b11">Li et al., 2016a;</ref><ref type="bibr" target="#b16">Lowe et al., 2017;</ref><ref type="bibr" target="#b18">Mei et al., 2017</ref>) learn a map- ping directly from previous utterances to the next utterance. While these models capture open-ended aspects of dialogue, the lack of structured dialogue state prevents them from being directly applied to settings that require interfacing with structured knowledge.</p><p>In order to bridge the gap between the two types <ref type="figure">Figure 1</ref>: An example dialogue from the Mutual- Friends task in which two agents, A and B, each given a private list of a friends, try to identify their mutual friend. Our objective is to build an agent that can perform the task with a human. Cross- talk (Section 2.3) is italicized.</p><p>of systems, we focus on a symmetric collabora- tive dialogue setting, which is task-oriented but encourages open-ended dialogue acts. In our set- ting, two agents, each with a private list of items with attributes, must communicate to identify the unique shared item. Consider the dialogue in <ref type="figure">Fig- ure</ref> 1, in which two people are trying to find their mutual friend. By asking "do you have anyone who went to columbia?", B is suggesting that she has some Columbia friends, and that they probably work at Google. Such conversational implicature is lost when interpreting the utterance as simply an information request. In addition, it is hard to define a structured state that captures the diverse semantics in many utterances (e.g., defining "most of", "might be"; see details in <ref type="table">Table 1</ref>).</p><p>To model both structured and open-ended con- text, we propose the Dynamic Knowledge Graph Network (DynoNet), in which the dialogue state is modeled as a knowledge graph with an embedding for each node <ref type="bibr">(Section 3)</ref>. Our model is similar to <ref type="bibr">EntNet (Henaff et al., 2017)</ref> in that node/entity embeddings are updated recurrently given new utterances. The difference is that we structure entities as a knowledge graph; as the dialogue proceeds, new nodes are added and new context is propagated on the graph. An attention-based mechanism ( <ref type="bibr" target="#b2">Bahdanau et al., 2015</ref>) over the node embeddings drives generation of new utterances. Our model's use of knowledge graphs captures the grounding capability of classic task-oriented sys- tems and the graph embedding provides the repre- sentational flexibility of neural models.</p><p>The naturalness of communication in the sym- metric collaborative setting enables large-scale data collection: We were able to crowdsource around 11K human-human dialogues on Amazon Mechanical Turk (AMT) in less than 15 hours. <ref type="bibr">1</ref> We show that the new dataset calls for more flex- ible representations beyond fully-structured states <ref type="bibr">(Section 2.2)</ref>.</p><p>In addition to conducting the third-party human evaluation adopted by most work ( <ref type="bibr" target="#b15">Liu et al., 2016;</ref><ref type="bibr" target="#b12">Li et al., 2016b</ref>,c), we also conduct partner evalu- ation ( <ref type="bibr" target="#b28">Wen et al., 2017</ref>) where AMT workers rate their conversational partners (other workers or our models) based on fluency, correctness, coopera- tion, and human-likeness. We compare DynoNet with baseline neural models and a strong rule- based system. The results show that DynoNet can perform the task with humans efficiently and nat- urally; it also captures some strategic aspects of human-human dialogues.</p><p>The contributions of this work are: (i) a new symmetric collaborative dialogue setting and a large dialogue corpus that pushes the boundaries of existing dialogue systems; (ii) DynoNet, which integrates semantically rich utterances with struc- tured knowledge to represent open-ended dialogue states; (iii) multiple automatic metrics based on bot-bot chat and a comparison of third-party and partner evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Symmetric Collaborative Dialogue</head><p>We begin by introducing a collaborative task be- tween two agents and describe the human-human dialogue collection process. We show that our data exhibits diverse, interesting language phenomena.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Definition</head><p>In the symmetric collaborative dialogue setting, there are two agents, A and B, each with a pri- vate knowledge base-KB A and KB B , respec- tively. Each knowledge base includes a list of items, where each item has a value for each at- tribute. For example, in the MutualFriends set- ting, <ref type="figure">Figure 1</ref>, items are friends and attributes are name, school, etc. There is a shared item that A and B both have; their goal is to converse with each other to determine the shared item and select it. Formally, an agent is a mapping from its pri- vate KB and the dialogue thus far (sequence of ut- terances) to the next utterance to generate or a se- lection. A dialogue is considered successful when both agents correctly select the shared item. This setting has parallels in human-computer collabora- tion where each agent has complementary exper- tise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data collection</head><p>We created a schema with 7 attributes and approx- imately 3K entities (attribute values). To elicit lin- guistic and strategic variants, we generate a ran- dom scenario for each task by varying the num- ber of items (5 to 12), the number attributes (3 or 4), and the distribution of values for each attribute (skewed to uniform). See Appendix A and B for details of schema and scenario generation. We crowdsourced dialogues on AMT by ran- domly pairing up workers to perform the task within 5 minutes. <ref type="bibr">2</ref> Our chat interface is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. To discourage random guessing, we pre- vent workers from selecting more than once every 10 seconds. Our task was very popular and we col-  lected 11K dialogues over a period of 13.5 hours. <ref type="bibr">3</ref> Of these, over 9K dialogues are successful. Un- successful dialogues are usually the result of either worker leaving the chat prematurely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Dataset statistics</head><p>We show the basic statistics of our dataset in <ref type="table" target="#tab_3">Ta- ble 3</ref>. An utterance is defined as a message sent by one of the agents. The average utterance length is short due to the informality of the chat, how- ever, an agent usually sends multiple utterances in one turn. Some example dialogues are shown in  We categorize utterances into coarse types- inform, ask, answer, greeting, apology-by pattern matching (Appendix E). There are 7.4% multi- type utterances, and 30.9% utterances contain more than one entity. In <ref type="table">Table 1</ref>, we show exam- ple utterances with rich semantics that cannot be sufficiently represented by traditional slot-values.</p><p>Some of the standard ones are also non-trivial due to coreference and logical compositionality.</p><p>Our dataset also exhibits some interesting com- munication phenomena. Coreference occurs fre- quently when people check multiple attributes of one item. Sometimes mentions are dropped, as an utterance simply continues from the part- ner's utterance. People occasionally use exter- nal knowledge to group items with out-of-schema attributes (e.g., gender based on names, location based on schools). We summarize these phenom- ena in <ref type="table" target="#tab_1">Table 2</ref>. In addition, we find 30% utter- ances involve cross-talk where the conversation does not progress linearly (e.g., italic utterances in <ref type="figure">Figure 1</ref>), a common characteristic of online chat <ref type="bibr" target="#b7">(Ivanovic, 2005)</ref>.</p><p>One strategic aspect of this task is choosing the order of attributes to mention. We find that people tend to start from attributes with fewer unique val- ues, e.g., "all my friends like morning" given the KB B in <ref type="table" target="#tab_2">Table 6</ref>, as intuitively it would help ex- clude items quickly given fewer values to check. <ref type="bibr">5</ref> We provide a more detailed analysis of strategy in Section 4.2 and Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic Knowledge Graph Network</head><p>The diverse semantics in our data motivates us to combine unstructured representation of the di- alogue history with structured knowledge. Our The knowledge graph represents entities and re- lations in the agent's private KB, e.g., item-1's company is google. As the conversation unfolds, utterances are embedded and incorporated into node embeddings of mentioned entities. For in- stance, in <ref type="figure" target="#fig_1">Figure 3</ref>, "anyone went to columbia" updates the embedding of columbia. Next, each node recursively passes its embedding to neigh- boring nodes so that related entities (e.g., those in the same row or column) also receive informa- tion from the most recent utterance. In our exam- ple, jessica and josh both receive new context when columbia is mentioned. Finally, the utter- ance generator, an LSTM, produces the next utter- ance by attending to the node embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knowledge Graph</head><p>Given a dialogue of T utterances, we construct graphs (G t ) T t=1 over the KB and dialogue history for agent A. <ref type="bibr">6</ref> There are three types of nodes: item nodes, attribute nodes, and entity nodes. Edges between nodes represent their relations. For ex- ample, (item-1, hasSchool, columbia) means that the first item has attribute school whose value <ref type="bibr">6</ref> It is important to differentiate perspectives of the two agents as they have different KBs. Thereafter we assume the perspective of agent A, i.e., accessing KBA for A only, and refer to B as the partner.</p><p>is columbia. An example graph is shown in <ref type="figure" target="#fig_1">Fig- ure 3</ref>. The graph G t is updated based on utterance t by taking G t1 and adding a new node for any entity mentioned in utterance t but not in KB A . <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Embedding</head><p>Given a knowledge graph, we are interested in computing a vector representation for each node v that captures both its unstructured context from the dialogue history and its structured context in the KB. A node embedding V t (v) for each node v 2 G t is built from three parts: structural prop- erties of an entity defined by the KB, embeddings of utterances in the dialogue history, and message passing between neighboring nodes.</p><p>Node Features. Simple structural properties of the KB often govern what is talked about; e.g., a high-frequency entity is usually interesting to mention (consider "All my friends like dancing.").</p><p>We represent this type of information as a fea- ture vector F t (v), which includes the degree and type (item, attribute, or entity type) of node v, and whether it has been mentioned in the current turn. Each feature is encoded as a one-hot vector and they are concatenated to form F t (v).</p><p>Mention Vectors. A mention vector M t (v) con- tains unstructured context from utterances relevant to node v up to turn t. To compute it, we first de- fine the utterance representatioñ u t and the set of relevant entities E t . Let u t be the embedding of utterance t (Section 3.3). To differentiate between the agent's and the partner's utterances, we repre- sent it as˜uas˜</p><formula xml:id="formula_0">as˜u t = ⇥ u t · {ut2U self } , u t · {ut2Upartner} ⇤ ,</formula><p>where U self and U partner denote sets of utterances generated by the agent and the partner, and [·, ·] denotes concatenation. Let E t be the set of entity nodes mentioned in utterance t if utterance t men- tions some entities, or utterance t 1 otherwise. <ref type="bibr">8</ref> The mention vector M t (v) of node v incorporates the current utterance if v is mentioned and inherits M t1 (v) if not:</p><formula xml:id="formula_1">M t (v) = t M t1 (v) + (1 t )˜ u t ;<label>(1)</label></formula><formula xml:id="formula_2">t = ( W inc [M t1 (v), ˜ u t ] if v 2 E t , 1 otherwise.</formula><p>Here, is the sigmoid function and W inc is a pa- rameter matrix.</p><p>Recursive Node Embeddings. We propagate information between nodes according to the struc- ture of the knowledge graph. In <ref type="figure" target="#fig_1">Figure 3</ref>, given "anyone went to columbia?", the agent should fo- cus on her friends who went to Columbia Univer- sity. Therefore, we want this utterance to be sent to item nodes connected to columbia, and one step further to other attributes of these items because they might be mentioned next as relevant informa- tion, e.g., jessica and josh. We compute the node embeddings recursively, analogous to belief propagation:</p><formula xml:id="formula_3">V k t (v) = max v 0 2Nt(v) tanh (2) ⇣ W mp h V k1 t (v 0 ), R(e v!v 0 ) i⌘ ,</formula><p>where V k t (v) is the depth-k node embedding at turn t and N t (v) denotes the set of nodes adjacent to v. The message from a neighboring node v 0 de- pends on its embedding at depth-(k 1), the edge label e v!v 0 (embedded by a relation embedding function R), and a parameter matrix W mp . Mes- sages from all neighbors are aggregated by max, the element-wise max operation. <ref type="bibr">9</ref> Example mes- sage passing paths are shown in <ref type="figure" target="#fig_1">Figure 3</ref>.</p><p>The final node embedding is the concatenation of embeddings at each depth:</p><formula xml:id="formula_4">V t (v) = ⇥ V 0 t (v), . . . , V K t (v) ⇤ ,<label>(3)</label></formula><p>where K is a hyperparameter (we experiment with K 2 {0, 1, 2}) and</p><formula xml:id="formula_5">V 0 t (v) = [F t (v), M t (v)].</formula><p>8 Relying on utterance t 1 is useful when utterance t answers a question, e.g., "do you have any google friends?" "No." <ref type="bibr">9</ref> Using sum or mean slightly hurts performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Utterance Embedding and Generation</head><p>We embed and generate utterances using Long Short Term Memory (LSTM) networks that take the graph embeddings into account.</p><p>Embedding. On turn t, upon receiving an utterance consisting of n t tokens, x t = (x t,1 , . . . , x t,nt ), the LSTM maps it to a vector as follows:</p><formula xml:id="formula_6">h t,j = LSTM enc (h t,j1 , A t (x t,j )),<label>(4)</label></formula><p>where h t,0 = h t1,n t1 , and A t is an entity ab- straction function, explained below. The final hid- den state h t,nt is used as the utterance embed- ding u t , which updates the mention vectors as de- scribed in Section 3.2.</p><p>In our dialogue task, the identity of an entity is unimportant. For example, replacing google with alphabet in <ref type="figure">Figure 1</ref> should make little dif- ference to the conversation. The role of an entity is determined instead by its relation to other en- tities and relevant utterances. Therefore, we de- fine the abstraction A t (y) for a word y as follows: if y is linked to an entity v, then we represent an entity by its type (school, company etc.) embed- ding concatenated with its current node embed- ding:</p><formula xml:id="formula_7">A t (y) = [E type(y) , V t (v)]. Note that V t (v)</formula><p>is determined only by its structural features and its context. If y is a non-entity, then A t (y) is the word embedding of y concatenated with a zero vector of the same dimensionality as V t (v). This way, the representation of an entity only depends on its structural properties given by the KB and the dia- logue context, which enables the model to gener- alize to unseen entities at test time.</p><p>Generation. Now, assuming we have embedded utterance x t1 into h t1,n t1 as described above, we use another LSTM to generate utterance x t . Formally, we carry over the last utterance embed- ding h t,0 = h t1,n t1 and define:</p><formula xml:id="formula_8">h t,j = LSTM dec (h t,j1 , [A t (x t,j ), c t,j ]), (5)</formula><p>where c t,j is a weighted sum of node embeddings in the current turn: c t,j = P v2Gt ↵ t,j,v V t (v), where ↵ t,j,v are the attention weights over the nodes. Intuitively, high weight should be given to relevant entity nodes as shown in <ref type="figure" target="#fig_1">Figure 3</ref>,. We compute the weights through standard attention mechanism ( <ref type="bibr" target="#b2">Bahdanau et al., 2015)</ref>:</p><formula xml:id="formula_9">↵ t,j = softmax(s t,j ), s t,j,v = w attn · tanh W attn [h t,j1 , V t (v)] ,</formula><p>where vector w attn and W attn are parameters. Finally, we define a distribution over both words in the vocabulary and nodes in G t using the copy- ing mechanism of Jia and Liang (2016):</p><formula xml:id="formula_10">p(x t,j+1 = y | G t , x t,j ) / exp W vocab h t,j + b , p(x t,j+1 = r(v) | G t , x t,j ) / exp (s t,j,v ) ,</formula><p>where y is a word in the vocabulary, W vocab and b are parameters, and r(v) is the realization of the entity represented by node v, e.g., google is real- ized to "Google" during copying. <ref type="bibr">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare our model with a rule-based sys- tem and a baseline neural model. Both automatic and human evaluations are conducted to test the models in terms of fluency, correctness, coopera- tion, and human-likeness. The results show that DynoNet is able to converse with humans in a co- herent and strategic way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>We randomly split the data into train, dev, and test sets (8:1:1). We use a one-layer LSTM with 100 hidden units and 100-dimensional word vectors for both the encoder and the decoder (Section 3.3). Each successful dialogue is turned into two exam- ples, each from the perspective of one of the two agents. We maximize the log-likelihood of all ut- terances in the dialogues. The parameters are opti- mized by AdaGrad ( <ref type="bibr" target="#b5">Duchi et al., 2010</ref>) with an ini- tial learning rate of 0.5. We trained for at least 10 epochs; after that, training stops if there is no im- provement on the dev set for 5 epochs. By default, we perform K = 2 iterations of message passing to compute node embeddings (Section 3.2). For decoding, we sequentially sample from the output distribution with a softmax temperature of 0.5. 11 Hyperparameters are tuned on the dev set. We compare DynoNet with its static cou- sion (StanoNet) and a rule-based system (Rule). StanoNet uses G 0 throughout the dialogue, thus the dialogue history is completely contained in the LSTM states instead of being injected into the knowledge graph. Rule maintains weights for each entity and each item in the KB to decide what to talk about and which item to select. It has a pattern-matching semantic parser, a rule- based policy, and a templated generator. See Ap- pendix G for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>We test our systems in two interactive settings: bot-bot chat and bot-human chat. We perform both automatic evaluation and human evaluation.</p><p>Automatic Evaluation. First, we compute the cross-entropy (`) of a model on test data. As shown in <ref type="table" target="#tab_5">Table 4</ref>, DynoNet has the lowest test loss. Next, we have a model chat with itself on the scenarios from the test set. <ref type="bibr">12</ref> We evaluate the chats with respect to language variation, effective- ness, and strategy.</p><p>For language variation, we report the average utterance length L u and the unigram entropy H in <ref type="table" target="#tab_5">Table 4</ref>. Compared to Rule, the neural mod- els tend to generate shorter utterances ( <ref type="bibr" target="#b12">Li et al., 2016b;</ref><ref type="bibr" target="#b21">Serban et al., 2017b</ref>). However, they are more diverse; for example, questions are asked in multiple ways such as "Do you have ...", "Any friends like ...", "What about ...".</p><p>At the discourse level, we expect the distribu- tion of a bot's utterance types to match the distri- bution of human's. We show percentages of each utterance type in <ref type="table" target="#tab_5">Table 4</ref>. For Rule, the decision about which action to take is written in the rules, while StanoNet and DynoNet learned to behave in a more human-like way, frequently informing and asking questions.</p><p>To measure effectiveness, we compute the over- all success rate (C) and the success rate per turn (C T ) and per selection (C S ). As shown in <ref type="table" target="#tab_5">Table 4</ref>, humans are the best at this game, followed by Rule which is comparable to DynoNet.</p><p>Next, we investigate the strategies leading to these results. An agent needs to decide which entity/attribute to check first to quickly reduce the search space. We hypothesize that humans tend to first focus on a majority entity and an attribute with fewer unique values (Section 2.3). For example, in the scenario in <ref type="table" target="#tab_2">Table 6</ref>, time and location are likely to be mentioned first. We show the average frequency of first-mentioned en- tities (#Ent 1 ) and the average number of unique values for first-mentioned attributes (|Attr 1 |) in Ta-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System`#</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System`System`#</head><p>Lu H C " CT " CS " Sel Inf Ask Ans Greet #Ent1 |Attr1| #Ent #Attr   To examine the overall strategy, we show the average number of attributes (#Attr) and entities (#Ent) mentioned during the conversation in Ta- ble 4. Humans and DynoNet strategically focus on a few attributes and entities, whereas Rule needs almost twice entities to achieve similar success rates. This suggests that the effectiveness of Rule mainly comes from large amounts of unselective information, which is consistent with comments from their human partners.</p><p>Partner Evaluation. We generated 200 new scenarios and put up the bots on AMT using the same chat interface that was used for data col- lection. The bots follow simple turn-taking rules explained in Appendix H. Each AMT worker is randomly paired with Rule, StanoNet, DynoNet, or another human (but the worker doesn't know which), and we make sure that all four types of agents are tested in each scenario at least once. At the end of each dialogue, humans are asked to rate their partner in terms of fluency, correctness, co- operation, and human-likeness from 1 (very bad) to 5 (very good), along with optional comments.</p><p>We show the average ratings (with significance tests) in <ref type="table" target="#tab_7">Table 5</ref> and the histograms in Appendix J. In terms of fluency, the models have similar per- formance since the utterances are usually short. Judgment on correctness is a mere guess since the evaluator cannot see the partner's KB; we will an- alyze correctness more meaningfully in the third- party evaluation below.</p><p>Noticeably, DynoNet is more cooperative than the other models. As shown in the example dia- logues in <ref type="table" target="#tab_2">Table 6</ref>, DynoNet cooperates smoothly with the human partner, e.g., replying with rel- evant information about morning/indoor friends when the partner mentioned that all her friends prefer morning and most like indoor. StanoNet starts well but doesn't follow up on the morn- ing friend, presumably because the morning node is not updated dynamically when mentioned by the partner. Rule follows the partner poorly. In the comments, the biggest complaint about Rule was that it was not 'listening' or 'understanding'. Overall, DynoNet achieves better partner satisfac- tion, especially in cooperation.</p><p>Third-party Evaluation. We also created a third-party evaluation task, where an independent AMT worker is shown a conversation and the KB of one of the agents; she is asked to rate the same aspects of the agent as in the partner evaluation and provide justifications. Each agent in a dia- logue is rated by at least 5 people.</p><p>The average ratings and histograms are shown in <ref type="table" target="#tab_7">Table 5</ref> and Appendix J. For correctness, we see that Rule has the best performance since it always tells the truth, whereas humans can make mistakes due to carelessness and the neural models can gen- erate false information. For example, in <ref type="table" target="#tab_2">Table 6</ref>, DynoNet 'lied' when saying that it has a morning friend who likes outdoor.</p><p>Surprisingly, there is a discrepancy between the two evaluation modes in terms of cooperation and human-likeness. Manual analysis of the com- ments indicates that third-party evaluators focus less on the dialogue strategy and more on linguis- tic features, probably because they were not fully engaged in the dialogue. For example, justification   for cooperation often mentions frequent questions and timely answers, less attention is paid to what is asked about though. For human-likeness, partner evaluation is largely correlated with coherence (e.g., not repeat- ing or ignoring past information) and task suc- cess, whereas third-party evaluators often rely on informality (e.g., usage of colloquia like "hiya", capitalization, and abbreviation) or intuition. In- terestingly, third-party evaluators noted most phe- nomena listed in <ref type="table" target="#tab_1">Table 2</ref> as indicators of human- beings, e.g., correcting oneself, making chit-chat other than simply finishing the task. See example comments in Appendix K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Studies</head><p>Our model has two novel designs: entity abstrac- tion and message passing for node embeddings. <ref type="table">Table 7</ref> shows what happens if we ablate these. When the number of message passing iterations, K, is reduced from 2 to 0, the loss consistently increases. Removing entity abstraction-meaning adding entity embeddings to node embeddings and the LSTM input embeddings-also degrades per- formance. This shows that DynoNet benefits from contextually-defined, structural node embeddings rather than ones based on a classic lookup table.</p><p>ModeìModeì</p><formula xml:id="formula_11">DynoNet (K = 2) 2.16 DynoNet (K = 1) 2.20 DynoNet (K = 0)</formula><p>2.26 DynoNet (K = 2) w/o entity abstraction 2.21 <ref type="table">Table 7</ref>: Ablations of our model on the dev set show the importance of entity abstraction and message passing (K = 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Related Work</head><p>There has been a recent surge of interest in end-to-end task-oriented dialogue systems, though progress has been limited by the size of available datasets <ref type="bibr" target="#b22">(Serban et al., 2015a</ref>). Most work focuses on information-querying tasks, using Wizard-of- Oz data collection <ref type="bibr" target="#b30">(Williams et al., 2016;</ref><ref type="bibr" target="#b1">Asri et al., 2016)</ref> or simulators ( <ref type="bibr" target="#b14">Li et al., 2016d</ref>), In contrast, collaborative dialogues are easy to collect as natural human conversations, and are also challenging enough given the large number of scenarios and diverse conversation phenomena. There are some in- teresting strategic dialogue datasets-settlers of Catan ( <ref type="bibr" target="#b0">Afantenos et al., 2012</ref>) (2K turns) and the cards corpus (Potts, 2012) (1.3K dialogues), as well as work on dialogue strategies ( <ref type="bibr" target="#b9">Keizer et al., 2017;</ref><ref type="bibr" target="#b27">Vogel et al., 2013</ref>), though no full dialogue system has been built for these datasets.</p><p>Most task-oriented dialogue systems follow the POMDP-based approach <ref type="bibr" target="#b31">(Williams and Young, 2007;</ref><ref type="bibr" target="#b32">Young et al., 2013)</ref>. Despite their suc- cess ( <ref type="bibr" target="#b28">Wen et al., 2017;</ref><ref type="bibr" target="#b4">Dhingra et al., 2017;</ref><ref type="bibr" target="#b26">Su et al., 2016)</ref>, the requirement for handcrafted slots limits their scalability to new domains and bur- dens data collection with extra state labeling. To go past this limit,  pro- posed a Memory-Networks-based approach with- out domain-specific features. However, the mem- ory is unstructured and interfacing with KBs relies on API calls, whereas our model embeds both the dialogue history and the KB structurally. <ref type="bibr" target="#b29">Williams et al. (2017)</ref> use an LSTM to automatically infer the dialogue state, but as they focus on dialogue control rather than the full problem, the response is modeled as a templated action, which restricts the generation of richer utterances. Our network ar-    chitecture is most similar to EntNet <ref type="bibr" target="#b6">(Henaff et al., 2017)</ref>, where memories are also updated by input sentences recurrently. The main difference is that our model allows information to be propagated be- tween structured entities, which is shown to be crucial in our setting (Section 4.3).</p><p>Our work is also related to language generation conditioned on knowledge bases ( <ref type="bibr" target="#b17">Mei et al., 2016;</ref><ref type="bibr" target="#b10">Kiddon et al., 2016)</ref>. One challenge here is to avoid generating false or contradicting statements, which is currently a weakness of neural models. Our model is mostly accurate when generating facts and answering existence questions about a single entity, but will need a more advanced at- tention mechanism for generating utterances in- volving multiple entities, e.g., attending to items or attributes first, then selecting entities; generat- ing high-level concepts before composing them to natural tokens ( <ref type="bibr" target="#b20">Serban et al., 2017a</ref>).</p><p>In conclusion, we believe the symmetric col- laborative dialogue setting and our dataset pro- vide unique opportunities at the interface of tra- ditional task-oriented dialogue and open-domain chat. We also offered DynoNet as a promising means for open-ended dialogue state representa- tion. Our dataset facilitates the study of prag- matics and human strategies in dialogue-a good stepping stone towards learning more complex di- alogues such as negotiation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Screenshot of the chat interface.</figDesc><graphic url="image-1.png" coords="2,307.28,474.93,226.76,141.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Overview of our approach. First, the KB and dialogue history (entities in bold) is mapped to a graph. Here, an item node is labeled by the item ID and an attribute node is labeled by the attribute's first letter. Next, each node is embedded using relevant utterance embeddings through message passing. Finally, an LSTM generates the next utterance based on attention over the node embeddings.</figDesc><graphic url="image-2.png" coords="4,344.53,153.81,148.07,148.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Human</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Friends</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>|| i have one outdoor A: I have 4 TRT Holdings || I have 2 outdoor one Johnny, other Frank B: i only have one TRT Holdings -Kathleen A: SELECT 7 B: SELECT 2 A: hi B: Hello || all my friends prefer morning A: 1 of my morning likes the outdoors B: and all like indoor except for one A: do they work for trt holdings? B: Kathleen? A: SELECT 7 B: SELECT 2 A: StanoNet B: Human A: Human B: Rule A: Hello B: hi A: Hello || I have one morning person. B: all of my friends like mornings A: My friend prefers afternoon works at trt holdings. B: what is their name? A: Likes indoors. B: what is your fiend who likes morning name? A: They work for trt holdings. B: SELECT 2 A: SELECT 7 B: hiya A: hEY B: I have 1 indoors and kathleen. A: Most of mine are indoors. B: SELECT 1 A: I have one morning and rest afternoon. B: Do you have any friend working at l hawaiian? A: I don't know Justin B: I have 1 alexander. ...</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Communication phenomena in the dataset. Evident parts is in bold and text spans corresponding 
to an entity are underlined. For coreference, the antecedent is in parentheses. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 6 and Appendix I.</head><label>6</label><figDesc></figDesc><table># dialogues 
11157 
# completed dialogues 
9041 
Vocabulary size 
5325 
Average # of utterances 
11.41 
Average time taken per task (sec.) 
91.18 
Average utterance length (tokens) 
5.08 
Number of linguistic templates 4 
41561 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Statistics of the MutualFriends dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Automatic evaluation on human-human and bot-bot chats on test scenarios.</head><label>4</label><figDesc></figDesc><table>We use " / # to 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on human-bot/human chats. Best results (except Human) in each column are in bold. 
We report the average ratings of each system. For third-party evaluation, we first take mean of each 
question then average the ratings. DynoNet has the best partner satisfaction in terms of fluency (Flnt), 
correctness (Crct), cooperation (Coop), human likeness (Human). The superscript of a result indicates that 
its advantage over other systems (r: Rule, s: StanoNet, d: DynoNet) is statistically significant with 
p &lt; 0.05 given by paired t-tests. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Examples of human-bot chats. The mutual friend is highlighted in blue in each KB. Bots' 
utterances are in bold and selected items are represented by item IDs. Only the first half of the human-
Rule chat is shown due to limited space. Multiple utterances of one agent rae separated by ||. 

</table></figure>

			<note place="foot" n="1"> The dataset is available publicly at https:// stanfordnlp.github.io/cocoa/.</note>

			<note place="foot" n="2"> If the workers exceed the time limit, the dialogue is marked as unsuccessful (but still logged).</note>

			<note place="foot" n="3"> Tasks are put up in batches; the total time excludes intervals between batches. 4 Entity names are replaced by their entity types.</note>

			<note place="foot" n="5"> Our goal is to model human behavior thus we do not discuss the optimal strategy here.</note>

			<note place="foot" n="7"> We use a rule-based lexicon to link text spans to entities. See details in Appendix D.</note>

			<note place="foot" n="10"> We realize an entity by sampling from the empirical distribution of its surface forms found in the training data. 11 Since selection is a common &apos;utterance&apos; in our dataset and neural generation models are susceptible to overgenerating common sentences, we halve its probability during sampling.</note>

			<note place="foot" n="12"> We limit the number of turns in bot-bot chat to be the maximum number of turns humans took in the test set (46 turns).</note>

			<note place="foot" n="13"> Both numbers are normalized to [0, 1] with respect to all entities/attributes in the corresponding KB.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Developing a corpus of strategic conversation in the settlers of catan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cadilhac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dégremont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lascarides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SeineDial 2012The 16th Workshop on the Semantics and Pragmatics of Dialogue</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Frames: A corpus for adding memory to goaloriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Maluuba Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end reinforcement learning of dialogue agents for information access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dialogue act tagging for instant messaging chat sessions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ivanovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cuayahuitl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Efstathiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lascarides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Association for Computational Linguistics (EACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Globally coherent text generation with neural checklist models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">A user simulator for taskcompletion dialogues. arXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Training End-to-End dialogue systems with the ubuntu dialogue corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What to talk about and how? selective generation using LSTMs with coarse-to-fine alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Coherent dialogue with attention-based language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Goal-driven answers in the Cards dialogue corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th West Coast Conference on Formal Linguistics</title>
		<meeting>the 30th West Coast Conference on Formal Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiresolution recurrent neural networks: An application to dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A survey of available corpora for building data-driven dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05742</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.04808</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02689</idno>
		<title level="m">Continuously learning neural dialogue management</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Emergence of gricean maxims from multi-agent decision theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bodoia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1072" to="1081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Association for Computational Linguistics (EACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hybrid code networks: Practical and efficient end-toend dialog control with supervised and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The dialog state tracking challenge series: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Partially observable Markov decision processes for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">POMDP-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
