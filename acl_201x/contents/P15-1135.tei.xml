<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Probing the Linguistic Strengths and Limitations of Unsupervised Grammar Induction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave Urbana</addrLine>
									<postCode>61801</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">The University of Illinois at Urbana-Champaign</orgName>
								<address>
									<addrLine>201 N Goodwin Ave Urbana</addrLine>
									<postCode>61801</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Probing the Linguistic Strengths and Limitations of Unsupervised Grammar Induction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1395" to="1404"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Work in grammar induction should help shed light on the amount of syntactic structure that is discoverable from raw word or tag sequences. But since most current grammar induction algorithms produce unlabeled dependencies, it is difficult to analyze what types of constructions these algorithms can or cannot capture, and, therefore, to identify where additional supervision may be necessary. This paper provides an in-depth analysis of the errors made by unsupervised CCG parsers by evaluating them against the labeled dependencies in CCGbank, hinting at new research directions necessary for progress in grammar induction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Grammar induction aims to develop algorithms that can automatically discover the latent syntactic structure of language from raw or part-of-speech tagged text. While such algorithms would have the greatest utility for low-resource languages for which no treebank is available to train supervised parsers, most work in this area has focused on languages where existing treebanks can be used to measure and compare the performance of the resultant parsers. Despite significant progress in the last decade ( <ref type="bibr" target="#b10">Klein and Manning, 2004;</ref><ref type="bibr" target="#b8">Headden III et al., 2009;</ref><ref type="bibr" target="#b2">Blunsom and Cohn, 2010;</ref><ref type="bibr" target="#b16">Spitkovsky et al., 2013;</ref><ref type="bibr" target="#b13">Mareček and Straka, 2013)</ref>, there has been little analysis performed on the types of errors these induction systems make, and our understanding of what kinds of construc- tions these parsers can or cannot recover is still rather limited. One likely reason for this lack of analysis is the fact that most of the work in this do- main has focused on parsers that return unlabeled dependencies, which cannot easily be assigned a linguistic interpretation. This paper shows that approaches that are based on categorial grammar <ref type="bibr" target="#b17">(Steedman, 2000)</ref> are amenable to more stringent evaluation metrics, which enable detailed analyses of the construc- tions they capture, while the commonly used unlabeled directed attachment scores hide linguis- tically important errors. Any categorial grammar based system, whether deriving its grammar from seed knowledge distinguishing nouns and verbs <ref type="bibr" target="#b1">(Bisk and Hockenmaier, 2013)</ref>, from a lexicon constructed from a simple questionnaire for linguists <ref type="bibr" target="#b3">(Boonkwan and Steedman, 2011</ref>), or from sections of a treebank ( <ref type="bibr" target="#b7">Garrette et al., 2015)</ref>, will attach linguistically expressive categories to individual words, and can therefore produce labeled dependencies. We provide a simple proof of concept for how these labeled dependencies can be used to isolate problem areas in CCG induction algorithms. We illustrate how they make the linguistic assumptions and mistakes of the model transparent, and are easily comparable to a treebank where available. They also allow us to identify linguistic phenomena that require addi- tional supervision or training signal to master. Our analysis will be based on extensions of our earlier system <ref type="bibr" target="#b1">(Bisk and Hockenmaier, 2013)</ref>, since it requires less supervision than the CCG-based approaches of <ref type="bibr" target="#b3">Boonkwan and Steedman (2011)</ref> or <ref type="bibr" target="#b7">Garrette et al. (2015)</ref>. Our aim in presenting this analysis is to initiate a broader conversation and classification of the impact of various types of supervision provided to these approaches. We will see that most of the constructions that our system cannot capture, even when they are included in the model's search space, involve precisely the kinds of non-local dependencies that elude even supervised dependency parsers (since they require dependency graphs, instead of trees), and that have motivated the use of categorial grammar- based approaches for supervised parsing.</p><p>First, we provide a brief introduction to CCG. Next, we define a labeled evaluation metric that al- lows us to compare the labeled dependencies pro- duced by <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref>'s unsu- pervised parser with those in CCGbank <ref type="bibr" target="#b9">(Hockenmaier and Steedman, 2007)</ref>. Third, we ex- tend their induction algorithm to allow it to induce more complex categories, and refine their proba- bility model to handle punctuation and lexicaliza- tion, which we show to be necessary when han- dling the larger grammars induced by our vari- ant of their algorithm. While we also perform a traditional dependency evaluation for comparison to the non-CCG based literature, we focus on our CCG-based labeled evaluation metrics to perform a comparative analysis of <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref>'s parser and our extensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Combinatory Categorial Grammar</head><p>CCG categories CCG <ref type="bibr" target="#b17">(Steedman, 2000</ref>) is a lexicalized grammar formalism which associates each word with a set of lexical categories that fully specify its syntactic behavior. Lexical categories indicate the expected number, type and relative lo- cation of arguments a word should take, or what constituents it may modify. Even without explicit evaluation against a treebank, the CCG lexicon that an unsupervised parser produces provides an easily interpretable snapshot of the assumptions the model has made about a language <ref type="bibr" target="#b1">(Bisk and Hockenmaier, 2013)</ref>. The set of CCG categories is defined recursively over a small set of atomic cat- egories (e.g. S, N, NP, PP). Complex categories take the form X\Y or X/Y and represent functions which create a result of category X when com- bined with an argument Y. The slash indicates whether the argument precedes (\) or follows (/) the functor (descriptions of CCG commonly use the vertical slash | to range over both / and \). Modifiers are categories of the form X|X, and may take arguments of their own.</p><p>CCG rules CCG rules are defined schematically as function application (&gt;, &lt;), unary (&gt;B 1 , &lt;B 1 ) and generalized composition (&gt;B n , &lt;B n ), type- raising (&gt;T, &lt;T) and conjunction: CCG derivations In the following derivation, forward application is used in line 1) as both the verb and the preposition take their NP arguments. In line 2), the prepositional phrase modifies the verb via backwards composition. Finally, in line 3), the derivation completes by producing a sen- tence (S) via backwards application:</p><formula xml:id="formula_0">I saw her from afar N (S\N1)/N2 N (S\S1)/N2 N &gt; &gt; 1) S\N1 S\S1 &lt;B 2) S\N1 &lt; 3) S</formula><p>CCG dependencies CCG has two standard evaluation metrics. Supertagging accuracy sim- ply computes how often a model chooses the cor- rect lexical category for a given word. The cor- rect category is a prerequisite for recovering the correct labeled dependency. By tracing through which word fills which argument of which cate- gory, a set of dependency arcs, labeled by lexical category and slot, can be extracted:</p><p>lexical head of a lexical category c i is the corre- sponding word w i . In general, the lexical head of a derived category is determined by the (primary) functor, so that the lexical head of a category X or X|Z 1 |...|Z n that resulted from combining X|Y and Y or Y|Z 1 |...|Z n is identical to the lexical head of X. However, when a modifier X|X with lexical head m is combined with an X|... whose lexical head is w, the lexical head of the resultant X|... is w, not m. <ref type="bibr">2</ref> Otherwise, from would become the lexical head of the S\N saw her from afar, and the sentence You know I saw her from afar would have a dependency between know and from, rather than between know and saw.</p><p>In general, word w j is a dependent of word w i if the k-th argument of the lexical category c i of word w i is instantiated with the lexical category of word w j . In the above derivation:</p><formula xml:id="formula_1">i j ci k wi wj 1 0 (S\N1)/N2 1 saw I 1 2 (S\N1)/N2 2 saw her 1 3 (S\S1)/N2 1 from saw 4 3 (S\S1)/N2 2 from afar I saw her from afar (S\S)/N 2 (S\S)/N 1 (S\N)/N 2 (S\N)/N 1</formula><p>The use of categories as dependency labels makes CCG labels more fine-grained than a stan- dard dependency grammar. For example, the sub- ject role of intransitive, transitive and ditransitive verbs are all SUB in dependency treebanks but take at least three different labels in CCGbank. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROOT</head><p>An additional complexity in CCGbank are cer- tain types of lexical categories (e.g. for relative pronouns or control verbs) which mediate non- local dependencies via a co-indexation mecha- nism. Identifying such non-local dependencies, e.g. to distinguish between subject and object con- trol (I promise her to come vs. I persuade her to come), is most likely beyond the scope of any purely syntactic grammar induction system but will begin to emerge in a semi-supervised system. <ref type="bibr">2</ref> That is, the argument X and result X of a modifier X|X are not two distinct instances of the same category, but unify. Bisk and H rithm that au from part-of- cess. This p seed knowle gories (S, N part-of-speec the category gory S). Bas restrictions, modify the w produces lex ity. Immedia S or N may or N|N. The introduce mo ifiers X|X. I gory S can ta ond round, m that are adja</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spurious am</head><p>In this example, I fills the first argument of saw. This is represented by an edge from saw to I, la- beled as a transitive verb ((S\N)/N). This proce- dure is followed for every argument of every pred- icate, leading to a labeled directed graph.</p><p>Evaluation metrics for supervised CCG parsers ( <ref type="bibr" target="#b5">Clark et al., 2002</ref>) measure labeled f-score (LF1) precision of these dependencies (requiring the functor, argument, lexical category of the func- tor and slot of the argument to all match). A second, looser, evaluation is often also performed which measures unlabeled, undirected depen- dency scores (UF1).</p><p>Non-local dependencies and complex argu- ments One advantage of CCG is its ability to recover the non-local dependencies involved in control, raising, or wh-extraction. Since these constructions introduce additional dependencies, CCG parsers return dependency graphs (DAGs), not trees. To obtain these additional dependen- cies, relative pronouns and control verbs require lexical categories that take complex arguments of the form S\NP or S/NP, and a mechanism for co- indexation of the NP inside this argument with an- other NP argument (e.g. (NP\NP i )/(S|NP i ) for relative pronouns). These co-indexed subjects can be seen in <ref type="figure">Figure 1</ref>.</p><formula xml:id="formula_2">I N promise (S\N)/(S\N) to (S\N)/(S\N) pay (S\N)/N you N John N , , who (N\N)/(S\N) ran (S\N)/N home N , , ate (S\N)/N dinner N</formula><p>(I, promise) (I, pay) (John, ran) (John, ate) <ref type="table" target="#tab_16">Table 6</ref>: Unlabeled predicate argument structures for two sentences, both of whom result in DAGs, not trees, as the subject is shared by multiple verbs.</p><formula xml:id="formula_3">Additional Category p(cat | tag) ((N\N)/(S\N))/N .93 WP$ N/(S/N) .14 WP N/(S\N) .08 WP ((N\N)/S)\((N\N)/N) .07 WDT ((S\S)\(S\S))\N .04 RBR S/(S\N)</formula><p>.04 WP S/(S/N)</p><p>.02 WP  <ref type="table" target="#tab_6">Table 9</ref>: Overall performance of the final systems discussed in this paper (Section 23) dicate missing information which only becomes available later in the discourse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Final Overall Model Performance</head><p>Finally, we evaluate these models again on the standard Section 23 against our simplified labelset and on undirected unlabeled arcs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CoNLL vs CCGbank dependencies</head><p>Finally, we examine whether the performance on standard unlabeled dependencies correlates with performance on CCGbank dependencies (Ta- ble 10) 2 . This also allows us to compare our systems directly to an unsupervised dependency parser ( <ref type="bibr" target="#b14">Naseem et al., 2010)</ref>, who report directed attachment (unlabeled dependency) scores of a dependency-based HDP model that incorporates either "universal" knowledge (e.g. that adjectives may modify nouns) or "English-specific" knowl- edge (e.g. that adjectives tend to precede nouns) in the form of soft constraints. Their universal knowledge is akin to, but more explicit and de- 2 BH13 use hyperparameter schemes and report <ref type="bibr">64</ref>  tailed than the information given to the induction algorithm (see <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> for a discussion). They evaluate on their training data, i.e. sentences of up to length 20 (without punctu- ation marks) of Sections 02-21 of the Penn Tree- bank <ref type="bibr">3</ref> .</p><p>We see that performance increases on CCG- bank translate to similar gains on the CoNLL de- pendencies on long sentences. We should note that we expect this discrepancy to grow as sys- tems capture more fine-grained distinction. In this vein, we computed directed attachment recall be- tween CCGbank dependencies and Yamada and Matusumoto's head finding rules and found only a 72.5% overlap. Many of the discrepancies ap- pear to be related to verb chains and analysis of the many DAG structures previously discussed. A full analsyis of the distinctions is beyond the scope of this paper but there is an interesting emperical question for future work as to whether annotation standards make learning even more burdensome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>In this paper, we have touched upon many linguis- tic phenomena that are common in language and we feel are currently out of scope for grammar in- duction systems. We focused our analysis on En- glish for simplicity but many of the same types of problems exist in other languages and can be easily identified as stemming from the same lack <ref type="bibr">3</ref> With Yamada and Matsumoto's (2003) head rules</p><formula xml:id="formula_4">I N promise (S\N)/(S\N) to (S\N)/(S\N) pay (S\N)/N you N John N , , who (N\N)/(S\N) ran (S\N)/N home N , , ate (S\N)/N dinner N</formula><p>(I, promise) (I, pay) (John, ran) (John, ate) <ref type="table" target="#tab_16">Table 6</ref>: Unlabeled predicate argument structures for two sentences, both of whom result in DAGs, not trees, as the subject is shared by multiple verbs.</p><formula xml:id="formula_5">Additional Category p(cat | tag) ((N\N)/(S\N))/N .93 WP$ N/(S/N) .14 WP N/(S\N) .08 WP ((N\N)/S)\((N\N)/N) .07 WDT ((S\S)\(S\S))\N .04 RBR S/(S\N)</formula><p>.04 WP S/(S/N)</p><p>.02 WP  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Final Overall Model Performance</head><p>Finally, we evaluate these models again on the standard Section 23 against our simplified labelset and on undirected unlabeled arcs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CoNLL vs CCGbank dependencies</head><p>Finally, we examine whether the performance on standard unlabeled dependencies correlates with performance on CCGbank dependencies (Ta- ble 10) 2 . This also allows us to compare our systems directly to an unsupervised dependency parser ( <ref type="bibr" target="#b14">Naseem et al., 2010)</ref>, who report directed attachment (unlabeled dependency) scores of a dependency-based HDP model that incorporates either "universal" knowledge (e.g. that adjectives may modify nouns) or "English-specific" knowl- edge (e.g. that adjectives tend to precede nouns) in the form of soft constraints. Their universal knowledge is akin to, but more explicit and de- 2 BH13 use hyperparameter schemes and report <ref type="bibr">64</ref>  tailed than the information given to the induction algorithm (see <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> for a discussion). They evaluate on their training data, i.e. sentences of up to length 20 (without punctu- ation marks) of Sections 02-21 of the Penn Tree- bank <ref type="bibr">3</ref> .</p><p>We see that performance increases on CCG- bank translate to similar gains on the CoNLL de- pendencies on long sentences. We should note that we expect this discrepancy to grow as sys- tems capture more fine-grained distinction. In this vein, we computed directed attachment recall be- tween CCGbank dependencies and Yamada and Matusumoto's head finding rules and found only a 72.5% overlap. Many of the discrepancies ap- pear to be related to verb chains and analysis of the many DAG structures previously discussed. A full analsyis of the distinctions is beyond the scope of this paper but there is an interesting emperical question for future work as to whether annotation standards make learning even more burdensome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>In this paper, we have touched upon many linguis- tic phenomena that are common in language and we feel are currently out of scope for grammar in- duction systems. We focused our analysis on En- glish for simplicity but many of the same types of problems exist in other languages and can be easily identified as stemming from the same lack <ref type="bibr">3</ref> With Yamada and Matsumoto's (2003) head rules <ref type="figure">Figure 1</ref>: Unlabeled predicate-argument dependency graphs for two sentences with co-indexed subjects.</p><p>Errors exposed by labeled evaluation We now illustrate how the lexical categories and labeled dependencies produced by CCG parsers expose linguistic mistakes. First, we consider a wildly in- correct analysis of the first example sentence, in which the subject is treated as an adverb, and the PP as an NP object of the verb:</p><formula xml:id="formula_6">I saw her from afar S/S (S/N1)/N2 N N/N1 N &gt; &gt; S/N1 N &gt; S &gt; S</formula><p>None of the labeled directed CCG dependencies are correct. But under the more lenient unlabeled directed evaluation of <ref type="bibr" target="#b7">Garrette et al. (2015)</ref>, and the even more lenient unlabeled undirected metric of Clark et al. <ref type="formula">(2002)</ref>, two (or three) of the four dependencies would be deemed correct: When we translate the CCG analysis to an unla- beled dependency tree (and hence flip the direction of modifier dependencies and add a root edge), a similar picture emerges, and three out of five at- tachments are deemed correct: We now turn to a subtle distinction that corre- sponds to a systematic mistake made by all mod- els we evaluate. The categories of noun-modifying prepositions (at) and possessive markers (') differ only in the directionality of their slashes:</p><formula xml:id="formula_7">Incorrect parse Correct parse nsubj dobj prep S/S (S/N)/N (S/N)/N N/N (S\N)/N (S\S)/N (S\S)/N (S\N)/</formula><formula xml:id="formula_8">Incorrect parse Correct parse nsubj dobj prep S/S (S/N)/N (S/N)/N N/N (S\N)/N (S\S)/N (S\S)/N (S\N)/</formula><formula xml:id="formula_9">X/Y Y )&gt; X X/Y Y |Z )&gt;B 1 X|Z X/Y Y |Z1|...|Zn )&gt;B n X|Z1|...|Zn Y X \Y )&lt; X Y|Z X \Y )&lt;B 1 X|Z Y|Z1|...|Zn X\Y )&lt;B n X|Z1|...|Zn</formula><p>A full explanation of the calculus can be found in <ref type="bibr" target="#b17">(Steedman, 2000</ref>) including discussion of a type-raising and a ternary rule for conjunction. We assume no type-changing in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dependencies</head><p>By tracing through which word fills which argu- ment of a category a set of dependency arcs, la- beled by lexical category and slot, can be extracted and are used for evaluation: lexical head of a lexical category c i is the corre- sponding word w i . In general, the lexical head of a derived category is determined by the (primary) functor, so that the lexical head of a category X or X|Z 1 |...|Z n that resulted from combining X|Y and Y or Y|Z 1 |...|Z n is identical to the lexical head of X. However, when a modifier X|X with lexical head m is combined with an X|... whose lexical head is w, the lexical head of the resultant X|... is w, not m. <ref type="bibr">2</ref> Otherwise, from would become the lexical head of the S\N saw her from afar, and the sentence You know I saw her from afar would have a dependency between know and from, rather than between know and saw.</p><p>In general, word w j is a dependent of word w i if the k-th argument of the lexical category c i of word w i is instantiated with the lexical category of word w j . In the above derivation:</p><formula xml:id="formula_10">i j ci k wi wj 1 0 (S\N1)/N2 1 saw I 1 2 (S\N1)/N2 2 saw her 1 3 (S\S1)/N2 1 from saw 4 3 (S\S1)/N2 2 from afar I saw her from afar (S\S)/N 2 (S\S)/N 1 (S\N)/N 2 (S\N)/N 1</formula><p>The use of categories as dependency labels makes CCG labels more fine-grained than a stan- dard dependency grammar. For example, the sub- ject role of intransitive, transitive and ditransitive verbs are all SUB in dependency treebanks but take at least three different labels in CCGbank. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROOT</head><p>An additional complexity in CCGbank are cer- tain types of lexical categories (e.g. for relative pronouns or control verbs) which mediate non- local dependencies via a co-indexation mecha- nism. Identifying such non-local dependencies, e.g. to distinguish between subject and object con- trol (I promise her to come vs. I persuade her to come), is most likely beyond the scope of any purely syntactic grammar induction system but will begin to emerge in a semi-supervised system.</p><p>Spurious ambiguity and normal-form parsing Composition and type-raising introduce an expo- nential number of derivations that are semantically equivalent, i.e. yield the same set of dependen- cies. In supervised CCG parsers <ref type="bibr" target="#b5">(Hockenmaier and Steedman, 2002;</ref><ref type="bibr">Clark and Curran, 2007)</ref>, this spurious ambiguity is largely eliminated be- cause the derivations in CCGbank are in a normal form that uses composition and type-raising only when necessary, although it can be further allevi- ated via the use of a normal-form parsing algo- rithm <ref type="bibr">(Eisner, 1996;</ref><ref type="bibr">Hockenmaier and Bisk, 2010</ref>) that minimizes the use of composition (and type- raising). We will show below that this spurious ambiguity is particularly deleterious for unsuper- vised CCG parsers that do not impose any normal- form constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Unsupervised CCG parsing</head><p>We now review the unsupervised CCG parser of <ref type="bibr">Bisk and Hockenmaier (2012b;</ref>, which is trained over parse forests obtained from a CCG lexicon that was induced from POS-tagged text.</p><p>Unsupervised CCG induction The induction algorithm needs to identify the set of lexical categories and to learn the mapping between words and lexical categories, e.g.: Bisk and Hockenmaier (2012b) define an algo- rithm that automatically induces a CCG lexicon from part-of-speech tagged text in an iterative pro- cess. This process starts with a small amount of seed knowledge that defines which atomic cate- gories (S, N and conj) can be assigned to which part-of-speech tags (nominal POS tags may have the category N, while verbs may have the cate- gory S). Based on the assumption that, under mild restrictions, words can either subcategorize for or modify the words they are adjacent to, this process produces lexical categories of increasing complex- ity. Immediate neighbors of words with categories S or N may act as modifiers with categories S|S or N|N. The second round of induction can also introduce modifiers (X|X)|(X|X) of existing mod- ifiers X|X. In the first iteration, words with cate- gory S can take adjacent N arguments. In the sec- ond round, modifiers and words with category S|N that are adjacent to words with the category N or These dependencies are the complete predicate ar- gument structure of the sentence and supervised evaluation is performed by computing a parser's precision and recall on matching the head, depen- dant, category and slot of each arc. A second looser evaluation is often also performed which simply checks that the undirected and unlabeled arcs match. An example of this difference that's particularly relevant to the discussion in this paper is the headedness of prepositional phrases versus posessives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prepositional Phrase</head><p>The</p><formula xml:id="formula_11">N/N woman N at (N\N)/N the N/N company N laughed S\N (N\N)/N 2 (N\N)/N 1 S\N 1 Possessive The N/N woman N 's (N/N)\N IT N/N company N grew S\N (N/N)\N 1 (N/N)\N 2 S\N 1</formula><p>The undirected edges for the inital noun phrase are identical, but the heads differ. In CCG, we as- sume that categories of the form X|X where X is atomic are modifiers. In this way, the first sentence turns the prepositional phrase (at the company) into a modifier of the woman. In contrast, in the as getting the wrong head leads to the company laughing or other semantically nonsensical analy- ses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using Labels to Diagnose Errors</head><p>Finally, we quickly provide an incorrect analysis of the first example sentence as a simple exercise in using labels to diagnose mistakes:</p><formula xml:id="formula_12">I s a w h e r f r o m a f a r S/S (S/N1)/N2 N N/N1 N &gt; &gt; S/N1 N &gt; S &gt; S</formula><p>In this example, the verb analysis is trying to an- alyze the language as VOS instead of SVO. Once familiar with reading CCG categories the model's output and mistake can be easily diagnosed. A model producing this analysis is not learning the correct word order of the language, nor the correct role for prepositions by taking afar as a subject. This type of mistake is obvious to a speaker of the language even without a treebank for evaluation. In this way we believe label prediction eases the analysis burden when diagnosing a system's out- put.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Simplified Labeled Evaluation</head><p>In languages with treebanks, labeled evaluation can make this style of analysis even simpler. Fortunately, approaches using CCG can produce labeled output but unfortunately there are mis- matches between the basic set of categories and those used in treebanks. We will focus on the En- glish CCGbank but these details apply with only minor changes to German and Chinese as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simplification</head><p>Because the lexical categories guide parsing, the set used in supervised parsing is extremely large and augmented with features. These features are not strictly part of the CCG calculus but mark properties of the underlying words, for example indicating if a verb is declarative or infinitival or if a noun phrase contains a number. These features</p><formula xml:id="formula_13">X/Y Y )&gt; X X/Y Y |Z )&gt;B 1 X|Z X/Y Y |Z1|...|Zn )&gt;B n X|Z1|...|Zn Y X \Y )&lt; X Y|Z X \Y )&lt;B 1 X|Z Y|Z1|...|Zn X\Y )&lt;B n X|Z1|...|Zn</formula><p>A full explanation of the calculus can be found in <ref type="bibr" target="#b17">(Steedman, 2000</ref>) including discussion of a type-raising and a ternary rule for conjunction. We assume no type-changing in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dependencies</head><p>By tracing through which word fills which argu- ment of a category a set of dependency arcs, la- beled by lexical category and slot, can be extracted and are used for evaluation: lexical head of a lexical category c i is the corre- sponding word w i . In general, the lexical head of a derived category is determined by the (primary) functor, so that the lexical head of a category X or X|Z 1 |...|Z n that resulted from combining X|Y and Y or Y|Z 1 |...|Z n is identical to the lexical head of X. However, when a modifier X|X with lexical head m is combined with an X|... whose lexical head is w, the lexical head of the resultant X|... is w, not m. <ref type="bibr">2</ref> Otherwise, from would become the lexical head of the S\N saw her from afar, and the sentence You know I saw her from afar would have a dependency between know and from, rather than between know and saw.</p><p>In general, word w j is a dependent of word w i if the k-th argument of the lexical category c i of word w i is instantiated with the lexical category of word w j . In the above derivation:</p><formula xml:id="formula_14">i j ci k wi wj 1 0 (S\N1)/N2 1 saw I 1 2 (S\N1)/N2 2 saw her 1 3 (S\S1)/N2 1 from saw 4 3 (S\S1)/N2 2 from afar I saw her from afar (S\S)/N 2 (S\S)/N 1 (S\N)/N 2 (S\N)/N 1</formula><p>The use of categories as dependency labels makes CCG labels more fine-grained than a stan- dard dependency grammar. For example, the sub- ject role of intransitive, transitive and ditransitive verbs are all SUB in dependency treebanks but take at least three different labels in CCGbank.</p><note type="other">i j wj Label 2 1 I SUB 0 2 saw ROOT 2 3 her OBJ 2 4 from VMOD 4 5 afar PMOD I saw her from afar PMOD VMOD OBJ SUB</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROOT</head><p>An additional complexity in CCGbank are cer- tain types of lexical categories (e.g. for relative pronouns or control verbs) which mediate non- local dependencies via a co-indexation mecha- nism. Identifying such non-local dependencies, e.g. to distinguish between subject and object con- trol (I promise her to come vs. I persuade her to come), is most likely beyond the scope of any purely syntactic grammar induction system but will begin to emerge in a semi-supervised system. <ref type="bibr">2</ref> That is, the argument X and result X of a modifier X|X are not two distinct instances of the same category, but unify.</p><p>Spurious ambiguity and normal-form parsing Composition and type-raising introduce an expo- nential number of derivations that are semantically equivalent, i.e. yield the same set of dependen- cies. In supervised CCG parsers <ref type="bibr" target="#b5">(Hockenmaier and Steedman, 2002;</ref><ref type="bibr">Clark and Curran, 2007)</ref>, this spurious ambiguity is largely eliminated be- cause the derivations in CCGbank are in a normal form that uses composition and type-raising only when necessary, although it can be further allevi- ated via the use of a normal-form parsing algo- rithm <ref type="bibr">(Eisner, 1996;</ref><ref type="bibr">Hockenmaier and Bisk, 2010</ref>) that minimizes the use of composition (and type- raising). We will show below that this spurious ambiguity is particularly deleterious for unsuper- vised CCG parsers that do not impose any normal- form constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Unsupervised CCG parsing</head><p>We now review the unsupervised CCG parser of <ref type="bibr">Bisk and Hockenmaier (2012b;</ref>, which is trained over parse forests obtained from a CCG lexicon that was induced from POS-tagged text.</p><p>Unsupervised CCG induction The induction algorithm needs to identify the set of lexical categories and to learn the mapping between words and lexical categories, e.g.: Bisk and Hockenmaier (2012b) define an algo- rithm that automatically induces a CCG lexicon from part-of-speech tagged text in an iterative pro- cess. This process starts with a small amount of seed knowledge that defines which atomic cate- gories (S, N and conj) can be assigned to which part-of-speech tags (nominal POS tags may have the category N, while verbs may have the cate- gory S). Based on the assumption that, under mild restrictions, words can either subcategorize for or modify the words they are adjacent to, this process produces lexical categories of increasing complex- ity. Immediate neighbors of words with categories S or N may act as modifiers with categories S|S or N|N. The second round of induction can also introduce modifiers (X|X)|(X|X) of existing mod- ifiers X|X. In the first iteration, words with cate- gory S can take adjacent N arguments. In the sec- ond round, modifiers and words with category S|N that are adjacent to words with the category N or These dependencies are the complete predicate ar- gument structure of the sentence and supervised evaluation is performed by computing a parser's precision and recall on matching the head, depen- dant, category and slot of each arc. A second looser evaluation is often also performed which simply checks that the undirected and unlabeled arcs match. An example of this difference that's particularly relevant to the discussion in this paper is the headedness of prepositional phrases versus posessives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prepositional Phrase</head><p>The</p><formula xml:id="formula_15">N/N woman N at (N\N)/N the N/N company N laughed S\N (N\N)/N 2 (N\N)/N 1 S\N 1 Possessive The N/N woman N 's (N/N)\N IT N/N company N grew S\N (N/N)\N 1 (N/N)\N 2 S\N 1</formula><p>The undirected edges for the inital noun phrase are identical, but the heads differ. In CCG, we as- sume that categories of the form X|X where X is atomic are modifiers. In this way, the first sentence turns the prepositional phrase (at the company) into a modifier of the woman. In contrast, in the as getting the wrong head leads to the company laughing or other semantically nonsensical analy- ses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using Labels to Diagnose Errors</head><p>Finally, we quickly provide an incorrect analysis of the first example sentence as a simple exercise in using labels to diagnose mistakes:</p><formula xml:id="formula_16">I s a w h e r f r o m a f a r S/S (S/N1)/N2 N N/N1 N &gt; &gt; S/N1 N &gt; S &gt; S</formula><p>In this example, the verb analysis is trying to an- alyze the language as VOS instead of SVO. Once familiar with reading CCG categories the model's output and mistake can be easily diagnosed. A model producing this analysis is not learning the correct word order of the language, nor the correct role for prepositions by taking afar as a subject. This type of mistake is obvious to a speaker of the language even without a treebank for evaluation. In this way we believe label prediction eases the analysis burden when diagnosing a system's out- put.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Simplified Labeled Evaluation</head><p>In languages with treebanks, labeled evaluation can make this style of analysis even simpler. Fortunately, approaches using CCG can produce labeled output but unfortunately there are mis- matches between the basic set of categories and those used in treebanks. We will focus on the En- glish CCGbank but these details apply with only minor changes to German and Chinese as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Simplification</head><p>Because the lexical categories guide parsing, the set used in supervised parsing is extremely large and augmented with features. These features are not strictly part of the CCG calculus but mark properties of the underlying words, for example indicating if a verb is declarative or infinitival or if a noun phrase contains a number. These features</p><p>The unlabeled dependencies inside the noun phrases are identical, but the heads differ. The first sentence turns the prepositional phrase (at the company) into a modifier of woman. In contrast, in the possessive case, woman 's modifies com- pany. According to an unlabeled (directed) score, confusing these analyses would be 80% correct, whereas LF1 would only be 20%. But without a semantic bias for companies growing and women laughing, there is no signal for the learner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Labeled Evaluation for CCG Induction</head><p>We have just seen that labeled evaluation can ex- pose many linguistically important mistakes. In order to enable a fair and informative comparison of unsupervised CCG parsers against the lexical categories and labeled dependencies in CCGbank, we define a simplification of CCGbank's lexical categories that does not alter the number or direc- tion of dependencies, but makes the categories and dependency labels directly comparable to those produced by an unsupervised parser. We also do not alter the derivations themselves, although these may contain type-changing rules (which al- low e.g. participial verb phrases S[ng]\NP to be used as NP modifiers NP\NP) that are beyond the scope of our induction algorithm.</p><p>Although the CCG derivations and dependen- cies that CCG-based parsers return should in prin- ciple be amenable to a quantitative labeled evalu- ation when a gold-standard CCG corpus is avail- able, there may be minor systematic differences between the sets of categories assumed by the in- duced parser and those in the treebank. In par- ticular, the lexical categories in the English CCG- bank are augmented with morphosyntactic fea- tures that indicate e.g. whether sentences are declarative (S[dcl]), or verb phrases are infiniti- val (S[to]\NP). Prior work on supervised parsing with CCG found that many of these features can be recovered with proper modeling of latent state splitting <ref type="bibr" target="#b6">(Fowler and Penn, 2010)</ref>. Since we wish to evaluate a system that does not aim to induce such features, we remove them. We also remove the distinction between noun phrases (NP) and nouns (N), which is predicated on knowledge of Our simplification of CCGbank's lexical categories Congress has n't lifted the ceiling , allowing us to maintain the de- pendency on the subject. With these three simplifi- cations we eliminate much of the detailed knowl- edge required to construct the precise CCGbank- style categories, and dramatically reduce the set of categories without losing expressive power. One distinction that we do not conflate, even though it is currently beyond the scope of the induc- tion algorithm, is the distinction between PP argu- ments (requiring prepositions to have the category PP/NP) and adjuncts (requiring prepositions to be (NP\NP)/NP or ((S\NP)\(S\NP))/NP). This simplification is consistent with the most basic components of CCG and can therefore be easily used for the evaluation and analysis of any weakly or fully supervised CCG system, not just that of <ref type="bibr" target="#b0">Bisk and Hockenmaier (2012)</ref>. An example simplification is present in <ref type="figure">Figure 2</ref>, and the reduc- tion in the set of categories can be seen in <ref type="table">Table 1</ref>. Similar simplifications should also be possible for CCGbanks in other languages.</p><formula xml:id="formula_17">Original NP (S[dcl]\NP)/(S[pt]\NP) (S\NP)\(S\NP) (S[pt]\NP)/NP NP[nb]/N N Simplified N (S\N)/(S\N) S\S (S\N)/N N/N N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our approach</head><p>There are two parts to our approach: 1) induc- ing a CCG grammar from seed knowledge and 2) learning a probability model over parses. The in- duction algorithm <ref type="bibr" target="#b0">(Bisk and Hockenmaier, 2012)</ref> uses the seed knowledge that nouns can take the CCG category N, that verbs can take the category S and may take N arguments, and that any word may modify a constituent it is adjacent to, to iter- atively induce a CCG lexicon to parse the train- ing data. In <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref>, we introduced a model that is based on Hierarchical Dirichlet Processes ( <ref type="bibr" target="#b18">Teh et al., 2006</ref>). This HDP- CCG model gave state-of-the-art performance on a number languages, and qualitative analysis of the resultant lexicons indicated that the system was learning the word order and many of the correct attachments of the tested languages. But this sys- tem also had a number of shortcomings: the in- duction algorithm was restricted to a small frag- ment of CCG, the model emitted only POS tags rather than words, and punctuation was ignored. Here, we use our previous HDP-CCG system as a baseline, and introduce three novel extensions that attempt to address these concerns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>For our experiments we will follow the standard practice in supervised parsing of using WSJ Sec- tions 02-21 for training, Section 22 for develop- ment and error analysis, and a final evaluation of the best models on Section 23. Because the in- duced lexicons are overly general, the memory footprint grows rapidly as the complexity of the grammar increases. For this reason, we only train on sentences that contain up to 20 words (as well as an arbitrary number of punctuation marks). All analyses and evaluation are performed with sen- tences of all lengths unless otherwise indicated. Finally, Bisk and Hockenmaier (2013) followed <ref type="bibr" target="#b11">Liang et al. (2007)</ref> in setting the values of the hy- perparameters α to powers (eg. the square) of the number of observed outcomes in the distribution. But when the output consists of words rather than POS tags, the concentration parameter α = V 2 is too large to allow the model to learn. For this rea- son, experiments will be reported with all hyper- parameters set to a constant of 2500. <ref type="bibr">1</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base + Lexicalization + Punctuation + Punc &amp; Lex + Allow (X|X)|X</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Only Atomic Arguments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Extending the HDP-CCG system</head><p>We now examine how extending the HDP-CCG baseline model to capture lexicalization and punc- tuation, and how increasing the complexity of the induced grammars affect performance <ref type="table" target="#tab_9">(Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Modeling Lexicalization</head><p>In keeping with most work in grammar induction from part-of-speech tagged text, Bisk and Hocken- maier's (2013) HDP-CCG treats POS tags t rather than words w as the terminals it generates based on their lexical categories c. The advantage of this approach is that tag-based emissions p(t|c) are a lot less sparse than word-based emissions p(w|c).</p><p>It is therefore beneficial to first train a model that emits tags rather than words <ref type="bibr" target="#b4">(Carroll and Rooth, 1998)</ref>, and then to use this simpler model to ini- tialize a lexicalized model that generates words in- stead of tags. To perform the switch we simply es- timate counts for the parse forests using the unlex- icalized model during the E-Step and then apply those counts to the lexicalized model during the M-Step. Inside-Outside then continues as before. Many words, like prepositions, differ systemati- cally in their preferred syntactic role from that of their part-of-speech tags. This change benefits all settings of the model (Column 2 of <ref type="table" target="#tab_9">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Modeling Punctuation</head><p>Spitkovsky et al. (2011) performed a detailed anal- ysis of punctuation for dependency-based gram- mar induction, and proposed a number of con- straints that aimed to capture the different ways in which dependencies might cross constituent boundaries implied by punctuation marks. A constituency-based formalism like CCG al- lows us instead to define a very simple, but effec- tive Dirichlet Process (DP) based Markov gram- reported dependency evaluation comparison with the work of <ref type="bibr" target="#b14">Naseem et al. (2010)</ref>. We fixed this hyperparameter setting for experimental simplicity but a more rigorous grid search might find better parameters for the complex models. mar that emits punctuation marks at the maximal projections of constituents. We note that CCG derivations are binary branching, and that virtually every instance of a binary rule in a normal-form derivation combines a head X or X|Y with an ar- gument Y or modifier X|X. Without reducing the set of strings generated by the grammar, we can therefore assume that punctuation marks can only be attached to the argument Y or the adjunct X|X:</p><formula xml:id="formula_18">Y , , X/Y X Y X\X , , X X X\X</formula><p>To model this, for each maximal projection (i.e. whenever we generate a non-head child) with cate- gory C, we first decide whether punctuation marks should be emitted (M = {true, false}) to the left or right side (Dir) of C. Since there may be mul- tiple adjacent punctuation marks (... ."), we treat this as a Markov process in which the history vari- able captures whether previous punctuation marks have been generated or not. Finally, we generate an actual punctuation mark w m :</p><formula xml:id="formula_19">p(M | Dir , Hist, C) ∼ DP (α, p(M | dir )) p(M | Dir ) ∼ DP (α, p(M )) p(wm | Dir , Hist, C) ∼ DP (α, p(wm | dir , hist)) p(wm | Dir , Hist) ∼ DP (α, p(wm))</formula><p>We treat # and $ symbols as ordinary lexi- cal items for which CCG categories will be in- duced by the regular induction algorithm, but treat all other punctuation marks, including quotes and brackets. Commas and semicolons (,, ;) can act both as punctuation marks generated by this Markov grammar, and as conjunctions with lexical category conj. This model leads to further perfor- mance gains <ref type="table" target="#tab_9">(Columns 3 and 4 of Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Increasing Grammatical Complexity</head><p>The existing grammar induction scheme is very simplistic. It assumes that adjacent words either modify one another or can be taken as arguments. Left unconstrained this space of grammatical cat-  59.2 34.5 60.6 B C 1 59.9</p><p>34.9 63.6 B P&amp;L 3 62.3 37.1 64.9 <ref type="table">Table 3</ref>: Test set performance of the final systems discussed in this paper <ref type="table" target="#tab_9">(Section 23)</ref> egories introduced grows very rapidly, introduc- ing a tremendous number of incorrect categories (analyzed later in <ref type="table" target="#tab_6">Table 9</ref>). For this reason Bisk and Hockenmaier (2013) applied the HDP-CCG model to a context-free fragment of CCG, limit- ing the arity of lexical categories (number of ar- guments they can take) to two and the arity of composition (how many arguments can be passed through composition) to one. We know the space of grammatical constructions is larger than this, so we will allow the model to induce categories with three arguments and use generalized composition <ref type="bibr">(B 3</ref> ). <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> allow lexical categories to only take atomic arguments, but, as explained above, non-local dependencies require complex arguments of the form S|N. We therefore allow lexical categories to take up to one complex argument of the form S|N. Atomic lexical cate- gories are not allowed to take complex arguments, eliminating S|(S|N) and N|(S|N). Increasing the search space <ref type="table" target="#tab_9">(Rows 3 and 4 of Table 2</ref>) shows cor- responding decreases in performance. Finally, Bisk and Hockenmaier (2013) elim- inated the possessive-preposition ambiguity ex- plained above by disallowing categories of the form (X\X)/X and (X/X)\X to be used simulta- neously. Removing this restriction does not harm performance (Column 5 of <ref type="table" target="#tab_9">Table 2</ref>). <ref type="table" target="#tab_9">Table 2</ref> shows the performance of 20 different model settings on Section 22 under the simpli- fied labeled CCG-based dependency evaluation proposed above, starting with Bisk and Hocken- maier's (2013) original model (henceforth: B 1 , top left). We see that modeling punctuation and lexicalization both increase performance. We also show that allowing categories of the form (X\X)/X and (X/X)\X on top of the lexicalized models with punctuation does not lead to a notice- able decrease in performance. We also see that an increase in grammatical and lexical complexity is only beneficial for the grammars that allow only atomic arguments, and only if both lexicalization   (the best overall model), whose supertag accuracy, labeled (LF1) and unlabeled undirected CCG de- pendency recovery on Section 23 are shown in Ta- ble 3. We see that B C 1 and B P&amp;L 3 both outperform B 1 on all metrics, although the unlabeled met- ric (UF1) perhaps misleadingly suggests that B C 1 leads to a greater improvement than the supertag- ging and LF1 metrics indicate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Summary and test set performance</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">CCGbank vs. dependency trees</head><p>Finally, to compare our models directly to a com- parable unsupervised dependency parser <ref type="bibr" target="#b14">(Naseem et al., 2010)</ref>, we evaluate them against the un- labeled dependencies produced by <ref type="bibr" target="#b19">Yamada and Matsumoto's (2003)</ref> head rules for Sections 02- 21 of the Penn Treebank <ref type="table" target="#tab_13">(Table 4)</ref>  <ref type="bibr">2</ref> . <ref type="bibr" target="#b14">Naseem et al. (2010)</ref> only report performance on sentences of up to length 20 (without punctuation marks). Their approach incorporates prior linguistic knowledge either in the form of "universal" constraints (e.g. that adjectives may modify nouns) or "English- specific" constraints (e.g. that adjectives tend to modify and precede nouns). These universal con- straints are akin to, but more explicit and detailed than the information given to the induction algo- rithm (see <ref type="bibr" target="#b1">Bisk and Hockenmaier (2013)</ref> for a dis- cussion). Comparing these numbers to labeled and unlabeled CCG dependencies on the same cor- pus (all sentences, hence, @∞), we see that per- formance increases on CCGbank do not translate to similar gains on these unlabeled dependencies. While we have done our best to convert the predi- cate argument structure of CCG into dependencies 37.8 N\N 20.8 41.1 N/N 16.3 57.2 (S\S)/S 13.8 (N\N)/N 64.3 (S\S)/N 20.8 60.5 (S\S)/N 13.8 53.1 (S\S)/N 23.8 (S\N)/N 25.6 S/N 27.0 26.0 (S/N)/N 23.5 29.4 S/N 22.3 (S\S)/N 51.0 (N\N)/N 23.1 48.0 (N\N)/N 18.2 62.6 N/N 10.1 (S\N)/S 60.7 S\N 12.1 55.7 S\N 12.4 57.9 S\N 11.0 (S\S)/S 38.0 (N\N)/N 35.2 50.8 S/S 14.4 61.5 N 7.5 on the most common recoverable (simplified) lexical categories in Section 22 along with the most commonly produced error.</p><formula xml:id="formula_20">Correct B1 B P&amp;L 3 B C 1 Category LR Used instead (%) LR Used instead (%) LR Used instead (%) N 82.6 N/N 7.5 74.5 N/N 8.3 77.4 N/N 9.8 N/N 78.5 (S\S)\(S\S) 9.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category Example usage</head><p>Used instead by</p><formula xml:id="formula_21">B C 1 (%) (N/N)\N The woman 's company ... (N\N)/N 89.9 N/N 3.7 N 2.9 (S/S)/N Before Monday, ... S/S 69.9 N/N 14.8 (N\N)/N 8.2 (N/N)/(N/N)</formula><p>The very tall man ...</p><formula xml:id="formula_22">N/N 38.0 (S\S)\(S\S) 33.9 (S\S)/N 10.1 (N\N)/(S\N)</formula><p>John, who ran home, ...  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Error analysis</head><p>Supertagging error analysis We first consider the lexical categories that are induced by the mod- els. <ref type="table" target="#tab_15">Table 5</ref> shows the accuracy with which they recover the most common gold lexical categories, together with the category that they most often produced instead. We see that the simplest model (B 1 ) performs best on N, and perhaps over gen- erates (N\N)/N (noun-modifying prepositions), while the overall best model (B P&amp;L 3 ) outperforms both other models only on intransitive verbs.</p><p>The most interesting component of our analysis is the long tail of constructions that must be cap- tured in order to produce semantically appropriate representations. We can inspect the confusion ma- trix of the lexical categories that the model fails to use to obtain insight into how its predictions dis- agree with the ground truth, and why these con- structions may require special attention. <ref type="table" target="#tab_16">Table 6</ref> shows the most common CCGbank categories that were in the search space of some of the more com- plex models (e.g. B C</p><p>3 ), but were never used by any of the parsers in a Viterbi parse. These include possessives, relative pronouns, modals/auxiliaries, control verbs and ditransitives. We show the cat- egories that the B C 1 model uses instead. The gold categories shown correspond to the bold words in <ref type="table" target="#tab_16">Table 6</ref>. While the reason many of these cases are difficult is intuitive (e.g. very modifying tall instead of man), a more difficult type of error than previously discussed is that of recovering non-local dependencies. The recovery of non- local dependencies is beyond the scope of both standard dependency-based approaches and Bisk and Hockenmaier (2013)'s original induction al- gorithm. But the parser does not learn to use lexi- cal categories with complex arguments correctly even when the algorithm is extended, to induce them. For example, B C 1 prefers to treat auxiliaries or equi verbs like promise as intransitives rather than as an auxiliary that shares its subject with pay. The surface string supports this decision, as it can be parsed without having to capture the non- local dependencies (top row) present in the correct (bottom row) analysis: 24.0 24.9 29.3 (S\N)/S 23.9 50.3 32. <ref type="bibr">5</ref> 25.2 59.1 35.0 (S\S)/S 6.1 22.7 14.1 9.5 34.6 19.5 <ref type="table">Table 7</ref>: LF1 scores of B 1 , B C 1 and B 3 P&amp;L on the most common dependency types in Section 22.</p><formula xml:id="formula_23">I promise to pay you N S\N (S\S)/S S/N N N (S\N)/(S\N) (S\N)/(S\N) (S\N)/N N 1st Argument 2nd Argument B1 B C 1 B P&amp;L 3 B1 B C 1 B P&amp;L 3 N/N 68</formula><p>We also see that this model uses seemingly non- English verb categories of the form (S/N)/N, both for ditransitives, and object control verbs, perhaps because the possibly spurious /N argument could be swallowed by other categories that take argu- ments of the form S/N, like the (incorrect) treat- ment of subject relative pronouns. One possible lesson we can extract from this is that practical approaches for building parsers for new languages might need to focus on injecting semantic infor- mation that is outside the scope of the learner.</p><p>Dependency error analysis <ref type="table">Table 7</ref> shows the labeled recall of the most common dependencies. We see that both new models typically outper- form the baseline, although they yield different improvements on different dependency types. B C 1 is better at recovering the subjects of intransitive verbs (S\N) and verbs that take sentential com- plements ((S\N)/S), while B 3 is better for simple adjuncts (N/N, S/S, S\S) and transitive verbs.</p><p>Wh-words and the long tail To dig slightly deeper into the set of missing constructions, we tried to identify the most common categories that are beyond the search space of the current induc- tion algorithm. We first computed the set of cat- egories used by each part of speech tag in CCG- bank, and thresholded the lexicon at 95% token coverage for each tag. Removing the categories that contain PP and those that can be induced by the algorithm in its most general setting, we are left with the categories shown in <ref type="table" target="#tab_2">Table 8</ref>. The tags that are missing categories are predominantly wh- words required for wh-questions, relative clauses or free relative clauses. Some of these categories violate the assumptions made by the induction al- gorithm: question words return a sentence (S) but are not themselves verbs. Free relative pronouns return a noun, but take arguments. However, this is</p><formula xml:id="formula_24">Additional Category p(cat | tag) ((N\N)/(S\N))/N .93 WP$ N/(S/N) .14 WP N/(S\N)</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="08">WP ((N\N)/S)\((N\N)/N) .07 WDT ((S\S)\(S\S))\N</head><p>.04 RBR S/(S\N)</p><p>.04 WP S/(S/N)</p><p>.02 WP  a surprisingly small set of special function words and therefore perhaps a strategic place for super- vision. Questions in particular pose an interesting learning question -how does one learn that these constructions indicate missing information which only becomes available later in the discourse?</p><p>Grammatical complexity and size of the search space As lexical categories are a good proxy for the set of constructions the grammar will enter- tain, we can measure the size and ambiguity of the search space as a function of the number of lexical category types it induces as compared to the per- centage that are actually valid categories for the language. In <ref type="table" target="#tab_6">Table 9</ref>, we compare the lexicons in- duced by variants of the induction algorithm by their token-based coverage (the percent of tokens in Sections 22 for which the induced tag lexicon contains the correct category), type-based cover- age (the percent of category types that the induced lexicon contains), as well as type-based precision (the percent of induced category types that occur in Section 22). This analysis is independent of the learned models, as their probabilities are not taken into account. We see that as the number of lex- ical categories induced (subject to the constraints of <ref type="bibr" target="#b0">Bisk and Hockenmaier (2012)</ref>) increases, the percent that are valid English categories decreases rapidly (type-based precision falls from 81.1% to 36.1%). Despite this, and despite a high token coverage of up to 90%, we still miss almost 70% of the required category types. This helps explain why performance degrades so much for B C 3 , the arity three lexicon with complex arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Dealing with Non-Local Dependencies</head><p>While the methodology used here is restricted to CCG based algorithms, we believe the lessons to be very general. The aforementioned construc- tions involve optional arguments, non-local de- pendencies, and multiple potential heads. Even though CCG is theoretically expressive enough to handle these constructions, they present the un- supervised learner with additional ambiguity that will pose difficulties independently of the under- lying grammatical representation.</p><p>For example, although our approach learns that subject NPs are taken as arguments by verbs, the task of deciding which verb to attach the subject to is frequently ambiguous. This most commonly occurs in verb chains, and is compounded in the presence of subject-modifying relative clauses (in CCGbank, both constructions are in fact treated as several verbs sharing a single subject). To illustrate this, we ran the B C 1 and B 3 P&amp;L systems on the following three sentences:</p><p>1. The woman won an award 2. The woman has won an award 3. The woman being promoted has won an award</p><p>The single-verb sentence is correctly parsed by both models, but they flounder as distractors are added. Both treat has as an intransitive verb, won as an adverb and an as a preposition: Discovering these, and many of the other sys- tematic errors describe here, may be less obvi- ous when analyzing unlabeled dependency trees. But we would expect similar difficulties for any unsupervised approach when sentence complexity grows without a specific bias for a given analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusions</head><p>In this paper, we have introduced labeled evalu- ation metrics for unsupervised CCG parsers, and have shown that these expose many common syn- tactic phenomena that are currently out of scope for any unsupervised grammar induction systems. While we do not wish claim that CCGbank's anal- yses are free of arbitrary decisions, we hope to have demonstrated that these labeled metrics en- able linguistically informed error analyses, and hence allow us to at least in part address the ques- tion of where and why the performance of these approaches might plateau. We focused our analy- sis on English for simplicity, but many of the same types of problems exist in other languages and can be easily identified as stemming from the same lack of supervision. For example, in Japanese we would expect problems with post-positions, in German with verb clusters, in Chinese with mea- sure words, or in Arabic with morphology and variable word order.</p><p>We believe that one way to overcome the is- sues we have identified is to incorporate a seman- tic signal. Lexical semantics, if sparsity can be avoided, might suffice; otherwise learning with grounding or an extrinsic task could be used to bias the choice of predicates, their arity and in turn the function words that connect them. Alterna- tively, a simpler solution might be to follow the lead of Boonkwan and Steedman (2011) or <ref type="bibr" target="#b7">Garrette et al. (2015)</ref> where gold categories are as- signed by a linguist or treebank to tags and words. It is possible that more limited syntactic supervi- sion might be sufficient if focused on the semanti- cally ambiguous cases we have isolated.</p><p>More generally, we hope to initiate a conver- sation about grammar induction which includes a discussion of how these non-trivial constructions can be discovered, learned, and modeled. Relat- edly, in future extensions to semi-supervised or projection based approaches, these types of con- structions are probably the most useful to get right despite comprising the tail, as analyses without them may not be semantically appropriate. In summary, we hope to begin to pull back the veil on the types of information that a truly unsuper- vised system, if one should ever exist, would need to learn, and we pose a challenge to the commu- nity to find ways that a learner might discover this knowledge without hand-engineering it. This material is based upon work supported by the National Science Foundation under Grants No. 1053856, 1205627 and 1405883. Any opinions, findings, and conclusions or recommendations ex- pressed in this material are those of the author(s) and do not necessarily reflect the views of the Na- tional Science Foundation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>I</head><label></label><figDesc>saw her from afar I saw her from afar I saw her from afar I saw her from afar</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>pobj I saw her from afar I saw her from afar I saw her from afar I saw her from afar</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>N</head><label></label><figDesc>:{he, girl, lunch,...} N/N:{good, the, eating, ...} S\N:{sleeps, ate, eating,...} (S\N)/N:{sees, ate, ...} S\S:{quickly, today...} S/S:{Today,...}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>N</head><label></label><figDesc>:{he, girl, lunch,...} N/N:{good, the, eating, ...} S\N:{sleeps, ate, eating,...} (S\N)/N:{sees, ate, ...} S\S:{quickly, today...} S/S:{Today,...}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>CCGbank</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>To accommodate the presence of two additional verbs, both models analyze being as a noun modi- fier that takes promoted as an argument. B C 1 (cor- rectly) stipulates a non-local dependency involv- ing promoted, but treats it (arguably incorrectly) as a case of object extraction:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Common categories that the algorithm 
cannot induce, and their corpus probability (given 
their most frequent tag in Sec. 02-21) 

Model Supervision 
LF1 UF1 

B1 
POS tags 
34.5 60.6 

B3 

P&amp;L 

+ Punc &amp; Words 37.1 64.9 
B C 

1 

+ Complex Args 34.9 63.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>.2@20.</figDesc><table>CCGbank 02-21 
WSJ2-21 DA 
Model 
LF1 UF1 
@10 @20 @1 

Naseem (Universal) 
71.9 
50.4 
Naseem (English) 
73.8 
66.1 

B1 
33.8 60.3 
70.7 
63.1 
58.4 

B3 

P&amp;L 

38.3 66.2 
71.3 
65.9 
62.3 
B C 

1 

34.4 62.0 
70.5 
65.4 
61.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Performance on CCGbank and CoNLL-
style dependencies (Sections 02-21) for a compar-
ison with Naseem et al. (2010). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Common categories that the algorithm 
cannot induce, and their corpus probability (given 
their most frequent tag in Sec. 02-21) 

Model Supervision 
LF1 UF1 

B1 
POS tags 
34.5 60.6 

B3 

P&amp;L 

+ Punc &amp; Words 37.1 64.9 
B C 

1 

+ Complex Args 34.9 63.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 9 :</head><label>9</label><figDesc>Overall performance of the final systems discussed in this paper (Section 23) dicate missing information which only becomes available later in the discourse.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head></head><label></label><figDesc>.2@20.</figDesc><table>CCGbank 02-21 
WSJ2-21 DA 
Model 
LF1 UF1 
@10 @20 @1 

Naseem (Universal) 
71.9 
50.4 
Naseem (English) 
73.8 
66.1 

B1 
33.8 60.3 
70.7 
63.1 
58.4 

B3 

P&amp;L 

38.3 66.2 
71.3 
65.9 
62.3 
B C 

1 

34.4 62.0 
70.5 
65.4 
61.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Performance on CCGbank and CoNLL-
style dependencies (Sections 02-21) for a compar-
ison with Naseem et al. (2010). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Figure 2 : We remove morphosyntactic features, simplify verb phrase modifiers, and change NP to N.</head><label>2</label><figDesc></figDesc><table>CCGbank w/out Feats Simplified 

All 
1640 
458 
444 
Lexical 
1286 
393 
384 

Table 1: Category types in CCGbank 02-21 

determiners and other structural elements of a lan-
guage. Finally, CCGbank distinguishes between 
sentential modifiers (which have categories of the 
form S|S, without features) and verb phrase mod-
ifiers ((S\NP)|(S\NP), again without features). 
But since the NP argument slot of a VP mod-
ifier is never filled, we can maintain the same 
number of gold standard dependencies by remov-
ing this distinction and changing all VP modifiers 
to be of the form S|S. However, categories of 
the form (S[·]\NP i )/(S[·]\NP i ), which are used 
e.g. for modals and auxiliaries, are changed to 
(S\N i )/(S\N i )</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 2 : The impact of our changes to Bisk and Hockenmaier's (2013) model (henceforth: B 1 , top left</head><label>2</label><figDesc></figDesc><table>) 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance on CCGbank and CoNLL-
style dependencies (Sections 02-21) for a compar-
ison with Naseem et al. (2010). 

and punctuation are modeled. Allowing complex 
arguments is generally not beneficial, and perfor-
mance drops further if the grammatical complex-
ity is increased to B 3 . Our further analysis will 
focus on the three bolded models, B 1 , B C 
1 (the 
best model with complex arguments) and B P&amp;L 

3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Detailed supertagging analysis: Recall scores of B 1 , B C 
1 , and B 3 

P&amp;L 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Categories that are in the search space of the induction algorithm, but do not occur in any Viterbi 
parse, and what B C 
1 uses instead. 

there are many constructions which have vastly 
different analysis, making a proper conversion too 
difficult for the scope of this paper. 3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Common categories that the algorithm 
cannot induce 

Size, ambiguity, coverage and precision 
of the induced lexicons 
Arguments: 
Atomic 
Complex 
# Lexical Arity: 
2 
3 
2 
3 

# Lexical Categories 
37 
53 
61 133 
Avg. #Cats / Tag 
26.4 29.5 
42.3 56.3 
Token-based Coverage 
84.3 84.4 
89.8 90.2 
Type-based Coverage 
20.3 21.6 
27.0 32.4 
Type-based Precision 
81.1 60.4 
65.6 36.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Size, ambiguity, coverage and precision 
(evaluated on Section 22) of the induced lexicons. 

</table></figure>

			<note place="foot" n="2"> That is, the argument X and result X of a modifier X|X are not two distinct instances of the same category, but unify.</note>

			<note place="foot" n="1"> We tested three values (1000, 2500, 5000) and found that the basic model at 2500 performed closest to the previously</note>

			<note place="foot" n="2"> BH13 use hyperparameter schemes and report 64.2@20.</note>

			<note place="foot" n="3"> The overlap (F-score of unlabeled undirected attachment scores) between CCGbank dependencies and those obtained via Matsumoto&apos;s head finding rules is only 81.9%.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simple Robust Grammar Induction with Combinatory Categorial Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentySixth Conference on Artificial Intelligence (AAAI12)</title>
		<meeting>the TwentySixth Conference on Artificial Intelligence (AAAI12)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1643" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An HDP Model for Inducing Combinatory Categorial Grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="75" to="88" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised Induction of Tree Substitution Grammars for Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1204" to="1213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Grammar Induction from Text Using Small Syntactic Prototypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prachya</forename><surname>Boonkwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
			<biblScope unit="page" from="438" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Valence induction with a head-lexicalized PCFG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glenn</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 3rd Conference on Empirical Methods in Natural Language Processing<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building Deep Dependency Structures using a Wide-Coverage CCG Parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="327" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accurate Context-Free Parsing with Combinatory Categorial Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A D</forename><surname>Timothy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weakly-Supervised GrammarInformed Bayesian CCG Parser Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)<address><addrLine>Austin, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving Unsupervised Dependency Parsing with Richer Contexts and Smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename><surname>William P Headden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="101" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="355" to="396" />
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CorpusBased Induction of Syntactic Structure: Models of Dependency and Constituency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="478" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Infinite PCFG Using Hierarchical Dirichlet Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="688" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stopprobability estimates computed on a large corpus improve Unsupervised Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mareček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using Universal Linguistic Knowledge to Guide Grammar Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Punctuation: Making a Point in Unsupervised Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The Syntactic Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical Dirichlet Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<biblScope unit="page" from="1566" to="1581" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Statistical Dependency Analysis With Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 8th International Workshop on Parsing Technologies (IWPT)</title>
		<meeting>8th International Workshop on Parsing Technologies (IWPT)<address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
