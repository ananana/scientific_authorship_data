<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mining Paraphrasal Typed Templates from a Plain Text Corpus</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Biran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terra</forename><surname>Blevins</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Columbia University</orgName>
								<orgName type="institution" key="instit3">Columbia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Mining Paraphrasal Typed Templates from a Plain Text Corpus</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1913" to="1923"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Finding paraphrases in text is an important task with implications for generation , summarization and question answering , among other applications. Of particular interest to those applications is the specific formulation of the task where the paraphrases are templated, which provides an easy way to lexicalize one message in multiple ways by simply plugging in the relevant entities. Previous work has fo-cused on mining paraphrases from parallel and comparable corpora, or mining very short sub-sentence synonyms and paraphrases. In this paper we present an approach which combines distributional and KB-driven methods to allow robust mining of sentence-level paraphrasal templates, utilizing a rich type system for the slots, from a plain text corpus.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the main difficulties in Natural Language Generation (NLG) is the surface realization of messages: transforming a message from its inter- nal representation to a natural language phrase, sentence or larger structure expressing it. Often the simplest way to realize messages is though the use of templates. For example, any message about the birth year and place of any person can be ex- pressed with the template " <ref type="bibr">[Person]</ref> was born in <ref type="bibr">[Place]</ref> in <ref type="bibr">[Year]</ref>".</p><p>Templates have the advantage that the genera- tion system does not have to deal with the inter- nal syntax and coherence of each template, and can instead focus on document-level discourse co- herence and on local coreference issues. On the other hand, templates have two major disadvan- tages. First, having a human manually compose a template for each possible message is costly, espe- cially when a generation system is relatively open- ended or is expected to deal with many domains. In addition, a text generated using templates often lacks variation, which means the system's output will be repetitive, unlike natural text produced by a human.</p><p>In this paper, we are concerned with a task aimed at solving both problems: automatically mining paraphrasal templates, i.e. groups of tem- plates which share the same slot types and which, if their slots are filled with the same entities, re- sult in paraphrases. We introduce an unsupervised approach to paraphrasal template mining from the text of Wikipedia articles.</p><p>Most previous work on paraphrase detection fo- cuses either on a corpus of aligned paraphrase candidates or on such candidates extracted from a parallel or comparable corpus. In contrast, we are concerned with a very large dataset of tem- plates extracted from a single corpus, where any two templates are potential paraphrases. Specifi- cally, paraphrasal templates can be extracted from sentences which are not in fact paraphrases; for example, the sentences "The population of Mis- souri includes more than 1 million African Ameri- cans" and "Roughly 185,000 Japanese Americans reside in Hawaii" can produce the templated para- phrases "The population of [american state] in- cludes more than <ref type="bibr">[number]</ref> [ethnic group]" and "Roughly <ref type="bibr">[number]</ref> [ethnic group] reside in [amer- ican state]". Looking for paraphrases among tem- plates, instead of among sentences, allows us to avoid using an aligned corpus.</p><p>Our approach consists of three stages. First, we process the entire corpus and determine slot lo- cations, transforming the sentences to templates (Section 4). Next, we find most approriate type for each slot using a large taxonomy, and group to- gether templates which share the same set of types as potential paraphrases (Section 5). Finally, we cluster the templates in each group into sets of paraphrasal templates (Section 6).</p><p>We apply our approach to six corpora represent- ing diverse subject domains, and show through a crowd-sourced evaluation that we can achieve a high precision of over 80% with a reasonable sim- ilarity threshold setting. We also show that our threshold parameter directly controls the trade-off between the number of paraphrases found and the precision, which makes it easy to adjust our ap- proach to the needs of various applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To our knowledge, although several works exist which utilize paraphrasal templates in some way, the task of extracting them has not been defined as such in the literature. The reason seems to be a difference in priorities. In the context of NLG, <ref type="bibr" target="#b0">Angeli et al. (2010)</ref> as well as <ref type="bibr" target="#b19">Kondadadi et al. (2013)</ref> used paraphrasal templates extracted from aligned corpora of text and data representations in specific domains, which were grouped by the data types they relate to. <ref type="bibr" target="#b12">Duma and Klein (2013)</ref> extract templates from Wikipedia pages aligned with RDF information from DBPedia, and although they do not explicitly mention aligning multiple templates to the same set of RDF templates, the possibility seems to exist in their framework. In contrast, we are interested in extracting paraphrasal templates from non-aligned text for general NLG, as aligned corpora are difficult to obtain for most domains.</p><p>While template extraction has been a relatively small part of NLG research, it is very prominent in the field of Information Extraction (IE), begin- ning with <ref type="bibr" target="#b16">Hearst (1992)</ref>. There, however, the goal is to extract good data and not to extract templates that are good for generation. Many pattern extrac- tion (as it is more commonly referred to in IE) ap- proaches focus on semantic patterns that are not coherent lexically or syntactically, and the idea of paraphrasal templates is not important ( <ref type="bibr" target="#b8">Chambers and Jurafsky, 2011)</ref>. One exception which expic- itly contains a paraphrase detection component is <ref type="bibr" target="#b30">(Sekine, 2006</ref>).</p><p>Meanwhile, independently of templates, detect- ing paraphrases is an important, difficult and well- researched problem of Natural Language Process- ing. It has implications for the general study of se- mantics as well as many specific applications such as Question Answering and Summarization. Re- search that focuses on mining paraphrases from large text corpora is especially relevant for our work. Typically, these approaches utilize a paral- lel ( <ref type="bibr" target="#b5">Barzilay and McKeown, 2001;</ref><ref type="bibr" target="#b17">Ibrahim et al., 2003;</ref><ref type="bibr" target="#b26">Pang et al., 2003;</ref><ref type="bibr" target="#b14">Fujita et al., 2012;</ref><ref type="bibr" target="#b28">Regneri and Wang, 2012)</ref> or compa- rable corpus <ref type="bibr" target="#b32">(Shinyama et al., 2002;</ref><ref type="bibr" target="#b4">Barzilay and Lee, 2003;</ref><ref type="bibr" target="#b29">Sekine, 2005;</ref><ref type="bibr" target="#b31">Shen et al., 2006;</ref><ref type="bibr" target="#b35">Zhao et al., 2009;</ref><ref type="bibr" target="#b34">Wang and Callison-Burch, 2011</ref>), and there have been approaches that leverage bilingual aligned corpora as well <ref type="bibr">(Bannard and CallisonBurch, 2005;</ref><ref type="bibr" target="#b21">Madnani et al., 2008</ref>).</p><p>Of the above, two are particularly relevant. <ref type="bibr" target="#b4">Barzilay and Lee (2003)</ref> produce slotted lattices that are in some ways similar to templates, and their work can be seen as the most closely related to ours. However, as they rely on a comparable corpus and produce untyped slots, it is not directly comparable. In our approach, it is precisely the fact that we use a rich type system that allows us to extract paraphrasal templates from sentences that are not, by themselves, paraphrases and avoid us- ing a comparable corpus. Sekine (2005) produces typed phrase templates, but the approach does not allow learning non-trivial paraphrases (that is, paraphrases that do not share the exact same key- words) from sentences that do not share the same entities (thus remaining dependent on a compara- ble corpus), and the type system is not very rich. In addition, that approach is limited to learning short paraphrases of relations between two entities.</p><p>Another line of research is based on contex- tual similarity <ref type="bibr" target="#b20">(Lin and Pantel, 2001;</ref><ref type="bibr" target="#b25">Pas¸caPas¸ca and Dienes, 2005;</ref><ref type="bibr" target="#b6">Bhagat and Ravichandran, 2008)</ref>. Here, shorter (phrase-level) paraphrases are ex- tracted from a single corpus when they appear in a similar lexical (and in later approaches, also syntactic) context. The main drawbacks of these methods are their inability to handle longer para- phrases and their tendency to find phrase pairs that are semantically related but not real paraphrases (e.g. antonyms or taxonomic siblings).</p><p>More recent work on paraphrase detection has, for the most part, focused on classifying provided sentence pairs as paraphrases or not, using the Mi- crosoft Paraphrase Corpus ( ). <ref type="bibr" target="#b23">Mihalcea et al. (2006</ref>) evaluated a wide range of lexical and semantic measures of similarity and in- troduced a combined metric that outperformed all previous measures. <ref type="bibr" target="#b22">Madnani et al. (2012)</ref> showed that metrics from Machine Translation can be used to find paraphrases with high accuracy. Another line of research uses the similarity of texts in a latent space created through matrix factorization <ref type="bibr" target="#b15">(Guo and Diab, 2012;</ref><ref type="bibr" target="#b18">Ji and Eisenstein, 2013)</ref>. Other approaches that have been explored are ex- plicit alignment models ( <ref type="bibr" target="#b10">Das and Smith, 2009)</ref>, distributional memory tensors ( <ref type="bibr" target="#b3">Baroni and Lenci, 2010)</ref> and syntax-aware representations of multi- word phrases using word embeddings <ref type="bibr" target="#b33">(Socher et al., 2011</ref>). Word embeddings were also used by <ref type="bibr" target="#b24">Milajevs et al. (2014)</ref>. These approaches are not comparable to ours because they focus on classifi- cation, as opposed to mining, of paraphrases.</p><p>Detecting paraphrases is closely related to re- search on the mathematical representation of sen- tences and other short texts, which draws on a vast literature on semantics, including but not limited to lexical, distributional and knowledge-based se- mantics. Of particular interest to us is the work of <ref type="bibr" target="#b7">Blacoe and Lapata (2012)</ref>, which show that simple combination methods (e.g., vector multiplication) in classic vector space representations outperform more sophisticated alternatives which take into ac- count syntax and which use deep representations (e.g. word embeddings, or the distributional mem- ory approach). This finding is appealing since classic vector space representation (distributional vectors) are easy to obtain and are interpretable, making it possible to drill into errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Taxonomy</head><p>Our method relies on a type system which links entities to one another in a taxonomy. We use a combination of WordNet <ref type="bibr">(Fellbaum, 1998) and</ref><ref type="bibr">DBPedia (Auer et al., 2007)</ref>, which provides both a rich top-level type system with lexicalizations of multiple senses and a large database of enti- ties linked through the type system (the top-level DBPedia categories all have cognates in WordNet, which make the two easy to combine). Leveraging the fact that DBPedia entities have corresponding Wikipedia pages, we also use the redirect terms for those pages as alternative lexicalizations of the entity (e.g., the Wikipedia article "United States" has "USA" as a redirect term, among others).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Creating Templates</head><p>The first step to creating the templates is to find entities, which are candidates to becoming slots in the templates. Since we are trying to find sentence-level paraphrasal templates, each sen- tence in the corpus is a potential template.</p><p>Entities are found in multiple ways. First, we use regular expressions to find dates, percentages, currencies, counters (e.g., "9th") and general num- bers. Those special cases are immediately given their known type (e.g., "date" or "percentage"). Next, after POS-tagging the entire corpus, we look for candidate entities of the following kinds: terms that contain only NNP (including NNPS) tags; terms that begin and end with an NNP and con- tain only NNP, TO, IN and DT tags; and terms that contain only capitalized words, regardless of the POS tags. Of these candidates, we only keep ones that appear in the taxonomy. Unlike the spe- cial cases above, the type of the slots created from these general entities is not yet known and will be decided in the next step.</p><p>At the end of this step, we have a set of partially- typed templates: one made from each sentence in the corpus, with its slots (but not their types in most cases) defined by the location of entities. We remove from this set all templates which have less than two slots as these are not likely to be interest- ing, and all templates which have more than five slots to avoid excessively complicated templates.</p><p>We originally experimented with simply accept- ing any term that appears in the taxonomy as an entity. That method, however, resulted in a large number of both errors and entities that were too general to be useful (e.g, "table", "world" and sim- ilar terms are in the taxonomy). Note that NER ap- proaches, even relatively fine-grained ones, would not give us the same richness of types that directly comparing to the taxonomy allows (and the next step requires that each entity we handle exist in the taxonomy, anyway).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Template Typing and Grouping</head><p>Determining the type of a slot in the template presents two difficulties. First, there is a sense dis- ambiuation problem, as many lexical terms have more than one sense (that is, they can correspond to more than one entry in the taxonomy). Sec- ond, even if the sense is known, it is not clear which level of the taxonomy the type should be chosen from. For example, consider the sentence " <ref type="bibr">[JFK]</ref> is <ref type="bibr">[New York]</ref>'s largest airport" (the terms in square brackets will become slots once their types are determined). "JFK" is ambiguous: it can be an airport, a president, a school, etc. The first step in this process is, then, to determine which of the possible senses of the term best fits the sen- tence. But once we determine that the sense of "JFK" here is of an airport, there are different types we can choose. JFK is a New York Air- port, which is a type of Airport, which is a type of Air Field, which is a type of Facility and so on. The specificity of the type we choose will de- termine the correctness of the template, and also which other templates we can consider as poten- tial paraphrases.</p><p>Our solution is a two-stage distributional ap- proach: choosing the sense, and then choosing the type level that best fit the context of the slot. In each stage, we construct a pseudo − sentence (a collection of words in arbitrary, non-grammatical order) from words used in the taxonomy to de- scribe each option (a sense in the first stage, and a type level in the second stage), and then use their vector representations to find the option that best matches the context.</p><p>Following the observation of Blacoe and Lapata (2012) that simple similarity metrics in traditional vector representations match and even outperform more sophisticated representations in finding rela- tions among short texts as long as multiplication is used in forming vector representations for the texts, we use traditional context vectors as the ba- sis of our comparisons in both stages. We collect context vectors from the entire English Wikipedia corpus, with a token window of 5. To avoid noise from rarely occuring words and reduce the size of the vectors, we remove any feature with a count below a threshold of log 10 (Σ) where Σ is the sum of all feature counts in the vector. Finally, the vector features are weighted with (normalized) TF*IDF. <ref type="bibr">1</ref> For a multi-word collection (e.g. a pseudo- sentence) ψ, we define the features of the com- bined vector V ψ using the vectors of member words V w as:</p><formula xml:id="formula_0">V jψ = ( w∈ψ V jw ) 1 |S| (1)</formula><p>Where V jw is the value of the jth feature of V w . To choose the sense of the slot (the first stage), we start with S, the set of all possible senses (in the taxonomy) for the entity in the slot. We cre- ate a pseudo-sentence ψ s from the primary lexi-calizations of all types in the hierarchy above each sense s -e.g., for the airport sense of JFK we cre- ate a single pseudo-sentence ψ JF K−airport−sense consisting of the terms "New York airport", "air- port", "air field", "facility" and so on. <ref type="bibr">2</ref> We create a vector representation V ψs for each ψ s using Equa- tion 1. Then, we create a pseudo-sentence ψ context for the context of the slot, composed of the words in a 5-word window to the left and right of the slot in the original sentence, and create the vector V ψcontext . We choose the sensê s with the highest cosine similarity to the contex:</p><formula xml:id="formula_1">ˆ s = arg max s∈S cos(V ψs , V ψcontext )</formula><p>Note that this is a deep similarity -the similarity of the (corpus) context of the sense and the (cor- pus) context of the slot context; the words in the sentence themselves are not used directly.</p><p>We use the lexicalizations of all types in the hi- erarchy to achieve a more robust vector represen- tation that has higher values for features that co- occur with many levels in the sense's hierarchy. For example, we can imagine that "airplane" will co-occur with many of the types for the JFK air- port sense, but "La Guardia" will not (helping to lower the score of the first, too-specific sense of "New York airport") and neither will features that co-occur with other senses of a particular type - e.g., "Apple" for the "airport" type. <ref type="bibr">3</ref> Once the sense is chosen, we choose the proper type level to use (the second stage). Here we cre- ate a pseudo-sentence for each type level sepa- rately, composed of all possible lexicalizations for the type. For example, the "air field" type contains the lexicalizations "air field", "landing field", and "flying field". These pseudo-sentences are then compared to the context in the same way as above, and the one with highest similarity is chosen. The reason for using all lexicalizations is similar to the one for using all types when determining the sense: to create a more robust representation that down-scores arbitrary co-occurences.</p><p>At the end of this step, the templates are fully typed. Before continuing to the next step of finding paraphrases, we group all potential para- phrases together. Potential paraphrases are simply groups of templates which share exactly the same set of slot types (regardless of ordering).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Finding Paraphrases within Groups</head><p>Each group of potential paraphrases may contain multiple sub-groups such that each of the members of the subgroup is a paraphrase of all the others. In this last stage, we use a clustering algorithm to find these sub-groups.</p><p>We define the distance between any two tem- plates in a group as the Euclidean distance be- tween the vectors (created using Equation 1) of the two templates with the entity slots removed (that is, the pseudo-sentences created with all words in the template outside of the slots). We tried other distance metrics as well (for example, averaging the distances between the contexts surrounding each pair of corresponding slots in both templates) but the Euclidean distance seemed to work best.</p><p>Using this metric, we apply single-linkage ag- glomerative clustering, with the stopping criteria defined as a threshold τ for the maximum sum of squared errors (SSE) within any cluster. Specifi- cally, the algorithm stops linking if the cluster C that would be created by the next link satisfies:</p><formula xml:id="formula_2">log( C v d(v, µ C ) 2 ) ≥ τ</formula><p>Where µ C is the centroid of C and d is the Eu- clidean distance. The logarithm is added for con- venience, since the SSE can get quite large and we want to keep τ on a smaller scale.</p><p>The intuition behind this algorithm is that some paraphrases will be very similar (lexically or on a deeper level) and easy to find, while some will be more difficult to distinguish from template pairs that are related but not paraphrasal. The single- linkage approach is essentially transductive, al- lowing the most obvious clusters to emerge first and avoiding the creation of a central model that will become less precise over time. The threshold is a direct mechanism for controlling the trade-off between precision and recall.</p><p>At the end of this step, any pair of templates within the same cluster is considered a para- phrase. Clusters that contain only a single tem- plate are discarded (in groups that have high dis- tances among their member templates, often the entire group is discarded since even a single link violates the threshold).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Evaluation</head><p>To evaluate our method, we applied it to the six do- mains described in <ref type="table">Table 1</ref>. We tried to choose a set of domains that are diverse in topic, size and degree of repeated structure across documents. For each domain, we collected a corpus com- posed of relevant Wikipedia articles (as described in the table) and used the method described in Sections 4-6 to extract paraphrasal templates. We used Wikipedia for convenience, since it allows us to easily select domain corpora, but there is noth- ing in our approach that is specific to Wikipedia; it can be applied to any text corpus.</p><p>We sampled 400 pairs of paraphrases extracted from each domain and used this set of 2400 pairs to conduct a crowd-sourced human evaluation on CrowdFlower. For each template pair, we ran- domly selected one and used its original entities in both templates to create two sentences about the same set of entities. The annotators were pre- sented with this pair and asked to score the extent to which they are paraphrases on a scale from 1 to 5. <ref type="table" target="#tab_1">Table 2</ref> shows the labels and a brief version of the explanations provided for each. To ensure the quality of annotations, we used a set of hidden test questions throughout the evaluation and rejected the contributions of annotators which did not get at least 70% of the test questions correctly. Of those that did perform well on the test questions, we had three annotators score each pair and used the aver- age as the final score for the pair. In 39.4% of the cases, all three annotators agreed; two annotators agreed in another 47% of the cases, and in the re- maining 13.6% there was complete disagreement. The inter-annotator agreement for the two anno- tators that had the highest overlap (27 annotated pairs), using Cohen's Kappa, was κ = 0.35.</p><p>The overall results are shown in <ref type="figure">Figure 1</ref>. Note that because of our clustering approach, we have a choice of similarity threshold. The results are shown across a range of thresholds from 8 to 11 -it is clear from the figure that the threshold pro- vides a way to control the trade-off between the number of paraphrases generated and their preci- sion. <ref type="table">Table 3</ref> shows the results with our preferred threshold of 9.5.</p><p>The number of paraphrase clusters found changes with the threshold. For the 9.5 threshold we find 512 clusters over all domains, a little over 60% of the number of paraphrases. The distribu- tion of their sizes is Zipfian: a few very large clus-   <ref type="table">Table 3</ref>: Size, average score, % of pairs with a score above 3 (paraphrases), and % of pairs with a score above 4 (high quality paraphrases) for the different domains with a 9.5 threshold ters, dozens of increasingly smaller medium-sized ones and a long tail of clusters that contain only two templates. The vast majority of paraphrase pairs come from sentences that were not originally para- phrases (i.e, sentences that originally had differ- ent entities). With a 9.5 threshold, 86% of para- phrases answer that criteria. While that number varies somewhat across thresholds, it is always above 80% and does not consistently increase or decrease as the threshold increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prec. PPS This paper, τ = 8</head><p>Unaligned 94% 0.005 This paper, τ = 9.5 Unaligned 82% 0.013 This paper, τ = 11 Unaligned 65% 0.1 <ref type="bibr" target="#b5">Barzilay and McKeown (2001)</ref> Parallel 86.5% 0.1 * Ibrahim et al. <ref type="formula">(2003)</ref> Parallel 41.2% 0. <ref type="formula">(2012)</ref> Parallel 79% 0.17 * These papers do not report the number of sentences in the corpus, but do report enough for us to estimate it (e.g. the number of documents or the size in MB) ** These papers do not report the number of paraphrases extracted, or such a number does not exist in their approach <ref type="table">Table 4</ref>: Comparison with the precision and paraphrases generated per input sentence (PPS) of relevant prior work</p><note type="other">11 * Pang et al. (2003) Parallel 81.5% 0.33 Barzilay and Lee (2003) Comparable 78.5% 0.07 Bannard and Callison-Burch (2005) Parallel bilingual 61.9% n/a ** Zhao et al. (2009) Parallel or Comparable 70.6% n/a ** Wang and Callison-Burch (2011) Comparable 67% 0.01 Fujita et al. (2012) Parallel bilingual + unaligned 58% 0.34 Regneri and Wang</note><p>While we wanted to show a meaningful com- parison with another method from previous work, none of them do what we are doing here -extrac- tion of sentence-size paraphrasal templates from a non-aligned corpus -and so a comparison us- ing the same data would not be fair (and in most cases, not possible). While it seems that provid- ing the results of human evaluation without com- parison to prior methods is the norm in most rel- evant prior work ( <ref type="bibr" target="#b17">Ibrahim et al., 2003;</ref><ref type="bibr" target="#b25">Pas¸caPas¸ca and Dienes, 2005;</ref><ref type="bibr" target="#b2">Bannard and Callison-Burch, 2005;</ref><ref type="bibr" target="#b14">Fujita et al., 2012)</ref>, we wanted to at least get some sense of where we stand in comparison to other methods, and so we provide a list of (not directly comparable) results reported by other authors in <ref type="table">Table 4</ref>. <ref type="bibr">4</ref> While it is impossible to meaningfully compare and rate such different methods, these numbers support the conclusion that our single- corpus, domain-agnostic approach achieves a pre- cision that is similar to or better than other meth- ods. We also include the paraphrase per sentence (PPS) value -the ratio of paraphrases extracted to the number of input sentences of the corpus -for each method in the table. We intend this figure as the closest thing to recall that we can conceive for mining paraphrases. However, keep in mind that it is not a comparable figure across the meth- ods, since different corpora are used. In partic- ular, it is expected to be significantly higher for parallel corpora, where the entire corpus consists of potential paraphrases (and that fact is reflected in <ref type="table">Table 4</ref>, where some methods that use parallel corpora have a PPS that is an order of magnitude higher than other methods).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion and Examples</head><p>The first thing to note about the results shown in <ref type="figure">Figure 1</ref> is that even for the highest threshold considered, which gives us a ×21 improvement in size over the smallest threshold considered, all domains except CWB achieve an average score higher than 3, meaning most of the pairs extracted are paraphrases (CWB is close -a little over 2.9 on average). For the lowest threshold considered, all domains are at a precision above 88%, and for three of them it is 100%. In general, across all do- mains, there seems to be a significant drop in pre- cision (and a significant boost in size) for thresh- olds between 9 and 10, while the precisions and sizes are fairly stable for thresholds between 8 and 9 and between 10 and 11. This result is encourag- ing: since the method seems to behave fairly simi- larly for different domains with regard to changes in the threshold, we should be able to expect sim- ilar behavior for new domains as the threshold is adjusted.</p><p>The magnitude of precision across domains is another matter. It is clear from the results that some domains are more difficult than others. The Metal domain seems to be the hardest: it never achieves an average score higher than 3.8. For the highest threshold, however, Metal is not dif- ferent from most of the others, while CWB is sig- nificantly lower in precision. The reason seems to be the styles of the domain articles: some domains tend to have a more structured form. For exam- ple, each article in the States domain will discuss the economy, demographics, formation etc. of the state, and we are more likely to find paraphrases there (simply by virtue of there being 50 × 49 can- didates). Articles in the Metal domain are much less structured, and there are fewer obvious para- phrase candidates. In CWB articles, there are a few repetitive themes: the outcome of the battle, the casualties, the generals involved etc., but be- yond that it is fairly unstructured. This "struc- turality" of the domain also affects the number of paraphrases that can be found, as evident from the number of paraphrases found in the states domain in <ref type="table">Table 3</ref> as compared with the (much larger) Metal and CWB domains. <ref type="table" target="#tab_3">Table 5</ref> shows a number of examples from each domain, along with the score given to each by the annotators. In an informal error analysis, we saw a few scenarios recurring in low-scored pairs. The Metal example at the bottom of <ref type="table" target="#tab_3">Table 5</ref> is a dou- ble case of bad sense disambiguation: the album in the second sentence ("Pyromania" in the origi- nal) happened to have a name that is also a patho- logical state. In addition, the number in the sec- ond sentence really was a date ("1980"). If we had correctly assigned the senses, these two tem- plates would not be paraphrase candidates. The process of grouping by type is an important part of improving precision: two sentences can be mis- leadingly similar in the vector space, but it is less likely to have two sentences with the exact same entity types and a high vector similarity that are not close in meaning.</p><p>Another scenario is the one seen in the NBA example that was scored as 1. Here the senses were chosen correctly, but the level of the hierar- chy chosen for the person slot was too high. If instead we had chosen basketball coach and bas- ketball player for the two sentences respectively, they would not be considered as paraphrase can- didates (and note that both meanings are implied by the templates). This sort of error does not cre- ate a problem (in our evaluation, at least) if the more accurate sense is the same in both sentences -for example, in the other NBA example (which scored 4), the place slot could be more accurately replaced with sports arena in both templates.</p><p>Cases where the types are chosen correctly do not always result in perfect paraphrases, but are typically at least related (e.g. in the examples that scored 2, and to a lesser extent those that scored 3). That scenario can be controlled using a lower threshold, with the downside that the number of paraphrases found decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Future Work</head><p>We presented a method for extracting paraphrasal templates from a plain text corpus in three steps: templatizing the sentences of the corpus; finding the most appropriate type for each slot; and clus- tering groups of templates that share the same set of types into paraphrasal sub-groups. We conducted a crowd-sourced human evaluation and showed that our method performs similarly to or better than prior work on mining paraphrases, with three major improvements. First, we do not rely on a parallel or comparable corpus, which are not as easily obtained; second, we produce typed tem- plates that utilize a rich, fine-grained type system, which can make them more suitable for genera- tion; and third, by using such a type system we are able to find paraphrases from sentence pairs that are not, before templatization, really paraphrases.</p><p>Many, if not most, of the worst misidentifica- tions seem to be the result of errors in the sec- ond stage of the approach -disambiguating the sense and specificity of the slot types. In this paper we focused on a traditional distributional approach that has the advantage of being explainable, but it would be interesting and useful to explore other options such as word embeddings, matrix factor- ization and semantic similarity metrics. We leave these to future work.</p><p>Another task for future work is semantic align- ment. Our approach discovers paraphrasal tem- plates without aligning them to a semantic mean- ing representation; while these are perfectly usable by summarization, question answering, and other text-to-text generation applications, it would be useful for concept-to-text generation and other ap- plications to have each cluster of templates aligned Marvel [imaginary being 1] approached [imaginary being 2], hunting for leads about the whereabouts of the X-Men.</p><p>[imaginary being 1] and [imaginary being 2] eventually found the X-Men and became full time mem- bers. Metal</p><p>In [date 1], [band) 1] recorded their third studio album, "[album 1]", which was produced by Kornelije Kovač.</p><p>[band 1] released their next full-length studio album, "[album 1]" in [date 1]. 2 Auma [company 1] and its subsidiaries created a variety of initiatives in the social sphere, initially in [country 1] and then internationally as the company expanded.</p><p>[</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>company 1] participated in [country 1]'s unprecedented economic growth of the 1950s and 1960s. Marvel</head><p>Using her powers of psychological deduction, she picked up on [first name 1]'s attraction towards her, and then [first name 2] admits she is attracted to him as well.</p><p>While [first name 1] became shy, reserved and bookish, [first name 2] became athletically inclined, aggressive, and arrogant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">NBA Though the [date 1] 76ers exceeded many on-court expectations, there was a great deal of behind-the- scenes tension between [person 1], his players, and the front office. After an [date 1] start, with [person 1] already hurt, these critics seemed to have been proven right. Metal</head><p>Within [number 1] hours of the statement, he died of bronchial pneumonia, which was brought on as a complication of [pathological state 1].</p><p>With the album's massive success, "[pathological state 1]" was the catalyst for the [number 1] pop-metal movement. to a semantic representation of the meaning ex- pressed. Since we already discover all the entity types involved, all that is missing is the proposi- tion (or frame, or set of propositions); this seems to be a straightforward, though not necessarily easy, task to tackle in the near future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Annotation score labels and explanations 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 : Examples of template pairs and their scores</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> A &quot;term&quot; being a single feature count, and a &quot;document&quot; being a vector</note>

			<note place="foot" n="2"> But we exclude a fixed, small set of the most abstract types from the first few levels of the WordNet hierarchy, as these turn out to never be useful 3 AirPort is the name of an Apple product</note>

			<note place="foot" n="4"> We always show the results of the best system described. Where needed, if results were reported in a different way than simple percentages, we use averages and other appropriate measures. Some previous work defines related sentences (as opposed to paraphrases) as positives and some does not; we do not change their numbers to fit a single definition, but we use the harsher measure for our own results</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A simple domain-independent probabilistic approach to generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="502" to="512" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dbpedia: a nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC&apos;07/ASWC&apos;07</title>
		<meeting>the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC&apos;07/ASWC&apos;07<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Paraphrasing with bilingual parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="597" to="604" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distributional memory: A general framework for corpusbased semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="673" to="721" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to paraphrase: An unsupervised approach using multiple-sequence alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
	<note>NAACL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extracting paraphrases from a parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, ACL &apos;01</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics, ACL &apos;01<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large Scale Acquisition of Paraphrases for Learning Surface Patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="674" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A comparison of vector-based representations for semantic composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Blacoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="546" to="556" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Template-based information extraction without the templates</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="976" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Paraphrase identification as probabilistic quasi-synchronous recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-IJCNLP</title>
		<meeting>of ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Coling</title>
		<meeting>Coling<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>COLING</publisher>
			<date type="published" when="2004-08-23" />
			<biblScope unit="page" from="350" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generating natural language from linked data: Unsupervised template extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Duma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013)-Long Papers</title>
		<meeting>the 10th International Conference on Computational Semantics (IWCS 2013)-Long Papers</meeting>
		<imprint>
			<publisher>ASSOC COMPUTATIONAL LINGUISTICS-ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="83" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">WordNet An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enlarging paraphrase collections through generalization and instantiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="631" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling sentences in the latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marti A Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th conference on Computational linguistics</title>
		<meeting>the 14th conference on Computational linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting structural paraphrases from aligned monolingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Paraphrasing</title>
		<meeting>the Second International Workshop on Paraphrasing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
	<note>PARAPHRASE &apos;03</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative improvements to distributional sentence similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing, EMNLP 2013<address><addrLine>Seattle, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="891" to="896" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A statistical nlg framework for aggregated planning and realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kondadadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blake</forename><surname>Howald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1406" to="1415" />
		</imprint>
	</monogr>
	<note>ACL (1)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dirt @sbt@discovery of inference rules from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;01</title>
		<meeting>the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="323" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Applying automatically generated semantic knowledge: A case study in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NSF Symposium on Semantic Knowl</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Re-examining machine translation metrics for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT &apos;12</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="182" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Corpus-based and knowledge-based measures of text semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st National Conference on Artificial Intelligence</title>
		<meeting>the 21st National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="775" to="780" />
		</imprint>
	</monogr>
	<note>AAAI&apos;06</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating neural word representations in tensor-based compositional settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Milajevs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kartsaklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadrzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Purver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP), Doha, Qatar. Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Aligning needles in a haystack: Paraphrase acquisition across the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pas¸capas¸ca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Péter</forename><surname>Dienes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Joint Conference on Natural Language Processing, IJCNLP&apos;05</title>
		<meeting>the Second International Joint Conference on Natural Language Processing, IJCNLP&apos;05<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="119" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="102" to="109" />
		</imprint>
	</monogr>
	<note>NAACL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Monolingual machine translation for paraphrase generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using discourse information for paraphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="916" to="927" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Automatic paraphrase discovery based on context and keywords between ne pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing (IWP2005)</title>
		<meeting>the Third International Workshop on Paraphrasing (IWP2005)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="80" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On-demand information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main Conference Poster Sessions, COLING-ACL &apos;06</title>
		<meeting>the COLING/ACL on Main Conference Poster Sessions, COLING-ACL &apos;06<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="731" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adding syntax to dynamic programming for aligning comparable texts for the generation of paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agam</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günesgünes¸günes¸erkan</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main Conference Poster Sessions, COLING-ACL &apos;06</title>
		<meeting>the COLING/ACL on Main Conference Poster Sessions, COLING-ACL &apos;06<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="747" to="754" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic paraphrase acquisition from news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Shinyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoshi</forename><surname>Sudo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research, HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research, HLT &apos;02<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="313" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semi-supervised recursive autoencoders for predicting sentiment distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Paraphrase fragment extraction from monolingual comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web, BUCC &apos;11</title>
		<meeting>the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web, BUCC &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="52" to="60" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Application-driven statistical paraphrase generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th</title>
		<meeting>the Joint Conference of the 47th</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<title level="m">Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="834" to="842" />
		</imprint>
	</monogr>
	<note>ACL &apos;09</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
