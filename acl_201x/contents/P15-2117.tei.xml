<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buzhou</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
							<email>wangxl@insun.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Intelligent Computing Research Center</orgName>
								<orgName type="department" key="dep2">Shenzhen Graduate School</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="713" to="718"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, the answer selection problem in community question answering (CQA) is regarded as an answer sequence labeling task, and a novel approach is proposed based on the recurrent architecture for this problem. Our approach applies convo-lution neural networks (CNNs) to learning the joint representation of question-answer pair firstly, and then uses the joint representation as input of the long short-term memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 C-QA dataset shows the effectiveness of our approach.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Answer selection in community question answer- ing (CQA), which recognizes high-quality re- sponses to obtain useful question-answer pairs, is greatly valuable for knowledge base construc- tion and information retrieval systems. To rec- ognize matching answers for a question, typi- cal approaches model semantic matching between question and answer by exploring various fea- tures ( <ref type="bibr" target="#b17">Wang et al., 2009a;</ref><ref type="bibr" target="#b14">Shah and Pomerantz, 2010)</ref>. Some studies exploit syntactic tree struc- tures ( <ref type="bibr" target="#b18">Wang et al., 2009b;</ref><ref type="bibr" target="#b12">Moschitti et al., 2007)</ref> to measure the semantic matching between question and answer. However, these approaches require high-quality data and various external resources which may be quite difficult to obtain. To take advantage of a large quantity of raw data, deep learning based approaches ( <ref type="bibr" target="#b19">Wang et al., 2010;</ref><ref type="bibr" target="#b5">Hu et al., 2013</ref>  semantic correlations embedded in the answer se- quence of a question are ignored, while they are very important for answer selection. <ref type="figure" target="#fig_0">Figure 1</ref> is a example to show the relationship of answers in the sequence for a given question. Intuitively, other answers of the question are beneficial to judge the quality of the current answer.</p><p>Recently, recurrent neural network (RNN), especially Long Short-Term Memory (LST- M) <ref type="bibr" target="#b4">(Hochreiter et al., 2001</ref>), has been proved su- periority in various tasks <ref type="bibr" target="#b16">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b15">Srivastava et al., 2015</ref>) and it models long term and short term information of the sequence. And also, there are some works on using convolution- al neural networks (CNNs) to learn the represen- tations of sentence or short text, which achieve state-of-the-art performance on sentiment classi- fication <ref type="bibr" target="#b9">(Kim, 2014</ref>) and short text matching ( <ref type="bibr" target="#b6">Hu et al., 2014)</ref>.</p><p>In this paper, we address the answer selection problem as a sequence labeling task, which iden- tifies the matching quality of each answer in the answer sequence of a question. Firstly, CNNs are used to learn the joint representation of question answer (QA) pair. Then the learnt joint repre-sentations are used as inputs of LSTM to predic- t the quality (e.g., Good, Bad and Potential) of each answer in the answer sequence. Experiments conducted on the CQA dataset of the answer se- lection task in SemEval-2015 <ref type="bibr">1</ref> show that the pro- posed approach outperforms other state-of-the-art approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Prior studies on answer selection generally treat- ed this challenge as a classification problem via employing machine learning methods, which re- ly on exploring various features to represent QA pair. <ref type="bibr" target="#b7">Huang et al. (2007)</ref> integrated textual fea- tures with structural features of forum threads to represent the candidate QA pairs, and used sup- port vector machine (SVM) to classify the can- didate pairs. Beyond typical features, Shah and Pomerantz (2010) trained a logistic regression (L- R) classifier with user metadata to predict the qual- ity of answers in CQA. <ref type="bibr" target="#b1">Ding et al. (2008)</ref> pro- posed an approach based on conditional random fields (CRF), which can capture contextual fea- tures from the answer sequence for the semantic matching between question and answer. Addition- ally, the translation-based language model was al- so used for QA matching by transferring the an- swer to the corresponding question ( <ref type="bibr" target="#b8">Jeon et al., 2005;</ref><ref type="bibr" target="#b20">Xue et al., 2008;</ref><ref type="bibr" target="#b23">Zhou et al., 2011</ref>). The translation-based methods suffer from the infor- mal words or phrases in Q&amp;A archives, and per- form less applicability in new domains.</p><p>In contrast to symbolic representation, <ref type="bibr" target="#b19">Wang et al. (2010)</ref> proposed a deep belief nets (DBN) based semantic relevance model to learn the dis- tributed representation of QA pair. Recently, the convolutional neural networks (CNNs) based sen- tence representation models have achieved suc- cesses in neural language processing (NLP) tasks. <ref type="bibr" target="#b21">Yu et al. (2014)</ref> proposed a convolutional sentence model to identify answer contents of a question from Q&amp;A archives via means of distributed rep- resentations. The work in <ref type="bibr" target="#b6">Hu et al. (2014)</ref> demon- strated that 2-dimensional convolutional sentence models can represent the hierarchical structures of sentences and capture rich matching patterns be- tween two language objects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>We consider the answer selection problem in CQA as a sequence labeling task. To label the matching quality of each answer for a given question, our approach models the semantic links between suc- cessive answers, as well as the semantic relevance between question and answer. <ref type="figure">Figure 2</ref> summa- rizes the recurrent architecture of our model (R- CNN). The motivation of R-CNN is to learn the useful context to improve the performance of an- swer selection. The answer sequence is modeled to enrich semantic features.</p><p>At each step, our approach uses the pre-trained word embeddings to encode the sentences of QA pair, which then is used as the input vectors of the model. Based on the joint representation of QA pair learned from CNNs, the LSTM is applied in our model for answer sequence learning, which makes a prediction to each answer of the question with softmax function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolutional Neural Networks for QA Joint Learning</head><p>Given a question-answer pair at the step t, we use convolutional neural networks (CNNs) to learn the joint representation p t for the pair. <ref type="figure" target="#fig_2">Figure 3</ref> illus- trates the process of QA joint learning, which in- cludes two stages: summarizing the meaning of the question and an answer, and generating the joint representation of QA pair.</p><p>To obtain high-level sentence representations of the question and answer, we set 3 hidden layers in two convolutional sentence models respective- ly. The output of each hidden layer is made up of a set of 2-dimensional arrays called feature map pa- rameters (w m , b m ). Each feature map is the out- come of one convolutional or pooling filter. Each pooling layer is followed an activation function σ. The output of the m th hidden layer is computed as </p><formula xml:id="formula_0">H m = σ(pool(w m H m−1 + b m ))<label>(1)</label></formula><p>Here, H 0 is one real-value matrix after sentence semantic encoding by concatenating the word vec- tors with sliding windows. It is the input of deep convolution and pooling, which is similar to that of traditional image input. Finally, we combine the two sentence models by adding an additional layer H t on the top. The learned joint representation p t for QA pair is for- malized as Eq. 2:</p><formula xml:id="formula_1">p t = σ(w t H t + b t )<label>(2)</label></formula><p>where σ is an activation function, and the input vector is constructed by concatenating the sen- tence representations of question and answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">LSTM for Answer Sequence Learning</head><p>Based on the joint representation of QA pair, the LSTM unit of our model performs answer se- quence learning to model semantic links between continuous answers. Unlike the traditional recur- rent unit, the LSTM unit modulates the memory at each time step, instead of overwriting the states.</p><p>The key component of LSTM unit is the memo- ry cell c t which has a state over time, and the L- STM unit decides to modify and add the memory in the cell via the sigmoidal gates: input gate i t , forget gate f t and output gate o t . The implemen- tation of the LSTM unit in our study is close the one discussed by <ref type="bibr" target="#b2">Graves (2013)</ref>. Given the joint representation p t at time t, the memory cell c t is updated by the input gate's activation i t and the forget gate's activation f t . The updating equation is given by Eq. 3: The LSTM unit keeps to update the context by discarding the useless context in forget gate f t and adding new content from input gate i t . The ex- tents to modulate context for these two gates are computed as Eq. 4 and Eq. 5:</p><formula xml:id="formula_2">c t = f t c t−1 +i t tanh(W xc p t +W hc h t−1 +b c )<label>(3)</label></formula><formula xml:id="formula_3">i t = σ(W xi p t + W hi h (t−1) + W ci c t−1 + b i ) (4) f t = σ(W xf p t + W hf h t−1 + W cf c t−1 + b f ) (5)</formula><p>With the updated cell state c t , the final output from LSTM unit h t is computed as Eq 6 and Eq 7:</p><formula xml:id="formula_4">o t = σ(W xo p t + W ho h t−1 + W co c t + b o ) (6) h t = o t tanh(c t )<label>(7)</label></formula><p>Note that (W * , b * ) is the parameters of LSTM unit, in which W cf , W ci , and W co are diagonal matrices.</p><p>According to the output h t at each time step, our approach estimates the conditional probability of the answer sequence over answer classes, it is given by Eq. 8:</p><formula xml:id="formula_5">P (y 1 , ..., y T |c, p 1 , ..., p t−1 ) = T t=1 p(y t |c, y 1 , ..., y t−1 )<label>(8)</label></formula><p>Here, (y 1 , ..., y T ) is the corresponding label se- quence for the input sequence (p 1 , ..., p t−1 ), and the class distribution p(y t |c, y 1 , ..., .y t−1 ) is repre- sented by a softmax function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>Experimental Dataset: We conduct experiments on the public dataset of the answer selection chal- lenge in SemEval 2015. This dataset consists of three subsets: training, development, and test sets, and contains 3,229 questions with 21,062 answer- s. The answers falls into three classes: Good, Bad, and Potential, accounting for 51%, 39%, and 10% respectively. The statistics of the dataset are sum- marized in <ref type="table">Table 1</ref>, where #question/answer de- notes the number of questions/answers, and length stands for the average number of answers for a question.</p><p>Competitor Methods: We compare our approach against the following competitor methods: SVM ( <ref type="bibr" target="#b7">Huang et al., 2007)</ref>: An SVM-based method with bag-of-words (textual features), non- textual features, and features based on topic model (i.e., latent Dirichlet allocation, LDA).</p><p>CRF ( <ref type="bibr" target="#b1">Ding et al., 2008)</ref>: A CRF-based method using the same features as the SVM approach. DBN ( <ref type="bibr" target="#b19">Wang et al., 2010)</ref>: Taking bag-of-words representation, the method applies deep belief net- s to learning the distributed representation of QA pair, and predicts the class of answers using a lo- gistic regression classifier on the top layer. mDBN ( <ref type="bibr" target="#b5">Hu et al., 2013)</ref>: In contrast to DBN, multimodal DBN learns the joint representations of textual features and non-textual features rather than bag-of-words.</p><p>CNN: Using word embedding, the CNNs based model in <ref type="bibr" target="#b6">Hu et al. (2014)</ref> is used to learn the rep- resentations of questions and answers, and a logis- tic regression classifier is used to predict the class of answers. Evaluation Metrics: The evaluation metric- s include M acro − precision(P ), M acro − recall(R), M acro − F 1(F 1), and F 1 scores of the individual classes. According to the evalua- tion results on the development set, all the hyper- parameters are optimized on the training set. Model Architecture and Training Details: The CNNs of our model for QA joint representation learning have 3 hidden layers for modeling ques- tion and answer sentence respectively, in which each layer has 100 feature maps for convolution and pooling operators. The window sizes of con- volution for each layer are [1 × 1, 2 × 2, 2 × 2], the window sizes of pooling are [2 × 2, 2 × 2, 1 × 1]. For the LSTM unit, the size of input gate is set to 200, the sizes of forget gate, output gate, and memory cell are all set to 360.</p><p>Stochastic gradient descent (SGD) algorithm vi- a back-propagation through time is used to train the model. To prevent serious overfitting, early stopping and dropout <ref type="bibr" target="#b3">(Hinton et al., 2012</ref>  during the training procedure. The learning rate λ is initialized to be 0.01 and is updated dynam- ically according to the gradient descent using the ADADELTA method <ref type="bibr" target="#b22">(Zeiler, 2012)</ref>. The activa- tion functions (σ, γ) in our model adopt the rec- tified linear unit (ReLU) ( <ref type="bibr" target="#b0">Dahl et al., 2013</ref>). In addition, the word embeddings for encoding sen- tences are pre-trained with the unsupervised neu- ral language model ( <ref type="bibr" target="#b11">Mikolov et al., 2013</ref>) on the Qatar Living data 2 . <ref type="table" target="#tab_3">Table 2</ref> summarizes the Macro-averaged results. The F1 scores of the individual classes are present- ed in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Analysis</head><p>It is clear to see that the proposed R-CNN ap- proach outperforms the competitor methods over the Macro-averaged metrics as expected from Ta- ble 2. The main reason lies in that R-CNN takes advantages of the semantic correlations between successive answers by LSTM, in addition to the semantic relationships between question and an- swer. The joint representation of QA pair learnt by CNNs also captures richer matching patterns between question and answer than other methods.</p><p>It is notable that the methods based on deep learning perform more powerful than SVM and CRF, especially for complicate answers (e.g., Po- tential answers). In contrast, SVM and CRF using a large amount of features perform better for the answers that have obvious tendency (e.g., Good and Bad answers). The main reason is that the distributed representation learnt from deep learn- ing architecture is able to capture the semantic re- lationships between question and answer. On the other hand, the feature-engineers in both SVM and CRF suffer from noisy information of CQA and the feature sparse problem for short questions and answers.   The improvement achieved by R-CNN over C- NN demonstrates that answer sequence learning is able to improve the performance of the answer se- lection in CQA. Because modeling the answer se- quence can enjoy the advantage of the shared rep- resentation between successive answers, and com- plement the classification features with the learn- t useful context from previous answers. Further- more, memory cell and gates in LSTM unit modify the valuable context to pass onwards by updating the state of RNN during the learning procedure.</p><p>The main improvement of R-CNN against with the competitor methods comes from the Potential answers, which are much less than other two type of answers. It demonstrates that R-CNN is able to process the unbalance data. In fact, the Potential answers are most difficult to identify among the three types of answers as Potential is an intermedi- ate category <ref type="bibr">(M` arquez et al., 2015)</ref>. Nevertheless, R-CNN achieves the highest F1 score of 15.22% on Potential answers. In CQA, Q&amp;A archives usu- ally form one multi-parties conversation when the asker gives feedbacks (e.g., "ok" and "please") to users responses, indicating that the answers of one question are sematic related. Thus, it is easy to un- derstand that R-CNN performs better performance than competitor methods, especially on the recal- l. The reason is that R-CNN can model semantic correlations between successive answers to learn the context and the long range dependencies in the answer sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we propose an answer sequence learning model R-CNN for the answer selection task by integrating LSTM unit and CNNs. Based on the recurrent architecture of our model, our ap- proach is able to model the semantic link between successive answers, in addition to the semantic rel- evance between question and answer. Experimen- tal results demonstrate that our approach can learn the useful context from the answer sequence to im- prove the performance of answer selection in C- QA.</p><p>In the future, we plan to explore the method- s on training the unbalance data to improve the overall performances of our approach. Based on this work, more research can be conducted on topic recognition and semantic roles labeling for human-human conversations in real-world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An Example of the Answer Sequence for a Question. The dashed arrows depict the relationships of the answers in the sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1</head><label></label><figDesc>Figure 2: The architecture of R-CNN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CNNs for QA joint learning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 :</head><label>3</label><figDesc>F1 scores for the individual classes(%) Compared to DBN and mDBN, CNN and R- CNN show their superiority in modeling QA pair. The convolutional sentence models, used in CN- N and R-CNN, can learn the hierarchical struc- ture of language object by deep convolution and pooling operators. In addition, both R-CNN and CNN encode the sentence into one tensor, which makes sure the representation contains more se- mantic features than the bag-of-words representa- tion in DBN and mDBN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>) are proposed to learn the distribut- ed representation of question-answer pair directly. One disadvantage of these approaches lies in that * * Corresponding author Hi. anyone can suggest a good tailor shop (preferably Philippine nationality) in Qatar? i heard there's one over at Al Saad. just not sure the details... thanks! There are a lot of tailor shops, it depends on what you want! Sterling Tailors in Barwa Village, it is run by indians and sri lankans but service is good. I've seen some filipinos who are taking orders from them. Just Check it out... thanks. will def check 'em out... Oh my...they now sell Filipinos? Is there anything they don't sell? Well, apart from Guitar Hero... there's always a place for improvement. lol,.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Macro-averaged results(%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> http://alt.qcri.org/semeval2015/task3/index.php?id=dataand-tools</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Improving deep neural networks for lvcsr using rectified linear units and dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8609" to="8613" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using conditional random fields to extract contexts and answers of questions from online forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Chin Yew Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08</title>
		<meeting>ACL-08</meeting>
		<imprint>
			<publisher>HLT</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Generating sequences with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<idno>abs/1308.0850</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<idno>abs/1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Ruslan Salakhutdinov</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Gradient flow in recurrent nets: the difficulty of learning long-term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multimodal dbn for predicting high-quality answers in cqa portals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Extracting chatbot knowledge from online discussion forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07</title>
		<meeting>the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="423" to="428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding similar questions in large question and answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Jiwoon Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joon Ho</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Information and Knowledge Management, CIKM &apos;05</title>
		<meeting>the 14th ACM International Conference on Information and Knowledge Management, CIKM &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno>abs/1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 3: Answer selection in community question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randeree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>SemEval-2015</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting syntactic and shallow semantic kernels for question answer classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Quarteroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="776" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evaluating and predicting answer quality in community qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chirag</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jefferey</forename><surname>Pomerantz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;10</title>
		<meeting>the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Unsupervised learning of video representations using lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elman</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>ab- s/1502.04681</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Sequence to sequence learning with neural networks. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno>abs/1409.3215</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting chinese question-answer pairs from online forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Systems, Man, and Cybernetics (SMC)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1159" to="1164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A syntactic tree matching approach to finding similar questions in community-based qa services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyan</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09</title>
		<meeting>the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling semantic relevance for question-answer pairs in web social communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1230" to="1238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Retrieval models for question and answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwoon</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;08</title>
		<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Deep learning for answer sentence selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
		<idno>abs/1412.1632</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Phrase-based translation model for question retrieval in community question answer archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="653" to="662" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
