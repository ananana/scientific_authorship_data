<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-Target Stance Classification with Self-Attention Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Marsfield</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cécile</forename><surname>Paris</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Marsfield</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Nepal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Marsfield</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Sparks</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">CSIRO Data61</orgName>
								<address>
									<settlement>Marsfield</settlement>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-Target Stance Classification with Self-Attention Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="778" to="783"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>778</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In stance classification, the target on which the stance is made defines the boundary of the task, and a classifier is usually trained for prediction on the same target. In this work, we explore the potential for generalizing classifiers between different targets, and propose a neural model that can apply what has been learned from a source target to a destination target. We show that our model can find useful information shared between relevant targets which improves generalization in certain scenarios.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stance classification is the task of automatically identifying users' positions about a specific target from text ( <ref type="bibr" target="#b10">Mohammad et al., 2017)</ref>. <ref type="table">Table 1</ref> shows an example of this task, where the stance of the sentence is recognized as favorable on the target climate change is concern. Traditionally, this task is approached by learning a target-specific classi- fier that is trained for prediction on the same tar- get of interest <ref type="bibr" target="#b4">(Hasan and Ng, 2013;</ref><ref type="bibr" target="#b9">Mohammad et al., 2016;</ref><ref type="bibr" target="#b2">Ebrahimi et al., 2016)</ref>. This implies that a new classifier has to be built from scratch on a well-prepared set of ground-truth data whenever predictions are needed for an unseen target.</p><p>An alternative to this approach is to conduct a cross-target classification, where the classifier is adapted from different but related targets ( <ref type="bibr" target="#b0">Augenstein et al., 2016)</ref>, which allows benefiting from the knowledge of existing targets. For ex- ample, in our project we are interested in online users' stances on the approvals of particular min- ing projects in the country. It might be useful to start with a classifier that is adapted from a related target such as climate change is concern (presum- ably available and annotated), as in both cases Sentence: We need to protect our islands and stop the destruction of coral reef.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target: Climate Change is Concern</head><p>Stance: Favor <ref type="table">Table 1</ref>: An example of stance classification task.</p><p>users could discuss the impacts from the targets to some common issues, such as the environment or communities.</p><p>Cross-target stance classification is a more chal- lenging task simply because the language models may not be compatible between different targets. However, for some targets that can be recognized as being related to the same and more general do- mains, it could be possible to generalize through certain aspects of the domains that reflect users' major concerns. For example, from the following sentence, whose stance is against the approval of a mining project, "Environmentalists warn the $16 billion coal facility will damage the Great Barrier Reef", it can be seen that both this sentence and the one in <ref type="table">Table 1</ref> mention the same aspect "reef destruction/damage", which is closely related to the "environment" domain.</p><p>In this paper, we focus on cross-target stance classification and explore the limits of generaliz- ing models between different but domain-related targets <ref type="bibr">1</ref> . The basic idea is to learn a set of domain- specific aspects from a source target, and then apply them to prediction on a destination target. To this end, we propose CrossNet, a novel neu- ral model that implements the above idea based on the self-attention mechanism. Our preliminary analysis shows that the proposed model can find useful domain-specific information from a stance- bearing sentence and that the classification perfor- mance is improved in certain domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>In this section, we introduce the proposed model, CrossNet, for cross-target stance classification. <ref type="figure" target="#fig_0">Figure 1</ref> shows the architecture of CrossNet. It consists of four layers from the Embedding Layer (bottom) to the Prediction Layer (top). It works by taking a stance-bearing sentence and a target as input and yielding the predicted stance label as output. In the following, we present the imple- mentation of each layer in CrossNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Embedding Layer</head><p>There are two inputs in CrossNet: a stance-bearing sentence P and a descriptive target T (e.g, cli- mate change is concern in <ref type="table">Table 1</ref>). We use word embeddings ( <ref type="bibr" target="#b8">Mikolov et al., 2013</ref>) to represent each word in the input as a dense vector. The output of this layer are two sequences of vectors P = {p 1 , ..., p |P | } and T = {t 1 , ..., t |T | }, where p, t are word vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Context Encoding Layer</head><p>In this layer, we encode the contextual informa- tion in the input sentence and target. We use a bi-directional Long Short-Term Memory Network (BiLSTM) <ref type="bibr" target="#b5">(Hochreiter and Schmidhuber, 1997</ref>) to capture the left and right contexts of each word in the input. Moreover, to account for the impact of the target on stance inference, we borrow the idea of conditional encoding ( <ref type="bibr" target="#b0">Augenstein et al., 2016)</ref> to model the dependency of the sentence on the target. Formally, we first use a BiLSTM T to en- code the target:</p><formula xml:id="formula_0">[ − → h T i − → c T i ] = − −−− → LSTM T (t i , − → h T i−1 , − → c T i−1 ) [ ← − h T i ← − c T i ] = ← −−− − LSTM T (t i , ← − h T i+1 , ← − c T i+1 )<label>(1)</label></formula><p>where h ∈ R h and c ∈ R h are the hidden state and cell state of LSTM. The symbol − →(← −) indicates the forward (backward) pass. t i is the input word vector at time step i.</p><p>Then, we learn a conditional encoding of the sentence P , by initializing BiLSTM P (a different BiLSTM) with the final states of BiLSTM T :</p><formula xml:id="formula_1">[ − → h P 1 − → c P 1 ] = − −−− → LSTM P (p 1 , − → h T |T | , − → c T |T | ) [ ← − h P |P | ← − c P |P | ] = ← −−− − LSTM P (p |P | , ← − h T 1 , ← − c T 1 )<label>(2)</label></formula><p>It can be seen that the initialization is done by aligning the forward (backward) pass of the two BiLSTMs. The output is a contextually-encoded sequence,</p><formula xml:id="formula_2">H P = {h P 1 , ..., h P |P | }, where h = [ − → h ; ← − h ] ∈ R 2h with [; ]</formula><p>as the vector concatena- tion operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Aspect Attention Layer</head><p>In this layer, we implement the idea of discover- ing domain-specific aspects for cross-target stance inference. In particular, the key observation we make is that the domain aspects that reflect users' major concerns are usually the core of understand- ing their stances, and could be mentioned by mul- tiple users in a discussion. For example, we find that many users in our corpus mention the aspect "reef" to express their concerns about the impact of a mining project on the Great Barrier Reef. Based on this observation, the perception of the domain aspects can be boiled down to finding the sentence parts that not only carry the core idea of a stance-bearing sentence but also tend to be recur- ring in the corpus.</p><p>First, to capture the recurrences of the domain aspects, a simple way is to make every input sen- tence be consumed by this layer (see <ref type="figure" target="#fig_0">Figure 1</ref>), so that the layer parameters are shared across the cor- pus for being stimulated by all appearances of the domain aspects.</p><p>Then, we utilize self-attention to signal the core parts of a stance-bearing sentence. Self-attention is an attention mechanism for selecting specific parts of a sequence by relating its elements at different positions ( <ref type="bibr">Vaswani et al., 2017;</ref><ref type="bibr" target="#b1">Cheng et al., 2016</ref>). In our case, the self-attention pro- cess is based on the assumption that the core parts of a sentence are those that are compatible with the semantics of the entire sentence. To this end, we introduce a compatibility function to score the semantic compatibility between the encoded se-quence H P and each of its hidden states h P :</p><formula xml:id="formula_3">c i = w 2 σ(W 1 h P i + b 1 ) + b 2<label>(3)</label></formula><p>where</p><formula xml:id="formula_4">W 1 ∈ R d×2h , w 2 ∈ R d , b 1 ∈ R d</formula><p>, and b 2 ∈ R are trainable parameters, and σ is the activation function. Note that all the above parameters are shared by every hidden state in H P . Next, we compute the attention weight a i for each h P i based on its compatibility score via softmax operation:</p><formula xml:id="formula_5">a i = exp(c i ) |P | j=1 exp(c j )<label>(4)</label></formula><p>Finally, we can obtain the domain aspect encoded representation based on the attention weights:</p><formula xml:id="formula_6">A P = |P | i=1 a i h P i<label>(5)</label></formula><p>where A P ∈ R 2h is the domain aspect encoding for sentence P and also the output of this layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Prediction Layer</head><p>We predict the stance label of the sentence based on its domain aspect encoding:</p><formula xml:id="formula_7">ˆ y = softmax(MLP(A P ))<label>(6)</label></formula><p>where we use a multilayer perceptron (MLP) to consume the domain aspect encoding A P and ap- ply the softmax to get the predicted probability for each of the C classes, ˆ y = {y 1 , ..., y C }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Model Training</head><p>For model training, we use multi-class cross- entropy loss,</p><formula xml:id="formula_8">J (θ) = − N i C j y (i) j logˆylogˆ logˆy (i) j + λΘ (7)</formula><p>where N is the size of training set. y is the ground- truth label indicator for each class, andˆyandˆ andˆy is the predicted probability. λ is the coefficient for L 2 - regularization. Θ denotes the set of all trainable parameters in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>This section reports the results of quantitative and qualitative evaluations of the proposed model.   <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Tweets on an Australian mining project (AM): the second is our collection of tweets on a mining project in Australia obtained using Twitter API. It includes 220,067 tweets posted from January 2016 to June 2017 that contain the project name in the text. We remove all URL-only tweets and dupli- cate tweets, and obtain a set of 40,852 (unlabeled) tweets. Due to the lack of annotation, this dataset is only used for our qualitative evaluation.</p><p>To align with our scenario, the above targets can be categorized into three different domains: Women's Rights (FM, LA), American Politics (HC, DT), and Environments (CC, AM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metric</head><p>We use F1-score to measure the classification performance. Due to the imbalanced class dis- tributions of the SemEval dataset, we com- pute both micro-averaged (large classes dominate) and macro-averaged (small classes dominate) F1- scores ( <ref type="bibr" target="#b7">Manning et al., 2008)</ref>, and use their aver- age as the metric, i.e., F = 1 2 (F micro + F macro ). To evaluate the effectiveness of target adapta- tion, we use the metric transfer ratio <ref type="bibr" target="#b3">(Glorot et al., 2011</ref>) to compare the cross-target and in-target performance of a model:</p><formula xml:id="formula_9">Q = F (S,D) F b (D,D)</formula><p>, where F (S, D) is the cross-target F1-score of a model trained on the source target S and tested on the destination target D, and F b (D, D) is the in-target F1-score of a baseline model trained and tested on the same target D, which serves as the perfor- mance calibration for target adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training setup</head><p>The word embeddings are initialized with the pre- trained 200d GloVe word vectors on the 27B Twit- ter corpus ( <ref type="bibr" target="#b11">Pennington et al., 2014)</ref>, and fixed dur- ing training. The model is trained (90%) and val- idated (10%) on a source target, and tested on a destination target. The following model set- tings are selected based on a small grid search on the validation set: the LSTM hidden size of 60, the MLP layer size of 60, and dropout 0.1. The L2-regularization coefficient λ in the loss is 0.01. ADAM ( <ref type="bibr" target="#b6">Kingma and Ba, 2014</ref>) is used as the op- timizer, with a learning rate of 10 −3 . Stratified 10-fold cross-validation is conducted to produce averaged results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Classification Performance</head><p>This section reports the results of our model and two baseline approaches on cross-target stance classification. BiLSTM: this is a base model for our task. It has two BiLSTMs for encoding the sentence and tar- get separately. Then, the concatenation of the re- sulting encodings is fed into the final Prediction Layer to generate predicted stance labels. In our evaluation, this model is treated as the baseline model for deriving the in-target performance cali- bration F b (D, D). MITRE ( <ref type="bibr" target="#b0">Augenstein et al., 2016)</ref>  <ref type="table">Table 3</ref>: Classification performance of our model and other baselines on 4 targets: Feminist Move- ment (FM), Hillary Clinton (HC), Legalization of Abortion (LA), and Donald Trump (DT).</p><p>best system in SemEval-2016 Task 6. It uti- lizes the conditional encoding to learn a target- dependent representation for the input sentence. The conditional encoding is realized in the same way as the Context Encoding Layer does in our model, namely by using the hidden states of the target-encoding BiLSTM to initialize the sentence-encoding BiLSTM. <ref type="table">Table 3</ref> shows the results (in-target and cross- target) on the two domains: Women's Rights and American Politics. First, it is observed that MITRE outperforms BiLSTM over all target con- figurations, suggesting that, compared to simple concatenation, the conditional encoding of the tar- get information could be more helpful to capture the dependency of the sentence on the target. Second, our model is shown to achieve better results than the two baselines in almost all cases (only slightly worse than MITRE on LA under the in-target setting, and the difference is not statis- tically significant), which implies that the aspect attention mechanism adopted in our model could benefit target-level generalization while it does not hurt the in-target performance. Moreover, by com- paring the performance of our model under differ- ent target configurations, we see that the improve- ments brought by our model are more significant on the cross-target task than they are on the in- target task, with an average improvement of 6.6% (cross-target) vs. 3.0% (in-target) over MITRE in F1-score, which demonstrates a greater advantage of our model in the cross-target task.</p><p>Finally, according to the transfer ratio results, the general drop from the in-target to cross-target performance (26% averaged over all cases) could imply that while the target-independent informa- tion (i.e., the domain-specific aspects) is shown to benefit generalization, it could be important to also consider the information that is specific to the des- tination target for model building (which has not yet been explored in this work).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Visualization of Attention</head><p>To show that our model can select sentence parts that are related to domain aspects, we visualize the self-attention results on some tweet examples that are correctly classified by our model in <ref type="table" target="#tab_3">Table 4</ref>.</p><p>We can see that the most highlighted parts in each example are relevant to the respective do- main. For example, "feminist", "rights", and "equality" are commonly used when talking about women's rights, and "president" and "dreams" of-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ID Target Tweet</head><p>1 FM→LA Abortion has nothing to do with feminism . Its about the BABYS body , not yours. <ref type="table">(A)</ref> 2 LA→FM All humans , male and female, should have equal political , economic and social rights . Equality . <ref type="figure">(</ref>   ten appear in text about politics. It is also interest- ing to note that words that are specific to the des- tination target may not be captured by the model learned from the source target, such as "abortion" in sentence 1 and "trumps" in sentence 3. This makes sense because those words are rare in the source target corpus and thus not well noticed by the model. Finally, for our project, we can see from the last two sentences that the model learned from climate change is concern is able to concentrate on words that are central to understanding the authors' stances on the approval of the mining project, such as "reef", "destroy", "environmen- tal", and "disaster". Overall, the above visual- ization demonstrates that our model could bene- fit stance inference across related targets through capturing domain-specific information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Learned Domain-Specific Aspects</head><p>Finally, it is also possible to show the learned do- main aspects by extracting all sentence parts in a corpus that are highly attended by our model. <ref type="table" target="#tab_4">Table 5</ref> presents a number of samples from the intersections between the sets of highly-attended words on the respective targets in the three do- mains. Again, we see that these highly-attended words are specific to the respective domains. We also notice that besides the domain-aspect words, our model can find words that carry sentiments as well, such as "great", "crazy", and "beautiful", which contribute to stance prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>In this work, we study cross-target stance clas- sification and propose a novel self-attention neu- ral model that can extract target-independent in- formation for model generalization. Experimental results show that the proposed model can perceive high-level domain-specific information in a sen- tence and achieves superior results over a number of baselines in certain domains. In the future, there are several ways of extending our model. First, selecting the effective source targets to generalize from is crucial for achieving satisfying results on the destination targets. One possibil- ity could be to learn certain correlations between target closeness and generalization performance, which could further be used for guiding the target selection process. Second, our current model for identifying users' stances on mining projects only generalizes from one source target (i.e., Climate Change is Concern). However, a mining project in general could affect other aspects of our soci- ety such as community and economics. It could be useful to also consider other related sources for knowledge transfer. Finally, it would be in- teresting to evaluate our model in a multilingual scenario <ref type="bibr" target="#b12">(Taulé et al., 2017)</ref>, in order to examine its generalization ability (whether it can attend to useful domain-specific information in a new lan- guage) and multilingual scope.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Architecture of CrossNet.</figDesc><graphic url="image-1.png" coords="2,76.82,62.81,208.64,172.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>F) 3 HC→DT Trumps presidential dreams r about as real as KimJonguns unicorns. (A) 4 DT→HC Maybe a woman should be President . (F) 5 CC→AM [N] still will destroy the reef . It is criminal that QLD federal govts are promoting it. (A) 6 CC→AM [N] , who are trying to change our laws , 'forgot' to tell us about their CEO's environmental disaster ! (A)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>SemEval-2016 Task 6 Tweet Stance De-
tection dataset used in our evaluation. 

3.1 Datasets 

SemEval-2016: the first dataset is from SemEval-
2016 Task 6 on Twitter stance detection, which 
contains stance-bearing tweets on different targets. 
We use the following five targets for our experi-
ments: Climate Change is Concern (CC), Feminist 
Movement (FM), Hillary Clinton (HC), Legaliza-
tion of Abortion (LA), and Donald Trump (DT). 
The class labels are favor, against, and neither, 
and their distributions are shown in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>: this is the</head><label></label><figDesc></figDesc><table>Domain 
Target 
BiLSTM MITRE CrossNet 

In-target performance (F1-score) 

Women's 
FM 
51.4(2.6)  *  53.7(3.9) 55.9(4.6) 
Rights 
LA 
59.4(6.4) 61.9(6.3) 61.8(4.7) 
American 
HC 
55.5(4.7)  *  56.0(3.1)  *  60.0(3.3) 
Politics 
DT 
57.9(6.0)  *  59.6(5.8)  *  60.2(5.1) 

Cross-target performance (F1-score) 

Women's FM→LA 40.1(2.3)  *  40.3(2.2)  *  44.2(1.3) 
Rights 
LA→FM 37.9(2.9)  *  39.2(1.5)  *  43.1(1.3) 
American HC→DT 43.3(2.4)  *  44.2(3.2) 46.1(3.7) 
Politics 
DT→HC 40.1(2.6) 40.8(2.2) 41.8(3.2) 

Transfer ratio 

Women's FM→LA 
0.67 
0.67 
0.74 
Rights 
LA→FM 
0.74 
0.76 
0.83 
American HC→DT 
0.75 
0.76 
0.79 
Politics 
DT→HC 
0.72 
0.73 
0.75 

(Standard deviation in parentheses) 
 *  Improvements over baselines at p &lt;.05 with paired t-test 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>The heatmap of the attention weights assigned by the Aspect Attention Layer to the tweets with 
stance labels favor (F) and against (A). "[N]" denotes the mining project's name of interest. 

Domain 
Sample 
Women's 
Rights 
(FM↔LA) 

feminist, victim, fight, equality, 
children, women, mom, great, love, 
fight, beautiful, girl, housewife, 
wrong, fear, safe, good, life, crime 
American 
Politics 
(HC↔DT) 

american, winning, welfare, obama, 
society, wall, crazy, money, repub-
lican, nation, great, vote, amazing, 
stupid, justice, government, future 
Environments 
(CC→AM) 

environment, reverse, needs, bad, 
weather, solution, important, rain, 
earth, generation, humans, power, 
heat, future, strategy, together, idea 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Samples of the learned domain aspects.</figDesc><table></table></figure>

			<note place="foot" n="1"> In this work, the source target is chosen based on common sense. Exploring more sophisticated source target selection methods will be our future work.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank all anonymous reviewers for their valu-able comments. We would also like to thank Keith Vander Linden for his helpful comments on drafts of this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stance detection with bidirectional conditional encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
	<note>Andreas Vlachos, and Kalina Bontcheva</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Long short-term memory-networks for machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="551" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Weakly supervised tweet stance classification by relational bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javid</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1012" to="1017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning (ICML)</title>
		<meeting>the 28th international conference on machine learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stance classification of ideological debates: Data, models, features, and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Joint Conference on Natural Language Processing</title>
		<meeting>the 6th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge university press</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 6: Detecting stance in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Dan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval@ NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="31" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Stance and sentiment in tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parinaz</forename><surname>Saif M Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiritchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Internet Technology (TOIT)</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Overview of the task on stance and gender detection in tweets on catalan independence at ibereval 2017</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariona</forename><surname>Taulé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Evaluation of Human Language Technologies for Iberian Languages</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1881</biblScope>
			<biblScope unit="page" from="157" to="177" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
