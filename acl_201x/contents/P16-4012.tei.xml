<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">OpenDial: A Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Lison</surname></persName>
							<email>plison@ifi.uio.no</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Language Technology Group University of Oslo</orgName>
								<orgName type="institution">Boise State University</orgName>
								<address>
									<country>Norway), USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Kennington</surname></persName>
							<email>casey.kennington@cs.boisestate.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Language Technology Group University of Oslo</orgName>
								<orgName type="institution">Boise State University</orgName>
								<address>
									<country>Norway), USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">OpenDial: A Toolkit for Developing Spoken Dialogue Systems with Probabilistic Rules</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="67" to="72"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new release of OpenDial, an open-source toolkit for building and evaluating spoken dialogue systems. The toolkit relies on an information-state architecture where the dialogue state is represented as a Bayesian network and acts as a shared memory for all system modules. The domain models are specified via prob-abilistic rules encoded in XML. Open-Dial has been deployed in several application domains such as human-robot interaction , intelligent tutoring systems and multi-modal in-car driver assistants.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent advent of voice-controlled personal as- sistants (such as Siri, Cortana or Alexa) has pop- ularised the use of speech as a means for interfac- ing with everyday devices. These dialogue sys- tems are built on complex architectures that in- clude components such as speech recognition, lan- guage understanding, dialogue management, gen- eration, speech synthesis, situation awareness and multi-modal inputs/outputs. To allow developers to abstract from implementation details and fo- cus on high-level domain modelling, a number of software frameworks have been developed to glue together these components, such as Olym- pus/Ravenclaw ( <ref type="bibr" target="#b1">Bohus and Rudnicky, 2009)</ref>, the AT&amp;T Statistical Dialog toolkit ( <ref type="bibr" target="#b8">Williams et al., 2010)</ref>, InproTK ( <ref type="bibr" target="#b0">Baumann and Schlangen, 2012)</ref> or IrisTK ( <ref type="bibr" target="#b7">Skantze and Al Moubayed, 2012)</ref>.</p><p>Existing frameworks can be grouped in two cat- egories. On the one hand, symbolic frameworks rely on finite-state automata or logical methods to represent and reason over the current dialogue * The present work was conducted while the author was affiliated to CITEC, Bielefeld University (Germany).</p><p>state. While they provide fine-grained control over the dialogue, these approaches are often poor at handling errors and uncertainty. On the other hand, statistical frameworks capture the interac- tion dynamics in a probabilistic manner and seek to optimise the dialogue behaviour from data. However, these methods typically require large amounts of data, making them difficult to apply in domains for which dialogue data is scarce.</p><p>In this paper, we present a new release of Open- Dial 1 , a Java-based, open-source software toolkit designed to facilitate the development of spoken dialogue systems in domains such as personal as- sistants, in-car driving interfaces, intelligent tutor- ing systems, or even autonomous robots. Open- Dial adopts a hybrid approach that combines the benefits of logical and statistical methods to di- alogue modelling into a single framework. The toolkit relies on probabilistic rules to represent the internal models of the domain (i.e. the probabil- ity and utility models employed to update the dia- logue state and make decisions) in a compact and human-readable format. Crucially, the probabilis- tic rules can contain unknown parameters that can be efficiently estimated from dialogue data using supervised or reinforcement learning. This paper is structured as follows. Section 2 presents the toolkit architecture and Section 3 ex- plains how to specify dialogue domains with prob- abilistic rules. Section 4 reviews the toolkit's im- plementation and Section 5 its deployment in sev- eral application domains. Finally, Sections 6 and 7 relate OpenDial with other frameworks and sum- marise the key contributions of the toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture</head><p>OpenDial relies on a information-state architec- ture <ref type="bibr" target="#b4">(Larsson and Traum, 2000</ref>) in which all com-  ponents work together on a shared memory that represents the current dialogue state. This dia- logue state is factored into distinct variables, each representing a particular aspect of the interaction (e.g. the user intention, the dialogue history or the external context). The dialogue state is encoded as a Bayesian network, which is a directed graphi- cal model where the nodes represent the state vari- ables and the edges are conditional dependencies.</p><p>The key benefit of this probabilistic representation of the dialogue state is the ability to capture uncer- tainties and partially observable variables, which are commonplace in most dialogue domains. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the general architecture. The dialogue system is composed of a set of compo- nents which are continuously monitoring the di- alogue state for relevant changes. When such a change occurs, the corresponding modules can re- act to such events and further modify the dialogue state, thereby generating new updates. A typical information flow starts with the speech recogniser, which periodically outputs recognition hypothe- ses u u . <ref type="bibr">2</ref> Language understanding maps these hy- potheses into representations of the dialogue act a u expressed by the user. Dialogue management then selects the system action a m to perform. If the selected action is a communicative act, lan- guage generation is triggered to find its linguistic realisation, denoted u m . Finally, the constructed utterance is sent to the speech synthesiser.</p><p>OpenDial provides two ways to integrate new components into a dialogue system. The first is to specify a model, which is a collection of prob- abilistic rules (see next section). Each model is associated with one or more trigger variables, i.e. variables that trigger the instantiation of the rules upon their update. Alternatively, one can also implement an external module from scratch and connect it to the dialogue state. OpenDial pro- vides a Java API to easily integrate such external modules, which may either wait for update events from the dialogue state or run asynchronously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dialogue domains</head><p>OpenDial is fully domain-independent. To apply it to a particular domain, the system developer pro- vides a specification of the dialogue domain en- coded in XML. This XML file contains the fol- lowing information:</p><p>1. The initial dialogue state;</p><p>2. A collection of domain models, which are themselves composed of probabilistic rules;</p><p>3. Prior distributions for unknown parameters in the probabilistic rules (if any);</p><p>4. Optional configuration settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Probabilistic rules</head><p>The probabilistic rules in the domain models are expressed as if...then...else constructions that map logical conditions on some state variables to prob- abilistic effects on some other state variables. Due to space constraints, we only provide here a brief overview of the formalism, the reader is invited to consult Lison (2015) for more details. The rule conditions are expressed as logical for- mulae, using the usual logic operators (conjunc- tions, disjunctions, and negations) and various bi- nary relations (equality, inequalities, string match- ing, etc.). The conditions may also include under- specified (i.e. free) variables which are universally quantified on the top of the rule. Each condition is associated with a distribution over mutually exclu- sive effects, where each effect is an assignment of values to some state variable(s). Here is a simple example of probabilistic rule:</p><formula xml:id="formula_0">∀x, if (a u = Request(x) ∧ a m = Verify(x)) then P (a u = Confirm(x)) = 0.9</formula><p>The rule expresses a prediction on the future user dialogue act a u based on the last user dialogue act a u and system's action a m . The rule stipulates that if the user requested some x and the system replied by asking whether the request is indeed x, the user is expected to comply and confirm their request with probability 0.9. A void effect with no pre- diction is implicitly associated with the remaining probability mass (0.1 here). The universal quan- tification on x indicates that this probability is in- dependent of the type of user request.</p><p>The if...then...else structure of the probabilistic rules partitions the state space into groups of simi- lar states (corresponding to the logical conditions). In particular, the sequential ordering of the con- ditions enable dialogue developers to write rules with "backoff strategies", starting from the most specific conditions and then gradually moving to more generic cases if the top conditions do not apply. Such partitioning of the state space is im- portant to ensure the probabilistic rules are able to generalise to new, unseen situations.</p><p>Probabilistic rules can express both conditional probability distributions and utility functions. At runtime, the rules are instantiated as latent nodes in the Bayesian network representing the dialogue state. The rules can therefore be seen as high-level templates for the construction of directed graph- ical models <ref type="bibr" target="#b6">(Lison, 2015)</ref>. The latest release of OpenDial offers several new functionalities such as the support for custom functions and the ability to directly manipulate relational structures -such as dependency trees, semantic graphs or hierarchi- cal task networks -in the probabilistic rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Example</head><p>Listing 1 provides a simple example of dialogue domain in XML. The domain specifies the be- haviour of a elevator that can move between three floors through a voice-controlled interface. The interaction starts with a system prompt ("Which floor do you want? ") followed by the user request (e.g. "third floor, please"). If the request is un- certain, the elevator should ask the user to confirm (e.g. "Do you want the third floor? ").</p><p>The domain contains an initial state with one variable (the initial prompt) and three models: an intent recognition model mapping the user utter- ance u u to the corresponding dialogue act a u , an action selection model encoding the utility of the system actions a m , and a third model responsible for generating the system responses u m and pre- dicting the next user act a u . Each model is as- sociated with a trigger variable and is composed of a set of probabilistic rules. The rules are writ- &lt;domain&gt; &lt;initialstate&gt; &lt;variable id="u m"&gt; &lt;value prob="1"&gt;Which floor do you want?&lt;/value&gt; &lt;/variable&gt; &lt;/initialstate&gt; &lt;!−− Intent recognition −−&gt; &lt;model trigger="u u"&gt; &lt;rule&gt; &lt;case&gt; &lt;condition operator="and"&gt; &lt;if var="X" relation="in" value="[first,second,third]"/&gt; &lt;if var="u u" relation="contains" value="{X} (floor)?"/&gt; &lt;/condition&gt; &lt;effect prob="1"&gt; &lt;set var="a u" value="Request({X})"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;case&gt; &lt;condition operator="and"&gt; &lt;if var="u u" relation="contains" value="(yes|exactly)"/&gt; &lt;if var="a m" relation="=" value="Verify({X})"/&gt; &lt;/condition&gt; &lt;effect prob="1"&gt; &lt;set var="a u" value="Confirm({X})"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;/rule&gt; &lt;/model&gt; &lt;!−− Action selection model −−&gt; &lt;model trigger="a u"&gt; &lt;rule&gt; &lt;case&gt; &lt;condition operator="or"&gt; &lt;if var="a u" relation="=" value="Request({X})"/&gt; &lt;if var="a u" relation="=" value="Confirm({X})"/&gt; &lt;/condition&gt; &lt;effect util="1"&gt; &lt;set var="a m" value="GoTo({X})"/&gt; &lt;/effect&gt; &lt;effect util="0.5"&gt; &lt;set var="a m" value="Verify({X})"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;case&gt; &lt;effect util="−2"&gt; &lt;set var="a m" value="GoTo({X})"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;/rule&gt; &lt;/model&gt; &lt;!−− Generation and user action models −−&gt; &lt;model trigger="a m"&gt; &lt;rule&gt; &lt;case&gt; &lt;condition&gt; &lt;if var="a m" relation="=" value="GoTo({X})"/&gt; &lt;/condition&gt; &lt;effect util="1"&gt; &lt;set var="u m" value="Ok, going to the {X} floor"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;case&gt; &lt;condition&gt; &lt;if var="a m" relation="=" value="Verify({X})"/&gt; &lt;/condition&gt; &lt;effect util="1"&gt; &lt;set var="u m" value="Do you want the {X} floor?"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;/rule&gt; &lt;rule&gt; &lt;case&gt; &lt;condition operator="and"&gt; &lt;if var="a m" relation="=" value="Verify({X})"/&gt; &lt;if var="a u" relation="=" value="Request({X})"/&gt; &lt;/condition&gt; &lt;effect prob="0.9"&gt; &lt;set var="a uˆp" value="Confirm({X})"/&gt; &lt;/effect&gt; &lt;/case&gt; &lt;/rule&gt; &lt;/model&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;/domain&gt;</head><p>Listing 1: Dialogue domain example in XML. ten as sequences of if-then-else cases, where each case has a (possibly void) condition and a set of corresponding effects. Curly brackets such as {X} denote underspecified variables.</p><p>Intent recognition contains one single rule which maps utterances matching the pattern "x (floor)? " where x ∈ ["first", "second","third"] to the dialogue act <ref type="bibr">Request(x)</ref>, and maps the re- sponses "yes" or "exactly" following the system action <ref type="bibr">Verify(x)</ref> to the dialogue act <ref type="bibr">Confirm(x)</ref>. This rule is deterministic, since all its effects have a probability 1 if their condition is met. A default value is assigned to a u if no condition applies.</p><p>The action selection model expresses the utility of two system actions: GoTo(x), representing the action of moving to the floor x, and the clarifica- tion Verify(x). The two actions respectively have a utility of 1 and 0.5 if the last user act is <ref type="bibr">Request(x)</ref> or Confirm(x). Otherwise, the action <ref type="bibr">GoTo(x)</ref> has a negative utility of -2. The action <ref type="bibr">GoTo(x)</ref> will therefore be selected if the probability of the user act Request(x) is higher than 0.8, while <ref type="bibr">Verify(x)</ref> will be chosen if this probability is lower.</p><p>The generation model simply maps the sys- tem actions to their corresponding surface realisa- tions. <ref type="bibr">3</ref> Finally, the prediction model (correspond- ing to the example in the previous section) states that the probability of the user confirming their re- quest when asked to do so is set to 0.9.</p><p>The example could of course be extended in many ways -for instance by explicitly specifying the current floor as state variable, and providing prior distributions on the floor requested by the user, conditioned on the current one. The user guide on the OpenDial website provides several additional examples of dialogue domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><p>The probabilistic rules in the example were associ- ated with fixed probabilities or utilities. However, in most domains, these values are difficult to de- termine in advance and are best learned from em- pirical data. The toolkit allows dialogue develop- ers to estimate unknown parameters via Bayesian learning. In practice, this is done by replacing the probability or utility values in the rules by pa- rameters associated with prior distributions. For instance, the utilities 1, 0.5 and -2 in the action selection model can be replaced by three Gaus-sians representing the spread of possible utility values, and the probability 0.9 in the prediction rule can be replaced by a Dirichlet expressing the prior belief about the user response. System de- velopers can then exploit dialogue data to auto- matically learn the posterior distributions for these parameters. Two methods have been developed: supervised learning from Wizard-of-Oz data <ref type="bibr" target="#b6">(Lison, 2015</ref>) and reinforcement learning from real or simulated experience <ref type="bibr" target="#b5">(Lison, 2013)</ref>. Both learning methods assume that the rule structure -the map- ping between conditions and effects -is provided by the developer, while the numerical parameters are determined via statistical estimation. Indeed, system developers often have a good grasp of the general structure of the dialogue domain but are typically unable to quantify the precise probabil- ity of a prediction or utility of an action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation</head><p>OpenDial is implemented in Java and is released under an open-source MIT license. The software comes along with a graphical user interface which allows developers to run a given dialogue domain and test its behaviour in an interactive manner. Three views are available in the interface. The "chat window" view, shown in <ref type="figure">Figure 2(a)</ref>, dis- plays the dialogue history and let the user en- ter new (text or speech) inputs. In the "dialogue monitor" view, shown in <ref type="figure">Figure 2(b)</ref>, the user can inspect the Bayesian network representing the current dialogue state, perform various inference queries (e.g. calculating marginal distributions), and look at previous state updates. This last fea- ture is particularly useful for debugging. Finally, the "domain editor" view provides an interactive editor for the XML domain file.</p><p>To ensure the system can quickly react to new events, most processes operate in anytime mode, which implies they can be gracefully interrupted and deliver their outputs at any time. Both exact and approximate inference are employed to update the dialogue state and plan system actions.</p><p>A collection of plugins extends the toolkit with additional modules. Plugins are notably available to connect OpenDial to Nuance and AT&amp;T cloud- based speech APIs, to the MaltParser for data- driven dependency parsing, the Sphinx speech recogniser and the MARY speech synthesiser. <ref type="bibr">4</ref> (a) Chat window (b) Dialogue state monitor <ref type="figure">Figure 2</ref>: Graphical user interface for OpenDial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Application Domains</head><p>OpenDial has been deployed in several applica- tion domains, either directly as an end-to-end di- alogue system, or as a specific component in a larger software architecture, typically to handle di- alogue state tracking and management tasks.</p><p>An important application domain is human- robot interaction. <ref type="bibr" target="#b6">Lison (2015)</ref> illustrates how OpenDial is used in a human-robot interaction do- main where a humanoid robot is instructed to navi- gate through a simple environment, fetch an object and bring it to a particular landmark. The exper- iment shows in particular how the parameters of probabilistic rules can be efficiently learned from limited amounts of Wizard-of-Oz data.</p><p>OpenDial was used in another human-robot interaction domain with multiple human partic- ipants.  describe how OpenDial was employed as the primary dialogue manager in a twenty-questions game scenario be- tween a robot and up to three human participants. Using Wizard-of-Oz data, the parameters were es- timated with the toolkit's training regime. Dur- ing evaluation, multiple instantiations of Open- Dial were used to model the interaction with each participant. Even though the instantiations were mutually independent, all shared the same modules, allowing communication between them when turn-taking decisions needed to be made.</p><p>OpenDial was also deployed as a dialogue man- ager in an in-car dialogue scenario ( <ref type="bibr" target="#b3">Kousidis et al., 2014</ref>). The objective was to deliver upcom- ing calendar entries to the driver (e.g. "on Tues- day you have lunch with John at the cafeteria") http://www.maltparser.org and http://mary.dfki.de. via speech and the toolkit was employed to deter- mine when the speech should be interrupted. The driver could also indicate to the system via speech or a head nod that the interrupted speech should continue. Information from the simulated driving environment (see <ref type="figure" target="#fig_1">Figure 3</ref>) was used to make the system "situationally aware" and able to react to dangerous events by interrupting speech, allowing the driver to focus on the primary task of driving. OpenDial was employed to dynamically track the state of the dialogue system over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The purpose of OpenDial is to combine the expres- sivity of logic-based frameworks with the robust- ness and adaptivity of statistical systems. In line with logic-based frameworks <ref type="bibr" target="#b4">(Larsson and Traum, 2000;</ref><ref type="bibr" target="#b1">Bohus and Rudnicky, 2009)</ref>, the toolkit pro- vides system developers with powerful abstrac- tions to structure the domain models, since proba- bilistic rules can make use of complex logical for- mulae and universal quantification. And in line with statistical approaches ( <ref type="bibr" target="#b9">Young et al., 2013)</ref>, OpenDial is also able to explicitly handle uncer- tain knowledge and stochastic relations between variables thanks to its probabilistic representation of the dialogue state and its ability to estimate un- known parameters from data.</p><p>The presented framework is very general and can be employed to design a wide spectrum of models, from traditional handcrafted models (such as finite-state automata) on one extreme to prob- abilistic models fully estimated from data on the other extreme. The choice of model within this spectrum boils down to a design decision based on the relative availabilities of training data and do- main knowledge. Furthermore, OpenDial enables users to quickly develop a working system with little or no data, then gradually extend and refine their models as more data becomes available.</p><p>The primary focus of OpenDial is on high- level processes such as language understanding, dialogue management and generation. Com- pared to frameworks such as IrisTK (Skantze and Al Moubayed, 2012) or InproTK ( <ref type="bibr" target="#b0">Baumann and Schlangen, 2012)</ref>, OpenDial offers more limited support for lower-level interaction control such as attentional behaviours or turn-taking strategies. How to reconcile the "low-level" and "high-level" aspects of dialogue modelling in a principled man- ner is an important question for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a new release of OpenDial, a Java- based toolkit for developing and evaluating spo- ken dialogue systems. The toolkit rests on a hy- brid modelling framework that seeks to combine the benefits of logical and probabilistic approaches to dialogue. The dialogue state is represented as a Bayesian network, and the domain models are specified using probabilistic rules. Unknown rule parameters can be automatically estimated from dialogue data using Bayesian learning.</p><p>OpenDial is in our view particularly well-suited to handle dialogue domains that exhibits both a complex state-action space and high levels of noise and uncertainty. Typical examples of such dialogue domains are human-robot interaction, virtual assistants and tutoring systems. These do- mains must often deal with state-action spaces that include multiple tasks to perform in rich interac- tion contexts. They are also confronted with sub- stantial levels of uncertainty, arising from speech recognition errors and partially observable envi- ronments. Due its hybrid modelling approach, the toolkit is able to capture such dialogue domains in a relatively small set of probabilistic rules and associated parameters, allowing them to be tuned from modest amounts of training data, which is a critical requirement in many applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source code and documentation</head><p>The www.opendial-toolkit.net website presents the release along with the source code and a step-by- step user guide. A screencast is also available at https://www.youtube.com/watch?v=X8x8Qj5Z7Ag.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Information-state architecture for the toolkit, with the dialogue state acting as a central shared memory for all system components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Driver's view from the OpenDS driving simulator [http://www.opends.eu].</figDesc><graphic url="image-3.png" coords="5,324.54,276.93,183.75,103.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>User dialogue act au System action am System utterance um</head><label></label><figDesc></figDesc><table>Dialogue 
state 

Speech 
recognition 

Language 
Understanding 

Dialogue 
management 
Generation 

Speech 
synthesis 

Situation 
awareness 
Extra-verbal 
modalities 

... 

User 
utterance uu 

</table></figure>

			<note place="foot" n="1"> http://www.opendial-toolkit.net</note>

			<note place="foot" n="2"> We denote user-specific variables with the subscript u and machine-specific variables with the subscript m.</note>

			<note place="foot" n="3"> In a real elevator, an external module will of course need to convert the actions GoTo(x) into a physical motion.</note>

			<note place="foot" n="4"> See http://developer.nuance.com, http://developer.att.com/ apis/speech (to be closed), http://cmusphinx.sourceforge.net,</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The InproTK 2012 release</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT Workshop on Future Directions and Needs in the Spoken Dialog Community</title>
		<meeting><address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="29" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The RavenClaw dialog management framework: Architecture and systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="332" to="361" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Probabilistic multiparty dialogue management for a game master robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Funakoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nakano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM/IEEE international conference on Human-robot interaction</title>
		<meeting>the ACM/IEEE international conference on Human-robot interaction</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="200" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Multimodal In-Car Dialogue System That Tracks The Driver&apos;s Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kousidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Buschmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kopp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICMI</title>
		<meeting>ICMI<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information state and dialogue management in the TRINDI dialogue move engine toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="323" to="340" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-based Bayesian reinforcement learning for dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Conference of the International Speech Communication Association</title>
		<meeting>the 14th Annual Conference of the International Speech Communication Association<address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A hybrid approach to dialogue management based on probabilistic rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="232" to="255" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">IrisTK: A statechart-based toolkit for multi-party face-to-face interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Skantze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Al</forename><surname>Moubayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Multimodal Interaction (ICMI 2012)</title>
		<meeting>the 14th International Conference on Multimodal Interaction (ICMI 2012)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Demonstration of AT&amp;T Let&apos;s Go: A productiongrade statistical spoken dialog system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Arizmendi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conkie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the IEEE Spoken Language Technology Workshop</title>
		<meeting>the the IEEE Spoken Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="157" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">POMDP-based statistical spoken dialogue systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
