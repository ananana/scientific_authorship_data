<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Conversations Gone Awry: Detecting Early Signs of Conversational Failure</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">P</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
							<email>cristian@cs.cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><forename type="middle">Thain</forename><surname>Jigsaw</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Taraborelli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Wikimedia Foundation</orgName>
								<orgName type="laboratory">Yiqing Hua Cornell University</orgName>
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Conversations Gone Awry: Detecting Early Signs of Conversational Failure</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1350" to="1361"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1350</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>One of the main challenges online social systems face is the prevalence of antisocial behavior, such as harassment and personal attacks. In this work, we introduce the task of predicting from the very start of a conversation whether it will get out of hand. As opposed to detecting undesirable behavior after the fact, this task aims to enable early, actionable prediction at a time when the conversation might still be salvaged. To this end, we develop a framework for capturing pragmatic devices-such as politeness strategies and rhetorical prompts-used to start a conversation, and analyze their relation to its future trajec-tory. Applying this framework in a controlled setting, we demonstrate the feasibility of detecting early warning signs of antisocial behavior in online discussions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>"Or vedi l'anime di color cui vinse l'ira." <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>-Dante Alighieri, Divina Commedia, Inferno</head><p>Online conversations have a reputation for go- ing awry <ref type="bibr">(Hinds and Mortensen, 2005;</ref><ref type="bibr">Gheitasy et al., 2015)</ref>: antisocial behavior ( <ref type="bibr" target="#b19">Shepherd et al., 2015)</ref> or simple misunderstandings <ref type="bibr">(Churchill and Bly, 2000;</ref><ref type="bibr" target="#b31">Yamashita and Ishida, 2006</ref>) hamper the efforts of even the best intentioned collabo- rators. Prior computational work has focused on characterizing and detecting content exhibiting an- tisocial online behavior: trolling ( <ref type="bibr">Cheng et al., 2015</ref><ref type="bibr">Cheng et al., , 2017</ref>, hate speech ( <ref type="bibr" target="#b27">Warner and Hirschberg, 2012;</ref><ref type="bibr">Davidson et al., 2017</ref>), harassment <ref type="bibr" target="#b32">(Yin et al., 2009</ref>), personal attacks ( <ref type="bibr" target="#b30">Wulczyn et al., 2017</ref>) or, more generally, toxicity <ref type="bibr">(Chandrasekharan et al., 2017;</ref><ref type="bibr" target="#b15">Pavlopoulos et al., 2017b</ref>).</p><p>Our goal is crucially different: instead of identi- fying antisocial comments after the fact, we aim to detect warning signs indicating that a civil conver- sation is at risk of derailing into such undesirable behaviors. Such warning signs could provide po- tentially actionable knowledge at a time when the conversation is still salvageable.</p><p>As a motivating example, consider the pair of conversations in <ref type="figure">Figure 1</ref>. Both exchanges took place in the context of the Wikipedia discussion page for the article on the Dyatlov Pass Incident, and both show (ostensibly) civil disagreement be- tween the participants. However, only one of these conversations will eventually turn awry and de- volve into a personal attack ("Wow, you're com- ing off as a total d**k. <ref type="bibr">[...]</ref> What the hell is wrong with you?"), while the other will remain civil.</p><p>As humans, we have some intuition about which conversation is more likely to derail. <ref type="bibr">2</ref> We may note the repeated, direct questioning with which A1 opens the exchange, and that A2 replies with yet another question. In contrast, B1's softer, hedged approach ("it seems", "I don't think") appears to invite an exchange of ideas, and B2 actually addresses the question instead of stonewalling. Could we endow artificial systems with such intuitions about the future trajectory of conversations?</p><p>In this work we aim to computationally cap- ture linguistic cues that predict a conversation's future health. Most existing conversation mod- eling approaches aim to detect characteristics of an observed discussion or predict the outcome af- ter the discussion concludes-e.g., whether it in- volves a present dispute <ref type="bibr">(Allen et al., 2014;</ref><ref type="bibr" target="#b26">Wang and Cardie, 2014</ref>) or contributes to the even-A1: Why there's no mention of it here? Namely, an altercation with a foreign intelligence group? True, by the standards of sources some require it wouln't even come close, not to men- tion having some really weak points, but it doesn't mean that it doesn't exist.</p><p>A2: So what you're saying is we should put a bad source in the article because it exists? B1: Is the St. Petersberg Times considered a reliable source by wikipedia? It seems that the bulk of this article is coming from that one article, which speculates about missile launches and UFOs. I'm going to go through and try and find corroborating sources and maybe do a rewrite of the article. I don't think this article should rely on one so-so source.</p><p>B2: I would assume that it's as reliable as any other mainstream news source.</p><p>Figure 1: Two examples of initial exchanges from conversations concerning disagreements between editors working on the Wikipedia article about the Dyatlov Pass Incident. Only one of the conversations will eventually turn awry, with an interlocutor launching into a personal attack.</p><p>tual solution of a problem (Niculae and Danescu- Niculescu-Mizil, 2016). In contrast, for this new task we need to discover interactional signals of the future trajectory of an ongoing conversation.</p><p>We make a first approach to this problem by an- alyzing the role of politeness (or lack thereof) in keeping conversations on track. Prior work has shown that politeness can help shape the course of offline <ref type="bibr">(Clark, 1979;</ref><ref type="bibr">Clark and Schunk, 1980)</ref>, as well as online interactions <ref type="bibr">(Burke and Kraut, 2008)</ref>, through mechanisms such as softening the perceived force of a message <ref type="bibr">(Fraser, 1980)</ref>, act- ing as a buffer between conflicting interlocutor goals ( <ref type="bibr">Brown and Levinson, 1987)</ref>, and enabling all parties to save face <ref type="bibr">(Goffman, 1955)</ref>. This sug- gests the potential of politeness to serve as an in- dicator of whether a conversation will sustain its initial civility or eventually derail, and motivates its consideration in the present work.</p><p>Recent studies have computationally opera- tionalized prior formulations of politeness by extracting linguistic cues that reflect politeness strategies <ref type="bibr">(Danescu-Niculescu-Mizil et al., 2013;</ref><ref type="bibr">Aubakirova and Bansal, 2016)</ref>. Such research has additionally tied politeness to social fac- tors such as individual status <ref type="bibr">(Danescu-NiculescuMizil et al., 2012;</ref><ref type="bibr" target="#b5">Krishnan and Eisenstein, 2015)</ref>, and the success of requests ( <ref type="bibr">Althoff et al., 2014)</ref> or of collaborative projects ( <ref type="bibr" target="#b13">Ortu et al., 2015)</ref>. However, to the best of our knowledge, this is the first computational investigation of the relation be- tween politeness strategies and the future trajec- tory of the conversations in which they are de- ployed. Furthermore, we generalize beyond pre- defined politeness strategies by using an unsu- pervised method to discover additional rhetorical prompts used to initiate different types of conver- sations that may be specific to online collaborative settings, such as coordinating work <ref type="bibr" target="#b3">(Kittur and Kraut, 2008)</ref> or conducting factual checks.</p><p>We explore the role of such pragmatic and rhetorical devices in foretelling a particularly per- plexing type of conversational failure: when par- ticipants engaged in previously civil discussion start to attack each other. This type of derailment "from within" is arguably more disruptive than other forms of antisocial behavior, such as vandal- ism or trolling, which the interlocutors have less control over or can choose to ignore.</p><p>We study this phenomenon in a new dataset of Wikipedia talk page discussions, which we com- pile through a combination of machine learning and crowdsourced filtering. The dataset consists of conversations which begin with ostensibly civil comments, and either remain healthy or derail into personal attacks. Starting from this data, we con- struct a setting that mitigates effects which may trivialize the task. In particular, some topical con- texts (such as politics and religion) are naturally more susceptible to antisocial behavior ( <ref type="bibr" target="#b2">Kittur et al., 2009;</ref><ref type="bibr">Cheng et al., 2015)</ref>. We employ tech- niques from causal inference <ref type="bibr" target="#b17">(Rosenbaum, 2010)</ref> to establish a controlled framework that focuses our study on topic-agnostic linguistic cues.</p><p>In this controlled setting, we find that prag- matic cues extracted from the very first exchange in a conversation (i.e., the first comment-reply pair) can indeed provide some signal of whether the conversation will subsequently go awry. For example, conversations prompted by hedged re- marks sustain their initial civility more so than those prompted by forceful questions, or by direct language addressing the other interlocutor.</p><p>In summary, our main contributions are:</p><p>• We articulate the new task of detecting early on whether a conversation will derail into personal attacks;</p><p>• We devise a controlled setting and build a la- beled dataset to study this phenomenon;</p><p>• We investigate how politeness strategies and other rhetorical devices are tied to the future trajectory of a conversation.</p><p>More broadly, we show the feasibility of auto- matically detecting warning signs of future mis- behavior in collaborative interactions. By provid- ing a labeled dataset together with basic method- ology and several baselines, we open the door to further work on understanding factors which may derail or sustain healthy online conversations. To facilitate such future explorations, we distrubute the data and code as part of the Cornell Conversa- tional Analysis Toolkit. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Further Related Work</head><p>Antisocial behavior. Prior work has studied a wide range of disruptive interactions in various on- line platforms like Reddit and Wikipedia, exam- ining behaviors like aggression <ref type="bibr" target="#b1">(Kayany, 1998)</ref>, harassment ( <ref type="bibr">Chatzakou et al., 2017;</ref><ref type="bibr" target="#b25">Vitak et al., 2017)</ref>, and bullying <ref type="bibr" target="#b0">(Akbulut et al., 2010;</ref><ref type="bibr" target="#b7">Kwak et al., 2015;</ref><ref type="bibr" target="#b20">Singh et al., 2017)</ref>, as well as their im- pact on aspects of engagement like user retention <ref type="bibr">(Collier and Bear, 2012;</ref><ref type="bibr">Wikimedia Support and Safety Team, 2015</ref>) or discussion quality ( <ref type="bibr">Arazy et al., 2013)</ref>. Several studies have sought to de- velop machine learning techniques to detect sig- natures of online toxicity, such as personal in- sults ( <ref type="bibr" target="#b32">Yin et al., 2009</ref>), harassment <ref type="bibr" target="#b21">(Sood et al., 2012</ref>) and abusive language ( <ref type="bibr" target="#b12">Nobata et al., 2016;</ref><ref type="bibr">Gambäck and Sikdar, 2017;</ref><ref type="bibr" target="#b14">Pavlopoulos et al., 2017a;</ref><ref type="bibr" target="#b30">Wulczyn et al., 2017</ref>). These works fo- cus on detecting toxic behavior after it has al- ready occurred; a notable exception is <ref type="bibr">Cheng et al. (2017)</ref>, which predicts future community enforce- ment against users in news-based discussions. Our work similarly aims to understand future antiso- cial behavior; however, our focus is on studying the trajectory of a conversation rather than the be- havior of individuals across disparate discussions. Discourse analysis. Our present study builds on a large body of prior work in computationally mod- eling discourse. Both unsupervised ( <ref type="bibr" target="#b16">Ritter et al., 2010</ref>) and supervised ( <ref type="bibr" target="#b33">Zhang et al., 2017a</ref>) ap- proaches have been used to categorize behavioral patterns on the basis of the language that ensues in a conversation, in the particular realm of online discussions. Models of conversational behavior have also been used to predict conversation out- comes, such as betrayal in games (Niculae et al., <ref type="bibr">3</ref> http://convokit.infosci.cornell.edu 2015), and success in team problem solving set- tings ( <ref type="bibr">Fu et al., 2017)</ref> or in persuading others ( <ref type="bibr" target="#b22">Tan et al., 2016;</ref><ref type="bibr" target="#b34">Zhang et al., 2016)</ref>.</p><p>While we are inspired by the techniques em- ployed in these approaches, our work is concerned with predicting the future trajectory of an ongoing conversation as opposed to a post-hoc outcome. In this sense, we build on prior work in modeling conversation trajectory, which has largely consid- ered structural aspects of the conversation ( <ref type="bibr" target="#b6">Kumar et al., 2010;</ref><ref type="bibr">Backstrom et al., 2013</ref>). We comple- ment these structural models by seeking to extract potential signals of future outcomes from the lin- guistic discourse within the conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Finding Conversations Gone Awry</head><p>We develop our framework for understanding lin- guistic markers of conversational trajectories in the context of Wikipedia's talk page discussions- public forums in which contributors convene to deliberate on editing matters such as evaluating the quality of an article and reviewing the com- pliance of contributions with community guide- lines. The dynamic of conversational derailment is particularly intriguing and consequential in this setting by virtue of its collaborative, goal-oriented nature. In contrast to unstructured commenting fo- rums, cases where one collaborator turns on an- other over the course of an initially civil exchange constitute perplexing pathologies. In turn, these toxic attacks are especially disruptive in Wikipedia since they undermine the social fabric of the com- munity as well as the ability of editors to con- tribute <ref type="bibr">(Henner and Sefidari, 2016)</ref>.</p><p>To approach this domain we reconstruct a com- plete view of the conversational process in the edit history of English Wikipedia by translating se- quences of revisions of each talk page into struc- tured conversations. This yields roughly 50 mil- lion conversations across 16 million talk pages.</p><p>Roughly one percent of Wikipedia comments are estimated to exhibit antisocial behavior <ref type="bibr" target="#b30">(Wulczyn et al., 2017)</ref>. This illustrates a challenge for studying conversational failure: one has to sift through many conversations in order to find even a small set of examples. To avoid such a pro- hibitively exhaustive analysis, we first use a ma- chine learning classifier to identify candidate con- versations that are likely to contain a toxic contri- bution, and then use crowdsourcing to vet the re- sulting labels and construct our controlled dataset.</p><p>Job 1: Ends in personal attack. We show three annotators a conversation and ask them to determine if its last comment is a personal attack toward someone else in the conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotators Conversations Agreement 367 4,022 67.8%</head><p>Job 2: Civil start. We split conversations into snip- pets of three consecutive comments. We ask three annotators to determine whether any of the comments in a snippet is toxic.</p><p>Annotators Conversations Snippets Agreement 247 1,252 2,181 87.5% <ref type="table">Table 1</ref>: Descriptions of crowdsourcing jobs, with relevant statistics. More details in Appendix A.</p><formula xml:id="formula_0">Candidate selection.</formula><p>Our goal is to analyze how the start of a civil conversation is tied to its poten- tial future derailment into personal attacks. Thus, we only consider conversations that start out as os- tensibly civil, i.e., where at least the first exchange does not exhibit any toxic behavior, <ref type="bibr">4</ref> and that con- tinue beyond this first exchange. To focus on the especially perplexing cases when the attacks come from within, we seek examples where the attack is initiated by one of the two participants in the ini- tial exchange.</p><p>To select candidate conversations to include in our collection, we use the toxicity classifier pro- vided by the Perspective API, 5 which is trained on Wikipedia talk page comments that have been an- notated by crowdworkers ( <ref type="bibr" target="#b29">Wulczyn et al., 2016)</ref>. This provides a toxicity score t for all comments in our dataset, which we use to preselect two sets of conversations: (a) candidate conversations that are civil throughout, i.e., conversations in which all comments (including the initial exchange) are not labeled as toxic (t &lt; 0.4); and (b) candidate conversations that turn toxic after the first (civil) exchange, i.e., conversations in which the N -th comment (N &gt; 2) is labeled toxic (t ≥ 0.6), but all the preceding comments are not (t &lt; 0.4). Crowdsourced filtering. Starting from these can- didate sets, we use crowdsourcing to vet each con- versation and select a subset that are perceived by humans to either stay civil throughout ("on- track" conversations), or start civil but end with a personal attack ("awry-turning" conversations). To inform the design of this human-filtering pro- cess and to check its effectiveness, we start from a seed set of 232 conversations manually ver- ified by the authors to end in personal attacks (more details about the selection of the seed set and its role in the crowd-sourcing process can be found in Appendix A). We take particular care to not over-constrain crowdworker interpretations of what personal attacks may be, and to separate tox- icity from civil disagreement, which is recognized as a key aspect of effective collaborations <ref type="bibr">(Coser, 1956;</ref><ref type="bibr">De Dreu and Weingart, 2003)</ref>.</p><p>We design and deploy two filtering jobs using the CrowdFlower platform, summarized in <ref type="table">Table 1</ref> and detailed in Appendix A. Job 1 is designed to select conversations that contain a "rude, insulting, or disrespectful" comment towards another user in the conversation-i.e., a personal attack. In con- trast to prior work labeling antisocial comments in isolation ( <ref type="bibr" target="#b21">Sood et al., 2012;</ref><ref type="bibr" target="#b30">Wulczyn et al., 2017)</ref>, annotators are asked to label personal attacks in the context of the conversations in which they oc- cur, since antisocial behavior can often be context- dependent ( <ref type="bibr">Cheng et al., 2017)</ref>. In fact, in order to ensure that the crowdworkers read the entire con- versation, we also ask them to indicate who is the target of the attack. We apply this task to the set of candidate awry-turning conversations, selecting the 14% which all three annotators perceived as ending in a personal attack. <ref type="bibr">6</ref> Job 2 is designed to filter out conversations that do not actually start out as civil. We run this job to ensure that the awry-turning conversations are civil up to the point of the attack-i.e., they turn awry-discarding 5% of the candidates that passed Job 1. We also use it to verify that the candidate on-track conversations are indeed civil throughout, discarding 1% of the respective candi- dates. In both cases we filter out conversations in which three annotators could identify at least one comment that is "rude, insulting, or disrespectful". Controlled setting. Finally, we need to construct a setting that affords for meaningful comparison between conversations that derail and those that stay on track, and that accounts for trivial topical confounds ( <ref type="bibr" target="#b2">Kittur et al., 2009;</ref><ref type="bibr">Cheng et al., 2015)</ref>. We mitigate topical confounds using matching, a technique developed for causal inference in obser- vational studies <ref type="bibr" target="#b18">(Rubin, 2007)</ref>. Specifically, start-ing from our human-vetted collection of conver- sations, we pair each awry-turning conversation, with an on-track conversation, such that both took place on the same talk page. If we find multi- ple such pairs, we only keep the one in which the paired conversations take place closest in time, to tighten the control for topic. Conversations that cannot be paired are discarded.</p><p>This procedure yields a total of 1,270 paired awry-turning and on-track conversations (includ- ing our initial seed set), spanning 582 distinct talk pages (averaging 1.1 pairs per page, maximum 8) and 1,876 (overlapping) topical categories. The average length of a conversation is 4.6 comments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Capturing Pragmatic Devices</head><p>We now describe our framework for capturing lin- guistic cues that might inform a conversation's fu- ture trajectory. Crucially, given our focus on con- versations that start seemingly civil, we do not ex- pect overtly hostile language-such as insults ( <ref type="bibr" target="#b32">Yin et al., 2009</ref>)-to be informative. Instead, we seek to identify pragmatic markers within the initial ex- change of a conversation that might serve to reveal or exacerbate underlying tensions that eventually come to the fore, or conversely suggest sustainable civility. In particular, in this work we explore how politeness strategies and rhetorical prompts reflect the future health of a conversation. Politeness strategies.</p><p>Politeness can reflect a-priori good will and help navigate potentially face-threatening acts <ref type="bibr">(Goffman, 1955;</ref><ref type="bibr" target="#b8">Lakoff, 1973)</ref>, and also offers hints to the underlying in- tentions of the interlocutors <ref type="bibr">(Fraser, 1980)</ref>. Hence, we may naturally expect certain politeness strate- gies to signal that a conversation is likely to stay on track, while others might signal derailment.</p><p>In particular, we consider a set of pragmatic devices signaling politeness drawn from <ref type="bibr">Brown and Levinson (1987)</ref>. These linguistic features re- flect two overarching types of politeness. Posi- tive politeness strategies encourage social connec- tion and rapport, perhaps serving to maintain co- hesion throughout a conversation; such strategies include gratitude ("thanks for your help"), greet- ings ("hey, how is your day so far") and use of "please", both at the start ("Please find sources for your edit...") and in the middle ("Could you please help with...?") of a sentence. Negative politeness strategies serve to dampen an interlocutor's impo- sition on an addressee, often through conveying indirectness or uncertainty on the part of the com- menter. Both commenters in example B <ref type="figure">(Fig. 1)</ref> employ one such strategy, hedging, perhaps seek- ing to soften an impending disagreement about a source's reliability ("I don't think...", "I would assume..."). We also consider markers of impo- lite behavior, such as the use of direct questions ("Why's there no mention of it?') and sentence- initial second person pronouns ("Your sources don't matter..."), which may serve as forceful- sounding contrasts to negative politeness markers. Following Danescu-Niculescu-Mizil et al. <ref type="formula">(2013)</ref>, we extract such strategies by pattern matching on the dependency parses of comments.</p><p>Types of conversation prompts. To complement our pre-defined set of politeness strategies, we seek to capture domain-specific rhetorical patterns used to initiate conversations. For instance, in a collaborative setting, we may expect conversations that start with an invitation for working together to signal less tension between the participants than those that start with statements of dispute. We dis- cover types of such conversation prompts in an un- supervised fashion by extending a framework used to infer the rhetorical role of questions in (offline) political debates ( <ref type="bibr" target="#b35">Zhang et al., 2017b</ref>) to more generally extract the rhetorical functions of com- ments. The procedure follows the intuition that the rhetorical role of a comment is reflected in the type of replies it is likely to elicit. As such, comments which tend to trigger similar replies constitute a particular type of prompt.</p><p>To implement this intuition, we derive two dif- ferent low-rank representations of the common lexical phrasings contained in comments (agnos- tic to the particular topical content discussed), au- tomatically extracted as recurring sets of arcs in the dependency parses of comments. First, we derive reply-vectors of phrasings, which reflect their propensities to co-occur. In particular, we perform singular value decomposition on a term- document matrix R of phrasings and replies as R ≈ ˆ R = U R SV T R , where rows of U R are low- rank reply-vectors for each phrasing.</p><p>Next, we derive prompt-vectors for the phras- ings, which reflect similarities in the subsequent replies that a phrasing prompts. We construct a prompt-reply matrix P = (p ij ) where p ij = 1 if phrasing j occurred in a reply to a comment con- taining phrasing i. We project P into the same space as U R by solving forˆPforˆ forˆP in P = ˆ PSV T R as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompt Type Description Examples</head><p>Factual check Statements about article content, pertaining to or The terms are used interchangeably in the US. contending issues like factual accuracy.</p><p>The census is not talking about families here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moderation</head><p>Rebukes or disputes concerning moderation decisions If you continue, you may be blocked from editing. such as blocks and reversions. He's accused me of being a troll.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coordination</head><p>Requests, questions, and statements of intent It's a long list so I could do with your help. pertaining to collaboratively editing an article.</p><p>Let me know if you agree with this and I'll go ahead <ref type="bibr">[...]</ref> Casual remark Casual, highly conversational aside-remarks. What's with this flag image? I'm surprised there wasn't an article before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action statement Requests, statements, and explanations about</head><p>Please consider improving the article to address the issues [...] various editing actions.</p><p>The page was deleted as self-promotion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Opinion</head><p>Statements seeking or expressing opinions about I think that it should be the other way around. editing challenges and decisions.</p><p>This article seems to have a lot of bias.  <ref type="table">Table 4</ref>.</p><formula xml:id="formula_1">ˆ P = PV R S −1</formula><p>. Each row ofˆPofˆ ofˆP is then a prompt- vector of a phrasing, such that the prompt-vector for phrasing i is close to the reply-vector for phras- ing j if comments with phrasing i tend to prompt replies with phrasing j. Clustering the rows ofˆPofˆ ofˆP then yields k conversational prompt types that are unified by their similarity in the space of replies.</p><p>To infer the prompt type of a new comment, we represent the comment as an average of the repre- sentations of its constituent phrasings (i.e., rows ofˆP ofˆ ofˆP) and assign the resultant vector to a cluster. <ref type="bibr">7</ref> To determine the prompt types of comments in our dataset, we first apply the above procedure to derive a set of prompt types from a disjoint (un- labeled) corpus of Wikipedia talk page conversa- tions <ref type="bibr">(Danescu-Niculescu-Mizil et al., 2012)</ref>. Af- ter initial examination of the framework's output on this external data, we chose to extract k = 6 prompt types, shown in <ref type="table" target="#tab_0">Table 2</ref> along with our in- terpretations. 8 These prompts represent signatures of conversation-starters spanning a wide range of topics and contexts which reflect core elements of Wikipedia, such as moderation disputes and co- ordination ( <ref type="bibr" target="#b4">Kittur et al., 2007;</ref><ref type="bibr" target="#b3">Kittur and Kraut, 2008)</ref>. We assign each comment in our present dataset to one of these types. 9 <ref type="bibr">7</ref> We scale rows of UR andˆPandˆ andˆP to unit norm. We assign comments whose vector representation has (ℓ2) distance ≥ 1 to all cluster centroids to an extra, infrequently-occurring null type which we ignore in subsequent analyses. <ref type="bibr">8</ref> We experimented with more prompt types as well, find- ing that while the methodology recovered finer-grained types, and obtained qualitatively similar results and prediction ac- curacies as described in Sections 5 and 6, the assignment of comments to types was relatively sparse due to the small data size, resulting in a loss of statistical power. <ref type="bibr">9</ref> While the particular prompt types we discover are spe-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>We are now equipped to computationally explore how the pragmatic devices used to start a con- versation can signal its future health. Concretely, to quantify the relative propensity of a linguistic marker to occur at the start of awry-turning ver- sus on-track conversations, we compute the log- odds ratio of the marker occurring in the initial exchange-i.e., in the first or second comments- of awry-turning conversations, compared to initial exchanges in the on-track setting. These quantities are depicted in <ref type="figure">Figure 2A</ref>. <ref type="bibr">10</ref> Focusing on the first comment (represented as ♦s), we find a rough correspondence between linguistic directness and the likelihood of future personal attacks. In particular, comments which contain direct questions, or exhibit sentence- initial you (i.e., "2 nd person start"), tend to start awry-turning conversations significantly more of- ten than ones that stay on track (both p &lt; 0.001). 11 This effect coheres with our intuition that direct- ness signals some latent hostility from the conver- sation's initiator, and perhaps reinforces the force- fulness of contentious impositions <ref type="bibr">(Brown and Levinson, 1987)</ref>. This interpretation is also sug- cific to Wikipedia, the methodology for inferring them is un- supervised and is applicable in other conversational settings. <ref type="bibr">10</ref> To reduce clutter we only depict features which occur a minimum of 50 times and have absolute log-odds ≥ 0.2 in at least one of the data subsets. The markers indicated as statis- tically significant for <ref type="figure">Figure 2A</ref> remain so after a Bonferroni correction, with the exception of factual checks, hedges (lex- icon, ♦), gratitude (♦), and opinion. <ref type="bibr">11</ref> All p values in this section are computed as two-tailed bi- nomial tests, comparing the proportion of awry-turning con- versations exhibiting a particular device to the proportion of on-track conversations.</p><p>Figure 2: Log-odds ratios of politeness strategies and prompt types exhibited in the first and second comments of conversations that turn awry, versus those that stay on-track. All: Purple and green markers denote log-odds ratios in the first and second comments, respectively; points are solid if they reflect significant (p &lt; 0.05) log-odds ratios with an effect size of at least 0.2. A: ♦s and s denote first and second comment log-odds ratios, respectively; * denotes statistically significant differences at the p &lt; 0.05 (*), p &lt; 0.01 (**) and p &lt; 0.001 (***) levels for the first comment (two-tailed binomial test); + denotes corresponding statistical significance for the second comment. B and C: ▽s and ⃝s correspond to effect sizes in the comments authored by the attacker and non-attacker, respectively, in attacker initiated (B) and non-attacker initiated (C) conversations.</p><p>gested by the relative propensity of the factual check prompt, which tends to cue disputes re- garding an article's factual content (p &lt; 0.05).</p><p>In contrast, comments which initiate on-track conversations tend to contain gratitude (p &lt; 0.05) and greetings (p &lt; 0.001), both positive polite- ness strategies. Such conversations are also more likely to begin with coordination prompts (p &lt; 0.05), signaling active efforts to foster constructive teamwork. Negative polite- ness strategies are salient in on-track conversa- tions as well, reflected by the use of hedges (p &lt; 0.01) and opinion prompts (p &lt; 0.05), which may serve to soften impositions or factual contentions <ref type="bibr">(Hübler, 1983)</ref>.</p><p>These effects are echoed in the second comment-i.e., the first reply (represented as s). Interestingly, in this case we note that the difference in pronoun use is especially marked. First replies in conversations that eventually de- rail tend to contain more second person pro- nouns (p &lt; 0.001), perhaps signifying a replier pushing back to contest the initiator; in con- trast, on-track conversations have more sentence- initial I/We (i.e., "1 st person start", p &lt; 0.001), po- tentially indicating the replier's willingness to step into the conversation and work with-rather than argue against-the initiator <ref type="bibr" target="#b23">(Tausczik and Pennebaker, 2010</ref>).</p><p>Distinguishing interlocutor behaviors. Are the linguistic signals we observe solely driven by the eventual attacker, or do they reflect the behavior of both actors? To disentangle the attacker and non- attackers' roles in the initial exchange, we exam- ine their language use in these two possible cases: when the future attacker initiates the conversation, or is the first to reply. In attacker-initiated con- versations ( <ref type="figure">Figure 2B, 608 conversations)</ref>, we see that both actors exhibit a propensity for the lin- guistically direct markers (e.g., direct questions) that tend to signal future attacks. Some of these markers are used particularly often by the non- attacking replier in awry-turning conversations (e.g., second person pronouns, p &lt; 0.001, ⃝s), further suggesting the dynamic of the replier push- ing back at-and perhaps even escalating-the at- tacker's initial hint of aggression. Among conver- sations initiated instead by the non-attacker <ref type="figure">(Fig- ure 2C, 662 conversations)</ref>, the non-attacker's lin- guistic behavior in the first comment (⃝s) is less distinctive from that of initiators in the on-track setting (i.e., log-odds ratios closer to 0); mark- ers of future derailment are (unsurprisingly) more pronounced once the eventual attacker (▽s) joins the conversation in the second comment. <ref type="bibr">12</ref> More broadly, these results reveal how differ- ent politeness strategies and rhetorical prompts de- ployed in the initial stages of a conversation are tied to its future trajectory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Predicting Future Attacks</head><p>We now show that it is indeed feasible to predict whether a conversation will turn awry based on linguistic properties of its very first exchange, pro- viding several baselines for this new task. In do- ing so, we demonstrate that the pragmatic devices examined above encode signals about the future trajectory of conversations, capturing some of the intuition humans are shown to have.</p><p>We consider the following balanced prediction task: given a pair of conversations, which one will eventually lead to a personal attack? We ex- tract all features from the very first exchange in a conversation-i.e., a comment-reply pair, like those illustrated in our introductory example <ref type="figure">(Fig- ure 1)</ref>. We use logistic regression and report ac- curacies on a leave-one-page-out cross validation, such that in each fold, all conversation pairs from a given talk page are held out as test data and pairs from all other pages are used as training data (thus preventing the use of page-specific information). Prediction results are summarized in <ref type="table" target="#tab_2">Table 3</ref>. Language baselines. As baselines, we con- sider several straightforward features: word count (which performs at chance level), sentiment lexi- con ( <ref type="bibr" target="#b9">Liu et al., 2005</ref>) and bag of words. Pragmatic features. Next, we test the predic- tive power of the prompt types and politeness   Interlocutor features: Certain kinds of interlocu- tors are potentially more likely to be involved in awry-turning conversations. For example, perhaps newcomers or anonymous participants are more likely to derail interactions than more experienced editors. We consider a set of features representing participants' experience on Wikipedia (i.e., num- ber of edits) and whether the comment authors are anonymous. In our task, these features perform at the level of random chance.</p><p>Trained toxicity: We also compare with the tox- icity score of the exchange from the Perspective API classifier-a perhaps unfair reference point, since this supervised system was trained on addi- tional human-labeled training examples from the same domain and since it was used to create the very data on which we evaluate. This results in an accuracy of 60.5%; combining trained toxicity with our pragmatic features achieves 64.9%. Humans: A sample of 100 pairs were labeled by (non-author) volunteer human annotators. They were asked to guess, from the initial exchange, which conversation in a pair will lead to a personal attack. Majority vote across three annotators was used to determine the human labels, resulting in an accuracy of 72%. This confirms that humans have some intuition about whether a conversation might be heading in a bad direction, which our features can partially capture. In fact, the classifier using pragmatic features is accurate on 80% of the ex- amples that humans also got right.</p><p>Attacks on the horizon. Finally, we seek to un- derstand whether cues extracted from the first ex- change can predict future discussion trajectory be- yond the immediate next couple of comments. We thus repeat the prediction experiments on the sub- set of conversations in which the first personal at- tack happens after the fourth comment (282 pairs), and find that the pragmatic devices used in the first exchange maintain their predictive power (67.4% accuracy), while the sentiment and bag of words baselines drop to the level of random chance. Overall, these initial results show the feasibil- ity of reconstructing some of the human intuition about the future trajectory of an ostensibly civil conversation in order to predict whether it will eventually turn awry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>In this work, we started to examine the intriguing phenomenon of conversational derailment, study- ing how the use of pragmatic and rhetorical de- vices relates to future conversational failure. Our investigation centers on the particularly perplex- ing scenario in which one participant of a civil discussion later attacks another, and explores the new task of predicting whether an initially healthy conversation will derail into such an attack. To this end, we develop a computational framework for analyzing how general politeness strategies and domain-specific rhetorical prompts deployed in the initial stages of a conversation are tied to its future trajectory.</p><p>Making use of machine learning and crowd- sourcing tools, we formulate a tightly-controlled setting that enables us to meaningfully compare conversations that stay on track with those that go awry. The human accuracy on predicting future at- tacks in this setting (72%) suggests it is feasible at least at the level of human intuition. We show that our computational framework can recover some of that intuition, hinting at the potential of automated methods to identify signals of the future trajecto- ries of online conversations.</p><p>Our approach has several limitations which open avenues for future work. Our correlational analyses do not provide any insights into causal mechanisms of derailment, which randomized ex- periments could address. Additionally, since our procedure for collecting and vetting data focused on precision rather than recall, it might miss more subtle attacks that are overlooked by the toxicity classifier. Supplementing our investigation with other indicators of antisocial behavior, such as ed- itors blocking one another, could enrich the range of attacks we study. Noting that our framework is not specifically tied to Wikipedia, it would also be valuable to explore the varied ways in which this phenomenon arises in other (possibly non- collaborative) public discussion venues, such as Reddit and Facebook Pages.</p><p>While our analysis focused on the very first ex- change in a conversation for the sake of general- ity, more complex modeling could extend its scope to account for conversational features that more comprehensively span the interaction. Beyond the present binary classification task, one could ex- plore a sequential formulation predicting whether the next turn is likely to be an attack as a discus- sion unfolds, capturing conversational dynamics such as sustained escalation.</p><p>Finally, our study of derailment offers only one glimpse into the space of possible conversa- tional trajectories. Indeed, a manual investiga- tion of conversations whose eventual trajectories were misclassified by our models-as well as by the human annotators-suggests that interactions which initially seem prone to attacks can nonethe- less maintain civility, by way of level-headed in- terlocutors, as well as explicit acts of reparation. A promising line of future work could consider the complementary problem of identifying pragmatic strategies that can help bring uncivil conversations back on track.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Feature</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Prompt types automatically extracted from talk page conversations, with interpretations and examples from the data. Bolded text indicate common prompt phrasings extracted by the framework. Further examples are shown in Appendix B,</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Accuracies for the balanced future-
prediction task. Features based on pragmatic de-
vices are bolded, reference points are italicized. 

strategies features introduced in Section 4. The 
12 prompt type features (6 features for each com-
ment in the initial exchange) achieve 59.2% accu-
racy, and the 38 politeness strategies features (19 
per comment) achieve 60.5% accuracy. The prag-
matic features combine to reach 61.6% accuracy. 
Reference points. To better contextualize the per-
formance of our features, we compare their pre-
dictive accuracy to the following reference points: 
</table></figure>

			<note place="foot" n="2"> In fact, humans achieve an accuracy of 72% on this balanced task, showing that it is feasible, but far from trivial.</note>

			<note place="foot" n="4"> For the sake of generality, in this work we focus on this most basic conversational unit: the first comment-reply pair starting a conversation. 5 https://www.perspectiveapi.com/</note>

			<note place="foot" n="6"> We opted to use unanimity in this task to account for the highly subjective nature of the phenomenon.</note>

			<note place="foot" n="12"> As an interesting avenue for future work, we note that some markers used by non-attacking initiators potentially still anticipate later attacks, suggested by, e.g., the relative prevalence of sentence-initial you (p &lt; 0.05, ⃝s).</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cyberbullying victimization among Turkish online social utility members</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yavuz</forename><surname>Akbulut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuf</forename><surname>Levent Sahin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bahadir</forename><surname>Eristi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Technology &amp; Society</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contexts of uninhibited online behavior: Flaming in social newsgroups on usenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joseph M Kayany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What&apos;s in Wikipedia?: Mapping topics and conflict using socially annotated category structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongwon</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Harnessing the wisdom of crowds in Wikipedia: Quality through coordination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Kraut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CSCW</title>
		<meeting>CSCW</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">He says, she says: Conflict and coordination in Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Kittur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongwon</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ed</forename><forename type="middle">H</forename><surname>Bryan A Pendleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">You&apos;re Mr. Lebowski, I&apos;m the Dude&quot;: Inducing address term formality in signed social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodh</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamics of conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Mcglohon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploring cyberbullying and other toxic behavior in team competition online games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haewoon</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungyeop</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The logic of politeness: Minding your P&apos;s and Q&apos;s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Robin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Chicago Linguistic Society</title>
		<meeting>the Chicago Linguistic Society</meeting>
		<imprint>
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Opinion observer: Analyzing and comparing opinions on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsheng</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Conversational markers of constructive discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistic harbingers of betrayal: A case study on an online strategy game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srijan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Abusive language detection in online user content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chikashi</forename><surname>Nobata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achint</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Are bullies more productive? Empirical study of affectiveness vs. issue fixing time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ortu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Destefanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parastou</forename><surname>Tourani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Marchesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Tonelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of MSR</title>
		<meeting>MSR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning for user comment moderation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Abusive Language Online</title>
		<meeting>the Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deeper attention to abusive user content moderation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prodromos Malakasiotis, and Ion Androutsopoulos</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised modeling of Twitter conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Design of observational studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul R Rosenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The design versus the analysis of observational studies for causal effects: Parallels with the design of randomized trials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donald B Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Shepherd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Srauy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Miltner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Histories of hating. Social Media + Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">They basically like destroyed the school one day&quot;: On newer app features and cyberbullying in schools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vivek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><forename type="middle">L</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianjia</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Furrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CSCW</title>
		<meeting>CSCW</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic identification of personal insults on social news sites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><forename type="middle">Owsley</forename><surname>Sood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">F</forename><surname>Churchill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judd</forename><surname>Antin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescuniculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: LIWC and computerized text analysis methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Thats Bullshit&quot;-Rude Enough for Removal? A Multi-Mod Perspective. Change My View Blog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kal</forename><surname>Turnbull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Identifying women&apos;s experiences with and strategies for mitigating negative effects of online harassment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Vitak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyani</forename><surname>Chadha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Ashktorab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CSCW</title>
		<meeting>CSCW</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A piece of my mind: A sentiment analysis approach for online dispute detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detecting hate speech on the World Wide Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Warner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Language in Social Media</title>
		<meeting>the Workshop on Language in Social Media</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wikimedia Support and Safety Team</title>
	</analytic>
	<monogr>
		<title level="m">Wikimedia Foundation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Harassment survey</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<title level="m">Wikipedia talk labels: Toxicity</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Ex machina: Personal attacks seen at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic prediction of misconceptions in multilingual computer-mediated communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Ishida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IUI</title>
		<meeting>IUI</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Detection of harassment on Web 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhen</forename><surname>Dawei Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjie</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">April</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynne</forename><surname>Kontostathis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Content Analysis</title>
		<meeting>the Workshop on Content Analysis</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>in the Web 2.0</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Characterizing online discussion using coarse discourse sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Amy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Culbertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paritosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Conversational flow in Oxford-style debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Asking too much? The rhetorical role of questions in political discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justine</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Spirling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescuniculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
