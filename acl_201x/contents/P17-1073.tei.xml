<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Polish evaluation dataset for compositional distributional semantics models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Wróblewska</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katarzyna</forename><surname>Krasnowska-Kieraś</surname></persName>
						</author>
						<title level="a" type="main">Polish evaluation dataset for compositional distributional semantics models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="784" to="792"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1073</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The paper presents a procedure of building an evaluation dataset 1. for the validation of compositional distributional semantics models estimated for languages other than English. The procedure generally builds on steps designed to assemble the SICK corpus, which contains pairs of English sentences annotated for semantic related-ness and entailment, because we aim at building a comparable dataset. However, the implementation of particular building steps significantly differs from the original SICK design assumptions, which is caused by both lack of necessary extraneous resources for an investigated language and the need for language-specific transformation rules. The designed procedure is verified on Polish, a fusional language with a relatively free word order, and contributes to building a Polish evaluation dataset. The resource consists of 10K sentence pairs which are human-annotated for semantic relatedness and entailment. The dataset may be used for the evaluation of compositional distributional semantics models of Polish.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.1 Distributional semantics</head><p>The basic idea of distributional semantics, i.e. de- termining the meaning of a word based on its co-occurrence with other words, is derived from the empiricists -Harris <ref type="bibr">(1954)</ref> and <ref type="bibr" target="#b7">Firth (1957)</ref>. John R. Firth drew attention to the context- dependent nature of meaning especially with his <ref type="bibr">1</ref> The dataset is obtainable at: http://zil.ipipan.waw.pl/Scwad/CDSCorpus famous maxim "You shall know a word by the company it keeps" <ref type="bibr">(Firth, 1957, p. 11)</ref>.</p><p>Nowadays, distributional semantics models are estimated with various methods, e.g. word em- bedding techniques ( <ref type="bibr" target="#b3">Bengio et al., 2003</ref><ref type="bibr" target="#b4">Bengio et al., , 2006</ref><ref type="bibr" target="#b15">Mikolov et al., 2013)</ref>. To ascertain the purport of a word, e.g. bath, you can use the context of other words that surround it. If we assume that the meaning of this word expressed by its lexical context is associated with a distributional vector, the distance between distributional vectors of two semantically similar words, e.g bath and shower, should be smaller than between vectors represent- ing semantically distinct words, e.g. bath and tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Compositional distributional semantics</head><p>Based on empirical observations that distribu- tional vectors encode certain aspects of word meaning, it is expected that similar aspects of the meaning of phrases and sentences can also be represented with vectors obtained via composi- tion of distributional word vectors. The idea of se- mantic composition is not new. It is well known as the principle of compositionality: 2 "The mean- ing of a compound expression is a function of the meaning of its parts and of the way they are syntactically combined." <ref type="bibr">(Janssen, 2012, p. 19)</ref>.</p><p>Modelling the meaning of textual units larger than words using compositional and distribu- tional information is the main subject of compo- sitional distributional semantics <ref type="bibr" target="#b16">(Mitchell and Lapata, 2010;</ref><ref type="bibr" target="#b2">Baroni and Zamparelli, 2010;</ref><ref type="bibr" target="#b9">Grefenstette and Sadrzadeh, 2011;</ref><ref type="bibr" target="#b19">Socher et al., 2012</ref>, to name a few studies). The fundamental principles of compositional distributional semantics, hence- forth referred to as CDS, are mainly propagated with papers written on the topic. Apart from the papers, it was the SemEval-2014 Shared Task 1 ) that essentially contributed to the expansion of CDS and increased an interest in this domain. The goal of the task was to evaluate CDS models of English in terms of semantic relat- edness and entailment on proper sentences from the SICK corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">The SICK corpus</head><p>The SICK corpus ( ) con- sists of 10K pairs of English sentences contain- ing multiple lexical, syntactic, and semantic phe- nomena. It builds on two external data sources -the 8K ImageFlickr dataset ( <ref type="bibr" target="#b17">Rashtchian et al., 2010)</ref> and SemEval-2012 Semantic Textual Simi- larity dataset <ref type="bibr" target="#b0">(Agirre et al., 2012)</ref>. Each sentence pair is human-annotated for relatedness in mean- ing and entailment.</p><p>The relatedness score corresponds to the degree of semantic relatedness between two sentences and is calculated as the average of ten human rat- ings collected for this sentence pair on the 5-point Likert scale. This score indicates the extent to which the meanings of two sentences are related.</p><p>The entailment relation between two sentences, in turn, is labelled with entailment, contradic- tion, or neutral. According to the SICK guidelines, the label assigned by the majority of human anno- tators is selected as the valid entailment label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Motivation and organisation of the paper</head><p>Studying approaches to various natural language processing (henceforth NLP) problems, we have observed that the availability of language re- sources (e.g. training or testing data) stimulates the development of NLP tools and the estimation of NLP models. English is undoubtedly the most prominent in this regard and English resources are the most numerous. Therefore, NLP methods are mostly designed for English and tested on English data, even if there is no guarantee that they are universal. In order to verify whether an NLP al- gorithm is adequate, it is not enough to evaluate it solely for English. It is also valuable to have high-quality resources for languages typologically different to English. Hence, we aim at building datasets for the evaluation of CDS models in lan- guages other than English, which are often under- resourced. We strongly believe that the availability of test data will encourage development of CDS models in these languages and allow to better test the universality of CDS methods.</p><p>We start with a high-quality dataset for Pol- ish, which is a completely different language than English in at least two dimensions. First, it is a rather under-resourced language in contrast to the resource-rich English. Second, it is a fusional language with a relatively free word order in con- trast to the isolated English with a relatively fixed word order. If some heuristics is tested on e.g. Pol- ish, the evaluation results can be approximately generalised to other Slavic languages. We hope the Slavic NLP community will be interested in de- signing and evaluating methods of semantic mod- elling for Slavic languages.</p><p>The procedure of building an evaluation dataset for validating compositional distributional seman- tics models of Polish generally builds on steps de- signed to assemble the SICK corpus (described in Section 1.3) because we aim at building an eval- uation dataset which is comparable to the SICK corpus. However, the implementation of particular building steps significantly differs from the orig- inal SICK design assumptions, which is caused by both lack of necessary extraneous resources for Polish (see Section 2.1) and the need for Polish-specific transformation rules (see Section 2.2). Furthermore, the rules of arranging sentences into pairs (see Section 2.3) are defined anew tak- ing into account the characteristic of data and bi- directional entailment annotations, since an entail- ment relation between two sentences must not be symmetric. Even if our assumptions of annotating sentence pairs coincide with the SICK principles to a certain extent (see Section 3.1), the annotation process differs from the SICK procedure, in par- ticular by introducing an element of human verifi- cation of correctness of automatically transformed sentences (see Section 3.2) and some additional post-corrections (see Section 3.3). Finally, a sum- mary of the dataset is provided in Section 4.1 and the dataset evaluation is given in Section 4.2.</p><p>2 Procedure of collecting data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Selection and description of images</head><p>The first step of building the SICK corpus con- sisted in the random selection of English sentence pairs from existing datasets ( <ref type="bibr" target="#b17">Rashtchian et al., 2010;</ref><ref type="bibr" target="#b0">Agirre et al., 2012</ref>). Since we are not aware of accessibility of analogous resources for Polish, we have to select images first and then describe the selected images.</p><p>Images are selected from the 8K ImageFlickr dataset ( <ref type="bibr" target="#b17">Rashtchian et al., 2010)</ref>. At first we wanted to take only these images the descriptions of which were selected for the SICK corpus. How- ever, a cursory check shows that these images are quite homogeneous, with a predominant number of dogs depictions. Therefore, we independently extract 1K images and split them into 46 thematic groups (e.g. children, musical instruments, mo- torbikes, football, dogs). The numbers of images within individual thematic groups vary from 6 im- ages in the volleyball and telephoning groups to 94 images in the various people group. The sec- ond largest groups are children and dogs with 50 images each. The chosen images are given to two authors who independently of each other formulate their descriptions based on a short instruction. The au- thors are instructed to write one single sentence (with a sentence predicate) describing the ac- tion in a displayed image. They should not de- scribe an imaginable context or an interpretation of what may lie behind the scene in the picture. If some details in the picture are not obvious, they should not be described either. Furthermore, the authors should avoid multiword expressions, such as idioms, metaphors, and named entities, because those are not compositional linguistic phenomena. Finally, descriptions should contain Polish diacrit- ics and proper punctuation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Transformation of descriptions</head><p>The second step of building the SICK corpus consisted in pre-processing extracted sentences, i.e. normalisation and expansion <ref type="bibr">(Bentivogli et al., 2014, p. 3-4)</ref>. Since the authors of Polish descrip- tions are asked to follow the guidelines (presented in Section 2.1), the normalisation step is not essen- tial for our data. The expansion step, in turn, is im- plemented and the sentences provided by the au- thors are lexically and syntactically transformed in order to obtain derivative sentences with sim- ilar, contrastive, or neutral meanings. The follow- ing transformations are implemented:</p><p>1. dropping conjunction concerns sentences with coordinated predicates sharing a sub- ject, e.g. Rowerzysta odpoczywa i obserwuje morze. (Eng. 'A cyclist is resting and watch- ing the sea.'). The finite form of one of the co- ordinated predicates is transformed into:</p><p>• an active adjectival participle, e.g. Odpoczywaj ˛ acy rowerzysta obserwuje morze. (Eng. 'A resting cyclist is watch- ing the sea.') or Obserwuj ˛ acy morze rowerzysta odpoczywa. (Eng. 'A cyclist, who is watching the sea, is resting.'),</p><p>• a contemporary adverbial participle, e.g. Rowerzysta, odpoczywaj ˛ ac, obser- wuje morze. (Eng. 'A cyclist is watch- ing the sea, while resting.') or Row- erzysta odpoczywa, obserwuj ˛ ac morze. (Eng. 'A cyclist is resting, while watch- ing the sea.').</p><p>2. removing conjunct in adjuncts, i.e. the dele- tion of one of coordinated elements of an ad- junct, e.g. Mały, ale zwinny kot miauczy. 7. constrained mixing of dependents from var- ious sentences, e.g. Dwoje dzieci siedzi na wielbł ˛ adach w pobli˙ zu wysokich gór. (Eng. 'Two children are sitting on camels near high mountains.') can be changed into Dwoje dzieci siedzi przy zastawionym stole w pobli˙ zu wysokich gór. (Eng. 'Two children are sitting at the table laid with food near high mountains.').</p><p>The first five transformations are designed to pro- duce sentences with a similar meaning, the sixth transformation outputs sentences with a contra- dictory meaning, and the seventh transformation should generate sentences with a neutral (or unre- lated) meaning. All transformations are performed on the dependency structures of input sentences <ref type="bibr" target="#b20">(Wróblewska, 2014)</ref>.</p><p>Some of the transformations are very produc- tive (e.g. mixing dependents). Other, in turn, are sparsely represented in the output (e.g. dropping conjunction). The number of transformed sen- tences randomly selected to build the dataset is in the second column of  <ref type="table" target="#tab_1">Table 1</ref>: Numbers of transformed sentences se- lected for annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Data ensemble</head><p>The final step of building the SICK corpus consisted in arranging normalised and expanded sentences into pairs. Since our data diverges from SICK data, the process of arranging Pol- ish sentences into pairs also differs from pair- ing in the SICK corpus. The general idea be- hind the pair-ensembling procedure was to intro- duce sentence pairs with different levels of relat- edness into the dataset. Apart from pairs connect- ing two sentences originally written by humans (as described in Section 2.1), there are also pairs in which an original sentence is connected with a transformed sentence. For each of the 1K im- ages, the following 10 pairs are constructed (for A being the set of all sentences originally written by the first author, B being the set of all sentences originally written by the second author, a ∈ A and b ∈ B being the original descriptions of the pic- ture):</p><formula xml:id="formula_0">1. (a, b)</formula><p>2. (a, a 1 ), where a 1 ∈ t(a), and t(a) is the set of all transformations of the sentence a</p><formula xml:id="formula_1">3. (b, b 1 ), where b 1 ∈ t(b) 4. (a, b 2 ), where b 2 ∈ t(b) 5. (b, a 2 )</formula><p>, where a 2 ∈ t(a)</p><p>6. (a, a 3 ), where a 3 ∈ t(a ), a ∈ A, T (a ) = T (a), a = a, for T (a) being the thematic group 3 of a</p><formula xml:id="formula_2">7. (b, b 3 ), where b 3 ∈ t(b ), b ∈ B, T (b ) = T (b), b = b 8. (a, a 4 ), where a 4 ∈ A, T (a 4 ) = T (a) 4 9. (b, b 4 ), where b 4 ∈ B, T (b 4 ) = T (b)</formula><p>10. (a, a 5 ), where a 5 ∈ t(a), a 5 = a 1 for 50% images, (b, b 5 ) (analogously) for other 50%. 5</p><p>For each sentence pair (a, b) created according to this procedure, its reverse (b, a) is also included in our corpus. As a result, the working set consists of 20K sentence pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus annotation 3.1 Annotation assumptions</head><p>The degree of semantic relatedness between two sentences is calculated as the average of all human ratings on the Likert scale with the range from 0 to 5. Since we do not want to excessively influence <ref type="bibr">3</ref> The thematic group of a sentence a corresponds to the thematic group of an image being the source of a (as de- scribed in Section 2.1). <ref type="bibr">4</ref> The pairs (a, a4) of the same authors' descriptions of two images from different thematic groups are expected to be unrelated. The same applies to (b, b4).</p><p>5 A repetition of point 2 with a restriction that a different pair is created (pairs of very related sentences are expected). We alternate between authors A and B to obtain equal author proportions in the final ensemble of pairs. the annotations, the guidelines given to annotators are mainly example-based: <ref type="bibr">6</ref> • 5 (very related): Kot siedzi na płocie.</p><p>( Apart from these examples, there is a note in the annotation guidelines indicating that the de- gree of semantic relatedness is not equivalent to the degree of semantic similarity. Semantic sim- ilarity is only a special case of semantic related- ness, semantic relatedness is thus a more general term than the other one.</p><p>Polish entailment labels correspond directly to the SICK labels (i.e. entailment, contradiction, neutral). The entailment label assigned by the ma- jority of human judges is selected as the gold label. The entailment labels are defined as follows:</p><p>• a wynika z b (b entails a) -if a situation or an event described by sentence b occurs, it is recognised that a situation or an event described by a occurs as well, i.e. a and b refer to the same event or the same situation,</p><p>• a jest zaprzeczeniem b (a is the negation of b) -if a situation or an event described by b occurs, it is recognised that a situation or an event described by a may not occur at the same time,</p><p>• a jest neutralne wobec b (a is neutral to b) - the truth of a situation described by a cannot be determined on the basis of b.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Annotation procedure</head><p>Similar to the SICK corpus, each Polish sentence pair is human-annotated for semantic relatedness and entailment by 3 human judges experienced in Polish linguistics. <ref type="bibr">7</ref> Since for each annotated pair (a, b), its reverse (b, a) is also subject to anno- tation, the entailment relation is in practice deter- mined 'in both directions' for 10K sentence pairs. For the task of relatedness annotation, the order of sentences within pairs seems to be irrelevant, we can thus assume to obtain 6 relatedness scores for 10K unique pairs. Since the transformation process is fully auto- matic and to a certain extent based on imperfect dependency parsing, we cannot ignore errors in the transformed sentences. In order to avoid anno- tating erroneous sentences, the annotation process is divided into two stages:</p><p>1. a sentence pair is sent to a judge with the leader role, who is expected to edit and to correct the transformed sentence from this pair before annotation, if necessary, 2. the verified and possibly enhanced sentence pair is sent to the other two judges, who can only annotate it.</p><p>The leader judges should correct incomprehen- sible and ungrammatical sentences with a mini- mal number of necessary changes. Unusual sen- tences which could be accepted by Polish speakers should not be modified. Moreover, the modified sentence may not be identical with the other sen- tence in the pair. The classification and statistics of distinct corrections made by the leader judges are provided in <ref type="table">Table 2</ref>. A strict classification of error types is quite hard to provide because some sentences contain more than one error. We thus order the error types from the most serious errors (i.e. 'sense' errors) to the redundant corrections (i.e. 'other' type). If a sen- tence contains several errors, it is qualified for the higher order error type.</p><p>In the case of sentences with 'sense' errors, the need for correction is uncontroversial and error type # of errors % of <ref type="table" target="#tab_1">errors  sense  171  12.3  semantic  407  29.2  grammatical  243  17.4  word order  141  10.1  punctuation  366</ref> 26.2 other 68 4.9 <ref type="table">Table 2</ref>: Classification and statistics of correc- tions.</p><p>arises from an internal logical contradiction. <ref type="bibr">8</ref> The sentences with 'semantic' changes are syn- tactically correct, but deemed unacceptable by the leader annotators from the semantic or pragmatic point of view. <ref type="bibr">9</ref> The 'grammatical' errors mostly concern missing agreement. <ref type="bibr">10</ref> The majority of 'word order' corrections are unnecessary, but we found some examples which can be classified as actual word or phrase order errors. <ref type="bibr">11</ref> The correc- tion of punctuation consists in adding or deleting a comma. <ref type="bibr">12</ref> The sentences in the 'other' group, in turn, could as well have been left unchanged be- cause they are proper Polish sentences, but were apparently considered odd by the leader annota- tors. <ref type="bibr">8</ref> An example of 'sense' error: the sentence Chłopak w zielonej bluzie i czapce zje˙ zd˙ za na rolkach na le˙ z ˛ aco. (Eng. 'A boy in a green sweatshirt and a cap roller-skates down- hill in a lying position.') is corrected into Chłopak w zielonej bluzie i czapce zje˙ zd˙ za na rolkach. (Eng. 'A boy in a green sweatshirt and a cap roller-skates downhill.'). <ref type="bibr">9</ref> An example of 'semantic' correction: the sentence Dziewczyna trzyma w pysku patyk. (Eng. 'A girl holds a stick in her muzzle.') is corrected into Dziewczyna trzyma w us- tach patyk. (Eng. 'A girl holds a stick in her mouth.'). <ref type="bibr">10</ref> An example of 'grammatical' error: the sentence Grupasg.nom u´smiechaju´smiechaj ˛ acych si˛ e ludzi tá ncz ˛ a pl . (Eng. *'A group of smiling people are dancing.') is corrected into Grupasg.nom u´smiechaju´smiechaj ˛ acych si˛ e ludzi tá nczysg. (Eng. 'A group of smiling people is dancing.'). <ref type="bibr">11</ref> An example of word order error: the sentence Samochód, który jest uszkodzony, koloru białego stoi na lawecie du˙ zego auta. (lit. 'A car that is damaged, of the white color stands on the trailer of a large car.', Eng. 'A white car that is dam- aged is standing on the trailer of a large car.') is corrected into Samochód koloru białego, który jest uszkodzony, stoi na lawecie du˙ zego auta. <ref type="bibr">12</ref> An example of punctuation correction: the wrong comma in the sentence Nad brzegiem wody, stoj ˛ a dwaj m˛ e˙ zczy´znizczy´zni z w˛ edkami. (lit. 'On the water's edge, two men are standing with rods.'; Eng. 'Two men with rods are standing on the wa- ter's edge.') should be deleted, i.e. Nad brzegiem wody stoj ˛ a dwaj m˛ e˙ zczy´znizczy´zni z w˛ edkami.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Impromptu post-corrections</head><p>During the annotation process it came out that sen- tences accepted by some human annotators are un- acceptable for other annotators. We thus decided to garner annotators' comments and suggestions for improving sentences. After validation of these suggestions by an experienced linguist, it turns out that most of these proposals concern punctuation errors (e.g. missing comma) and typos in 312 dis- tinct sentences. These errors are fixed directly in the corpus because they should not impact the an- notations of sentence pairs. The other suggestions concern more significant changes in 29 distinct sentences (mostly minor grammatical or seman- tic problems overlooked by the leader annotators). The annotations of pairs with modified sentences are resent to the annotators so that they can verify and update them. <ref type="table">Tables 3 and 4</ref> summarise the annotations of the resulting 10K sentence pairs corpus. <ref type="table">Table  3</ref> aggregates the occurrences of 6 possible related- ness scores, calculated as the mean of all 6 indi- vidual annotations, rounded to an integer. <ref type="table" target="#tab_1">0  1978  1  1428  2  1082  3  2159  4  2387  5  966   Table 3</ref>: Final relatedness scores rounded to inte- gers (total: 10K pairs). <ref type="table">Table 4</ref> shows the number of the particular en- tailment labels in the corpus. Since each sentence pair is annotated for entailment in both directions, the final entailment label is actually a pair of two labels:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Corpus summary and evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>relatedness # of pairs</head><p>• entailment+neutral points to 'one-way' en- tailment,</p><p>• contradiction+neutral points to 'one-way' contradiction,</p><p>• entailment+entailment, contradiction+con- tradiction, and neutral+neutral point to equivalence.</p><p>While the actual corpus labels are ordered in the sense that there is a difference between e.g. entailment+neutral and neutral+entailment (the entailment occurs in different directions), we treat all labels as unordered for the purpose of this summary (e.g. entailment+neutral covers neutral+entailment as well, representing the same type of relation between two sentences).  <ref type="table">Table 4</ref>: Final entailment labels (total: 10K pairs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inter-annotator agreement</head><p>The standard measure of inter-annotator agree- ment in various natural language labelling tasks is Cohen's kappa <ref type="bibr" target="#b6">(Cohen, 1960)</ref>. However, this coef- ficient is designed to measure agreement between two annotators only. Since there are three annota- tors of each pair of ordered sentences, we decided to apply Fleiss' kappa 13 <ref type="bibr" target="#b8">(Fleiss, 1971)</ref> designed for measuring agreement between multiple raters who give categorical ratings to a fixed number of items. An additional advantage of this measure is that different items can be rated by different hu- man judges, which doesn't impact measurement. The normalised Fleiss' measure of inter-annotator agreement is:</p><formula xml:id="formula_3">κ = ¯ P − ¯ P e 1 − ¯ P e</formula><p>where the quantity ¯ P − ¯ P e measures the degree of agreement actually attained in excess of chance, while "[t]he quantity 1 − ¯ P e measures the de- gree of agreement attainable over and above what would be predicted by chance" <ref type="bibr">(Fleiss, 1971, p. 379)</ref>.</p><p>We recognise Fleiss' kappa as particularly use- ful for measuring inter-annotator agreement with respect to entailment labelling in our evaluation dataset. First, there are more than two raters. Sec- ond, entailment labels are categorically. Measured <ref type="bibr">13</ref> As Fleiss' kappa is actually the generalisation of Scott's π <ref type="bibr" target="#b18">(Scott, 1955)</ref>, it is sometimes referred to as Fleiss' multi-π, cf. <ref type="bibr" target="#b1">Artstein and Poesio (2008).</ref> with Fleiss' kappa, there is an inter-annotator agreement of κ = 0.734 for entailment labels in Polish evaluation dataset, which is quite satisfac- tory as for a semantic labelling task.</p><p>Relative to semantic relatedness, the distinc- tion in meaning of two sentences made by human judges is often very subtle. This is also reflected in the inter-annotator agreement scores measured with Fleiss' kappa. Inter-annotator agreement measured for six semantic relatedness groups corresponding to points on the Likert scale is quite low: κ = 0.337. If we measure inter- annotator agreement for three classes correspond- ing to the three relatedness groups from the an- notation guidelines (see Section 3.1), i.e. &lt;0&gt;, &lt;1, 2, 3, 4&gt;, and &lt;5&gt;, the Fleiss' score is sig- nificantly higher: κ = 0.543. Hence, we con- clude that Fleiss' kappa is not a reliable measure of inter-annotator agreement in relation to related- ness scores. Therefore, we decided to use Krippen- dorff's α instead. <ref type="bibr">Krippendorff's α (Krippendorff, 1980</ref><ref type="bibr" target="#b13">, 2013</ref> is a coefficient appropriate for measuring the inter- annotator agreement of a dataset which is anno- tated with multiple judges and characterised by different magnitudes of disagreement and miss- ing values. Krippendorff proposes distance met- rics suitable for various scales: binary, nominal, interval, ordinal, and ratio. In ordinal measure- ment 14 the attributes can be rank-ordered, but dis- tances between them do not have any meaning. Measured with Krippendorff's ordinal α, there is an inter-annotator agreement of α = 0.780 for re- latedness scores in the Polish evaluation dataset, which is quite satisfactory as well. Hence, we con- clude that our dataset is a reliable resource for the purpose of evaluating compositional distribu- tional semantics model of Polish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The goal of this paper is to present the proce- dure of building a Polish evaluation dataset for the validation of compositional distributional se- mantics models. As we aim at building an evalua-tion dataset which is comparable to the SICK cor- pus, the general assumptions of our procedure cor- respond to the design principles of the SICK cor- pus. However, the procedure of building the SICK corpus cannot be adapted without modifications. First, the Polish seed-sentences have to be written based on the images which are selected from 8K ImageFlickr dataset and split into thematic groups, since usable datasets are not publicly available. Second, since the process of transforming sen- tences seems to be language-specific, the linguistic transformation rules appropriate for Polish have to be defined from scratch. Third, the process of ar- ranging Polish sentences into pairs is defined anew taking into account the data characteristic and bi- directional entailment annotations. The discrepan- cies relative to the SICK procedure also concern the annotation process itself. Since an entailment relation between two sentences must not be sym- metric, each sentence pair is annotated for entail- ment in both directions. Furthermore, we intro- duce an element of human verification of correct- ness of automatically transformed sentences and some additional post-corrections.</p><p>The presented procedure of building a dataset was tested on Polish. However, it is very likely that the annotation framework will work for other Slavic languages (e.g. Czech with an excellent de- pendency parser).</p><p>The presented procedure results in building the Polish test corpus of relatively high quality, confirmed by the inter-annotator agreement coeffi- cients of κ = 0.734 (measured with Fleiss' kappa) for entailment labels and of α = 0.780 (measured with Krippendorff's ordinal alpha) for relatedness scores.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>transformation 
selected 
dropping conjunction 
139 
2.0% 
removing conjunct in adjunct 
485 
6.9% 
passivisation 
893 12.8% 
removing adjuncts 
1013 14.5% 
swapping rc↔ptcp 
1291 18.4% 
negation 
1304 18.6% 
mixing dependents 
1878 26.8% 

</table></figure>

			<note place="foot" n="2"> As the principle of compositionality is attributed to Gottlob Frege, it is often called Frege&apos;s principle.</note>

			<note place="foot" n="6"> We realise that the boundary between semantic perception of a sentence by various speakers is fuzzy (it depends on speakers&apos; education, origin, age, etc.). It was thus our wellthought-out decision to draw only general annotation frames and to enable annotators to rely on their feel for language.</note>

			<note place="foot" n="7"> Our annotators have relatively strong linguistic background. Five of them have PhD in linguistics, five are PhD students, one is a graduate, and one is an undergraduate.</note>

			<note place="foot" n="14"> Nominal measurement is useless for measuring agreement between relatedness scores (α = 0.340 is the identical value as Fleiss&apos; kappa, since all disagreements are considered equal). We also test interval measurement, in which the distance between the attributes does have meaning and an average of an interval variable is computed. The interval score measured for relatedness annotations is quite high α = 0.785, but we doubt whether the distance between relatedness scores is meaningful in this case.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the reliable and tena-cious annotators of our dataset: Alicja Dziedzic-Rawska, Bo˙ zena Itoya, Magdalena Król, Anna La-tusek, Justyna Małek, Małgorzata Michalik, Ag-nieszka Norwa, Małgorzata Szajbel-Keck, Alicja Walichnowska, Konrad Zieli´nskiZieli´nski, and some other. The research presented in this paper was supported by SONATA 8 grant no 2014/15/D/HS2/03486 from the National Science Centre Poland.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics (*SEM)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Inter-Coder Agreement for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="557" to="596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1183" to="1193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Neural Probabilistic Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural Probabilistic Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Sébastien</forename><surname>Senécal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fréderic</forename><surname>Morin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations in Machine Learning. Theory and Applications</title>
		<editor>D.E. Holmes and L.C. Jain</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="137" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SICK through the SemEval Glasses. Lesson learned from the evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="95" to="124" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A synopsis of linguistic theory, 1930-1955</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Rupert Firth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Linguistic Analysis. Special volume of the Philological Society</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="378" to="382" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Experimental Support for a Categorical Compositional Distributional Model of Meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrnoosh</forename><surname>Sadrzadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1394" to="1404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zellig</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Distributional structure. Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compositionality: its historic context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Theo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Janssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Oxford Handbook of Compositionality</title>
		<editor>Wolfram Hinzen, Edouard Machery, and Markus Werning</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="19" to="46" />
		</imprint>
	</monogr>
	<note>Studies in Fuzziness and Soft Computing</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Content Analysis: An Introduction to Its Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Sage Publications</publisher>
			<pubPlace>Beverly Hills</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Content Analysis: An Introduction to Its Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thousand Oaks</title>
		<imprint>
			<publisher>Sage Publication</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SemEval-2014 Task 1: Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Textual Entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26. Proceedings of Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Composition in Distributional Models of Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Collecting Image Annotations Using Amazon&apos;s Mechanical Turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Rashtchian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</title>
		<meeting>the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reliability of Content Analysis: The Case of Nominal Scale Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="321" to="325" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semantic Compositionality through Recursive Matrix-Vector Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1201" to="1211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Polish Dependency Parser Trained on an Automatically Induced Dependency Bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Wróblewska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>Warsaw</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute of Computer Science, Polish Academy of Sciences</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
