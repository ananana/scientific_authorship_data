<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Higher-order Relation Schema Induction using Tensor Factorization with Back-off and Aggregation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madhav</forename><surname>Nimishakavi</surname></persName>
							<email>madhav@iisc.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science Bangalore</orgName>
								<orgName type="institution">Indian Institute of Science Bangalore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Gupta</surname></persName>
							<email>manishg@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science Bangalore</orgName>
								<orgName type="institution">Indian Institute of Science Bangalore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Microsoft</forename><surname>Hyderabad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science Bangalore</orgName>
								<orgName type="institution">Indian Institute of Science Bangalore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Indian Institute of Science Bangalore</orgName>
								<orgName type="institution">Indian Institute of Science Bangalore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Higher-order Relation Schema Induction using Tensor Factorization with Back-off and Aggregation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1575" to="1584"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1575</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Relation Schema Induction (RSI) is the problem of identifying type signatures of arguments of relations from unlabeled text. Most of the previous work in this area have focused only on binary RSI, i.e., inducing only the subject and object type signatures per relation. However, in practice, many relations are high-order, i.e., they have more than two arguments and inducing type signatures of all arguments is necessary. For example, in the sports domain, inducing a schema win(WinningPlayer, OpponentPlayer, Tournament, Location) is more informative than inducing just win(WinningPlayer, OpponentPlayer). We refer to this problem as Higher-order Relation Schema Induction (HRSI). In this paper, we propose Tensor Factorization with Back-off and Aggregation (TFBA), a novel framework for the HRSI problem. To the best of our knowledge, this is the first attempt at inducing higher-order relation schemata from unlabeled text. Using the experimental analysis on three real world datasets, we show how TFBA helps in dealing with sparsity and induce higher order schemata.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building Knowledge Graphs (KGs) out of un- structured data is an area of active research. Re- search in this has resulted in the construction of several large scale KGs, such as NELL ( <ref type="bibr" target="#b17">Mitchell et al., 2015)</ref>, Google Knowledge Vault ( <ref type="bibr" target="#b6">Dong et al., 2014</ref>) and YAGO ( <ref type="bibr" target="#b33">Suchanek et al., 2007)</ref>. These KGs consist of millions of entities and be- liefs involving those entities. Such KG construc- tion methods are schema-guided as they require the list of input relations and their schemata (e.g., playerPlaysSport <ref type="bibr">(Player, Sport)</ref>). In other words, knowledge of schemata is an important first step towards building such KGs.</p><p>While beliefs in such KGs are usually binary (i.e., involving two entities), many beliefs of in- terest go beyond two entities. For example, in the sports domain, one may be interested in beliefs of the form win(Roger Federer, Nadal, Wimbledon, London), which is an instance of the high-order (or n-ary) relation win whose schema is given by win(WinningPlayer, OpponentPlayer, Tourna- ment, Location). We refer to the problem of induc- ing such relation schemata involving multiple ar- guments as Higher-order Relation Schema Induc- tion (HRSI). In spite of its importance, HRSI is mostly unexplored.</p><p>Recently, tensor factorization-based methods have been proposed for binary relation schema in- duction ( <ref type="bibr" target="#b25">Nimishakavi et al., 2016)</ref>, with gains in both speed and accuracy over previously proposed generative models. To the best of our knowledge, tensor factorization methods have not been used for HRSI. We address this gap in this paper.</p><p>Due to data sparsity, straightforward adaptation of tensor factorization from ( <ref type="bibr" target="#b25">Nimishakavi et al., 2016</ref>) to HRSI is not feasible, as we shall see in Section 3.1. We overcome this challenge in this paper, and make the following contributions.</p><p>• We propose Tensor Factorization with Back- off and Aggregation (TFBA), a novel tensor factorization-based method for Higher-order RSI (HRSI). In order to overcome data spar- sity, TFBA backs-off and jointly factorizes multiple lower-order tensors derived from an extremely sparse higher-order tensor.</p><p>• As an aggregation step, we propose a con- strained clique mining step which constructs the higher-order schemata from multiple bi- nary schemata.</p><p>• Through experiments on multiple real-world datasets, we show the effectiveness of TFBA for HRSI.</p><p>Source code of TFBA is available at https: //github.com/madhavcsa/TFBA.</p><p>The remainder of the paper is organized as fol- lows. We discuss related work in Section 2. In Section 3.1, we first motivate why a back-off strat- egy is needed for HRSI, rather than factorizing the higher-order tensor. Further, we discuss the pro- posed TFBA framework in Section 3.2. In Sec- tion 4, we demonstrate the effectiveness of the pro- posed approach using multiple real world datasets. We conclude with a brief summary in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we discuss related works in two broad areas: schema induction, and tensor and ma- trix factorizations.</p><p>Schema Induction: Most work on inducing schemata for relations has been in the binary set- ting <ref type="bibr" target="#b18">(Mohamed et al., 2011;</ref><ref type="bibr" target="#b20">Movshovitz-Attias and Cohen, 2015;</ref><ref type="bibr" target="#b25">Nimishakavi et al., 2016)</ref>. <ref type="bibr" target="#b15">McDonald et al. (2005)</ref> and <ref type="bibr" target="#b26">Peng et al. (2017)</ref> extract n-ary relations from Biomedical documents, but do not induce the schema, i.e., type signature of the n-ary relations. There has been significant amount of work on Semantic Role Labeling ( <ref type="bibr" target="#b12">Lang and Lapata, 2011;</ref><ref type="bibr" target="#b34">Titov and Khoddam, 2015;</ref><ref type="bibr" target="#b30">Roth and Lapata, 2016)</ref>, which can be considered as n- ary relation extraction. However, we are inter- ested in inducing the schemata, i.e., the type signa- ture of these relations. Event Schema Induction is the problem of inducing schemata for events in the corpus ( <ref type="bibr" target="#b1">Balasubramanian et al., 2013;</ref><ref type="bibr" target="#b2">Chambers, 2013;</ref><ref type="bibr" target="#b22">Nguyen et al., 2015)</ref>. Recently, a model for event representations is proposed in ( <ref type="bibr" target="#b37">Weber et al., 2018)</ref>. <ref type="bibr" target="#b5">Cheung et al. (2013)</ref> propose a probabilistic model for inducing frames from text. Their no- tion of frame is closer to that of scripts ( <ref type="bibr" target="#b31">Schank and Abelson, 1977)</ref>. Script learning is the pro- cess of automatically inferring sequence of events from text ( <ref type="bibr" target="#b19">Mooney and DeJong, 1985)</ref>. There is a fair amount of recent work in statistical script learning <ref type="bibr" target="#b28">(Pichotta and Mooney, 2016)</ref>, <ref type="bibr" target="#b27">(Pichotta and Mooney, 2014)</ref>. While script learning deals with the sequence of events, we try to find the schemata of relations at a corpus level. <ref type="bibr" target="#b8">Ferraro and Durme (2016)</ref> propose a unified Bayesian model for scripts, frames and events. Their model tries to capture all levels of Minsky Frame structure <ref type="bibr" target="#b16">(Minsky, 1974)</ref>, however we work with the surface se- mantic frames.</p><p>Tensor and Matrix Factorizations: Matrix factorization and joint tensor-matrix factorizations have been used for the problem of predicting links in the Universal Schema setting ( <ref type="bibr" target="#b29">Riedel et al., 2013;</ref><ref type="bibr" target="#b32">Singh et al., 2015)</ref>.  use matrix factorizations for the problem of finding semantic slots for unsupervised spoken language understanding. Tensor factorization methods are also used in factorizing knowledge graphs <ref type="bibr" target="#b3">(Chang et al., 2014;</ref><ref type="bibr" target="#b24">Nickel et al., 2012)</ref>. Joint matrix and tensor factorization frameworks, where the ma- trix provides additional information, is proposed in ( <ref type="bibr" target="#b0">Acar et al., 2013)</ref> and ( ). These models are based on PARAFAC <ref type="bibr" target="#b9">(Harshman, 1970)</ref>, a tensor factorization model which approximates the given tensor as a sum of rank- 1 tensors. A boolean Tucker decomposition for discovering facts is proposed in <ref type="bibr" target="#b7">(Erdos and Miettinen, 2013)</ref>. In this paper, we use a modified ver- sion (Tucker2) of Tucker decomposition <ref type="bibr" target="#b35">(Tucker, 1963)</ref>. RESCAL ( <ref type="bibr" target="#b23">Nickel et al., 2011</ref>) is a simplified Tucker model suitable for relational learning. Re- cently, SICTF ( <ref type="bibr" target="#b25">Nimishakavi et al., 2016</ref>), a vari- ant of RESCAL with side information, is used for the problem of schema induction for binary rela- tions. SICTF cannot be directly used to induce higher order schemata, as the higher-order tensors involved in inducing such schemata tend to be ex- tremely sparse. TFBA overcomes these challenges to induce higher-order relation schemata by per- forming Non-Negative Tucker-style factorization of sparse tensor while utilizing a back-off strategy, as explained in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Higher Order Relation Schema</head><p>Induction using <ref type="bibr">Back-off Factorization</ref> In this section, we start by discussing the approach of factorizing a higher-order tensor and provide the motivation for back-off strategy. Next, we discuss the proposed TFBA approach in detail. Please refer to <ref type="table">Table 1</ref> for notations used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation Definition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R+</head><p>Set of non-negative reals. X ∈ R n 1 ×n 2 ×...×n N + N th -order non-negative tensor.</p><formula xml:id="formula_0">X (i)</formula><p>mode-i matricization of tensor X . Please see ( <ref type="bibr" target="#b11">Kolda and Bader, 2009</ref>) for details. A ∈ R n×r + Non-negative matrix of order n × r. * Hadamard product: (A * B)i,j = Ai,j × Bi,j. <ref type="table">Table 1</ref>: Notations used in the paper. <ref type="figure">Figure 1</ref>: Overview of Step 1 of TFBA. Rather than factorizing the higher-order tensor X , TFBA performs joint Tucker decomposition of multiple 3-mode tensors, X 1 , X 2 , and X 3 , derived out of X . This joint factorization is performed using shared latent factors A, B, and C. This results in binary schemata, each of which is stored as a cell in one of the core tensors G 1 , G 2 , and G 3 . Please see Section 3.2.1 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Factorizing a Higher-order Tensor</head><p>Given a text corpus, we use OpenIEv5 <ref type="bibr" target="#b14">(Mausam, 2016)</ref> to extract tuples. Consider the following sentence "Federer won against Nadal at Wimble- don.". Given this sentence, OpenIE extracts the 4-tuple (Federer, won, against Nadal, at Wimble- don). We lemmatize the relations in the tuples and only consider the noun phrases as arguments. Let T represent the set of these 4-tuples. We can con- struct a 4-order tensor X ∈ R n 1 ×n 2 ×n 3 ×m + from T. Here, n 1 is the number of subject noun phrases (NPs), n 2 is the number of object NPs, n 3 is the number of other NPs, and m is the number of re- lations in T. Values in the tensor correspond to the frequency of the tuples. In case of 5-tuples of the form (subject, relation, object, other-1, other-2), we split the 5-tuples into two 4-tuples of the form (subject, relation, object, other-1) and (subject, re- lation, object, other-2) and frequency of these 4- tuples is considered to be same as the original 5- tuple. Factorizing the tensor X results in discov- ering latent categories of NPs, which help in in- ducing the schemata. We propose the following approach to factorize X .</p><formula xml:id="formula_1">min G,A,B,C X − G × 1 A × 2 B × 3 C × 4 I 2 F + λ a A 2 F + λ b B 2 F + λ c C 2 F ,</formula><p>where,</p><formula xml:id="formula_2">A ∈ R n 1 ×r 1 + , B ∈ R n 2 ×r 2 + , C ∈ R n 3 ×r 3 + , G ∈ R r 1 ×r 2 ×r 3 ×m + , λ a ≥ 0, λ b ≥ 0 and λ c ≥ 0.</formula><p>Here, I is the identity matrix. Non-negative up- dates for the variables can be obtained following <ref type="bibr" target="#b13">(Lee and Seung, 2000</ref>). Similar to ( <ref type="bibr" target="#b25">Nimishakavi et al., 2016)</ref>, schemata induced will be of the form relation A i , B j , C k . Here, P i represents the i th column of a matrix P. A is the embedding matrix of subject NPs in T (i.e., mode-1 of X ), r 1 is the embedding rank in mode-1 which is the number of latent categories of subject NPs. Similarly, B and <ref type="figure">Figure 2</ref>: Overview of Step 2 of TFBA. Induction of higher-order schemata from the tri-partite graph formed from the columns of matrices A, B, and C. Triangles in this graph (solid) represent a 3-ary schema, n-ary schemata for n &gt; 3 can be induced from the 3-ary schemata. Please refer to Section 3.2.2 for details.</p><p>C are the embedding matrices of object NPs and other NPs respectively. r 2 and r 3 are the number of latent categories of object NPs and other NPs respectively. G is the core tensor. λ a , λ b and λ c are the regularization weights.</p><p>However, the 4-order tensors are heavily sparse for all the datasets we consider in this work. The sparsity ratio of this 4-order tensor for all the datasets is of the order 1e-7. As a result of the extreme sparsity, this approach fails to learn any schemata. Therefore, we propose a more success- ful back-off strategy for higher-order RSI in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TFBA: Proposed Framework</head><p>To alleviate the problem of sparsity, we construct three tensors X 3 , X 2 , and X 1 from T as follows:</p><p>• X 3 ∈ R n 1 ×n 2 ×m + is constructed out of the tuples in T by dropping the other argu- ment and aggregating resulting tuples, i.e.,</p><formula xml:id="formula_3">X 3 i,j,p = n 3 k=1 X i,j,k,p .</formula><p>For example, 4- tuples (Federer, Win, Nadal, Wimbledon), 10 and (Federer, Win, Nadal, Australian Open), 5 will be aggregated to form a triple (Federer, Win, Nadal), 15.</p><p>• X 2 ∈ R n 1 ×n 3 ×m + is constructed out of the tuples in T by dropping the object argument and aggregating resulting tuples i.e., X 2 i,j,p = n 2 k=1 X i,k,j,p .</p><p>• X 1 ∈ R n 2 ×n 3 ×m + constructed out of the tu- ples in T by dropping the subject argument and aggregating resulting tuples i.e.,</p><formula xml:id="formula_4">X 1 i,j,p = n 1 k=1 X k,i,j,p .</formula><p>The proposed framework TFBA for inducing higher order schemata involves the following two steps.</p><p>• Step 1: In this step, TFBA factorizes multi- ple lower-order overlapping tensors, X 1 , X 2 , and X 3 , derived from X to induce binary schemata. This step is illustrated in <ref type="figure">Figure  1</ref> and we discuss details in Section 3.2.1.</p><p>• Step 2: In this step, TFBA connects multiple binary schemata identified above to induce higher-order schemata. The method accom- plishes this by solving a constrained clique problem. This step is illustrated in <ref type="figure">Figure 2</ref> and we discuss the details in Section 3.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Step 1: Back-off Tensor Factorization</head><p>A schematic overview of this step is shown in <ref type="figure">Fig- ure 1</ref>. TFBA first preprocesses the corpus and ex- tracts OpenIE tuple set T out of it. The 4-mode tensor X is constructed out of T. Instead of per- forming factorization of the higher-order tensor X as in Section 3.1, TFBA creates three tensors out of X : X 1 n 2 ×n 3 ×m , X 2 n 1 ×n 3 ×m and X 3 n 1 ×n 2 ×m . TFBA performs a coupled non-negative Tucker factorization of the input tensors X 1 , X 2 and X 3 by solving the following optimization problem.</p><formula xml:id="formula_5">min A,B,C G 1 ,G 2 ,G 3 f (X 3 , G 3 , A, B) + f (X 2 , G 2 , A, C) + f (X 1 , G 1 , B, C) + λ a A 2 F + λ b B 2 F + λ c C 2 F ,<label>(1)</label></formula><p>where,</p><formula xml:id="formula_6">f (X i , G i , P, Q) = X i − G i × 1 P × 2 Q × 3 I 2 F A ∈ R n 1 ×r 1 + , B ∈ R n 2 ×r 2 + , C ∈ R n 3 ×r 3 + G 1 ∈ R r 2 ×r 3 ×m + , G 2 ∈ R r 1 ×r 3 ×m + , G 3 ∈ R r 1 ×r 2 ×m + .</formula><p>We enforce non-negativity constraints on the ma- trices A, B, C and the core tensors G i (i ∈ {1, 2, 3}). Non-negativity is essential for learning interpretable latent factors ( <ref type="bibr" target="#b21">Murphy et al., 2012</ref>).</p><p>Each slice of the core tensor G 3 corresponds to one of the m relations. Each cell in a slice cor- responds to an induced schema in terms of the latent factors from matrices A and B. In other words, G 3 i,j,k is an induced binary schema for re- lation k involving induced categories represented by columns A i and B j . Cells in G 1 and G 2 may be interpreted accordingly.</p><p>We derive non-negative multiplicative updates for A, B and C following the NMF updating rules given in <ref type="bibr" target="#b13">(Lee and Seung, 2000</ref>). For the update of A, we consider the mode-1 matricization of first and the second term in Equation 1 along with the regularizer.</p><formula xml:id="formula_7">A ← A * X 3 (1) G B A + X 2 (1) G C A A[G B A G B A + G C A G C A ] + λ a A ,</formula><p>where,</p><formula xml:id="formula_8">G B A = (G 3 × 2 B) (1) , G C A = (G 2 × 2 C) (1) .</formula><p>In order to estimate B, we consider mode-2 ma- tricization of first term and mode-1 matricization of third term in Equation 1, along with the regu- larization term. We get the following update rule for B B ← B *</p><formula xml:id="formula_9">X 3 (2) G A B + X 1 (1) G C B B[G A B G A B + G C B G C B ] + λ b B ,</formula><p>where,</p><formula xml:id="formula_10">G A B = (G 3 × 1 A) (2) , G C B = (G 1 × 2 C) (1) .</formula><p>For updating C, we consider mode-2 matriciza- tion of second and third terms in Equation 1 along with the regularization term, and we get</p><formula xml:id="formula_11">C ← C * X 3 (2) G B C + X 2 (2) G A C C[G A C G A C + G B C G B C ] + λ c C ,</formula><p>where,</p><formula xml:id="formula_12">G A C = (G 3 × 1 B) (2) , G B C = (G 2 × 1 A) (2) .</formula><p>Finally, we update the three core tensors in Equation 1 following <ref type="bibr" target="#b10">(Kim and Choi, 2007)</ref> as fol- lows,</p><formula xml:id="formula_13">G 1 ← G 1 * X 1 × 1 B × 2 C G 1 × 1 B B × 2 C C , G 2 ← G 2 * X 2 × 1 A × 2 C G 2 × 1 A A × 2 C C , G 3 ← G 3 * X 3 × 1 A × 2 B G 3 × 1 A A × 2 B B .</formula><p>In all the above updates, P Q represents element- wise division and I is the identity matrix.</p><p>Initialization: For initializing the component matrices A, B, and C, we first perform a non- negative Tucker2 Decomposition of the individ- ual input tensors X 1 , X 2 , and X 3 . Then com- pute the average of component matrices obtained from each individual decomposition for initializa- tion. We initialize the core tensors G 1 , G 2 , and G 3 with the core tensors obtained from the individual decompositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Step 2: Binary to Higher-Order Schema Induction</head><p>In this section, we describe how a higher-order schema is constructed from the factorization de- scribed in the previous sub-section. Each relation k has three representations given by the slices G 1 k , G 2 k and G 3 k from each core tensor. We need a prin- cipled way to produce a joint schema from these representations. For a relation, we select top-n in- dices (i, j) with highest values from each matrix. The indices i and j from G 3 k correspond to column numbers of A and B respectively, indices from G 2 k correspond to columns from A and C and columns from G 1 k correspond to columns from B and C. We construct a tri-partite graph with the col- umn numbers from each of the component matri- ces A, B and C as the vertices belonging to in- dependent sets, the top-n indices selected are the edges between these vertices. From this tri-partite graph, we find all the triangles which will give schema with three arguments for a relation, illus- trated in <ref type="figure">Figure 2</ref>. We find higher order schemata, i.e., schemata with more than three arguments by merging two third order schemata with same col- umn number from A and B. For example, if we find two schemata (A 2 , B 4 , C 10 ) and (A 2 , B 4 , C 8 ) then we merge these two to give (A 2 , B 4 , C 10 , C 8 ) as a higher order schema. This can be continued further for even higher order schemata. This pro- cess may be thought of as finding a constrained clique over the tri-partite graph. Here the con- straint is that in the maximal clique, there can only be one edge between sets corresponding to columns of A and columns of B.</p><p>The procedure above is inspired by <ref type="bibr" target="#b15">(McDonald et al., 2005</ref>). However, we note that ( <ref type="bibr" target="#b15">McDonald et al., 2005</ref>) solved a different problem, viz., n-ary relation instance extraction, while our focus is on inducing schemata. Though we discuss the case of back-off from 4-order to 3-order, ideas presented above can be extended for even higher orders de- pending on the sparsity of the tensors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate the performance of TFBA for the task of HRSI. We also propose a baseline model for HRSI called HardClust. HardClust: We propose a baseline model called the Hard Clustering Baseline (HardClust) for the task of higher order relation schema induction. This model induces schemata by grouping per- relation NP arguments from OpenIE extractions. In other words, for each relation, all the Noun Phrases (NPs) in first argument form a cluster that represents the subject of the relation, all the NPs in the second argument form a cluster that repre- sents object and so on. Then from each cluster, the top most frequent NPs are chosen as the repre- sentative NPs for the argument type. We note that this method is only able to induce one schema per relation.</p><p>Datasets: We run our experiments on three datasets. The first dataset (Shootings) is a collec- tion of 1,335 documents constructed from a pub- licly available database of mass shootings in the United States. The second is New York Times Sports (NYT Sports) dataset which is a collection of 20,940 sports documents from the period 2005 and 2007. And the third dataset (MUC) is a set of 1300 Latin American newswire documents about terrorism events. After performing the processing steps described in Section 3, we obtained 357,914 unique OpenIE extractions from the NYT Sports dataset, 10,847 from Shootings dataset, and 8,318 from the MUC dataset. However, in order to prop- erly analyze and evaluate the model, we consider only the 50 most frequent relations in the datasets and their corresponding OpenIE extractions. This is done to avoid noisy OpenIE extractions to yield better data quality and to aid subsequent manual evaluation of the data. We construct input tensors following the procedure described in Section 3.2. Details on the dimensions of tensors obtained are given in <ref type="table">Table 2</ref>.</p><p>Model Selection: In order to select appropriate TFBA parameters, we perform a grid search over the space of hyper-parameters, and select the set of hyper-parameters that give best Average FIT score (AvgFIT).</p><formula xml:id="formula_14">AvgFIT(G 1 , G 2 , G 3 , A, B, C, X 1 , X 2 , X 3 ) = 1 3 {FIT(X 1 , G 1 , B, C) + FIT(X 2 , G 2 , A, C) + FIT(X 3 , G 3 , A, B)},</formula><p>where,</p><formula xml:id="formula_15">FIT(X , G, P, Q) = 1− X − G × 1 P × 2 Q F X F .</formula><p>We perform a grid search for the rank param- eters between 5 and 20, for the regularization weights we perform a grid search over 0 and 1. <ref type="table" target="#tab_0">Table 3</ref> provides the details of hyper-parameters set for different datasets.</p><p>Evaluation Protocol: For TFBA, we follow the protocol mentioned in Section 3.2.2 for con- structing higher order schemata. For every rela- tion, we consider top 5 binary schemata from the factorization of each tensor. We construct a tri- partite graph, as explained in Section 3.2.2, and mine constrained maximal cliques from the tripar- tite graphs for schemata. <ref type="table" target="#tab_2">Table 4</ref> provides some qualitative examples of higher-order schemata in- duced by TFBA. Accuracy of the schemata in- duced by the model is evaluated by human evalua- tors. In our experiments, we use human judgments from three evaluators. For every relation, the first and second columns given in <ref type="table" target="#tab_2">Table 4</ref> are presented to the evaluators and they are asked to validate the schema. We present top 50 schemata based on the score of the constrained maximal clique induced by TFBA to the evaluators. This evaluation proto- col was also used in (Movshovitz-Attias and Co- hen, 2015) for evaluating ontology induction. All evaluations were blind, i.e., the evaluators were not aware of the model they were evaluating.</p><p>Difficulty with Computing Recall: Even though recall is a desirable measure, due to the lack of availability of gold higher-order schema annotated corpus, it is not possible to compute re- call. Although the MUC dataset has gold annota- tions for some predefined list of events, it does not have annotations for the relations.  <ref type="bibr">57, 820 × 20, 356 × 50 49, 659 × 20, 356 × 50 49, 659 × 57, 820 × 50 MUC</ref> 2825 × 962 × 50 2555 × 962 × 50 2555 × 2825 × 50 <ref type="table">Table 2</ref>: Details of dimensions of tensors constructed for each dataset used in the experiments.  Experimental results comparing performance of various models for the task of HRSI are given in <ref type="table">Table 5</ref>. We present evaluation results from three evaluators represented as E1, E2 and E3. As can be observed from <ref type="table">Table 5</ref>, TFBA achieves better results than HardClust for the Shootings and NYT Sports datasets, however HardClust achieves bet- ter results for the MUC dataset. Percentage agree- ment of the evaluators for TFBA is 72%, 70% and 60% for Shootings, NYT Sports and MUC datasets respectively.</p><note type="other">X 1 shape X 2 shape X 3 shape Shootings 3365 × 1295 × 50 2569 × 1295 × 50 2569 × 3365 × 50 NYT Sports</note><p>HardClust Limitations: Even though Hard- Clust gives better induction for MUC corpus, this approach has some serious drawbacks. HardClust can only induce one schema per relation. This is a restrictive constraint as multiple senses can exist for a relation. For example, consider the schemata induced for the relation shoot as shown in <ref type="table" target="#tab_2">Table  4</ref>. TFBA induces two senses for the relation, but HardClust can induce only one schema. For a set of 4-tuples, HardClust can only induce ternary schemata; the dimensionality of the schemata can- not be varied. Since the latent factors induced by HardClust are entirely based on frequency, the latent categories induced by HardClust are dom- inated by only a fixed set of noun phrases. For example, in NYT Sports dataset, subject category induced by HardClust for all the relations is team, yankees, mets. In addition to inducing only one schema per relation, most of the times HardClust only induces a fixed set of categories. Whereas for TFBA, the number of categories depends on the rank of factorization, which is a user provided pa- rameter, thus providing more flexibility to choose the latent categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Using Event Schema Induction for HRSI</head><p>Event schema induction is defined as the task of learning high-level representations of events, like a tournament, and their entity roles, like winning- player etc, from unlabeled text. Even though the main focus of event schema induction is to induce the important roles of the events, as a side result most of the algorithms also provide schemata for the relations. In this section, we investigate the effectiveness of these schemata compared to the ones induced by TFBA.</p><p>Event schemata are represented as a set of (Ac- tor, Rel, Actor) triples in ( <ref type="bibr" target="#b1">Balasubramanian et al., 2013)</ref>. Actors represent groups of noun phrases and Rels represent relations. From this style of representation, however, the n-ary schemata for re- lations cannot be induced. Event schemata gen- erated in <ref type="bibr" target="#b37">(Weber et al., 2018</ref>) are similar to that in ( <ref type="bibr" target="#b1">Balasubramanian et al., 2013)</ref>. Event schema induction algorithm proposed in <ref type="bibr" target="#b22">(Nguyen et al., 2015</ref>) doesn't induce schemata for relations, but rather induces the roles for the events. For this investigation we experiment with the following al- gorithm.</p><p>Chambers-13 <ref type="bibr" target="#b2">(Chambers, 2013)</ref>: This model learns event templates from text documents. Each event template provides a distribution over slots, where slots are clusters of NPs. Each event tem- plate also provides a cluster of relations, which is most likely to appear in the context of the afore- mentioned slots. We evaluate the schemata of these relation clusters.</p><p>As can be observed from <ref type="table">Table 5</ref>, the proposed TFBA performs much better than Chambers-13. HardClust also performs better than Chambers-13 on all the datasets. From this analysis we infer that there is a need for algorithms which induce higher-order schemata for relations, a gap we fill in this paper. Please note that the experimental results provided in (Chambers, 2013) for MUC dataset are for the task of event schema induction, but in this work we evaluate the relation schemata. Hence the results in <ref type="bibr" target="#b2">(Chambers, 2013)</ref> and re- sults in this paper are not comparable. Example</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation Schema</head><p>NPs from the induced categories Evaluator Judgment (Human) Suggested Label Shootings leaveA6, B0, C7 A6: shooting, shooting incident, double shooting valid &lt; shooting &gt; B0: one person, two people, three people &lt; people &gt; C7: dead, injured, on edge &lt;injured &gt;    <ref type="table">Table 5</ref>: Higher-order RSI accuracies of various methods on the three datasets. Induced schemata for each dataset and method are evaluated by three human evaluators, E1, E2, and E3. TFBA performs better than HardClust for Shootings and NYT Sports datasets. Even though HardClust achieves better accuracy on MUC dataset, it has several limitations, see Section 4 for more details. Chambers-13 solves a slightly different problem called event schema induction, for more details about the comparison with Chambers-13 see Section 4.1.</p><p>schemata induced by TFBA and (Chambers-13) are provided as part of the supplementary mate- rial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Higher order Relation Schema Induction (HRSI) is an important first step towards building domain- specific Knowledge Graphs (KGs). In this pa- per, we proposed TFBA, a tensor factorization- based method for higher-order RSI. To the best of our knowledge, this is the first attempt at in- ducing higher-order (n-ary) schemata for relations from unlabeled text. Rather than factorizing a severely sparse higher-order tensor directly, TFBA performs back-off and jointly factorizes multiple lower-order tensors derived out of the higher-order tensor. In the second step, TFBA solves a con- strained clique problem to induce schemata out of multiple binary schemata. We are hopeful that the backoff-based factorization idea exploited in TFBA will be useful in other sparse factorization settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Dataset</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Details of hyper-parameters set for dif-
ferent datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Examples of schemata induced by TFBA. Please note that some of them are 3-ary while others are 4-ary. For details about schema induction, please refer to Section 3.2.</figDesc><table>Shootings 
NYT Sports 
MUC 
E1 
E2 
E3 
Avg 
E1 
E2 
E3 
Avg 
E1 
E2 
E3 
Avg 
HardClust 
</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We thank the anonymous reviewers for their in-sightful comments and suggestions. This research has been supported in part by the Ministry of Hu-man Resource Development (Government of In-dia), Accenture, and Google.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding data fusion within the framework of coupled matrix and tensor factorizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evrim</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><forename type="middle">Arendt</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Savorani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tormod</forename><surname>Ns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rasmus</forename><surname>Bro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemometrics and Intelligent Laboratory Systems</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="page" from="53" to="63" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating coherent event schemas at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Event schema induction with a probabilistic entity-driven model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Typed tensor decomposition of knowledge bases for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Matrix factorization with knowledge graph propagation for unsupervised spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatole</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic frame induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discovering facts with boolean tensor tucker decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dora</forename><surname>Erdos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauli</forename><surname>Miettinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A unified bayesian model of scripts, frames and language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Foundations of the PARAFAC procedure: Models and conditions for an&quot; explanatory&quot; multi-modal factor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UCLA Working Papers in Phonetics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">84</biblScope>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonnegative tucker decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Deok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungjin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised semantic role induction via split-merge clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithms for non-negative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Open information extraction systems and downstream applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple algorithms for complex relation extraction with applications to biomedical ie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A framework for representing knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Minsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Never-ending learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Platanios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saparov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discovering relations between noun categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thahir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohamed</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Estevam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Hruschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning schemata for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Dejong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kb-lda: Jointly learning a knowledge base of hierarchy, relations, and facts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Movshovitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning effective and interpretable semantic models using non-negative sparse embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generative event schema induction with entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiem-Hieu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Besançon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Factorizing yago: Scalable machine learning for linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Volker Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kriegel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Relation schema induction using tensor factorization with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madhav</forename><surname>Nimishakavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uday</forename><surname>Singh Saini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Statistical script learning with multi-argument events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning statistical scripts with lstm recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural semantic role labeling with dependency path embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Scripts, plans, goals and understanding: An inquiry into human knowledge structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Abelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards Combined Matrix and Tensor Factorization for Universal Schema Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL Workshop on Vector Space Modeling for NLP (VSM)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unsupervised induction of semantic roles within a reconstructionerror minimization framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Khoddam</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Implications of factor analysis of three-way matrices for measurement of change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Problems in measuring change</title>
		<meeting><address><addrLine>Madison WI</addrLine></address></meeting>
		<imprint>
			<publisher>University of Wisconsin Press</publisher>
			<date type="published" when="1963" />
			<biblScope unit="page" from="122" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rubik: Knowledge guided tensor factorization and completion for health data analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">C</forename><surname>Denny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><forename type="middle">N</forename><surname>Kho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><forename type="middle">A</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Event representations with tensor-based compositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
