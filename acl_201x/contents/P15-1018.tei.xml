<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stacked Ensembles of Information Extractors for Knowledge-Base Population</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazneen</forename><forename type="middle">Fatema</forename><surname>Rajani</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidhoon</forename><surname>Viswanathan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinon</forename><surname>Bentor</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stacked Ensembles of Information Extractors for Knowledge-Base Population</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="177" to="187"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present results on using stacking to ensemble multiple systems for the Knowledge Base Population English Slot Filling (KBP-ESF) task. In addition to using the output and confidence of each system as input to the stacked classifier, we also use features capturing how well the systems agree about the provenance of the information they extract. We demonstrate that our stacking approach outper-forms the best system from the 2014 KBP-ESF competition as well as alternative en-sembling methods employed in the 2014 KBP Slot Filler Validation task and several other ensembling baselines. Additionally, we demonstrate that including provenance information further increases the performance of stacking.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Using ensembles of multiple systems is a stan- dard approach to improving accuracy in machine learning <ref type="bibr" target="#b3">(Dietterich, 2000</ref>). Ensembles have been applied to a wide variety of problems in natural language processing, including parsing <ref type="bibr" target="#b8">(Henderson and Brill, 1999</ref>), word sense disambiguation <ref type="bibr" target="#b11">(Pedersen, 2000)</ref>, and sentiment analysis <ref type="bibr" target="#b24">(Whitehead and Yaeger, 2010)</ref>. This paper presents a de- tailed study of ensembling methods for the TAC Knowledge Base Population (KBP) English Slot Filling (ESF) task <ref type="bibr" target="#b21">(Surdeanu, 2013;</ref><ref type="bibr" target="#b20">Surdeanu and Ji, 2014)</ref>.</p><p>We demonstrate new state-of-the-art results on this KBP task using stacking <ref type="bibr" target="#b25">(Wolpert, 1992)</ref>, which trains a final classifier to optimally com- bine the results of multiple systems. We present results for stacking all systems that competed in both the 2013 and 2014 KBP-ESF tracks, training * These authors contributed equally on 2013 data and testing on 2014 data. The re- sulting stacked ensemble outperforms all systems in the 2014 competition, obtaining an F1 of 48.6% compared to 39.5% for the best performing system in the most recent competition.</p><p>Although the associated KBP Slot Filler Val- idation (SFV) Track ( <ref type="bibr" target="#b16">Sammons et al., 2014</ref>) is officially fo- cused on improving the precision of individual ex- isting systems by filtering their results, frequently participants in this track also combine the results of multiple systems and also report increased re- call through this use of ensembling. However, SFV participants have not employed stacking, and we demonstrate that our stacking approach out- performs existing published SFV ensembling sys- tems.</p><p>KBP ESF systems must also provide prove- nance information, i.e. each extracted slot-filler must include a pointer to a document passage that supports it ( <ref type="bibr" target="#b20">Surdeanu and Ji, 2014)</ref>. Some SFV systems have used this provenance information to help filter and combine extractions <ref type="bibr" target="#b16">(Sammons et al., 2014</ref>). Therefore, we also explored enhancing our stacking approach by including additional in- put features that capture provenance information. By including features that quantify how much the ensembled systems agree on provenance, we fur- ther improved our F1 score for the 2014 ESF task to 50.1%.</p><p>The remainder of the paper is organized as fol- lows. Section 2 provides background information on existing KBP-ESF systems and stacking. Sec- tion 3 provides general background on the KBP- ESF task. Section 4 describes our stacking ap- proach, including how provenance information is used. Section 5 presents comprehensive exper- iments comparing this approach to existing re- sults and several additional baselines, demonstrat- ing new state-of-the-art results on KBP-ESF. Sec- tion 6 reviews prior related work on ensembling for information extraction. Section 7 presents our final conclusions and proposed directions for fu- ture research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>For the past few years, NIST has been conducting the English Slot Filling (ESF) Task in the Knowl- edge Base Population (KBP) track among various other tasks as a part of the Text Analysis Con- ference(TAC) <ref type="bibr" target="#b21">(Surdeanu, 2013;</ref><ref type="bibr" target="#b20">Surdeanu and Ji, 2014</ref>). In the ESF task, the goal is to fill spe- cific slots of information for a given set of query entities (people or organizations) based on a sup- plied text corpus. The participating systems em- ploy a variety of techniques in different stages of the slot filling pipeline, such as entity search, relevant document extraction, relation modeling and inference. In 2014, the top performing sys- tem, DeepDive with Expert Advice from Stanford University ( <ref type="bibr" target="#b23">Wazalwar et al., 2014</ref>), employed dis- tant supervision <ref type="bibr" target="#b10">(Mintz et al., 2009</ref>) and Markov Logic Networks ( <ref type="bibr" target="#b4">Domingos et al., 2008</ref>) in their learning and inferencing system. Another system, RPI BLENDER ( <ref type="bibr" target="#b9">Hong et al., 2014</ref>), used a re- stricted fuzzy matching technique in a framework that learned event triggers and employed them to extract relations from documents.</p><p>Given the diverse set of slot-filling systems available, it is interesting to explore methods for ensembling these systems. In this regard, TAC also conducts a Slot Filler Validation (SFV) task who goal is to improve the slot-filling performance using the output of existing systems. The input for this task is the set of outputs from all slot- filling systems and the expected output is a filtered set of slot fills. As with the ESF task, partici- pating systems employ a variety of techniques to perform validation. For instance, RPI BLENDER used a Multi-dimensional Truth Finding model ( <ref type="bibr" target="#b9">Yu et al., 2014</ref>) which is an unsupervised vali- dation approach based on computing multidimen- sional credibility scores. The UI CCG system ( <ref type="bibr" target="#b16">Sammons et al., 2014</ref>) developed two different validation systems using entailment and majority voting.</p><p>However, stacking ( <ref type="bibr" target="#b17">Sigletos et al., 2005;</ref><ref type="bibr" target="#b25">Wolpert, 1992)</ref> has not previously been employed for ensembling KBP-ESF systems. In stacking, a meta-classifier is learned from the output of multi- ple underlying systems. In our work, we translate this to the context of ensembling slot filling sys- tems and build a stacked meta-classifier that learns to combine the results from individual slot filling systems. We detail our stacking approach for en- sembling existing slot filling systems in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of KBP Slot Filling Task</head><p>The goal of the TAC KBP-ESF task <ref type="bibr" target="#b21">(Surdeanu, 2013;</ref><ref type="bibr" target="#b20">Surdeanu and Ji, 2014</ref>) is to collect infor- mation (fills) about specific attributes (slots) for a set of entities (queries) from a given corpus. The queries vary in each year of the task and can be either a person (PER) or an organization (ORG) entity. The slots are fixed and are listed in Ta- ble 1 by entity type. Some slots (like per:age) are single-valued while others (like per:children) are list-valued i.e., they can take multiple slot fillers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Input and Output</head><p>The input for the task is a set of queries and the corpus in which to look for information. The queries are provided in an XML format containing basic information including an ID for the query, the name of the entity, and the type of entity (PER or ORG). The corpus consists of documents for- mat from discussion forums, newswire and the In- ternet. Each document is identified by a unique document ID.</p><p>The output for the task is a set of slot fills for each input query. Depending on the type, each query should have a NIL or one or more lines of output for each of the corresponding slots. The output line for each slot fill contains the fields shown in <ref type="table" target="#tab_1">Table 2</ref>. The query ID in Column 1 should match the ID of the query given as input. The slot name (Column 2) is one of the slots listed in <ref type="table">Table 1</ref> based on entity type. Run ID (Column 3) is a unique identifier for each system. Column 4 contains a NIL filler if the system could not find any relevant slot filler. Otherwise, it contains the relation provenance. Provenance is of the form docid:startoffset-endoffset, where docid specifies a source document from the corpus and the offsets demarcate the text in this document supporting the relation. The offsets correspond to the spans of the candidate document that describe the relation between the query entity and the extracted slot filler. Column 5 contains the extracted slot filler. Column 6 is a filler provenance that is similar in format to relation provenance but in this case the offset corresponds to the portion of the document containing the extracted filler. Column 7 is a confi-  <ref type="table">Table 1</ref>: Slots for PER and ORG queries dence score which systems can provide to indicate their certainty in the extracted information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scoring</head><p>The scoring for the ESF task is carried out as fol- lows. The responses from all slot-filling systems are pooled and a key file is generated by having human assessors judge the correctness of these re- sponses. In addition, LDC includes a manual key of fillers that were determined by human judges. Using the union of these keys as the gold standard, precision, recall, and F1 scores are computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Column</head><p>Field Description Column 1 Query ID Column 2 Slot name Column 3 Run ID Column 4 NIL or Relation Provenance Column 5 Slot filler Column 6 Filler Provenance Column 7 Confidence score </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Ensembling Slot-Filling Systems</head><p>Given a set of query entities and a fixed set of slots, the goal of ensembling is to effectively combine the output of different slot-filling systems. The in- put to the ensembling system is the output of in- dividual systems (in the format described in previ- ous section) containing slot fillers and additional information such as provenance and confidence scores. The output of the ensembling system is similar to the output of an individual system, but it productively aggregates the slot fillers from dif- ferent systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Algorithm</head><p>This section describes our ensembling approach which trains a final binary classifier using features that help judge the reliability and thus correctness of individual slot fills. In a final post-processing step, the slot fills that get classified as "correct" by the classifier are kept while the others are set to NIL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Stacking</head><p>Stacking is a popular ensembling method in ma- chine learning <ref type="bibr" target="#b25">(Wolpert, 1992)</ref> and has been suc- cessfully used in many applications including the top performing systems in the Netflix competition ( <ref type="bibr" target="#b18">Sill et al., 2009</ref>). The idea is to employ multiple learners and combine their predictions by training a "meta-classifier" to weight and combine multi- ple models using their confidence scores as fea- tures. By training on a set of supervised data that is disjoint from that used to train the individual models, it learns how to combine their results into an improved ensemble model. We employ a single classifier to train and test on all slot types using an L1-regularized SVM with a linear kernel <ref type="bibr" target="#b6">(Fan et al., 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Using Provenance</head><p>As discussed above, each system provides prove- nance information for every non-NIL slot filler. There are two kinds of provenance provided: the relation provenance and the filler provenance. In our algorithm, we only use the filler provenance for a given slot fill. This is because of the changes in the output formats for the ESF task from 2013 to 2014. Specifically, the 2013 specification requires separate entity and justification provenance fields, but the 2014 collapses these into a single relation provenance field. An additional filler provenance field is common to both specifications. Hence, we use the filler provenance that is common be- tween 2013 and 2014 formats. As described ear- lier, every provenance has a docid and startoffset- endoffset that gives information about the docu- ment and offset in the document from where the slot fill has been extracted. The UI-CCG SFV sys- tem <ref type="bibr" target="#b16">Sammons et al. (2014)</ref> effectively used this provenance information to help validate and filter slot fillers. This motivated us to use provenance in our stacking approach as additional features as input to the meta-classifier.</p><p>We use provenance in two ways, first using the docid information, and second using the off- set information. We use the docids to define a document-based provenance score in the follow- ing way: for a given query and slot, if N sys- tems provide answers and a maximum of n of those systems give the same docid in their filler provenance, then the document provenance score for those n slot fills is n/N . Similarly, other slot fills are given lower scores based on the fraction of systems whose provenance document agree with theirs. Since this provenance score is weighted by the number of systems that refer to the same provenance, it measures the reliability of a slot fill based on the document from where it was ex- tracted.</p><p>Our second provenance measure uses offsets. The degree of overlap among the various systems' offsets can also be a good indicator of the reliabil- ity of the slot fill. The Jaccard similarity coeffi- cient is a statistical measure of similarity between sets and is thus useful in measuring the degree of overlap among the offsets of systems. Slot fills have variable lengths and thus the provenance off- set ranges are variable too. A metric such as the Jaccard coefficient captures the overlapping off- sets along with normalizing based on the union and thus resolving the problem with variable offset ranges. For a given query and slot, if N systems that attempt to fill it have the same docid in their document provenance, then the offset provenance (OP) score for a slot fill by a system x is calculated as follows:</p><formula xml:id="formula_0">OP (x) = 1 |N | × i∈N,i =x |offsets(i) ∩ offsets(x)| |offsets(i) ∪ offsets(x)|</formula><p>Per our definition, systems that extract slot fills from different documents for the same query slot have zero overlap among offsets. We note that the offset provenance is always used along with the document provenance and thus useful in discrim- inating slot fills extracted from a different docu- ment for the same query slot. Like the document provenance score, the offset provenance score is also a weighted feature and is a measure of relia- bility of a slot fill based on the offsets in the docu- ment from where it is extracted. Unlike past SFV systems that use provenance for validation, our ap- proach does not need access to the large corpus of documents from where the slot fills are extracted and is thus very computationally inexpensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Eliminating Slot-Filler Aliases</head><p>When combining the output of different ESF sys- tems, it is possible that some slot-filler entities might overlap with each other. An ESF system could extract a filler F 1 for a slot S while another ESF system extracts another filler F 2 for the same slot S. If the extracted fillers F 1 and F 2 are aliases (i.e. different names for the same entity), the scor- ing system for the TAC KBP SF task considers them redundant and penalizes the precision of the system.</p><p>In order to eliminate aliases from the output of ensembled system, we employ a technique derived by inverting the scheme used by the LSV ESF sys- tem ( ) for query expansion. LSV ESF uses a Wikipedia anchor-text model <ref type="bibr" target="#b14">(Roth and Klakow, 2010)</ref> to generate aliases for given query entities. By including aliases for query names, the ESF system increase the number of candidate sentences fetched for the query.</p><p>To eliminate filler aliases, we apply the same technique to generate aliases for all slot fillers of a given query and slot type. Given a slot filler, we obtain the Wikipedia page that is most likely linked to the filler text. Then, we obtain the anchor texts and their respective counts from all other Wikipedia pages that link to this page. Using these counts, we choose top N (we use N =10 as in LSV) and pick the corresponding anchor texts as aliases for the given slot filler. Using the gener- ated aliases, we then verify if any of the slot fillers are redundant with respect to these aliases. This scheme is not applicable to slot types whose fillers are not entities (like date or age). Therefore, sim- pler matching schemes are used to eliminate re- dundancies for these slot types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common systems dataset</head><p>All 2014 SFV systems dataset </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>This section describes a comprehensive set of ex- periments evaluating ensembling for the KBP ESF task. Our experiments are divided into two sub- sets based on the datasets they employ. Since our stacking approach relies on 2013 SFV data for training, we build a dataset of one run for ev- ery team that participated in both the 2013 and 2014 competitions and call it the common systems dataset. There are 10 common teams of the 17 teams that participated in ESF 2014. The other dataset comprises of all 2014 SFV systems (in- cluding all runs of all 17 teams that participated in 2014). There are 10 systems in the common sys- tems dataset, while there are 65 systems in the all 2014 SFV dataset. <ref type="table" target="#tab_3">Table 3</ref> gives a list of the com- mon systems for 2013 and 2014 ESF task. ESF systems do change from year to year and it's not a perfect comparison, but systems generally get bet- ter every year and thus we are probably only un- derperforming.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common Systems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methodology and Results</head><p>For our unsupervised ensembling baselines, we evaluate on both the common systems dataset as well as the entire 2014 SFV dataset. We compare our stacking approach to three unsupervised base- lines. The first is Union which takes the combina- tion of values for all systems to maximize recall. If the slot type is list-valued, it classifies all slot fillers as correct and always includes them. If the slot type is single-valued, if only one systems at- tempts to answer it, then it includes that system's slot fill. Otherwise if multiple systems produce a response, it only includes the slot fill with the highest confidence value as correct and discards the rest.</p><p>The second baseline is Voting. For this ap- proach, we vary the threshold on the number of systems that must agree on a slot fill from one to all. This gradually changes the system from the union to intersection of the slot fills, and we identify the threshold that results in the highest F1 score. We learn a threshold on the 2013 SFV dataset (containing 52 systems) that results in the best F1 score. We use this threshold for the voting baseline on 2014 SFV dataset. As we did for the 2013 common systems dataset, we learn a thresh- old on the 2013 common systems that results in the best F1 score and use this threshold for the voting baseline on 2014 common systems.</p><p>The third baseline is an "oracle threshold" ver- sion of Voting. Since the best threshold for 2013 may not necessarily be the best threshold for 2014, we identify the best threshold for 2014 by plot- ting a Precision-Recall curve and finding the best F1 score for the voting baseline on both the SFV and common systems datasets. <ref type="figure" target="#fig_0">Figure 1</ref> shows the   <ref type="table">Table 5</ref>: Performance on the common systems dataset (10 systems) for various configurations. All approaches except the Stanford system are our implementations.</p><p>Precision-Recall curve for two datasets for finding the best possible F1 score using the voting base- line. We find that for the common systems dataset, a threshold of 3 (of 10) systems gives the best F1 score, while for the entire 2014 SFV dataset, a threshold of 10 (of 65) systems gives the highest F1. Note that this gives an upper bound on the best results that can be achieved with voting, as- suming an optimal threshold is chosen. Since the upper bound can not be predicted without using the 2014 dataset, this baseline has an unfair ad- vantage. <ref type="table" target="#tab_4">Table 4</ref> shows the performance of all 3 baselines on the all 2014 SFV systems dataset.</p><p>For all our supervised ensembling approaches, we train on the 2013 SFV data and test on the 2014 data for the common systems. We have 5 different supervised approaches. Our first ap- proach is stacking the common systems using their confidence scores to learn a classifier. As discussed earlier, in stacking we train a meta- classifier that combines the systems using their confidence scores as features. Since the com- mon systems dataset has 10 systems, this classifier uses 10 features. The second approach also pro- vides stacking with a nominal feature giving the relation name (as listed in <ref type="table">Table 1</ref>) for the given slot instance. This allows the system to learn dif- ferent evidence-combining functions for different slot types if the classifier finds this useful. For our third approach, we also provide the document provenance feature described in Section 4.1. Al- together this approach has 11 features (10 confi- dence score + 1 document provenance score). The fourth approach uses confidences, the document provenance feature, and a one-hot encoding of the relation name for the slot instance. Our final ap- proach also includes the offset provenance (OP) feature discussed in Section 4.1. There are alto- gether 13 features in this approach. All our su- pervised approaches use the Weka package ( <ref type="bibr" target="#b7">Hall et al., 2009</ref>) for training the meta-classifier, using an L1-regularized SVM with a linear kernel (other classifiers gave similar results). <ref type="figure" target="#fig_1">Figure 2</ref> shows our system pipeline for evaluating supervised en- sembling approaches. <ref type="table">Table 5</ref> gives the perfor- mance of all our supervised approaches as well as our unsupervised baselines for the common sys- tems dataset.</p><p>Analysis by <ref type="bibr" target="#b20">Surdeanu and Ji (2014)</ref> suggests that 2014 ESF queries are more difficult than those for 2013. They compare two systems by running both on 2013 and 2014 data and find there is a con- siderable drop in the performance of both the sys- tems. We note that they run the same exact system on 2013 and 2014 data. Thus, in order to have a better understanding of our results, we plot a learn- ing curve by training on different sizes of the 2013 SFV data and using the scorer to measure the F1 score on the 2014 SFV data for the 10 common systems. <ref type="figure" target="#fig_2">Figure 3</ref> shows the learning curve thus obtained. Although there are certain parts of the dataset when the F1 score drops which we sus- pect is due to overfitting the 2013 data, there is still a strong correlation between the 2013 training data size and F1 score on the 2014 dataset. Thus we can infer that training on 2013 data is useful even though the 2013 and 2014 data are fairly dif- ferent. Although the queries change, the common systems remain more-or-less the same and stack- ing enables a meta-classifier to weigh those com- mon systems based on their 2013 performance. To further validate our approach, we divide the 2013 SFV data based on the systems that extracted those slot fills. Then we sort the systems, from higher to lower, based on the number of false pos- itives produced by them in the ensembling ap- proach. Next we train a classifier in an incremen- tal fashion adding one system's slot fills for train- ing at each step and analyzing the performance on 2014 data. This allows us to analyze the results at the system level. <ref type="figure" target="#fig_3">Figure 4</ref> shows the plot of F1 score vs. the number of systems at each step. The figure shows huge improvement in F1 score at steps 6 and 7. At step 6 the Stanford system is added to the pool of systems which is the best performing ESF system in 2014 and fourth best in 2013. At step 7, the UMass system is added to the pool and, although the system on it own is weak, it boosts the performance of our ensem- bling approach. This is because the UMass system alone contributes approximately 24% of the 2013 training data <ref type="figure" target="#fig_0">(Singh et al., 2013)</ref>. Thus adding this one system significantly improves the training step leading to better performance. We also no- tice that our system becomes less conservative at this step and has higher recall. The reason for this is that the systems from 1 to 5 had very high pre- cision and low recall whereas from system 6 on- wards the systems have high recall. Thus adding the UMass system enables our meta-classifier to have a higher recall for small decrease in precision and thus boosting the overall F1 measure. With- out it, the classifier produces high precision but low recall and decreases the overall F1 score by approximately 6 points.     <ref type="table">Table 8</ref>: Performance on the common systems dataset (10 systems) for various configurations using the unofficial scorer. All approaches except the UIUC system are our implementations.</p><p>SFV data.</p><p>The TAC KBP official scoring key for the ESF task includes human annotated slot fills along with the pooled slot fills obtained by all participating systems. However, <ref type="bibr" target="#b16">Sammons et al. (2014)</ref> use an unofficial scoring key in their paper that does not include human annotated slot fills. In order to compare to their results, we also present results using the same unofficial key. <ref type="table" target="#tab_7">Table 7</ref> gives the performance of our baseline systems on the 2014 SFV dataset using the unofficial key for scoring. We note that our Union does not produce a recall of 1.0 on the unofficial scorer due to our single- valued slot selection strategy for multiple systems. As discussed earlier for the single-valued slot, we include the slot fill with highest confidence (which may not necessarily be correct) and thus may not match the unofficial scorer. <ref type="table">Table 8</ref> gives the performance of all our super- vised approaches along with the baselines on the common systems dataset using the unofficial key for scoring. UIUC is one of the two teams par- ticipating in the SFV 2014 task and the only team to report results, but they report 6 different sys- tem configurations and we show their best perfor- mance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion</head><p>Our results indicate that stacking with provenance information and relation type gives the best perfor- mance using both the official ESF scorer as well as the unofficial scorer that excludes the human- generated slot fills. Our stacking approach that uses the 10 systems common between 2013 and 2014 also outperforms the ensembling baselines that have the advantage of using all 65 of the 2014 systems. Our stacking approach would presum- ably perform even better if we had access to 2013 training data for all 2014 systems.</p><p>Of course, the best-performing ESF system for 2014 did not have access to the pooled slot fills of all participating systems. Although pooling the results has an advantage, naive pooling meth- ods such as the ensembling baselines, in particu- lar the voting approach, do not perform as well as our stacked ensembles. Our best approach outper- forms the best baseline for both the datasets by at least 6 F1 points using both the official and unof-ficial scorer.</p><p>As expected the Union baseline has the highest recall. Among the supervised approaches, stack- ing with document provenance produces the high- est precision and is significantly higher (approx- imately 5%) than the approach that produces the second highest precision. As discussed earlier, we also scored our approaches on the unofficial scorer so that we can compare our results to the UIUC system that was the best performer in the 2014 SFV task. Our best approach beats their best sys- tem configuration by a F1 score of 12 points. Our stacking approach also outperforms them on pre- cision and recall by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Our system is part of a body of work on increas- ing the performance of relation extraction through ensemble methods.</p><p>The use of stacked generalization for informa- tion extraction has been demonstrated to outper- form both majority voting and weighted voting methods ( <ref type="bibr" target="#b17">Sigletos et al., 2005</ref>). In relation ex- traction, a stacked classifier effectively combines a supervised, closed-domain Conditional Ran- dom Field-based relation extractor with an open- domain CRF Open IE system, yielding a 10% in- crease in precision without harming recall ( <ref type="bibr" target="#b1">Banko et al., 2008)</ref>. To our knowledge, we are the first to apply stacking to KBP and the first to use prove- nance as a feature in a stacking approach.</p><p>Many KBP SFV systems cast validation as a single-document problem and apply a vari- ety of techniques, such as rule-based consistency checks ( <ref type="bibr" target="#b0">Angeli et al., 2013)</ref>, and techniques from the well-known Recognizing Textual Entailment (RTE) task <ref type="bibr" target="#b2">(Cheng et al., 2013;</ref><ref type="bibr" target="#b16">Sammons et al., 2014</ref>). In contrast, the 2013 JHUAPL system ag- gregates the results of many different extractors using a constraint optimization framework, ex- ploiting confidence values reported by each input system ( . A second approach in the UI CCG system ( <ref type="bibr" target="#b16">Sammons et al., 2014</ref>) aggre- gates results of multiple systems by using majority voting.</p><p>In the database, web-search, and data-mining communities, a line of research into "truth- finding" or "truth-discovery" methods addresses the related problem of combining evidence for facts from multiple sources, each with a latent credibility ( <ref type="bibr" target="#b26">Yin et al., 2008</ref>). The RPI BLENDER KBP system ( <ref type="bibr" target="#b9">Yu et al., 2014</ref>) casts SFV in this framework, using a graph propagation method that modeled the credibility of systems, sources, and response values. However they only report scores on the 2013 SFV data which contain less com- plicated and easier queries compared to the 2014 data. Therefore, we cannot directly compare our system's performance to theirs.</p><p>Google's Knowledge Vault system ( <ref type="bibr" target="#b5">Dong et al., 2014</ref>) combines the output of four diverse extrac- tion methods by building a boosted decision stump classifier <ref type="bibr" target="#b13">(Reyzin and Schapire, 2006</ref>). For each proposed fact, the classifier considers both the confidence value of each extractor and the number of responsive documents found by the extractor. A separate classifier is trained for each predicate, and Platt Scaling <ref type="bibr" target="#b12">(Platt, 1999</ref>) is used to calibrate confidence scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper has presented experimental results showing that stacking is a very promising ap- proach to ensembling KBP systems. From our literature survey, we observe that we are the first to employ stacking and combine it with prove- nance information to ensemble KBP systems. Our stacked meta-classifier provides an F1 score of 50.1% on 2014 KBP ESF, outperforming the best ESF and SFV systems from the 2014 competition, and thereby achieving a new state-of-the-art for this task. We found that provenance features in- creased accuracy, highlighting the importance of provenance information (even without accessing the source corpus) in addition to confidence scores for ensembling information extraction systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Precision-Recall curves for identifying the best voting performance on the two datasets</figDesc><graphic url="image-1.png" coords="5,100.04,62.81,192.75,144.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our system pipeline for evaluating supervised ensembling approaches Baseline Precision Recall F1 Union 0.067 0.762 0.122 Voting (threshold learned on 2013 data) 0.641 0.288 0.397 Voting (optimal threshold for 2014 data) 0.547 0.376 0.445</figDesc><graphic url="image-3.png" coords="6,94.68,62.81,408.19,58.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning curve for training on 2013 and testing on 2014 common systems dataset</figDesc><graphic url="image-4.png" coords="7,84.76,432.73,192.75,144.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Incrementally training on 2013 by adding a system at each step and testing on 2014 common systems dataset</figDesc><graphic url="image-5.png" coords="7,320.03,404.44,192.75,144.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : SF Output line fields</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Common teams for 2013 and 2014 ESF</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Performance of baselines on all 2014 SFV dataset (65 systems)</head><label>4</label><figDesc></figDesc><table>Approach 
Precision Recall 
F1 
Union 
0.176 
0.647 0.277 
Voting (threshold learned on 2013 data) 
0.694 
0.256 0.374 
Best ESF system in 2014 (Stanford) 
0.585 
0.298 0.395 
Voting (optimal threshold for 2014 data) 
0.507 
0.383 0.436 
Stacking 
0.606 
0.402 0.483 
Stacking + Relation 
0.607 
0.406 0.486 
Stacking + Provenance (document) 
0.499 
0.486 0.492 
Stacking + Provenance (document) + Relation 
0.653 
0.400 0.496 
Stacking + Provenance (document and offset) + Relation 
0.541 
0.466 0.501 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>The performance of using only the filler provenance is slightly worse than training on 2013 because the 2014 SFV data has many fewer instances but uses more systems for learning compared to the 2013</figDesc><table>Approach 

Precision Recall 
F1 
Stacking + Filler provenance + Relation 
0.606 
0.415 0.493 
Stacking + Filler and Relation provenance + Relation 
0.609 
0.434 0.506 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 : 10-fold Cross-Validation on 2014 SFV dataset (65 systems)</head><label>6</label><figDesc></figDesc><table>Baseline 
Precision Recall 
F1 
Union 
0.054 
0.877 0.101 
Voting (threshold learned on 2013 data) 
0.637 
0.406 0.496 
Voting (optimal threshold for 2014 data) 
0.539 
0.526 0.533 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Baseline performance on all 2014 SFV dataset (65 systems) using unofficial scorer 

Approach 
Precision Recall 
F1 
Union 
0.177 
0.922 0.296 
Voting (threshold learned on 2013 data) 
0.694 
0.256 0.374 
Best published SFV result in 2014 (UIUC) 
0.457 
0.507 0.481 
Voting (optimal threshold for 2014 data) 
0.507 
0.543 0.525 
Stacking + Provenance(document) 
0.498 
0.688 0.578 
Stacking 
0.613 
0.562 0.586 
Stacking + Relation 
0.613 
0.567 0.589 
Stacking + Provenance (document and offset) + Relation 
0.541 
0.661 0.595 
Stacking + Provenance (document) + Relation 
0.659 
0.56 
0.606 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>We thank the anonymous reviewers for their valu-able feedback. This research was supported by the DARPA DEFT program under AFRL grant FA8750-13-2-0026.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stanford&apos;s 2013 KBP system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Chaganty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osbert</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Bastani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Siilats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference (TAC2013)</title>
		<meeting>the Sixth Text Analysis Conference (TAC2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The tradeoffs between open and traditional relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Turing</forename><surname>Center</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Illinois cognitive computation group UI-CCG TAC 2013 entity linking and slot filler validation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingling</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajhans</forename><surname>Samdani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiye</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chizheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference (TAC2013)</title>
		<meeting>the Sixth Text Analysis Conference (TAC2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First International Workshop on Multiple Classifier Systems</title>
		<editor>J. Kittler and F. Roli</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Markov logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parag</forename><surname>Singla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probabilistic Inductive Logic Programming</title>
		<editor>Luc De Raedt, Paolo Frasconi, Kristian Kersting, and Stephen Muggleton</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">4911</biblScope>
			<biblScope unit="page" from="92" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The WEKA data mining software: an update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploiting diversity in natural language processing: Combining parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP/VLC-99)<address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">RPI BLENDER TAC-KBP2014 knowledge base population system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongtao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Text Analysis Conference</title>
		<meeting>the Seventh Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple approach to building ensembles of naive Bayesian classifiers for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Meeting of the North American Association for Computational Linguistics</title>
		<meeting>the Meeting of the North American Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="63" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<editor>Peter J. Bartlett, Bernhard Schölkopf, Dale Schuurmans, and Alex J. Smola</editor>
		<meeting><address><addrLine>Boston</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How boosting the margin can also boost classifier complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Reyzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting>the 23rd International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="753" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crosslanguage retrieval using link-based language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Klakow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="773" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Effective slot filling based on shallow distant supervision methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tassilo</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Text Analysis Conference (TAC2013)</title>
		<meeting>the Seventh Text Analysis Conference (TAC2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Overview of UI-CCG systems for event argument extraction, entity discovery and linking, and slot filler validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gourab</forename><surname>Kundu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Proceedings of the Seventh Text Analysis Conference (TAC2014)</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Combining information extraction systems using voting and stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Sigletos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michalis</forename><surname>Hatzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1751" to="1782" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Sill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Takács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lester</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0911.0460</idno>
		<title level="m">Feature-weighted linear stacking</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Kobren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Anzaroot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshal</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m">Universal schema for slot filling and cold start: UMass IESL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Overview of the English slot filling track at the TAC2014 Knowledge Base Population Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Text Analysis Conference (TAC2014)</title>
		<meeting>the Seventh Text Analysis Conference (TAC2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Overview of the TAC2013 knowledge base population evaluation: English slot filling and temporal slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference</title>
		<meeting>the Sixth Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">JHUAPL TAC-KBP2013 slot filler validation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Jeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwina</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Piatko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Text Analysis Conference (TAC2013)</title>
		<meeting>the Sixth Text Analysis Conference (TAC2013)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">TAC KBP 2014 : English slot filling track DeepDive with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Wazalwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jude</forename><surname>Shavlik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriraam</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Text Analysis Conference</title>
		<meeting>the Seventh Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentiment mining using ensemble classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Yaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Innovations and Advances in Computer Sciences and Engineering</title>
		<editor>Tarek Sobh</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolpert</surname></persName>
		</author>
		<title level="m">Stacked generalization. Neural Networks</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Truth discovery with multiple conflicting information providers on the web. Knowledge and Data Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Xiaoxin Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="796" to="808" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The wisdom of minority: Unsupervised slot filling validation based on multidimensional truth-finding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Magdon-Ismail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The 25th International Conference on Computational Linguistics</title>
		<meeting>The 25th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
