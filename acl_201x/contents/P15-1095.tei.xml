<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Subgraph Generation Improves Abstract Meaning Representation Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keenon</forename><surname>Werling</surname></persName>
							<email>keenon@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
							<email>angeli@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
							<email>manning@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Subgraph Generation Improves Abstract Meaning Representation Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="982" to="991"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The Abstract Meaning Representation (AMR) is a representation for open-domain rich semantics, with potential use in fields like event extraction and machine translation. Node generation, typically done using a simple dictionary lookup, is currently an important limiting factor in AMR parsing. We propose a small set of actions that derive AMR subgraphs by transformations on spans of text, which allows for more robust learning of this stage. Our set of construction actions generalize better than the previous approach , and can be learned with a simple classifier. We improve on the previous state-of-the-art result for AMR parsing , boosting end-to-end performance by 3 F 1 on both the LDC2013E117 and LDC2014T12 datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Abstract Meaning Representation (AMR) ( <ref type="bibr" target="#b0">Banarescu et al., 2013</ref>) is a rich, graph-based lan- guage for expressing semantics over a broad do- main. The formalism is backed by a large data- labeling effort, and it holds promise for enabling a new breed of natural language applications rang- ing from semantically aware MT to rich broad- domain QA over text-based knowledge bases. <ref type="figure" target="#fig_0">Fig- ure 1</ref> shows an example AMR for "he gleefully ran to his dog Rover," and we give a brief introduction to AMR in Section 2. This paper focuses on AMR parsing, the task of mapping a natural language sentence into an AMR graph.</p><p>We follow previous work <ref type="bibr" target="#b10">(Flanigan et al., 2014</ref>) in dividing AMR parsing into two steps. The first step is concept identification, which generates AMR nodes from text, and which we'll refer to as NER++ (Section 3.1). The second step is relation identification, which adds arcs to link these nodes into a fully connected AMR graph, which we'll call SRL++ (Section 3.2).</p><p>We observe that SRL++ is not the hard part of AMR parsing; rather, much of the difficulty in AMR is generating high accuracy concept sub- graphs from the NER++ component. For example, when the existing AMR parser JAMR ( <ref type="bibr" target="#b10">Flanigan et al., 2014</ref>) is given a gold NER++ output, and must only perform SRL++ over given subgraphs it scores 80 F 1 -nearly the inter-annotator agree- ment of 83 F 1 , and far higher than its end to end accuracy of 59 F 1 .</p><p>SRL++ within AMR is relatively easy given a perfect NER++ output, because so much pressure is put on the output of NER++ to carry meaningful information. For example, there's a strong type- check feature for the existence and type of any arc just by looking at its end-points, and syntactic de- pendency features are very informative for remov- ing any remaining ambiguity. If a system is con- <ref type="figure">Figure 2</ref>: A graphical explanation of our method. We represent the derivation process for He gleefully ran to his dog Rover. First the tokens in the sentence are labeled with derivation actions, then these actions are used to generate AMR subgraphs, which are then stitched together to form a coherent whole. sidering how to link the node run-01 in <ref type="figure" target="#fig_0">Figure 1</ref>, the verb-sense frame for "run-01" leaves very little uncertainty for what we could assign as an ARG0 arc. It must be a noun, which leaves either he or dog, and this is easily decided in favor of he by looking for an nsubj arc in the dependency parse.</p><p>The primary contribution of this paper is a novel approach to the NER++ task, illustrated in Fig- ure 2. We notice that the subgraphs aligned to lexi- cal items can often be generated from a small set of generative actions which generalize across tokens. For example, most verbs generate an AMR node corresponding to the verb sense of the appropri- ate PropBank frame -e.g., run generates run-01 in <ref type="figure" target="#fig_0">Figure 1</ref>. This allows us to frame the NER++ task as the task of classifying one of a small num- ber of actions for each token, rather than choosing a specific AMR subgraph for every token in the sentence.</p><p>Our approach to the end-to-end AMR parsing task is therefore as follows: we define an action space for generating AMR concepts, and create a classifier for classifying lexical items into one of these actions (Section 4). This classifier is trained from automatically generated alignments between the gold AMR trees and their associated sentences (Section 5), using an objective which fa- vors alignment mistakes which are least harmful to the NER++ component. Finally, the concept sub- graphs are combined into a coherent AMR parse using the maximum spanning connected subgraph algorithm of <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref>.</p><p>We show that our approach provides a large boost to recall over previous approaches, and that end to end performance is improved from 59 to 62 smatch (an F 1 measure of correct AMR arcs; see <ref type="bibr" target="#b4">Cai and Knight (2013)</ref>) when incorporated into the SRL++ parser of <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref>. When evaluating the performance of our action classifier in isolation, we obtain an action classification ac- curacy of 84.1%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The AMR Formalism</head><p>AMR is a language for expressing semantics as a rooted, directed, and potentially cyclic graph, where nodes represent concepts and arcs are re- lationships between concepts. AMR is based on neo-Davidsonian semantics, <ref type="bibr" target="#b8">(Davidson, 1967;</ref><ref type="bibr" target="#b22">Parsons, 1990)</ref>. The nodes (concepts) in an AMR graph do not have to be explicitly grounded in the source sentence, and while such an alignment is often generated to train AMR parsers, it is not pro- vided in the training corpora. The semantics of nodes can represent lexical items (e.g., dog), sense tagged lexical items (e.g., run-01), type markers (e.g., date-entity), and a host of other phenomena.</p><p>The edges (relationships) in AMR describe one of a number of semantic relationships between concepts. The most salient of these is seman- tic role labels, such as the ARG0 and destination arcs in <ref type="figure">Figure 2</ref>. However, often these arcs define <ref type="figure">Figure 3</ref>: AMR representation of the word sailor, which is notable for breaking the word up into a self-contained multi-node unit unpacking the derivational morphology of the word.</p><p>a semantics more akin to syntactic dependencies (e.g., mod standing in for adjective and adverbial modification), or take on domain-specific mean- ing (e.g., the month, day, and year arcs of a date- entity).</p><p>To introduce AMR and its notation in more de- tail, we'll unpack the translation of the sentence "he gleefully ran to his dog Rover." We show in <ref type="figure" target="#fig_0">Figure 1</ref> the interpretation of this sentence as an AMR graph.</p><p>The root node of the graph is labeled run-01, corresponding to the PropBank ( <ref type="bibr" target="#b21">Palmer et al., 2005</ref>) definition of the verb ran. run-01 has an outgoing ARG0 arc to a node he, with the usual PropBank semantics. The outgoing mod edge from run-01 to glee takes a general purpose se- mantics corresponding to adjective, adverbial, or other modification of the governor by the depen- dent. We note that run-01 has a destination arc to dog. The label for destination is taken from a finite set of special arc sense tags similar to the prepo- sition senses found in <ref type="bibr" target="#b25">(Srikumar, 2013)</ref>. The last portion of the figure parses dog to a node which serves as a type marker similar to named entity types, and Rover into the larger subgraph indicat- ing a concept with name "Rover."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">AMR Subgraphs</head><p>The mapping from tokens of a sentence to AMR nodes is not one-to-one. A single token or span of tokens can generate a subgraph of AMR con- sisting of multiple nodes. These subgraphs can logically be considered the expression of a single concept, and are useful to treat as such (e.g., see Section 3.1).</p><p>Many of these multi-node subgraphs capture structured data such as time expressions, as in <ref type="figure">Fig-  Figure 4</ref>: AMR representation of the span Jan- uary 1, 2008, an example of how AMR can rep- resent structured data by creating additional nodes such as date-entity to signify the presence of spe- cial structure. ure 4. In this example, a date-entity node is cre- ated to signify that this cluster of nodes is part of a structured sub-component representing a date, where the nodes and arcs within the component have specific semantics. This illustrates a broader recurring pattern in AMR: an artificial node may, based on its title, have expected children with spe- cial semantics. A particularly salient example of this pattern is the name node (see "Rover" in <ref type="figure" target="#fig_0">Fig- ure 1</ref>) which signifies that all outgoing arcs with label op comprise the tokens of a name object.</p><p>The ability to decouple the meaning representa- tion of a lexical item from its surface form allows for rich semantic interpretations of certain con- cepts in a sentence. For example, the token sailor is represented in <ref type="figure">Figure 3</ref> by a concept graph rep- resenting a person who performs the action sail- 01. Whereas often the AMR node aligned to a span of text is a straightforward function of the text, these cases remain difficult to capture in a principled way beyond memorizing mappings be- tween tokens and subgraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Decomposition</head><p>To the best of our knowledge, the JAMR parser is the only published end-to-end AMR parser at the time of publication. An important insight in JAMR is that AMR parsing can be broken into two distinct tasks: (1) NER++ (concept identifi- cation): the task of interpreting what entities are being referred to in the text, realized by gener- ating the best AMR subgraphs for a given set of tokens, and (2) SRL++ (relation identification): the task of discovering what relationships exist be- tween entities, realized by taking the disjoint sub- graphs generated by NER++ and creating a fully- connected graph. We describe both tasks in more detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NER++</head><p>Much of the difficulty of parsing to AMR lies in generating local subgraphs representing the mean- ing of token spans. For instance, the formalism implicitly demands rich notions of NER, lemma- tization, word sense disambiguation, number nor- malization, and temporal parsing; among others. To illustrate, a correct parse of the sentence in Fig- ure 2 requires lemmatization (gleefully → glee), word sense tagging (run → run-01), and open do- main NER (i.e., Rover), Furthermore, many of the generated subgraphs (e.g., sailor in <ref type="figure">Figure 3</ref>) have rich semantics beyond those produced by standard NLP systems.</p><p>Formally, NER++ is the task of generating a disjoint set of subgraphs representing the mean- ings of localized spans of words in the sentence. For NER++, JAMR uses a simple Viterbi sequence model to directly generate AMR-subgraphs from memorized mappings of text spans to subgraphs. This paper's main contribution, presented in Sec- tion 4, is to make use of generative actions to gen- erate these subgraphs, rather than appealing to a memorized mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SRL++</head><p>The second stage of the AMR decomposition con- sists of generating a coherent graph from the set of disjoint subgraphs produced by NER++. Whereas NER++ produces subgraphs whose arcs encode domain-specific semantics (e.g., month), the arcs in SRL++ tend to have generally applicable se- mantics. For example, the many arcs encode con- ventional semantic roles (e.g., ARG0 and desti- nation in <ref type="figure">Figure 2</ref>), or a notion akin to syntac- tic dependencies (e.g., mod and poss in <ref type="figure">Figure 2</ref>). For SRL++, JAMR uses a variation of the max- imum spanning connected graph algorithm aug- mented by dual decomposition to impose linguis- tically motivated constraints on a maximum likeli- hood objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Novel NER++ Method</head><p>The training sets currently available for AMR are not large. To illustrate, 38% of the words in the LDC2014E113 dev set are unseen during training time. With training sets this small, memorization- based approaches are extremely brittle. We re- move much of the necessity to memorize map- pings in NER++ by partitioning the AMR sub- graph search space in terms of the actions needed to derive a node from its aligned token. At test time we do a sequence labeling of input tokens with these actions, and then deterministically de- rive the AMR subgraphs from spans of tokens by applying the transformation decreed by their actions. We explain in Section 4.1 how exactly we manage this partition, and in Section 4.3 how we create training data from existing resources to setup and train an action-type classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Derivation actions</head><p>We partition the AMR subgraph space into a set of 9 actions, each corresponding to an action that will be taken by the NER++ system if a token receives this classification.</p><p>IDENTITY This action handles the common case that the title of the node corresponding to a token is identical to the source token. To execute the action, we take the lowercased version of the token to be the title of the corresponding node.</p><p>NONE This action corresponds to ignoring this token, in the case that the node should not align to any corresponding AMR fragment.</p><p>VERB This action captures the verb-sense dis- ambiguation feature of AMR. To execute on a to- ken, we find the most similar verb in PropBank based on Jaro-Winkler distance, and adopt its most frequent sense. This serves as a reasonable base- line for word sense disambiguation, although of course accuracy would be expected to improve if a sophisticated system were incorporated.</p><p>VALUE This action interprets a token by its in- teger value. The AMR representation is sensitive to the difference between a node with a title of 5 (the integer value) and "5" or "five" -the string value. This is a rare action, but is nonetheless dis- tinct from any of the other classes. We execute this action by extracting an integer value with a regex based number normalizer, and using the result as the title of the generated node.</p><p>LEMMA AMR often performs stemming and part-of-speech transformations on the source to- ken in generating a node. For example, we get glee from gleefully. We capture this by a LEMMA action, which is executed by using the lemma of the source token as the generated node title. Note that this does not capture all lemmatizations, as there are often discrepancies between the lemma generated by the lemmatizer and the correct AMR lemma.</p><p>NAME AMR often references names with a special structured data type: the name construc- tion. For example, Rover in <ref type="figure" target="#fig_0">Figure 1</ref>. We can capture this phenomenon on unseen names by at- taching a created name node to the top of a span.</p><p>PERSON A variant of the NAME action, this action produces a subgraph identical to the NAME action, but adds a node person as a parent. This is, in effect, a name node with an implicit entity type of person. Due to discrepancies between the output of our named entity tagger and the richer AMR named entity ontology, we only apply this tag to the person named entity tag.</p><p>DATE The most frequent of the structured data type in the data, after name, is the date-entity con- struction (for an example see <ref type="figure">Figure 4</ref>). We de- terministically take the output of SUTime (Chang and Manning, 2012) and convert it into the date- entity AMR representation.</p><p>DICT This class serves as a back-off for the other classes, implementing an approach similar to <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref>. In particular, we mem- orize a simple mapping from spans of text (such as sailor) to their corresponding most frequently aligned AMR subgraphs in the training data (i.e., the graph in <ref type="figure">Figure 3</ref>). See Section 5 for details on the alignment process. At test time we can do a lookup in this dictionary for any element that gets labeled with a DICT action. If an entry is not found in the mapping, we back off to the second most probable class proposed by the classifier.</p><p>It is worth observing at this point that our ac- tions derive much of their power from the similar- ity between English words and their AMR coun- terparts; creating an analogue of these actions for other languages remains an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Action Reliability</head><p>In many cases, multiple actions could yield the same subgraph when applied to a node. In this section we introduce a method for resolving this ambiguity based on comparing the reliability with which actions generate the correct subgraph, and discuss implications.</p><p>Even given a perfect action classification for a token, certain action executions can introduce <ref type="figure">Figure 5</ref>: Reliability of each action. The top row are actions which are deterministic; the second row occasionally produce errors. DICT is the least preferred action, with a relatively high error rate.</p><p>errors. Some of our actions are entirely deter- ministic in their conversion from the word to the AMR subgraph (e.g., IDENTITY), but others are prone to making mistakes in this conversion (e.g., VERB, DICT). We define the notion of action re- liability as the probability of deriving the correct node from a span of tokens, conditioned on hav- ing chosen the correct action.</p><p>To provide a concrete example, our dictionary lookup classifier predicts the correct AMR sub- graph 67% of the time on the dev set. We therefore define the reliability of the DICT action as 0.67. In contrast to DICT, correctly labeling a node as IDENTITY, NAME, PERSON, and NONE have action reliability of 1.0, since there is no ambigu- ity in the node generation once one of those ac- tions have been selected, and we are guaranteed to generate the correct node given the correct action.</p><p>We can therefore construct a hierarchy of reli- ability ( <ref type="figure">Figure 5</ref>) -all else being equal, we pre- fer to generate actions from higher in the hierar- chy, as they are more likely to produce the cor- rect subgraph. This hierarchy is useful in resolv- ing ambiguity throughout our system. During the creation of training data for our classifier (Sec- tion 4.3) from our aligner, when two actions could both generate the aligned AMR node we prefer the more reliable one. In turn, in our aligner we bias alignments towards those which generating more reliable action sequences as training data (see Sec- tion 5).</p><p>The primary benefit of this action-based NER++ approach is that we can reduce the us- age of low reliability actions, like DICT. The approach taken in <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref>   We analyze the empirical distribution of actions in our automatically aligned corpus in <ref type="table">Table 1</ref>. The cumulative frequency of the non-DICT ac- tions is striking: we can generate 74% of the to- kens with high reliability (p ≥ 0.9) actions. In this light, it is unsurprising that our results demonstrate a large gain in recall on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training the Action Classifier</head><p>Given a set of AMR training data, in the form of (graph, sentence) pairs, we first induce alignments from the graph nodes to the sentence (see Sec- tion 5). Formally, for every node n i in the AMR graph, alignment gives us some token s j (at the jth index in the sentence) that we believe gener- ated the node n i .</p><p>Then, for each action type, we can ask whether or not that action type is able to take token s j and correctly generate n i . For concreteness, imagine the token s j is running, and the node n i has the title run-01. The two action types we find that are able to correctly generate this node are DICT and VERB. We choose the most reliable action type of those available (see <ref type="figure">Figure 5</ref>) to generate the observed node -in this case, VERB.</p><p>In cases where an AMR subgraph is generated from multiple tokens, we assign the action label to each token which generates the subgraph. Each of these tokens are added to the training set; at test time, we collapse sequences of adjacent identical action labels, and apply the action once to the re- sulting token span.</p><p>Inducing the most reliable action (according to the alignments) for every token in the training cor- pus provides a supervised training set for our ac- tion classifier, with some noise introduced by the automatically generated alignments. We then train a simple maxent classifier 1 to make action deci- sions at each node. At test time, the classifier takes as input a pair i, S, where i is the index of the to- ken in the input sentence, and S is a sequence to- kens representing the source sentence. It then uses the features in <ref type="table" target="#tab_1">Table 2</ref> to predict the actions to take at that node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Automatic Alignment of Training Data</head><p>AMR training data is in the form of bi-text, where we are given a set of (sentence, graph) pairs, with no explicit alignments between them. We would like to induce a mapping from each node in the AMR graph to the token it represents. It is per- fectly possible for multiple nodes to align to the same token -this is the case with sailors, for in- stance.</p><p>It is not possible, within our framework, to rep- resent a single node being sourced from multi- ple tokens. Note that a subgraph can consist of many individual nodes; in cases where a subgraph should align to multiple tokens, we generate an alignment from the subgraph's nodes to the associ- ated tokens in the sentence. It is empirically very rare for a subgraph to have more nodes than the token span it should align to.</p><p>There have been two previous attempts at pro- ducing automatic AMR alignments. The first was published as a component of JAMR, and used a rule-based approach to perform alignments. This was shown to work well on the sample of 100 hand-labeled sentences used to develop the sys- tem. <ref type="bibr" target="#b23">Pourdamghani et al. (2014)</ref> approached the alignment problem in the framework of the IBM alignment models. They rendered AMR graphs as text, and then used traditional machine translation alignment techniques to generate an alignment.</p><p>We propose a novel alignment method, since our decomposition of the AMR node generation process into a set of actions provides an additional objective for the aligner to optimize, in addition to the accuracy of the alignment itself. We would like to produce the most reliable sequence of actions for the NER++ model to train from, where reliable is taken in the sense defined in Section 4.2. To give an example, a sequence of all DICT actions could generate any AMR graph, but is very low reliabil- ity. A sequence of all IDENTITY actions could only generate one set of nodes, but does it with absolute certainty.</p><p>We formulate this objective as a Boolean LP problem. Let Q be a matrix in {0, 1} |N|×|S| of Boolean constrained variables, where N are the nodes in an AMR graph, and S are the tokens in the sentence. The meaning of Q i,j = 1 can be interpreted as node n i having being aligned to to- ken s j . Furthermore, let V be a matrix T |N|×|S| , where T is the set of NER++ actions from Sec- tion 4. Each matrix element V i,j is assigned the most reliable action which would generate node n i from token s j . We would like to maximize the probability of the actions collectively generating a perfect set of nodes. This can be formulated lin- early by maximizing the log-likelihood of the ac- tions. Let the function REL(l) be the reliability of action l (probability of generating intended node). Our objective can then be formulated as follows:</p><formula xml:id="formula_0">max Q i,j Q i,j [log(REL(V i,j )) + αE i,j ]<label>(1)</label></formula><formula xml:id="formula_1">s.t. j Q i,j = 1 ∀i (2) Q k,j + Q l,j ≤ 1 ∀k, l, j; n k n l (3)</formula><p>where E is the Jaro-Winkler similarity between the title of the node i and the token j, α is a hyper- parameter (set to 0.8 in our experiments), and the operator denotes that two nodes in the AMR graph are both not adjacent and do not have the same title.</p><p>The constraint <ref type="formula">(2)</ref>, combined with the binary constraint on Q, ensures that every node in the graph is aligned to exactly one token in the source sentence. The constraint (3) ensures that only ad- jacent nodes or nodes that share a title can refer to the same token.</p><p>The objective value penalizes alignments which map to the unreliable DICT tag, while rewarding alignments with high overlap between the title of the node and the token. Note that most incorrect alignments fall into the DICT class by default, as no other action could generate the correct AMR subgraph. Therefore, if there exists an alignment that would consume the token using another ac- tion, the optimization prefers that alignment. The Jaro-Winkler similarity term, in turn, serves as a tie-breaker between equally (un)reliable align- ments.</p><p>There are many packages which can solve this Boolean LP efficiently. We used Gurobi <ref type="bibr">(Gurobi Optimization, 2015)</ref>. Given a matrix Q that maximizes our objective, we can decode our solved alignment as follows: for each i, align n i to the j s.t. Q i,j = 1. By our constraints, exactly one such j must exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Prior work in AMR and related formalisms in- clude <ref type="bibr" target="#b14">Jones et al. (2012)</ref>, and <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref>. <ref type="bibr" target="#b14">Jones et al. (2012)</ref>, motivated by appli- cations in Machine Translation, proposed a graph- ical semantic meaning representation that predates AMR, but is intimately related. They propose a hyper-edge replacement grammar (HRG) ap- proach to parsing into and out of this graphical semantic form. <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> forms the basis of the approach of this paper. Their system introduces the two-stage approach we use: they implement a rule-based alignment to learn a map- ping from tokens to subgraphs, and train a vari- ant of a maximum spanning tree parser adapted to graphs and with additional constraints for their re- lation identifications (SRL++) component. <ref type="bibr" target="#b28">Wang et al. (2015)</ref> uses a transition based algorithm to transform dependency trees into AMR parses. They achieve 64/62/63 P/R/F 1 with contributions roughly orthogonal to our own. Their transforma- tion action set could be easily augmented by the robust subgraph generation we propose here, al- though we leave this to future work.</p><p>Beyond the connection of our work with Flani-gan et al. <ref type="formula" target="#formula_0">(2014)</ref>, we note that the NER++ com- ponent of AMR encapsulates a number of lex- ical NLP tasks. These include named entity recognition ( <ref type="bibr" target="#b20">Nadeau and Sekine, 2007;</ref><ref type="bibr" target="#b9">Finkel et al., 2005</ref>), word sense disambiguation <ref type="bibr" target="#b29">(Yarowsky, 1995;</ref><ref type="bibr" target="#b1">Banerjee and Pedersen, 2002</ref>), lemmatiza- tion, and a number of more domain specific tasks. For example, a full understanding of AMR re- quires normalizing temporal expressions <ref type="bibr" target="#b27">(Verhagen et al., 2010;</ref><ref type="bibr" target="#b26">Strötgen and Gertz, 2010;</ref><ref type="bibr" target="#b6">Chang and Manning, 2012</ref>).</p><p>In turn, the SRL++ facet of AMR takes many insights from semantic role labeling ( <ref type="bibr" target="#b11">Gildea and Jurafsky, 2002;</ref><ref type="bibr" target="#b24">Punyakanok et al., 2004;</ref><ref type="bibr" target="#b25">Srikumar, 2013;</ref><ref type="bibr" target="#b7">Das et al., 2014</ref>) to capture the rela- tions between verbs and their arguments. In addi- tion, many of the arcs in AMR have nearly syntac- tic interpretations (e.g., mod for adjective/adverb modification, op for compound noun expressions). These are similar to representations used in syn- tactic dependency parsing ( <ref type="bibr">de Marneffe and Manning, 2008;</ref><ref type="bibr" target="#b18">McDonald et al., 2005;</ref><ref type="bibr" target="#b3">Buchholz and Marsi, 2006</ref>).</p><p>More generally, parsing to a semantic represen- tation is has been explored in depth for when the representation is a logical form ( <ref type="bibr" target="#b15">Kate et al., 2005;</ref><ref type="bibr" target="#b30">Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b17">Liang et al., 2011</ref>). Recent work has applied semantic parsing tech- niques to representations beyond lambda calculus expressions. For example, work by <ref type="bibr" target="#b2">Berant et al. (2014)</ref> parses text into a formal representation of a biological process. <ref type="bibr" target="#b13">Hosseini et al. (2014)</ref> solves algebraic word problems by parsing them into a structured meaning representation. In contrast to these approaches, AMR attempts to capture open domain semantics over arbitrary text.</p><p>Interlingua ( <ref type="bibr" target="#b19">Mitamura et al., 1991;</ref><ref type="bibr" target="#b5">Carbonell et al., 1999;</ref><ref type="bibr" target="#b16">Levin et al., 1998</ref>) are an important in- spiration for decoupling the semantics of the AMR language from the surface form of the text being parsed; although, AMR has a self-admitted En- glish bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>We present improvements in end-to-end AMR parsing on two datasets using our NER++ compo- nent. Action type classifier accuracy on an auto- matically aligned corpus and alignment accuracy on a small hand-labeled corpus are also reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>System P R F 1 2014T12 JAMR 67.1 53.2 59.3 Our System 66.6 58.3 62.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2013E117</head><p>JAMR 66.9 52.9 59.1 Our System 65.9 59.0 62.3 <ref type="table">Table 3</ref>: Results on two AMR datasets for JAMR and our NER++ embedded in the JAMR SRL++ component. Note that recall is consistently higher across both datasets, with only a small loss in pre- cision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">End-to-end AMR Parsing</head><p>We evaluate our NER++ component in the context of end-to-end AMR parsing on two corpora: the newswire section of LDC2014T12 and the split given in <ref type="bibr" target="#b10">Flanigan et al. (2014)</ref> of LDC2013E117, both consisting primarily of newswire. We com- pare two systems: the JAMR parser ( <ref type="bibr" target="#b10">Flanigan et al., 2014</ref>), 2 and the JAMR SRL++ component with our NER++ approach.</p><p>AMR parsing accuracy is measured with a met- ric called smatch <ref type="bibr" target="#b4">(Cai and Knight, 2013)</ref>, which stands for "s(emantic) match." The metric is the F 1 of a best-match between triples implied by the tar- get graph, and triples in the parsed graph -that is, the set of (parent, edge, child) triples in the graph.</p><p>Our results are given in <ref type="table">Table 3</ref>. We report much higher recall numbers on both datasets, with only small (≤ 1 point) loss in precision. This is natural considering our approach. A better NER++ system allows for more correct AMR sub- graphs to be generated -improving recall -but does not in itself necessarily improve the accuracy of the SRL++ system it is integrated in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Component Accuracy</head><p>We evaluate our aligner on a small set of 100 hand- labeled alignments, and evaluate our NER++ clas- sifier on automatically generated alignments over the whole corpus, On a hand-annotated dataset of 100 AMR parses from the LDC2014T12 corpus, 3 our aligner achieves an accuracy of 83.2. This is a measure- ment of the percentage of AMR nodes that are aligned to the correct token in their source sen- tence. Note that this is a different metric than the precision/recall of prior work on alignments, and is based on both a different alignment dataset and subtly different alignment annotation scheme. In particular, we require that every AMR node aligns to some token in the sentence, which forces the system to always align nodes, even when unsure. A standard semantics and annotation guideline for AMR alignment is left for future work; our accu- racy should be considered only an informal metric.</p><p>We find our informativeness-based alignment objective slightly improves end-to-end perfor- mance when compared to the rule-based approach of ( <ref type="bibr" target="#b10">Flanigan et al., 2014</ref>), improving F 1 by roughly 1 point (64/59/61 P/R/F 1 to 65/59/62 P/R/F 1 ).</p><p>On the automatic alignments over the LDC2014T12 corpus, our action classifier achieved a test accuracy of 0.841. The classifier's most common class of mistakes are incorrect DICT classifications. It is reassuring that some of these errors can be recovered from by the na¨ıvena¨ıve dictionary lookup finding the correct mapping.</p><p>The DICT action lookup table achieved an ac- curacy of 0.67. This is particularly impressive given that our model moves many of the difficult semantic tasks onto the DICT tag, and that this lookup does not make use of any learning beyond a simple count of observed span to subgraph map- pings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We address a key challenge in AMR parsing: the task of generating subgraphs from lexical items in the sentence. We show that a simple classi- fier over actions which generate these subgraphs improves end-to-end recall for AMR parsing with only a small drop in precision, leading to an over- all gain in F 1 . A clear direction of future work is improving the coverage of the defined actions. For example, a richer lemmatizer could shift the bur- den of lemmatizing unknown words into the AMR lemma semantics and away from the dictionary lookup component. We hope our decomposition provides a useful framework to guide future work in NER++ and AMR in general.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The AMR graph for He gleefully ran to his dog Rover. We show that improving the generation of low level subgraphs (e.g., Rover generating name :op1 −−→ "Rover") significantly improves end-to-end performance.</figDesc><graphic url="image-1.png" coords="1,354.91,204.54,123.00,165.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The features for the NER++ maxent clas-
sifier. 

thought of as equivalent to classifying every token 
as the DICT action. 
</table></figure>

			<note place="foot" n="1"> A sequence model was tried and showed no improvement over a simple maxent classifier.</note>

			<note place="foot" n="2"> Available at https://github.com/jflanigan/ jamr. 3 Our dataset is publicly available at http://nlp. stanford.edu/projects/amr</note>

			<note place="foot">Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their thoughtful feedback. Stanford University grate-fully acknowledges the support of the Defense Ad-vanced Research Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract no. FA8750-13-2-0040. Any opinions, findings, and conclusion or recommendations ex-pressed in this material are those of the authors and do not necessarily reflect the view of the DARPA, AFRL, or the US government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Linguistic Annotation Workshop</title>
		<meeting>Linguistic Annotation Workshop<address><addrLine>Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An adapted Lesk algorithm for word sense disambiguation using wordnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational linguistics and intelligent text processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling biological processes for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abby</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vander Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP<address><addrLine>Brittany Harding, and Peter Clark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CONLL-X shared task on multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The KANT perspective: A critique of pure transfer (and pure interlingua</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Jaime G Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nyberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>pure statistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">SUTIME: a library for recognizing and normalizing time expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Framesemantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The logical form of action sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Davidson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Logic of Decision and Action</title>
		<editor>Nicholas Rescher</editor>
		<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<publisher>Pittsburgh Press</publisher>
			<date type="published" when="1967" />
			<biblScope unit="page" from="81" to="120" />
		</imprint>
		<respStmt>
			<orgName>University of</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by Gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="245" to="288" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Gurobi optimizer reference manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Inc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gurobi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Optimization</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to solve arithmetic word problems with verb categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad Javad</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><surname>Kushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantics-based machine translation with hyperedge replacement grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bevan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1359" to="1376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to transform natural to formal languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An interlingua based on domain actions for machine translation of task-oriented dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donna</forename><surname>Lori S Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSLP</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="1155" to="1158" />
		</imprint>
	</monogr>
	<note>Alon Lavie, and Alex Waibel</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An efficient interlingua translation system for multi-lingual document production. Proceedings of Machine Translation Summit III</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime G</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carbonell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey of named entity recognition and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Nadeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lingvisticae Investigationes</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Events in the Semantics of English: A study in subatomic semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Parsons</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Aligning english strings with abstract meaning representation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semantic role labeling via integer linear programming inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dav</forename><surname>Zimak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics, page 1346. Association for Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics, page 1346. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The semantics of role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of Illinois at UrbanaChampaign</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Heideltime: High quality rule-based extraction and normalization of temporal expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jannik</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation<address><addrLine>Sem-Eval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<title level="m">Semeval-2010 task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A transition-based algorithm for amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<editor>NAACL-HLT</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised word sense disambiguation rivaling supervised methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
