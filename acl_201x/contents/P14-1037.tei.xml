<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Zero-shot Entity Extraction from Web Pages</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
							<email>ppasupat@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Zero-shot Entity Extraction from Web Pages</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="391" to="401"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In order to extract entities of a fine-grained category from semi-structured data in web pages, existing information extraction systems rely on seed examples or redundancy across multiple web pages. In this paper, we consider a new zero-shot learning task of extracting entities specified by a natural language query (in place of seeds) given only a single web page. Our approach defines a log-linear model over latent extraction predicates, which select lists of entities from the web page. The main challenge is to define features on widely varying candidate entity lists. We tackle this by abstracting list elements and using aggregate statistics to define features. Finally, we created a new dataset of diverse queries and web pages, and show that our system achieves significantly better accuracy than a natural baseline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We consider the task of extracting entities of a given category (e.g., hiking trails) from web pages. Previous approaches either (i) assume that the same entities appear on multiple web pages, or (ii) require information such as seed examples <ref type="bibr" target="#b8">(Etzioni et al., 2005</ref>; <ref type="bibr" target="#b23">Wang and Cohen, 2009;</ref><ref type="bibr" target="#b6">Dalvi et al., 2012</ref>). These approaches work well for common categories but encounter data sparsity problems for more specific categories, such as the products of a small company or the dishes at a lo- cal restaurant. In this context, we may have only a single web page that contains the information we need and no seed examples.</p><p>In this paper, we propose a novel task, zero- shot entity extraction, where the specification of the desired entities is provided as a natural language query. Given a query (e.g., hiking Figure 1: Entity extraction typically requires ad- ditional knowledge such as a small set of seed ex- amples or depends on multiple web pages. In our setting, we take as input a natural language query and extract entities from a single web page.</p><p>trails near Baltimore) and a web page (e.g., http://www.everytrail.com/best/ hiking-baltimore-maryland), the goal is to extract all entities corresponding to the query on that page (e.g., Avalon Super Loop, etc.). <ref type="figure">Figure 1</ref> summarizes the task setup. The task introduces two challenges. Given a single web page to extract entities from, we can no longer rely on the redundancy of entities across multiple web pages. Furthermore, in the zero-shot learning paradigm ( <ref type="bibr" target="#b14">Larochelle et al., 2008)</ref>, where entire categories might be unseen during training, the system must generalize to new queries and web pages without the additional aid of seed examples.</p><p>To tackle these challenges, we cast the task as a structured prediction problem where the input is the query and the web page, and the output is a list of entities, mediated by a latent extraction predicate. To generalize across different inputs, we rely on two types of features: structural fea- tures, which look at the layout and placement of the entities being extracted; and denotation fea-tures, which look at the list of entities as a whole and assess their linguistic coherence. When defin- ing features on lists, one technical challenge is be- ing robust to widely varying list sizes. We ap- proach this challenge by defining features over a histogram of abstract tokens derived from the list elements.</p><p>For evaluation, we created the OPENWEB dataset comprising natural language queries from the Google Suggest API and diverse web pages re- turned from web search. Despite the variety of queries and web pages, our system still achieves a test accuracy of 40.5% and an accuracy at 5 of 55.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem statement</head><p>We define the zero-shot entity extraction task as follows: let x be a natural language query (e.g., hiking trails near Baltimore), and w be a web page. Our goal is to construct a mapping from (x, w) to a list of entities y (e.g., <ref type="bibr">[Avalon Super Loop, Patapsco Valley State Park, . . . ]</ref>) which are extracted from the web page.</p><p>Ideally, we would want our data to be anno- tated with the correct entity lists y, but this would be very expensive to obtain. We instead define each training and test example as a triple <ref type="bibr">(x, w, c)</ref>, where the compatibility function c maps each y to c(y) ∈ {0, 1} denoting the (approximate) correct- ness of the list y. In this paper, an entity list y is compatible (c(y) = 1) when the first, second, and last elements of y match the annotation; otherwise, it is incompatible (c(y) = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dataset</head><p>To experiment with a diverse set of queries and web pages, we created a new dataset, OPENWEB, using web pages from Google search results. <ref type="bibr">1</ref> We use the method from <ref type="bibr" target="#b1">Berant et al. (2013)</ref> to gen- erate search queries by performing a breadth-first search over the query space. Specifically, we use the Google Suggest API, which takes a par- tial query (e.g., "list of movies") and out- puts several complete queries (e.g., "list of hor- ror movies"). We start with seed partial queries "list of • " where • is one or two initial let- ters. In each step, we call the Google Suggest API on the partial queries to obtain complete queries, <ref type="bibr">1</ref> The OPENWEB dataset and our code base are available for download at http://www-nlp.stanford.edu/ software/web-entity-extractor-ACL2014.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full query</head><p>New partial queries and then apply the transformation rules in <ref type="table" target="#tab_1">Table 1</ref> to generate more partial queries from complete queries. We run the procedure until we obtained 100K queries.</p><formula xml:id="formula_0">list of X IN Y list of X where IN is a preposition list of X (list of [hotels]X in [Guam]Y ) list of X IN list of IN Y list of X CC Y list of X where CC is a conjunction list of X (list of [food]X and [drink]Y ) list of Y list of Y list of X w list of w (list of [good 2012]X [movies]w) list of w list of X</formula><p>Afterwards, we downloaded the top 2-3 Google search results of each query, sanitized the web pages, and randomly submitted 8000 query / web page pairs to Amazon Mechanical Turk (AMT). Each AMT worker must either mark the web page as irrelevant or extract the first, second, and last entities from the page. We only included exam- ples where at least two AMT workers agreed on the answer.</p><p>The resulting OPENWEB dataset consists of 2773 examples from 2269 distinct queries. Among these queries, there are 894 headwords ranging from common categories (e.g., movies, companies, characters) to more specific ones (e.g., enzymes, proverbs, headgears). The dataset con- tains web pages from 1438 web domains, of which 83% appear only once in our dataset. <ref type="figure">Figure 2</ref> shows some queries and web pages from the OPENWEB dataset. Besides the wide range of queries, another main challenge of the dataset comes from the diverse data representa- tion formats, including complex tables, grids, lists, headings, and paragraphs. <ref type="figure" target="#fig_1">Figure 3</ref> shows the framework of our system. Given a query x and a web page w, the system generates a set Z(w) of extraction predicates z which can extract entities from semi-structured data in w. Section 3.1 describes extraction pred- icates in more detail. Afterwards, the system chooses z ∈ Z(w) that maximizes the model probability p θ (z | x, w), and then executes z on Queries airlines of italy natural causes of global warming lsu football coaches bf3 submachine guns badminton tournaments foods high in dha technical colleges in south carolina songs on glee season 5 singers who use auto tune san francisco radio stations actors from boston Examples (web page, query) airlines of italy natural causes of global warming lsu football coaches <ref type="figure">Figure 2</ref>: Some examples illustrating the diversity of queries and web pages from the OPENWEB dataset.  w to get the list of entities y = z w . Section 3.2 describes the model and the training procedure, while Section 3.3 presents the features used in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extraction predicates</head><p>We represent each web page w as a DOM tree, a common representation among wrapper induction and web information extraction systems (Sahuguet and Azavant, 1999; <ref type="bibr" target="#b15">Liu et al., 2000;</ref><ref type="bibr" target="#b4">Crescenzi et al., 2001</ref>). The text of any DOM tree node that is shorter than 140 characters is a candidate entity. However, without further restrictions, the number of possible entity lists grows exponentially with the number of candidate entities.</p><p>To make the problem tractable, we introduce an extraction predicate z as an intermediate represen- tation for extracting entities from w. In our sys- tem, we let an extraction predicate be a simplified XML path (XPath) such as <ref type="bibr">[2]</ref>/tr/td <ref type="bibr">[1]</ref> Informally, an extraction predicate is a list of path entries. Each path entry is either a tag (e.g., tr), which selects all children with that tag; or a tag and an index i (e.g., td <ref type="bibr">[1]</ref>), which selects only the ith child with that tag. The denotation y = z w of an extraction predicate z is the list of entities selected by the XPath. <ref type="figure" target="#fig_3">Figure 4</ref> illustrates the execution of the extraction predicate above on a DOM tree.</p><formula xml:id="formula_1">/html[1]/body[1]/table</formula><p>In the literature, many information extraction systems employ more versatile extraction predi- cates ( <ref type="bibr" target="#b23">Wang and Cohen, 2009;</ref><ref type="bibr" target="#b9">Fumarola et al., 2011</ref>). However, despite the simplicity, we are able to find an extraction predicate that extracts a compatible entity list in 69.7% of the develop- ment examples. In some examples, we cannot ex- tract a compatible list due to unrecoverable issues such as incorrect annotation. Section 4.4 provides a detailed analysis of these issues. Additionally, extraction predicates can be easily extended to in- crease the coverage. For example, by introduc- ing new index types [1:] (selects all but the first node) and <ref type="bibr">[:-1]</ref> (selects all but the last node), we can increase the coverage to 76.2%.</p><p>Extraction predicate generation. We generate a set Z(w) of extraction predicates for a given web page w as follows. For each node in the DOM tree, we find an extraction predicate which selects only that node, and then gener- alizes the predicate by removing any subset of the indices of the last k path entries. For in- stance, when k = 2, an extraction predicate ending in .../tr <ref type="bibr">[5]</ref>/td <ref type="bibr">[2]</ref> will be general- ized to .../tr <ref type="bibr">[5]</ref>/td <ref type="bibr">[2]</ref>, .../tr/td <ref type="bibr">[2]</ref>, .../tr <ref type="bibr">[5]</ref>/td, and .../tr/td. In all ex- periments, we use k = 8, which gives at most 2 8 generalized predicates for each original predicate. This generalization step allows the system to se- lect multiple nodes with the same structure (e.g.,   Out of all generalized extraction predicates, we retain the ones that extract at least two entities from w. Note that several extraction predicates may select the same list of nodes and thus produce the same list of entities.</p><p>The procedure above gives a manageable num- ber of extraction predicates. Among the devel- opment examples of the OPENWEB dataset, we generate an average of 8449 extraction predicates per example, which evaluate to an average of 1209 unique entity lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modeling</head><p>Given a query x and a web page w, we define a log-linear distribution over all extraction predi- cates z ∈ Z(w) as</p><formula xml:id="formula_2">p θ (z | x, w) ∝ exp{θ φ(x, w, z)},<label>(1)</label></formula><p>where θ ∈ R d is the parameter vector and φ(x, w, z) is the feature vector, which will be de- fined in Section 3.3. To train the model, we find a parameter vec- tor θ that maximizes the regularized log marginal probability of the compatibility function being sat- isfied. In other words, given training data</p><formula xml:id="formula_3">D = {(x (i) , w (i) , c (i) )} n i=1 , we find θ that maximizes n i=1 log p θ (c (i) = 1 | x (i) , w (i) ) − λ 2 θ 2 2</formula><p>where</p><formula xml:id="formula_4">p θ (c = 1 | x, w) = z∈Z(w) p θ (z | x, w) · c(z w ).</formula><p>Note that c(z w ) = 1 when the entity list y = z w selected by z is compatible with the annota- tion; otherwise, c(z w ) = 0. We use AdaGrad, an online gradient descent with an adaptive per-feature step size ( <ref type="bibr" target="#b7">Duchi et al., 2010</ref>), making 5 passes over the training data. We use λ = 0.01 obtained from cross-validation for all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Features</head><p>To construct the log-linear model, we define a fea- ture vector φ(x, w, z) for each query x, web page w, and extraction predicate z. The final feature vector is the concatenation of structural features φ s (w, z), which consider the selected nodes in the DOM tree, and denotation features φ d (x, y), which look at the extracted entities.</p><p>We will use the query hiking trails near Balti- more and the web page in <ref type="figure" target="#fig_3">Figure 4</ref> as a running example. <ref type="figure" target="#fig_5">Figure 5</ref> lists some features extracted from the example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Recipe for defining features on lists</head><p>One main focus of our work is finding good fea- ture representations for a list of objects (DOM tree nodes for structural features and entity strings for denotation features). One approach is to define the feature vector of a list to be the sum of the feature vectors of individual elements. This is commonly done in structured prediction, where the elements are local configurations (e.g., rule applications in parsing). However, this approach raises a normal- ization issue when we have to compare and rank lists of drastically different sizes.</p><p>As an alternative, we propose a recipe for gen- erating features from a list as follows:    <ref type="figure">Figure 6</ref>: The recipe for defining features on a list of objects: (i) the abstraction step converts list elements into abstract tokens; (ii) the aggregation step defines features using the histogram of the ab- stract tokens.</p><p>Step 1: Abstraction. We map each list element into an abstract token. For example, we can map each DOM tree node onto an integer equal to the number of children, or map each entity string onto its part-of-speech tag sequence.</p><p>Step 2: Aggregation. We create a histogram of the abstract tokens and define features on proper- ties of the histogram. Generally, we use ENTROPY (entropy normalized to the maximum value of 1), MAJORITY (mode), MAJORITYRATIO (percent- age of tokens sharing the majority value), and SINGLE (whether all tokens are identical). For abstract tokens with finitely many possible values (e.g., part-of-speech), we also use the normalized histogram count of each possible value as a fea- ture. And for real-valued abstract tokens, we also use the mean and the standard deviation. In the actual system, we convert real-valued features (en- tropy, histogram count, mean, and standard devia- tion) into indicator features by binning. <ref type="figure">Figure 6</ref> summarizes the steps explained above. We use this recipe for defining both structural and denotation features, which are discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Structural features</head><p>Although different web pages represent data in different formats, they still share some common hierarchical structures in the DOM tree. To cap- ture this, we define structural features φ s (w, z), which consider the properties of the selected nodes in the DOM tree, as follows:</p><p>Features on selected nodes. We apply our recipe on the list of nodes in w selected by z using the following abstract tokens:</p><p>• TAG, ID, CLASS, etc. (HTML attributes)</p><p>• CHILDRENCOUNT and SIBLINGSCOUNT (number of children and siblings)</p><p>• INDEX (position among its siblings)</p><p>• PARENT (parent node; e.g., PARENT-SINGLE means that all nodes share the same parent.) Additionally, we define the following features based on the coverage of all selected nodes:</p><p>• NOHOLE, HEADHOLE, etc. (node coverage in the same DOM tree level; e.g., HEAD- HOLE activates when the first sibling of the selected nodes is not selected.)</p><p>• PAGECOVERAGE (node coverage relative to the entire tree; we use depth-first traversal timestamps to estimate the fraction of nodes in the subtrees of the selected nodes.)</p><p>Features on ancestor nodes. We also define the same feature set on the list of ancestors of the se- lected nodes in the DOM tree. In our experiments, we traverse up to 5 levels of ancestors and define features from the nodes in each level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Denotation features</head><p>Structural features are not powerful enough to dis- tinguish between entity lists appearing in similar structures such as columns of the same table or fields of the same record. To solve this ambiguity, we introduce denotation features φ d (x, y) which considers the coherence or appropriateness of the selected entity strings y = z w . We observe that the correct entities often share some linguistic statistics. For instance, entities in many categories (e.g., people and place names) usually have only 2-3 word tokens, most of which are proper nouns. On the other hand, random words on the web page tend to have more diverse lengths and part-of-speech tags.</p><p>We apply our recipe on the list of selected enti- ties using the following abstract tokens:</p><p>• WORDSCOUNT (number of words)</p><p>• PHRASESHAPE (abstract shape of the phrase; e.g., Barack Obama becomes Aa Aa)</p><p>• WORDSHAPE (abstract shape of each word; the number of abstract tokens will be the total number of words over all selected entities)</p><p>• FIRSTWORD and LASTWORD</p><p>• PHRASEPOS and WORDPOS (part-of- speech tags for whole phrases and individual words)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we evaluate our system on the OPENWEB dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation metrics</head><p>Accuracy. As the main metric, we use a notion of accuracy based on compatibility; specifically, we define the accuracy as the fraction of examples where the system predicts a compatible entity list as defined in Section 2. We also report accuracy at 5, the fraction of examples where the top five predictions contain a compatible entity list.  To see how our compatibility-based accuracy tracks exact correctness, we sampled 100 web pages which have at least one valid extraction predicate and manually annotated the full list of entities. We found that in 85% of the examples, the longest compatible list y is the correct list of entities, and many lists in the remaining 15% miss the correct list by only a few entities.</p><p>Oracle. In some examples, our system cannot find any list of entities that is compatible with the gold annotation. The oracle score is the fraction of examples in which the system can find at least one compatible list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline</head><p>As a baseline, we list the suffixes of the cor- rect extraction predicates in the training data, and then sort the resulting suffix patterns by frequency. To improve generalization, we treat path entries with different indices (e.g., td <ref type="bibr">[1]</ref> vs. td <ref type="bibr">[2]</ref>) as equivalent and allow path entries to be permuted. <ref type="table" target="#tab_5">Table 2</ref> lists the top 10 suffix patterns from the de- velopment data. At test time, we choose an extrac- tion predicate with the most frequent suffix pat- tern. The baseline should work considerably well if the web pages were relatively homogeneous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main results</head><p>We held out 30% of the dataset as test data. For the results on development data, we report the average across 10 random 80-20 splits. <ref type="table">Table 3</ref> shows the results. The system gets an accuracy of 41.1% and 40.5% for the development and test data, respec- tively. If we consider the top 5 lists of entities, the accuracy increases to 58.4% on the development data and 55.8% on the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Development data</head><p>Test data Acc A@5 Acc A@5 Baseline 10.8 ± 1.3 25.6 ± 2.0 10.3 20.9 Our system 41.1 ± 3.4 58.4 ± 2.7 40.5 55.8 Oracle 68.7 ± 2.4 68.7 ± 2.4 66.6 66.6 <ref type="table">Table 3</ref>: Main results on the OPENWEB dataset using the default set of features. (Acc = accuracy, A@5 = accuracy at 5)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Error analysis</head><p>We now investigate the errors made by our system using the development data. We classify the er- rors into two types: (i) coverage errors, which are when the system cannot find any entity list satis- fying the compatibility function; and (ii) ranking errors, which are when a compatible list of entities exists, but the system outputs an incompatible list. <ref type="table" target="#tab_7">Tables 4 and 5</ref> show the breakdown of cover- age and ranking errors from an experiment on the development data.</p><p>Analysis of coverage errors. From <ref type="table" target="#tab_7">Table 4</ref>, about 36% of coverage errors happen when the extraction predicate for the correct entities also captures unrelated parts of the web page (Reason C1). For example, many Wikipedia articles have the See Also section that lists related articles in an unordered list (/ul/li/a), which causes a prob- lem when the entities are also represented in the same format.</p><p>Another main source of errors is the in- consistency in HTML tag usage (Reason C2). For instance, some web pages use &lt;b&gt; and &lt;strong&gt; tags for bold texts interchangeably, or switch between &lt;b&gt;&lt;a&gt;...&lt;/a&gt;&lt;/b&gt; and &lt;a&gt;&lt;b&gt;...&lt;/b&gt;&lt;/a&gt; across entities. We ex- pect that this problem can be solved by normaliz- ing the web page, using an alternative web page representation ( <ref type="bibr" target="#b3">Cohen et al., 2002</ref>; <ref type="bibr" target="#b23">Wang and Cohen, 2009;</ref><ref type="bibr" target="#b9">Fumarola et al., 2011)</ref>, or leveraging more expressive extraction predicates <ref type="bibr" target="#b5">(Dalvi et al., 2011)</ref>.</p><p>One interesting source of errors is Reason C3, where we need to filter the selected entities to match the complex requirement in the query. For example, the query tech companies in China re- quires the system to select only the company names with China in the corresponding location column. To handle such queries, we need a deeper understanding of the relation between the linguis- tic structure of the query and the hierarchical structure of the web page. Tackling this error re-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setting</head><p>Acc A@5 All features 41.1 ± 3.4 58.4 ± 2.7 Oracle 68.7 ± 2.4 68.7 ± 2.4 (Section 4.5) Structural features only 36.2 ± 1.9 54.5 ± 2.5 Denotation features only 19.8 ± 2.5 41.7 ± 2.7 (Section 4.6) Structural + query-denotation 41.7 ± 2.5 58.1 ± 2.4 Query-denotation features only 25.0 ± 2.3 48.0 ± 2.7 Concat. a random web page + structural + denotation 19.3 ± 2.6 41.2 ± 2.3 Concat. a random web page + structural + query-denotation 29.2 ± 1.7 49.2 ± 2.2 (Section 4.7) Add 1 seed entity 52.9 ± 3.0 66.5 ± 2.5 <ref type="table">Table 6</ref>: System accuracy with different feature and input settings on the development data. (Acc = accuracy, A@5 = accuracy at 5) quires compositionality and is critical to general- ize to more complex queries.</p><p>Analysis of ranking errors. From <ref type="table" target="#tab_8">Table 5</ref>, a large number of errors are attributed to the system selecting non-content elements such as navigation links and content headings (Reason R1). Feature analysis reveals that both structural and linguis- tic statistics of these non-content elements can be more coherent than those of the correct entities. We suspect that since many of our features try to capture the coherence of entities, the system some- times erroneously favors the more homonogenous non-content parts of the page. To disfavor these parts, One possible solution is to add visual fea- tures that capture how the web page is rendered and favor more salient parts of the page. ( <ref type="bibr" target="#b16">Liu et al., 2003;</ref><ref type="bibr" target="#b21">Song et al., 2004;</ref><ref type="bibr" target="#b28">Zhu et al., 2005;</ref><ref type="bibr" target="#b26">Zheng et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Feature variations</head><p>We now investigate the contribution of each fea- ture type. The ablation results on the development set over 10 random splits are shown in <ref type="table">Table 6</ref>. We observe that denotation features improves ac- curacy on top of structural features. <ref type="table">Table 7</ref> shows an example of an error that is eliminated by each feature type. Generally, if the entities are represented as records (e.g., rows of a table), then denotation features will help the system select the correct field from each record. On the other hand, structural features prevent the system from selecting random entities outside the main part of the page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reason</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Short example</head><p>Count C1 Answers and contextual elements are selected by the same extraction predicate. Select entries in See Also section in addition to the con- tent because they are all list entries. 48 C2 HTML tag usage is inconsistent. The page uses both b and strong for headers. 16 C3 The query applies to only some sections of the matching entities. Need to select only companies in <ref type="table">China from the table  of</ref>     <ref type="table">Table 7</ref>: System outputs for the query UK news- papers with different feature sets. Without deno- tation features, the system selects the daily circu- lation of each newspaper instead of the newspaper names. And without structural features, the sys- tem selects the hidden navigation links from the top of the page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Incorporating query information</head><p>So far, note that all our features depend only on the extraction predicate z and not the input query x. Remarkably, we were still able to obtain rea- sonable results. One explanation is that since we obtained the web pages from a search engine, the most prominent entities on the web pages, such as entities in table cells in the middle of the page, are likely to be good independent of the query. However, different queries often denote enti- ties with different linguistic properties. For exam- ple, queries mayors of Chicago and universities in Chicago will produce entities of different lengths, part-of-speech sequences, and word distributions. This suggests incorporating features that depend on the query.</p><p>To explore the potential of query informa- tion, we conduct the following oracle experi- ment. We replace each denotation feature f (y) with a corresponding query-denotation feature (f (y), g(x)), where g(x) is the category of the query x. We manually classified all queries in our dataset into 7 categories: person, media title, loca- tion/organization, abtract entity, word/phrase, ob- ject name, and miscellaneous. <ref type="table">Table 8</ref> shows some examples where adding these query-denotation features improves the se- lected entity lists by favoring answers that are more suitable to the query category. However, Ta- ble 6 shows that these new features do not signifi- cantly improve the accuracy of our original system on the development data.</p><p>We suspect that any gains offered by the query- denotation features are subsumed by the structural features. To test this hypothesis, we conducted two experiments, the results of which are shown in <ref type="table">Table 6</ref>. First, we removed structural features and found that using query-denotation features im- proves accuracy significantly over using denota- tion features alone from 19.8% to 25.0%. Second, we created a modified dataset where the web page in each example is a concatenation of the orig- inal web page and an unrelated web page. On Query euclid's elements book titles soft drugs professional athletes with concussions Default features "Prematter", "Book I.", "Book II.", "Book III.", . . . "Hard drugs", "Soft drugs", "Some drugs cannot be classified that way", . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"Pistons-Knicks Game Becomes Site of Incredible Dance Battle", "Toronto</head><p>Mayor Rob Ford Attends . . . ", . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Structural + Query- Denotation</head><p>(category = media title) "Book I. The fundamentals . . . ", "Book II. Geometric algebra", . . .</p><p>(category = object name) "methamphetamine", "psilocybin", "caffeine" (category = person) "Mike Richter", "Stu Grimson", "Geoff Courtnall", . . . <ref type="table">Table 8</ref>: System outputs after changing denotation features into query-denotation features. this modified dataset, the prominent entities may not be the answers to the query. Here, query- denotation features improves accuracy over deno- tation features alone from 19.3% to 29.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Comparison with other problem settings</head><p>Since zero-shot entity extraction is a new task, we cannot directly compare our system with other systems. However, we can mimic the settings of other tasks. In one experiment, we augment each input query with a single seed entity (the second annotated entity in our experiments); this setting is suggestive of <ref type="bibr" target="#b23">Wang and Cohen (2009)</ref>. <ref type="table">Table 6</ref> shows that this augmentation increases accuracy from 41.1% to 52.9%, suggesting that our sys- tem can perform substantially better with a small amount of additional supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Our work shares a base with the wrapper induc- tion literature <ref type="bibr" target="#b12">(Kushmerick, 1997</ref>) in that it lever- ages regularities of web page structures. However, wrapper induction usually focuses on a small set of web domains, where the web pages in each do- main follow a fixed template ( <ref type="bibr" target="#b18">Muslea et al., 2001;</ref><ref type="bibr" target="#b4">Crescenzi et al., 2001;</ref><ref type="bibr" target="#b3">Cohen et al., 2002;</ref><ref type="bibr" target="#b0">Arasu and Garcia-Molina, 2003)</ref>. Later work in web data extraction attempts to generalize across different web pages, but relies on either restricted data for- mats ( <ref type="bibr" target="#b24">Wong et al., 2009)</ref> or prior knowledge of web page structures with respect to the type of data to extract <ref type="bibr" target="#b25">(Zhang et al., 2013)</ref>.</p><p>In our case, we only have the natural language query, which presents the more difficult problem of associating the entity class in the query (e.g., hiking trails) to concrete entities (e.g., Avalon Su- per Loop). In contrast to information extraction systems that extract homogeneous records from web pages ( <ref type="bibr" target="#b16">Liu et al., 2003;</ref><ref type="bibr" target="#b27">Zheng et al., 2009)</ref>, our system must choose the correct field from each record and also identify the relevant part of the page based on the query.</p><p>Another related line of work is information ex- traction from text, which relies on natural lan- guage patterns to extract categories and relations of entities. One classic example is Hearst pat- terns <ref type="bibr" target="#b10">(Hearst, 1992;</ref><ref type="bibr" target="#b8">Etzioni et al., 2005</ref>), which can learn new entities and extraction patterns from seed examples. More recent approaches also leverage semi-structured data to obtain more ro- bust extraction patterns ( <ref type="bibr" target="#b17">Mintz et al., 2009;</ref><ref type="bibr" target="#b11">Hoffmann et al., 2011;</ref><ref type="bibr" target="#b22">Surdeanu et al., 2012;</ref><ref type="bibr" target="#b19">Riedel et al., 2013)</ref>. Although our work focuses on semi- structured web pages rather than raw text, we use linguistic patterns of queries and entities as a sig- nal for extracting appropriate answers.</p><p>Additionally, our efforts can be viewed as build- ing a lexicon on the fly. In recent years, there has been a drive to scale semantic parsing to large databases such as Freebase <ref type="bibr" target="#b2">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b13">Kwiatkowski et al., 2013)</ref>. However, despite the best efforts of information extraction, such databases will always lag behind the open web. For example, <ref type="bibr" target="#b1">Berant et al. (2013)</ref> found that less than 10% of naturally occurring questions are answerable by a simple Freebase query. By using the semi-structured data from the web as a knowledge base, we hope to increase fact coverage for semantic parsing.</p><p>Finally, as pointed out in the error analysis, we need to filter or aggregate the selected entities for complex queries (e.g., tech companies in China for a web page with all Asian tech companies). In fu- ture work, we would like to explore the issue of compositionality in queries by aligning linguistic structures in natural language with the relative po- sition of entities on web pages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An overview of our system. The system uses the input query x and web page w to produce a list of entities y via an extraction predicate z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A simplified example of a DOM tree w and an extraction predicate z, which selects a list of entity strings y = z w from the page (highlighted in red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A small subset of features from the example hiking trails near Baltimore in Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Rules for generating new partial queries 
from complete queries. (X and Y are sequences 
of words; w is a single word.) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>table tr td</head><label>tr</label><figDesc></figDesc><table>Home.. 

td 

Expl.. 

td 

Mobi.. 

td 

Crea.. 

h1 

Hiki.. 

table 

tr 

th 

Name.. 

th 

Loca.. 

tr 

td 

Aval.. 

td 

12.7.. 

... 
tr 

td 

Gove.. 

td 

3.1 .. 

Extraction predicate z 

/html[1]/body[1]/table[2]/tr/td[1] 

Rendered web page 

Home Explore Mobile Apps Create Trip 

Hiking near Baltimore, Maryland 
Name 
Length 
Avalon Super Loop 
12.7 miles 
Hilton Area 
7.8 miles 
Avalon Loop 
9.4 miles 
Wildlands Loop 
4.4 miles 
Mckeldin Area 
16.7 miles 
Greenbury Point 
3.7 miles 
Governer Bridge Natural Area 3.1 miles 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>table . ..</head><label>.</label><figDesc></figDesc><table>h1 
table 

tr 

th 
th 

tr 

td 
td 

tr 

td 
td 

... 
tr 

td 
td 

Structural feature 
Value 
Features on selected nodes: 
TAG-MAJORITY = td 
1 
INDEX-ENTROPY 
0.0 
Features on parent nodes: 
CHILDRENCOUNT-MAJORITY = 2 
1 
PARENT-SINGLE 
1 
INDEX-ENTROPY 
1.0 
HEADHOLE (The first node is skipped) 1 
Features on grandparent nodes: 
PAGECOVERAGE 
0.6 
. . . 
. . . 

Selected entities 
Avalon Super Loop 
Hilton Area 
Avalon Loop 
Wildlands Loop 
Mckeldin Area 
Greenbury Point 
Governer Bridge Natural Area 

Denotation feature 
Value 
WORDSCOUNT-MEAN 
2.42 
PHRASESHAPE-MAJORITY = Aa Aa 1 
PHRASESHAPE-MAJORITYRATIO 
0.71 
WORDSHAPE-MAJORITY = Aa 
1 
PHRASEPOS-MAJORITY = NNP NN 
1 
LASTWORD-ENTROPY 
0.74 
WORDPOS = NN (normalized count) 
0.53 
. . . 
. . . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top 10 path suffix patterns found by the 
baseline learner in the development data. Since 
we allow path entries to be permuted, each suffix 
pattern is represented by a multiset of path entries. 
The notation [ * ] denotes any path entry index. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Breakdown of coverage errors from the development data. 

Reason 
Short example 
Count 
R1 Select non-content strings. 
Select navigation links, headers, footers, or sidebars. 
25 
R2 Select entities from a wrong field. 
Select book authors instead of book names. 
22 
R3 Select entities from the wrong section(s). 
For the query schools in Texas, select all schools on the 
page, or select the schools in Alabama instead. 
19 

R4 Also select headers or footers. 
Select the table header in addition to the answers. 
7 
R5 Select only entities with a particular formatting. From a list of answers, select only anchored (a) entities. 
4 
R6 Select headings instead of the contents or vice 
versa. 
Select the categories of rums in h2 tags instead of the 
rum names in the tables. 
2 

R7 Other issues. 
Incorrect annotation. / Multiple sets of answers appear 
on the same page. / etc. 
9 

Total 
88 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="true"><head>Table 5 : Breakdown of ranking errors from the development data.</head><label>5</label><figDesc></figDesc><table>All features 
Structural only 
Denotation only 
The Sun 
CIRC: 2,279,492 Paperboy Australia 
Daily Mail 
CIRC: 1,821,684 Paperboy UK 
Daily Mirror CIRC: 1,032,144 Paperboy Home Page 
. . . 
. . . 
. . . 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We gratefully acknowledge the support of the Google Natural Language Understanding Focused Program. In addition, we would like to thank anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Extracting structured data from web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD international conference on Management of data</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="337" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A flexible learning system for wrapping tables and lists in HTML documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Roadrunner: Towards automatic data extraction from large web sites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Crescenzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Merialdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="109" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic wrappers for large scale web extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soliman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="219" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Websets: Extracting sets of entities from the web using unsupervised information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Web Search and Data Mining (WSDM)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity extraction from the web: An experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="134" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extracting general lists from web documents: A hybrid approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fumarola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Malerba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Modern Approaches in Applied Intelligence Springer</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interational Conference on Computational linguistics</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Wrapper induction for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kushmerick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>University of Washington</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Zerodata learning of new tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="646" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">XWRAP: An XMLenabled wrapper construction system for web information sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th International Conference on</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="611" to="621" />
		</imprint>
	</monogr>
<note type="report_type">Proceedings</note>
	<note>Data Engineering</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining data records in web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="601" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical wrapper induction for semistructured information sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Muslea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Agents and MultiAgent Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="114" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">WysiWyg web wrapper factory (W4F)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sahuguet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Azavant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Conference</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning block importance models for web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="203" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Character-level analysis of semi-structured documents for set expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1503" to="1512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scalable attribute-value extraction from semistructured text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Widdows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining Workshops</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="302" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic extraction of top-k lists from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Templateindependent news extraction based on visual consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1507" to="1513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient record-level wrapper induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">2D conditional random fields for web information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1044" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
