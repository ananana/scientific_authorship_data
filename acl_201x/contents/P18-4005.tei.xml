<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Jack the Reader-A Machine Reading Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">German Research Center for Artificial Intelligence (DFKI)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Università della Svizzera italiana</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matko</forename><surname>Bošnjak</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Ghent University -imec</orgName>
								<address>
									<settlement>Ghent</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Jack the Reader-A Machine Reading Framework</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="25" to="30"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>25</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many Machine Reading and Natural Language Understanding tasks require reading supporting text in order to answer questions. For example, in Question Answering , the supporting text can be newswire or Wikipedia articles; in Natural Language Inference, premises can be seen as the supporting text and hypotheses as questions. Providing a set of useful primitives operating in a single framework of related tasks would allow for expressive modelling, and easier model comparison and replication. To that end, we present Jack the Reader (JACK), a framework for Machine Reading that allows for quick model prototyp-ing by component reuse, evaluation of new models on existing datasets as well as integrating new datasets and applying them on a growing set of implemented baseline models. JACK is currently supporting (but not limited to) three tasks: Question Answering , Natural Language Inference, and Link Prediction. It is developed with the aim of increasing research efficiency and code reuse.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated reading and understanding of textual and symbolic input, to a degree that enables ques- tion answering, is at the core of Machine Read- ing (MR). A core insight facilitating the develop- ment of MR models is that most of these tasks can be cast as an instance of the Question Answering (QA) task: an input can be cast in terms of ques- tion, support documents and answer candidates, and an output in terms of answers. For instance, in case of Natural Language Inference (NLI), we can view the hypothesis as a multiple choice ques- tion about the underlying premise (support) with predefined set of specific answer candidates (en- tailment, contradiction, neutral). Link Prediction (LP) -a task which requires predicting the truth value about facts represented as (subject, predi- cate, object)-triples -can be conceived of as an in- stance of QA (see Section 4 for more details). By unifying these tasks into a single framework, we can facilitate the design and construction of multi- component MR pipelines.</p><p>There are many successful frameworks such as STANFORD CORENLP <ref type="bibr" target="#b12">(Manning et al., 2014</ref>), NLTK ( <ref type="bibr" target="#b2">Bird et al., 2009)</ref>, and SPACY 1 for NLP, LUCENE 2 and SOLR 3 for Information Retrieval, and SCIKIT-LEARN 4 , PYTORCH <ref type="bibr">5</ref> and TENSOR- FLOW ( <ref type="bibr" target="#b0">Abadi et al., 2015</ref>) for general Machine Learning (ML) with a special focus on Deep Learning (DL), among others. All of these frame- works touch upon several aspects of Machine Reading, but none of them offers dedicated sup- port for modern MR pipelines. Pre-processing and transforming MR datasets into a format that is us- able by a MR model as well as implementing com- mon architecture building blocks all require sub- stantial effort which is not specifically handled by any of the aforementioned solutions. This is due to the fact that they serve a different, typically much broader purpose.</p><p>In this paper, we introduce Jack the Reader (JACK), a reusable framework for MR. It allows for the easy integration of novel tasks and datasets by exposing a set of high-level primitives and a common data format. For supported tasks it is straight-forward to develop new models without worrying about the cumbersome implementation of training, evaluation, pre-and post-processing routines. Declarative model definitions make the development of QA and NLI models using com- mon building blocks effortless. JACK covers a large variety of datasets, implementations and pre- trained models on three distinct MR tasks and sup- ports two ML backends, namely PYTORCH and TENSORFLOW. Furthermore, it is easy to train, deploy, and interact with MR models, which we refer to as readers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Machine Reading requires a tight integration of Natural Language Processing and Machine Learn- ing models. General NLP frameworks include CORENLP ( <ref type="bibr" target="#b12">Manning et al., 2014</ref>), NLTK <ref type="bibr" target="#b2">(Bird et al., 2009)</ref>, OPENNLP <ref type="bibr">6</ref> and SPACY. All these frameworks offer pre-built models for standard NLP preprocessing tasks, such as tokenisation, sentence splitting, named entity recognition and parsing.</p><p>GATE <ref type="bibr" target="#b7">(Cunningham et al., 2002</ref>) and UIMA ( <ref type="bibr" target="#b9">Ferrucci and Lally, 2004</ref>) are toolk- its that allow quick assembly of baseline NLP pipelines, and visualisation and annotation via a Graphical User Interface. GATE can utilise NLTK and CORENLP models and additionally enable development of rule-based methods using a dedicated pattern language. UIMA offers a text analysis pipeline which, unlike GATE, also includes retrieving information, but does not offer its own rule-based language. It is further worth mentioning the Information Retrieval frameworks APACHE LUCENE and APACHE SOLR which can be used for building simple, keyword-based question answering systems, but offer no ML support.</p><p>Multiple general machine learning frame- works, such as SCIKIT-LEARN ( <ref type="bibr" target="#b15">Pedregosa et al., 2011</ref>), PYTORCH, THEANO (Theano Develop- ment Team, 2016) and TENSORFLOW ( <ref type="bibr" target="#b0">Abadi et al., 2015</ref>), among others, enable quick proto- typing and deployment of ML models. However, unlike JACK, they do not offer a simple framework for defining and evaluating MR models.</p><p>The framework closest in objectives to JACK is ALLENNLP ( <ref type="bibr" target="#b10">Gardner et al., 2017</ref>  <ref type="figure">Figure 1</ref>: Our core abstraction, the JTREADER. On the left, the responsibilities covered by the IN- PUT, MODEL and OUTPUT modules that compose a JTREADER instance. On the right, the data for- mat that is used to interact with a JTREADER (dot- ted lines indicate that the component is optional).</p><p>to pre-assembled models for standard NLP tasks, such as coreference resolution, constituency pars- ing, named entity recognition, question answer- ing and textual entailment. In comparison with ALLENNLP, JACK supports both TENSORFLOW and PYTORCH. Furthermore, JACK can also learn from Knowledge Graphs (discussed in Section 4), while ALLENNLP focuses on textual inputs. Fi- nally, JACK is structured following a modular ar- chitecture, composed by input-, model-, and out- put modules, facilitating code reuse and the inclu- sion and prototyping of new methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview</head><p>In <ref type="figure">Figure 1</ref> we give a high-level overview of our core abstraction, the JTREADER. It is a task-agnostic wrapper around three typically task- dependent modules, namely the input, model and output modules. Besides serving as a container for modules, a JTREADER provides convenience functionality for interaction, training and serialisa- tion. The underlying modularity is therefore well hidden from the user which facilitates the applica- tion of trained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modules and Their Usage</head><p>Our abstract modules have the following high- level responsibilities:</p><p>• INPUT MODULES: Pre-processing that trans- forms a text-based input to tensors.</p><p>• MODEL MODULES: Implementation of the actual end-to-end MR model.</p><p>• OUTPUT MODULES: Converting predictions into human readable answers.</p><p>The main design for building models in JACK revolves around functional interfaces between the three main modules: the input-, model-, and out- put module. Each module can be viewed as a thin wrapper around a (set of) function(s) that addi- tionally provides explicit signatures in the form of tensor ports which can be understood as named placeholders for tensors.</p><p>The use of explicit signatures helps validate whether modules are correctly implemented and invoked, and to ensure correct behaviour as well as compatibility between modules. Finally, by imple- menting modules as classes and their interaction via a simple functional interface, JACK allows for the exploitation of benefits stemming from the use of object oriented programming, while retaining the flexibility offered by the functional program- ming paradigm when combining modules.</p><p>Given a list of training instances, correspond- ing to question-answer pairs, a input module is re- sponsible for converting such instances into ten- sors. Each produced tensor is associated with a pre-defined tensor port -a named placeholder for a tensor -which can in turn be used in later mod- ules to retrieve the actual tensor. This step typ- ically involves some shallow forms of linguistic pre-processing such as tokenisation, building vo- cabularies, etc. The model module runs the end- to-end MR model on the now tensorised input and computes a new mapping of output tensor ports to newly computed tensors. Finally, the joint tensor mappings of the input-and model module serve as input to the output module which produces a human-readable answer. More in-depth documen- tation can be found on the project website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Distinguishing Features</head><p>Module Reusability. Our shallow modularisa- tion of readers into input-, model-and output mod- ules has the advantage that they can be reused easily. Most of nowadays state-of-the-art MR models require the exact same kind of input pre- processing and produce output of the same form. Therefore, existing input-and output modules that are responsible for pre-and post-processing can be reused in most cases, which enables researchers to focus on prototyping and implementing new models. Although we acknowledge that most of the pre-processing can easily be performed by third-party libraries such as CORENLP, NLTK or SPACY, we argue that additional functional- ity, such as building and controlling vocabular- ies, padding, batching, etc., and connecting the pre-processed output with the actual model im- plementation pose time intensive implementation challenges. These can be avoided when work- ing with one of our currently supported tasks - Question Answering, Natural Language Inference, or Link Prediction in Knowledge Graphs. Note that modules are typically task specific and not shared directly between tasks. However, utilities like the pre-processing functions mentioned above and model building blocks can readily be reused even between tasks.</p><p>Supported ML Backends. By decoupling mod- elling from pre-and post-processing we can easily switch between backends for model implementa- tions. At the time of writing, JACK offers support for both TENSORFLOW and PYTORCH. This al- lows practitioners to use their preferred library for implementing new MR models and allows for the integration of more back-ends in the future. Declarative Model Definition. Implementing different kinds of MR models can be repetitive, tedious, and error-prone. Most neural architec- tures are built using a finite set of basic building blocks for encoding sequences, and realising inter- action between sequences (e.g. via attention mech- anisms). For such a reason, JACK allows to de- scribe these models at a high level, as a composi- tion of simpler building blocks 7 , leaving concrete implementation details to the framework.</p><p>The advantage of using such an approach is that is very easy to change, adapt or even cre- ate new models without knowing any implemen- tation specifics of JACK or its underlying frame- works, such as TENSORFLOW and PYTORCH. This solution also offers another important advan- tage: it allows for easy experimentation of auto- mated architecture search and optimisation (Au- toML). JACK already enables the definition of new models purely within configuration files without writing any source code. These are interpreted by JACK and support a (growing) set of pre-defined building blocks. In fact, many models for differ- ent tasks in JACK are realised by high-level archi- tecture descriptions. An example of an high-level architecture definition in JACK is available in Ap- pendix A.</p><p>Dataset Coverage. JACK allows parsing a large number of datasets for QA, NLI, and Link Pre- diction. The supported QA datasets include SQuAD ( <ref type="bibr" target="#b16">Rajpurkar et al., 2016)</ref>, <ref type="bibr">TriviaQA (Joshi et al., 2017</ref>), NewsQA ( <ref type="bibr" target="#b21">Trischler et al., 2017)</ref>, and QAngaroo ( <ref type="bibr" target="#b24">Welbl et al., 2017)</ref>. The sup- ported NLI datasets include SNLI ( <ref type="bibr" target="#b5">Bowman et al., 2015)</ref>, and MultiNLI ( <ref type="bibr" target="#b25">Williams et al., 2018)</ref>. The supported Link Prediction datasets include WN18 ( <ref type="bibr" target="#b4">Bordes et al., 2013</ref>), WN18RR <ref type="bibr" target="#b8">(Dettmers et al., 2018), and</ref><ref type="bibr">FB15k-237 (Toutanova and</ref><ref type="bibr" target="#b20">Chen, 2015)</ref>.</p><p>Pre-trained Models. JACK offers several pre- trained models. For QA, these include FastQA, BiDAF, and JackQA trained on SQuAD and Triv- iaQA. For NLI, these include DAM and ESIM trained on SNLI and MultiNLI. For LP, these in- clude DistMult and ComplEx trained on WN18, WN18RR and FB15k-237.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Supported MR Tasks</head><p>Most end-user MR tasks can be cast as an instance of question answering. The input to a typical ques- tion answering setting consists of a question, sup- porting texts and answers during training. In the following we show how JACK is used to model our currently supported MR tasks.</p><p>Ready to use implementations for these tasks exist which allows for rapid prototyping. Re- searchers interested in developing new models can define their architecture in TENSORFLOW or PY- TORCH, and reuse existing of input-and output modules. New datasets can be tested quickly on a set of implemented baseline models after convert- ing them to one of our supported formats.</p><p>Extractive Question Answering. JACK sup- ports the task of Extractive Question Answering (EQA), which requires a model to extract an an- swer for a question in the form of an answer span comprising a document id, token start and -end from a given set of supporting documents. This task is a natural fit for our internal data format, and is thus very easy to represent with JACK.</p><p>Natural Language Inference. Another popu- lar MR task is Natural Language Inference, also known as Recognising Textual Entailment (RTE). The task is to predict whether a hypothesis is en- tailed by, contradicted by, or neutral with respect to a given premise. In JACK, NLI is viewed as an instance of multiple-choice Question Answer- ing problem, by casting the hypothesis as the ques- tion, and the premise as the support. The answer candidates to this question are the three possible outcomes or classes -namely entails, contradicts or neutral.</p><p>Link Prediction. A Knowledge Graph is a set of (s, p, o) triples, where s, o denote the subject and object of the triple, and p denotes its predicate: each (s, p, o) triple denotes a fact, represented as a relationship of type p between entities s and o, such as: <ref type="figure">(LONDON, CAPITALOF, UK)</ref>. Real- world Knowledge Graphs, such as Freebase ( <ref type="bibr" target="#b3">Bollacker et al., 2007)</ref>, are largely incomplete: the Link Prediction task consists in identifying miss- ing (s, p, o) triples that are likely to encode true facts ( <ref type="bibr" target="#b13">Nickel et al., 2016)</ref>.</p><p>JACK also supports Link Prediction, because existing LP models can be cast as multiple-choice Question Answering models, where the question is composed of three words -a subject s, a predi- cate p, and an object o. The answer candidates to these questions are true and false.</p><p>In its original formulation of the Link Predic- tion task, the support is left empty. However, JACK facilitates enriching the questions with additional support -consisting, for instance, of the neigh- bourhood of the entities involved in the question, or sentences from a text corpus that include the entities appearing in the triple in question. Such a setup can be interpreted as an instance of NLI, and existing models not originally designed for solv- ing Link Prediction problems can be trained ef- fortlessly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Experimental setup and results for different mod- els on the three above-mentioned MR tasks are reported in this section.</p><p>Note that our re- implementations or training configurations may not be entirely faithful.We performed slight mod- ifications to original setups where we found this to perform better in our experiments, as indicated in the respective task subsections. However, our results still vary from the reported ones, which we believe is due to the extensive hyper-parameter engineering that went into the original settings, which we did not perform. For each experiment, a ready to use training configuration as well as pre- trained models are part of JACK.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Original F1 JACK F1 Speed #Params   <ref type="table">Table 3</ref>: Link Prediction results, measured using the Mean Reciprocal Rank (MRR) and Hits@10, for DistMult ( <ref type="bibr" target="#b26">Yang et al., 2015), and</ref><ref type="bibr">ComplEx (Trouillon et al., 2016</ref>).</p><p>Link Prediction. For Link Prediction in Knowl- edge Graphs, we report results for our implemen- tations of DistMult ( <ref type="bibr" target="#b26">Yang et al., 2015)</ref> and <ref type="bibr">ComplEx (Trouillon et al., 2016</ref>) on various datasets. Results are otlined in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Demo</head><p>We created three tutorial Jupyter notebooks at https://github.com/uclmr/jack/ tree/master/notebooks to demo JACK's use cases. The quick start notebook shows how to quickly set up, load and run the existing systems for QA and NLI. The model training notebook demonstrates training, testing, evaluating and saving QA and NLI models programmatically. However, normally the user will simply use the provided training script from command line. The model implementation notebook delves deeper into implementing new models from scratch by writing all modules for a custom model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented Jack the Reader (JACK), a shared framework for Machine Reading tasks that will allow component reuse and easy model transfer across both datasets and domains.</p><p>JACK is a new unified Machine Reading frame- work applicable to a range of tasks, developed with the aim of increasing researcher efficiency and code reuse. We demonstrate the flexibility of our framework in terms of three tasks: Ques- tion Answering, Natural Language Inference, and Link Prediction in Knowledge Graphs. With fur- ther model additions and wider user adoption, JACK will support faster and reproducible Ma- chine Reading research, enabling a building-block approach to model design and development.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Accuracy on the SNLI test set achieved 
by cBiLSTM, DAM, and ESIM. 

Question Answering. For the Question An-
swering (QA) experiments we report results for 
our implementations of FastQA (Weissenborn 
et al., 2017), BiDAF (Seo et al., 2016) and, in ad-
dition, our own JackQA implementations. With 
JackQA we aim to provide a fast and accurate 
QA model. Both BiDAF and JackQA are re-
alised using high-level architecture descriptions, 
that is, their architectures are purely defined within 
their respective configuration files. Results of our 
models on the SQuAD (Rajpurkar et al., 2016) 
development set along with additional run-time 
and parameter metrics are presented in Table 1. 
Apart from SQuAD, JACK supports the more re-
cent NewsQA (Trischler et al., 2017) and Trivi-
aQA (Joshi et al., 2017) datasets too. 

Natural Language Inference. For NLI, we re-
port results for our implementations of condi-
tional BiLSTMs (cBiLSTM) (Rocktäschel et al., 
2016), the bidirectional version of conditional 
LSTMs (Augenstein et al., 2016), the Decompos-
able Attention Model (DAM, Parikh et al., 2016) 
and Enhanced LSTM (ESIM, Chen et al., 2017). 
ESIM was entirely implemented as a modular NLI 
model, i.e. its architecture was purely defined in a 
configuration file -see Appendix A for more de-
tails. Our models or training configurations con-
tain slight modifications from the original which 
we found to perform better than the original setup. 
Our results are slightly differ from those reported, 
since we did not always perform an exhaustive 
hyper-parameter search. 

Dataset Model 
MRR Hits@3 Hits@10 

WN18 
DistMult 
0.822 
0.914 
0.936 
ComplEx 0.941 
0.936 
0.947 

WN18RR 
DistMult 
0.430 
0.443 
0.490 
ComplEx 0.440 
0.461 
0.510 

FB15k-237 
DistMult 
0.241 
0.263 
0.419 
ComplEx 0.247 
0.275 
0.428 

</table></figure>

			<note place="foot" n="1"> https://spacy.io 2 https://lucene.apache.org 3 http://lucene.apache.org/solr/ 4 http://scikit-learn.org 5 http://pytorch.org/</note>

			<note place="foot" n="7"> For instance, see https://github.com/uclmr/ jack/blob/master/conf/nli/esim.yaml</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Largescale machine learning on heterogeneous systems. Software available from tensorflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stance detection with bidirectional conditional encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings or EMNLP</title>
		<meeting>or EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
	<note>Andreas Vlachos, and Kalina Bontcheva</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: A shared database of structured general human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Tufts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1962" to="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcíadurán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">GATE: an Architecture for Development of Robust HLT applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamish</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Tablan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minervini</forename><surname>Pasquale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stenetorp</forename><surname>Pontus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Uima: an architectural approach to unstructured information processing in the corporate research environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="327" to="348" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">AllenNLP: A Deep Semantic Natural Language Processing Platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>White paper</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A review of relational machine learning for knowledge graphs. In Proceedings of IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="11" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ Questions for Machine Comprehension of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reasoning about Entailment with Neural Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<idno>abs/1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Theano Development Team</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVSC workshop, ACL pages</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rep4NLP workshop, ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Making neural QA as simple as possible but not simpler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Seiffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<idno>CoRR abs/1710.06481</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Bowman</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Embedding Entities and Relations for Learning and Inference in Knowledge Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
