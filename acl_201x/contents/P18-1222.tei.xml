<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">hyperdoc2vec: Distributed Representations of Hypertext Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialong</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♠</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haisong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent AI Lab School of Information</orgName>
								<orgName type="institution">Renmin University of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">hyperdoc2vec: Distributed Representations of Hypertext Documents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2384" to="2394"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2384</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classification and citation recommendation , in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ubiquitous World Wide Web has boosted re- search interests on hypertext documents, e.g., per- sonal webpages ( <ref type="bibr" target="#b18">Lu and Getoor, 2003)</ref>, Wikipedia pages ( <ref type="bibr" target="#b7">Gabrilovich and Markovitch, 2007)</ref>, as well as academic papers <ref type="bibr" target="#b26">(Sugiyama and Kan, 2010)</ref>. Unlike independent plain documents, a hypertext document (hyper-doc for short) links to another hyper-doc by a hyperlink or citation mark in its textual content. Given this essential distinction, hyperlinks or citations are worth specific model- ing in many tasks such as link-based classifica- tion ( <ref type="bibr" target="#b18">Lu and Getoor, 2003)</ref>, web retrieval ( <ref type="bibr" target="#b21">Page et al., 1999</ref>), entity linking <ref type="bibr" target="#b3">(Cucerzan, 2007)</ref>, and citation recommendation ( <ref type="bibr" target="#b10">He et al., 2010)</ref>.</p><p>To model hypertext documents, various ef- forts <ref type="bibr" target="#b1">(Cohn and Hofmann, 2000;</ref><ref type="bibr" target="#b15">Kataria et al., 2010;</ref><ref type="bibr" target="#b23">Perozzi et al., 2014;</ref><ref type="bibr" target="#b37">Zwicklbauer et al., 2016;</ref> have been made to de- pict networks of hyper-docs as well as their con- tent. Among potential techniques, distributed rep- resentation ( <ref type="bibr" target="#b19">Mikolov et al., 2013;</ref><ref type="bibr" target="#b17">Le and Mikolov, 2014</ref>) tends to be promising since its validity and effectiveness are proven for plain documents on many natural language processing (NLP) tasks.</p><p>Conventional attempts on utilizing embedding techniques in hyper-doc-related tasks generally fall into two types. The first type <ref type="bibr" target="#b0">(Berger et al., 2017;</ref><ref type="bibr" target="#b37">Zwicklbauer et al., 2016</ref>) simply downcasts hyper-docs to plain documents and feeds them into word2vec ( <ref type="bibr" target="#b19">Mikolov et al., 2013</ref>) (w2v for short) or doc2vec ( <ref type="bibr" target="#b17">Le and Mikolov, 2014</ref>) (d2v for short). These approaches involve downgrading hyperlinks and inevitably omit certain information in hyper-docs. However, no previous work inves- tigates the information loss, and how it affects the performance of such downcasting-based adapta- tions. The second type designs sophisticated em- bedding models to fulfill certain tasks, e.g., cita- tion recommendation <ref type="bibr" target="#b14">(Huang et al., 2015b</ref>), pa- per classification ( , and entity linking ( <ref type="bibr" target="#b34">Yamada et al., 2016)</ref>, etc. These models are limited to specific tasks, and it is yet unknown whether embeddings learned for those particular tasks can generalize to others. Based on the above facts, we are interested in two questions:</p><p>• What information should hyper-doc embed- ding models preserve, and what nice property should they possess?</p><p>• Is there a general approach to learning task- independent embeddings of hyper-docs?</p><p>To answer the two questions, we formalize the hyper-doc embedding task, and propose four cri- teria, i.e., content awareness, context awareness, newcomer friendliness, and context intent aware-ness, to assess different models. Then we discuss simple downcasting-based adaptations of existing approaches w.r.t. the above criteria, and demon- strate that none of them satisfy all four. To this end, we propose hyperdoc2vec (h-d2v for short), a general embedding approach for hyper- docs. Different from most existing approaches, h-d2v learns two vectors for each hyper-doc to characterize its roles of citing others and being cited. Owning to this, h-d2v is able to directly model hyperlinks or citations without downgrad- ing them. To evaluate the learned embeddings, we employ two tasks in the academic paper domain 1 , i.e., paper classification and citation recommenda- tion. Experimental results demonstrate the supe- riority of h-d2v. Comparative studies and con- trolled experiments also confirm that h-d2v ben- efits from satisfying the above four criteria.</p><p>We summarize our contributions as follows:</p><p>• We propose four criteria to assess different hyper-document embedding models.</p><p>• We propose hyperdoc2vec, a general em- bedding approach for hyper-documents.</p><p>• We systematically conduct comparisons with competing approaches, validating the superi- ority of h-d2v in terms of the four criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Network representation learning is a related topic to ours since a collection of hyper-docs re- semble a network. To embed nodes in a network, <ref type="bibr" target="#b23">Perozzi et al. (2014)</ref> propose DeepWalk, where nodes and random walks are treated as pseudo words and texts, and fed to w2v for node vectors. <ref type="bibr" target="#b29">Tang et al. (2015b)</ref> explicitly embed second-order proximity via the number of common neighbors of nodes. <ref type="bibr" target="#b9">Grover and Leskovec (2016)</ref> extend Deep- Walk with second-order Markovian walks. To im- prove classification tasks, <ref type="bibr" target="#b32">Tu et al. (2016)</ref> explore a semi-supervised setting that accesses partial la- bels. Compared with these models, h-d2v learns from both documents' connections and contents while they mainly focus on network structures.</p><p>Document embedding for classification is an- other focused area to apply document embeddings. <ref type="bibr" target="#b17">Le and Mikolov (2014)</ref> employ learned d2v vec- tors to build different text classifiers. <ref type="bibr" target="#b28">Tang et al. (2015a)</ref> apply the method in <ref type="table" target="#tab_4">(Tang et al., 2015b)</ref> on word co-occurrence graphs for word embed- dings, and average them for document vectors. For hyper-docs, <ref type="bibr" target="#b8">Ganguly and Pudi (2017)</ref> and  target paper classification in unsuper- vised and semi-supervised settings, respectively. However, unlike h-d2v, they do not explicitly model citation contexts. 's ap- proach also addresses embedding hyper-docs, but involves matrix factorization and does not scale.</p><p>Citation recommendation is a direct downstream task to evaluate embeddings learned for a cer- tain kind of hyper-docs, i.e., academic papers. In this paper we concentrate on context-aware cita- tion recommendation <ref type="bibr" target="#b10">(He et al., 2010</ref>). Some pre- vious studies adopt neural models for this task. <ref type="bibr" target="#b14">Huang et al. (2015b)</ref> propose Neural Probabilistic Model (NPM) to tackle this problem with embed- dings. Their model outperforms non-embedding ones ( <ref type="bibr" target="#b15">Kataria et al., 2010;</ref><ref type="bibr" target="#b30">Tang and Zhang, 2009;</ref><ref type="bibr" target="#b13">Huang et al., 2012)</ref>. <ref type="bibr" target="#b4">Ebesu and Fang (2017)</ref> also exploit neural networks for citation recommenda- tion, but require author information as additional input. Compared with h-d2v, these models are limited in a task-specific setting.</p><p>Embedding-based entity linking is another topic that exploits embeddings to model certain hyper- docs, i.e., <ref type="bibr">Wikipedia (Huang et al., 2015a;</ref><ref type="bibr" target="#b34">Yamada et al., 2016;</ref><ref type="bibr" target="#b5">Fang et al., 2016;</ref><ref type="bibr" target="#b11">He et al., 2013;</ref><ref type="bibr" target="#b37">Zwicklbauer et al., 2016)</ref>, for entity linking <ref type="bibr" target="#b25">(Shen et al., 2015)</ref>. It resembles citation recommendation in the sense that linked entities highly depend on the contexts. Meanwhile, it re- quires extra steps like candidate generation, and can benefit from sophisticated techniques such as collective linking <ref type="bibr" target="#b3">(Cucerzan, 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>We introduce notations and definitions, then for- mally define the embedding problem. We also pro- pose four criteria for hyper-doc embedding models w.r.t their appropriateness and informativeness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations and Definitions</head><p>Let w ∈ W be a word from a vocabulary W , and d ∈ D be a document id (e.g., web page URLs and paper DOIs) from an id collection D. After filter- ing out non-textual content, a hyper-document H is reorganized as a sequence of words and doc ids, <ref type="bibr" target="#b16">(Koehn et al., 2007)</ref> ( <ref type="bibr" target="#b36">Zhao and Gildea, 2010)</ref> ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>)</p><p>Original Source doc</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context words</head><p>Target doc … We also evaluate our model by computing the machine translation BLEU score ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>) using the Moses system ( <ref type="bibr" target="#b16">Koehn et al., 2007</ref> "Word" Vectors … <ref type="bibr">w2v</ref> …We also evaluate our model by computing the machine translation BLEU score ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>) using the Moses system ( <ref type="bibr" target="#b16">Koehn et al., 2007</ref> ( <ref type="bibr" target="#b36">Zhao and Gildea, 2010)</ref> ( <ref type="bibr" target="#b22">Papineni et al., 2002)</ref> …We also evaluate our model by computing the machine translation BLEU score using the    <ref type="figure" target="#fig_1">Figure 1</ref>(a) exemplifies a hyperlink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Problem Statement</head><p>Given a corpus of hyper-docs {H d } d∈D with D and W , we want to learn document and word em- bedding matrices D ∈ R k×|D| and W ∈ R k×|W | simultaneously. The i-th column d i of D is a k- dimensional embedding vector for the i-th hyper- doc with id d i . Similarly, w j , the j-th column of W, is the vector for word w j . Once embed- dings for hyper-docs and words are learned, they can facilitate applications like hyper-doc classifi- cation and citation recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Criteria for Embedding Models</head><p>A reasonable model should learn how contents and hyperlinks in hyper-docs impact both D and W. We propose the following criteria for models:</p><p>• Content aware. Content words of a hyper- doc play the main role in describing it, so the document representation should depend on its own content. For example, the words in <ref type="bibr" target="#b36">Zhao and Gildea (2010)</ref> should affect and contribute to its embedding.</p><p>• Context aware. Hyperlink contexts usu- ally provide a summary for the target docu- ment. Therefore, the target document's vec- tor should be impacted by words that others use to summarize it, e.g., paper <ref type="bibr" target="#b22">Papineni et al. (2002)</ref> and the word "BLEU" in <ref type="figure" target="#fig_1">Figure 1</ref>(a).</p><p>• Newcomer friendly. In a hyper-document network, it is inevitable that some documents are not referred to by any hyperlink in other hyper-docs. If such "newcomers" do not get embedded properly, downstream tasks in- volving them are infeasible or deteriorated.</p><p>• Context intent aware. Words around a hy- perlink, e.g., "evaluate . . . by" in <ref type="figure" target="#fig_1">Figure 1</ref>(a), normally indicate why the source hyper-doc makes the reference, e.g., for general refer- ence or to follow/oppose the target hyper- doc's opinion or practice. Vectors of those context words should be influenced by both documents to characterize such semantics or intents between the two documents.</p><p>We note that the first three criteria are for hyper- docs, while the last one is desired for word vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Representing Hypertext Documents</head><p>In this section, we first give the background of two prevailing techniques, word2vec and doc2vec.</p><p>Then we present two conversion approaches for hyper-documents so that w2v and d2v can be ap- plied. Finally, we address their weaknesses w.r.t. the aforementioned four criteria, and propose our hyperdoc2vec model. In the remainder of this paper, when the context is clear, we mix the use of terms hyper-doc/hyperlink with paper/citation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">word2vec and doc2vec</head><p>w2v <ref type="formula">(</ref>  Model Output <ref type="table">Table 2</ref>: Output of models.</p><formula xml:id="formula_0">D I D O W I W O w2v d2v (pv-dm) × d2v (pv-dbow) × × h-d2v</formula><p>is regarded as a special context vector to average. Analogously, pv-dbow uses IN document vec- tor to predict its words' OUT vectors, following the same structure of skip-gram. Therefore in pv-dbow, words' IN vectors are omitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Adaptation of Existing Approaches</head><p>To represent hyper-docs, a straightforward strat- egy is to convert them into plain documents in a certain way and apply w2v and d2v. Two conver- sions following this strategy are illustrated below.</p><p>Citation as word. This approach is adopted by <ref type="bibr" target="#b0">Berger et al. (2017)</ref>. <ref type="bibr">2</ref> As <ref type="figure" target="#fig_1">Figure 1</ref>(b) shows, doc- ument ids D are treated as a collection of spe- cial words. Each citation is regarded as an oc- currence of the target document's special word.</p><p>After applying standard word embedding meth- ods, e.g., <ref type="bibr">w2v</ref>, we obtain embeddings for both ordinary words and special "words", i.e., docu- ments. In doing so, this approach allows target documents interacting with context words, thus produces context-aware embeddings for them.</p><p>Context as content. It is often observed in aca- demic papers when citing others' work, an author briefly summarizes the cited paper in its citation context. Inspired by this, we propose a context- as-content approach as in <ref type="figure" target="#fig_1">Figure 1</ref>(c). To start, we remove all citations. Then all citation contexts of a target document d t are copied into d t as additional contents to make up for the lost information. Fi- nally, d2v is applied to the augmented documents to generate document embeddings. With this ap- proach, the generated document embeddings are both context-and content-aware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">hyperdoc2vec</head><p>Besides citation-as-word with <ref type="bibr">w2v</ref> and context- as-content with d2v (denoted by d2v-cac for short), there is also an alternative using d2v on documents with citations removed (d2v-nc for <ref type="bibr">2</ref> It is designed for document visualization purposes.</p><p>short). We made a comparison of these approaches in <ref type="table" target="#tab_4">Table 1</ref>   <ref type="bibr" target="#b36">Zhao and Gildea (2010)</ref>, thus not contributing to its embedding. In addition, for papers being just published and having not ob- tained citations yet, they will not appear as special "words" in any text. This makes w2v newcomer- unfriendly, i.e., unable to produce embeddings for them. Second, being trained on a corpus without citations, d2v-nc is obviously not context aware. Finally, in both w2v and d2v-cac, context words interact with the target documents without treat- ing the source documents as backgrounds, which forces IN vectors of words with context intents, e.g., "evaluate" and "by" in <ref type="figure" target="#fig_1">Figure 1</ref>(a), to simply remember the target documents, rather than cap- ture the semantics of the citations.</p><p>The above limitations are caused by the conver- sions of hyper-docs where certain information in citations is lost. For a citation d s , C, d t , citation- as-word only keeps the co-occurrence information between C and d t . Context-as-content, on the other hand, mixes C with the original content of d t . Both approaches implicitly downgrade cita- tions d s , C, d t to C, d t for adaptation purposes.</p><p>To learn hyper-doc embeddings without such limitations, we propose hyperdoc2vec. In this model, two vectors of a hyper-doc d, i.e., IN and OUT vectors, are adopted to represent the docu- ment of its two roles. The IN vector d I character- izes d being a source document. The OUT vector d O encodes its role as a target document. We note that learning those two types of vectors is advan- tageous. It enables us to model citations and con- Formally, for all citations C = {{d s , C, d t }, we aim to optimize the following average log probability objective:</p><formula xml:id="formula_1">max D I ,D O ,W I 1 |C| ds,C,dt∈C log P (d t |d s , C) (1)</formula><p>To model the probability P (d t |d s , C) where d t is cited in d s with C, we average their IN vectors</p><formula xml:id="formula_2">x = 1 1 + |C| d I s + w∈C w I<label>(2)</label></formula><p>and use x to compose a multi-class softmax clas- sifier on all OUT document vectors</p><formula xml:id="formula_3">P (d t |d s , C) = exp(x d O t ) d∈D exp(x d O )<label>(3)</label></formula><p>To model contents' impact on document vec- tors, we simply consider an additional objective function that is identical to pv-dm, i.e., enumer- ate words and contexts, and use the same input ar- chitecture as <ref type="figure" target="#fig_3">Figure 2</ref> to predict the OUT vector of the current word. Such convenience owes to the fact that using two vectors makes the model pa- rameters compatible with those of pv-dm. Note that combining the citation and content objectives leads to a joint learning framework. To facilitate easier and faster training, we adopt an alterna- tive pre-training/fine-tuning or retrofitting frame- work ( <ref type="bibr" target="#b6">Faruqui et al., 2015)</ref>. We initialize with a predefined number of pv-dm iterations, and then optimize Eq. 1 based on the initialization. <ref type="table" target="#tab_4">Train  1,590  512 Up to 1998  Test  150  89  1999  Total  1,740  601 Up to</ref>   <ref type="table">Table 3</ref>: The statistics of three datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Docs Citations Years</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NIPS</head><p>Finally, similar to <ref type="bibr">w2v (Mikolov et al., 2013</ref>) and d2v ( <ref type="bibr" target="#b17">Le and Mikolov, 2014)</ref>, to make training efficient, we adopt negative sampling:</p><formula xml:id="formula_4">log σ(x d O t ) + n i=1 E d i ∼P N (d) log σ(−x d O i )<label>(4)</label></formula><p>and use it to replace every log P (d t |d s , C). Fol- lowing <ref type="bibr" target="#b14">Huang et al. (2015b)</ref>, we adopt a uniform distribution on D as the distribution P N (d).</p><p>Unlike the other models in <ref type="table" target="#tab_4">Table 1</ref>, h-d2v sat- isfies all four criteria. We refer to the example in <ref type="figure" target="#fig_3">Figure 2</ref> to make the points clear. First, when op- timizing Eq. 1 with the instance in <ref type="figure" target="#fig_3">Figure 2</ref>, the update to d <ref type="bibr">O of Papineni et al. (2002)</ref> depends on w I of context words such as "BLEU". Sec- ond, we pre-train d I with contents, which makes the document embeddings content aware. Third, newcomers can depend on their contents for d I , and update their OUT vectors when they are sam- pled 3 in Eq. 4. Finally, the optimization of Eq. 1 enables mutual enhancement between vectors of hyper-docs and context intent words, e.g., "evalu- ate by". Under the background of a machine trans- lation paper <ref type="bibr" target="#b36">Zhao and Gildea (2010)</ref>, the above two words help point the citation to the BLEU pa- per ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>), thus updating its OUT vector. The intent "adopting tools/algorithms" of "evaluate by" is also better captured by iterating over many document pairs with them in between.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we first introduce datasets and ba- sic settings used to learn embeddings. We then discuss additional settings and present experimen- tal results of the two tasks, i.e., document classifi- cation and citation recommendation, respectively.    <ref type="table">Table 5</ref>: F 1 on DBLP when newcomers are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Experimental Settings</head><p>We use three datasets from the academic paper do- main, i.e., NIPS 4 , ACL anthology 5 and DBLP 6 , as shown in <ref type="table">Table 3</ref>. They all contain full text of papers, and are of small, medium, and large size, respectively. We apply ParsCit 7 ( <ref type="bibr" target="#b2">Councill et al., 2008)</ref> to parse the citations and bibliography sec- tions. Each identified citation string referring to a paper in the same dataset, e.g., <ref type="bibr">[1]</ref>   <ref type="bibr">Rehůřek and Sojka, 2010</ref>) is used to implement all w2v and d2v baselines as well as h-d2v. We use cbow for w2v and pv-dbow for d2v, unless otherwise noted. For all three base- lines, we set the (half) context window length to 50. For w2v, d2v, and the pv-dm-based ini- tialization of h-d2v, we run 5 epochs following Gensim's default setting. For h-d2v, its iteration is set to 100 epochs with 1000 negative samples. The dimension size k of all approaches is 100. All other parameters in Gensim are kept as default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Document Classification</head><p>In this task, we classify the research fields of pa- pers given their vectors learned on DBLP. <ref type="bibr">To</ref>  e.g., "Artificial Intelligence" of "Artificial Intelli- gence -Natural Language Processing", leading to 10 unique classes. We then intersect the dataset with DBLP, and obtain 5,975 labeled papers. For w2v and h-d2v outputing both IN and OUT document vectors, we use IN vectors or con- catenations of both vectors as features. For new- comer papers without w2v vectors, we use zero vectors instead. To enrich the features with net- work structure information, we also try concate- nating them with the output of DeepWalk ( <ref type="bibr" target="#b23">Perozzi et al., 2014</ref>), a representative network embedding model. The model is trained on the citation net- work of DBLP with an existing implementation <ref type="bibr">9</ref> and default parameters. An SVM classifier with RBF kernel is used. We perform 5-fold cross vali- dation, and report Macro-and Micro-F 1 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Classification Performance</head><p>In <ref type="table" target="#tab_7">Table 4</ref>, we demonstrate the classification re- sults. We have the following observations. First, adding DeepWalk information almost al- ways leads to better classification performance, except for Macro-F 1 of the d2v-cac approach.</p><p>Second, owning to different context awareness, d2v-cac consistently outperforms d2v-nc in terms of all metrics and settings.</p><p>Third, w2v has the worst performance. The rea- son may be that w2v is neither content aware nor newcomer friendly. We will elaborate more on the impacts of the two properties in Section 5.2.2.</p><p>Finally, no matter whether DeepWalk vectors are used, h-d2v achieves the best F 1 scores. However, when OUT vectors are involved, h-d2v with DeepWalk has slightly worse performance. A possible explanation is that, when h-d2v IN and DeepWalk vectors have enough information to train the SVM classifiers, adding another 100 fea- tures (OUT vectors) only increase the parameter  <ref type="table">Table 6</ref>: Top-10 citation recommendation results (dimension size k = 100).</p><p>space of the classifiers and the training variance. For w2v with or without DeepWalk, it is also the case. This may be because information in <ref type="bibr">w2v</ref>'s IN and OUT vectors is fairly redundant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Impacts of Content Awareness and Newcomer Friendliness</head><p>Because content awareness and newcomer friend- liness are highly correlated in <ref type="table" target="#tab_4">Table 1</ref>, to isolate and study their impacts, we decouple them as fol- lows. In the 5,975 labeled papers, we keep 2,052 with at least one citation, and redo experiments in <ref type="table" target="#tab_7">Table 4</ref>. By carrying out such controlled exper- iments, we expect to remove the impact of new- comers, and compare all approaches only with re- spect to different content awareness. In <ref type="table">Table 5</ref>, we provide the new scores obtained. By comparing <ref type="table" target="#tab_7">Tables 4 and 5</ref>, we observe that w2v benefits from removing newcomers with zero vectors, while all newcomer friendly approaches get lower scores because of fewer training exam- ples. Even though the change, w2v still cannot outperform the other approaches, which reflects the positive impact of content awareness on the classification task. It is also interesting that Deep- Walk becomes very competitive. This implies that structure-based methods favor networks with bet- ter connectivity. Finally, we note that <ref type="table">Table 5</ref> is based on controlled experiments with intentionally skewed data. The results are not intended for com- parison among approaches in practical scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Citation Recommendation</head><p>When writing papers, it is desirable to recommend proper citations for a given context. This could be achieved by comparing the vectors of the context and previous papers. We use all three datasets for this task. Embeddings are trained on papers before 1998, 2012, and 2009, respectively. The remain- ing papers in each dataset are used for testing.</p><p>We compare h-d2v with all approaches in Sec- tion 4.2, as well as NPM 10 (Huang et al., 2015b) mentioned in Section 2, the first embedding-based approach for the citation recommendation task. Note that the inference stage involves interactions between word and document vectors and is non- trivial. We describe our choices as below. First, for <ref type="bibr">w2v vectors, Nalisnick et al. (2016)</ref> suggest that the IN-IN similarity favors word pairs with similar functions (e.g., "red" and "blue"), while the IN-OUT similarity characterizes word co-occurrence or compatibility (e.g., "red" and "bull"). For citation recommendation that relies on the compatibility between context words and cited papers, we hypothesize that the IN-for-OUT (or I4O for short) approach will achieve better results. Therefore, for w2v-based approaches, we average IN vectors of context words, then score and and rank OUT document vectors by dot product.</p><p>Second, for d2v-based approaches, we use the learned model to infer a document vector d for the context words, and use d to rank IN document vectors by cosine similarity. Among multiple at- tempts, we find this choice to be optimal.</p><p>Third, for h-d2v, we adopt the same scoring and ranking configurations as for <ref type="bibr">w2v</ref>.</p><p>Finally, for NPM, we adopt the same ranking strategy as in <ref type="bibr" target="#b14">Huang et al. (2015b)</ref>. Following them, we focus on top-10 results and report the Recall, MAP, MRR, and nDCG scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Recommendation Performance</head><p>In <ref type="table">Table 6</ref>, we report the citation recommendation results. Our observations are as follows.</p><p>First, among all datasets, all methods perform relatively well on the medium-sized ACL dataset. This is because the smallest NIPS dataset provides Rec@10 (%) <ref type="bibr">w2v</ref> (I4O) d2v-nc d2v-cac NPM h-d2v too few citation contexts to train a good model. Moreover, DBLP requires a larger dimension size k to store more information in the embedding vec- tors. We increase k and report the Rec@10 scores in <ref type="figure" target="#fig_6">Figure 3</ref>. We see that all approaches have bet- ter performance when k increases to 200, though d2v-based ones start to drop beyond this point. Second, the I4I variant of w2v has the worst performance among all approaches. This obser- vation validates our hypothesis in Section 5.3.</p><p>Third, the d2v-cac approach outperforms its variant d2v-nc in terms of all datasets and met- rics. This indicates that context awareness matters in the citation recommendation task.</p><p>Fourth, the performance of NPM is sandwiched between those of w2v's two variants. We have tried our best to reproduce it. Our explanation is that NPM is citation-as-word-based, and only de- pends on citation contexts for training. Therefore, it is only context aware but neither content aware nor newcomer friendly, and behaves like w2v.</p><p>Finally, when retrofitting pv-dm, h-d2v gen- erally has the best performance. When we substi- tute pv-dm with random initialization, the perfor- mance is deteriorated by varying degrees on differ- ent datasets. This implies that content awareness is also important, if not so important than context awareness, on the citation recommendation task.    <ref type="table">Table 5, this table is</ref> also based on controlled experiments and not in- tended for comparing approaches.  <ref type="bibr">w2v</ref> Result Ranking of d2v-cac Result Ranking of h-d2v</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Impact of Newcomer Friendliness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">Impact of Context Intent Awareness</head><p>. . . We also evaluate our model by computing the machine trans- lation BLEU score ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>) using the Moses system ( <ref type="bibr" target="#b16">Koehn et al., 2007</ref> Statistical Phrase-Based Translation 3. Improved Statistical Align- ment Models 4. HMM-Based Word Align- ment in Statistical Translation 5. Moses: Open Source Toolkit for Statistical Machine Trans- lation <ref type="table">Table 9</ref>: Papers recommended by different approaches for a citation context in <ref type="bibr" target="#b36">Zhao and Gildea (2010)</ref>.  We omit d2v-nc because it is very inferior to d2v-cac. We have the following observations. First, <ref type="bibr" target="#b31">Teufel et al. (2006)</ref>'s feature-engineering- based approach has the best performance. Note that we cannot obtain their original cross valida- tion split, so the comparison may not be fair and is only for consideration in terms of numbers.</p><formula xml:id="formula_5">W e a k C o C o G M C o C o R 0 C o C o - C o C o X Y P B</formula><p>Second, among all embedding-based methods, h-d2v has the best citation function classification results, which is close to <ref type="bibr" target="#b31">Teufel et al. (2006)</ref>'s.</p><p>Finally, the d2v-cac vectors are only good at Neutral, the largest class. On the other classes and global F 1 , they are outperformed by w2v vectors.</p><p>To study how citation function affects citation recommendation, we combine the 2,824 labeled citation contexts and another 1,075 labeled con- texts the authors published later to train an SVM, and apply it to the DBLP testing set to get cita- tion functions. We evaluate citation recommenda- tion performance of <ref type="bibr">w2v</ref>   To better investigate the impact of context intent awareness, <ref type="table">Table 9</ref> shows recommended papers of the running example of this paper. Here, <ref type="bibr" target="#b36">Zhao and Gildea (2010)</ref> cited the BLEU metric ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>) and Moses tools ( <ref type="bibr" target="#b16">Koehn et al., 2007)</ref> of machine translation. However, the additional words "machine translation" lead both w2v and d2v-cac to recommend many machine transla- tion papers. Only our h-d2v manages to recog- nize the citation function "using tools/algorithms (PBas)", and concentrates on the citation intent to return the right papers in top-5 results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We focus on the hyper-doc embedding problem. We propose that hyper-doc embedding algorithms should be content aware, context aware, new- comer friendly, and context intent aware. To meet all four criteria, we propose a general approach, hyperdoc2vec, which assigns two vectors to each hyper-doc and models citations in a straight- forward manner. In doing so, the learned embed- dings satisfy all criteria, which no existing model is able to. For evaluation, paper classification and citation recommendation are conducted on three academic paper datasets. Results confirm the ef- fectiveness of our approach. Further analyses also demonstrate that possessing the four properties helps h-d2v outperform other models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Moses system … … machine translation BLEU score … … Moses system … (c) Context as content.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of Zhao and Gildea (2010) citing Papineni et al. (2002) and existing approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>in terms of the four criteria stated in Sec- tion 3.3. It is observed that none of them satisfy all criteria, where the reasons are as follows. First, w2v is not content aware. Following our examples in the academic paper domain, consider the paper (hyper-doc) Zhao and Gildea (2010) in Figure 1(a), from w2v's perspective in Fig- ure 1(b), ". . . computing the machine translation BLEU . . . " and other text no longer have as- sociation with</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The hyperdoc2vec model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Varying k on DBLP. The scores of w2v keeps increasing to 26.63 at k = 1000, and then begins to drop. Although at the cost of a larger model and longer training/inference time, it still cannot outperform h-d2v of 30.37 at k = 400.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: F 1 of citation function classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(I4O), d2v-cac, and h-d2v on a per-citation-function basis. In Fig- ure 5, we break down Rec@10 scores on citation functions. On the six largest classes (marked by solid dots), h-d2v outperforms all competitors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Rec@10 w.r.t. citation functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>with some surrounding words C appear in the hyper-doc of d s , i.e., H ds , we stipulate that a hyper-link d s , C, d t is formed. Herein d s , d t ∈ D are ids of the source and tar- get documents, respectively; C ⊆ W are context words.</head><label></label><figDesc></figDesc><table>i.e., W ∪D. For example, web pages could be sim-
plified as streams of words and URLs, and papers 
are actually sequences of words and cited DOIs. 
If a document id d t </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Analysis of tasks and approaches w.r.t. desired properties. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 4 : F 1 scores on DBLP.</head><label>4</label><figDesc></figDesc><table>Model 
Content Aware/ 
Original 
w/ DeepWalk 
Newcomer Friendly Macro Micro Macro Micro 

DeepWalk 
-
66.57 76.56 66.57 76.56 

w2v (I) 
× / × 
19.77 47.32 59.80 72.90 
w2v (I+O) 
× / × 
15.97 45.66 50.77 70.08 

d2v-nc 
/ 
61.54 73.73 69.37 78.22 
d2v-cac 
/ 
65.23 75.93 70.43 78.75 
h-d2v (I) 
/ 
58.59 69.79 66.99 75.63 
h-d2v (I+O) 
/ 
66.64 75.19 68.96 76.61 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head></head><label></label><figDesc>ob- tain labels, we use Cora 8 , a small dataset of Com- puter Science papers and their field categories. We keep the first levels of the original categories, 4 https://cs.nyu.edu/ roweis/data.html 5 http://clair.eecs.umich.edu/aan/index.php (2013 release) 6 http://zhou142.myweb.cs.uwindsor.ca/academicpaper.html This page has been unavailable recently. They provide a larger CiteSeer dataset and a collection of DBLP paper ids. To better interpret results from the Computer Science perspective, we intersect them and obtain the</figDesc><table>DBLP dataset. 
7 https://github.com/knmnyn/ParsCit 
8 http://people.cs.umass.edu/˜mccallum/data.html 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>MRR nDCG Rec MAP MRR nDCG Rec MAP MRR nDCG</head><label></label><figDesc></figDesc><table>Model 
NIPS 
ACL Anthology 
DBLP 
Rec MAP w2v (cbow, I4I) 
5.06 1.29 1.29 2.07 12.28 5.35 5.35 6.96 3.01 1.00 1.00 1.44 
w2v (cbow, I4O) 
12.92 6.97 6.97 8.34 15.68 8.54 8.55 10.23 13.26 7.29 7.33 8.58 
d2v-nc (pv-dbow, cosine) 
14.04 3.39 3.39 5.82 21.09 9.65 9.67 12.29 7.66 3.25 3.25 4.23 
d2v-cac (same as d2v-nc) 
14.61 4.94 4.94 7.14 28.01 11.82 11.84 15.59 15.67 7.34 7.36 9.16 
NPM (Huang et al., 2015b) 
7.87 2.73 3.13 4.03 12.86 5.98 5.98 7.59 6.87 3.28 3.28 4.07 

h-d2v (random init, I4O) 
3.93 0.78 0.78 1.49 30.98 16.76 16.77 20.12 17.22 8.82 8.87 10.65 
h-d2v (pv-dm retrofitting, I4O) 15.73 6.68 6.68 8.80 31.93 17.33 17.34 20.76 21.32 10.83 10.88 13.14 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 7 analyzes</head><label>7</label><figDesc></figDesc><table>the impact of newcomer friendli-
ness. Opposite from what is done in Section 5.2.2, 
we only evaluate on testing examples where at 
least a ground-truth paper is a newcomer. Please 
note that newcomer unfriendly approaches do not 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>DBLP results evaluated on 63,342 cita-
tion contexts with newcomer ground-truth. 

Category Description 

Weak 
Weakness of cited approach 

CoCoGM Contrast/Comparison in Goals/Methods (neutral) 
CoCo-
Work stated to be superior to cited work 
CoCoR0 Contrast/Comparison in Results (neutral) 
CoCoXY Contrast between 2 cited methods 

PBas 
Author uses cited work as basis or starting point 
PUse 
Author uses tools/algorithms/data/definitions 
PModi 
Author adapts or modifies tools/algorithms/data 
PMot 
This citation is positive about approach used or 
problem addressed (used to motivate work in cur-
rent paper) 
PSim 
Author's work and cited work are similar 
PSup 
Author's work and cited work are compati-
ble/provide support for each other 
Neut 
Neutral description of cited work, or not enough 
textual evidence for above categories, or unlisted 
citation function 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Annotation scheme of citation functions 
in Teufel et al. (2006). 

necessarily get zero scores. The table shows that 
newcomer friendly approaches are superior to un-
friendly ones. Note that, like </table></figure>

			<note place="foot" n="1"> Although limited in tasks and domains, we expect that our embedding approach can be potentially generalized to, or serve as basis to more sophisticated methods for, similar tasks in the entity domain, e.g., Wikipedia page classification and entity linking. We leave them for future work.</note>

			<note place="foot" n="3"> Given a relatively large n.</note>

			<note place="foot" n="9"> https://github.com/phanein/deepwalk</note>

			<note place="foot" n="10"> Note that the authors used n = 1000 for negative sampling, and did not report the number of training epoches. After many trials, we find that setting the number of both the negative samples and epoches at 100 to be relatively effective and affordable w.r.t. training time.</note>

			<note place="foot" n="11"> The number is 2,829 in the original paper. The inconsistency may be due to different regular expressions we used.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Citation-driven document exploration via word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Mcdonough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><forename type="middle">M</forename><surname>Seversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Vis. Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="691" to="700" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The missing link-A probabilistic model of document content and hypertext connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 13, Papers from Neural Information Processing Systems (NIPS) 2000</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="430" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parscit: an open-source CRF reference string parsing package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Councill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation, LREC</title>
		<meeting>the International Conference on Language Resources and Evaluation, LREC</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large-scale named entity disambiguation based on wikipedia data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silviu Cucerzan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="708" to="716" />
		</imprint>
	</monogr>
	<note>EMNLPCoNLL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural citation network for context-aware citation recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Ebesu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1093" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Entity disambiguation by knowledge and text jointly embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>CoNLL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujay</forename><surname>Kumar Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1606" to="1615" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2015</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Computing semantic relatedness using wikipediabased explicit semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Paper2vec: Combining graph and text information for scientific paper representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyajit</forename><surname>Ganguly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Pudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval-39th European Conference on IR Research</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="383" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context-aware citation recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web, WWW 2010</title>
		<meeting>the 19th International Conference on World Wide Web, WWW 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning entity representation for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Leveraging deep neural networks and knowledge graphs for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">P</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<idno>CoRR abs/1504.07678</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recommending citations: translating papers into references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Kataria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Caragea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st ACM International Conference on Information and Knowledge Management, CIKM&apos;12</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1910" to="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A neural probabilistic model for context based citation recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2404" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Utilizing context in generative bayesian models for linked corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Kataria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Bhatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentyFourth AAAI Conference on Artificial Intelligence</title>
		<meeting>the TwentyFourth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2010</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2007, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th International Conference on Machine Learning, ICML 2014</title>
		<meeting>the 31th International Conference on Machine Learning, ICML 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Link-based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning, Proceedings of the Twentieth International Conference (ICML</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving document ranking with dual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">T</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web, WWW 2016, Companion Volume</title>
		<meeting>the 25th International Conference on World Wide Web, WWW 2016, Companion Volume</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="83" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajeev</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deepwalk: online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;14</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Radimřehůřekradimˇradimřehůřek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. ELRA</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks. ELRA<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Entity linking with a knowledge base: Issues, techniques, and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scholarly paper recommendation via user&apos;s recent research interests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazunari</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Joint International Conference on Digital Libraries, JCDL 2010</title>
		<meeting>the 2010 Joint International Conference on Digital Libraries, JCDL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Modeling mention, context and entity with neural networks for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentyFourth International Joint Conference on Artificial Intelligence, IJCAI 2015</title>
		<meeting>the TwentyFourth International Joint Conference on Artificial Intelligence, IJCAI 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1333" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PTE: predictive text embedding through large-scale heterogeneous text networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1165" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">LINE: large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW 2015</title>
		<meeting>the 24th International Conference on World Wide Web, WWW 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A discriminative approach to topic-based citation recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Knowledge Discovery and Data Mining, 13th Pacific-Asia Conference</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="572" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic classification of citation function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tidhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP 2007, Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Max-margin deepwalk: Discriminative learning of network representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunchao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weicheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3889" to="3895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Linked document embedding for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International Conference on Information and Knowledge Management, CIKM 2016</title>
		<meeting>the 25th ACM International Conference on Information and Knowledge Management, CIKM 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="115" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint learning of the embedding of words and entities for named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuya</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Takeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshiyasu</forename><surname>Takefuji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>CoNLL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="250" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Network representation learning with rich text information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015</title>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2111" to="2117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A fast fertility hidden markov model for word alignment using MCMC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="596" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Robust and collective entity disambiguation through semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Zwicklbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christin</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="425" to="434" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
