<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Well can We Learn Interpretable Entity Types from Text?</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
							<email>dirk@cst.dk</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Language Technology</orgName>
								<orgName type="institution">University of Copenhagen Njalsgade 140</orgName>
								<address>
									<postCode>2300</postCode>
									<settlement>Copenhagen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Well can We Learn Interpretable Entity Types from Text?</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="482" to="487"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many NLP applications rely on type systems to represent higher-level classes. Domain-specific ones are more informative , but have to be manually tailored to each task and domain, making them inflexible and expensive. We investigate a largely unsupervised approach to learning interpretable, domain-specific entity types from unlabeled text. It assumes that any common noun in a domain can function as potential entity type, and uses those nouns as hidden variables in a HMM. To constrain training, it extracts co-occurrence dictionaries of entities and common nouns from the data. We evaluate the learned types by measuring their prediction accuracy for verb arguments in several domains. The results suggest that it is possible to learn domain-specific entity types from unlabeled data. We show significant improvements over an informed baseline, reducing the error rate by 56%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many NLP applications, such as question answer- ing (QA) or information extraction (IE), use type systems to represent relevant semantic classes. Types allow us to find similarities at a higher level to group lexically different entities together. This helps to filter out candidates that violate certain constraints (e.g., in QA, if the intended answer type is PERSON, we can ignore all candidate an- swers with a different type), but is also used for feature generation and fact-checking.</p><p>A central question is: where do the types come from? Typically, they come from a hand- constructed set. This has some disadvantages. Domain-general types, such as named entities or WordNet supersenses <ref type="bibr" target="#b4">(Fellbaum, 1998)</ref>, often fail to capture critical domain-specific information (in the medical domain, we might want ANTIBI- OTIC, SEDATIVE, etc., rather than just ARTI- FACT). Domain-specific types perform much bet- ter <ref type="bibr" target="#b5">(Ferrucci et al., 2010</ref>), but must be manually adapted to each new domain, which is expensive. Alternatively, unsupervised approaches ( <ref type="bibr" target="#b12">Ritter et al., 2010)</ref> can be used to learn clusters of similar words, but the resulting types (=cluster numbers) are not human-interpretable, which makes analy- sis difficult. Furthermore, it requires us to define the number of clusters beforehand.</p><p>Ideally, we would like to learn domain-specific types directly from data. To this end, pattern- based approaches have long been used to induce type systems <ref type="bibr" target="#b6">(Hearst, 1992;</ref><ref type="bibr" target="#b8">Kozareva et al., 2008)</ref>. Recently, <ref type="bibr" target="#b7">Hovy et al. (2011)</ref> proposed an ap- proach that uses co-occurrence patterns to find en- tity type candidates, and then learns their appli- cability to relation arguments by using them as la- tent variables in a first-order HMM. However, they only evaluate their method using human sensibil- ity judgements for one domain. While this shows that the types are coherent, it does not tell us much about their applicability.</p><p>We extend their approach with three important changes:</p><p>1. we evaluate the types by measuring accuracy when using them in an extrinsic task, 2. we evaluate on more than one domain, and 3. we explore a variety of different models.</p><p>We measure prediction accuracy when us- ing the learned types in a selectional restriction task for frequent verbs. E.g., given the rela- tion throw(X, pass) in the football domain, we compare the model prediction to the gold data X=QUARTERBACK. The results indicate that the learned types can be used to in relation extraction tasks.</p><p>Our contributions in this paper are:</p><p>• we empirically evaluate an approach to learn- ing types from unlabeled data</p><p>• we investigate several domains and models</p><p>• the learned entity types can be used to predict selectional restrictions with high accuracy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In relation extraction, we have to identify the re- lation elements, and then map the arguments to types.</p><p>We follow an open IE approach ( <ref type="bibr" target="#b1">Banko and Etzioni, 2008)</ref> and use dependencies to identify the elements. In contrast to most previous work ( <ref type="bibr" target="#b10">Pardo et al., 2006;</ref><ref type="bibr" target="#b19">Yao et al., 2011;</ref><ref type="bibr" target="#b20">Yao et al., 2012)</ref>, we have no pre-defined set of types, but try to learn it along with the relations. Some ap- proaches use types from general data bases such as Wikipedia, <ref type="bibr">Freebase, etc. (Yan et al., 2009;</ref><ref type="bibr" target="#b3">Eichler et al., 2008;</ref><ref type="bibr" target="#b14">Syed and Viegas, 2010)</ref>, side- stepping the question how to construct those DBs in the first place. We are less concerned with ex- traction performance, but focus on the accuracy of the learned type system by measuring how well it performs in a prediction task. <ref type="bibr" target="#b17">Talukdar et al. (2008)</ref> and <ref type="bibr" target="#b16">Talukdar and Pereira (2010)</ref> present graph-based approaches to the sim- ilar problem of class-instance learning. While this provides a way to discover types, it requires a large graph that does not easily generalize to new instances (transductive), since it produces no predictive model. The models we use are trans- ductive and can be applied to unseen data. Our approach follows <ref type="bibr" target="#b7">Hovy et al. (2011)</ref>. However, they only evaluate one model on football by col- lecting sensibility ratings from Mechanical Turk. Our method provides extrinsic measures of perfor- mance on several domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Our goal is to find semantic type candidates in the data, and apply them in relation extraction to see which ones are best suited. We restrict ourselves to verbal relations. We build on the approach by <ref type="bibr" target="#b7">Hovy et al. (2011)</ref>, which we describe briefly be- low. It consists of two parts: extracting the type candidates and fitting the model.</p><p>The basic idea is that semantic types are usu- ally common nouns, often frequent ones from the  domain at hand. Thus all common nouns are pos- sible types, and can be used as latent variables in an HMM. By estimating emission and transition parameters with EM, we can learn the subset of nouns to apply. However, assuming the set of all common nouns as types is intractable, and would not al- low for efficient learning. To restrict the search space and improve learning, we first have to learn which types modify entities and record their co- occurrence, and use this as dictionary. Dictionary Construction The number of com- mon nouns in a domain is generally too high to consider all of them for every entity. A com- mon way to restrict the number of types is to pro- vide a dictionary that lists all legal types for each entity <ref type="bibr" target="#b9">(Merialdo, 1994;</ref><ref type="bibr" target="#b11">Ravi and Knight, 2009;</ref><ref type="bibr" target="#b15">Täckström et al., 2013)</ref>. To construct this dictio- nary, we collect for each entity (i.e., a sequence of words labeled with NNP or NNPS tags) in our data all common nouns (NN, NNS) that modify it. These are 1. nominal modifiers ("judge Scalosi ..."), 2. appositions ("Tilton, a professor at ..."), and 3. copula constructions ("Finton, who is the in- vestor ...").</p><p>These modifications can be collected from the de- pendency parse trees. For each entity, we store the type candidates and their associated counts. See <ref type="figure" target="#fig_2">Figure 2</ref> for examples. We only consider types observed more than 10 times. Any entity with- out type information, as well as dictionary entities with only singleton types are treated as unknown tokens ("UNK"). We map UNK to the 50 most common types in the dictionary. Verbs are con- sidered to each have their own type, i.e., token and label for verbs are the same. We do not modify this step.</p><p>Original Model Hovy et al. (2011) construct a HMM using subject-verb-object (SVO) parse triples as observations, and the type candidates as hidden variables. Similar models have been used in ( <ref type="bibr" target="#b0">Abney and Light, 1999;</ref><ref type="bibr" target="#b10">Pardo et al., 2006</ref>).</p><p>We estimate the free model parameters with EM <ref type="bibr" target="#b2">(Dempster et al., 1977)</ref>, run for a fixed number of iterations <ref type="formula">(30)</ref> or until convergence.</p><p>Note that Forward-backward EM has time com- plexity of O(N 2 T ), where N is the number of states, and T the number of time steps. T = 3 in the model formulations used here, but N is much larger than typically found in NLP tasks (see also <ref type="table" target="#tab_2">Table 3</ref>). The only way to make this tractable is to restrict the free parameters the model needs to estimate to the transitions.</p><p>The model is initialized by jointly normalizing 1 the dictionary counts to obtain the emission pa- rameters, which are then fixed (except for the un- known entities (P (word = UNK|type = ·)). Tran- sition parameters are initialized uniformly (re- stricted to potentially observable type sequences), and kept as free parameters for the model to opti- mize.</p><p>Common nouns can be both hidden variables and observations in the model, so they act like an- notated items: their legal types are restricted to the identity. All entities are thus constrained by the dictionary, as in <ref type="bibr" target="#b9">(Merialdo, 1994)</ref>. To further con- strain the model, only the top three types of each entity are considered. Since the type distribution typically follows a Zipf curve, this still captures most of the information.</p><p>The model can be fully specified as P (x, y) = P (y 1 )·P (x 1 |y 1 ) 3 i=2 P (y i |y i−1 )·P (x i |y i )</p><p>(1) where x is an input triple of a verb and its argu- ments, and y a sequence of types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Extending the Model</head><p>The model used by Hovy et al. (2011) was a sim- ple first order HMM, with the elements in SVO or- der (see <ref type="figure" target="#fig_3">Figure 3a)</ref>. We observe two points: we al- ways deal with the same number of elements, and we have observed variables. We can thus move from a sequential model to a general graphical model by adding transitions and re-arranging the structure.</p><p>Since we do not model verbs (they each have their identity as type), they act like observed vari- ables. We can thus move them in first position and condition the subject on it (3b). By adding additional transitions, we can con- strain the latent variables further. This is similar to moving from a first to a second order HMM. In contrast to the original model, we also distinguish between unknown entities in the first and second argument position.</p><p>The goal of these modifications is to restrict the number of potential values for the argument po- sitions. This allows us to use the models to type individual instances. In contrast, the objective in <ref type="bibr" target="#b7">Hovy et al. (2011)</ref> was to collect frequent relation templates from a domain to populate a knowledge base.</p><p>The modifications presented here extend to Football Finances Law system arg1 arg2 avg ∆BL arg1 arg2 avg ∆BL arg1 arg2 avg ∆BL baseline 0.28 0.26 0.27 - 0.39 0.42 0.41 - 0.37 0.32 0.35 - orig.</p><p>0.05 0.23 0.14 -0.13 0.08 0.39 0.23 -0.18 0.06 0.31 0.18 -0.17 VSO, seq. 0.37 0.28 0.32 +0.05 0.38 0.45 0.41 0.0 0.45 0.37 0.41 +0.06 SVO, net 0.63 0.60 0.62 +0.35 0.55 0.63 0.59 +0.18 0.69 0.68 0.68 +0.33 VSO, net 0.66 0.58 0.62 +0.35 0.61 0.54 0.57 +0.16 0.71 0.62 0.66 +0.31 <ref type="table">Table 1</ref>: Accuracy for most frequent sense baseline and different models on three domains. Italic num- bers denote significant improvement over baseline (two-tailed t-test at p &lt; 0.01). ∆BL = difference to baseline.  verbs with more than two arguments, but in the present paper, we focus on binary relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Football</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Since the labels are induced dynamically from the data, traditional precision/recall measures, which require a known ground truth, are difficult to ob- tain. Hovy et al. (2011) measured sensibility by obtaining human ratings and measuring weighted accuracies over all relations. While this gives an intuition of the general methodology, it is harder to put in context. Here, we want to evaluate the model's performance in a downstream task. We measure its ability to predict the correct types for verbal arguments. We evaluate on three different domains.</p><p>As test case, we use a cloze test, or fill-in-the- blank. We select instances that contain a type- candidate word in subject or object position and replace that word with the unknown token. We can then compare the model's prediction to the origi- nal word to measure accuracy.  <ref type="formula">2012)</ref>, we use articles whose content meta- data field contains certain labels to distinguish data from different domains. We use the labels Foot- ball 2 , Law and Legislation, and Finances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>We remove meta-data and lists, tokenize, parse, and lemmatize all articles. We then automatically extract subject-verb-object (SVO) triples from the parses, provided the verb is a full verb. Similarly to ( <ref type="bibr" target="#b10">Pardo et al., 2006</ref>), we focus on the top 100 full verbs for efficiency reasons, though nothing in our approach prevents us from extending it to all verbs. For each domain, we select all instances which have a potential type (common noun) in at least one argument position. These serve as cor- pus.  As test data, we randomly select a subset of 1000 instances for each argument, provided they contain one of the 50 most frequent types in sub- ject or object position, such as player in "player throw pass". This serves as gold data. We then replace those types by UNK (i.e., we get "UNK throw pass") and use this as test set for our model. <ref type="bibr">3</ref> Table <ref type="table" target="#tab_2">3</ref> shows that the domains vary with re-spect to the ratio of unique types to unique enti- ties. Football uses many different entities (e.g., team and player names), but has few types (e.g., player positions), while the other domains use more types, but fewer entities (e.g., company names, law firms, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Football Finances</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>We run Viterbi decoding on each test set with our trained model to predict the most likely type for the unknown entities. We then compare these pre- dictions to the type in the respective gold data and compute the accuracy for each argument position. As baseline, we predict the argument types most frequently observed for the particular verb in train- ing, e.g., predict PLAYER as subject of tackle in football. We evaluate the influence of the different model structures on performance. <ref type="table">Table 1</ref> shows the accuracy of the different mod- els in the prediction task for the three different do- mains. The low results of the informed baseline indicate the task complexity. We note that the original model, a bigram HMM with SVO order <ref type="figure" target="#fig_3">(Figure 3a)</ref>, fails to improve accu- racy over the baseline (although its overall results were judged sensible). Changing the input order to VSO <ref type="figure" target="#fig_3">(Figure 3b</ref>) improves accuracy for both arguments over SVO order and the baseline, albeit not significantly. The first argument gains more, since conditioning the subject type on the (unam- biguous) verb is more constrained than starting out with the subject. Conditioning the object directly upon the subject creates sparser bigrams, which capture "who does what to whom".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Moving from the HMMs to a general graphi- cal model structure <ref type="figure" target="#fig_3">(Figures 3c and d)</ref> creates a sparser distribution and significantly improves ac- curacy across the board. Again, the position of the verb makes a difference: in SVO order, accuracy for the second argument is better, while in VSO order, accuracy for the subject increases. This in- dicates that direct conditioning on the verb is the strongest predictor. Intuitively, knowing the verb restricts the possible arguments much more than knowing the arguments restrict the possible verbs (the types of entities who can throw something are becomes almost impossible to predict without further context, even for humans (compare "UNK make UNK").</p><p>limited, but knowing that the subject is a quarter- back still allows all kinds of actions).</p><p>We also compute the mean reciprocal rank (MRR) for each condition (see <ref type="table" target="#tab_0">Table 2</ref>). MRR de- notes the inverse rank in the model's k-best output at which the correct answer occurs, i.e., <ref type="bibr">1</ref> k . The result gives us an intuition of "how far off" the model predictions are. Across domains, the cor- rect answer is found on average among the top two (rank 1.36). Note that since MRR require k- best outputs, we cannot compute a measure for the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We evaluated an approach to learning domain- specific interpretable entity types from unlabeled data. Type candidates are collected from patterns and modeled as hidden variables in graphical mod- els. Rather than using human sensibility judge- ments, we evaluate prediction accuracy for selec- tional restrictions when using the learned types in three domains. The best model improves 35 per- centage points over an informed baseline. On av- erage, we reduce the error rate by 56%. We con- clude that it is possible to learn interpretable type systems directly from data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of input sentence x and output types for the HMM. Note that the verb type is treated as observed variable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of dictionary entries with counts. Types in brackets are not considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Original SVO. model (a), modified VSO order (b), extension to general models (c and d)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Like Yao et al. (2012) and Hovy et al. (2011), we derive our data from the New York Times (NYT) corpus (Sandhaus, 2008). It contains several years worth of articles, manually annotated with meta- data such as author, content, etc. Similar to Yao et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Mean reciprocal rank for models on three domains.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Statistics for the three domains.</figDesc><table></table></figure>

			<note place="foot" n="1"> This preserves the observed entity-specific distributions. Under conditional normalization, the type candidates from frequent entities tend to dominate those of infrequent entities. I.e., the model favors an unlikely candidate for entity a if it is frequent for entity b.</note>

			<note place="foot" n="2"> The data likely differs from Hovy et al. (2011). 3 We omit cases with two unknown arguments, since this</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The author would like to thank Victoria Fossum, Eduard Hovy, Kevin Knight, and the anonymous reviewers for their invaluable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hiding a semantic hierarchy in a Markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Unsupervised Learning in Natural Language Processing</title>
		<meeting>the ACL Workshop on Unsupervised Learning in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">67</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The tradeoffs between open and traditional relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
	<note>Rubin</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Unsupervised relation extraction from web documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Eichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holmer</forename><surname>Hemsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Neumann</surname></persName>
		</author>
		<ptr target="http://www.lrecconf.org/proceedings/lrec2008" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">WordNet: an electronic lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press USA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building Watson: An overview of the DeepQA project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th conference on Computational linguistics</title>
		<meeting>the 14th conference on Computational linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of domain-specific knowledge from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1466" to="1475" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semantic class learning from the web with hyponym pattern linkage graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1048" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tagging English text with a probabilistic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Merialdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="171" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised Learning of Verb Argument Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Minimized Models for Unsupervised Part-of-Speech Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="504" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A latent dirichlet allocation method for selectional preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><forename type="middle">Etzioni</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="424" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<title level="m">The New York Times Annotated Corpus. Number LDC2008T19. Linguistic Data Consortium</title>
		<editor>Evan Sandhaus</editor>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A hybrid approach to unsupervised relation discovery based on linguistic analysis and semantic typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zareen</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelyne</forename><surname>Viegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading</title>
		<meeting>the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="105" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Token and type constraints for cross-lingual part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Experiments in graph-based semi-supervised learning methods for class-instance acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1473" to="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weakly-supervised acquisition of labeled class instances using graph random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Reisinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Pas¸capas¸ca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="582" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised relation extraction by mining wikipedia texts using information from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenglu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1021" to="1029" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structured relation discovery using generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1456" to="1466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised relation discovery with sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="712" to="720" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
