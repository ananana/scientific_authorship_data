<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient and Robust Question Answering from Minimal Context over Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University 1</orgName>
								<address>
									<country>Salesforce Research</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University 1</orgName>
								<address>
									<country>Salesforce Research</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University 1</orgName>
								<address>
									<country>Salesforce Research</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Seoul National University 1</orgName>
								<address>
									<country>Salesforce Research</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Efficient and Robust Question Answering from Minimal Context over Documents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1725" to="1735"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1725</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Neural models for question answering (QA) over documents have achieved significant performance improvements. Although effective, these models do not scale to large corpora due to their complex mod-eling of interactions between the document and the question. Moreover, recent work has shown that such models are sensitive to adversarial inputs. In this paper, we study the minimal context required to answer the question, and find that most questions in existing datasets can be answered with a small set of sentences. Inspired by this observation, we propose a simple sentence selector to select the minimal set of sentences to feed into the QA model. Our overall system achieves significant reductions in training (up to 15 times) and inference times (up to 13 times), with accuracy comparable to or better than the state-of-the-art on SQuAD, NewsQA, TriviaQA and SQuAD-Open. Furthermore, our experimental results and analyses show that our approach is more robust to adversarial inputs.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of textual question answering (QA), in which a machine reads a document and answers a question, is an important and challenging problem in natural language processing. Recent progress in performance of QA models has been largely due to the variety of available QA datasets ( <ref type="bibr" target="#b25">Richardson et al., 2013;</ref><ref type="bibr" target="#b7">Hermann et al., 2015;</ref><ref type="bibr" target="#b24">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b32">Trischler et al., 2016;</ref><ref type="bibr" target="#b12">Joshi et al., 2017;</ref><ref type="bibr" target="#b14">Kočisk`Kočisk`y et al., 2017</ref>).</p><p>Many neural QA models have been proposed for these datasets, the most successful of which tend to leverage coattention or bidirectional atten- tion mechanisms that build codependent represen- tations of the document and the question ( <ref type="bibr" target="#b37">Xiong et al., 2018;</ref>).</p><p>Yet, learning the full context over the document is challenging and inefficient. In particular, when the model is given a long document, or multiple documents, learning the full context is intractably slow and hence difficult to scale to large corpora. In addition, <ref type="bibr" target="#b11">Jia and Liang (2017)</ref> show that, given adversarial inputs, such models tend to focus on wrong parts of the context and produce incorrect answers.</p><p>In this paper, we aim to develop a QA system that is scalable to large documents as well as ro- bust to adversarial inputs. First, we study the con- text required to answer the question by sampling examples in the dataset and carefully analyzing them. We find that most questions can be an- swered using a few sentences, without the consid- eration of context over entire document. In partic- ular, we observe that on the SQuAD dataset <ref type="bibr" target="#b24">(Rajpurkar et al., 2016</ref>), 92% of answerable questions can be answered using a single sentence.</p><p>Second, inspired by this observation, we pro- pose a sentence selector to select the minimal set of sentences to give to the QA model in order to answer the question. Since the minimum num- ber of sentences depends on the question, our sen- tence selector chooses a different number of sen- tences for each question, in contrast with previ- ous models that select a fixed number of sentences. Our sentence selector leverages three simple tech- niques -weight transfer, data modification and score normalization, which we show to be highly effective on the task of sentence selection.</p><p>We compare the standard QA model given the full document (FULL) and the QA model given the N % on % on <ref type="table" target="#tab_5">Document  Question  sent SQuAD TriviaQA  1  90  56</ref> In 1873, Tesla returned to his birthtown, Smiljan. Shortly after he arrived, (...) Where did Tesla return to in 1873? 2 6 28 After leaving Edison's company Tesla partnered with two businessmen in 1886, What did Tesla Electric Light &amp; Manufacturing Robert Lane and Benjamin Vail, who agreed to finance an electric lighting do? company in Tesla's name, Tesla Electric Light &amp; Manufacturing. The company installed electrical arc light based illumination systems designed by Tesla and also had designs for dynamo electric machine commutators, (. <ref type="table" target="#tab_1">..)  3↑  2  4</ref> Kenneth Swezey, a journalist whom Tesla had befriended, confirmed that Tesla Who did Tesla call in the middle of the night? rarely slept . Swezey recalled one morning when Tesla called him at 3 a.m. : "I was sleeping in my room (...) Suddenly, the telephone ring awakened me ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>N/A 2 12</head><p>Writers whose papers are in the library are as diverse as Charles Dickens and The papers of which famous English Victorian Beatrix Potter. Illuminated manuscripts in the library dating from (...) author are collected in the library? <ref type="table">Table 1</ref>: Human analysis of the context required to answer questions on SQuAD and TriviaQA. 50 examples from each dataset are sampled randomly. 'N sent' indicates the number of sentences required to answer the question, and 'N/A' indicates the question is not answerable even given all sentences in the document. 'Document' and 'Question' are from the representative example from each category on SQuAD. Examples on TriviaQA are shown in Appendix B. The groundtruth answer span is in red text, and the oracle sentence (the sentence containing the grountruth answer span) is in bold text.</p><p>No. Description % Sentence Question 0</p><p>Correct (Not exactly same 58 Gothic architecture is represented in the majestic churches but also at the burgher What type of architecture is represented as grountruth)</p><p>houses and fortifications. in the majestic churches? 1</p><p>Fail to select precise span 6 Brownlee argues that disobedience in opposition to the decisions of non-governmental Brownlee argues disobedience can be agencies such as trade unions, banks, and private universities can be justified if it justified toward what institutions? reflects 'a larger challenge to the legal system that permits those decisions to be taken;. 2</p><p>Complex semantics in 34 Newton was limited by Denver's defense, which sacked him seven times and forced him How many times did the Denver defense sentence/question into three turnovers, including a fumble which they recovered for a touchdown. force Newton into turnovers? 3</p><p>Not answerable even with 2 He encourages a distinction between lawful protest demonstration, nonviolent civil What type of civil disobedience is full paragraph disobedience, and violent civil disobedience. accompanied by aggression? <ref type="table">Table 2</ref>: Error cases (on exact match (EM)) of DCN+ given oracle sentence on SQuAD. 50 examples are sampled randomly. Grountruth span is in underlined text, and model's prediction is in bold text.</p><p>minimal set of sentences (MINIMAL) on five dif- ferent QA tasks with varying sizes of documents. On SQuAD, NewsQA, TriviaQA(Wikipedia) and SQuAD-Open, MINIMAL achieves significant re- ductions in training and inference times (up to 15× and 13×, respectively), with accuracy com- parable to or better than FULL. On three of those datasets, this improvements leads to the new state- of-the-art. In addition, our experimental results and analyses show that our approach is more ro- bust to adversarial inputs. On the development set of SQuAD-Adversarial (Jia and Liang, 2017), MINIMAL outperforms the previous state-of-the- art model by up to 13%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task analyses</head><p>Existing QA models focus on learning the context over different parts in the full document. Although effective, learning the context within the full docu- ment is challenging and inefficient. Consequently, we study the minimal context in the document re- quired to answer the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Human studies</head><p>First, we randomly sample 50 examples from the SQuAD development set, and analyze the mini- mum number of sentences required to answer the question, as shown in <ref type="table">Table 1</ref>. We observed that 98% of questions are answerable given the docu- ment. The remaining 2% of questions are not an- swerable even given the entire document. For in- stance, in the last example in <ref type="table">Table 1</ref>, the question requires the background knowledge that Charles Dickens is an English Victorian author. Among the answerable examples, 92% are answerable with a single sentence, 6% with two sentences, and 2% with three or more sentences.</p><p>We perform a similar analysis on the TriviaQA (Wikipedia) development (verified) set. Finding the sentences to answer the question on TriviaQA is more challenging than on SQuAD, since Triv- iaQA documents are much longer than SQuAD documents (488 vs 5 sentences per document). Nevertheless, we find that most examples are an- swerable with one or two sentences -among the 88% of examples that are answerable given the full document, 95% can be answered with one or two sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analyses on existing QA model</head><p>Given that the majority of examples are answer- able with a single oracle sentence on SQuAD, we analyze the performance of an existing, compet- itive QA model when it is given the oracle sen- tence. We train DCN+ ( <ref type="bibr" target="#b37">Xiong et al., 2018)</ref>, one of the state-of-the-art models on SQuAD (details in Section 3.1), on the oracle sentence. The model achieves 83.1 F1 when trained and evaluated us- ing the full document and 85.1 F1 when trained and evaluated using the oracle sentence. We ana- lyze 50 randomly sampled examples in which the model fails on exact match (EM) despite using the oracle sentence. We classify these errors into 4 categories, as shown in <ref type="table">Table 2</ref>. In these exam- ples, we observed that 40% of questions are an- swerable given the oracle sentence but the model unexpectedly fails to find the answer. 58% are those in which the model's prediction is correct but does not lexically match the groundtruth answer, as shown in the first example in <ref type="table">Table 2</ref>. 2% are those in which the question is not answerable even given the full document. In addition, we com- pare predictions by the model trained using the full document (FULL) with the model trained on the oracle sentence (ORACLE). <ref type="figure" target="#fig_0">Figure 1</ref> shows the Venn diagram of the questions answered correctly by FULL and ORACLE on SQuAD and NewsQA. ORACLE is able to answer 93% and 86% of the questions correctly answered by FULL on SQuAD and NewsQA, respectively.</p><p>These experiments and analyses indicate that if the model can accurately predict the oracle sen- tence, the model should be able to achieve compa- rable performance on overall QA task. Therefore, we aim to create an effective, efficient and robust QA system which only requires a single or a few sentences to answer the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our overall architecture ( <ref type="figure" target="#fig_2">Figure 2</ref>) consists of a sentence selector and a QA model. The sentence selector computes a selection score for each sen- tence in parallel. We give to the QA model a re- duced set of sentences with high selection scores to answer the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural Question Answering Model</head><p>We study two neural QA models that obtain close to state-of-the-art performance on SQuAD. DCN+ ( <ref type="bibr" target="#b37">Xiong et al., 2018</ref>) is one of the start-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Full</head><p>Oracle Full Oracle </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sentence Selector</head><p>Our sentence selector scores each sentence with respect to the question in parallel. The score indi- cates whether the question is answerable with this sentence. The model architecture is divided into the en- coder module and the decoder module. The en- coder is a shared module with S-Reader, which computes sentence encodings and question encod- ings from the sentence and the question as inputs. First, the encoder computes sentence embeddings </p><formula xml:id="formula_0">D ∈ R h d ×L d , question embeddings Q ∈ R h d ×Lq , and question-aware sentence embeddings D q ∈ R h d ×L d ,</formula><formula xml:id="formula_1">α i = softmax(D T i W 1 Q) ∈ R Lq (1) D q i = Lq j=1 (α i,j Q j ) ∈ R h d<label>(2)</label></formula><p>Here, D i ∈ R h d is the hidden state of sentence embedding for the i th word and a trainable weight matrix. After this, sentence en- codings and question encodings are obtained using an LSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref>.</p><formula xml:id="formula_2">W 1 ∈ R h d ×h d is Embed Matrix Embed Matrix BiLSTM BiLSTM … L D Sentence … L Q D … … Question Q í µí°· í µí± … … … D enc Q enc … … D enc Q enc Linear+Softmax … score start BiLinear score end … D enc … BiLinear … … D enc Q enc Linear+Softmax … Max</formula><formula xml:id="formula_3">D enc = BiLSTM([D i ; D q i ]) ∈ R h×L d (3) Q enc = BiLSTM(Q j ) ∈ R h×Lq<label>(4)</label></formula><p>Here, ';' denotes the concatenation of two vec- tors, and h is a hyperparameter of the hidden di- mension.</p><p>Next, the decoder is a task-specific module which computes the score for the sentence by cal- culating bilinear similarities between sentence en- codings and question encodings as follows.</p><formula xml:id="formula_4">β = softmax(w T Q enc ) ∈ R Lq<label>(5)</label></formula><formula xml:id="formula_5">˜ q enc = Lq j=1 (β j Q enc j ) ∈ R h<label>(6)</label></formula><formula xml:id="formula_6">˜ h i = (D enc i W 2 ˜ q enc ) ∈ R h (7) ˜ h = max( ˜ h 1 , ˜ h 2 , · · · , ˜ h L d ) (8) score = W T 3 ˜ h ∈ R 2<label>(9)</label></formula><p>Here, w ∈ R h , W 2 ∈ R h×h×h , W 3 ∈ R h×2 , are trainable weight matrices. Each dimension in score means the question is answerable or nonan- swerable given the sentence.</p><p>We introduce 3 techniques to train the model. (i) As the encoder module of our model is iden- tical to that of S-Reader, we transfer the weights to the encoder module from the QA model trained on the single oracle sentence <ref type="bibr">(ORACLE)</ref>  obtain the score for each sentence, we normalize scores across sentences from the same paragraph, similar to <ref type="bibr" target="#b3">Clark and Gardner (2017)</ref>. All of these three techniques give substantial improvements in sentence selection accuracy, as shown in <ref type="table" target="#tab_3">Table 4</ref>. More details including hyperparameters and train- ing procedures are shown in Appendix A.</p><p>Because the minimal set of sentences required to answer the question depends on the question, we select the set of sentences by thresholding the sentence scores, where the threshold is a hyper- parameter (details in Appendix A). This method allows the model to select a variable number of sentences for each question, as opposed to a fixed number of sentences for all questions. Also, by controlling the threshold, the number of sen- tences can be dynamically controlled during the inference. We define Dyn (for Dynamic) as this method, and define Top k as the method which simply selects the top-k sentences for each ques- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Evaluation Metrics</head><p>We train and evaluate our model on five different datasets as shown in <ref type="table" target="#tab_1">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SQuAD</head><p>( <ref type="bibr" target="#b24">Rajpurkar et al., 2016</ref>) is a well- studied QA dataset on Wikipedia articles that re- quires each question to be answered from a para- graph.</p><p>NewsQA ( <ref type="bibr" target="#b32">Trischler et al., 2016</ref>) is a dataset on news articles that also provides a paragraph for each question, but the paragraphs are longer than those in SQuAD. SQuAD-Adversarial (Jia and Liang, 2017) is a variant of SQuAD. It shares the same training set as SQuAD, but an adversarial sentence is added to each paragraph in a subset of the development set.</p><p>We use accuracy (Acc) and mean average pre- cision (MAP) to evaluate sentence selection. We also measure the average number of selected sen- tences (N sent) to compare the efficiency of our Dyn method and the Top k method.</p><p>To evaluate the performance in the task of ques- tion answering, we measure F1 and EM (Exact Match), both being standard metrics for evaluat- ing span-based QA. In addition, we measure train- ing speed (Train Sp) and inference speed (Infer Sp) relative to the speed of standard QA model (FULL). The speed is measured using a single GPU (Tesla K80), and includes the training and inference time for the sentence selector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SQuAD and NewsQA</head><p>For each QA model, we experiment with three types of inputs. First, we use the full document (FULL). Next, we give the model the oracle sentence containing the groundtruth answer span (ORACLE). Finally, we select sentences using our sentence selector (MINIMAL), using both Top k and Dyn. We also compare this last method with TF-IDF method for sentence selection, which se- lects sentences using n-gram TF-IDF distance be- tween each sentence and the question.    Results <ref type="table" target="#tab_3">Table 4</ref> shows results in the task of sen- tence selection on SQuAD and NewsQA. First, our selector outperforms TF-IDF method and the previous state-of-the-art by large margin (up to 2.9% MAP).</p><p>Second, our three training techniques -weight transfer, data modification and score normaliza- tion -improve performance by up to 5.6% MAP. Finally, our Dyn method achieves higher accuracy with less sentences than the Top k method. For example, on SQuAD, Top 2 achieves 97.2 accu- racy, whereas Dyn achieves 99.3 accuracy with <ref type="bibr">SQuAD</ref>    , which are the model leveraging sentence selection for question answering, and the published state-of-the-art mod- els on SQuAD and NewsQA, respectively.</p><p>a Numbers on the test set.</p><p>1.9 sentences per example. On NewsQA, Top 4 achieves 92.5 accuracy, whereas Dyn achieves 94.6 accuracy with 3.9 sentences per example. <ref type="figure" target="#fig_5">Figure 3</ref> shows that the number of sentences selected by Dyn method vary substantially on both SQuAD and NewsQA. This shows that Dyn chooses a different number of sentences de- pending on the question, which reflects our intu- ition. <ref type="table" target="#tab_5">Table 5</ref> shows results in the task of QA on SQuAD and NewsQA. MINIMAL is more efficient in training and inference than FULL. On SQuAD, S-Reader achieves 6.7× training and 3.6× infer- ence speedup on SQuAD, and 15.0× training and 6.9× inference speedup on NewsQA. In addition to the speedup, MINIMAL achieves comparable re- sult to FULL (using S-Reader, 79.9 vs 79.8 F1 on SQuAD and 63.8 vs 63.2 F1 on NewsQA).</p><p>We compare the predictions from FULL and MINIMAL in <ref type="table">Table 6</ref>. In the first two examples, our sentence selector chooses the oracle sentence, The initial LM model weighed approximately 33,3000 pounds, and allowed surface stays up to around 34 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. . . An Extended Lunar Module weighed over 36,200 pounds, and allowed surface stays of over 3 days.</head><p>For about how long would the extended LM allow a surface stay on the moon? Approximately 1,000 British soldiers were killed or injured. . . . The remaining 500 British troops, led by George Washington, retreated to Virginia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How many casualties did British get?</head><p>This book, which influenced the thought of Charles Darwin, successfully promoted the doctrine of uniformitarianism. This theory states that slow geological processes have occurred throughout the Earth's history and are still occurring today. In contrast, catastrophism is the theory that Earth's features formed in single, catastrophic events and remained unchanged thereafter.</p><p>Which theory states that slow geological processes are still occuring today, and have occurred throughout Earth's history? <ref type="table">Table 6</ref>: Examples on SQuAD. Grountruth span (underlined text), the prediction from FULL (blue text) and MINIMAL (red text). Sentences selected by our selector is denoted with . In the above two examples, MINIMAL correctly answer the question by selecting the oracle sentence. In the last example, MINIMAL fails to answer the question, since the inference over first and second sentences is required to answer the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>selected sentence</head><p>However, in 1883-84 Germany began to build a colonial empire in Africa and the South Pacific, before losing interest in imperialism.</p><p>The establishment of the German colonial empire proceeded smoothly, starting with German New Guinea in 1884. When did Germany found their first settlement? 1883-84 1884 1884</p><p>In the late 1920s, Tesla also befriended George Sylvester Viereck, a poet, writer, mystic, and later, a Nazi propagandist. In middle age, Tesla became a close friend of Mark Twain; they spent a lot of time together in his lab and elsewhere. When did Tesla become friends with Viereck? late 1920s middle age late 1920s <ref type="table">Table 7</ref>: An example on SQuAD, where the sentences are ordered by the score from our selector. Groun- truth span (underlined text), the predictions from Top 1 (blue text), Top 2 (green text) and Dyn (red text). Sentences selected by Top 1, Top 2 and Dyn are denoted with , and , respectively. and the QA model correctly answers the question. In the last example, our sentence selector fails to choose the oracle sentence, so the QA model can- not predict the correct answer. In this case, our se- lector chooses the second and the third sentences instead of the oracle sentence because the former contains more information relevant to question. In fact, the context over the first and the second sen- tences is required to correctly answer the question. <ref type="table">Table 7</ref> shows an example on SQuAD, which MINIMAL with Dyn correctly answers the ques- tion, and MINIMAL with Top k sometimes does not. Top 1 selects one sentence in the first exam- ple, thus fails to choose the oracle sentence. Top 2 selects two sentences in the second example, which is inefficient as well as leads to the wrong answer. In both examples, Dyn selects the oracle sentence with minimum number of sentences, and subsequently predicts the answer. More analyses are shown in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">TriviaQA and SQuAD-Open</head><p>TriviaQA and SQuAD-Open are QA tasks that reason over multiple documents. They do not provide the answer span and only provide the question-answer pairs. For each QA model, we experiment with two types of inputs.</p><p>First, since TriviaQA and SQuAD-Open have many documents for each question, we first filter paragraphs based on the TF-IDF similarities between the question and the paragraph, and then feed the full paragraphs to the QA model (FULL). On TriviaQA, we choose the top 10 paragraphs for training and inference. On SQuAD-Open, we choose the top 20 paragraphs for training and the top 40 for inferences. Next, we use our sentence selector with Dyn (MINIMAL). We select 5-20 sentences using our sentence se- lector, from 200 sentences based on TF-IDF.</p><p>For training the sentence selector, we use two techniques described in Section 3.2, weight trans- fer and score normalization, but we do not use data modification technique, since there are too many sentences to feed each of them to the QA model. For training the QA model, we transfer the weights from the QA model trained on SQuAD, then fine- tune.  Results <ref type="table" target="#tab_7">Table 8</ref> shows results on TriviaQA (Wikipedia) and SQuAD-Open. First, MINI- MAL obtains higher F1 and EM over FULL, with the inference speedup of up to 13.8×. Sec- ond, the model with our sentence selector with Dyn achieves higher F1 and EM over the model with TF-IDF selector. For example, on the development-full set, with 5 sentences per ques- tion on average, the model with Dyn achieves 59.5 F1 while the model with TF-IDF method achieves 51.9 F1. Third, we outperforms the published state-of-the-art on both dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">SQuAD-Adversarial</head><p>We use the same settings as Section 4.2. We use the model trained on SQuAD, which is exactly same as the model used for <ref type="table" target="#tab_5">Table 5</ref>. For MINI- MAL, we select top 1 sentence from our sentence selector to the QA model. <ref type="table" target="#tab_9">Table 9</ref> shows that MINIMAL outper- forms FULL, achieving the new state-of-the-art by large margin (+11.1 and +11.5 F1 on AddSent and AddOneSent, respectively). <ref type="figure" target="#fig_0">Figure 10</ref> compares the predictions by DCN+ FULL (blue) and MINIMAL (red). While FULL se- lects the answer from the adversarial sentence, MINIMAL first chooses the oracle sentence, and  subsequently predicts the correct answer. These experimental results and analyses show that our approach is effective in filtering adversarial sen- tences and preventing wrong predictions caused by adversarial sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Question Answering over Documents There has been rapid progress in the task of question answering (QA) over documents along with vari-San Francisco mayor Ed Lee said of the highly visible homeless presence in this area "they are going to have to leave". Jeff Dean was the mayor of Diego Diego during Champ Bowl 40.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Who was the mayor of San Francisco during Super Bowl 50?</head><p>In January 1880, two of Tesla's uncles put together enough money to help him leave Gospi for Prague where he was to study. Tadakatsu moved to the city of Chicago in 1881. What city did Tesla move to in 1880?  <ref type="bibr" target="#b32">Trischler et al., 2016)</ref>, fictional sto- ries ( <ref type="bibr" target="#b25">Richardson et al., 2013;</ref><ref type="bibr" target="#b14">Kočisk`Kočisk`y et al., 2017)</ref>, and textbooks ).</p><p>Many neural QA models have successfully ad- dressed these tasks by leveraging coattention or bidirectional attention mechanisms ( <ref type="bibr" target="#b37">Xiong et al., 2018;</ref> to model the codependent context over the document and the question. How- ever, <ref type="bibr" target="#b11">Jia and Liang (2017)</ref> find that many QA mod- els are sensitive to adversarial inputs.</p><p>Recently, researchers have developed large- scale QA datasets, which requires answering the question over a large set of documents in a closed ( <ref type="bibr" target="#b12">Joshi et al., 2017)</ref> or open-domain ( <ref type="bibr" target="#b5">Dunn et al., 2017;</ref><ref type="bibr" target="#b0">Berant et al., 2013;</ref><ref type="bibr" target="#b4">Dhingra et al., 2017</ref>). Many models for these datasets either retrieve documents/paragraphs rel- evant to the question ( <ref type="bibr" target="#b3">Clark and Gardner, 2017;</ref><ref type="bibr" target="#b33">Wang et al., 2018)</ref>, or lever- age simple non-recurrent architectures to make training and inference tractable over large cor- pora ( <ref type="bibr" target="#b29">Swayamdipta et al., 2018;</ref>).</p><p>Sentence selection The task of selecting sen- tences that can answer to the question has been studied across several QA datasets <ref type="bibr" target="#b38">(Yang et al., 2015)</ref>, by modeling relevance between a sen- tence and the question ( <ref type="bibr" target="#b39">Yin et al., 2016;</ref><ref type="bibr" target="#b19">Miller et al., 2016;</ref><ref type="bibr" target="#b20">Min et al., 2017)</ref>. Several recent works also study joint sentence selection and ques- tion answering.  propose a framework that identifies the sentences relevant to the question (property) using simple bag-of- words representation, then generates the answer from those sentences using recurrent neural net- works. <ref type="bibr" target="#b23">Raiman and Miller (2017)</ref> cast the task of extractive question answering as a search problem by iteratively selecting the sentences, start position and end position. They are different from our work in that (i) we study of the minimal context required to answer the question, (ii) we choose the minimal context by selecting variable number of sentences for each question, while they use a fixed size of number as a hyperparameter, (iii) our framework is flexible in that it does not require end-to-end training and can be combined with existing QA models, and (iv) they do not show robustness to adversarial inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed an efficient and robust QA system that is scalable to large documents and robust to adversarial inputs. First, we studied the minimal context required to answer the question in existing datasets and found that most questions can be an- swered using a small set of sentences. Second, in- spired by this observation, we proposed a sentence selector which selects a minimal set of sentences to answer the question to give to the QA model. We demonstrated the efficiency and effectiveness of our method across five different datasets with varying sizes of source documents. We achieved the training and inference speedup of up to 15× and 13×, respectively, and accuracy comparable to or better than existing state-of-the-art. In addi- tion, we showed that our approach is more robust to adversarial inputs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Venn diagram of the questions answered correctly (on exact match (EM)) by the model given a full document (FULL) and the model given an oracle sentence (ORACLE) on SQuAD (left) and NewsQA (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where h d is the dimension of word em- beddings, and L d and L q are the sequence length of the document and the question, respectively. Specifically, question-aware sentence embeddings are obtained as follows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our model architecture. (a) Overall pipeline, consisting of sentence selector and QA model. Selection score of each sentence is obtained in parallel, then sentences with selection score above the threshold are merged and fed into QA model. (b) Shared encoder of sentence selector and S-Reader (QA Model), which takes document and the question as inputs and outputs the document encodings D enc and question encodings Q enc. (c) Decoder of S-Reader (QA Model), which takes D enc and Q enc as inputs and outputs the scores for start and end positions. (d) Decoder of sentence selector, which takes D enc and Q enc for each sentence and outputs the score indicating if the question is answerable given the sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>TriviaQA</head><label></label><figDesc>(Joshi et al., 2017) is a dataset on a large set of documents from the Wikipedia domain and Web domain. Here, we only use the Wikipedia domain. Each question is given a much longer context in the form of multiple documents. SQuAD-Open (Chen et al., 2017) is an open- domain question answering dataset based on SQuAD. In SQuAD-Open, only the question and the answer are given. The model is responsible for identifying the relevant context from all English Wikipedia articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The distributions of number of sentences that our selector selects using Dyn method on the dev set of SQuAD (left) and NewsQA (right).</figDesc><graphic url="image-1.png" coords="6,167.25,450.97,120.37,79.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Dataset used for experiments. 'N word', 'N sent' and 'N doc' refer to the average number of 
words, sentences and documents, respectively. All statistics are calculated on the development set. For 
SQuAD-Open, since the task is in open-domain, we calculated the statistics based on top 10 documents 
from Document Retriever in DrQA (Chen et al., 2017). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results of sentence selection on the dev 
set of SQuAD and NewsQA. (Top) We compare 
different models and training methods. We report 
Top 1 accuracy (Top 1) and Mean Average Pre-
cision (MAP). Our selector outperforms the pre-
vious state-of-the-art (Tan et al., 2018). (Bottom) 
We compare different selection methods. We re-
port the number of selected sentences (N sent) and 
the accuracy of sentence selection (Acc). 'T', 'M' 
and 'N' are training techniques described in Sec-
tion 3.2 (weight transfer, data modification and 
score normalization, respectively). 

a 'N' does not change the result on Top k, since Top 
k depends on the relative scores across the sentences from 
same paragraph. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on the dev set of SQuAD (First 
two) and NewsQA (Last). For Top k, we use 
k = 1 and k = 3 for SQuAD and NewsQA, re-
spectively. We compare with GNR (Raiman and 
Miller, 2017), FusionNet (Huang et al., 2018) and 
FastQA (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Results on the dev-full set of TriviaQA (Wikipedia) and the dev set of SQuAD-Open. Full re-
sults (including the dev-verified set on TriviaQA) are in Appendix C. For training FULL and MINIMAL on 
TriviaQA, we use 10 paragraphs and 20 sentences, respectively. For training FULL and MINIMAL on 
SQuAD-Open, we use 20 paragraphs and 20 sentences, respectively. For evaluating FULL and MINIMAL, 
we use 40 paragraphs and 5-20 sentences, respectively. 'n sent' indicates the number of sentences used 
during inference. 'Acc' indicates accuracy of whether answer text is contained in selected context. 'Sp' 
indicates inference speed. We compare with the results from the sentences selected by TF-IDF method 
and our selector (Dyn). We also compare with published Rank1-3 models. For TriviaQA(Wikipedia), 
they are Neural Casecades (Swayamdipta et al., 2018), Reading Twice for Natural Language Under-
standing (Weissenborn, 2017) and Mnemonic Reader (Hu et al., 2017). For SQuAD-Open, they are 
DrQA (Chen et al., 2017) (Multitask), R 3 (Wang et al., 2018) and DrQA (Plain). 

a Approximated based on there are 475.2 sentences per document, and they use 5 documents per question 
b Numbers on the test set. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Results on the dev set of SQuAD-
Adversarial. We compare with RaSOR (Lee 
et al., 2016), ReasoNet (Shen et al., 2017) and 
Mnemonic Reader (Hu et al., 2017), the previous 
state-of-the-art on SQuAD-Adversarial, where the 
numbers are from Jia and Liang (2017). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 10 : Examples on SQuAD-Adversarial. Groundtruth span is in underlined text, and</head><label>10</label><figDesc></figDesc><table>predictions 
</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers and the Sales-force Research team members for their thoughtful comments and discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coarse-to-fine question answering for long documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Illia Polosukhin, Alexandre Lacoste, and Jonathan Berant</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ACL</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Quasar: Datasets for question answering by search and reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathryn</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03904</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugur</forename><surname>Guney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volkan</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05179</idno>
		<title level="m">Searchqa: A new q&amp;a dataset augmented with context from a search engine</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A joint many-task model: Growing a neural network for multiple nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Mnemonic reader for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02798</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fusionnet: Fusing via fullyaware attention with application to machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsin-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02596v2</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">`</forename><surname>Kočisk`y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.07040</idno>
		<title level="m">The narrativeqa reading comprehension challenge</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Race: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning recurrent span representations for extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimi</forename><surname>Salant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01436</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>AmirHossein Karimi, Antoine Bordes, and Jason Weston</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Question answering through transfer learning from large fine-grained supervision data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Sewon Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Memen: Multi-layer embedding with memory networks for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Boyuan Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09098</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Bin Cao, Deng Cai, and Xiaofei He</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Globally normalized reader</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>In EMNLP</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reasonet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Journal of machine learning research</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Multi-mention learning for reading comprehension with neural cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In ICLR</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Context-aware answer sentence selection with hierarchical gated recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.09830</idno>
		<title level="m">Newsqa: A machine comprehension dataset</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">R3: Reinforced reader-ranker for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Reading twice for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<idno>CoRR abs/1706.02596</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Making neural qa as simple as possible but not simpler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Seiffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Large-scale cloze test dataset designed by teachers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03225</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dcn+: Mixed objective and deep residual coattention for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schtze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast and accurate reading comprehension by combining self-attention and convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
