<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Event Detection and Domain Adaptation with Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien</forename><forename type="middle">Huu</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution">New York University New York</orgName>
								<address>
									<postCode>10003</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
							<email>grishman@cs.nyu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">New York University New York</orgName>
								<address>
									<postCode>10003</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Event Detection and Domain Adaptation with Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="365" to="371"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We study the event detection problem using convolutional neural networks (CNNs) that overcome the two fundamental limitations of the traditional feature-based approaches to this task: complicated feature engineering for rich feature sets and error propagation from the preceding stages which generate these features. The experimental results show that the CNNs outper-form the best reported feature-based systems in the general setting as well as the domain adaptation setting without resorting to extensive external resources.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We address the problem of event detection (ED): identifying instances of specified types of events in text. Associated with each event mention is a phrase, the event trigger (most often a single verb or nominalization), which evokes that event. Our task, more precisely stated, involves identifying event triggers and classifying them into specific types. For instance, according to the ACE 2005 annotation guideline 1 , in the sentence "A police officer was killed in New Jersey today", an event detection system should be able to recognize the word "killed" as a trigger for the event "Die". This task is quite challenging, as the same event might appear in the form of various trigger expressions and an expression might represent different events in different contexts. ED is a crucial component in the overall task of event extraction, which also involves event argument discovery.</p><p>Recent systems for event extraction have em- ployed either a pipeline architecture with separate classifiers for trigger and argument labeling <ref type="bibr" target="#b9">(Ji and Grishman, 2008;</ref><ref type="bibr" target="#b4">Gupta and Ji, 2009</ref> and <ref type="bibr" target="#b22">Rilof, 2009;</ref><ref type="bibr" target="#b16">Liao and Grishman, 2011;</ref><ref type="bibr" target="#b18">McClosky et al., 2011;</ref><ref type="bibr" target="#b8">Huang and Riloff, 2012;</ref><ref type="bibr" target="#b13">Li et al., 2013a</ref>) or a joint inference architecture that performs the two subtasks at the same time to ben- efit from their inter-dependencies ( <ref type="bibr">Riedel and McCallum, 2011a</ref>; <ref type="bibr">Riedel and McCallum, 2011b;</ref><ref type="bibr" target="#b14">Li et al., 2013b;</ref><ref type="bibr" target="#b28">Venugopal et al., 2014</ref>). Both ap- proaches have coped with the ED task by elabo- rately hand-designing a large set of features (fea- ture engineering) and utilizing the existing super- vised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers etc) to extract these features to be fed into sta- tistical classifiers. Although this approach has achieved the top performance <ref type="bibr" target="#b6">(Hong et al., 2011;</ref><ref type="bibr" target="#b14">Li et al., 2013b</ref>), it suffers from at least two issues:</p><p>(i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new ap- plication domains and limiting the capacity to quickly adapt to these new domains.</p><p>(ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains <ref type="bibr" target="#b0">(Blitzer et al., 2006;</ref><ref type="bibr" target="#b3">Daumé III, 2007;</ref><ref type="bibr" target="#b17">McClosky et al., 2010)</ref>), probably propagated to the final event detector.</p><p>This paper presents a convolutional neural net- work ( <ref type="bibr" target="#b12">LeCun et al., 1988;</ref><ref type="bibr" target="#b10">Kalchbrenner et al., 2014</ref>) for the ED task that automatically learns features from sentences, and minimizes the depen- dence on supervised toolkits and resources for fea- tures, thus alleviating the error propagation and improving the performance for this task. Due to the emerging interest of the NLP community in deep learning recently, CNNs have been stud- ied extensively and applied effectively in vari- ous tasks: semantic parsing ( <ref type="bibr" target="#b29">Yih et al., 2014</ref>), search query retrieval <ref type="bibr" target="#b26">(Shen et al., 2014</ref>), seman- tic matching ( <ref type="bibr" target="#b7">Hu et al., 2014)</ref>, sentence modeling and classification <ref type="bibr" target="#b10">(Kalchbrenner et al., 2014</ref>; Kim,  <ref type="bibr" target="#b31">Zeng et al., 2014;</ref><ref type="bibr" target="#b21">Nguyen and Grishman, 2015)</ref>. However, to the best of our knowl- edge, this is the first work on event detection via CNNs so far.</p><p>First, we evaluate CNNs for ED in the general setting and show that CNNs, though not requir- ing complicated feature engineering, can still out- perform the state-of-the-art feature-based meth- ods extensively relying on the other supervised modules and manual resources for features. Sec- ond, we investigate CNNs in a domain adaptation (DA) setting for ED. We demonstrate that CNNs significantly outperform the traditional feature- based methods with respect to generalization per- formance across domains due to: (i) their capac- ity to mitigate the error propagation from the pre- processing modules for features, and (ii) the use of word embeddings to induce a more general rep- resentation for trigger candidates. We believe that this is also the first research on domain adaptation using CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>We formalize the event detection problem as a multi-class classification problem. Given a sen- tence, for every token in that sentence, we want to predict if the current token is an event trigger: i.e, does it express some event in the pre-defined event set or not ( <ref type="bibr" target="#b14">Li et al., 2013b</ref>)? The current token along with its context in the sentence constitute an event trigger candidate or an example in multi- class classification terms. In order to prepare for the CNNs, we limit the context to a fixed window size by trimming longer sentences and padding shorter sentences with a special token when nec- essary. Let 2w + 1 be the fixed window size, and x = [x −w , x −w+1 , . . . , x 0 , . . . , x w−1 , x w ] be some trigger candidate where the current token is positioned in the middle of the window (token x 0 ). Before entering the CNNs, each token x i is trans- formed into a real-valued vector by looking up the following embedding tables to capture different characteristics of the token:</p><p>-Word Embedding <ref type="table">Table (</ref>initialized by some pre-trained word embeddings): to capture the hid- den semantic and syntactic properties of the tokens <ref type="bibr" target="#b1">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b27">Turian et al., 2010)</ref>.</p><p>-Position Embedding <ref type="table">Table:</ref> to embed the rel- ative distance i of the token x i to the current token x 0 . In practice, we initialize this table randomly.</p><p>-Entity Type Embedding <ref type="table">Table:</ref> If we further know the entity mentions and their entity types 2 in the sentence, we can also capture this informa- tion for each token by looking up the entity type embedding table (initialized randomly) using the entity type associated with each token. We em- ploy the BIO annotation scheme to assign entity type labels to each token in the trigger candidate using the heads of the entity mentions.</p><p>For each token x i , the vectors obtained from the three look-ups above are concatenated into a sin- gle vector x i to represent the token. As a result, the original event trigger x is transformed into a matrix x = [x −w , x −w+1 , . . . , x 0 , . . . , x w−1 , x w ] of size m t × (2w + 1) (m t is the dimensionality of the concatenated vectors of the tokens).</p><p>The matrix representation x is then passed through a convolution layer, a max pooling layer and a softmax at the end to perform classifica- tion (like <ref type="bibr" target="#b11">(Kim, 2014;</ref><ref type="bibr" target="#b10">Kalchbrenner et al., 2014)</ref>). In the convolution layer, we have a set of feature maps (filters) {f 1 , f 2 , . . . , f n } for the convolution operation. Each feature map f i corresponds to some window size k and can be essentially seen as a weight matrix of size m t × k. <ref type="figure" target="#fig_0">Figure 1</ref> illus- trates the proposed CNN.</p><p>The gradients are computed using back- propagation; regularization is implemented by a dropout <ref type="bibr" target="#b11">(Kim, 2014;</ref><ref type="bibr" target="#b5">Hinton et al., 2012)</ref>, and training is done via stochastic gradient descent with shuffled mini-batches and the AdaDelta up- date rule <ref type="bibr" target="#b30">(Zeiler, 2012;</ref><ref type="bibr" target="#b11">Kim, 2014)</ref>. During the training, we also optimize the weights of the three embedding tables at the same time to reach an ef- fective state <ref type="bibr" target="#b11">(Kim, 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset, Hyperparameters and Resources</head><p>As the benefit of multiple window sizes in the con- volution layer has been demonstrated in the previ- ous work on sentence modeling <ref type="bibr" target="#b10">(Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b11">Kim, 2014)</ref>, in the experiments below, we use window sizes in the set {2, 3, 4, 5} to gen- erate feature maps. We utilize 150 feature maps for each window size in this set. The window size for triggers is set to 31 while the dimensionality of the position embeddings and entity type embed- dings is 50 3 .We inherit the values for the other pa- rameters from <ref type="bibr" target="#b11">Kim (2014)</ref>, i.e, the dropout rate ρ = 0.5, the mini-batch size = 50, the hyperpa- rameter for the l 2 norms = 3. Finally, we em- ploy the pre-trained word embeddings word2vec with 300 dimensions from <ref type="bibr" target="#b19">Mikolov et al. (2013)</ref> for initialization.</p><p>We evaluate the presented CNN over the ACE 2005 corpus. For comparison purposes, we uti- lize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaning 529 documents (14,849 sentences) as the previous studies on this dataset ( <ref type="bibr" target="#b9">Ji and Grishman, 2008;</ref><ref type="bibr" target="#b15">Liao and Grishman, 2010;</ref><ref type="bibr" target="#b14">Li et al., 2013b</ref>). The ACE 2005 cor- pus has 33 event subtypes that, along with one class "None" for the non-trigger tokens, consti- tutes a 34-class classification problem.</p><p>In order to evaluate the effectiveness of the posi- tion embeddings and the entity type embeddings, <ref type="table" target="#tab_1">Table 1</ref> reports the performance of the proposed CNN on the development set when these embed- dings are either included or excluded from the sys- tems. With the large margins of performance, it is very clear from the table that the position embed- dings are crucial while the entity embeddings are also very useful for CNNs on ED.  For the experiments below, we examine the CNNs in two scenarios: excluding the entity type embeddings (CNN1) and including the entity type embeddings (CNN2). We always use position em- beddings in these two scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance Comparison</head><p>The state-of-the-art systems for event detection on the ACE 2005 dataset have followed the traditional feature-based approach with rich hand-designed feature sets, and statistical classifiers such as Max- Ent and perceptron for structured prediction in a joint architecture <ref type="bibr" target="#b6">(Hong et al., 2011;</ref><ref type="bibr" target="#b14">Li et al., 2013b)</ref>. In this section, we compare the proposed CNNs with these state-of-the-art systems on the blind test set. <ref type="table" target="#tab_3">Table 2</ref> presents the overall per- formance of the systems with gold-standard entity mention and type information <ref type="bibr">4</ref> .</p><p>As we can see from the  with the joint beam search approach using both lo- cal and global features ( <ref type="bibr" target="#b14">Li et al., 2013b</ref>). This is remarkable since CNN1 does not require any ex- ternal features <ref type="bibr">5</ref> , in contrast to the other feature- based systems that extensively rely on such exter- nal features to perform well. More interestingly, when the entity type information is incorporated into CNN1, we obtain CNN2 that still only needs sentence level information but achieves the state- of-the-art performance for this task (an improve- ment of 1.5% over the best system with only sen- tence level information ( <ref type="bibr" target="#b14">Li et al., 2013b)</ref>). Except for CNN1, all the systems reported in <ref type="table" target="#tab_3">Table 2</ref> employ the gold-standard (perfect) entities mentions and types from manual annotation which might not be available in reality. <ref type="table" target="#tab_4">Table 3</ref> compares the performance of CNN1 and the feature-based systems in a more realistic setting, where entity mentions and types are acquired from an auto- matic high-performing name tagger and informa- tion extraction system ( <ref type="bibr" target="#b14">Li et al., 2013b)</ref>. Note that CNN1 is eligible for this comparison as it does not utilize any external features, thus avoiding usage of the name tagger and the information extraction system to identify entity mentions and types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Domain Adaptation Experiment</head><p>In this section, we aim to further compare the pro- posed CNNs with the feature-based systems under the domain adaptation setting for event detection.</p><p>The ultimate goal of domain adaptation re- search is to develop techniques taking training <ref type="bibr">5</ref> External features are the features generated from the su- pervised NLP modules and manual resources such as parsers, name tagger, entity mention extractors (either automatic or manual), gazetteers etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>F Sentence level in <ref type="bibr" target="#b9">Ji and Grishman (2008)</ref> 59.7 MaxEnt with local features in <ref type="bibr" target="#b14">Li et al. (2013b)</ref> 64.7 Joint beam search with local features in <ref type="bibr" target="#b14">Li et al. (2013b</ref>  data in some source domain and learning models that can work well on target domains. The target domains are supposed to be so dissimilar from the source domain that the learning techniques would suffer from a significant performance loss when trained on the source domain and applied to the target domains. To make it clear, we address the unsupervised DA problem in this section, i.e no training data in the target domains <ref type="bibr" target="#b0">(Blitzer et al., 2006;</ref><ref type="bibr" target="#b23">Plank and Moschitti, 2013</ref>). The fundamen- tal reason for the performance loss of the feature- based systems on the target domains is twofold: (i) The behavioral changes of features across domains: As domains differ, some features might be informative in the source domain but become less relevant in the target domains and vice versa.</p><p>(ii) The propagated errors of the pre-processing toolkits for lower-level tasks (POS tagging, name tagging, parsing etc) to extract features: These pre-processing toolkits are also known to degrade when shifted to target domains ( <ref type="bibr" target="#b0">Blitzer et al., 2006;</ref><ref type="bibr" target="#b3">Daumé III, 2007;</ref><ref type="bibr" target="#b17">McClosky et al., 2010)</ref>, introducing noisy features into the systems for higher-level tasks in the target domains and even- tually impairing the performance of these higher- level systems on the target domains.</p><p>For ED, we postulate that CNNs are more use- ful than the feature-based approach for DA for two reasons. First, rather than relying on the symbolic and concrete forms (i.e words, types etc) to con- struct features as the traditional feature-based sys- tems ( <ref type="bibr" target="#b9">Ji and Grishman, 2008;</ref><ref type="bibr" target="#b14">Li et al., 2013b</ref>) do, CNNs automatically induce their features from word embeddings, the general distributed repre- sentation of words that is shared across domains. This helps CNNs mitigate the lexical sparsity, learn more general and effective feature represen- tation for trigger candidates, and thus bridge the gap between domains. Second, as CNNs mini- mize the reliance on the supervised pre-processing toolkits for features, they can alleviate the error   propagation and be more robust to domain shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Dataset</head><p>We also do the experiments in this part over the ACE 2005 dataset but focus more on the difference between domains. The ACE 2005 corpus comes with 6 different domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl). Following the common practice of domain adaptation research on this dataset <ref type="bibr" target="#b23">(Plank and Moschitti, 2013;</ref><ref type="bibr" target="#b20">Nguyen and Grishman, 2014)</ref>, we use news (the union of bn and nw) as the source domain and bc, cts, wl as three different target domains. We take half of bc as the devel- opment set and use the remaining data for testing. We note that the distribution of event subtypes and the vocabularies of the source and target domains are quite different (Plank and Moschitti, 2013). <ref type="table" target="#tab_6">Table 4</ref>  The main conclusions from the table include: (i) The baseline systems MaxEnt, Joint+Local, Joint+Local+Global achieve high performance on the source domain, but degrade dramatically on <ref type="bibr">6</ref> The performance of the feature-based systems MaxEnt, Joint+Local and Joint+Local+Global are obtained from the actual systems in <ref type="bibr" target="#b14">Li et al. (2013b)</ref>. the target domains due to the domain shifts. (ii) Comparing CNN1 and the baseline systems, we see that CNN1 performs comparably with the baseline systems on the source domain (in-domain performance) (as expected), substantially outper- form the baseline systems on two of the three tar- get domains (i.e, bc and cts), and is only less ef- fective than the joint beam search approach on the wl domain; (iii) Finally and most importantly, we consistently achieve the best adaptation perfor- mance across all the target domains with CNN2 by only introducing entity type information into CNN1. In fact, CNN2 significantly outperforms the feature-based systems with p &lt; 0.05 and large margins of about 5.0% on the domains bc and cts, clearly confirming our argument in Section 3.3 and testifying to the benefits of CNNs on DA for ED.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Domain Adaptation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We present a CNN for event detection that auto- matically learns effective feature representations from pre-trained word embeddings, position em- beddings as well as entity type embeddings and reduces the error propagation. We conducted ex- periments to compare the proposed CNN with the state-of-the-art feature-based systems in both the general setting and the domain adaptation setting. The experimental results demonstrate the effec- tiveness as well as the robustness across domains of the CNN. In the future, our plans include: (i) to explore the joint approaches for event extrac- tion with CNNs; (ii) and to investigate other neural network architectures for information extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Convolutional Neural Network for Event Detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>) 63.7 Joint beam search with local and global features in Li et al. (2013b) 65.6 CNN1: CNN without any external features 67.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>System</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>presents the performance of five systems: the MaxEnt classifier with the local features from Li et al. (2013b) (called MaxEnt); the state-of-the- art joint beam search systems with: (i) only local features (called Joint+Local); and (ii) both local and global features (called Joint+Local+Global) in Li et al. (2013b) (the baseline systems); CNN1 and CNN2 via 5-fold cross validation. For each system, we train a model on the training set of the source domain and report the performance of this model on the test set of the source domain (in- domain performance) as well as the performance of the model on the three target domains bc, cts and wl (out-of-domain performance) 6 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Performance on the Development Set.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>table , considering</head><label>,</label><figDesc>the systems that only use sentence level information, CNN1 significantly outperforms the MaxEnt clas- sifier as well as the joint beam search with local features from Li et al. (2013b) (an improvement of 1.6% in F1 score), and performs comparably</figDesc><table>Methods 

P 
R 
F 
Sentence-level in Hong et al 
(2011) 
67.6 53.5 59.7 

MaxEnt with local features in 
Li et al. (2013b) 
74.5 59.1 65.9 

Joint beam search with local 
features in Li et al. (2013b) 
73.7 59.3 65.7 

Joint beam search with local 
and global features in Li et al. 
(2013b) 
73.7 62.3 67.5 

Cross-entity in Hong et al. 
(2011)  † 
72.9 64.3 68.3 

CNN1: CNN without any 
external features 
71.9 63.8 67.6 

CNN2: CNN augmented with 
entity types 
71.8 66.4 69.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance with Gold-Standard Entity Mentions 

and Types.  † beyond sentence level. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance with Predicted Entity Mentions and 

Types. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>In-domain (first column) and Out-of-domain Performance (columns two to four). Cells marked with  †designate 

CNN models that significantly outperform (p &lt; 0.05) all the reported feature-based methods on the specified domain. 

</table></figure>

			<note place="foot" n="2"> For convenience, when mentioning entities in this paper, we always include ACE timex and values.</note>

			<note place="foot" n="3"> These values are chosen for their best performance on the development data.</note>

			<note place="foot" n="4"> Entity mentions and types are used to introduce more features into the systems.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Qi Li for providing the per-formance of the feature-based systems on the do-main adaptation experiments. Thank you to Yifan He, Kai Cao, and Xiang Li for useful discussions on the task as well as the anonymous reviewers for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Domain Adaptation with Structural Correspondence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural Language Processing (Almost) from Scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">24932537</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Frustratingly Easy Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Predicting Unknown Time Arguments Based on Cross-Event Propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashant</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<idno>abs/1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Ruslan Salakhutdinov</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using Cross-entity Inference to Improve Event Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Min</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional Neural Network Architectures for Matching Natural Language Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling Textual Cohesion for Event Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Refining Event Extraction through Cross-Document Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Convolutional Neural Network for Modeling Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient-based Learning Applied to Document Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">22782324</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Argument Inference from Relevant Event Mentions in Chinese Argument Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint Event Extraction via Structured Prediction with Global Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using Document Level Cross-event Inference to Improve Event Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Acquiring Topic Features to Improve Event Extraction: in Preselected and Balanced Collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings RANLP</title>
		<meeting>RANLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic Domain Adaptation for Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Event Extraction as Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-HLT</title>
		<meeting>ACL-HLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Employing Word Representations and Regularization for Domain Adaptation of Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Relation Extraction: Perspective from Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop on Vector Space Modeling for NLP (VSM)</title>
		<meeting>the NAACL Workshop on Vector Space Modeling for NLP (VSM)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Unified Model of Phrasal and Sentential Evidence for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Rilof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Embedding Semantic Similarity in Tree Kernels for Domain Adaptation of Relation Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast and Robust Joint Models for Biomedical Event Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust Biomedical Event Extraction with Dual Decomposition and Minimal Domain Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP Shared Task 2011 Workshop</title>
		<meeting>the BioNLP Shared Task 2011 Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning Semantic Representations Using Convolutional Neural Networks for Web Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Word Representations: A Simple and General Method for Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Relieving the Computational Bottleneck: Joint Inference for Event Extraction with High-Dimensional Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Venugopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Gogate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic Parsing for Single-Relation Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">ADADELTA: An Adaptive Learning Rate Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Relation Classification via Convolutional Deep Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
