<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Leveraging Inflection Tables for Stemming and Lemmatization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Nicolai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing Science</orgName>
								<orgName type="institution">University of Alberta</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Leveraging Inflection Tables for Stemming and Lemmatization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1138" to="1147"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present several methods for stemming and lemmatization based on discrimina-tive string transduction. We exploit the paradigmatic regularity of semi-structured inflection tables to identify stems in an un-supervised manner with over 85% accuracy. Experiments on English, Dutch and German show that our stemmers substantially outperform Snowball and Morfes-sor, and approach the accuracy of a supervised model. Furthermore, the generated stems are more consistent than those annotated by experts. Our direct lemmatiza-tion model is more accurate than Morfette and Lemming on most datasets. Finally, we test our methods on the data from the shared task on morphological reinflection.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many languages contain multiple inflected forms that correspond to the same dictionary word. In- flection is a grammatical procedure that has little impact on the meaning of the word. For example, the German words in <ref type="table">Table 1</ref> all refer to the action of giving. When working with these languages, it is often beneficial to establish a consistent rep- resentation across a set of inflections. This is the task that we address here.</p><p>There are two principal approaches to inflec- tional simplification: stemming and lemmatiza- tion. Stemming aims at removing inflectional af- fixes from a word form. It can be viewed as a kind of word segmentation, in which the boundaries of the stem are identified within the word; no attempt is made to restore stem changes that may occur as part of the inflection process. The goal of lemma- tization is to map any inflected form to its unique lemma, which is typically the word form that rep-  <ref type="table">Table 1</ref>: Examples of German word-forms corre- sponding to the lemma geben.</p><p>resents a set of related inflections in a dictionary. Unlike stemming, lemmatization must always pro- duce an actual word form.</p><p>In this paper, we present a discriminative string transduction approach to both stemming and lemmatization. Supervised stemmers require mor- phologically annotated corpora, which are expen- sive to build. We remove this constraint by ex- tracting stems from semi-structured inflection ta- bles, such as the one shown in <ref type="table" target="#tab_1">Table 2</ref>, in an un- supervised manner. We design two transduction models that are trained on such stems, and eval- uate them on unseen forms against a supervised model. We then extend our stemming models to perform the lemmatization task, and to incorporate an unannotated corpus. We evaluate them on sev- eral datasets.Our best system improves the state of the art for Dutch, German, and Spanish. Finally, we test our methods on the data from the shared task on morphological reinflection. This paper is organized as follows. In Section 2, we present an overview of prior work on inflec- tional simplification. In Section 3, we describe our stemming methodology, followed by three types of evaluation experiments in Section 4. In Section 5, we describe our approach to lemmatization, fol- lowed by both intrinsic and extrinsic experiments in Section 6. Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we review prior work on stemming and lemmatization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Stemming and Segmentation</head><p>Stemming is a sub-task of the larger problem of morphological segmentation. Because of the scarcity of morphologically-annotated data, many segmentation algorithms are unsupervised or rule- based.</p><p>The Porter stemmer <ref type="bibr" target="#b19">(Porter, 1980)</ref> and its derivatives, such as Snowball, apply hand-crafted context rules to strip affixes from a word. Cre- ation of such rule-based programs requires signif- icant effort and expert knowledge. We use struc- tured inflection tables to create training data for a discriminative transducer.</p><p>Morfessor <ref type="bibr" target="#b4">(Creutz and Lagus, 2002</ref>) and Lin- guistica <ref type="bibr" target="#b9">(Goldsmith, 2001</ref>) are unsupervised word segmenters, which divide words into regularly oc- curring sub-sequences by applying the minimum description length (MDL) principle. While these methods are good at identifying common mor- phemes, they make no distinction between stems and affixes, and thus cannot be used for stemming. Morfessor Categories-MAP ( <ref type="bibr" target="#b5">Creutz and Lagus, 2004;</ref><ref type="bibr" target="#b6">Creutz and Lagus, 2005</ref>) distinguishes be- tween stems and affixes, but not between deriva- tional and inflectional affixes. We adapt a more recent version ( <ref type="bibr" target="#b10">Grönroos et al., 2014</ref>) to be used as an approximate stemmer. <ref type="bibr" target="#b18">Poon et al. (2009)</ref> abandons the generative model of Morfessor for a log-linear model that predicts segmentations in sequence. The discrim- inative approach allows for the incorporation of several priors that minimize over-segmentation. Their unsupervised model outperforms Morfessor, and they are also able to report semi-and fully- supervised results. We also approach the prob- lem using a discriminative method, but by aligning structured inflection tables, we can take advantage of linguistic knowledge, without requiring costly annotation. <ref type="bibr" target="#b20">Ruokolainen et al. (2014)</ref> obtain further im- provements by combining a structured perceptron CRF with letter successor variety (LSV), and the unsupervised features of <ref type="bibr" target="#b5">Creutz and Lagus (2004)</ref>. Their system is inherently supervised, while our stem annotations are derived in an unsupervised manner.</p><p>Cotterell  fully-supervised system for labeled morphological segmentation. Extending the sequence-prediction models, Chipmunk makes use of data that is anno- tated not only for stem or affix, but also for inflec- tional role, effectively combining morphological segmentation and morphological analysis. While highly accurate, Chipmunk is limited in that it re- quires data that is fully-annotated for both seg- mentation and inflection. Our system has access to the morphological tags in inflection tables, but segmentation and tag alignment are performed in an unsupervised way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Lemmatization</head><p>Unlike stemmers, which can be unsupervised, lemmatizers typically require annotated training data. In addition, some lemmatizers assume ac- cess to the morphological tag of the word, and/or the surrounding words in the text. Our focus is on context-free lemmatization, which could later be combined with a contextual disambiguation mod- ule.</p><p>Lemmatization is often part of the morpholog- ical analysis task, which aims at annotating each word-form with its lemma and morphological tag.  learn a joint model for contextual lemmatization and part-of-speech prediction from a morphologically annotated lexi- con. Their transduction model is tightly integrated with the POS information, which makes compar- ison difficult. However, in Section 6, we evaluate our approach against two other fully-supervised morphological analyzers: Morfette ( <ref type="bibr" target="#b1">Chrupała et al., 2008)</ref> and <ref type="bibr">Lemming (Müller et al., 2015</ref>). Both of these systems perform lemmatization and morphological analysis in context, but can be trained to learn non-contextual models. Morfette requires morphological tags during training, while Lemming requires a morphological model con- structed by its sister program, Marmot <ref type="bibr">(Müller et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Stemming Methods</head><p>We approach stemming as a string transduction task. Stemming can be performed by inserting morpheme boundary markers between the stem and the affixes. For example, the German verb form gegeben is transduced into ge+geb+en, which induces the stem geb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Character Alignment</head><p>The training of a transduction model requires a set of aligned pairs of source and target strings. The alignment involves every input and output charac- ter; the insertion and deletion operations are disal- lowed. Atomic character transformations are then extracted from the alignments.</p><p>We infer the alignment with a modified ver- sion of the M2M aligner of <ref type="bibr" target="#b12">Jiampojamarn et al. (2007)</ref>. The program applies the Expectation- Maximization algorithm with the objective to maximize the joint likelihood of its aligned source and target pairs. For our task, the source and target strings are nearly identical, except that the target includes stem-affix boundary markers. In order to account for every character in the target, which is usually longer than the source, we allow one-to- many alignment. This has the effect of tying the markers to the edge of a stem or affix. In order to encourage alignments between identical charac- ters, we modify the aligner to generalize all iden- tity transformations into a single match operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Supervised Transduction</head><p>Once we have aligned the source and target pairs, we proceed to train a word-to-stem transduction model for stemming unseen test instances. The word-to-stem model learns where to insert bound- ary markers. We refer to a model that is trained on annotated morphological segmentations as our supervised method.</p><p>We perform string transduction by adapting DI- RECTL+, a tool originally designed for grapheme- to-phoneme conversion ( <ref type="bibr" target="#b13">Jiampojamarn et al., 2010)</ref>. DIRECTL+ is a feature-rich, discrimina- tive character transducer that searches for a model- optimal sequence of character transformation rules for its input. The core of the engine is a dy- namic programming algorithm capable of trans- ducing many consecutive characters in a single op- eration. Using a structured version of the MIRA algorithm ( <ref type="bibr" target="#b15">McDonald et al., 2005</ref>), training at- tempts to assign weights to each feature so that its  gab|- setz|te tat|- STEM|2SIE gib|st setz|t tu|st PP|STEM|PP ge|geb|en ge|setz|t ge|ta|n <ref type="table" target="#tab_2">Table 3</ref>: Stemming of the training data based on the patterns of regularity in inflectional tables. Stemmas are shown in bold.</p><p>linear model separates the gold-standard deriva- tion from all others in its search space.</p><p>DIRECTL+ uses a number of feature templates to assess the quality of a rule: source context, tar- get n-gram, and joint n-gram features. Context features conjoin the rule with indicators for all source character n-grams within a fixed window of where the rule is being applied. Target n-grams provide indicators on target character sequences, describing the shape of the target as it is being pro- duced, and may also be conjoined with our source context features. Joint n-grams build indicators on rule sequences, combining source and target context, and memorizing frequently-used rule pat- terns.</p><p>Following Toutanova and Cherry <ref type="formula">(2009)</ref>, we modify the out-of-the-box version of DIRECTL+ by implementing an abstract copy feature that in- dicates when a rule simply copies its source char- acters into the target, e.g. b → b. The copy feature has the effect of biasing the transducer towards preserving the source characters during transduc- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Unsupervised Segmentation</head><p>In order to train a fully-supervised model for stem- ming, large lists of morphologically-segmented words are generally required. While such an- notated corpora are rare, semi-structured, crowd- sourced inflection tables are available for many languages on websites such as Wiktionary (Ta- ble 2). In this section, we introduce an unsu- pervised method of inducing stems by leveraging paradigmatic regularity in inflection tables.</p><p>Sets of inflection tables often exhibit the same inflectional patterns, called paradigms, which are based on phonological, semantic, or morphologi- cal criteria (cf.  The number of distinct affix forms corresponding to the same inflectional form across different lem- mas is also small, averaging below three for Ger- man verbs. For example, the second person sin- gular indicative present suffix is always either -st, -est, or -t.</p><p>We take advantage of this relative consistency to determine the boundaries between the stems and affixes of each word form in an unsupervised man- ner. We first associate each word form in the train- ing data with an abstract tag sequence, which is typically composed of the STEM tag and a suffix tag representing a given inflection slot <ref type="table" target="#tab_2">(Table 3)</ref>. We then apply the unsupervised aligner to deter- mine the most likely alignment between the char- acter sequences and the tags, which are treated as indivisible units. The aligner simultaneously learns common representations for stems within a single inflection table, as well as common repre- sentations for each affix across multiple tables.</p><p>Some inflections, such as the German past par- ticiple (PP in <ref type="table" target="#tab_2">Table 3</ref>) involve a circumfix, which can be analyzed as a prefix-suffix combination. Prior to the alignment, we associate all forms that belong to the inflection slots involving circumfix- ation with tag sequences composed of three tags. Occasionally, a word form will only have a suf- fix where one would normally expect a circumfix (e.g. existiert). In order to facilitate tag alignment in such cases, we prepend a dummy null character to each surface word form.</p><p>After the stem-affix boundaries have been iden- tified, we proceed to train a word-to-stem trans- duction model as described in Section 3.2. We refer to this unsupervised approach as our basic method (cf. <ref type="figure" target="#fig_3">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Joint Stemming and Tagging</head><p>The method described in the previous section fails to make use of a key piece of information in the in- flection table: the lemma. The stem of an inflected form is typically either identical or very similar to the stem of its lemma, or stemma <ref type="table" target="#tab_2">(Table 3)</ref>. Our</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Words</head><p>Noun <ref type="table" target="#tab_1">Verb Adj  English  50,155  2  5  3  Dutch  101,667  2  9  3  German 96,038  8  27  48   Table 5</ref>: The number of words and distinct inflec- tions for each language in the CELEX datasets.</p><p>joint method takes advantage of this similarity by transducing word-forms into stemmas with tags.</p><p>The format of the training data for the word-to- stemma model is different from the word-to-stem model. After the initial segmentation of the source word-forms into morphemes by the unsupervised aligner, as described in Section 3.3, the stems are replaced with the corresponding stemmas, and the affixes are replaced with the inflection tags. For example, the form gibt is paired with the sequence geb+3SIE, with the stem and stemma re-aligned at the character level as shown in <ref type="table" target="#tab_3">Table 4</ref>.</p><p>Unlike the basic method, which simply in- serts morpheme breaks into word-forms, the joint method uses the tags to identify the boundaries be- tween stems and affixes. At test time, the input word-form is transduced into a stemma and tag sequence. The character string that has generated the tag is then stripped from the input word-form to obtain the stem. By making use of both the tags and the stemma, the word-to-stemma model jointly optimizes the stem and affix combination. We refer to this unsupervised approach as our joint method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Stemming Experiments</head><p>Precise evaluation of stemming methods requires morphologically annotated lexicons, which are rare. Unlike lemmas, stems are abstract represen- tations, rather than actual word forms. Unsurpris- ingly, annotators do not always agree on the seg- mentation of a word. In this section, we describe three experiments for evaluating stem extraction, intrinsic accuracy, and consistency.</p><p>We evaluate our methods against three systems that are based on very different principles. Snow- ball 1 is a rule-based program based on the method- ology of the Porter Stemmer. Morfessor Flat- Cat ( <ref type="bibr" target="#b10">Grönroos et al., 2014</ref>) performs unsuper- vised morphological segmentation, and approxi- mates stemming by distinguishing stems and af-EN NL DE Our method 85.9 88.0 85.7 Snowball 48.2 58.8 49.5 Morfessor 61.4 71.4 61.4 <ref type="table">Table 6</ref>: Unsupervised stemming accuracy of the CELEX training set.</p><p>fixes. 2 Chipmunk ( , is a fully-supervised system that represents the current state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We perform an evaluation of stemming on En- glish (EN), Dutch (NL), and German (DE) lex- icons from CELEX ( <ref type="bibr" target="#b0">Baayen et al., 1995</ref>). The three languages vary in terms of morphological complexity <ref type="table">(Table 5)</ref>. We use the morphological boundary annotations for testing all stemming sys- tems, as well as for training our supervised system.</p><p>For both unsupervised systems, we could build training sets from any inflection tables that con- tain unsegmented word-forms. However, in order to perform a precise comparison between the su- pervised and unsupervised systems, we extract the inflection tables from CELEX, disregarding the segmentation information. Each system is repre- sented by a single stemming model that works on nouns, verbs, and adjectives. Due to differences in representation, the number of training instances vary slightly between models, but the number of words is constant <ref type="table">(Table 5)</ref>.</p><p>In order to demonstrate that our unsupervised methods require no segmentation information, we create additional German training sets using the inflection tables extracted from Wiktionary by <ref type="bibr" target="#b7">Durrett and DeNero (2013</ref>  <ref type="table" target="#tab_5">Table 7</ref>: Stemming accuracy of systems trained and tested on CELEX datasets. ery morpheme of a word is annotated for morpho- logical function. Since this information is not in- cluded in CELEX, we train and test Chipmunk, as well as a version of our supervised model, on the data created by , which is much smaller. The English and German seg- mentation datasets contain 1161 and 1266 training instances, and 816 and 952 test instances, respec- tively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Stem Extraction Evaluation</head><p>First, we evaluate our unsupervised segmentation approach, which serves as the basis for our ba- sic and joint models, on the union of the training and development parts of the CELEX dataset. We are interested how often the stems induced by the method described in Section 3.3 match the stem annotations in the CELEX database.</p><p>The results are presented in <ref type="table">Table 6</ref>. Our method is substantially more accurate than ei- ther Snowball or Morfessor. Snowball, despite being called a stemming algorithm, often elimi- nates derivational affixes; e.g. able in unbear- able. Morfessor makes similar mistakes, although less often. Our method tends to prefer longer stems and shorter affixes. For example, it stems verwandtestem, as verwandte, while CELEX has verwandt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Intrinsic Evaluation</head><p>The results of the intrinsic evaluation of the stem- ming accuracy on unseen forms in <ref type="table" target="#tab_5">Tables 7-9</ref> demonstrate the quality of our three models. The joint model performs better than the basic model, and approaches the accuracy of the supervised model. On the CELEX data, our unsupervised joint model substantially outperforms Snowball and Morfessor on all three languages (   <ref type="table">Table 9</ref>: Stemming accuracy of systems trained and tested on the Chipmunk data.</p><p>These results are further confirmed on the Ger- man Wiktionary data <ref type="table" target="#tab_6">(Table 8</ref>). Our supervised model performs almost as well as Chipmunk on its dataset <ref type="table">(Table 9)</ref>.</p><p>A major advantage of the joint model over the basic model is its tag awareness (cf. <ref type="table" target="#tab_3">Table 4)</ref>. Although the tags are not always correctly recov- ered on the test data, they often allow the model to select the right analysis. For example, the ba- sic model erroneously segments the German form erklärte as erklärt+e because +e is a common verbal, adjectival and nominal suffix. The joint model, recognizing er as a verbal derivational prefix, predicts a verbal inflection tag (+1SIA), and the correct segmentation erklär+te. Ver- bal stems are unlikely to end inärtinärt, and +te, unlike +e, can only be a verbal suffix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Consistency Evaluation</head><p>When stemming is used for inflectional simplifi- cation, it should ideally produce the same stem for all word-forms that correspond to a given lemma. In many cases, this is not an attainable goal because of internal stem changes (cf. Ta- ble 1). However, most inflected words follow reg- ular paradigms, which involve no stem changes. For example, all forms of the Spanish verb can- tar contain the substring cant, which is consid- ered the common stem. We quantify the extent to <ref type="bibr">which</ref>   sets. <ref type="bibr">5</ref> The results are presented in <ref type="table" target="#tab_8">Table 10</ref>. The stems-per-table average tends to reflect the mor- phological complexity of a language. All systems achieve excellent consistency on English, but the Dutch and German results paint a different pic- ture. The supervised system falls somewhat short of emulating the gold segmentations, which may be due to the confusion between different parts of speech. In terms of consistency, the stems gener- ated by our unsupervised methods are superior to those of Snowball and Morfessor, and even to the gold stems. We attribute this surprising result to the fact that the EM-based alignment of the train- ing data favors consistency in both stems and af- fixes, although this may not always result in the correct segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Lemmatization Methods</head><p>In this section, we present three supervised lemmatization methods, two of which incorporate the unsupervised stemming models described in Section 3. The different approaches are presented schematically in <ref type="figure" target="#fig_3">Figure 1</ref>, using the example of the German past participle gedacht.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Stem-based Lemmatization</head><p>Our stem-based lemmatization method is an ex- tension of our basic stemming method. We com- pose the word-to-stem transduction model from Section 3 with a stem-to-lemma model that con- verts stems into lemmas. The latter is trained on character-aligned pairs of stems and lemmas, where stems are extracted from the inflection ta- bles via the unsupervised method described in Section 3.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Stemma-based Lemmatization</head><p>Our stemma-based lemmatization method is an extension of our joint stemming method. We com- pose the word-to-stemma transduction model de- scribed in Section 3.4 with a stemma-to-lemma model that converts stems into lemmas. The lat- ter is trained on character-aligned pairs of stem- mas and lemmas, where stemmas are extracted via the method described in Section 3.4. Typically, the model simply appends a lemmatic affix to the stemma, as all stem changes are handled by the word-to-stemma model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Direct Lemmatization</head><p>Our final lemmatization method is a word-to- lemma transduction model that directly transforms word-forms into lemmas and tags. The model is trained on word-forms paired with their lemmas and inflectional tags, which are easily obtained from the inflection tables. A potential advantage of this method lies in removing the possibility of error propagation that is inherent in pipeline ap- proaches. However, it involves a more complex transduction model that must simultaneously ap- ply both stem changes, and transform inflectional affixes into lemmatic ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Re-ranking</head><p>Intuitively, lemmatization accuracy could be im- proved by leveraging large, unannotated corpora. After generating n-best lists of possible lemmas, we re-rank them using the method of Joachims (2002) implemented with the Liblinear SVM tool <ref type="bibr" target="#b8">(Fan et al., 2008)</ref>. We employ four features of the prediction:</p><p>1. normalized score from DIRECTL+, 2. rank in the n-best list 3. presence in the corpus, 4. normalized likelihood from a 4-gram charac- ter language model derived from the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Lemmatization Experiments</head><p>Unlike stemming, lemmatization is a completely consistent process: all word-forms within an in- flection table correspond to the same lemma. In this section, we describe intrinsic and extrinsic ex- periments to evaluate the quality of the lemmas generated by our systems, and compare the results against the current state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data</head><p>As in our stemming experiments, we extract com- plete English, Dutch, and German inflection ta- bles from CELEX. We use the same data splits as in Section 4.1. We also evaluate our methods on Spanish verb inflection tables extracted from Wiktionary by <ref type="bibr" target="#b7">Durrett and DeNero (2013)</ref>, using the original data splits. Spanish is a Romance lan- guage, with a rich verbal morphology comprising 57 inflections for each lemma. A different type of dataset comes from the <ref type="bibr">CoNLL-2009</ref><ref type="bibr">Shared Task (Hajič et al., 2009</ref>. Unlike the CELEX and Wiktionary datasets, they are extracted from an annotated text, and thus con- tain few complete inflection tables, with many lemmas represented by a small number of word- forms. We extract all appropriate parts-of-speech from the test section of the corpus for English, German, and Spanish. This results in a test set of 5165 unique forms for English, 6572 for German, and 2668 for Spanish.</p><p>For re-ranking, we make use of a word list con- structed from the first one million lines of the ap- propriate Wikipedia dump. <ref type="bibr">6</ref>   vs. canto). In order to facilitate generalization, we perform a lossless pre-processing step that re- places all accented vowels with their unaccented equivalent followed by a special stress symbol (e.g. canto'). For consistency, this modification is applied to the data for each system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Intrinsic Evaluation</head><p>We evaluate lemmatization using word accuracy.</p><p>In cases where a surface word-form without a morphological tag may correspond to multiple lemmas, we judge the prediction as correct if it matches any of the lemmas. For example, both the noun Schrei and the verb schreien are consid- ered to be correct lemmas for the German word schreien. <ref type="bibr">8</ref> The results without the use of a corpus are shown in <ref type="table" target="#tab_10">Table 11</ref>. Thanks to its tag awareness, the stemma-based method is more accurate than the stem-based method, except on the verb-only Spanish Wiktionary dataset. However, our best method is the direct word-to-lemma model, which outperforms both Morfette and Lemming on most datasets.</p><p>We interpret the results as the evidence for the effectiveness of our discriminative string transduc- tion approach. The direct model is superior to the stemma-based model because it avoids any infor- mation loss that may occur during an intermediate stemming step. However, it is still able to take ad- vantage of the tag that it generates together with the target lemma. For example, Lemming incor- rectly lemmatizes the German noun form Verdi- enste "earnings" as verdien because +ste is a superlative adjective suffix. Our direct model, however, considers dien to be an unlikely ending for an adjective, and instead produces the correct lemma Verdienst.</p><p>The results with the use of a corpus are shown <ref type="bibr">8</ref> The capitalization of German nouns is ignored.  in <ref type="table" target="#tab_1">Table 12</ref>. We omit the results on Spanish Wik- tionary and on both English datasets, which are almost identical to those in <ref type="table" target="#tab_10">Table 11</ref>. We observe that both the stemma-based and direct methods achieve a substantial error rate reduction on the Dutch and German datasets, while Lemming im- provements are minimal. <ref type="bibr">9</ref> The Spanish CoNLL results are different: only the stem-based and stemma-based methods benefit noticeably from re- ranking. Error analysis indicates that the re-ranker is able to filter non-existent lemmas, such as wint for Winter, and endstadie for Endstadien, instead of Endstadium. In general, the degree of improve- ment seems to depend on the set of randomly se- lected instances in the held-out set used for train- ing the re-ranker. If a base model achieves a very high accuracy on the held-out set, the re-ranker tends to avoid correcting the predictions on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CELEX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Extrinsic Evaluation</head><p>We perform our final evaluation experiment on the German dataset 10 from the SIGMORPHON shared task on morphological reinflection (Cot- <ref type="table" target="#tab_1">Task 1 Task 3  Baseline  89.4  81.5  Chipmunk  82.0  88.3  Stem-based  86.9  89.3  Stemma-based</ref> 84.0 89.5 Lemma-based n/a 90.7 Source-Target 94.8 88.2 <ref type="table" target="#tab_2">Table 13</ref>: Accuracy on the German dataset from the shared task on morphological reinflection.</p><p>terell et al., 2016). <ref type="bibr">11</ref> The task of inflection gen- eration (Task 1) is to produce a word-form given a lemma and an abstract inflectional tag. The task of unlabeled reinflection (Task 3) takes as input an unannotated inflected form instead of a lemma.</p><p>We evaluate four different methods that com- bine the models introduced in this paper. For Task 1, the stem-based method composes a lemma-to- stem and a stem-to-word models; the stemma- based method is similar, but pivots on stemmas in- stead; and the source-target method is a lemma- to-word model. For Task 3, a word-to-lemma model is added in front of both the stem-based and stemma-based methods; the lemma-based method composes a word-to-lemma and a lemma-to-word models; and the source-target method is a word- to-word model. In addition, we compare with a method that is similar to our stem-based method, but pivots on Chipmunk-generated stems instead. As a baseline, we run the transduction method pro- vided by the task organizers.</p><p>The results are shown in <ref type="table" target="#tab_2">Table 13</ref>. On Task 1, none of the stemming approaches is competitive with a direct lemma-to-word model. This is not surprising. First, the lemmatic suffixes provide in- formation regarding part-of-speech. Second, the stemmers fail to take into account the fact that the source word-forms are lemmas. For example, the German wordüberhitzendword¨wordüberhitzend "overheated" can either be an adjective, or the present participle of the verbüberhitzen verb¨verbüberhitzen; if the word is a lemma, it is obviously the former.</p><p>The lemma-based method is the best perform- ing one on Task 3. One advantage that it has over the word-to-word model lies in the ability to reduce the potentially quadratic number of trans- duction operations between various related word- <ref type="bibr">11</ref> We use the development sets for this evaluation because the target sides of the test sets have not been publicly released.</p><p>forms to a linear number of transduction opera- tions between the word-forms and their lemmas, and vice-versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have presented novel methods that leverage readily available inflection tables to produce high- quality stems and lemmas. In the future, we plan to expand our method to predict morphological analyses, as well as to incorporate other informa- tion such as parts-of-speech.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Three lemmatization methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>A partial inflection table for the Spanish 
verb dar "to give". 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 )</head><label>3</label><figDesc>. Each table consists of lists of word forms, including the lemma. The num- ber of distinct stems, such as 'geb' and 'gib' for the verb geben, is typically very small, averaging slightly over two per German verb inflection table.</figDesc><table>Source g i b 

t 
Target g i b 
+t 
Tags 
STEM 
3SIE 
Joint 
g e b +3SIE 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Alignment of the various representations 
of the word gibt. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>). The sets contain 18,912 noun forms and 43,929 verb forms. We derive separate models for verbs and nouns in or- der to compare the difficulty of stemming different parts of speech. The test sets for both CELEX and Wiktionary data come from CELEX, and consist of 5252, 6155, and 9817 unique forms for English, Dutch, and German, respectively. The German test set contains 2620 nouns, 3837 verbs, and 3360 adjec- tives. Chipmunk 3 requires training data in which ev-</figDesc><table>EN 
NL 
DE 
Supervised 98.5 96.0 91.2 
Basic 
82.3 89.1 80.9 
Joint 
94.6 93.2 86.0 
Snowball 50.0 58.4 48.2 
Morfessor 65.2 60.9 51.8 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 ). 4</head><label>7</label><figDesc></figDesc><table>Noun Verb 
Basic 
76.8 90.3 
Joint 
85.2 91.1 
Snowball 
55.5 39.8 
Morfessor 61.9 34.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>German stemming accuracy of systems 
trained on Wiktionary data, and tested on the 
CELEX data. 

EN 
DE 
Supervised 94.7 85.1 
Chipmunk 94.9 87.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head></head><label></label><figDesc>the various systems approximate this goal by calculating the average number of unique gen- erated stems per inflection table in the CELEX test</figDesc><table>EN 
NL 
DE 
Gold 
1.10 1.17 1.30 
Supervised 1.13 1.64 1.50 
Basic 
1.06 1.21 1.25 
Joint 
1.09 1.08 1.20 
Snowball 1.03 1.45 2.02 
Morfessor 1.11 1.68 3.27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 10 :</head><label>10</label><figDesc></figDesc><table>Average number of stems per lemma. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table>Lemmatization results without the use of a corpus. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 12 :</head><label>12</label><figDesc></figDesc><table>Lemmatization results boosted with a 
raw corpus. 

</table></figure>

			<note place="foot" n="1"> http://snowball.tartarus.org</note>

			<note place="foot" n="2"> Morfessor is applied to the union of the training and test data. 3 http://cistern.cis.lmu.de/chipmunk</note>

			<note place="foot" n="4"> The decrease in Morfessor accuracy between Tables 6 and 7 can be attributed to a different POS distribution between training and testing.</note>

			<note place="foot" n="5"> Chipmunk is excluded from the consistency evaluation because its dataset is not composed of complete inflection tables.</note>

			<note place="foot" n="6"> All dumps are from November 2, 2015. 7 http://www.speech.cs.cmu.edu</note>

			<note place="foot" n="9"> We were unable to obtain any corpus improvement with Morfette. 10 http://sigmorphon.org/sharedtask</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Natural Sciences and Engineering Research Council of Canada, and the Alberta Innovates Technology Futures.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><forename type="middle">R</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Piepenbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Gulikers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The CELEX Lexical Database. Release</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="Pennsyl" to=" vania" />
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>CD-ROM). Linguistic Data Consortium, University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning morphology with Morfette</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Labeled morphological segmentation with semi-markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoNLL</title>
		<imprint>
			<biblScope unit="page">164</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Jason Eisner, and Mans Hulden. 2016. The SIGMORPHON 2016 shared taskmorphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMORPHON</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of morphemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 workshop on Morphological and phonological learning</title>
		<meeting>the ACL-02 workshop on Morphological and phonological learning</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Induction of a simple morphology for highly-inflecting languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Meeting of the ACL Special Interest Group in Computational Phonology: Current Themes in Computational Phonology and Morphology</title>
		<meeting>the 7th Meeting of the ACL Special Interest Group in Computational Phonology: Current Themes in Computational Phonology and Morphology</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="43" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inducing the morphological lexicon of a natural language from unannotated text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR05)</title>
		<meeting>the International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning (AKRR05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised learning of complete morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1185" to="1195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised learning of the morphology of a natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Goldsmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="198" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Morfessor FlatCat: An HMM-based method for unsupervised and semisupervised learning of morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stig-Arne</forename><surname>Grönroos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1177" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarek</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Integrating joint n-gram features into a discriminative training network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACLHLT</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the eighth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient higher-order CRFs for morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint lemmatization and morphological tagging with LEMMING</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised morphological segmentation with log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="209" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An algorithm for suffix stripping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Program</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Painless semi-supervised morphological segmentation using conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oskar</forename><surname>Teemu Ruokolainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Kohonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurimo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EACL</title>
		<imprint>
			<biblScope unit="page">84</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A global model for joint lemmatization and part-of-speech prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="486" to="494" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
