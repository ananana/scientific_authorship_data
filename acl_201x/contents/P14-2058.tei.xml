<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automation and Evaluation of the Keyword Method for Second Language Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gözdë</forename><surname>Ozbal</surname></persName>
							<email>gozbalde@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">FBK-irst Trento</orgName>
								<orgName type="institution">Trento RISE Trento</orgName>
								<address>
									<country>Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Pighin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">FBK-irst Trento</orgName>
								<orgName type="institution">Trento RISE Trento</orgName>
								<address>
									<country>Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Zürich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">FBK-irst Trento</orgName>
								<orgName type="institution">Trento RISE Trento</orgName>
								<address>
									<country>Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Switzerland</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">FBK-irst Trento</orgName>
								<orgName type="institution">Trento RISE Trento</orgName>
								<address>
									<country>Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">FBK-irst Trento</orgName>
								<orgName type="institution">Trento RISE Trento</orgName>
								<address>
									<country>Italy, Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automation and Evaluation of the Keyword Method for Second Language Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="352" to="357"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we combine existing NLP techniques with minimal supervision to build memory tips according to the keyword method, a well established mnemonic device for second language learning. We present what we believe to be the first extrinsic evaluation of a creative sentence generator on a vocabulary learning task. The results demonstrate that NLP techniques can effectively support the development of resources for second language learning.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The keyword method is a mnemonic device <ref type="bibr" target="#b0">(Cohen, 1987;</ref><ref type="bibr" target="#b16">Thompson, 1987)</ref> that is especially suitable for vocabulary acquisition in second lan- guage learning <ref type="bibr" target="#b7">(Mizumoto and Kansai, 2009;</ref><ref type="bibr" target="#b2">Hummel, 2010;</ref><ref type="bibr" target="#b13">Shen, 2010;</ref><ref type="bibr" target="#b15">Tavakoli and Gerami, 2013)</ref>. In this method, a target word in a foreign language L2 can be learned by a native speaker of another language L1 in two main steps: 1) one or more L1 words, possibly referring to a concrete entity, are chosen based on orthographic or pho- netic similarity with the target word; 2) an L1 sen- tence is constructed in which an association be- tween the translation of the target word and the keyword(s) is established, so that the learner, when seeing or hearing the word, immediately recalls the keyword(s). To illustrate, for teaching the Ital- ian word cuore which means heart in English, the learner might be asked to imagine "a lonely heart with a hard core".</p><p>The keyword method has already been proven to be a valuable teaching device. However, the preparation of the memorization tips for each new word is an activity that requires considerable time, linguistic competence and creativity. To the best of our knowledge, there is only one study which attempts to automate the mechanism of the key- word method. In ( ¨ Ozbal and Strapparava, 2011), we proposed to automate the keyword method by retrieving sentences from the Web. However, we did not provide any evaluation to demonstrate the effectiveness of our approach in a real life sce- nario. In addition, we observed that retrieval poses severe limitations in terms of recall and sentence quality, and it might incur copyright violations.</p><p>In this paper, we overcome these limitations by introducing a semi-automatic system implement- ing the keyword method that builds upon the key- word selection mechanism of¨Ozbalof¨ of¨Ozbal and Strappar- ava (2011) and combines it with a state-of-the-art creative sentence generation framework <ref type="bibr" target="#b9">( ¨ Ozbal et al., 2013</ref>). We set up an experiment to simulate the situation in which a teacher needs to prepare material for a vocabulary teaching resource. Ac- cording to our scenario, the teacher relies on au- tomatic techniques to generate relatively few, high quality mnemonics in English to teach Italian vo- cabulary. She only applies a very light supervi- sion in the last step of the process, in which the most suitable among the generated sentences are selected before being presented to the learners. In this stage, the teacher may want to consider factors which are not yet in reach of automatic linguistic processors, such as the evocativeness or the mem- orability of a sentence. We show that the automat- ically generated sentences help learners to estab- lish memorable connections which augment their ability to assimilate new vocabulary. To the best of our knowledge, this work is the first documented extrinsic evaluation of a creative sentence genera- tor on a real-world application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The effectiveness of the keyword method (KM) is a well-established fact <ref type="bibr" target="#b12">(Sarıçoban and Bas¸ıbekBas¸ıbek, 2012)</ref>. <ref type="bibr" target="#b14">Sommer and Gruneberg (2002)</ref> found that using KM to teach French made learning easier and faster than conventional methods. <ref type="bibr" target="#b11">Sagarra and Alba (2006)</ref> compared the effectiveness of three learning methods including the semantic mapping, rote memorization (i.e., memorization by pure repetition, with no mnemonic aid) and keyword on beginner learners of a second lan- guage. Their results show that using KM leads to better learning of second language vocabulary for beginners. Similar results have been reported by <ref type="bibr" target="#b12">Sarıçoban and Bas¸ıbekBas¸ıbek (2012)</ref> and <ref type="bibr" target="#b15">Tavakoli and Gerami (2013)</ref>. Besides all the experimental results demonstrating the effectiveness of KM, it is worthwhile to mention about the computational efforts to automate the mechanism. In ( ¨ Ozbal and Strapparava, 2011) we proposed an automatic vo- cabulary teaching system which combines NLP and IR techniques to automatically generate mem- ory tips for vocabulary acquisition. The system exploits orthographic and phonetic similarity met- rics to find the best L2 keywords for each target L1 word. Sentences containing the keywords and the translation of the target word are retrieved from the Web, but we did not carry out an evaluation of the quality or the coverage of the retrieved sen- tences. <ref type="bibr">In¨OzbalIn¨ In¨Ozbal et al. (2013)</ref> we proposed an ex- tensible framework for the generation of creative sentences in which users are able to force sev- eral words to appear in the sentences. While we had discussed the potentiality of creative sentence generation as a useful teaching device, we had not validated our claim experimentally yet. As a previ- ous attempt at using NLP for education, <ref type="bibr" target="#b5">Manurung et al. (2008)</ref> employ a riddle generator to create a language playground for children with complex communication needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Memory tip generation</head><p>Preparing memory tips based on KM includes two main ingredients: one or more keywords which are orthographically or phonetically similar to the L2 word to be learned; and a sentence in which the keywords and the translation of the target L2 word are combined in a meaningful way. In this section, we detail the process that we employed to generate such memory tips semi-automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Target word selection and keyword generation</head><p>We started by compiling a collection of Ital- ian nouns consisting of three syllables from var- ious resources for vocabulary teaching includ- ing http://didattica.org/italiano. htm and http://ielanguages.com, and produced a list of 185 target L2 words. To gen- erate the L1 keywords for each target word, we adopted a similar strategy tö Ozbal and Strappa- rava (2011). For each L2 target word t, the key- word selection module generates a list of possi- ble keyword pairs, K. A keyword pair k ∈ K can either consist of two non-empty strings, i.e., k = [w 0 , w 1 ], or of one non-empty and one empty string, i.e., w 1 = . Each keyword pair has the property that the concatenation of its elements is either orthographically or phonetically similar to the target word t. Orthographic and phonetic sim- ilarity are evaluated by means of the Levenshtein distance <ref type="bibr" target="#b3">(Levenshtein, 1966)</ref>. For orthographic similarity, the distance is calculated over the char- acters in the words, while for phonetic similarity it is calculated over the phonetic representations of t and w 0 + w 1 . We use the CMU pronuncia- tion dictionary 1 to retrieve the phonetic represen- tation of English words. For Italian words, instead, their phonetic representation is obtained from an unpublished phonetic lexicon developed at FBK- irst.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Keyword filtering and ranking</head><p>Unlike in <ref type="bibr" target="#b8">( ¨ Ozbal and Strapparava, 2011</ref>), where we did not enforce any constraints for selecting the keywords, in this case we applied a more so- phisticated filtering and ranking strategy. We re- quire at least one keyword in each pair to be a content word; then, we require that at least one keyword has length ≥ 3; finally, we discard pairs containing at least one proper noun. We allowed the keyword generation module to consider all the entries in the CMU dictionary, and rank the key- word pairs based on the following criteria in de- creasing order of precedence: 1) Keywords with a smaller orthographic/phonetic distance are pre- ferred; 2) Keywords consisting of a single word are preferred over two words (e.g., for the target word lavagna, which means blackboard, lasagna takes precedence over love and onion); 3) Key- words that do not contain stop words are preferred (e.g., for the target word pettine, which means comb, the keyword pair pet and inn is ranked higher than pet and in, since in is a stop word); 4) Keyword pairs obtained with orthographic similar- ity are preferred over those obtained with phonetic similarity, as learners might be unfamiliar with the phonetic rules of the target language. For example, for the target word forbice, which means scissors, Group <ref type="table">Target   Sentence   A1</ref> campagna a company runs the country A1 isola an island of remote isolated communities A1 fabbrica a fabric worker in a factory A1 bagnino lifeguards carry no bag A1 inverno the inferno started, winter left A1 cielo the sky has no ceiling A1 marrone blood and marrow in a brown water A1 cuore the lonely heart has hard core A1 coperta a piece of copper in the corner of a blanket A1 locanda an inn oak door with lock and key A2 piazza a square building serves a free pizza A2 calzino big bloke with sock in the casino A2 scatola a cardboard box sat in a scuttle of a house A2 ragazzo boys also have rag dolls A2 angolo a corner kick came at an angle A2 cestino a teen movie uses basket to play the chess A2 carbone the coal is the form of carbon A2 cassetto a blank cassette tape is in a drawer A2 farfalla the butterflies are far in the fall A2 tovaglia a damp cloth towel B1 duomo the old cathedral has a dome B1 aceto a vinegar sauce contains the acid B1 nuvola the sophisticated novel depicts the cloud B1</p><note type="other">chiesa the Catholic church has Swiss cheese B1 bacino the explosion in the back broke the pelvis B1 maiale a pork meat comes in the mail B1 minestra Chinese ministries have soup B1 estate this estate is for summer B1 bozzolo a buzz comes wrapped in the cocoon B1 arnese harness a technology to develop a tool B2 asino an Asian elephant is riding a donkey B2 miele do not make honey to walk a mile B2 polmone crowded pullmans stop the lungs B2 fagiolo a topical facial bean cream B2 fiore a fire in a flower market B2</note><p>compressa the clay tablet is in the compressed form B2 cavallo horse running fast in cavalry B2 fiume the muddy river has smoke and fumes B2 pittore a famous painter has precious pictures B2 manico manic people have broken necks <ref type="table">Table 1</ref>: Sentences used in the vocabulary acqui- sition experiment.</p><p>the keyword pair for and bid is preferred to for and beach.</p><p>We selected up to three of the highest ranked keyword pairs for each target word, obtaining 407 keyword combinations for the initial 185 Italian words, which we used as the input for the sentence generator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sentence generation</head><p>In this step, our goal was to generate, for each Ital- ian word, sentences containing its L1 translation and the set of orthographically (or phonetically) similar keywords that we previously selected. For each keyword combination, starting from the top- ranked ones, we generated up to 10 sentences by allowing any known part-of-speech for the key- words. The sentences were produced by the state of the art sentence generator of¨Ozbalof¨ of¨Ozbal et al. (2013). The system relies on two corpora of automatic parses as a repository of sentence templates and lexical statistics. As for the former, we combined two resources: a corpus of 16,000 proverbs <ref type="bibr" target="#b6">(Mihalcea and Strapparava, 2006</ref>) and a collection of 5,000 image captions 2 collected by <ref type="bibr" target="#b10">Rashtchian et al. (2010)</ref>. We chose these two collections since they offer a combination of catchy or simple sen- tences that we expect to be especially suitable for second language learning. As for the sec- ond corpus, we used LDC's English GigaWord 5th Edition <ref type="bibr">3</ref> . Of the 12 feature functions described in <ref type="bibr" target="#b9">( ¨ Ozbal et al., 2013)</ref>, we only implemented the following scorers: Variety (to prevent duplicate words from appearing in the sentences); Seman- tic Cohesion (to enforce the generation of sentence as lexically related to the target words as possi- ble); Alliteration, Rhyme and Plosive (to intro- duce hooks to echoic memory in the output); De- pendency Operator and N -gram (to enforce output grammaticality).</p><p>We observed that the sentence generation mod- ule was not able to generate a sentence for 24% of the input configurations. For comparison, when we attempted to retrieve sentences from the Web as suggested in¨Ozbalin¨ in¨Ozbal and Strapparava (2011), we could collect an output for less than 10% of the in- put configurations. Besides, many of the retrieved sentences were exceedingly long and complex to be used in a second language learning experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sentence selection</head><p>For each L1 keyword pair obtained for each L2 target word, we allowed the system to output up to 10 sentences. We manually assessed the quality of the generated sentences in terms of meaningful- ness, evocativeness and grammaticality to select the most appropriate sentences to be used for the task. In addition, for keyword pairs not containing the empty string, we prioritized the sentences in which the keywords were closer to each other. For example, let us assume that we have the keywords call and in for the target word collina. Among the sentences "The girl received a call in the bath- room" and "Call the blond girl in case you need", the first one is preferred, since the keywords are closer to each other. Furthermore, we gave pri- ority to the sentences that included the keywords in the right order. To illustrate, for the same key- words and the target words, we would prefer the sentence "I called him in the morning yesterday" over "You talk a lot in a call".</p><p>Accordingly, for each target word in random or- der, we sequentially scanned the outputs generated for each keyword pair. As soon as a sentence of adequate quality was found, we added it to our evaluation data and moved on to the next keyword. We continued this process until we selected a sen- tence for 40 distinct target words, which we set as the target size of the experiment. We had to inspect the outputs generated for 48 target words before we were able to select 40 good examples, meaning that for 17% of the target words the sen- tence generator could not produce a sentence of acceptable quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment setup</head><p>For our experiment, we drew inspiration from <ref type="bibr" target="#b11">Sagarra and Alba (2006)</ref>. We compared the re- tention error rate of learners who tried to memo- rize new words with or without the aid of the auto- matically generated sentences. Through academic channels, we recruited 20 native English speakers with no prior knowledge of Italian. <ref type="bibr">4</ref> After obtaining the sentences as explained in Section 3, we shuffled and then divided the whole set including 40 target words together with their translation, the generated keywords and sentences into 2 batches (A, B) and further divided each batch into 2 groups consisting of 10 elements (A1, A2, B1 and B2). The set of sentences assigned to each group is listed in <ref type="table">Table 1</ref>: Column "Tar- get" reports the Italian target word being taught; Column "Sentence" shows the automatically gen- erated sentence, where the translation of the tar- get word is shown in bold and the keyword(s) in italic. For the experiments, we randomly assigned each subject to one of the batches (A or B). Then, each subject was asked to memorize all the word pairs in a batch, but they would see the memory tips only for one of the two groups, which was again randomly assigned. This approach resulted in 4 different memorization exercises, namely 1) A1 with tips and A2 without, 2) A2 with tips and A1 without, 3) B1 with tips and B2 without, 4) B2 with tips and B1 without.   <ref type="table">Table 2</ref>: Per-group and overall retention error rate when using rote or keyword-aided (KW) memo- rization.</p><p>When memorizing the translations without the aid of memory tips, the subjects were instructed to focus only on the Italian word and its English translation and to repeat them over and over in their mind. Conversely, when relying on the au- tomatic memory tips the subjects were shown the word, its translation and the generated sentence in- cluding the keywords. In this case, the subjects were instructed to read the sentence over and over trying to visualize it.</p><p>After going through each set of slides, we dis- tracted the subjects with a short video in order to reset their short term memory. After that, their re- tention was tested. For each Italian word in the ex- ercise, they were asked to select the English trans- lation among 5 alternatives, including the correct translation and 4 other words randomly selected from the same group. In this way, the subjects would always have to choose among the words that they encountered during the exercise. <ref type="bibr">5</ref> We also added an extra option "I already knew this word" that the subjects were instructed to select in case they already knew the Italian word prior to taking part in the experiment. <ref type="table">Table 2</ref> summarizes the outcome of the experi- ment. The contribution of the automatically gen- erated sentences to the learning task is assessed in terms of error rate-reduction, which we mea- sure both within each group (rows 1-4) and on the whole evaluation set (rows 5-6). Due to the pres- ence of the "I already knew this word" option in the learning-assessment questionnaire, the number of the actual answers provided by each subject can be slightly different, hence the difference between macro-and micro-average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment results</head><p>The error rate for each memorization technique t (where t = R for "Rote memorization" and t = K for "keyword-aided memorization") is cal- culated as: e t = it ct+it , where c t and i t are the number of correct and incorrect answers provided by the subjects, respectively. The absolute error rate reduction ∆e is calculated as the absolute dif- ference in error rate between rote and keyword- aided memorization, i.e.: ∆ e = e R − e K . Finally, the relative error rate reduction % e is calculated as the the ratio between the absolute error rate reduc- tion ∆e and the error rate of rote memorization e R , i.e.,:</p><formula xml:id="formula_0">% e = ∆e e R = e R −e K e R .</formula><p>The overall results (rows 5 and 6 in <ref type="table">Table 2)</ref> show that vocabulary learning noticeably im- proves when supported by the generated sen- tences, with error rates dropping by almost 30% in terms of macro-average (almost 27% for micro- average). The breakdown of the error rate across the 4 groups shows a clear pattern. The results clearly indicate that one group (A1) by chance contained easier words to memorize as shown by the low error rate (between 3% and 4%) obtained with both methods. Similarly, groups A2 and B1 are of average difficulty, whereas group B2 ap- pears to be the most difficult, with an error rate higher than 22% when using only rote memoriza- tion. Interestingly, there is a strong correlation (Pearson's r = 0.85) between the difficulty of the words in each group (measured as the error rate on rote memorization) and the positive contri- bution of the generated sentences to the learning process. In fact, we can see how the relative er- ror rate reduction % e increases from ∼17% (group A1) to almost 45% (group B2). Based on the re- sults obtained by <ref type="bibr" target="#b11">Sagarra and Alba (2006)</ref>, who showed that the keyword method results in bet- ter long-term word retention than rote memoriza- tion, we would expect the error rate reduction to be even higher in a delayed post-test. All in all, these findings clearly support the claim that a state-of- the-art sentence generator can be successfully em- ployed to support keyword-based second language learning. After completing their exercise, the sub- jects were asked to provide feedback about their experience as learners. We set up a 4-items Lik- ert scale <ref type="bibr" target="#b4">(Likert, 1932)</ref> where each item consisted of a statement and a 5-point scale of values rang- ing from (1) [I strongly disagree] to (5) <ref type="bibr">[I strongly agree]</ref>. The distribution of the answers to the ques- tions is shown in <ref type="table">Table 3</ref>. 60% of the subjects ac- knowledged that the memory tips helped them in Rating <ref type="table">(%)   Question  1  2  3  4  5   Sentences helped  5 20 15 35 25  Sentences are grammatical -25 30 35 10  Sentences are catchy  -25 10 50 15  Sentences are witty  -25 25 50  -  Table 3</ref>: Evaluation of the generated sentences on a 5-point Likert scale.</p><p>the memorization process; 45% found that the sen- tences were overall correct; 65% confirmed that the sentences were catchy and easy to remember; and 50% found the sentences to be overall witty although the sentence generator does not include a mechanism to generate humor. Finally, it is worth mentioning that none of the subjects noticed that the sentences were machine generated, which we regard as a very positive assessment of the qual- ity of the sentence generation framework. From their comments, it emerges that the subjects ac- tually believed that they were just comparing two memorization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have presented a semi-automatic system for the automation of the keyword method and used it to teach 40 Italian words to 20 En- glish native speakers. We let the system select appropriate keywords and generate sentences au- tomatically. For each Italian word, we selected the most suitable among the 10 highest ranked sug- gestions and used it for the evaluation. The sig- nificant reduction in retention error rate (between 17% and 45% on different word groups) for the words learned with the aid of the automatically generated sentences shows that they are a viable low-effort alternative to human-constructed exam- ples for vocabulary teaching. As future work, it would be interesting to in- volve learners in an interactive evaluation to un- derstand the extent to which learners can bene- fit from ad-hoc personalization. Furthermore, it should be possible to use frameworks similar to the one that we presented to automate other teach- ing devices based on sentences conforming to spe- cific requirements <ref type="bibr" target="#b1">(Dehn, 2011</ref>), such as verbal chaining and acrostic.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Error</head><label></label><figDesc></figDesc></figure>

			<note place="foot" n="1"> http://www.speech.cs.cmu.edu/cgi-bin/ cmudict</note>

			<note place="foot" n="2"> http://vision.cs.uiuc.edu/ pascal-sentences/ 3 http://www.ldc.upenn.edu/Catalog/ catalogEntry.jsp?catalogId=LDC2011T07</note>

			<note place="foot" n="4"> We preferred to select the experiment subjects in person as opposed to crowdsourcing the evaluation to be able to verify the proficiency of the subjects in the two languages and to ensure the reliability of the outcome of the evaluation.</note>

			<note place="foot" n="5"> Otherwise, they could easily filter out the wrong answers just because they were not exposed to them recently.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partially supported by the PerTe project (Trento RISE).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The use of verbal and imagery mnemonics in second-language vocabulary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Second Language Acquisition</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="43" to="61" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Working Memory and Academic Learning: Assessment and Intervention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Dehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Translation and short-term L2 vocabulary retention: Hindrance or help? Language Teaching Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hummel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Physics Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A technique for the measurement of attitudes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Likert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Archives of Psychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="55" />
			<date type="published" when="1932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Construction of a Pun Generator for Language Skill Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruli</forename><surname>Manurung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Pain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annalu</forename><surname>Waller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><forename type="middle">O</forename><surname>Mara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolf</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="841" to="869" />
			<date type="published" when="2008-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to laugh (automatically): Computational models for humor recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="142" />
			<date type="published" when="2006-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Examining the effectiveness of explicit instruction of vocabulary learning strategies with Japanese EFL university students</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mizumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">T</forename><surname>Kansai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Teaching Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MEANS: Moving Effective Assonances for Novice Students</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gözdë</forename><surname>Ozbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Intelligent User Interfaces (IUI 2011)</title>
		<meeting>the 16th International Conference on Intelligent User Interfaces (IUI 2011)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="449" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BRAINSUP: Brainstorming Support for Creative Sentence Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gözdë</forename><surname>Ozbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Pighin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1446" to="1455" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collecting image annotations using amazon&apos;s mechanical turk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Rashtchian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk, CSLDAMT &apos;10</title>
		<meeting>the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon&apos;s Mechanical Turk, CSLDAMT &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="139" to="147" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The key is in the keyword: L2 vocabulary learning methods with beginning learners of spanish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sagarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="243" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mnemonics technique versus context method in teaching vocabulary at upper-intermediate level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sarıçoban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bas¸ıbekbas¸ıbek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Education and Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">164</biblScope>
			<biblScope unit="page" from="251" to="266" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagery and verbal coding approaches in Chinese vocabulary instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Helen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Teaching Research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="485" to="499" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The use of linkword language computer courses in a classroom situation: a case study at rugby school</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gruneberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Learning Journal</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="53" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The effect of keyword and pictorial methods on EFL learners&apos; vocabulary learning and retention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tavakoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gerami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PORTA LINGUARUM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="299" to="316" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using bilingual dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ELT Journal</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="282" to="286" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
	<note>cited By (since 1996)6</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
