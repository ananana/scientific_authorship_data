<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Cascading Errors using Constraints in Dependency Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominick</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="laboratory">@-lab</orgName>
								<orgName type="institution">University of Sydney NSW 2006</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="laboratory">@-lab</orgName>
								<orgName type="institution">University of Sydney NSW 2006</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Cascading Errors using Constraints in Dependency Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1148" to="1158"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Dependency parsers are usually evaluated on attachment accuracy. Whilst easily interpreted , the metric does not illustrate the cascading impact of errors, where the parser chooses an incorrect arc, and is subsequently forced to choose further incorrect arcs elsewhere in the parse. We apply arc-level constraints to MST-parser and ZPar, enforcing the correct analysis of specific error classes, whilst otherwise continuing with decoding. We investigate the direct and indirect impact of applying constraints to the parser. Erroneous NP and punctuation attachments cause the most cascading errors, while incorrect PP and coordination attachments are frequent but less influential. Punctuation is especially challenging, as it has long been ignored in parsing, and serves a variety of disparate syntactic roles.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dependency parsers are evaluated using word- level attachment accuracy. Whilst comparable across systems, this does not provide insight into why the parser makes certain errors, or whether certain misattachments are caused by other errors. For example, incorrectly identifying a modifier head may only introduce a single attachment error, while misplacing the root of a sentence will create substantially more errors elsewhere. In projective dependency parsing, erroneous arcs can also force the parser to select other incorrect arcs. <ref type="bibr" target="#b11">Kummerfeld et al. (2012)</ref> propose a static post- parsing analysis to categorise groups of bracket er- rors in constituency parsing into higher level error classes such as clause attachment. However, this cannot account for cascading changes resulting from repairing errors, or limitations which may prevent the parser from applying a repair. It is un- clear whether the parser will apply the repair op- eration in its entirety, or if it will introduce other changes in response to the repairs.</p><p>We develop an evaluation procedure to evalu- ate the influence of each error class in dependency parsing without making assumptions about how the parser will behave. We define error classes based on dependency labels, and use the depen- dencies in each class as arc constraints specifying the correct head and label for particular words in each sentence. We adapt parsers to apply these constraints, whilst otherwise proceeding with de- coding under their grammar and model. By eval- uating performance with and without constraints, we can directly observe the cascading impact of each error class on each the parser.</p><p>We implement our procedure for the graph- based MSTparser <ref type="bibr" target="#b14">(McDonald and Pereira, 2006</ref>) and the transition-based ZPar ( <ref type="bibr" target="#b26">Zhang and Clark, 2011</ref>) using basic Stanford dependencies over the OntoNotes 4.0 release of the WSJ Penn Treebank data. Our results show that erroneously attach- ing NPs, PPs, modifiers, and punctuation have the largest overall impact on UAS. Of those, NPs and punctuation have the most substantial cascading impact, indicating that these errors have the most effect on the remainder of the parse. Enforcing correct punctuation arcs has a particularly large impact on accuracy, even though most evaluation scripts ignore punctuation. We find that punctu- ation arcs are commonly misplaced by large dis- tances in the final parse, crossing over and forcing other arcs to be incorrect in the process.</p><p>We will make our source code available, and</p><p>The LME stocks decline was about as expected , but the Comex gain was n't .  The LME stocks decline was about as expected , but the Comex gain was n't .  hope that our findings will drive efforts address- ing the remaining dependency parsing errors.  <ref type="figure" target="#fig_1">Figure 1</ref> depicts a WSJ 22 sentence as parsed by MSTparser, and the gold parse. The UAS is 47.1%, with 8 of 17 arcs correct. By contrast, ZPar (parse not shown) scores 94.1%, with the sole attachment error being on LME (as with MSTparser). While there are nine incorrect arcs overall, MSTparser seems to have made only two underlying errors:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation</head><p>• LME attached to decline rather than stocks (NP internal). Correcting this repairs one error;</p><p>• expected being chosen as the root rather than was. Correcting the root and moving all at- tachments to it from the old root repairs the remaining eight errors.</p><p>Intuitively, it seems that the impact of the NP error is limited. By contrast, the root selection error has a substantial impact on the second half of the sentence, causing a misplaced subject, mis- attached punctuation, and incorrect coordination. These cascaded errors appear to be caused by the incorrect root.</p><p>What we do not know is whether these intu- itions actually hold. Many dependency parsers, including MSTparser and ZPar, construct trees by repeatedly combining fragments together until a spanning analysis is found, using a small window of information to make each arc decision. An er- ror in one part of the tree may have no influence on a different part of the tree. Alternatively, er- rors may exert long-range influence -particularly if there are higher-order features or algorithmic constraints such as projectivity over the tree. As parsing algorithms are complex, we wish to repair various error types in isolation without otherwise making assumptions regarding the subsequent ac- tions of the parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Applying Constraints</head><p>We investigate how each parser behaves when cer- tain errors in the tree are corrected. We force each parser to select the correct head and label for spe- cific words, but otherwise allow it to construct its best parse. Given a set of constraints, each of which lists a word with the head and label to which it must be attached, we investigate two measures:</p><p>1. errors directly corrected by the constraints, called the constrained accuracy impact;</p><p>2. the indirect impact of the constraints, includ- ing errors indirectly corrected, and correct arcs indirectly destroyed, together called the cascaded accuracy impact.</p><p>The constrained accuracy impact tells us how often the parser makes errors in the set of words covered by the constraints. The cascaded accu- racy impact is less predictable, as it describes what effect the errors made over the constrained set of arcs have over the rest of the sentence. It is the influence of the set of constraints over the other attachments, which may be mediated through pro- jectivity requirements, or changes in the context used for other parsing decisions.</p><p>The core of our procedure is adapting each parser to accept a set of constraints. Following <ref type="bibr" target="#b11">Kummerfeld et al. (2012)</ref>, we define meaningful error classes grouped with the operations that re- pair them. In dependency parsing, error classes are groups of Stanford dependency labels, rather than groups of node repair operations. The Stan- ford labels provide a rich distinction in NP internal structure, clauses, and modifiers, and map well to the error categories of <ref type="bibr" target="#b11">Kummerfeld et al. (2012)</ref>, allowing us to avoid excessive heuristics in the mapping process. Our technique can be applied to other dependency schemes such as LTH <ref type="bibr" target="#b9">(Johansson and Nugues, 2007)</ref> by defining new mappings from labels to error types.</p><p>The difficulty of the mapping task depends on the intricacies of each formalism. The major challenge with LTH dependencies is the enormous skew towards the nominal modifier NMOD label. This label occurs 11,335 times in WSJ 22, more than twice as frequently as the next most fre- quent punctuation P. By contrast, the most com- mon Stanford label is punctuation, at 4,731 occur- rences. The NMOD label is split into many smaller, but more informative nominal labels in the Stan- ford scheme, making it better suited for our goal of error analysis.</p><p>The label grouping was performed with refer- ence to the Stanford dependencies manual v2.04 <ref type="bibr">Manning, 2008, updated 2012</ref>). For each error class, we generate a set of con- straints over WSJ 22 for all words with a gold- standard label in the set associated with the class. Our types are defined as follows: NP attachment: any label specifically attaching an NP, includes appos, dobj, iobj, nsubj, nsubjpass, pobj, and xsubj. NP internal: any label marking nominal struc- ture (not including adjectival modifiers), in- cludes abbrev, det, nn, number, poss, possessive, and predet. PP attachment: any label attaching a preposi- tional phrase, includes prep. Also includes pcomp if the POS of the word is TO or IN. Clause attachment: any label attaching a clause, includes advcl, ccomp, csubj, csubjpass, purpcl, rcmod, and xcomp. Also includes pcomp if the POS of the word is not TO or IN. Modifier attachment:</p><p>any label attaching an adverbial or adjectival modifier, includes advmod, amod, infmod, npadvmod, num, partmod, quantmod, and tmod. Coordination attachment: conj, cc, and preconj. Root attachment: the root label. Punctuation attachment: the punct label.</p><p>Other attachment: all other Stanford labels, specifically acomp, attr, aux, auxpass, complm, cop, dep, expl, mark, mwe, neg, parataxis, prt, ref, and rel. For example, Root constraints specify sentence roots, while PP constraints specify heads of prepo- sitional phrases.</p><p>One deficiency of our implementation is that we apply constraints to all arcs of a particular error type in each sentence, and do not isolate multiple instances of the same error class in a sentence. We do this since applying single constraints to a sen- tence at a time would require substantial modifica- tions to the standard evaluation regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MSTparser implementation</head><p>MSTparser is a graph-based, second-order parser that uses Eisner (1996)'s algorithm for projective decoding <ref type="bibr" target="#b14">(McDonald and Pereira, 2006</ref>). 1 Eis- ner's algorithm constructs and caches subtrees which span progressively larger sections of the sentence. These spans are marked either as com- plete, consisting of a head, a dependent, and all of the descendants of that head to one side, or in- complete, consisting of a head, a dependent, and an unfilled region where additional tokens may be attached. Dependencies are formed between the head and dependent in each complete span, while label assignment occurs as a separate process.</p><p>We enforce constraints by allowing complete spans to be formed only from constrained tokens to their correct heads with the correct labels. Any complete span between an incorrect head and the constrained token is forbidden. The algorithm is forced to choose the constrained spans as it builds the parse; these constraints have no impact on the parser's coverage as all possible head selections are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">ZPar implementation</head><p>ZPar is an arc-eager transition-based parser ( <ref type="bibr" target="#b26">Zhang and Clark, 2011</ref>) that uses an incremen- tal process with a stack storing partial parse states ( <ref type="bibr" target="#b18">Nivre et al., 2004</ref>). Each state represents tokens that may accept further arcs. The tokens of a sen- tence are initially stored in a buffer, and at each point during parsing, the parser decides whether or not to create an arc between the front token of the buffer and the top token on the stack.</p><p>We apply constraints in a similar way to <ref type="bibr" target="#b17">Nivre et al. (2014)</ref>. Arc creation actions are factored on the dependency label to be assigned to the arc. ZPar scores each possible action using a percep- tron model over features from the front of the buffer and the top of the stack (as well as some ad- ditional context features which refer to previously created states). The highest scoring actions and their resulting states are kept in a beam; during parsing, ZPar finds the optimal action for all items in the beam, and retains the highest scoring new states at each step.</p><p>We disallow any arc creation action that would create an arc that conflicts with any constraints. Due to the use of beam search, it is possible for all of the partial states containing the constrained arcs to be evicted from the beam if they score lower under the model than other states. When this hap- pens, the parser will fail to find an analysis for the sentence, as no head will exist in the beam for the constrained token. We have deliberately chosen to not address this issue as any solution (e.g. increas- ing the beam size from its default of 64) would change the decisions of the parser and model. We verified that our modifications were work- ing correctly for both parsers by passing in zero constraints (checking that the output matched the baseline performance), and every possible con- straint (checking that the output scored 100%). <ref type="bibr" target="#b11">Kummerfeld et al. (2012)</ref> perform a comprehen- sive classification of constituency bracket errors and their cascading impact, and their work is philosophically similar to ours. They associate groups of bracket errors in the parse with abstract error classes, and identify the tree operations that repair these error types, such as the insertion, dele- tion, or substitution of nodes in the parse tree. The error classes in a particular parser's output are identified through a heuristic procedure that re- peatedly applies the operation repairing the largest number of bracket errors. This approach differs from our methodology as it is a static post-process that assumes the parser would respond perfectly to each repair, when it is possible that the parser may not perform the repair in full, or even be incapable of constructing the repaired tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>McDonald and Nivre (2011) perform an in- depth comparison of the graph-based MSTparser and transition-based MaltParser. However, Malt- Parser uses support vector machines to determinis- tically predict the next transition, rather than stor- ing the most probable options in a beam like ZPar. Additionally, they do not focus on the cascad- ing impact of errors, and instead concentrate on higher-level error classification (e.g. by POS tag, labels and dependency lengths) in lieu of examin- ing how the parsers respond to forced corrections. <ref type="bibr" target="#b17">Nivre et al. (2014)</ref> describe several uses for arc- level constraints in transition-based parsing. How- ever, these applications focus on improving pars- ing accuracy when constraints can be readily iden- tified, e.g. imperatives at the beginning of a sen- tence are likely to be the root. We focus our con- straints on evaluation, attempting to identify im- portant sources of error in dependency parsers.</p><p>Our constraint-based approach shares similar- ities to oracle training and decoding methods, where an external source of truth is used to ver- ify parser decisions. An oracle source of parser actions is a necessary component for training transition-based parsers <ref type="bibr" target="#b16">(Nivre, 2009)</ref>. Oracle de- coding, where a system is forced to produce cor- rect output if possible, can be used to assess its up- per performance bounds (Ng and Curran, 2012).</p><p>Constraining the parser's internal search space is akin to an optimal pruning operation. Char- niak and Johnson (2005) use a coarse-to-fine, it- erative pruning approach for efficiently generat- ing high-quality n-best parses for a discriminative reranker. Rush and Petrov (2012) use a similar coarse-to-fine algorithm with vine grammars <ref type="bibr" target="#b8">(Eisner and Smith, 2005</ref>) to accelerate graph-based de-The LME stocks decline was about as expected , but the Comex gain was n't .   <ref type="table">Table 2</ref>: Correct and incorrect arcs, and the re- maining errors after applying various sets of con- straints to the sentence in <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>pendency parsing, achieving parsing speeds close to linear-time transition parsers despite encoding more complex features. Supertagging <ref type="bibr" target="#b4">(Clark and Curran, 2007)</ref> and chart pruning ( <ref type="bibr" target="#b25">Zhang et al., 2010)</ref> have been used to constrain the search space of a CCG parser, and to remove unlikely or for- bidden spans from repeated consideration. In our work, we use pruning not for parsing speed, but evaluation, and so we prune items based on gold- standard constraints rather than heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We use the training (sections 2-21) and develop-  <ref type="bibr" target="#b20">(Ratnaparkhi, 1996)</ref>. A model trained on WSJ sections 2-21 was used to tag the development set, and 10-fold jackknife training was used to tag the training data. We implement a custom evaluation script to facilitate a straightforward comparative analysis between the unconstrained and constrained out- put. The script is based on and produces identi- cal scores to eval06.pl, the official evaluation for the CoNLL-X Shared Task on Multilingual Dependency Parsing ( <ref type="bibr" target="#b1">Buchholz and Marsi, 2006</ref>). We ignore punctuation as defined by eval06.pl in our evaluation; experiments with constraints over punctuation tokens constrain those tokens in the parse, but ignore them during evaluation.</p><p>We run the modified parsers over WSJ 22 with and without each set of constraints. We ex- amine the overall unlabeled and labeled attach- ment scores (UAS and LAS), as well as identify- ing the contribution to the overall UAS improve- ment from directly (constrained) and indirectly corrected arcs.</p><p>MSTparser uses coarse-grained tags and fine- grained POS tags in its features, both of which were provided by the CoNLL-X Shared Task. We approximate the coarse-grained POS tags by taking the first character of the MXPOST-assigned POS tag, a technique also used by <ref type="bibr" target="#b0">Bansal et al. (2014)</ref> 3 .  <ref type="table">Table 2</ref> show the impact of applying constraints on tokens with various labels to MST- parser for the sentence in <ref type="figure" target="#fig_1">Figure 1</ref>. Enforcing the gold nn arc between decline and LME repairs that noun phrase error, but does not affect any of the other errors. Conversely, enforcing the gold root arc does not affect the noun phrase error, but re- pairs nearly every other error in the parse. Un- fortunately, the constrained root arc introduces cover eff eff % disp UAS   The UAS of constrained arcs in each experiment is the expected 100%. Effective constraints repair an error in the baseline, and the effective constraint percentage is this figure expressed as a percentage, i.e. the error rate. Error displacement is the av- erage number of words that effective constraints moved an attachment point. The overall ∆UAS improvement is divided into ∆c, the constrained impact, and ∆u, the cascaded impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∆UAS ∆c ∆u</head><p>It is important to note that a parser may make a substantial number of mistakes on a particular error class (large effective constraint percentage), but correcting those mistakes may have very little cascading impact (small ∆c), limiting the overall ∆UAS improvement. Conversely, there may be a class with a small effective constraint percentage, but a large ∆UAS due to a large cascading impact from the corrections, or simply because the class contains more constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Overall Parser Comparison</head><p>When applying all constraints, ZPar has a 8.8% effective constraint percentage compared to 9.3% for MSTparser. This is directly related to the UAS difference between the parsers. Aside from coor- dination, where the parsers made a nearly identi- cal number of errors, ZPar is more accurate across the board. It makes substantially fewer mistakes on clause attachments, punctuation dependencies, and NP attachments, whilst maintaining a small advantage across all of the other categories.</p><p>The relative rank of the effective constraint per- centage per error category is similar across the parsers, with PP attachment, punctuation, modi- fiers, and coordination recording the largest num- ber of effective constraints, and thus the most er- rors. This illustrates that the behaviour of both parsers is very consistent, despite one considering every possible attachment point, and the other us- ing a linear transition-based beam search. ZPar is able to make fewer mistakes across each error category, suggesting that the beam search pruning is maintaining more desired states than the graph- based parser is able to rank during its search.</p><p>ZPar's coverage is 98.5% when applying all constraints. However, as the number of con- straints is reduced, coverage also drops. This seems counter-intuitive, but applying more con- straints eliminates more undesired states, leaving more space in the beam for satisfying states. Re- ducing the number of constraints permits more states which do not yet violate a constraint, but only yield undesired states later.</p><p>Punctuation constraints have the largest impact on coverage, reducing it to 93.2%. NP attach- ments, clauses, and modifier attachments also in- cur substantial coverage reductions. This suggests that ZPar's performance will degrade substantially over the sentences which it cannot cover, as they must contain constructions which are dispreferred by the model and fall out of the beam. Constraints with the smallest effect on coverage include root attachments, which only occur once per sentence and are rarely incorrect, and NP internal and PP at- tachments. For the latter two, the small displace- ments suggest that alternate attachment points of- ten lie within the same projective span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Noun phrases</head><p>Applying NP attachment constraints causes a 4.4% drop in coverage for ZPar, and the effective con- straint percentage is below 5% for both parsers. However, these constraints still result in the largest ∆UAS for both parsers, at 2.6% for MSTparser and 2.2% for ZPar. This reflects the prevalence of NP attachments in the corpus.</p><p>∆UAS is split evenly between correcting con- strained (1.4%) and cascaded arcs (1.2%) for MSTparser, while it skews towards cascaded arcs for ZPar (1.0% and 1.4%). Most error classes skew in the other direction, while repairing one NP attachment error typically repairs another non-NP attachment error.</p><p>For NP internal attachments, both parsers have a similar error rate, with 206 effective constraints for MSTparser and 197 for ZPar. Although this is the second largest class, applying these constraints gives the second smallest ∆u for both parsers. This implies that determining NP internal struc- ture is a strength, even with the more complex OntoNotes 4 NP structure. ∆c is also small for both parsers, reinforcing the limited displacement and cascading impact of NP internal errors.</p><p>Despite fewer effective constraints (i.e. less errors to fix), ZPar exhibits more cascading re- pair than MSTparser using both NP and NP in- ternal constraints. This will be a common theme through this evaluation: the transition-based ZPar is better at propagating effective constraints into cascaded impact than the graph-based MSTparser, even though ZPar almost always begins with fewer effective constraints due to its better baseline per- formance. One possibility to explain this is that the beam is actually pruning away other erroneous states, while the graph-based MSTparser must still consider all of them. <ref type="table" target="#tab_8">Table 5</ref> summarises the error classes of cor- rected cascaded arcs for the two NP constraint types, which are closely related. NP attachment constraints directly identify the head of the NP as well as its correct attachment, providing strong cues for determining the internal structure. NP in- ternal constraints implicitly identify the head of an NP. We can see that for both types of constraints, many of the cascaded corrections come from the other NP error class. <ref type="table" target="#tab_8">Table 5</ref> also shows that, compared to MST- parser, ZPar repairs nearly twice as many NP inter- nal and coordination errors when using NP attach- ment constraints, and vice versa when using NP internal constraints. This suggests that ZPar has more difficulty identifying the correct heads for NP attachment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NP internal Error class</head><p>MSTparser <ref type="table" target="#tab_2">ZPar MSTparser ZPar   NP attachment  - - 45  69  NP internal  43  80  - - Modifier attachment  65  68  24  30  PP attachment  26  36  2  10  Coordination attachment  37  67  20  41  Clause attachment  59  65  1  1  Root attachment  24  21  2  1  Punctuation attachment  79  80  26  41  Other attachment  68  76  7  11  Total  401  493</ref> 127 204 nominal coordination, and often chooses a word which should be a nominal modifier instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Coordination, Modifiers and PPs</head><p>These categories are large error classes for both parsers, with constraints leading to UAS improve- ments of 1.3 to 1.7%.</p><p>PPs and coordination have high effective con- straint percentages relative to the other error classes for both parsers. However, they are also amongst the most isolated errors, with only 0.3% and 0.4% ∆u for MSTparser and ZPar respec- tively. These errors also have minimal impact on ZPar's coverage. Both classes seem to have rela- tively contained attachment options within a lim- ited projective span. The small error displace- ments reinforce this idea.</p><p>Modifiers are relatively isolated errors for MST- parser (0.5% ∆u), but less so for ZPar (0.7% ∆u). There are substantially more modifier constraints than PP or coordination, despite all yielding a sim- ilar UAS increase. This suggests that modifiers are actually relatively well analysed by both parsers, but there are so many of them that they form a large source of error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Clause attachment</head><p>MSTparser performs substantially worse than ZPar on clause attachments, with an effective con- straint percentage of 17.9% compared to 13.0%, and ∆c of 0.9% compared with 0.6%. MST- parser's error rate is the worst of any error class on clause attachments, while it is second to coor- dination attachments for ZPar. Attaching clauses is very challenging for dependency parsers, partic- ularly considering the small size of the class.</p><p>ZPar again achieves a slightly larger cascaded impact than MSTparser (0.6% to 0.5%), despite having far fewer effective constraints. This im- plies that the additional clause errors being made by MSTparser are largely self-contained, as they have not triggered a corresponding increase in ∆u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Root attachment</head><p>Both parsers make few root attachment errors, though MSTparser is less accurate than ZPar. However, root constraints provide the largest UAS improvement per number of constraints for both parsers. Root errors are also the most displaced of any error class, at 9.3 words for MSTparser and 9.9 for ZPar. When the root is incorrect, it is of- ten very far from its correct location, and causes substantial cascading errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Punctuation</head><p>Despite ignoring punctuation dependencies in evaluation, applying punctuation constraints led to substantial UAS improvements. On MSTparser, ∆u is 0.1% (due to some punctuation not being excluded from evaluation), but ∆c is 1.7%. On ZPar, the equivalent metrics are 0.2% and 1.5%. Enforcing correct punctuation has a disproportion- ate impact on the remainder of the parse.</p><p>For both parsers, punctuation errors occur more frequently than any other error type, with 469 and 430 effective constraints respectively (though the majority of these corrected errors are on non- evaluated arcs). ZPar's coverage is worst of all when enforcing punctuation constraints, suggest- ing that the remaining uncovered sentences will Error class <ref type="table" target="#tab_2">MSTparser ZPar   NP attachment  75  51  NP internal  25  27  Modifier attachment  33  43  PP attachment  45  55  Coordination attachment  87  106  Clause attachment  66  48  Root attachment  59  27  Other attachment  65  69  Total  455  426   Table 6</ref>: The number of unconstrained errors re- paired per error class when enforcing punctuation constraints for MSTparser and ZPar.</p><p>contain even more punctuation errors. Incorrect punctuation heads are displaced from their correct locations by 7.4 words for MSTparser and 7.3 words for ZPar on average, second only to root attachments. Given that we are using projec- tive parsers and a projective grammar, the large av- erage displacement caused by errors indicates that punctuation affects and is in turn affected by the requirement for non-crossing arcs. <ref type="table">Table 6</ref> summarises the error classes of the re- paired cascaded arcs when punctuation constraints are applied. MSTparser has a more even distri- bution of repairs, while ZPar's repairs are con- centrated in coordination attachment. This shows that MSTparser is relatively better at coordination as a proportion of its overall performance com- pared to ZPar. It also indicates that the majority of punctuation errors in both parsers (and especially ZPar) stem from incorrectly identified coordina- tion markers such as commas.</p><p>Punctuation is commonly ignored in depen- dency parser evaluation ( <ref type="bibr" target="#b24">Yamada and Matsumoto, 2003;</ref><ref type="bibr" target="#b1">Buchholz and Marsi, 2006</ref>), and they are inconsistently treated across different grammars. Our results show that enforcing the correct punc- tuation attachments in a sentence has a substan- tial cascading impact, suggesting that punctua- tion errors are highly correlated with errors else- where in the analysis. Given the broad simi- larities between Stanford dependencies and other dependency schemes commonly used in parsing <ref type="bibr">(Søgaard, 2013)</ref>, we anticipate that the problems with roots and punctuation will carry across dif- ferent treebanks and schemes.</p><p>Punctuation is often placed at phrasal bound- aries and serves to split sentences into smaller sec- tions within a projective parser. Graph-based and transition-based parsers, both of which use a lim- ited local context to make parsing decisions, are equally prone to the cascading impact of erroneous punctuation. Removing the confounding presence of punctuation from parsing and treating attach- ment as a global post-process may help to allevi- ate these issues. Alternatively, more punctuation- specific features to account for its myriad roles in syntax could serve to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have developed a procedure to classify the im- portance of errors in dependency parsers without any assumptions on how the parser will respond to attachment repairs. Our approach constrains the parser to allow only correct arcs for certain tokens, whilst allowing it to otherwise form the parse that it thinks is best. Compared to <ref type="bibr" target="#b11">Kummerfeld et al. (2012)</ref>, we can observe exactly how the parser re- sponds to the parse repairs, though at the cost of requiring modifications to the parser itself.</p><p>Our results show that noun phrases remain chal- lenging for dependency parsers, both in choosing the correct head, and in determining the internal structure. Punctuation, despite being commonly ignored in parsers and evaluation, causes substan- tial cascading errors when misattached.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>det</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: MSTparser output (top) and the gold parse (bottom) for a WSJ 22 sentence. MSTparser produces two independent errors: an NP bracketing error (red, dotted), and an incorrect root (blue, dashed).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MSTparser output for the sentence in Figure 1, where the root dependency is forced to its correct value. The incorrect noun phrase error is not affected by the constraint (dashed, red), six attachment errors are repaired (solid, blue), and two new errors are introduced (dotted, purple).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 and</head><label>2</label><figDesc>Figure 2 and Table 2 show the impact of applying constraints on tokens with various labels to MSTparser for the sentence in Figure 1. Enforcing the gold nn arc between decline and LME repairs that noun phrase error, but does not affect any of the other errors. Conversely, enforcing the gold root arc does not affect the noun phrase error, but repairs nearly every other error in the parse. Unfortunately, the constrained root arc introduces</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 summarises</head><label>1</label><figDesc></figDesc><table>the performance of MST-
parser and ZPar on Stanford dependencies over 
OntoNotes 4 WSJ 22. ZPar performs slightly 
better than MSTparser on UAS, and substantially 
better on LAS. However, these numbers do not 
show what types of errors are being made by each 
parser, what errors remain to be addressed, or hint 
at what underlying problems cause each error. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Constraints 
Remaining Errors 
None 
8 9 see Figure 1 
nn 
9 8 All except decline → LME 
root 
14 3 decline → LME 
about → expected 
was → about 
punct 
14 3 decline → LME 
about → expected 
was → about 
ccomp 
16 1 decline → LME 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The coverage, effective constraints and percentage, error displacement, UAS, LAS, ∆UAS over 
the corrected arcs, and the constrained and cascaded ∆ for MSTparser over WSJ 22 (covered by ZPar). 

Error class 
cover 
eff 
eff % disp UAS 

LAS 

∆UAS ∆c ∆u 
Baseline 
100.0 
-
-
-
91.7 
89.2 
-
-
-
NP attachment 
95.6 
277 
4.3 
4.8 
94.9 
92.7 
2.4 1.0 1.4 
NP internal 
98.2 
197 
3.0 
3.0 
93.2 
91.1 
1.2 0.7 0.5 
Modifier attachment 
96.8 
303 
7.5 
3.9 
94.0 
92.3 
1.8 1.1 0.7 
PP attachment 
98.3 
357 
12.4 
3.9 
93.8 
91.4 
1.7 1.3 0.4 
Coordination attachment 
97.7 
240 
16.2 
5.8 
93.5 
91.1 
1.3 0.9 0.4 
Clause attachment 
96.7 
166 
13.0 
5.6 
93.4 
91.2 
1.2 0.6 0.6 
Root attachment 
99.1 
57 
4.3 
9.9 
92.4 
89.9 
0.5 0.2 0.3 
Punctuation attachment 
93.2 
430 
13.0 
7.3 
94.5 
92.1 
1.6 0.2 1.5 
Other attachment 
94.3 
187 
6.3 
5.5 
94.2 
92.7 
1.3 0.7 0.6 
All attachments 
98.5 2760 
8.8 
5.8 100.0 100.0 
8.0 8.0 0.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Tables 3 and 4 summarise our results on MST- parser and ZPar, calculated over the sentences covered by ZPar in WSJ 22. Results over the full WSJ 22 for MSTparser were consistent with these figures. We focus on discussing UAS results in this paper, since LAS results are consistent.</figDesc><table>The coverage, effective constraints and percentage, error displacement, UAS, LAS, ∆UAS over 
the baseline, and the constrained and cascaded ∆ for ZPar over WSJ 22. 

two new errors, with the parser incorrectly attach-
ing the clausal complement headed by expected 
and the modifier headed by about. In fact, cor-
recting the ccomp arc in isolation rather than the 
root arc leads to MSTparser producing the full 
correct analysis for the second half of the sentence 
(though again, it does not repair the separate noun 
phrase error). This example highlights why we 
have chosen to implement our evaluation as a set 
of constraints in the parser, rather than Kummer-
feld et al. (2012)'s post-processing approach, as 
we cannot know that the parser will react as we 
expect it to when repairing errors. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : The number of unconstrained errors repaired per error class when enforcing NP attachment and NP internal constraints for MSTparser and ZPar over WSJ 22.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> As the variant of Stanford dependencies we use are projective, we did not use non-projective decoding.</note>

			<note place="foot" n="3"> Mohit Bansal, p.c.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tailoring continuous word representations for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-14)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-14)<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="809" to="815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">CoNLLX Shared Task on Multilingual Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-06)</title>
		<meeting>the Tenth Conference on Computational Natural Language Learning (CoNLL-06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Parsing to Stanford Dependencies: Trade-offs between Speed and Accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC-10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Formalism-Independent Parser Evaluation with CCG and DepBank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL-07)</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Stanford dependencies manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Three New Probabilistic Models for Dependency Parsing: An Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Computational Linguistics (COLING96)</title>
		<meeting>the 16th International Conference on Computational Linguistics (COLING96)</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Parsing with Soft and Hard Constraints on Dependency Length</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A. Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Workshop on Parsing Technology (IWPT05)</title>
		<meeting>the Ninth International Workshop on Parsing Technology (IWPT05)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="30" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extended Constituent-to-dependency Conversion for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th</title>
		<meeting>the 16th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Nordic Conference of Computational Linguistics (NODALIDA-07)</title>
		<meeting><address><addrLine>Tartu, Estonia</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-12)</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1048" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building a Large Annotated Corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<title level="m">Analyzing and Integrating Dependency Parsers. Computational Linguistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="197" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Online Learning of Approximate Dependency Parsing Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06)</title>
		<meeting>the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL-06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dependency Hashing for n-best CCG Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL12)</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="497" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Non-Projective Dependency Parsing in Expected Linear Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-09)</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-09)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="351" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Constrained arc-eager dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="257" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Memory-Based Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL-04)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of the 2012 Shared Task on Parsing the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Notes of the First Workshop on the Syntactic Analysis of Non-Canonical Language</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>SANCL12</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A Maximum Entropy Model for Part-of-Speech Tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1996 Conference on Empirical Methods in Natural Language Processing (EMNLP96)</title>
		<meeting>the 1996 Conference on Empirical Methods in Natural Language Processing (EMNLP96)</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Vine Pruning for Efficient Multi-Pass Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-12)</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="498" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An Empirical Study of Differences between Conversion Schemes and Annotation Guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Dependency Linguistics</title>
		<meeting>the 2nd International Conference on Dependency Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="298" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">OntoNotes: A Large Training Corpus for Enhanced Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Belvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Natural Language Processing and Machine Translation: DARPA Global Autonomous Language Exploitation</title>
		<editor>Joseph Olive, Caitlin Christianson, and John McCary</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Statistical Dependency Analysis with Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop of Parsing Technologies (IWPT-03)</title>
		<meeting>the 8th International Workshop of Parsing Technologies (IWPT-03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="196" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Chart Pruning for Fast LexicalisedGrammar Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byung-Gyu</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curt</forename><surname>Van Wyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Rimell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10)</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1471" to="1479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Syntactic Processing Using the Generalized Perceptron and Beam Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
