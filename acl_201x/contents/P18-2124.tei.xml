<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Know What You Don&apos;t Know: Unanswerable Questions for SQuAD</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Know What You Don&apos;t Know: Unanswerable Questions for SQuAD</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="784" to="789"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>784</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQUADRUN, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQUADRUN, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQUADRUN is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD achieves only 66% F1 on SQUADRUN. We release SQUADRUN to the community as the successor to SQuAD.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine reading comprehension has become a central task in natural language understanding, fu- eled by the creation of many large-scale datasets ( <ref type="bibr" target="#b3">Hermann et al., 2015;</ref><ref type="bibr" target="#b4">Hewlett et al., 2016;</ref><ref type="bibr" target="#b14">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b12">Nguyen et al., 2016;</ref><ref type="bibr" target="#b17">Trischler et al., 2017;</ref><ref type="bibr" target="#b8">Joshi et al., 2017)</ref>. In turn, these datasets have spurred a diverse array of model architecture improvements ( <ref type="bibr" target="#b16">Seo et al., 2016</ref>; Hu * The first two authors contributed equally to this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article: Endangered Species Act</head><p>Paragraph: " . . . Other legislation followed, including the Migratory Bird Conservation Act of 1929, a 1937 treaty prohibiting the hunting of right and gray whales, and the Bald Eagle Protection Act of 1940. These later laws had a low cost to society-the species were rela- tively rare-and little opposition was raised."  et al., 2017; <ref type="bibr" target="#b1">Clark and Gardner, 2017;</ref><ref type="bibr" target="#b6">Huang et al., 2018)</ref>. Recent work has even produced systems that surpass human-level exact match accuracy on the Stanford Question Answering Dataset (SQuAD), one of the most widely-used reading comprehension benchmarks ( <ref type="bibr" target="#b14">Rajpurkar et al., 2016)</ref>.</p><p>Nonetheless, these systems are still far from true language understanding. Recent analysis shows that models can do well at SQuAD by learn- ing context and type-matching heuristics <ref type="bibr" target="#b20">(Weissenborn et al., 2017)</ref>, and that success on SQuAD does not ensure robustness to distracting sen- tences ( <ref type="bibr" target="#b7">Jia and Liang, 2017)</ref>. One root cause of these problems is SQuAD's focus on questions for which a correct answer is guaranteed to exist in the context document. Therefore, models only need to select the span that seems most related to the ques- tion, instead of checking that the answer is actually entailed by the text.</p><p>In this work, we construct SQUADRUN, 1 a new dataset that combines the existing questions in SQuAD with 53,775 new, unanswerable ques-tions about the same paragraphs. Crowdworkers crafted these questions so that (1) they are relevant to the paragraph, and (2) the paragraph contains a plausible answer-something of the same type as what the question asks for. Two such examples are shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We confirm that SQUADRUN is both challeng- ing and high-quality. A state-of-the-art model achieves only 66.3% F1 score when trained and tested on SQUADRUN, whereas human accuracy is 89.5% F1, a full 23.2 points higher. The same model architecture trained on SQuAD gets 85.8% F1, only 5.4 points worse than humans. We also show that our unanswerable questions are more challenging than ones created automatically, either via distant supervision <ref type="bibr" target="#b1">(Clark and Gardner, 2017)</ref> or a rule-based method <ref type="bibr" target="#b7">(Jia and Liang, 2017)</ref>. We release SQUADRUN to the public as the succes- sor to SQuAD, and designate it SQuAD 2.0 on the official SQuAD leaderboard. <ref type="bibr">2</ref> We are optimistc that this new dataset will encourage the develop- ment of reading comprehension systems that know what they don't know.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Desiderata</head><p>We first outline our goals for SQUADRUN. Be- sides the generic goals of large size, diversity, and low noise, we posit two desiderata specific to unanswerable questions:</p><p>Relevance. The unanswerable questions should appear relevant to the topic of the context para- graph. Otherwise, simple heuristics (e.g., based on word overlap) could distinguish answerable and unanswerable questions <ref type="bibr" target="#b22">(Yih et al., 2013</ref>).</p><p>Existence of plausible answers. There should be some span in the context whose type matches the type of answer the question asks for. For ex- ample, if the question asks, "What company was founded in 1992?", then some company should be mentioned in the context. Otherwise, type- matching heuristics could distinguish answerable and unanswerable questions (Weissenborn et al., 2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Existing datasets</head><p>Next, we survey existing reading comprehension datasets with these criteria in mind. We use the term "negative example" to refer to a context pas- sage paired with an unanswerable question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extractive datasets</head><p>In extractive reading comprehension datasets, a system must extract the correct answer to a ques- tion from a context document or paragraph. The Zero-shot Relation Extraction dataset ( <ref type="bibr" target="#b10">Levy et al., 2017)</ref> contains negative examples generated with distant supervision. <ref type="bibr" target="#b10">Levy et al. (2017)</ref> found that 65% of these negative examples do not have a plausible answer, making them easy to identify.</p><p>Other distant supervision strategies can also create negative examples. TriviaQA ( <ref type="bibr" target="#b8">Joshi et al., 2017</ref>) retrieves context documents from the web or Wikipedia for each question. Some documents do not contain the correct answer, yielding negative examples; however, these are excluded from the final dataset. <ref type="bibr" target="#b1">Clark and Gardner (2017)</ref> generate negative examples for SQuAD by pairing existing questions with other paragraphs from the same ar- ticle based on TF-IDF overlap; we refer to these as TFIDF examples. In general, distant supervision does not ensure the existence of a plausible answer in the retrieved context, and might also add noise, as the context might contain a paraphrase of the correct answer. Moreover, when retrieving from a small set of possible contexts, as in Clark and Gardner (2017), we find that the retrieved para- graphs are often not very relevant to the question, making these negative examples easy to identify.</p><p>The NewsQA data collection process also yields unanswerable questions, because crowdworkers write questions given only a summary of an article, not the full text ( <ref type="bibr" target="#b17">Trischler et al., 2017)</ref>. Only 9.5% of their questions are unanswerable, making this strategy hard to scale. Of this fraction, we found that some are misannotated as unanswerable, and others are out-of-scope (e.g., summarization ques- tions). <ref type="bibr" target="#b17">Trischler et al. (2017)</ref> also exclude negative examples from their final dataset.</p><p>Jia and Liang (2017) propose a rule-based pro- cedure for editing SQuAD questions to make them unanswerable. Their questions are not very di- verse: they only replace entities and numbers with similar words, and replace nouns and adjectives with WordNet antonyms. We refer to these unan- swerable questions as RULEBASED questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Answer sentence selection datasets</head><p>Sentence selection datasets test whether a system can rank sentences that answer a question higher</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reasoning</head><p>Description Example Percentage Negation Negation word inserted or removed.</p><p>Sentence: "Several hospital pharmacies have decided to outsource high risk preparations . . . " Question: "What types of pharmacy functions have never been outsourced?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9%</head><p>Antonym Antonym used.</p><p>S: "the extinction of the dinosaurs. . . allowed the tropical rainforest to spread out across the continent." Q: "The extinction of what led to the decline of rainforests?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20%</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Swap</head><p>Entity, number, or date replaced with other entity, number, or date.</p><p>S: "These values are much greater than the 9-88 cm as projected . . . in its Third Assessment Report." Q: "What was the projection of sea level increases in the fourth assessment report?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>21%</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mutual Exclusion</head><p>Word or phrase is mutually exclusive with something for which an answer is present.</p><p>S: "BSkyB. . . waiv[ed] the charge for subscribers whose package included two or more premium channels." Q: "What service did BSkyB give away for free unconditionally?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15%</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impossible Condition</head><p>Asks for condition that is not satisfied by anything in the paragraph.</p><p>S: "Union forces left Jacksonville and confronted a Confederate Army at the Battle of Olustee. . . Union forces then retreated to Jacksonville and held the city for the remainder of the war." Q: "After what battle did Union forces leave Jacksonville for good?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4%</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other Neutral</head><p>Other cases where the paragraph does not imply any answer.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiple choice datasets</head><p>Finally, some datasets, like MCTest (Richard- son et al., 2013) and RACE ( <ref type="bibr" target="#b9">Lai et al., 2017)</ref>, pose multiple choice questions, which can have a "none of the above" option. In practice, mul- tiple choice options are often unavailable, making these datasets less suited for training user-facing systems. Multiple choice questions also tend to be quite different from extractive ones, with more emphasis on fill-in-the-blank, interpretation, and summarization ( <ref type="bibr" target="#b9">Lai et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The SQUADRUN dataset</head><p>We now describe our new dataset, which we con- structed to satisfy both the relevance and plausible answer desiderata from Section 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset creation</head><p>We employed crowdworkers on the Daemo crowd- sourcing platform ( <ref type="bibr" target="#b2">Gaikwad et al., 2015</ref>) to write unanswerable questions. Each task consisted of an entire article from the original SQuAD dataset. For each paragraph in the article, workers were asked to pose up to five questions that were im- possible to answer based on the paragraph alone, while referencing entities in the paragraph and en- suring that a plausible answer is present. As in- spiration, we also showed questions from SQuAD for each paragraph; this further encouraged unan- swerable questions to look similar to answerable ones. Workers were asked to spend 7 minutes per paragraph, and were paid $10.50 per hour. Screen- shots of our interface are shown in Appendix A.1. We removed questions from workers who wrote 25 or fewer questions on that article; this filter helped remove noise from workers who had trou- ble understanding the task, and therefore quit be- fore completing the whole article. We applied this filter to both our new data and the existing answer- able questions in SQuAD. To generate train, de- velopment, and test splits, we used the same parti- tion of articles as SQuAD, and combined the exist- ing SQuAD data with our new data for each split. For the SQUADRUN development and test sets, we removed articles for which we did not col- <ref type="table" target="#tab_0">Train  Total examples  87,599  130,319  Negative examples  0  43,498  Total articles  442  442  Articles with negatives  0  285  Development  Total examples  10,</ref>  lect unanswerable questions. This resulted in a roughly one-to-one ratio of answerable to unan- swerable questions in these splits, whereas the train data has roughly twice as many answerable questions as unanswerable ones. <ref type="table" target="#tab_2">Table 2</ref> summa- rizes overall statistics of SQUADRUN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SQuAD SQUADRUN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human accuracy</head><p>To confirm that our dataset is clean, we hired addi- tional crowdworkers to answer all questions in the SQUADRUN development and test sets. In each task, we showed workers an entire article from the dataset. For each paragraph, we showed all as- sociated questions; unanswerable and answerable questions were shuffled together. For each ques- tion, workers were told to either highlight the an- swer in the paragraph, or mark it as unanswer- able. Workers were told to expect every paragraph to have some answerable and some unanswerable questions. They were asked to spend one minute per question, and were paid $10.50 per hour.</p><p>To reduce crowdworker noise, we collected multiple human answers for each question and se- lected the final answer by majority vote, breaking ties in favor of answering questions and preferring shorter answers to longer ones. On average, we collected 4.8 answers per question. We note that for the original SQuAD, <ref type="bibr" target="#b14">Rajpurkar et al. (2016)</ref> evaluated a single human's performance; there- fore, they likely underestimate human accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>We manually inspected 100 randomly chosen neg- ative examples from our development set to under- stand the challenges these examples present. In <ref type="table" target="#tab_0">Table 1</ref>, we define different categories of nega- tive examples, and give examples and their fre- quency in SQUADRUN. We observe a wide range of phenomena, extending beyond expected phenomena like negation, antonymy, and entity changes. In particular, SQUADRUN is much more diverse than RULEBASED, which creates unanswerable questions by applying entity, num- ber, and antonym swaps to existing SQuAD ques- tions. We also found that 93% of the sampled neg- ative examples are indeed unanswerable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Models</head><p>We evaluated three existing model architectures: the BiDAF-No-Answer (BNA) model proposed by <ref type="bibr" target="#b10">Levy et al. (2017)</ref>, and two versions of the Docu- mentQA No-Answer (DocQA) model from <ref type="bibr" target="#b1">Clark and Gardner (2017)</ref>, namely versions with and without <ref type="bibr">ELMo (Peters et al., 2018</ref>). These mod- els all learn to predict the probability that a ques- tion is unanswerable, in addition to a distribution over answer choices. At test time, models abstain whenever their predicted probability that a ques- tion is unanswerable exceeds some threshold. We tune this threshold separately for each model on the development set. When evaluating on the test set, we use the threshold that maximizes F1 score on the development set. We find this strategy does slightly better than simply taking the argmax pre- diction, possibly due to the different proportions of negative examples at training and test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main results</head><p>First, we trained and tested all three models on SQUADRUN, as shown in <ref type="table" target="#tab_4">Table 3</ref>. Following <ref type="bibr" target="#b14">Rajpurkar et al. (2016)</ref>, we report average exact match and F1 scores. <ref type="bibr">3</ref> The best model, DocQA + ELMo, achieves only 66.3 F1 on the test set, 23.2 points lower than the human accuracy of 89.5 F1. Note that a baseline that always abstains gets 48.9 test F1; existing models are closer to this base- line than they are to human performance. There- fore, we see significant room for model improve- ment on this task. We also compare with reported test numbers for analogous model architectures on SQuAD. There is a much larger gap between hu- mans and machines on SQUADRUN compared to SQuAD, which confirms that SQUADRUN is a much harder dataset for existing models.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Automatically generated negatives</head><p>Next, we investigated whether automatic ways of generating negative examples can also yield a challenging dataset. We trained and tested all three model architectures on SQuAD augmented with either TFIDF or RULEBASED examples. To ensure a fair comparison with SQUADRUN, we generated training data by applying TFIDF or RULEBASED only to the 285 articles for which SQUADRUN has unanswerable questions. We tested on the articles and answerable questions in the SQUADRUN development set, adding unan- swerable questions in a roughly one-to-one ratio with answerable ones. These results are shown in <ref type="table" target="#tab_5">Table 4</ref>. The highest score on SQUADRUN is 15.4 F1 points lower than the highest score on either of the other two datasets, suggesting that au- tomatically generated negative examples are much easier for existing models to detect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Plausible answers as distractors</head><p>Finally, we measured how often systems were fooled into answering the plausible but incorrect answers provided by crowdworkers for our unan- swerable questions. For both computer systems and humans, roughly half of all wrong answers on unanswerable questions exactly matched the plau- sible answers. This suggests that the plausible an- swers do indeed serve as effective distractors. Full results are shown in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>SQUADRUN forces models to understand whether a paragraph entails that a certain span is the answer to a question. Similarly, recognizing textual entailment (RTE) requires systems to decide whether a hypothesis is entailed by, con- tradicted by, or neutral with respect to a premise ( <ref type="bibr" target="#b11">Marelli et al., 2014;</ref><ref type="bibr" target="#b0">Bowman et al., 2015)</ref>. Relation extraction systems must understand when a possible relationship between two entities is not entailed by the text ( <ref type="bibr" target="#b23">Zhang et al., 2017)</ref>. Jia and Liang (2017) created adversarial exam- ples that fool pre-trained SQuAD models at test time. However, models that train on similar exam- ples are not easily fooled by their method. In con- trast, the adversarial examples in SQUADRUN are difficult even for models trained on examples from the same distribution.</p><p>In conclusion, we have presented SQUADRUN, a challenging, diverse, and large-scale dataset that forces models to under- stand when a question cannot be answered given the context. We are optimistic that SQUADRUN will encourage the development of new reading comprehension models that know what they don't know, and therefore understand language at a deeper level.</p><p>Reproducibility. All code, data, experiments are available on the Codalab platform at https: //bit.ly/2rDHBgY.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Question 1 :</head><label>1</label><figDesc>"Which laws faced significant opposition?" Plausible Answer: later laws Question 2: "What was the name of the 1937 treaty?" Plausible Answer: Bald Eagle Protection Act</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two unanswerable questions written by crowdworkers, along with plausible (but incorrect) answers. Relevant keywords are shown in blue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>S</head><label></label><figDesc>: "Schuenemann et al. concluded in 2011 that the Black Death. . . was caused by a variant of Y. pestis. . . " Q: "Who discovered Y. pestis?" 24% Answerable Question is answerable (i.e. dataset noise). 7%</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Types of negative examples in SQUADRUN exhibiting a wide range of phenomena. 

than sentences that do not. Wang et al. (2007) 
constructed the QASENT dataset from questions 
in the TREC 8-13 QA tracks. Yih et al. (2013) 
showed that lexical baselines are highly competi-
tive on this dataset. WikiQA (Yang et al., 2015) 
pairs questions from Bing query logs with sen-
tences from Wikipedia. Like TFIDF examples, 
these sentences are not guaranteed to have plausi-
ble answers or high relevance to the question. The 
dataset is also limited in scale (3,047 questions, 
1,473 answers). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Dataset statistics of SQUADRUN, compared 
to the original SQuAD dataset. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Exact Match (EM) and F1 scores on SQUADRUN and SQuAD. The gap between humans and the best 
tested model is much larger on SQUADRUN, suggesting there is a great deal of room for model improvement. 

System 
SQuAD + TFIDF SQuAD + RULEBASED SQUADRUN dev 
EM 
F1 
EM 
F1 
EM 
F1 
BNA 
72.7 
76.6 
80.1 
84.8 
59.8 
62.6 
DocQA 
75.6 
79.2 
80.8 
84.8 
61.9 
64.8 
DocQA + ELMo 79.4 
83.0 
85.7 
89.6 
65.1 
67.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Exact Match (EM) and F1 scores on the SQUADRUN development set, compared with SQuAD with 
two types of automatically generated negative examples. SQUADRUN is more challenging for current models. 

</table></figure>

			<note place="foot" n="1"> SQuAD with adveRsarial Unanswerable questions</note>

			<note place="foot" n="2"> As with previous versions of SQuAD, we release SQUADRUN under the CC BY-SA 4.0 license.</note>

			<note place="foot" n="3"> For negative examples, abstaining receives a score of 1, and any other response gets 0, for both exact match and F1.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Daemo: A self-governed crowdsourcing marketplace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Gaikwad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Morina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nistala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cossette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Narwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rajpal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Regino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th Annual ACM Symposium on User Interface Software &amp; Technology</title>
		<meeting>the 28th Annual ACM Symposium on User Interface Software &amp; Technology</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="101" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Wikireading: A novel large-scale language understanding task over Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fandrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Reinforced mnemonic reader for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fusionnet: Fusing via fully-aware attention with application to machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Race: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04683</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A SICK cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation Conference (LREC)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MS MARCO: A human generated machine reading comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Cognitive Computing at NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Representation Learning for NLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasi-synchronous grammar for QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Making neural QA as simple as possible but not simpler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Question answering using enhanced lexical semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pastusiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Position-aware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
