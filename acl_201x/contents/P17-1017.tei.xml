<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:38+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Creating Training Corpora for NLG Micro-Planners</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
						</author>
						<title level="a" type="main">Creating Training Corpora for NLG Micro-Planners</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="179" to="188"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1017</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we present a novel framework for semi-automatically creating linguistically challenging micro-planning data-to-text corpora from existing Knowledge Bases. Because our method pairs data of varying size and shape with texts ranging from simple clauses to short texts, a dataset created using this framework provides a challenging benchmark for microplanning. Another feature of this framework is that it can be applied to any large scale knowledge base and can therefore be used to train and learn KB verbalisers. We apply our framework to DBpedia data and compare the resulting dataset with Wen et al. (2016)&apos;s. We show that while Wen et al.&apos;s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of handling the complex interactions occurring during in micro-planning between lexicalisation, aggregation, surface reali-sation, referring expression generation and sentence segmentation. To encourage researchers to take up this challenge, we recently made available a dataset created using this framework in the context of the WEBNLG shared task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>To train Natural Language Generation (NLG) sys- tems, various input-text corpora have been devel- oped which associate (numerical, formal, linguis- tic) input with text. As discussed in detail in Sec- tion 2, these corpora can be classified into three main types namely, (i) domain specific corpora, (ii) benchmarks constructed from "Expert" Lin- guistic Annotations and (iii) crowdsourced bench- marks. <ref type="bibr">1</ref> In this paper, we focus on how to create data- to-text corpora which can support the learning of micro-planners i.e., data-to-text generation sys- tems that can handle the complex interactions occurring between lexicalisation (mapping data to words), aggregation (exploiting linguistic con- structs such as ellipsis and coordination to avoid repetition), surface realisation (using the appropri- ate syntactic constructs to build sentences), sen- tence segmentation and referring expression gen- eration.</p><p>We start by reviewing the main existing types of NLG benchmarks and we argue for a crowdsourc- ing approach in which (i) data units are automati- cally built from an existing Knowledge Base (KB) and (ii) text is crowdsourced from the data (Sec- tion 2). We then propose a generic framework for semi-automatically creating training corpora for NLG (Section 3) from existing knowledge bases. In Section 4, we apply this framework to DBpedia data and we compare the resulting dataset with the dataset of <ref type="bibr" target="#b16">Wen et al. (2016)</ref> using various metrics to evaluate the linguistic and computational ade- quacy of both datasets. By applying these metrics, we show that while Wen et al.'s dataset is more than twice larger than ours, it is less diverse both in terms of input and in terms of text. We also com-pare the performance of a sequence-to-sequence model ( <ref type="bibr" target="#b15">Vinyals et al., 2015)</ref> on both datasets to es- timate the complexity of the learning task induced by each dataset. We show that the performance of this neural model is much lower on the new data set than on the existing ones. We thus propose our corpus generation framework as a novel method for creating challenging data sets from which NLG models can be learned which are capable of gen- erating complex texts from KB data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">NLG Benchmarks</head><p>Domain specific benchmarks. Several domain specific data-text corpora have been built by re- searchers to train and evaluate NLG systems. In the sports domain, <ref type="bibr" target="#b3">Chen and Mooney (2008)</ref> con- structed a dataset mapping soccer games events to text which consists of 1,539 data-text pairs and a vocabulary of 214 words. For weather forecast generation, the dataset of <ref type="bibr" target="#b6">Liang et al. (2009)</ref> in- cludes 29,528 data-text pairs with a vocabulary of 345 words. For the air travel domain, Ratnaparkhi (2000) created a dataset consisting of 5,426 data- text pairs with a richer vocabulary (927 words) and in the biology domain, the KBGen shared task ( <ref type="bibr" target="#b1">Banik et al., 2013</ref>) made available 284 data-text pairs where the data was extracted from an exist- ing knowledge base and the text was authored by biology experts.</p><p>An important limitation of these datasets is that, because they are domain specific, systems learned from them are restricted to generating domain spe- cific, often strongly stereotyped text (e.g., weather forecast or soccer game commentator reports). Ar- guably, training corpora for NLG should support the learning of more generic systems capable of handling a much wider range of linguistic interac- tions than is present in stereotyped texts. By na- ture however, domain specific corpora restrict the lexical and often the syntactic coverage of the texts to be produced and thereby indirectly limit the ex- pressivity of the generators trained on them.</p><p>Benchmarks constructed from "expert" lin- guistic annotations. NLG benchmarks have also been proposed where the input data is either derived from dependency parse trees (SR'11 task, <ref type="bibr" target="#b2">Belz et al. 2011</ref>) or constructed through manual annotation (AMR Corpus, <ref type="bibr" target="#b0">Banarescu et al. 2012</ref>). Contrary to the domain-specific data sets just men- tioned, these corpora have a wider coverage and are large enough for training systems that can gen- erate linguistically sophisticated text.</p><p>One main drawback of these benchmarks how- ever is that their construction required massive manual annotation of text with complex linguis- tic structures (parse trees for the SR task and Ab- stract Meaning Representation for the AMR cor- pus). Moreover because these structures are com- plex, the annotation must be done by experts. It cannot be delegated to the crowd. In short, the creation of such benchmark is costly both in terms of time and in terms of expertise.</p><p>Another drawback is that, because the input rep- resentation derived from a text is relatively close to its surface form 2 , the NLG task is mostly re- stricted to surface realisation (mapping input to sentences). That is, these benchmarks give very limited support for learning models that can han- dle the interactions between micro-planning sub- tasks.</p><p>Crowdsourced benchmarks. More recently, data-to-text benchmarks have also been created by associating data units with text using crowdsourc- ing. <ref type="bibr" target="#b16">Wen et al. (2016)</ref> first created data by enumer- ating all possible combinations of 14 dialog act types (e.g., request, inform) and attribute-value pairs present in four small-size, hand-written on- tologies about TVs, laptops, restaurants and ho- tels. They then use crowdsourcing to associate each data unit with a text. The resulting dataset is both large and varied (4 domains) and was successfully exploited to train neural and imita- tion learning data-to-text generator <ref type="bibr" target="#b16">(Wen et al., 2016;</ref><ref type="bibr" target="#b4">Lampouras and Vlachos, 2016)</ref>. Similarly, Novikova and Rieser (2016) described a frame- work for collecting data-text pairs using automatic quality control measures and evaluating how the type of the input representations (text vs pictures) impacts the quality of crowdsourced text.</p><p>The crowdsourcing approach to creating input- text corpora has several advantages.</p><p>First, it is low cost in that the data is produced automatically and the text is authored by a crowd- worker. This is in stark contrast with the previ- ous approach where expert linguists are required to align text with data.</p><p>Second, because the text is crowd-sourced from the data (rather than the other way round), there is an adequate match between text and data both se- mantically (the text expresses the information con- tained in the data) and computationally (the data is sufficiently different from the text to require the learning of complex generation operations such as sentence segmentation, aggregation and referring expression generation).</p><p>Third, by exploiting small hand-written ontolo- gies to quickly construct meaningful artificial data, the crowdsourcing approach allows for the easy creation of a large dataset with data units of var- ious size and bearing on different domains. This, in turn, allows for better linguistic coverage and for NLG tasks of various complexity since typi- cally, inputs of larger size increases the need for complex microplanning operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The WebNLG Framework for</head><p>Creating Data-to-Text, Micro-Planning Benchmarks</p><p>While as just noted, the crowdsourcing approach presented by <ref type="bibr" target="#b16">Wen et al. (2016)</ref> has several advan- tages, it also has a number of shortcomings. One important drawback is that it builds on arti- ficial rather than "real" data i.e., data that would be extracted from an existing knowledge base. As a result, the training corpora built using this method cannot be used to train KB verbalisers i.e., gener- ation systems that can verbalise KB fragments.</p><p>Another limitation concerns the shape of the in- put data. Wen et al.'s data can be viewed as trees of depth one (a set of attributes-value pairs describing a single entity e.g., a restaurant or a laptop). As illustrated in <ref type="figure" target="#fig_2">Figure 1</ref> however, there is a strong correlation between the shape of the input and the syntactic structure of the corresponding sentence. The path structure T 1 where B is shared by two predicates (mission and operator) will favour the use of a participial or a passive subject relative clause. In contrast, the branching structure T 2 will favour the use of a new clause with a pronomi- nal subject or a coordinated VP. More generally, allowing for trees of deeper depth is necessary to indirectly promote the introduction in the bench- mark of a more varied set of syntactic constructs to be learned by generators.</p><p>To address these issues, we introduce a novel method for creating data-to-text corpora from large knowledge bases such as DBPedia. Our </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1.1 A participated in mission B operated by C. S1.2</head><p>A participated in mission B which was operated by C.  method combines (i) a content selection module designed to extract varied, relevant and coherent data units from DBPedia with (ii) a crowdsourc- ing process for associating data units with human authored texts that correctly capture their mean- ing. Example 1 shows a data/text unit created by our method using DBPedia as input KB. Our method has the following features. First, it can be used to create a data-to-text cor- pus from any knowledge base where entities are categorised and there is a large number of entities belonging to the same category. As noted above, this means that the resulting corpus can be used to train KB verbalisers i.e., generators that are able to verbalise fragments of existing knowledge bases. It could be used for instance, to verbalise frag- ments of e.g., MusicBrainz 3 , FOAF 4 or Linked- GeoData. <ref type="bibr">5</ref> Second, as crowdworkers are required to enter text that matches the data and a majority vote val- idation process is used to eliminate mis-matched pairs, there is a direct match between text and data. This allows for a clear focus on the non con- tent selection part of generation known as micro- planning.</p><p>Third, because data of increasing size is matched with texts ranging from simple clauses to short texts consisting of several sentences, the re- sulting benchmark is appropriate for exercising the main subtasks of microplanning. For instance, in Example (1) above, given the input shown in (1a), generating (1b) involves lexicalising the occupa- tion property as the phrase worked as (lexicalisa- tion); using PP coordination (born in San Antonio on 1942-08-26) to avoid repeating the word born (aggregation); and verbalising the three triples us- ing a single complex sentence including an appo- sition, a PP coordination and a transitive verb con- struction (sentence segmentation and surface real- isation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DBPedia</head><p>To illustrate the functioning of our benchmark cre- ation framework, we apply it to DBPedia. DBPe- dia is a multilingual knowledge base that was built from various kinds of structured information con- tained in Wikipedia ( <ref type="bibr" target="#b9">Mendes et al., 2012)</ref>. This data is stored as RDF (Resource Description For- mat) triples of the form (subject, property, object) where the subject is a URI (Uniform Resource Identifier), the property is a binary relation and the object is either a URI or a literal value such as a string, a date or a number. We use an English version of the DBPedia knowledge base which en- compasses 6.2M entities, 739 classes, 1,099 prop- erties with reference values and 1,596 properties with typed literal values. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Selecting Content</head><p>To create data units, we adapted the procedure outlined by <ref type="bibr">Perez-Beltrachini et al. (2016)</ref> and sketched in <ref type="figure" target="#fig_4">Figure 2</ref>. This method can be sum- marised as follows.</p><p>First, DBPedia category graphs are extracted from DBPedia by retrieving up to 500 entity graphs for entities of the same category. <ref type="bibr">7</ref> For ex- ample, we build a category graph for the Astronaut category by collecting, graphs of depth five for 500 entities of types astronaut.</p><p>Next, category graphs are used to learn bi-gram models of DBPedia properties which specify the probability of two properties co-occuring together. Three types of bi-gram models are extracted from category graphs using the SRILM toolkit <ref type="bibr" target="#b14">(Stolcke, 2002)</ref>: one model (S-Model) for bigrams occur- ring in sibling triples (triples with a shared sub- ject); one model (C-Model) for bigrams occurring in chained triples (the object of one triple is the subject of the other); and one model (M-Model) which is a linear interpolation of the sibling and the chain model. The intuition is that these sib-ling and chain models capture different types of coherence, namely, topic-based coherence for the S-Model and discourse-based coherence for the C- Model.</p><p>Finally, the content selection task is formulated as an Integer Linear Programming (ILP) problem to select, for a given entity of category C and its entity graph G e , subtrees of G e with maximal bi- gram probability and varying size (between 1 and 7 RDF triples). We applied this content selection procedure to the DBPedia categories Astronaut (A), Building (B), Monument (M), University (U), Sports team (S) and Written work (W), using the three bi-gram models (S-Model, C-Model, M-Model) and mak- ing the number of triples required by the ILP con- straint to occur in the output solutions vary be- tween 1 and 7. The results are shown in <ref type="table">Table 1</ref>. An input is a set of triples produced by the content selection module. The number of input (#Inputs) is thus the number of distinct sets of triples pro- duced by this module. In contrast, input patterns are inputs where subject and object have been ab- stracted over. That is, the number of input patterns (#I. Patterns) is the number of distinct sets of prop- erties present in the set of inputs. The number of properties (#Properties) is the number of distinct RDF properties occurring in the dataset. Similarly, the number of entities (#Entities) is the number of distinct RDF subjects and objects occurring in each given dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Associating Content with Text</head><p>We associate data with text using the Crowdflower platform. <ref type="bibr">8</ref> We do this in four main steps as fol- lows.</p><p>1. Clarifying properties. One difficulty when collecting texts verbalising sets of DBPedia triples is that the meaning of DBPedia properties may be unclear. We therefore first manually clarified 8 http://www.crowdflower.com for each category being worked on, those prop- erties which have no obvious lexicalisations (e.g., crew1up was replaced by commander).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Getting verbalisations for single triples.</head><p>Next, we collected three verbalisations for data units of size one, i.e. single triples consisting of a subject, a property and an object. For each such input, crowdworkers were asked to produce a sentence verbalising its content. We used both a priori automatic checks to prevent spamming and a posteriori manual checks to remove incor- rect verbalisations. We also monitored crowd- workers as they entered their input and banned those who tried to circumvent our instructions and validators. The automatic checks comprise 12 custom javascript validators implemented in the CrowdFlower platform to block contributor an- swers which fail to meet requirements such as the minimal time a contributor should stay on page, the minimal length of the text produced, the min- imal match of tokens between a triple and its ver- balisation and various format restrictions used to detect invalid input. The exact match between a triple and its verbalisation was also prohibited. In addition, after data collection was completed, we manually checked each data-text pair and elimi- nated from the data set any pair where the text ei- ther did not match the information conveyed by the triple or was not a well-formed English sentence.</p><p>3. Getting verbalisations for input containing more than one triple. The verbalisations col- lected for single triples were used to construct in- put with bigger size. Thus, for input with a number of triples more than one, the crowd was asked to merge the sentences corresponding to each triple (obtained in step 2) into a natural sounding text. In such a way, we diminish the risk of having misinterpretations of the original semantics of a data unit. Contributors were also encouraged to change the order, and the wording of sentences, while writing their texts. For each data unit, we collected three verbalisations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Verifying the quality of the collected texts.</head><p>The verbalisations obtained in Step 3 were veri- fied through crowdsourcing. Each verbalisation collected in Step 3 was displayed to CrowdFlower contributors together with the corresponding set of triples. Then the crowd was asked to assess its fluency, semantic adequacy, and grammaticality. Those criteria were checked by asking the follow-  We collected five answers per verbalisation. A verbalisation was considered bad, if it received three negative answers in at least one criterion. Af- ter the verification step, the total corpus loss was of 8.7%. An example of rejected verbalisation can be found in Example (2). The verbalisation was dropped due to the lack of fluency (awkward lexi- calisation of the property club).  <ref type="table" target="#tab_2">Table 2</ref> shows some statistics about the texts obtained using our crowdsourcing procedure for triple sets of size one to seven.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparing Benchmarks</head><p>We now compare a dataset created using our dataset creation framework (henceforth WEBNLG) with the dataset of <ref type="bibr" target="#b16">Wen et al. (2016)</ref>  As should be clear from the discussion in Sec- tion 2 and 3, both datasets are similar in that, in both cases, data is built from ontological infor- mation and text is crowdsourced from the data. An important difference between the two datasets is that, while the RNNLG data was constructed by enumerating possible combinations of dialog act types and attribute-value pairs, the WEBNLG data is created using a sophisticated content se- lection procedure geared at producing sets of data <ref type="bibr">9</ref> https://github.com/shawnwun/RNNLG units that are relevant for a given ontological cat- egory and that are varied in terms of size, shape and content. We now investigate the impact of this difference on the two datasets (WEBNLG and RNNLG). To assess the degree to which both datasets support the generation of linguistically varied text requiring complex micro-planning op- erations, we examine a number of data and text related metrics. We also compare the results of an out-of-the-box sequence-to-sequence model as a way to estimate the complexity of the learning task induced by each dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Comparison</head><p>Terminology. The attributes in the RNNLG dataset can be viewed as binary relations between the object talked about (a restaurant, a laptop, a TV or a hotel) and a value. Similarly, in the WEBNLGdataset, DBpedia RDF properties relate a subject entity to an object which can be either an entity or a datatype value. In what follows, we refer to both as attributes. <ref type="table" target="#tab_6">Table 3</ref> shows several statistics which indicate that, while the RNNLG dataset is larger than WEBNLG, WEBNLG is much more diverse in terms of attributes, input patterns and input shapes.</p><p>Number of attributes. As illustrated in Exam- ple (4) below, different attributes can be lexi- calised using different parts of speech. A dataset with a larger number of attributes is therefore more likely to induce texts with greater syntactic variety.</p><p>(4) Verb: X title Y / X served as Y As shown in <ref type="table" target="#tab_6">Table 3</ref>, WEBNLG has a more diverse attribute set than RNNLG both in abso- lute (172 attributes in WEBNLG against 108 in RNNLG) and in relative terms (RNNLG is a lit- tle more than twice as large as WEBNLG).</p><p>Number of input patterns. Since attributes may give rise to lexicalisation with different parts of speech, the sets of attributes present in an input (input pattern) <ref type="bibr">10</ref> indirectly determine the syntac- tic realisation of the corresponding text. Hence a higher number of input patterns will favour a higher number of syntactic realisations. This is ex- emplified in Example (5) where two inputs with the same number of attributes give rise to texts with different syntactic forms. While in Exam- ple (5a), the attribute set {country, location, start- Date} is realised by a passive (is located), an ap- position (Australia) and a deverbal nominal (its construction), in Example (5b), the attribute set {almaMater, birthPlace, selection} induced a pas- sive (was born) and two VP coordinations (gradu- ated and joined). Again, despite the much larger size of the RNNLG dataset, the number of input patterns in both datasets is almost the same. That is, the relative variety in input patterns is higher in WEBNLG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of input / Number of input patterns.</head><p>The ratio between number of inputs and the num- ber of input patterns has an important impact both in terms of linguistic diversity and in terms of learning complexity. A large ratio indicates a "repetitive dataset" where the same pattern is in- stantiated a high number of times. While this <ref type="bibr">10</ref> Recall from section 3 that input patterns are inputs where subjects and objects have been remove thus, in essence, an input pattern is the set of all the attributes occurring in a given input. facilitates learning, this also reduces linguistic coverage (less combinations of structures can be learned) and may induce over-fitting. Note that because datasets are typically delexicalised when training NLG models (cf. e.g., <ref type="bibr" target="#b17">Wen et al. 2015</ref> and Lampouras and Vlachos 2016), at training time, different instantiations of the same input pattern reduce to identical input.</p><p>The two datasets markedly differ on this ratio which is five times lower in WEBNLG. While in WEBNLG, the same pattern is instantiated in average 2.40 times, it is instantiated 10.31 times in average in RNNLG. From a learning perspec- tive, this means that the RNNLG dataset facili- tates learning but also makes it harder to assess how well systems trained on it can generalise to handle unseen input.</p><p>Input shape. As mentioned in Section 3, in the RNNLG dataset, all inputs can be viewed as trees of depth one while in the WEBNLG dataset, input may have various shapes. As a result, RNNLG texts will be restricted to syntactic forms which permit expressing such multiple predications of the same entity e.g., subject relative clause, VP and sentence coordination etc. In contrast, the trees extracted by the WEBNLG content selection procedure may be of depth five and therefore allow for further syntactic constructs such as object rel- ative clause and passive participles (cf. <ref type="figure" target="#fig_2">Figure 1)</ref>.</p><p>We can show this empirically as well that WEBNLG is far more diverse than RNNLG in terms of input shapes. The RNNLG dataset has only 6 distinct shapes and all of them are of depth 1, i.e., all (attribute, value) pairs in an input are siblings to each other. In contrast, the WEBNLG dataset has 58 distinct shapes, out of which only 7 shapes are with depth 1, all others have depth more than 1 and they cover 49.6% of all inputs. <ref type="table" target="#tab_8">Table 4</ref> gives some statistics about the texts con- tained in each dataset.  As illustrated by the contrast between Exam- ples (6) and <ref type="formula" target="#formula_0">(7)</ref> above, text length (number of to- kens per text) and the number of sentences per text are strong indicators of the complexity of the gen- eration task. We use the Stanford Part-Of-Speech Tagger and Parser version 3.5. <ref type="bibr">2 (dated 2015</ref><ref type="bibr">2 (dated -0420, Manning et al. 2014</ref>) to tokenize and to per- form sentence segmentation on text. As shown in <ref type="table" target="#tab_8">Table 4</ref>, WEBNLG's texts are longer both in terms of tokens and in terms of number of sentences per text. Another difference between the two datasets is that WEBNLG contains a higher number of text per input thereby providing a better basis for learn- ing paraphrases.  The size and the content of the vocabulary is an- other important factor in ensuring the learning of wide coverage generators. While a large vocab- ulary makes the learning problem harder, it also allows for larger coverage. WEBNLG exhibits a higher corrected type-token ratio (CTTR), which indicates greater lexical variety, and higher lexical sophistication (LS). Lexical sophistication mea- sures the proportion of relatively unusual or ad- vanced word types in the text. In practice, LS is the proportion of lexical word types (lemma) which are not in the list of 2,000 most frequent words generated from the British National Cor- pus <ref type="bibr">11</ref> . Type-token ratio (TTR) is a measure of di- versity defined as the ratio of the number of word types to the number of words in a text. To address the fact that this ratio tends to decrease with the size of the corpus, corrected TTR can be used to control for corpus size. It is defined as T / √ 2N , where T is the number of types and N the number of tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Text Comparison</head><p>Overall, the results shown in <ref type="table" target="#tab_8">Table 4</ref> indicate that WEBNLG texts are both lexically more di- verse (higher corrected type/token ratio) and more sophisticated (higher proportion of unfrequent words) than RNNLG's. They also show a propor- tionately larger vocabulary for WEBNLG (2,992 types for 290,479 tokens in WEBNLG against 3,524 types for 531,871 tokens in RNNLG).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Neural Generation</head><p>Richer and more varied datasets are harder to learn from. As a proof-of-concept study of the compar- ative difficulty of the two datasets with respect to machine learning, we compare the performance of a sequence-to-sequence model for generation on both datasets.</p><p>We use the multi-layered sequence-to-sequence model with attention mechanism described in ( <ref type="bibr" target="#b15">Vinyals et al., 2015</ref>). <ref type="bibr">12</ref> The model was trained with 3-layer LSTMs with 512 units each with a batch size of 64 and a learning rate of 0.5.</p><p>To allow for a fair comparison, we use a simi- lar amount of data (13K data-text pairs) for both datasets. As RNNLG is bigger in size than WEBNLG, we constructed a balanced sample of RNNLG which included equal number of in- stances per category (tv, laptop, etc). We use a 3:1:1 ratio for training, developement and test- ing. The training was done in two delexicalisa- tion modes: fully and name only. In case of fully delexicalisation, all entities were replaced by their generic terms, whereas in name only mode only subjects were modified in that way. For instance, the triple (FC Köln manager Peter Stöger) was delexicalised as <ref type="bibr">(SportsTeam manager Manager)</ref> in the first mode, and as (SportsTeam manager Pe- ter Stöger) in the second mode. The delexicalisa- tion in sentences was done using the exact match between entities and tokens. For training, we use all the available vocabulary. Input and output vo- cabulary sizes are reported in <ref type="table" target="#tab_10">Table 5</ref>. <ref type="table" target="#tab_10">Table 5</ref> shows the perplexity results. In both modes, RNNLG yielded lower scores than WEBNLG. This is inline with the observations made above concerning the higher data diver- sity, larger vocabulary and more complex texts of <ref type="bibr">12</ref> We used the TensorFlow code available at https://github.com/tensorflow/models/ tree/master/tutorials/rnn/translate. Alter- natively, we could have used the implementation of <ref type="bibr" target="#b16">Wen et al. (2016)</ref> which is optimised for generation. However the code is geared toward dialog acts and modifying it to handle RDF triples is non trivial. Since the comparison aims at examining the relative performance of the same neural network on the two datasets, we used the tensor flow implementation instead. WEBNLG. Similary, the BLEU score of the gen- erated sentences ( <ref type="bibr" target="#b11">Papineni et al., 2002</ref>) is lower for WEBNLG suggesting again a dataset that is more complex and therefore more difficult to learn from.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delexicalisation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a framework for building NLG data- to-text training corpora from existing knowledge bases.</p><p>One feature of our framework is that datasets created using this framework can be used for train- ing and testing KB verbalisers an in particular, verbalisers for RDF knowledge bases. Following the development of the semantic web, many large scale datasets are encoded in the RDF language (e.g., MusicBrainz, FOAF, LinkedGeoData) and official institutions 13 increasingly publish their data in this format. In this context, our frame- work is useful both for creating training data from RDF KB verbalisers and to increase the number of datasets available for training and testing NLG.</p><p>Another important feature of our framework is that it permits creating semantically and linguis- tically diverse datasets which should support the learning of lexically and syntactically, wide cov- erage micro-planners. We applied our framework to DBpedia data and showed that although twice smaller than the largest corpora currently available for training data-to-text microplanners, the result- ing dataset is more semantically and linguistically diverse. Despite the disparity in size, the num- ber of attributes is comparable in the two datasets. The ratio between input and input patterns is five times lower in our dataset thereby making learning harder but also diminishing the risk of overfitting and providing for wider linguistic coverage. Con- versely, the ratio of text per input is twice higher thereby providing better support for learning para- phrases.</p><p>We have recently released a first version of the WebNLG dataset in the context of a shared task on micro-planning <ref type="bibr">14</ref> . This new dataset consists of 21,855 data/text pairs with a to- tal of 8,372 distinct data input.</p><p>The input describes entities belonging to 9 distinct DB- pedia categories namely, Astronaut, University, Monument, Building, ComicsCharacter, Food, Airport, SportsTeam and WrittenWork. The WebNLG data is licensed under the follow- ing license: CC Attribution-Noncommercial- Share Alike 4.0 International and can be downloaded at http://talc1.loria.fr/ webnlg/stories/challenge.html.</p><p>Recently, several sequence-to-sequence models have been proposed for generation. Our exper- iments suggest that these are not optimal when it comes to generate linguistically complex texts from rich data. More generally, they indicate that the data-to-text corpora built by our framework are challenging for such models. We hope that the WEBNLG dataset which we have made available for the WEBNLG shared task will drive the deep learning community to take up this new challenge and work on the development of neural generators that can handle the generation of KB verbalisers and of linguistically rich texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>A was born in E. She worked as an engineer. S2.2 A was born in E and worked as an engineer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Input shape and linguistic structures (A = Susan Helms, B = STS 78, C = NASA, D = engineer, E = Charlotte, North Carolina).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(John E Blaha birthDate 1942 08 26) (John E Blaha birthPlace San Antonio) (John E Blaha occupation Fighter pilot) b. John E Blaha, born in San Antonio on 1942-08-26, worked as a fighter pilot</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Extracting data units from DBPedia.</figDesc><graphic url="image-1.png" coords="4,72.00,62.80,453.55,251.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>('108 St Georges Terrace location Perth', 'Perth country Australia', '108 St Georges Terrace start- Date 1981') country, location, startDate 108 St. Georges Terrace is located in Perth, Aus- tralia. Its construction began in 1981. passive, apposition, deverbal nominal b. ('William Anders selection 1963', 'William Anders birthPlace British Hong Kong', 'William Anders almaMater "AFIT, M.S. 1962"') almaMater, birthPlace, selection William Anders was born in British Hong Kong, graduated from AFIT in 1962, and joined NASA in 1963. passive, VP coordination, VP coordination</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>( 6 )</head><label>6</label><figDesc>(Alan Bean birthDate "1932-03-15") Alan Bean was born on March 15, 1932.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>( 7 )</head><label>7</label><figDesc>('Alan Bean nationality United States', 'Alan Bean birthDate "1932-03-15"', 'Alan Bean almaMater "UT Austin, B.S. 1955"', 'Alan Bean birthPlace Wheeler, Texas', 'Alan Bean selection 1963') Alan Bean was an American astronaut, born on March 15, 1932 in Wheeler, Texas. He received a Bachelor of Science degree at the University of Texas at Austin in 1955 and was chosen by NASA in 1963.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Text statistics from crowdsourcing for triple sets of varying sizes (min/max/avg). ing three questions:</head><label>2</label><figDesc></figDesc><table>Does the text sound fluent and natural? 
Does the text contain all and only the information 
from the data? 
Is the text good English (no spelling or grammati-
cal mistakes)? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>2) (AEK Athens F.C. manager Gus Poyet) (Gus Poyet club Chelsea F.C.) AEK Athens F.C. are managed by Gus Poyet, who is in Chelsea F.C.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparing WEBNLG and RNNLG 
datasets. Attributes are properties in RDF triples 
or slots in dialog acts. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Text statistics from WEBNLG and 
RNNLG. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Vocabulary sizes of input, output (number 
of tokens). Perplexity and BLEU scores. 

</table></figure>

			<note place="foot" n="1"> We ignore here (Lebret et al., 2016)&apos;s dataset which was created fully automatically from Wikipedia by associating infoboxes with text because this dataset fails to ensure an adequate match between data and text. We manually examined 50 input/output pairs randomly extracted from this dataset and did not find a single example where data and text matched. As such, this dataset is ill-suited for training microplanners. Moreover, since its texts contain both missing and additional information, it cannot be used to train joint models for content selection and micro-planning either.</note>

			<note place="foot" n="2"> For instance, the input structures made available by the shallow track of the SR task contain all the lemmas present in the corresponding text. In this case, the generation task is limited to determining (i) the linear ordering and (ii) the full form of the word in the input.</note>

			<note place="foot" n="3"> https://musicbrainz.org/ 4 http://www.foaf-project.org/ 5 http://linkedgeodata.org/</note>

			<note place="foot" n="6"> http://wiki.dbpedia.org/ dbpedia-dataset-version-2015-10 7 An entity graph for some entity e is a graph obtained by traversing the DBPedia graph starting in e and stopping at depth five.</note>

			<note place="foot">Relational noun: X nationality Y / X&apos;s nationality is Y Preposition: X country Y / X is in Y Adjective: X nationality USA / X is American</note>

			<note place="foot" n="11"> We compute LS and CTTR using the Lexical Complexity Analyzer developed by Lu (2012).</note>

			<note place="foot" n="13"> See http://museum-api.pbworks.com for examples.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The research presented in this paper was par-tially supported by the French National Research Agency within the framework of the WebNLG Project (ANR-14-CE24-0033). The third author is supported by the H2020 project SUMMA (under grant agreement 688139).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Abstract meaning representation (AMR) 1.0 specification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The KBGen challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Banik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ENLG</title>
		<meeting>ENLG</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The 14 The test data for the WEBNLG challenge will be released on August 18th, 2017 and preliminary results will be presented and discussed at INLG 2017, https:// eventos.citius.usc.es/inlg2017/index. 187 first surface realisation shared task: Overview and evaluation results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominic</forename><surname>Espinosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deirdre</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ENLG</title>
		<meeting>ENLG</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to sportscast: A test of grounded language acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imitation learning for language generation from unaligned data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerasimos</forename><surname>Lampouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Text Generation from Structured Data with Application to the Biography Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning Semantic Correspondences with Less Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP</title>
		<meeting>ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The relationship of lexical richness to the quality of ESL learners&apos; oral narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="190" to="208" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL:System Demonstrations</title>
		<meeting>ACL:System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DBpedia: A Multilingual Cross-domain Knowledge Base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Pablo N Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The aNALoGuE challenge: Non aligned language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INLG</title>
		<meeting>INLG</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building RDF content for Data-to-Text generation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<editor>Laura Perez-Beltrachini, Rania Mohamed Sayed, and Claire Gardent</editor>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Trainable methods for surface natural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SRILM-An extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICSLP</title>
		<meeting>ICSLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-domain neural network language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantically conditioned LSTM-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
