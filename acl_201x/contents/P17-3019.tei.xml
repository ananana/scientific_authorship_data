<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Forward through Opportunistic Incremental Meaning Representation Construction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Babkin</surname></persName>
							<email>babkip@rpi.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rensselaer Polytechnic Institute Troy</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Nirenburg</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Rensselaer Polytechnic Institute Troy</orgName>
								<orgName type="institution" key="instit2">Rensselaer Polytechnic Institute Troy</orgName>
								<address>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fast Forward through Opportunistic Incremental Meaning Representation Construction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics-Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="114" to="119"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/P17-3019</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>One of the challenges semantic parsers face involves upstream errors originating from pre-processing modules such as ASR and syntactic parsers, which undermine the end result from the get go. We report the work in progress on a novel incremen-tal semantic parsing algorithm that supports simultaneous application of independent heuristics and facilitates the construction of partial but potentially actionable meaning representations to overcome this problem. Our contribution to this point is mainly theoretical. In future work we intend to evaluate the algorithm as part of a dialogue understanding system on state of the art benchmarks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The versatility of human language comprehension overshadows countless transient failures happen- ing under the hood. At various points during a conversation we are bound to tolerate error and uncertainty: coming either from the speech itself (e.g., disfluencies, omissions) or resulting from our own mistakes and deficiencies as a hearer (e.g., misinterpretation of an ambiguous utterance due to incomplete knowledge, etc.). The entire pro- cess is an ever recurring cycle of gap filling, error recovery and proactive re-evaluation. Better yet, some of the arising issues we choose not to re- solve completely -leaving room for underspeci- fication and residual ambiguity, or abandoning al- together. Similarly, we are highly selective with respect to material to attend to, glancing over the bits deemed of only minor relevance or redundant.</p><p>We believe incrementality and opportunism to be key to achieving this type of behavior in a com- putational NLU system. Incremental construction of meaning representations allows for their contin- uous refinement and revision with gradually accu- mulating evidence. In addition, it gives the sys- tem an opportunity to make meta-level decisions of whether to pursue analysis of further material and/or to a greater depth; or to satisfice with a par- tial meaning representation built so far -thereby reducing the amount of work and avoiding poten- tially problematic material.</p><p>By opportunism we refer to the ability to simul- taneously engage all available sources of decision making heuristics (morphological, syntactic, se- mantic, and pragmatic knowledge) as soon as their individual preconditions are met. On one hand, this provides a degree of independence among the knowledge sources such that a failure of any one of them does not necessarily undermine the success of the process as a whole. On the other hand, op- portunistic application of heuristics facilitates the construction of partial or underspecified meaning representations when their complete versions are infeasible to obtain.</p><p>As a step towards incorporating these princi- ples in an NLU system, we present a novel oppor- tunistic incremental algorithm for semantic pars- ing. The rest of the paper is organized as follows. In the following section, we will introduce our approach while providing necessary background. Next, we will work through an example derivation, highlighting some of the features of the algorithm. Then, in the discussion section, we will position this work in the context of related work in the field, as well as within our own research agenda. Fi- nally, we will conclude with the progress to date and plans for the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Framework</head><p>Our description will be grounded within the theoretico-computational framework of Ontologi- cal Semantics (OntoSem) -a cognitively inspired and linguistically motivated knowledge-rich ac- count of NLU and related cognitive processes .</p><p>The goal of the algorithm we are presenting in this paper is to build meaning representations of text (TMRs) in an incremental and opportunistic fashion. As a source of building blocks for the TMRs we will use the OntoSem lexicon and on- tology. The lexicon provides a bridge between surface forms (e.g., word lemmas, multi-word ex- pressions, or phrasals) and their corresponding se- mantic types (called concepts), while the ontology encodes the relationships among concepts, such as case roles defined on them. In addition, OntoSem provides accounts of modality, reference, tempo- ral relations, and speech acts, which become part of the search space for our algorithm. A mean- ing representation in OntoSem is denoted as a col- lection of numbered frames with key-value entries called slots. An example of such a TMR corre- sponding to the natural language utterance "Apply pressure to the wound!" is shown below:</p><formula xml:id="formula_0">REQUEST-ACTION-1 agent HUMAN-1 theme APPLY-1 beneficiary HUMAN-2 APPLY-1 agent HUMAN-2 instrument PRESSURE-1 theme WOUND-INJURY-1</formula><p>The root of this TMR is an instance of the REQUEST-ACTION speech act evoked by the im- perative mood of the utterance. The agent (re- quester) of this speech act is the implied speaker of the utterance. The beneficiary (or patient, in other semantic formalisms) is the implied addressee of this message. Next, the theme of the speech act (the action being requested) is an instance of the APPLY event defined in the ontology. The agent of the action requested is specified to be the same as the addressee. The instrument is specified to be an instance of PRESSURE. Finally, the theme (or target) of the requested action references some known instance of a WOUND-INJURY, either in- troduced earlier in text, or contained in the com- mon ground of the interlocutors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Algorithm</head><p>A TMR can be represented as a (possibly rooted) graph G = (V, E), where the set of vertices V rep- resents semantic instances and the set of edges E denotes case role linkings among them. We can thus formulate our problem generally as that of producing a pair (V, E) for an input utterance u as a sequence of tokens u 1 , u 2 , ..., u n , so as to maximize some score: arg max (V,E) score(V, E). The algorithm operates in two phases: the for- ward pass generates candidate solutions and the backward pass extracts the best scoring solution. The forward pass of the algorithm proceeds itera- tively: by performing a series of incremental op- erations: next and link, which we define in order. The basic data structure used is an abstract set S of items p 0 through p n .</p><p>next is defined as an incremental operation consuming one or more tokens from the input ut- terance u 1 , u 2 , ..., u n and returning zero or more items p to be added to the set S.</p><p>link operation is defined as accepting a set S i and returning a new set S i+1 and a bipartite graph defined by (S i , S i+1 , L i+1,i ), where L i+1,i is a set of edges between the two sets-partitions. The following snippet provides a high level de- scription of the execution of the forward pass of the algorithm.</p><formula xml:id="formula_1">function EXPAND(u 1 , u 2 , ..., u n ) S i ← ∅ initialize lattice C with tuple S i , ∅, ∅∅ while NO-ACTIONABLE-TMR(C) do if MORE-INPUT-NEEDED(C) then S i ← S i ∪NEXT(u 1 , u 2 , ..., u n ) else C ← C ∪ {LINK(S i )} S i ← S i+1 if FIXED-POINT(C) then return ∅ end if end if end while return C end function</formula><p>Expand in the name of the function refers to the fact that the lattice data structure used to store the candidate solutions is repeatedly expanded by the two incremental operations we just introduced. The next operation expands the width of the lat- tice by adding new elements to the set S i , which can be thought of as a "layer" of the lattice. The link operation, expands the depth of the lattice by creating a new "layer" and connecting it to the el- ements of the previous layer. Intuitively, the pro- cess can be visualized diagonally as alternating horizontal and vertical expansions. The entire lat- tice can be thought of as a metaphorical "loom", on which meaning representations are "woven". The depth of the lattice is the depth of nesting in the corresponding meaning representation tree with a linear upper bound. In practice, however, we expect it to approach O(log|U |) as most of the nesting occurs in multiple-argument instances. The following conditionals are employed to con- trol the execution flow of the main algorithm: 1. NO-ACTIONABLE-TMR captures high-level desiderata for execution continuation. In the cur- rent implementation the algorithm simply requires that the TMR is headed by an event and that its as well as its constituents' core roles (e.g., agent, theme) are filled; and that it spans all components of the input. Work is ongoing to operationalize pragmatic considerations for actionability, includ- ing whether a partial TMR is coherent with pre- ceding discourse or is consistent with a known script, that could warrant early halting. 2. MORE-INPUT-NEEDED is triggered when there are no components to link despite the TMR being non-actionable. 3. FIXED-POINT basically means that further it- eration does not produce any novel interpretations.</p><p>The subsequent solution extraction phase amounts to simply extracting TMR candidates from the lattice via depth-first traversal and rank- ing them by the cumulative scores of constituent nodes and edges. It should be noted that this pro- cedure operates on a considerably reduced sub- set of the original search space as it effectively chooses among a limited set of viable candidates produced during the forward pass. Going a level deeper in our description, we will now turn to the implementation details of the incremental opera- tions next and link.</p><p>The next operation translates the next word to- ken (or a group of tokens) from the input utter- ance into corresponding semantic type that are then combined together into a TMR. It is currently realized as a basic lexical look-up by lemma, with greedy matching for multi-word expressions and non-semantically loaded tokens are skipped. For polysemous words, semantic representations for all variants are considered. While the On- toSem lexicon specifies a battery of syntactic and morphological constraints imposed on each word sense (e.g., syntactic dependencies they are ex- pected to have -cf.  for an in-depth overview), their application is deferred until the scoring stage as word sense disambiguation is pursued jointly, as part of mean- ing representation construction by the algorithm, rather than as a pre-processing stage.</p><p>The link operation is the core TMR-building routine of the algorithm.</p><formula xml:id="formula_2">function LINK(S i ) S i+1 ← S i ; L i+i,i ← ∅ for all argument taking p j in S i+1 do R j ←CASE-ROLES(p j ) for all F in ALIGN(S i , R j ) do F ⇔ {p k ∈ S i |SAT(p k , r j,k ∈ R j )} yieldj, k, r j,k ,SCORE(p j , p k , r j,k ) end for end for return (S i , S i+1 , L i+1,i ) end function</formula><p>On each application, it considers a superposition of TMR fragments of depth 1 formed by the ele- ments of the two adjacent partitions S i and S i+i . The set L i i+1 is used to store edges connecting the elements of the two sets. For each argument- taking instance p j in S i+1 , the function attempts to find alignments from roles R j to instances F ⊂ S i that would satisfy their semantic constraints.</p><p>For each such alignment, the function yields the resulting edges as tuples containing the end point indices along with the corresponding case role la- bel and link score. In addition to the already men- tioned ranking of candidate meaning representa- tions during the solution extraction phase, link scores can also be used to drive beam search dur- ing the forward pass to prune the search space on the fly. Scores are currently assigned based on a) how closely the filler matches the role's type constraint (inverse ontological distance) and b) whether the role matches the expected syntactic dependency specified for it in the lexicon. A large part of future work will involve incorporation of pragmatic heuristics including those based on co- reference, coherence (e.g., prefer the role agent if a filler in question took on the that role in a series of events in preceding discourse), and knowledge of scripts, all of which we hypothesize especially crucial in situations with unreliable syntax.</p><p>The computational complexity of this operation is a little harder to estimate since it depends on variable numbers of word senses and correspond- ing case roles. Treating them as constant factors gives us quadratic worst-case complexity in the length of the utterance. A more accurate estimate can be obtained but the key point is that the over- lapping representation of hypotheses with itera- tive deepening eliminates the branching factor of exhaustive permutation and results in polynomial rather than exponential order of complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">A Worked Example</head><p>We will now proceed with the derivation of the meaning representation for the example sentence.</p><p>Although the OntoSem lexicon specifies more fine grain senses of the words used, to keep the exam- ple simple, we will only consider a subset. Our description will follow the derivation in <ref type="table">Table 1.</ref> 1. The algorithm initializes with the empty sets of semantic instances S and case roles links L. 2. Both NO-ACTIONABLE-TMR and MORE- INPUT-NEEDED conditions are triggered, invok- ing the next operation. The first token "Apply" has an instrumental sense e.g., "apply paint to the wall", but to introduce some degree of ambigu- ity we will also consider a phrasal sense as in "he needs to apply himself", having a meaning of the modality of type EFFORT. 3. At the next step, the conditions are triggered again since neither of the current head event can- didates have their roles specified. The next to- ken "pressure" instantiates two possible interpre- tations: literal, physical PRESSURE, and figura- tive i.e. "to be pressured to do something" trans- lating into a modality of type POTENTIAL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The currently disjoint TMR components (p 1 , p 2 , p 3 , p 4 ) can now be connected via case</head><formula xml:id="formula_3"># Op u z ∆S i , ∆L i</formula><p>roles, which triggers the link operation, result- ing in four compound TMR fragments: (AP- PLY instrument/theme PRESSURE), (EFFORT scope POTENTIAL), (POTENTIAL scope AP- PLY), (POTENTIAL scope EFFORT). The first interpretation has a role ambiguity to be resolved during the solution extraction phrase. 5. Neither of the TMR fragments are complete, still having unspecified roles, thereby triggering the next operation. The following token "wound" translates into p 8 :WOUND-INJURY concept <ref type="bibr">1</ref> . 6. During the next iteration of linking p 8 :WOUND-INJURY is employed as a theme of p 1 :APPLY resulting in the (APPLY (instrument PRESSURE) (theme WOUND-INJURY)) TMR fragment. 7. The last token "!" confirms the imperative mood of the utterance, signaling the instantiation of the REQUEST-ACTION speech act. 8. The three TMR heads are then linked to the theme slot of of the REQUEST-ACTION instance. 9. Since none of the current fragments alone spans all of the components of the input despite their aggregate coverage, they need to be com- bined together through the creation of a new layer producing nested TMR fragments. Certain links have been pruned as not leading to novel solutions. 10.The termination condition is fulfilled as there now exists a complete TMR candidate accounting for all of the lexemes observed in the input. It is shown in the table both as a tree and as a high- lighted fragment of the solution lattice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discussion &amp; Related Work</head><p>Syntax plays a formidable role in the understand- ing of meaning. In a number of theories of se- mantics, important aspects such as case role align- ment are determined primarily based on some syntactico-semantic interface such as in Lexical Functional Grammars <ref type="bibr" target="#b0">(Ackerman, 1995)</ref>, Com- binatory Categorial Grammars (Steedman and Baldridge, 2011), or others. Some approaches have even gone as far as to cast the entire prob- lem of semantic parsing as that of decorating a de- pendency parse <ref type="bibr" target="#b6">(May, 2016)</ref>. However, such tight coupling of semantics with syntax has its down- sides. First, linguistic variation in the expression of the same meaning needs to be accounted for ex- plicitly (e.g., by creating dedicated lexical senses or production rules to cover all possible realiza- tions). Second and more importantly, the feasi- bility of a semantic interpretation becomes con- ditional on the well-formedness of the language input and the correctness of the corresponding syntactic parse. This requirement seems unnec- essarily strong considering a) human outstanding ability to make sense of ungrammatical and frag- mented speech ( <ref type="bibr" target="#b4">Kong et al., 2014</ref>) and b) still con- siderably high error rates of ASR transcription and parsing <ref type="bibr" target="#b10">(Roark et al., 2006</ref>).</p><p>The algorithm we present, by contrast, operates directly over the meaning representation space, while relying on heuristics of arbitrary provenance (syntax, reference, coherence, etc.) in its scor- ing mechanism for disambiguation and to steer the search process towards the promising region of the search space. This allows it to focus on exploring conceptually plausible interpretations while being less sensitive to upstream noise. The algorithm is opportunistic as the overlapping lattice repre- sentation allows it to simultaneously pursue multi- ple hypotheses, while the explicit evaluation of the candidates is deferred until a promising solution is found.</p><p>Incremental semantic parsing has come back to the forefront of NLU tasks <ref type="bibr" target="#b9">(Peldszus and Schlangen, 2012)</ref>, ( <ref type="bibr" target="#b15">Zhou et al., 2016)</ref>. Ac- counting for incrementality helps to make dia- logues more human-like by accommodating spo- radic asynchronous feedback as well as correc- tions, wedged-in questions, etc. ( <ref type="bibr" target="#b11">Skantze and Schlangen, 2009)</ref>. In addition, incrementality of meaning representation construction coupled with sensory grounding has been shown to help prune the search space and reduce ambiguity during se- mantic parsing ( <ref type="bibr" target="#b5">Kruijff et al., 2007)</ref>. The pre- sented algorithm is incremental as it proceeds via a series of operations gradually extending and deep- ening the lattice structure containing candidate so- lutions. The algorithm constantly re-evaluates its partial solutions and potentially produces an ac- tionable TMR without exhaustive search over the entire input.</p><p>The design of the algorithm was influenced by the classical blackboard architecture <ref type="bibr" target="#b3">(Carver and Lesser, 1992)</ref>. Blackboard architectures offer sig- nificant benefits: they develop solutions incremen- tally by aggregating evidence; employ different sources of knowledge simultaneously; and enter- tain multiple competing or cooperating lines of reasoning concurrently. Some implementation de- tails of our algorithm were inspired by the well- known Viterbi algorithm: e.g., forward and back- ward passes, solution scoring <ref type="bibr" target="#b13">(Viterbi, 1967)</ref>; as well as the relaxed planning graph heuristic from autonomous planning: namely, the lattice repre- sentation of partial solutions and the repeated si- multaneous application of operators <ref type="bibr" target="#b2">(Blum and Furst, 1995</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion &amp; Future Work</head><p>The opportunistic and incremental algorithm we presented in this paper has the potential to improve the flexibility and robustness of meaning repre- sentation construction in the face of ASR noise, parsing errors, and unexpected input. This ca- pability is essential for NLU results to approach true human capability <ref type="bibr" target="#b9">(Peldszus and Schlangen, 2012)</ref>. We implemented the algorithm and inte- grated it with non-trivial subsets of the current OntoSem's domain-general lexicon (9354 out of 17198 senses) and ontology (1708 concept real- izations out of 9052 concepts) ( . Once fully integrated and tuned, we plan to formally evaluate the performance of the algo- rithm on a portion of the SemEval 2016 AMR parsing shared task dataset <ref type="bibr" target="#b6">(May, 2016)</ref> while measuring the impact of parsing errors on the end TMR quality. In addition, it would be in- teresting to empirically quantify the utility of our proposed pragmatic heuristics in the domain of a task-oriented dialogue such as the Dialogue State Tracking Challenge ( <ref type="bibr" target="#b14">Williams et al., 2013</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A schematic depiction of the incremental operations next (a), link (b), and the resulting lattice containing a solution (c).</figDesc><graphic url="image-1.png" coords="3,75.68,185.32,210.93,104.78" type="bitmap" /></figure>

			<note place="foot" n="1"> Although a verbal sense is also conceivable, we will assume it has been ruled out by morphology.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by Grant N00014-16-1-2118 from the U.S. Office of Naval Research and by the Cognitive and Immersive Systems Laboratory collaboration between Rens-selaer Polytechnic Institute and IBM Research. We would also like to thank the three anonymous reviewers for their valuable feedback.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lexical functional grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Farrell Ackerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Pragmatics</title>
		<editor>Jef Verschuren, Jan-Olä Ostman, and Jan Blommaert</editor>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page">346</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Benjamins</surname></persName>
		</author>
		<imprint>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast planning through planning graph analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Avrim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Merrick</forename><forename type="middle">L</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Furst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1636" to="1642" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The Evolution of Blackboard Control Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Carver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lesser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A Dependency Parser for Tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archna</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert-Jan</forename><surname>Kruijff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Lison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Jacobsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hawes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language and Robots: Proceedings from the Symposium</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">12</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Aveiro</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">SemEval-2016 Task 8: Meaning Representation Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Decisions for semantic analysis in cognitive systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjorie</forename><surname>Mcshane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Nirenburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Language understanding with ontological semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjorie</forename><surname>Mcshane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Nirenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Beale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Incremental Construction of Robust but Deep Semantic Representations for Use in Responsive Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Coling Workshop on Advances in Discourse Analysis and its Computational Aspects</title>
		<editor>Eva Hajiov</editor>
		<meeting>the Coling Workshop on Advances in Discourse Analysis and its Computational Aspects</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><forename type="middle">G</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Anna Krasnyanskaya, Matthew Lease, Izhak Shafran, Matthew Snover, Robin Stewart, and Lisa Yung</pubPlace>
		</imprint>
	</monogr>
	<note>Sparseval: Evaluation metrics for parsing speech</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Incremental dialogue processing in a micro-domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Skantze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schlangen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09</title>
		<meeting>the 12th Conference of the European Chapter of the Association for Computational Linguistics, EACL &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="745" to="753" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Combinatory Categorial Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>WileyBlackwell</publisher>
			<biblScope unit="page" from="181" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Error bounds for convolutional codes and an asymptotically optimum decoding algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Viterbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="1967-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Ramach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue SIGDIAL</title>
		<meeting>the 14th Annual Meeting of the Special Interest Group on Discourse and Dialogue SIGDIAL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AMR parsing with an incremental joint model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiguang</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhui</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
