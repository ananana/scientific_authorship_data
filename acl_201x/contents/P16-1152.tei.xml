<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Structured Predictors from Bandit Feedback for Interactive NLP</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Lo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computational Linguistics &amp; ‡ IWR</orgName>
								<orgName type="department" key="dep2">Department of Mathematics</orgName>
								<orgName type="institution">Heidelberg University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Amazon Development Center</orgName>
								<orgName type="institution">Tufts University</orgName>
								<address>
									<settlement>Boston, Berlin</settlement>
									<region>MA</region>
									<country>USA, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Structured Predictors from Bandit Feedback for Interactive NLP</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1610" to="1620"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Structured prediction from bandit feedback describes a learning scenario where instead of having access to a gold standard structure, a learner only receives partial feedback in form of the loss value of a predicted structure. We present new learning objectives and algorithms for this interactive scenario, focusing on convergence speed and ease of elicitability of feedback. We present supervised-to-bandit simulation experiments for several NLP tasks (machine translation, sequence labeling , text classification), showing that bandit learning from relative preferences eases feedback strength and yields improved empirical convergence.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Structured prediction from partial information can be described by the following learning protocol: On each of a sequence of rounds, the learning al- gorithm makes a prediction, and receives partial information in terms of feedback on the predicted point. This single-point feedback is used to con- struct a parameter update that is an unbiased esti- mate of the respective update rule for the full in- formation objective. In difference to the full infor- mation scenario, the learner does not know what the correct prediction looks like, nor what would have happened if it had predicted differently. This learning scenario has been investigated under the names of learning from bandit feedback 1 or rein- * The work for this paper was done while the authors were at Heidelberg University. <ref type="bibr">1</ref> The name is inherited from a model where in each round a gambler pulls an arm of a different slot machine ("one- armed bandit"), with the goal of maximizing his reward rel- ative to the maximal possible reward, without apriori knowl- edge of the optimal slot machine. See Bubeck and Cesa- Bianchi (2012) for an overview. forcement learning 2 , and has (financially) impor- tant real world applications such as online adver- tising ( <ref type="bibr" target="#b12">Chapelle et al., 2014</ref>). In this application, the probability that an ad will be clicked (and the advertiser has to pay) is estimated by trading off exploration (a new ad needs to be displayed in or- der to learn its click-through rate) and exploitation (displaying the ad with the current best estimate is better in the short term) in displaying ads to users. Similar to the online advertising scenario, there are many potential applications to interac- tive learning in NLP. For example, in interactive statistical machine translation (SMT), user feed- back in form of post-edits of predicted transla- tions is used for model adaptation <ref type="bibr" target="#b5">(Bertoldi et al., 2014;</ref><ref type="bibr" target="#b16">Denkowski et al., 2014;</ref><ref type="bibr" target="#b23">Green et al., 2014</ref>). Since post-editing feedback has a high cost and requires professional expertise of users, weaker forms of feedback are desirable. <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> showed in a simulation experiment that partial information in form of translation quality judgements on predicted translations is sufficient for model adaptation in SMT. However, one draw- back of their bandit expected loss minimization al- gorithm is the slow convergence speed, meaning that impractically many rounds of user feedback would be necessary for learning in real-world in- teractive SMT. Furthermore, their algorithms re- quires feedback in form of numerical assessments of translation quality. Such absolute feedback is arguably harder to elicit from human users than relative judgements.</p><p>The goal of this work is a preparatory study of different objectives and algorithms for struc- tured prediction from partial information with real-world interactive scenarios in mind. Since the algorithm of <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> can be charac- terized as stochastic optimization of a non-convex objective, a possible avenue to address the prob- lem of convergence speed is a (strong) convexifi- cation of the learning objective, which we formal- ize as bandit cross-entropy minimization. To the aim of easing elicitability of feedback, we present a bandit pairwise preference learning algorithm that requires only relative feedback in the form of pairwise preference rankings.</p><p>The focus of this paper is on an experimental evaluation of the empirical performance and con- vergence speed of the different algorithms. We follow the standard practice of early stopping by measuring performance on a development set, and present results of an extensive evaluation on sev- eral tasks with different loss functions, including BLEU for SMT, Hamming loss for optical char- acter recognition, and F1 score for chunking. In our experiments, we use a standard supervised- to-bandit transformation where a reward signal is simulated by evaluating a task loss against gold standard structures without revealing them to the learning algorithm ( <ref type="bibr" target="#b1">Agarwal et al., 2014</ref>). From the perspective of real-world interactive applica- tions, bandit pairwise preference learning is the preferred algorithm since it only requires compar- ative judgements for learning. This type of rela- tive feedback been shown to be advantageous for human decision making <ref type="bibr" target="#b56">(Thurstone, 1927)</ref>. How- ever, in our simulation experiments we found that relative feedback also results in improved empir- ical convergence speed for bandit pairwise pref- erence learning. The picture of fastest empirical convergence of bandit pairwise preference learn- ing is consistent across different tasks, both com- pared to bandit expected loss minimization and bandit cross-entropy minimization. Given the im- proved convergence and the ease of elicitability of relative feedback, the presented bandit pairwise preference learner is an attractive choice for inter- active NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Reinforcement learning (RL) has the goal of max- imizing the expected reward for choosing an ac- tion at a given state in a Markov Decision Pro- cess (MDP) model, where rewards are received at each state or once at the final state. The al- gorithms in this paper can be seen as one-state MDPs where choosing an action corresponds to predicting a structured output. Most closely re- lated are RL approaches that use gradient-based optimization of a parametric policy for action se- lection ( <ref type="bibr" target="#b6">Bertsekas and Tsitsiklis, 1996;</ref><ref type="bibr" target="#b53">Sutton et al., 2000</ref>). Policy gradient approaches have been applied to NLP tasks by <ref type="bibr" target="#b8">Branavan et al. (2009)</ref>, <ref type="bibr" target="#b11">Chang et al. (2015)</ref> or <ref type="bibr" target="#b43">Ranzato et al. (2016)</ref>.</p><p>Bandit learning operates in a similar scenario of maximizing the expected reward for selecting an arm of a multi-armed slot machine. Similar to our case, the models consist of a single state, however, arms are usually selected from a small set of op- tions while structures are predicted over exponen- tial output spaces. While bandit learning is mostly formalized as online regret minimization with re- spect to the best fixed arm in hindsight, we inves- tigate asymptotic convergence of our algorithms. In the spectrum of stochastic ( <ref type="bibr" target="#b3">Auer et al., 2002a</ref>) versus adversarial bandits <ref type="bibr" target="#b4">(Auer et al., 2002b</ref>), our approach takes a middle path by making stochastic assumptions on inputs, but not on rewards. Most closely related are algorithms that optimize para- metric models, e.g., contextual bandits ( <ref type="bibr" target="#b32">Langford and Zhang, 2007;</ref><ref type="bibr" target="#b35">Li et al., 2010</ref>) or combinatorial bandits ( <ref type="bibr" target="#b15">Dani et al., 2007;</ref><ref type="bibr" target="#b10">Cesa-Bianchi and Lugosi, 2012)</ref>. To the best of our knowledge, these types of algorithms have not yet been applied in the area of NLP.</p><p>Pairwise preference learning has been studied in the full information supervised setting (see <ref type="bibr" target="#b25">Herbrich et al. (2000)</ref>, Joachims (2002), <ref type="bibr" target="#b19">Freund et al. (2003)</ref>, <ref type="bibr" target="#b14">Cortes et al. (2007)</ref>, <ref type="bibr">Fürnkranz and Hüllermeier (2010)</ref>, inter alia) where given pref- erence pairs are assumed. Stochastic optimization from two-point (or multi-point) feedback has been investigated in the framework of gradient-free op- timization (see <ref type="bibr" target="#b57">Yue and Joachims (2009)</ref>, <ref type="bibr" target="#b0">Agarwal et al. (2010)</ref>, <ref type="bibr" target="#b21">Ghadimi and Lan (2012)</ref>, <ref type="bibr" target="#b27">Jamieson et al. (2012)</ref>, <ref type="bibr" target="#b17">Duchi et al. (2015)</ref>, inter alia), while our algorithms can be characterized as stochastic gradient descent algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Probabilistic Structured Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Full Information vs. Bandit Feedback</head><p>The objectives and algorithms presented in this pa- per are based on the well-known expected loss cri- terion for probabilistic structured prediction (see <ref type="bibr" target="#b39">Och (2003)</ref>, <ref type="bibr" target="#b48">Smith and Eisner (2006)</ref>, <ref type="bibr" target="#b22">Gimpel and Smith (2010)</ref>, <ref type="bibr" target="#b58">Yuille and He (2012)</ref>, <ref type="bibr" target="#b24">He and Deng (2012)</ref>, inter alia). The objective is defined as a minimization of the expectation of a given task loss function with respect to the conditional dis- tribution over structured outputs. This criterion has the form of a continuous, differentiable, and in general, non-convex objective function. More for- mally, let X be a structured input space, let Y(x) be the set of possible output structures for input x, and let ∆ y : Y → [0, 1] quantify the loss ∆ y (y ) suffered for predicting y instead of the gold stan- dard structure y; as a rule, ∆ y (y ) = 0 iff y = y . In the full information setting, for a data distri- bution p(x, y), the learning criterion is defined as minimization of the expected loss with respect to w ∈ R d where</p><formula xml:id="formula_0">E p(x,y)pw(y |x) ∆ y (y ) (1) = x,y p(x, y) y ∈Y(x) ∆ y (y )p w (y |x).</formula><p>Assume further that output structures given inputs are distributed according to an underlying Gibbs distribution (a.k.a. conditional exponential or log- linear model)</p><formula xml:id="formula_1">p w (y|x) = exp(w φ(x, y))/Z w (x),</formula><p>where φ : X × Y → R d is a joint feature rep- resentation of inputs and outputs, w ∈ R d is an associated weight vector, and Z w (x) is a normal- ization constant. For this model, the gradient of objective (1) is as follows:</p><formula xml:id="formula_2">E p(x,y)pw(y |x) ∆ y (y ) = E p(x,y)pw(y |x) ∆ y (y ) φ(x, y ) −E pw(y |x) [φ(x, y )] .<label>(2)</label></formula><p>Unlike in the full information scenario, bandit feedback in structured prediction means that the gold standard output structure y, with respect to which the objective function is evaluated, is not re- vealed to the learner. Thus we can neither evaluate the task loss ∆ nor calculate the gradient (2) of the objective function (1). A solution to this problem is to pass the evaluation of the loss function to the user, i.e, we access the loss directly through user feedback without assuming existence of a fixed reference y. We indicate this by dropping the sub- script referring to the gold standard structure in the definition of ∆. In all algorithms presented below we need to make the following assumptions:</p><p>1. We assume a sequence of input structures x t , t = 1, . . . , T that are generated by a fixed, unknown distribution p(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Bandit Expected Loss Minimization</head><p>1: Input: sequence of learning rates γ t 2: Initialize w 0 3: for t = 0, . . . , T do 4: Observe x t 5: Calculate</p><formula xml:id="formula_3">E pw t (y|xt) [φ(x t , y)] 6: Sample˜ySample˜ Sample˜y t ∼ p wt (y|x t ) 7: Obtain feedback ∆(˜ y t ) 8: w t+1 = w t − γ t ∆(˜ y t ) 9: × φ(x t , ˜ y t ) − E pw t [φ(x t , y)]</formula><p>Algorithm 2 Bandit Pairwise Preference Learning 1: Input: sequence of learning rates γ t 2: Initialize w 0 3:</p><formula xml:id="formula_4">for t = 0, . . . , T do 4: Observe x t 5: Calculate E pw t (y i ,y j |xt) [φ(x t , y i , y j )] 6: Sample˜ySample˜Sample˜y i , ˜ y j t ∼ p wt (y i , y j |x t ) 7: Obtain feedback ∆(˜ y i , ˜ y j t ) 8: w t+1 = w t − γ t ∆(˜ y i , ˜ y j t ) 9: × φ(x t , ˜ y i , ˜ y j t ) − E pw t [φ(x t , y i , y j )]</formula><p>2. We use a Gibbs model as sampling distri- bution to perform simultaneous exploitation (use the current best estimate) / exploration (get new information) on output structures.</p><p>3. We use feedback to the sampled output struc- tures to construct a parameter update rule that is an unbiased estimate of the true gradient of the respective objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning Objectives and Algorithms</head><p>Bandit Expected Loss Minimization. Algo- rithm 1 has been presented in <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> and minimizes the objective below by stochastic gradient descent optimization. It is non-convex for the specific instantiations in this paper:</p><formula xml:id="formula_5">E p(x)pw(y|x) [∆(y)] (3) = x p(x) y∈Y(x) ∆(y)p w (y|x).</formula><p>Intuitively, the algorithm compares the sampled feature vector to the average feature vector, and performs a step into the opposite direction of this difference, the more so the higher the loss of the sampled structure is. In the extreme case, if the sampled structure is correct (∆(˜ y t ) = 0), no up- date is performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Bandit Cross-Entropy Minimization</head><p>1: Input: sequence of learning rates γ t 2: Initialize w 0 3: for t = 0, . . . , T do 4: Observe x t 5: Sample˜ySample˜ Sample˜y t ∼ p wt (y|x t ) 6: Obtain feedback g(˜ y t ) 7: w t+1 = w t − γ t g(˜ yt) pw t (˜ yt|xt) 8:</p><formula xml:id="formula_6">× − φ(x t , ˜ y t ) + E pw t [φ(x t , ˜ y t )]</formula><p>Bandit Pairwise Preference Learning. De- composing complex problems into a series of pair- wise comparisons has been shown to be advan- tageous for human decision making <ref type="bibr" target="#b56">(Thurstone, 1927)</ref> and for machine learning <ref type="bibr">(Fürnkranz and Hüllermeier, 2010</ref>). For our case, this idea can be formalized as an expected loss objective with respect to a conditional distribution of pairs of structured outputs. Let P(x) = {{y i , y j |y i , y j ∈ Y(x)} denote the set of output pairs for an input x, and let ∆(y i , y j ) : P(x) → [0, 1] denote a task loss function that specifies a dispreference of y i compared to y j . Instantiating objective <ref type="formula">(3)</ref> to the case of pairs of output structures defines the following objective:</p><formula xml:id="formula_7">E p(x)pw(y i ,y j |x) [∆(y i , y j )] .<label>(4)</label></formula><p>Stochastic gradient descent optimization of this objective leads to Algorithm 2. The objective is again non-convex in the use cases in this pa- per. Minimization of this objective will assure that high probabilities are assigned to pairs with low loss due to misranking y j over y i . Stronger as- sumptions on the learned probability ranking can be made if assumptions of transitivity and asym- metry of the ordering of feedback structures are made. For efficient sampling and calculation of expectations, we assume a Gibbs model that fac- torizes as follows:</p><formula xml:id="formula_8">p w (y i , y j |x) = e w (φ(x,y i )−φ(x,y j )) y i ,y j ∈P(x) e w (φ(x,y i )−φ(x,y j )) = p w (y i |x)p −w (y j |x).</formula><p>If a sample from the p −w distribution is preferred over a sample from the p w distribution, this is a strong signal for model correction.</p><p>Bandit Cross-Entropy Minimization. The standard theory of stochastic optimization pre- dicts considerable improvements in convergence speed depending on the functional form of the objective. This motivates the formalization of convex upper bounds on expected normalized loss as presented in <ref type="bibr" target="#b23">Green et al. (2014)</ref>. Their objec- tive is based on a gain function g : Y → <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> (in this work, g(y) = 1 − ∆(y)) that is normal- ized over n-best lists where ¯ g(y) = g(y)</p><p>Zg(x) and Z g (x) = y∈n-best(x) g(y). It can be seen as the cross-entropy of model p w (y|x) with respect the "true" distribution ¯ g(y):</p><formula xml:id="formula_9">E p(x)¯ g(y) [− log p w (y|x)] (5) = − x p(x) y∈Y(x) ¯ g(y) log p w (y|x).</formula><p>For a proper probability distribution ¯ g(y), an ap- plication of Jensen's inequality to the convex neg- ative logarithm function shows that objective (5) is a convex upper bound on objective (3). However, normalizing the gain function is prohibitive in a bandit setting since it would require to elicit user feedback for each structure in the output space or n-best list. We thus work with an unnormalized gain function which sacrifices the upper bound but preserves convexity. This can be seen by rewriting the objective as the sum of a linear and a convex function in w:</p><formula xml:id="formula_10">E p(x)g(y) [− log p w (y|x)]<label>(6)</label></formula><formula xml:id="formula_11">= − x p(x) y∈Y(x)</formula><p>g(y)w φ(x, y)</p><formula xml:id="formula_12">+ x p(x)(log y∈Y(x) exp(w φ(x, y)))α(x),</formula><p>where α(x) = y∈Y(x) g(y) is a constant factor not depending on w. The gradient of objective (6) is as follows:</p><formula xml:id="formula_13">(− x p(x) y∈Y(x) g(y) log p w (y|x)) = E p(x)ps(y|x) g(y) p s (y|x) − φ(x, y) + E pw(y|x) [φ(x, y)] .</formula><p>Minimization of this objective will assign high probabilities to structures with high gain, as de- sired. Algorithm 3 minimizes this objective by sampling from a distribution p s (y|x), receiving feedback, and updating according to the ratio of gain versus current probability of the sampled structure. A positive ratio expresses a preference of the sampled structure under the gain function compared to the current probability estimate. We compare the sampled feature vector to the average feature vector, and we update towards the sampled feature vector relative to this ratio. We instanti- ate p s (y|x) to the current update of p wt <ref type="bibr">(y|x)</ref> </p><note type="other">in order to present progressively more useful struc- tures to the user. In contrast to Algorithms 1 and 2, each update is thus affected by a probability that changes over time and is unreliable when train- ing is started. This further increases the variance already present in stochastic optimization. We deal with this problem by clipping too small sam- pling probabilities (Ionides, 2008) or by reduc- ing variance using momentum techniques (Polyak, 1964).</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Remarks on Theoretical Analysis</head><p>Convergence of our algorithms can be analyzed using results of standard stochastic approximation theory. For example, <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> analyze the convergence of Algorithm 1 in the pseudogra- dient framework of <ref type="bibr" target="#b40">Polyak and Tsypkin (1973)</ref>, relying on the fact that a positive inner product of the update vector with the gradient in expectation suffices for convergence. <ref type="bibr" target="#b50">Sokolov et al. (2016)</ref> an- alyze convergence in the framework of stochas- tic first-order optimization of <ref type="bibr" target="#b21">Ghadimi and Lan (2012)</ref>, relying on the fact that the update vectors of the algorithms are stochastic gradients of the respective objectives, that is, the update vectors are unbiased gradient measurements that equal the gradient of the full information objective in expec- tation. Note that the latter analysis covers the use of constant learning rates.</p><p>Convergence speed is analyzed in standard stochastic approximation theory in terms of the number of iterations needed to reach an accuracy of for a gradient-based criterion</p><formula xml:id="formula_14">E[J(w t ) 2 ] ≤ ,<label>(7)</label></formula><p>where J(w t ) denotes the objective to be mini- mized. Following <ref type="bibr" target="#b21">Ghadimi and Lan (2012)</ref>, the iteration complexity of the non-convex objectives underlying our Algorithms 1 and 2 can be given as O(1// 2 ) (see <ref type="bibr" target="#b50">Sokolov et al. (2016)</ref>). Algo- rithm 3 can be seen as stochastic optimization of a strongly convex objective that is attained by adding an 2 regularizer λ 2 w 2 with constant λ &gt; 0 to objective (6). In the standard stochas- tic approximation theory, the iteration complexity of stochastic gradient algorithms using decreasing learning rates can be given as O(1//) for an ob- jective value-based criterion</p><formula xml:id="formula_15">E[J(w t )] − J(w * ) ≤ ,</formula><p>where w * = arg min w J(w) <ref type="bibr" target="#b42">(Polyak, 1987)</ref>. For constant learning rates, even faster convergence can be shown provided certain additional condi- tions are met <ref type="bibr" target="#b51">(Solodov, 1998)</ref>.</p><p>While the asymptotic iteration complexity bounds predict faster convergence for Algorithm 3 compared to Algorithms 1 and 2, and equal con- vergence speed for the latter two, <ref type="bibr" target="#b50">Sokolov et al. (2016)</ref> show that the hidden constant of variance of the stochastic gradient can offset this advan- tage empirically. They find smallest variance of stochastic updates and fastest empirical conver- gence under the gradient-based criterion <ref type="formula" target="#formula_14">(7)</ref> for Algorithm 2. In the next section we will present experimental results that show similar relations of fastest convergence of Algorithm 2 under a con- vergence criterion based on task loss evaluation on heldout data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Experimental design. Our experiments follow an online learning protocol where on each of a se- quence of rounds, an output structure is randomly sampled, and feedback to it is used to update the model <ref type="bibr" target="#b46">(Shalev-Shwartz, 2012</ref>). We simulate ban- dit feedback by evaluating ∆ against gold stan- dard structures which are never revealed to the learner ( <ref type="bibr" target="#b1">Agarwal et al., 2014</ref>). Training is started from w 0 = 0 or from an out-of-domain model (for SMT).</p><p>Following the standard practice of early stop- ping by performance evaluation on a development set, we compute convergence speed as the num- ber of iterations needed to find the point of op- timal performance before overfitting on the de- velopment set occurs. The convergence criterion is thus based on the respective task loss func- tion ∆(ˆ y wt (x)) under MAP predictionˆypredictionˆ predictionˆy w (x) = arg max y∈Y(x) p w (y|x), microaveraged on the de- velopment data. This lets us compare conver- gence across different objectives, and is justified by the standard practice of performing online-to- batch conversion by early stopping on a develop- ment set <ref type="bibr" target="#b36">(Littlestone, 1989)</ref>, or by tolerant train- ing to avoid overfitting <ref type="bibr" target="#b51">(Solodov, 1998)</ref>. As a further measure for comparability of convergence Text classification γ t = 1.0 γ t = 10 −0.75 γ t = 10 −1 CRF OCR T 0 = 0.4, γ t = 10 −3.5 T 0 = 0.1, γ t = 10 −4 λ = 10 −5 , k = 10 −2 , γ t = 10 −6 Chunking γ t = 10 −4 γ t = 10 −4 λ = 10 −6 , k = 10 −2 , γ t = 10 −6 SMT News (n-best, dense) γ t = 10 −5 γ t = 10 −4.75 λ = 10 −4 , µ = 0.99, γ t = 10 −6 / √ t News (h-graph, sparse) γ t = 10 −5 γ t = 10 −4 λ = 10 −6 , k = 5 · 10 −3 , γ t = 10 −6 <ref type="table">Table 1</ref>: Metaparameter settings determined on dev sets for constant learning rate γ t , temperature co- efficient T 0 for annealing under the schedule T = T 0 / 3 √ epoch + 1 <ref type="bibr" target="#b44">(Rose, 1998;</ref><ref type="bibr" target="#b2">Arun et al., 2010)</ref>, <ref type="bibr" target="#b41">Polyak, 1964;</ref><ref type="bibr" target="#b52">Sutskever et al., 2013</ref>), clipping con- stant k used to replace p wt (˜ y t |x t ) with max{p wt (˜ y t |x t ), k} in line 7 of Algorithm 3 (Ionides, 2008), 2 regularization constant λ. Unspecified parameters are set to zero.</p><formula xml:id="formula_16">momentum coefficient min{1 − 1/(t/2 + 2), µ} (</formula><p>speeds across algorithms, we employ small con- stant learning rates in all experiments. The use of constant learning rates for Algorithms 1 and 2 is justified by the analysis of <ref type="bibr" target="#b21">Ghadimi and Lan (2012)</ref>. For Algorithm 3, the use of constant learn- ing rates effectively compares convergence speed towards an area in close vicinity of a local mini- mum in the search phase of the algorithm <ref type="bibr" target="#b7">(Bottou, 2004</ref>). The development data are also used for meta- parameter search. Optimal configurations are listed in <ref type="table">Table 1</ref>. Final testing was done by com- puting ∆ on a further unseen test set using the model found by online-to-batch conversion. For bandit-type algorithms, final results are averaged over 3 runs with different random seeds. For sta- tistical significance testing of results against base- lines we use Approximate Randomization testing <ref type="bibr" target="#b38">(Noreen, 1989)</ref>.</p><p>Multiclass classification. Multiclass text clas- sification on the Reuters RCV1 dataset ( <ref type="bibr" target="#b33">Lewis et al., 2004</ref>) is a standard benchmark for (sim- plified) structured prediction that has been used in a bandit setup by <ref type="bibr" target="#b29">Kakade et al. (2008)</ref>. The simplified problem uses a binary ∆ function in- dicating incorrect assignment of one out of 4 classes. Following <ref type="bibr" target="#b29">Kakade et al. (2008)</ref>, we used documents with exactly one label from the set of labels {CCAT, ECAT, GCAT, MCAT} and con- verted them to tfidf word vectors of dimension 244,805 in training. The data were split into the sets train (509,381 documents from original test pt <ref type="bibr">[0]</ref><ref type="bibr">[1]</ref><ref type="bibr">[2]</ref>.dat files), dev (19,486 docs: every 8th entry from test pt3.dat and test (19,806 docs from train.dat).</p><p>As shown in <ref type="table">Table 2</ref> (row 1), all loss results are small and comparable since the task is relatively easy. For comparison, the partial information classification algorithm Banditron ( <ref type="bibr" target="#b29">Kakade et al., 2008</ref>) (after adjusting the exploration/exploitation constant on the dev set) scored 0.047 on the test set. However, our main interest is in convergence speed. <ref type="table" target="#tab_2">Table 3</ref> (row 1) shows that pairwise rank- ing (Algorithm 2) yields fastest convergence by a factor of 2-4 compared to the other bandit algo- rithms. <ref type="table">Table 1</ref> confirms that this improvement is not attributable to larger learning rates (Algo- rithm 2 employs a similar or smaller learning rate than Algorithms 1 and 3, respectively.)</p><p>Sequence labeling for OCR and chunking. Handwritten optical character recognition (OCR) is a standard benchmark task for structured pre- diction ( <ref type="bibr" target="#b55">Taskar et al., 2003)</ref>, where the Ham- ming distance between the predicted word and the gold standard labeling (normalized by word length) is assumed as the ∆ function. We used their dataset of 6,876 handwritten words, from 150 human subjects, under a split where 5,546 exam- ples (folds 2-9) were used as train set, 704 exam- ples (fold 1) as dev, and 626 (fold 0) as test set. We assumed the classical linear-chain Conditional Random Field (CRF) ( <ref type="bibr" target="#b31">Lafferty et al., 2001</ref>) model with input images x i at every ith node, tabular state-transition probabilities between 28 possible labels of the (i − 1)th and ith node (Latin letters plus two auxiliary start and stop states). <ref type="bibr">3</ref> To test the CRF-based model also with sparse features, we followed Sha and Pereira <ref type="bibr">(2003)</ref> in applying CRFs to the noun phrase chunking task</p><note type="other">task gain/loss full information partial information Alg. 1</note><p>Alg. 2 Alg. 3</p><p>Text classification 0/1 ↓ percep., λ = 10 −6 0.040 0.0306 ±0.0004 0.083 ±0.002 0.035 <ref type="bibr">±0</ref>  <ref type="table">Table 2</ref>: Test set evaluation for full information lower and upper bounds and partial information bandit learners (expected loss, pairwise loss, cross-entropy). ↑ and ↓ indicate the direction of improvement for the respective evaluation metric.</p><p>on the CoNLL-2000 dataset <ref type="bibr">4</ref> . We split the origi- nal training set into a dev set (top 1,000 sent.) and used the rest as train set (7,936 sent.); the test set was kept intact (2,012 sent.). For an input sentence x, each CRF node x i carries an observable word and its part-of-speech tag, and has to be assigned a chunk tag c i out of 3 labels: Beginning, Inside, or Outside (of a noun phrase). Chunk labels are not nested. As in Sha and Pereira <ref type="formula" target="#formula_2">(2003)</ref>, we use second order Markov dependencies (bigram chunk tags), such that for sentence position i, the state is y i = c i−1 c i , increasing the label set size from 3 to 9. Out of the full list of Sha and Pereira (2003)'s features we implemented all except two feature templates, y i = y and c(y i ) = c, to simplify im- plementation. Impossible bigrams (OI) and label transitions of the pattern O → I were prohib- ited by setting the respective potentials to −∞. As the active feature count in the train set was just un- der 2M, we hashed all features and weights into a sparse array of 2M entries. Despite the reduced train size and feature set, and hashing, our full in- formation baseline trained with log-likelihood at- tained the test F1-score of 0.935, which is compa- rable to the original result of 0.9438. <ref type="table">Table 2</ref> (rows 2-3) and <ref type="table" target="#tab_2">Table 3</ref> (rows 2-3) show evaluation and convergence results for the OCR and chunking tasks. For the chunking task, the F1- score results obtained for bandit learning are close to the full-information baseline. For the OCR task, bandit learning does decrease Hamming loss, but it does not quite achieve full-information perfor- mance. However, pairwise ranking (Algorithm 2) again converges faster than the alternative bandit algorithms by a factor of 2-4, despite similar learn- ing rates for Algorithms 1 and 2 and a compensa-   Discriminative ranking for SMT. Following <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref>, we apply bandit learning to simulate personalized MT where a given SMT system is adapted to user style and domain based on feedback to predicted translations. We per- form French-to-English domain adaptation from Europarl to NewsCommentary domains using the data of <ref type="bibr" target="#b30">Koehn and Schroeder (2007)</ref>. One differ- ence of our experiment compared to <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> is our use of the SCFG decoder cdec ( <ref type="bibr" target="#b18">Dyer et al., 2010</ref>) (instead of the phrase-based Moses decoder). Furthermore, in addition to ban- dit learning for re-ranking on unique 5,000-best lists, we perform ranking on hypergraphs with re- decoding after each update. Sampling and com- putation of expectations on the hypergraph uses the Inside-Outside algorithm over the expectation semiring ( <ref type="bibr" target="#b34">Li and Eisner, 2009)</ref>. The re-ranking model used 15 dense features (6 lexicalized re- ordering features, two (out-of-and in-domain) lan- guage models, 5 translation model features, dis- tortion and word penalty). The hypergraph ex- periments used additionally lexicalized sparse fea- tures: rule-id features, rule source and target bi- gram features, and rule shape features. For all SMT experiments we tokenized, lower- cased and aligned words using cdec tools, trained 4-gram in-domain and out-of-domain language models (on the English sides of Europarl and in-domain NewsCommentary) For dense feature models, the out-of-domain baseline SMT model was trained on 1.6M parallel Europarl data and tuned with cdec's lattice MERT <ref type="bibr" target="#b39">(Och, 2003)</ref> on out-of-domain Europarl dev2006 dev set (2,000 sent.). The full-information in-domain SMT model tuned by MERT on news in-domain sets (nc-dev2007, 1,057 sent.) gives the range of possible improvements by the difference of its BLEU score to the one of the out-of-domain model (2.5 BLEU points). For sparse feature models, in-domain and out-of-domain baselines were trained on the same data using MIRA <ref type="bibr" target="#b13">(Chiang, 2012</ref>). The in-domain MIRA model contains 133,531 active features, the out-of-domain MIRA model 214,642. MERT and MIRA runs for both settings were repeated 7 times and median results are reported.</p><p>Learning under bandit feedback starts at the learned weights of the out-of-domain median models. It uses the parallel in-domain data (news-commentary, 40,444 sent.) to simu- late bandit feedback, by evaluating the sampled translation against the reference using as loss func- tion ∆ a smoothed per-sentence 1 − BLEU (zero n-gram counts being replaced with 0.01). For pairwise preference learning we use binary feed- back resulting from the comparison of the BLEU scores of the sampled translations. To speed up training for hypergraph re-decoding, the train- ing instances were reduced to those with at most 60 words (38,350 sent.). Training is distributed across 38 shards using multitask-based feature se- lection for sparse models <ref type="bibr" target="#b47">(Simianer et al., 2012)</ref>, where after each epoch of distributed training, the top 10k features across all shards are se- lected, all other features are set to zero. The meta-parameters were adjusted on the in-domain dev sets (nc-devtest2007, 1,064 parallel sen- tences). The final results are obtained on separate in-domain test sets (nc-test2007, 2,007 sen- tences) by averaging three independent runs for the optimal dev set meta-parameters.</p><p>The results for n-best re-ranking in <ref type="table">Table 2</ref> (4th row) show statistically significant improve- ments of 1-2 BLEU points over the out-of-domain SMT model (that includes an in-domain language model) for all bandit learning methods, confirm- ing the results of <ref type="bibr" target="#b49">Sokolov et al. (2015)</ref> for a differ- ent decoder. Similarly, the results for hypergraph re-coding with sparse feature models (row 5 in <ref type="table">Table 2</ref>) show significant improvements over the out-of-domain baseline for all bandit learners. Ta- ble 3 (row 4) shows the convergence speed for n- best re-ranking, which is similar for Algorithms 2 and 3, and improved over Algorithm 1 by a factor of 3. For hypergraph re-decoding, <ref type="table" target="#tab_2">Table 3 (row 5)</ref> shows fastest convergence for Algorithm 2 com-pared to Algorithms 1 and 3 by a factor of 2-4. <ref type="bibr">5</ref> Again, we note that for both n-best re-ranking and hypergraph re-decoding, learning rates are similar for Algorithms 1 and 2, and smaller learning rates in Algorithm 3 are compensated by variance re- duction or regularization. <ref type="figure" target="#fig_2">Figure 1</ref> shows the learning curves of BLEU for SMT hypergraph re-decoding on the development set that were used to find the stopping points. For each algorithm, we show learning curves for three runs with different random seeds, together with an average learning curve. We see that Algorithm 2, optimizing the pairwise preference ranking objec- tive, reaches the stopping point of peak perfor- mance on development data fastest, followed by Algorithms 1 and 3. Furthermore, the larger vari- ance of the runs of Algorithm 3 is visible, despite the smallest learning rate used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented objectives and algorithms for struc- tured prediction from bandit feedback, with a fo- cus on improving convergence speed and ease of elicitability of feedback. We investigated the per- formance of all algorithms by test set performance on different tasks, however, the main interest of this paper was a comparison of convergence speed across different objectives by early stopping on a convergence criterion based on heldout data per- formance. Our experimental results on different NLP tasks showed a consistent advantage of con- vergence speed under this criterion for bandit pair- wise preference learning. In light of the standard stochastic approximation analysis, which predicts a convergence advantage for strongly convex ob- jectives over convex or non-convex objectives, this result is surprising. However, the result can be ex- plained by considering important empirical factors such as the variance of stochastic updates. Our experimental results support the numerical results of smallest stochastic variance and fastest conver- gence in gradient norm ( <ref type="bibr" target="#b50">Sokolov et al., 2016</ref>) by consistent fastest empirical convergence for ban- dit pairwise preference learning under the criterion of early stopping on heldout data performance. Given the advantages of faster convergence and the fact that only relative feedback in terms of comparative evaluations is required, bandit pair-wise preference learning is a promising framework for future real-world interactive learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>4</head><label></label><figDesc>http://www.cnts.ua.ac.be/conll2000/ chunking/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Learning curves for task loss BLEU on development data for SMT hypergraph re-decoding models, together with averages over three runs of the respective algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Number of iterations required to meet stopping criterion on development data. tion of smaller learning rates in Algorithm 3 by variance reduction and regularization.</figDesc><table></table></figure>

			<note place="foot" n="2"> See Szepesvári (2009) for an overview of algorithms for reinforcement learning and their relation to bandit learning.</note>

			<note place="foot" n="3"> The feature set is composed of a 16 × 8 binary pixel representation for each character, yielding 28×16×8+28 2 = 4, 368 features for the training set. We based our code on the pystruct kit (Müller and Behnke, 2014).</note>

			<note place="foot" n="5"> The faster convergence speed hypergraph re-decoding compared to n-best re-ranking is due to the distributed feature selection and thus orthogonal to the comparison of objective functions that is of interest here.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported in part by the Ger-man research foundation (DFG), and in part by a research cooperation grant with the Amazon De-velopment Center Germany.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Optimal algorithms for online convex optimization with multi-point bandit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<meeting><address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Taming the monster: A fast and simple algorithm for contextual bandits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyen</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A unified approach to minimum risk training and decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on SMT and Metrics (MATR)</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Finite-time analysis of the multiarmed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolo</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="235" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The nonstochastic multiarmed bandit problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolo</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. on Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="77" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Online adaptation to post-edits for phrase-based statistical machine translation. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Simianer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Wäschle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="309" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neuro-Dynamic Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Athena Scientific</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stochastic learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Lectures on Machine Learning</title>
		<editor>Olivier Bousquet, Ulrike von Luxburg, and Gunnar Rätsch</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="146" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL, Suntec</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Regret analysis of stochastic and nonstochastic multiarmed bandit problems. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastian</forename><surname>Bubeck Andnicoì O Cesa-Bianchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combinatorial bandits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Nicoì O Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lugosi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="1401" to="1422" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to search better than your teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simple and scalable response prediction for display advertising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eren</forename><surname>Masnavoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>and Romer Rosales</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hope and fear for discriminative training of statistical translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1159" to="1187" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Magnitude-preserving ranking algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asish</forename><surname>Rastogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Corvallis, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The price of bandit information for online optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Dani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">P</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sham</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning from post-editing: Online model adaptation for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<meeting><address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal rates for zero-order convex optimization: The power of two function evaluations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Wibisono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Translactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2788" to="2806" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendra</forename><surname>Setiawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Demo</title>
		<meeting><address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="933" to="969" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Preference learning and ranking by pairwise comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Fürnkranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyke</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Preference Learning</title>
		<editor>Johannes Fürnkranz and Eyke Hüllermeier</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stochastic first-and zeroth-order methods for nonconvex stochastic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Ghadimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanghui</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. on Optimization</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2342" to="2368" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Softmaxmargin training for structured log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno>CMU-LTI-10-008</idno>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Human effort and machine learnability in computer aided translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Heer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Maximum expected BLEU training of phrase and lexicon translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large margin rank boundaries for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="115" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Truncated importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">L</forename><surname>Ionides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Comp. and Graph. Stat</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="295" to="311" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Query complexity of derivative-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">G</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<meeting><address><addrLine>Lake Tahoe, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Efficient bandit algorithms for online multiclass prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Experiments in domain adaptation for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The epochgreedy algorithm for contextual multi-armed bandits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">RCV1: A new benchmark collection for text categorization research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">First-and secondorder expectation semirings with applications to minimum-risk training on translation forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A contextual-bandit approach to personalized news article recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<meeting><address><addrLine>Raleigh, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From on-line to batch learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Littlestone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<meeting><address><addrLine>Santa Cruz, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">pystruct-learning structured prediction in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="2055" to="2060" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Computer Intensive Methods for Testing Hypotheses. An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Pseudogradient adaptation and training algorithms. Automation and remote control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yakov</forename><forename type="middle">Z</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsypkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="377" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Some methods of speeding up the convergence of iteration methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">USSR Comp. Math. and Math. Phys</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Introduction to Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Optimization Software, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sequence level training with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Deterministic annealing for clustering, compression, classification, regression and related optimization problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Rose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>IEEE</publisher>
			<biblScope unit="page">86</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Shallow parsing with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Online learning and online convex optimization. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="107" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Simianer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Minimum risk annealing for training log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-ACL</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Bandit structured prediction for learning from user feedback in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanguy</forename><surname>Urvoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit XV</title>
		<meeting><address><addrLine>Miami, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Stochastic structured prediction under bandit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<idno>abs/1606.00739</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Incremental gradient algorithms with stepsizes bounded away from zero</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mikhail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solodov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="23" to="35" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Atlanta, GA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Algorithms for Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Csaba</forename><surname>Szepesvári</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Morgan &amp; Claypool</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Max-margin markov networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A law of comparative judgement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Louis Leon Thurstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="278" to="286" />
			<date type="published" when="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Interactively optimizing information retrieval systems as a dueling bandits problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Probabilistic models of vision and max-margin methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Electrical and Electronic Engineering</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="106" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
