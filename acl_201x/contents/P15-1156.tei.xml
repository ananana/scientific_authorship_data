<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Prediction of Acceptability Judgements</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey</forename><forename type="middle">Han</forename><surname>Lau</surname></persName>
							<email>jeyhan.lau@gmail.com, alexsclark@gmail.com, shalom.lappin@kcl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">King&apos;s College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King&apos;s College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalom</forename><surname>Lappin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King&apos;s College London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Prediction of Acceptability Judgements</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1618" to="1628"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we present the task of un-supervised prediction of speakers&apos; acceptability judgements. We use a test set generated from the British National Corpus (BNC) containing both grammatical sentences and sentences containing a variety of syntactic infelicities introduced by round trip machine translation. This set was annotated for acceptability judgements through crowd sourcing. We trained a variety of unsupervised language models on the original BNC, and tested them to see the extent to which they could predict mean speakers&apos; judgements on the test set. To map probability to acceptability, we experimented with several normalisa-tion functions to neutralise the effects of sentence length and word frequencies. We found encouraging results with the unsu-pervised models predicting acceptability across two different datasets. Our methodology is highly portable to other domains and languages, and the approach has potential implications for the representation and the acquisition of linguistic knowledge .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language modelling involves predicting the prob- ability of a sentence. Given a trained model, we can infer the quantitative likelihood that a sentence occurs. Acceptability, on the other hand, indicates the extent to which a sentence is permissible or ac- ceptable to native speakers of the language. While acceptability is affected by frequency and exhibits gradience <ref type="bibr" target="#b12">(Keller, 2001;</ref><ref type="bibr" target="#b24">Sprouse, 2007;</ref><ref type="bibr" target="#b16">Lau et al., 2014</ref>), there is limited research on the relationship between acceptability and probability. In this pa- per, we consider the the task of unsupervised pre- diction of acceptability.</p><p>Speakers have robust intuitions about accept- ability, and acceptability has been consistently rated on various scales <ref type="bibr" target="#b23">(Sprouse and Almeida, 2012)</ref>. The acceptability of a sentence appears to be relatively unaffected by its length (within cer- tain bounds), or the frequency of its words, prop- erties that we have confirmed experimentally. By contrast sentence probability does depend on these factors. To filter the effects of sentence length and word frequency, we devise normalising functions to map the probability of a sentence (inferred by our unsupervised language models) to an accept- ability score. <ref type="bibr" target="#b12">Keller (2001)</ref> and <ref type="bibr" target="#b16">Lau et al. (2014)</ref> present ev- idence that acceptability exhibits gradience. Ac- cordingly, we treat acceptability as a continuous variable here. We train a variety of unsuper- vised models for the acceptability prediction task, and we assess the performance of these models by measuring the correlation between their nor- malised acceptability scores and the mean crowd- sourced acceptability judgements on a set of test sentences.</p><p>There are a number of NLP tasks to which our work can be fruitfully applied. It can be used to evaluate the fluency of the output for machine translation and other language generation systems. It could also contribute to automatic essay scoring, and to second language tutorial systems.</p><p>There are several reasons to favour unsuper- vised models. From an engineering perspective, unsupervised models offer greater portability to other domains and languages. Our methodology takes only unannotated text as input. Extending 1618 our methodology to other domains/languages is therefore straightforward, as it requires only a raw training corpus in that domain/language.</p><p>Our work may also have significant implica- tions for the cognitive foundations of the repre- sentation and acquisition of linguistic knowledge. The unannotated training corpora of our language models are impoverished input in comparison to the data available to humans language learners, who learn from a variety of data sources (vi- sual and auditory cues, interaction with adults and peers in a non-linguistic environment, etc). If an unsupervised language model can reliably predict human acceptability judgements, then it provides a benchmark of what humans could, in principle, achieve with the same learning algorithm.</p><p>Success in this task raises interesting questions about the nature of grammatical knowledge. If ac- ceptability judgments can be accurately modeled through these techniques, then it seems unneces- sary to posit an underlying binary model of syn- tax which enumerates all and only the set of well- formed sentences. Instead it is reasonable to sug- gest that humans represent linguistic knowledge as a probabilistic, rather than as a binary system. Probability distributions provide a natural expla- nation of the gradience that characterises accept- ability judgements. Gradience is intrinsic to prob- ability distributions, and to the acceptability scores that we derive from these distributions.</p><p>While our results raise important questions con- cerning the nature of syntactic representation and of language acquisition, we leave them open for further research. We refrain from making strong claims on cognitive issues here. Clearly addi- tional psychological evidence is required to moti- vate substantive conclusions on these issues, even if our results suggest them.</p><p>Our focus in this paper is on the task of predict- ing speakers' acceptability judgements through unsupervised language models. We take this to be a problem in natural language processing, whose solution has useful applications in language tech- nology. All models described in this paper are im- plemented in an open source toolkit. <ref type="bibr">1</ref> We describe our dataset in Section 2, which consists of crowd sourced acceptability judg- ments applied to sentences with errors introduced through round trip machine translation. We de-scribe the models and their results in Section 3. In Section 4 we present results with a different cor- pus based on English Wikipedia. The new dataset shows that our observations generalise to another domain. We compare our methodology to a super- vised system in the acceptability prediction task in Section 5. We look more closely at the influence of sentence length and lexical frequency in Sec- tion 6, and we show that the normalising functions succeed in neutralising these effects. Finally, we discuss the implications of our results, and draw conclusions from them in Section 7 and Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset and Methodology</head><p>For our experiments, we require a collection of sentences that exhibit varying degrees of gram- matical well-formedness. We use the dataset that we discuss in <ref type="bibr" target="#b16">Lau et al. (2014)</ref>. We translated British National Corpus <ref type="bibr" target="#b1">(BNC Consortium, 2007</ref>) English sentences to four other languages -Nor- wegian, Spanish, Japanese and Chinese -and then back to English using Google Translate. To collect human judgements of acceptability for the sen- tences, we used Amazon Mechanical Turk. A total of 2,500 sentences were annotated.</p><p>Three modes of presentation were used for rat- ing a sentence: (1) binary with two options (un- natural vs. natural); (2) four options (extremely unnatural, somewhat unnatural, somewhat natural and extremely natural); and (3) a sliding scale with two extremes (extremely unnatural and extremely natural). To aggregate the ratings over multiple speakers for each sentence, we computed the arith- metic mean. As there is a high correlation of mean ratings among different modes of presentation, we take the judgements for the four-option mode of presentation as the gold-standard for our experi- ments.</p><p>To predict the ratings of the 2,500 test sen- tences, we trained several probabilistic models on the BNC, and then used the trained models to infer the probabilities of the test sentences. Models are trained on the written portion of the BNC, which has approximately 100 million words (henceforth referred to as BNC-100M). <ref type="bibr">2</ref> We used only the words, and no forms of annotation information in the BNC, as input to training.</p><p>We first experiment with simple lexical N -gram models, and then move to Bayesian and neural network models, increasing the complexity of the models to better capture word dependencies.</p><p>To translate probability into acceptability scores, we compute several acceptability mea- sures extracted from the model parameters. The acceptability measures are variants of the sen- tence's log probability, devised to normalise sen- tence length and low frequency words. These measures are summarised in <ref type="table">Table 1</ref>. For each measure (including LogProb as a baseline) we compute its Pearson correlation coefficient with the gold standard sentence mean rating to evalu- ate its effectiveness in predicting acceptability.</p><p>We tokenised the training data (BNC-100M) and the test sentences using OpenNLP, and we con- verted all words to lower case. To address out of vocabulary (OOV) words that are seen in the test sentences but not in the training data, we adopt the Berkeley Parser approach, where we replace low frequency or OOV words using the UNK sig- nature. We capture additional surface characteris- tics of the original word by attaching features at the end of the signature (e.g. the OOV word 1949 would be replaced by the signature UNK-NUM). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Unsupervised Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lexical N -gram Model</head><p>Lexical N -gram models were variously explored in tasks related to acceptability estimation <ref type="bibr" target="#b11">(Heilman et al., 2014;</ref><ref type="bibr" target="#b3">Clark et al., 2013;</ref><ref type="bibr" target="#b21">Pauls and Klein, 2012)</ref>. We use an N -gram model with Kneser-Ney interpolation <ref type="bibr" target="#b9">(Goodman, 2001</ref>), and we train bigram, trigram, and 4-gram models on BNC-100M. The trained models are then used to compute the acceptability measures of the test sen- tences.</p><p>The results are detailed in <ref type="table" target="#tab_0">Table 2</ref> (columns: "2-gram", "3-gram" and "4-gram"). <ref type="bibr">4</ref> In general across all models, the Norm LP (Div) and SLOR measures consistently produce the best correla- tions.</p><p>We see a significant improvement when the con- text window is increased from 2-gram to 3-gram, but not so from 3-gram to 4-gram (2-gram best: 0.34; 3-gram best: 0.42; 4-gram best: 0.42). This result implies that increasing the context window <ref type="table">Table 1</ref>: Acceptability measures for predicting the acceptability of a sentence. Notations: SLOR is the syntactic log-odds ratio, introduced by Pauls and Klein <ref type="formula">(2012)</ref>; ξ is the sentence (|ξ| is the sen- tence length); P m (ξ) is the probability of the sen- tence given by the model; P u (ξ) is the unigram probability of the sentence. Note that the negative sign in Norm LP (Div) is given to reverse the sign change introduced by the division of log unigram probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acc. Measure Equation</head><formula xml:id="formula_0">LogProb log P m (ξ) Mean LP log P m (ξ) |ξ| Norm LP (Div) − log P m (ξ) log P u (ξ) Norm LP (Sub) log P m (ξ) − log P u (ξ) SLOR log P m (ξ) − log P u (ξ) |ξ|</formula><p>of the lexical N -gram model does not correspond to a better representation of grammatical structure (insofar as the size of the dataset is fixed), and a more sophisticated model is necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bayesian HMM</head><p>Seeing that local context is insufficient for pre- dicting acceptability, we explore various Bayesian models that incorporate richer latent structures. We chose a Bayesian implementation because its "rich gets richer" dynamics tends to work well for languages <ref type="bibr" target="#b7">(Goldwater and Griffiths, 2007;</ref><ref type="bibr" target="#b8">Goldwater et al., 2009;</ref>).</p><p>Lexical N -grams model the generation of a word based on its preceding words. We introduce a layer of latent variables on top of the words, which can be interpreted as the word classes, and we model the transitions between the latent variables and observed words using Markov pro- cesses. In this model we first generate a (latent) word class based on its preceding word classes, and we then generate the word based on its word class. </p><formula xml:id="formula_1">s i−2 s i−1 s i s i+1</formula><p>wi−2 wi−1 wi wi+1</p><p>(b) Bayesian HMM (2nd Order)</p><formula xml:id="formula_2">t i−2 t i−1 t i t i+1 s i−2 s i−1 s i s i+1</formula><p>wi−2 wi−1 wi wi+1</p><p>(c) Two-Tier BHMM <ref type="figure" target="#fig_0">Figure 1</ref>: A comparison of word structures for 3-gram, BHMM and Two-Tier BHMM. w = observed words; s = tier-1 latent states ("word classes"); t = tier-2 latent states ("phrase classes").</p><p>For comparison, the structure of a lexical 3-gram model is given in <ref type="figure" target="#fig_0">Figure 1</ref>(a).</p><p>Goldwater and Griffiths <ref type="formula">(2007)</ref> propose a Bayesian approach for learning the HMM struc- ture. The authors found that their Bayesian HMM (BHMM) significantly outperforms a HMM trained with Maximum Likelihood Estima- tion in unsupervised part-of-speech tagging. We adopt the methodology of <ref type="bibr" target="#b7">Goldwater and Griffiths (2007)</ref>, and train a 2nd order BHMM for our task, using collapsed Gibbs sampling for inference. BHMM has two sets of multinomials: the state transition multinomials and the word emission multinomials. To generalise the state transition probabilities for start probabilities, we use dummy words/states for empty preceding words/states. BHMM has 3 parameters: (1) S, the number of latent states; (2) γ, the Dirichlet hyper-parameter for the state transition multinomials; and (3) δ, the Dirichlet hyper-parameter for the word emis- sion multinomials. We assume symmetric Dirich- let priors for the hyper-parameters, and optimise the 3 parameters based on test perplexity using a greedy search approach, i.e. we optimise locally for one parameter at each stage, while keeping the default or previously optimised values for other parameters. <ref type="bibr">5</ref> For the optimisation step models are trained using 10% of the full BNC (BNC-10M) for 2,000 iterations. <ref type="bibr">6</ref> Using the optimised parameters, we train BHMM on BNC-100M for 10,000 iterations. For test inference, we run the Gibbs sampler using the trained model for 5,000 iterations, and take 50 samples from the final 500 iterations (with a lag of 10 iterations). In each of the samples, we com- pute the test probabilities and acceptability mea- <ref type="bibr">5</ref> When optimising for a parameter, we experimented with 4-6 values of various orders of magnitudes. <ref type="bibr">6</ref> The optimised parameters are: S = 100, γ = 1.0 and δ = 0.01.</p><p>sures using the MAP estimated states. <ref type="bibr">7</ref> The final probabilities are computed as a harmonic mean of probabilities over the 50 samples.</p><p>We summarise the correlation results in <ref type="table" target="#tab_0">Table 2</ref> (column: "BHMM"). Compared to the N -gram models, we see an improvement in the correlation, indicating that the introduction of a layer of (la- tent) word classes produces a better structure for modelling acceptability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">LDAHMM and LDA</head><p>To better understand the role of semantics in acceptability, we experimented with LDAHMM ( <ref type="bibr" target="#b10">Griffiths et al., 2004</ref>), a model that combines syn- tactic and semantic dependencies between words.</p><p>The generative method of LDAHMM to gener- ate a word in a document is to first decide whether to generate a syntactic state or a semantic state for the word. For the former, follow the HMM process to generate a state, and generate the word based on the chosen state. For the latter, follow the LDA ( <ref type="bibr" target="#b0">Blei et al., 2003</ref>) process to generate a topic based on the document's topic mixture, and generate the word based on the chosen topic.</p><p>We use a second order HMM for the HMM part and Collapsed Gibbs sampling for performing in- ference. LDAHMM has 4 sets of multinomials: the HMM multinomials (state transition and word emission) and the LDA multinomials (document- topic and topic-word).</p><p>LDAHMM has 6 parameters to optimise: (1) K the number of topics; (2) S the number of syntactic states (semantic state has only 1 state, designated as state 0); (3) α, the Dirichlet hyper-parameter for document-topic multinomi- als; (4) β, the Dirichlet hyper-parameter for topic- word multinomials; (5) γ, the Dirichlet hyper-   parameter for state transition multinomials; and (6) δ, the Dirichlet hyper-parameter for word emission multinomials. We follow the same ap- proach as with BHMM for optimising, training, and testing the model. 8 Note that as LDAHMM operates with documents, the training data is par- titioned into documents, and each test sentence is treated as a document.</p><p>The results are summarised in <ref type="table" target="#tab_0">Table 2</ref> (column: "LDAHMM"). The result shows that LDAHMM underperforms in comparison to BHMM, indicat- ing that the incorporation of LDA did not improve the model. To understand the impact of LDA alone, we repeat the experiments using LDA and find that it performs very poorly. Results are sum- marised in <ref type="table" target="#tab_0">Table 2</ref> (column: LDA). We suspect that the low performance of LDA and LDAHMM is due to the small context window of the test doc- uments. The LDA part is unable to generate any meaningful topic mixtures, as there is insufficient context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Two-Tier BHMM</head><p>BHMM uses (latent) word classes to drive word generation. Exploring a richer structure, we intro- duce another layer of latent variables on top of the word classes. This second layer can be interpreted as phrase classes. The idea behind this model is to use these phrase classes to drive word class and word generation. An illustration of its word struc- ture is given in <ref type="figure" target="#fig_0">Figure 1(c)</ref>.</p><p>We use collapsed Gibbs sampling for perform- ing inference. We sample the tier-1 state s and tier- 2 state t separately, and the sampling equations are given as follows:</p><formula xml:id="formula_3">P (ti|t −i , s, w, α, γ, δ) ∝ #(ti−1, si−1, ti) + α #(ti−1, si−1) + T α × #(ti, si−1, si) + γ #(ti, si−1) + Sγ × #(ti, si, ti+1) + α #(ti, si) + T α ; P (si|s −i , t, w, α, γ, δ) ∝ #(ti, si−1, si) + γ #(ti, si−1) + Sγ × #(ti, si, ti+1) + α #(ti, si) + T α × #(ti+1, si, si+1) + γ #(ti+1, si) + Sγ × #(si, wi) + δ #(si) + W δ</formula><p>where s i , t i are the tier-1 and tier-2 state indices; s, t, w are the assignments for all tier-1 states, tier-2 states and words, respectively (subscript −i means the current assignment is excluded); α, γ and δ are the Dirichlet hyper-parameters; S = number of tier-1 states; T = number of tier-2 states; W = vocabulary size; and #(x, [y], <ref type="bibr">[z]</ref>) are the multinomial counts. We follow the same process for optimising, training, and testing the model, and we summarise the results in <ref type="table" target="#tab_0">Table 2</ref> (column: "2T"). <ref type="bibr">9</ref> We see an improved correlation relative to BHMM (BHMM best: 0.45, Two-Tier BHMM best: 0.50). In fact it has the best performance of all models thus far. This is encouraging, as it implies that the introduc- tion of the phrase layer produces a more optimal structure for representing acceptability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Bayesian Chunker</head><p>Goldwater et al. <ref type="formula">(2009)</ref> propose a Bayesian ap- proach to segment words in speech streams.  extend the approach to segment phrases -i.e. multiword units -in sentences, and they apply it to the task of index term identification and keyphrase extraction.</p><p>The core machinery of the methodology is driven by the Dirichlet Process, where segments (words in <ref type="bibr" target="#b8">Goldwater et al. (2009)</ref> or phrases in ) are retrieved from a cache, or newly generated. Using Gibbs sampling for in- ference, the sampler considers one boundary point at a time, and computes the probability of two hy- potheses: H 0 , for not generating a boundary; and H 1 , for generating a boundary.</p><p>Borrowing the notation of , given p # is the probability of generating a segment boundary, at the boundary point between words w x and w y , the probability of the hypothe- ses is computed as follows:</p><formula xml:id="formula_4">P (H0|H − ) =</formula><p>n(wxy) + αP0(wxy) n + α ;</p><formula xml:id="formula_5">P (H1|H − ) = n(wx) + αP0(wx) n + α × n(wy) + αP0(wy) n + 1 + α</formula><p>where H − is all of the structure shared by both hypotheses; w xy is a multiword unit consisting of w x and w y ; n is the number of multiword tokens; α is the concentration parameter of the Dirichlet process; n(w) is the count of multiword w; and P 0 (w) is the probability of generating a novel w.</p><p>i.e. P 0 (w xy ) = p # (1 − p # )P (w x )P (w y ).</p><p>We extend their methodology to segment word classes to do unsupervised chunking, motivated by the idea that a well-formed sentence contains predictable patterns of word class chunks. We extend the sampling process to incorporate tran- sitions between chunks. Given the word classes "c w c x c y c z ", at the boundary point between word class c x and c y , the hypothesis H 0 to not gener- ate a boundary (therefore producing a single chunk c xy ), and the hypothesis H 1 to generate a bound- ary (therefore producing two chunks c x and c y ), are computed as follows:</p><formula xml:id="formula_6">P (H0|H − ) = #(cw, cxy) + β n(cxy )+αP 0 (cxy ) n+α #(cw) + mβ × #(cxy, cz) + β n(cz )+αP 0 (cz ) n+α #(cxy) + mβ ; P (H1|H − ) = #(cw, cx) + β n(cx)+αP 0 (cx) n+α #(cw) + mβ × #(cx, cy) + β n(cy )+αP 0 (cy ) n+α #(cx) + mβ × #(cy, cz) + β n(cz )+αP 0 (cz ) n+α #(cy) + mβ</formula><p>where m = number of chunk types; n = num- ber of chunk tokens; β is the Dirichlet hyper- parameter for the chunk transition multinomials; and #(x, <ref type="bibr">[y]</ref>) is the count for the chunk transition multinomials.</p><p>As the model takes word classes as input, we use the word classes induced by two-tier BHMM. We follow the same process for optimising, train- ing and testing the model. <ref type="bibr">10</ref> The results are sum- marised in <ref type="table" target="#tab_0">Table 2</ref> (column: "Chunker"). The model produces a moderate correlation, perform- ing on par with the lexical 4-gram model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Recurrent Neural Network Language Model</head><p>In recent years, we have seen a resurgence in the use of neural networks for deep machine learn- ing and NLP. Rather than designing structures or handcrafting features that seem intuitive for a task, deep learning introduces an entirely general ar- chitecture for machine learning. It has yielded some impressive results for NLP tasks: automatic speech recognition, parsing, part of speech tag- ging, and named entity recognition, to name a few <ref type="bibr" target="#b22">(Seide et al., 2011;</ref><ref type="bibr" target="#b17">Mikolov et al., 2011a;</ref><ref type="bibr" target="#b4">Collobert et al., 2011;</ref><ref type="bibr" target="#b2">Chen and Manning, 2014</ref>).</p><p>We experiment with a recurrent neural net- work language model (RNNLM: <ref type="bibr" target="#b5">(Elman, 1998;</ref><ref type="bibr" target="#b19">Mikolov, 2012)</ref>) for our task. We choose this model because it has an internal state that keeps track of previously observed sequences, which is well suited for natural language problems. To train the model, we use stochastic gradient descent combined with back propagation through time. RNNLM is optimised to reduce the error in pre- dicting the following word, based on the current word and its history (represented in a compressed dimension in the size of the hidden layer). Full details of RNNLM can be found in the original papers ( <ref type="bibr" target="#b18">Mikolov et al., 2011b;</ref><ref type="bibr" target="#b19">Mikolov, 2012)</ref>. <ref type="bibr">11</ref> We experimented with some of the parameters of RNNLM using BNC-10M and found that most parameters have an intuitive setting. Its perfor- mance largely depends on the number of neurons in the hidden layer. Mikolov (2012) introduced a variant of RNNLM that does joint learning with a Maximum Entropy model which learns direct connections of N -gram features. We found that although there are advantages to using the ME model, the benefits disappear as we increase the number of neurons in the hidden layer. We saw optimal performance at 600 neurons, without us- ing the ME model. All our results are based   on the original RNNLM with 600 neurons in the hidden layer, trained on BNC-100M <ref type="table" target="#tab_0">(Table 2</ref> col- umn: "RNNLM"). <ref type="bibr">12</ref> We see that RNNLM per- forms very well. It outperforms the other models, achieving a correlation of 0.53.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">PCFG Parser (Supervised)</head><p>Although we are interested in unsupervised mod- els, for purposes of comparison we experimented with a constituent PCFG parser for our task.</p><p>We use the Stanford Parser ( <ref type="bibr" target="#b13">Klein and Manning, 2003a;</ref><ref type="bibr" target="#b14">Klein and Manning, 2003b)</ref>, and tested both the unlexicalised and lexicalised PCFG parser with the supplied model. To compute the log probability of test sentences, we experimented with both top-1 and top-1K best parses. We found that the unlexicalised variant gives better performance, but we saw little difference between using the top-1 and the top-1K best parses for computing log probability. In <ref type="table" target="#tab_0">Table 2</ref> (col- umn: "PCFG"), we report results for the unlexi- calised variant based on the top-1 best parse. The supervised PCFG parser performs poorly. This is not surprising, given that the parser is trained on a different domain. <ref type="bibr">13</ref> Moreover, the log probabil- ity scores are not true probabilities, but arbitrary values used for ranking the parse trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">English Wikipedia</head><p>For the BNC domain we saw that SLOR and Norm LP (Div) give the best acceptability measures, and that BHMM, two-tier BHMM and RNNLM are the best performing models. These findings are limited to a particular dataset. To better un- derstand if these observations generalise to an- other domain, we developed an English Wikipedia dataset (ENWIKI), following the same process de- scribed in <ref type="bibr" target="#b16">Lau et al. (2014)</ref> to generate test sen- <ref type="bibr">12</ref> Other parameter values of RNNLM: number of classes = 550; bptt = 4; bptt-block = 100. <ref type="bibr">13</ref> The Stanford English model is trained on the parse tree hand annotated WSJ (section 1-21), Genia, and a few other datasets.</p><p>tences through round-trip machine translation ,and to collect annotations via Mechanical Turk. <ref type="bibr">14</ref> As before, we follow the same procedures described in Section 3 to optimise, train, and test all models (excluding LDA and PCFG). The Pearson corre- lations with mean AMT annotations are presented in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>We identify similar trends in ENWIKI: Norm LP (Div) and SLOR are the best acceptability mea- sures, and we see improvements when we use a richer structure in the language model (two- tier BHMM&gt;BHMM&gt;N -grams). Interestingly, LDAHMM performs much better in this domain (possibly due to increased coherence in the docu- ment structure of ENWIKI). RNNLM has the best performance of all models, surpassing two-tier BHMM by a substantial margin. Overall, the cor- relation values are very similar across the two do- mains, indicating that the models and the accept- ability measures are robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comparison with a Supervised System</head><p>Although not a focus of this paper, supervised learning can further improve the correlation per- formance of our models. The acceptability mea- sures can be combined in a supervised context. We experimented with this approach in a support vec- tor regression model (with an RBF kernel). We achieved a correlation performance of 0.64 in BNC and of 0.69 in <ref type="bibr">ENWIKI. 15</ref> Heilman et al. (2014) propose a system for pre- dicting acceptability. They built a dataset con- sisting of sentences from essays written by non- native speakers for an ESL test. Acceptability ratings were judged by the authors, and through crowdsourcing (henceforth we refer to this anno- tated data set as the GUG data set). They applied a 4-category ordinal scale for rating the sentences. To predict sentence acceptability, they employ a linear regression model that draws features from spelling errors, an N -gram model, precision gram- mar parsers, and the Stanford PCFG parser.</p><p>To better understand the performance of our system compared to other acceptability prediction systems, we evaluated our methodology against that of <ref type="bibr" target="#b11">Heilman et al. (2014)</ref> on the GUG dataset. We preprocessed the GUG dataset minimally. We removed 15 short sentences that have less than 5 words, lowercased all words, and tokenised the sentences using OpenNLP. This yields 2255 sen- tences for the training and development subset, and 749 sentences for the test set. Using the out- put -i.e. the acceptability measures -of our un- supervised models (trained on BNC) as features, we trained an SVR model using GUG training and development subsets to predict acceptability rat- ings on GUG test sentences. We applied the de- fault SVR parameters, and so it was not necessary to use the development subset separately to opti- mise the parameters. For evaluation we computed the correlation of the predicted ratings and mean human ratings.</p><p>We present a comparison of results in <ref type="table" target="#tab_4">Table 4</ref>. We first tested the unsupervised models, with the best correlation of 0.472 produced by the lexical 4-gram model using the Norm LP (Div) measure. Combining the models in SVR, we achieve a cor- relation of 0.603. <ref type="bibr" target="#b11">Heilman et al. (2014)</ref> note that spelling is one of the important features in their regression model, as the dataset often contains spelling mistakes. We borrowed this feature, computed as the proportion of misspelled words, and incorporated into our model. It produced a significant improvement in the correlation (0.636), a performance almost on par with that of <ref type="bibr" target="#b11">Heilman et al. (2014)</ref>. <ref type="bibr">16</ref> Our results demonstrate the robustness and portability of our system in a new domain. Our SVR model requires significantly less supervision than that of <ref type="bibr" target="#b11">Heilman et al. (2014)</ref>, which relies on precision and constituent parsers. Moreover, our methodology provides a completely unsupervised alternative that requires only raw text for training. <ref type="bibr">16</ref> We use PyEnchant for spellcheck:</p><p>http: //pythonhosted.org/pyenchant/.</p><p>Note that we also tried adding the spelling feature to our original BNC derived dataset, but it yielded no improvement in the correlation. This is not surprising, given that it contains few spelling errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Pearson's r <ref type="bibr" target="#b11">Heilman et al. (2014)</ref> 0.644 Unsupervised Best 0.472 SVR: All Models 0.603 SVR: All Models+Spell 0.636 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Influence of Sentence Length and Lexical Frequency</head><p>Our primary motivation in doing this research has been to use acceptability predictions to explore whether acceptability can be represented through probability information. Unlike probability, ac- ceptability is generally not influenced by sentence length or low frequency words. The acceptability measures we apply normalise sentence length and word frequency. To evaluate their effectiveness, we computed two correlations in the BNC domain: (1) acceptability measure vs. sentence length <ref type="table" target="#tab_6">(Table 5)</ref>; and (2) acceptability measure vs. sentence minimum word frequency <ref type="table" target="#tab_7">(Table 6</ref>). <ref type="bibr">17</ref> For comparison we additionally computed the correlation of these factors with human ratings. The correlations are: +0.13 with sentence length; and +0.07 with minimum word frequency. These observations confirm the view that acceptability is not affected by these two factors. <ref type="table" target="#tab_6">Table 5</ref> shows that although LogProb yields a strong negative correlation with sentence length, Mean LP, Norm LP (Div) and SLOR all produce low correlations. The only exception is Norm LP (Sub), which still has a significant correlation with sentence length.</p><p>In <ref type="table" target="#tab_7">Table 6</ref> we see some degree of correlation in LogProb with the minimum word frequency, but it is relatively small. In general, SLOR is the scoring function that most effectively normalises word fre- quency, producing low correlation for most mod- els. Norm LP (Div) also does very well, for all models except N -grams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>In principle, the upper bound of the correlation be- tween our models' predicted acceptability values and mean human ratings is 1.0. But no individual human annotator will match mean judgements per- fectly. It is more plausible to measure our models'    rate of success against an estimated level of indi- vidual human performance. We do this by mim- icking an arbitrary speaker, and testing the corre- lation of this construct's judgements with the mean scores of the annotators. We simulate such an individual human judge by randomly selecting a single annotator rating for each sentence, and computing the Pearson corre- lation between these judgements and the mean rat- ings for the rest of the annotators (one vs the rest) in our test sets. We ran this experiment 50 times for each test set to reduce sample variation, pro- ducing a mean correlation of 0.67 for BNC and 0.74 for ENWIKI. For comparison, the best unsu- pervised model (RNNLM) achieves a correlation of 0.53 in BNC and 0.57 in ENWIKI (Section 3). The supervised model (SVR) produces a correla- tion of 0.64 in BNC and 0.69 in ENWIKI (Section 5). Although there is still room for improvement for the unsupervised methodology, it is encouraging to note that the supervised variant predicts accept- ability at a level that approaches estimated human performance.</p><p>To test the robustness of our methodology across languages, we are currently developing datasets in other languages, based on Wikipedia. Our preliminary results show similar performance to that which we report here for ENWIKI, suggesting that these results hold across languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We developed a methodology for using unsuper- vised language models to predict human accept- ability judgements. We experimented with a va- riety of unsupervised models. To map proba- bility to acceptability we proposed a set of ac- ceptability measures to normalise sentence length and lexical frequency. We achieved encourag- ing results across two datasets constructed through round trip machine translation, and the methodol- ogy is highly portable to other domains and lan- guages. This research has potential implications for our understanding of human language acquisi- tion and the way in which linguistic knowledge is represented.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 (</head><label>1</label><figDesc>b) illustrates the structure of a second order Hidden Markov model (HMM). 1620 wi−2 wi−1 wi wi+1 (a) Lexical 3-gram</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Measure</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2T</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2T</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>2 -gram 3-gram 4-gram BHMM LDA LDAHMM</head><label>2</label><figDesc></figDesc><table>2T 
Chunker RNNLM PCFG* 
LogProb 
0.24 
0.30 
0.32 
0.25 
0.09 
0.21 
0.26 
0.32 
0.32 
0.21 
Mean LP 
0.26 
0.35 
0.37 
0.26 
0.14 
0.19 
0.31 
0.42 
0.39 
0.18 
Norm LP (Div) 
0.33 
0.42 
0.42 
0.44 
0.05 
0.33 
0.50 
0.43 
0.53 
0.26 
Norm LP (Sub) 
0.12 
0.20 
0.23 
0.33 
0.01 
0.19 
0.46 
0.14 
0.31 
0.22 
SLOR 
0.34 
0.41 
0.41 
0.45 
0.03 
0.33 
0.50 
0.42 
0.53 
0.25 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Pearson's r of acceptability measure and mean sentence rating for all experimented models in BNC. Boldface 

indicates the best performing measure. Note that PCFG is a supervised model unlike the others. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Pearson's r of acceptability measure and mean sentence rating for all experimented models in ENWIKI. Boldface 

indicates the best performing measure. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>A comparison of results of our system and Heil-

man et al. (2014) on GUG. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Pearson's r of acceptability measure and sentence length for all models in BNC. For comparison the correlation 

with human ratings is +0.13. 

Measure 2-gram 3-gram 4-gram BHMM LDAHMM 
2T 
Chunker RNNLM 
LogProb 
+0.27 
+0.27 
+0.27 
+0.27 
+0.27 
+0.27 
+0.19 
+0.28 
Mean LP 
+0.30 
+0.28 
+0.27 
+0.29 
+0.28 
+0.29 
+0.08 
+0.26 
Norm LP (Div) 
+0.24 
+0.23 
+0.21 
+0.11 
+0.06 
+0.12 
+0.06 
+0.11 
Norm LP (Sub) 
−0.04 
−0.03 
−0.03 
−0.03 
−0.09 
+0.05 
−0.13 
−0.08 
SLOR 
+0.16 
+0.14 
+0.12 
+0.06 
±0.00 
+0.10 
+0.04 
+0.03 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Pearson's r of acceptability measure and sentence minimum word frequency for all models in BNC. The correlation 

with the human ratings is +0.07. 

</table></figure>

			<note place="foot" n="1"> This toolkit can be accessed at https://github. com/jhlau/acceptability_prediction.</note>

			<note place="foot" n="2"> We removed sentences with less than 8 words, as well as the 2,500 test sentences, from the training data.</note>

			<note place="foot" n="3"> Low frequency words are defined as words occurring less than 4 times in the BNC training data. A total of 15 features are used for the UNK signature. 4 We do not present model perplexity values in the results, as we did not find any correlation between perplexity and task performance.</note>

			<note place="foot" n="7"> As computing full probabilities gave little difference in the final outcome, we adopted the computationally more efficient MAP approach.</note>

			<note place="foot" n="8"> The final optimised parameters are: K = 100, S = 80, α = 0.1, β = 0.0001, γ = 0.1, and δ = 0.01.</note>

			<note place="foot" n="9"> The optimised parameters: S = 100, T = 60, α = 1.0, γ = 1.0, δ = 0.01.</note>

			<note place="foot" n="10"> The optimised parameters are: α = 0.1, β = 0.001, p # = 0.5. 11 We use Mikolov&apos;s implementation of RNNLM for our experiment: http://rnnlm.org/.</note>

			<note place="foot" n="14"> Both the BNC and the English Wikipedia datasets are available at http://www.dcs.kcl.ac.uk/staff/ lappin/smog/?page=research. 15 We use only the unsupervised models, excluding the supervised PCFG parser. The models are trained and tested using 10-fold cross validation.</note>

			<note place="foot" n="17"> We use BNC-100M for computing word frequency.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research reported here was done as part of the Statisticsal Models of Grammar (SMOG) project at King's College Lon-don (www.dcs.kcl.ac.uk/staff/lappin/smog/), funded by grant ES/J022969/1 from the Economic and So-cial Research Council of the UK.</p><p>We are grateful to Douglas Saddy and Garry Smith at the Centre for Integrative Neuroscience and Neurodynamics at the University of Reading for generously giving us access to their computing cluster, and for much helpful technical sup-port. We thank J. David Lappin for invaluable assistance in organising our AMT HITS. We presented part of the work discussed here to CL/NLP, cognitive science, and machine learning colloquia at Chalmers University of Technology, University of Gothenburg, University of Sheffield, University of Edinburgh, The Weizmann Institute of Science, University of Toronto, MIT, and the ILLC at the University of Amster-dam. We very much appreciate the comments and criticisms that we received from these audiences, which have guided us in our research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The British National Corpus, version 3 (BNC XML Edition)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bnc Consortium</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Distributed by Oxford University Computing Services on behalf of the BNC Consortium</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical representation of grammaticality judgements: The limits of n-gram models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluca</forename><surname>Giorgolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalom</forename><surname>Lappin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Cognitive Modelling and Computational Linguistics</title>
		<meeting>the ACL Workshop on Cognitive Modelling and Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalization, simple recurrent networks, and the emergence of structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th</title>
		<editor>M. Gernsbacher and S. Derry</editor>
		<meeting>the 20th</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Annual Conference of the Cognitive Science Society</title>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Mahway, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A fully Bayesian approach to unsupervised part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL 2007)</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics (ACL 2007)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="744" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Bayesian framework for word segmentation: Exploring the effects of context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="21" to="54" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A bit of progress in language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="403" to="434" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integrating topics and syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="537" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting grammaticality on an ordinal scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoife</forename><surname>Cahill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mulholland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="174" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Gradience in Grammar: Experimental and Computational Aspects of Degrees of Grammaticality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>The University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003)</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003)<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast exact inference with a factored model for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 15 (NIPS-03)</title>
		<meeting><address><addrLine>Whistler, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Word sense induction for novel sense detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the EACL (EACL 2012)</title>
		<meeting>the 13th Conference of the EACL (EACL 2012)<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="591" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Measuring gradience in speakers&apos; grammaticality judgements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lappin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 36th Annual Conference of the Cognitive Science Society<address><addrLine>Quebec City, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="821" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Empirical evaluation and combination of advanced language modeling techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kombrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eernock´yeernock´y</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH 2011)</title>
		<meeting>the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH 2011)<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="605" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rnnlm-recurrent neural network language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kombrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deoras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eernock´yeernock´y</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Automatic Speech Recognition and Understanding Workshop</title>
		<meeting><address><addrLine>Hawaii, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Statistical Language Models based on Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>Brno University of Technology</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian text segmentation for index term identification and keyphrase extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Koilada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jey</forename><forename type="middle">Han</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012)</title>
		<meeting>the 24th International Conference on Computational Linguistics (COLING 2012)<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2077" to="2092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Large-scale syntactic language modeling with treelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pauls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="959" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conversational speech transcription using context-dependent deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual Conference of the International Speech Communication Association</title>
		<meeting>the 12th Annual Conference of the International Speech Communication Association<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Assessing the reliability of textbook data in syntax: Adger&apos;s core syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sprouse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Linguistics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="609" to="652" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Continuous acceptability, categorical grammaticality, and experimental syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sprouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biolinguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="123" to="134" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
