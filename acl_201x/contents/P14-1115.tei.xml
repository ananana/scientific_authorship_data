<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Abstractive Summarization of Spoken and Written Conversations Based on Phrasal Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia Vancouver</orgName>
								<address>
									<postCode>V6T 1Z4</postCode>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia Vancouver</orgName>
								<address>
									<postCode>V6T 1Z4</postCode>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of British Columbia Vancouver</orgName>
								<address>
									<postCode>V6T 1Z4</postCode>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Abstractive Summarization of Spoken and Written Conversations Based on Phrasal Queries</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1220" to="1230"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a novel abstractive query-based summarization system for conversations , where queries are defined as phrases reflecting a user information needs. We rank and extract the utterances in a conversation based on the overall content and the phrasal query information. We cluster the selected sentences based on their lexical similarity and aggregate the sentences in each cluster by means of a word graph model. We propose a ranking strategy to select the best path in the constructed graph as a query-based abstract sentence for each cluster. A resulting summary consists of abstractive sentences representing the phrasal query information and the overall content of the conversation. Automatic and manual evaluation results over meeting, chat and email conversations show that our approach significantly outperforms baselines and previous extractive models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our lives are increasingly reliant on multimodal conversations with others. We email for business and personal purposes, attend meetings in per- son, chat online, and participate in blog or forum discussions. While this growing amount of per- sonal and public conversations represent a valu- able source of information, going through such overwhelming amount of data, to satisfy a partic- ular information need, often leads to an informa- tion overload problem ( <ref type="bibr" target="#b14">Jones et al., 2004</ref>). Au- tomatic summarization has been proposed in the past as a way to address this problem (e.g., <ref type="bibr" target="#b25">(Sakai and Sparck-Jones, 2001)</ref>). However, often a good summary cannot be generic and should be a brief and well-organized paragraph that answer a user's information need.</p><p>The Document Understanding Conference (DUC) 1 has launched query-focused multidocu- ment summarization as its main task since 2004, by focusing on complex queries with very specific answers. For example, "How were the bombings of the US embassies in Kenya and Tanzania conducted? How and where were the attacks planned?". Such complex queries are appropriate for a user who has specific information needs and can formulate the questions precisely. However, especially when dealing with conversational data that tend to be less structured and less topically focused, a user is often initially only exploring the source documents, with less specific information needs. Moreover, following the common practice in search engines, users are trained to form simpler and shorter queries <ref type="bibr" target="#b21">(Meng and Yu, 2010)</ref>. For example, when a user is interested in certain characteristics of an entity in online reviews (e.g., "location" or "screen") or a specific entity in a blog discussion (e.g., "new model of iphone"), she would not initially compose a complex query.</p><p>To address these issues, in this work, we tackle the task of conversation summarization based on phrasal queries. We define a phrasal query as a concatenation of two or more keywords, which is a more realistic representation of a user's informa- tion needs. For conversational data, this definition is more similar to the concept of search queries in information retrieval systems as well as to the con- cept of topic labels in the task of topic modeling. Example 1 shows two queries and their associated human written summaries based on a single chat log. We can observe that the two summaries, al- though generated from the same chat log, are to- tally distinct. This further demonstrates the impor- tance of phrasal query-based summarization sys- tems for long conversations.</p><p>To date, most systems in the area of summa-Query-1: Test/Sample database for GNUe Abstract-1: James Thompson asked Reinhard: I was going to work on the sample tonight. You mentioned wanting a fishhook and all data types. Any other things you want to see in there? Reinhard said that master/detail would be good, as there have been bugs only appearing in 3-level case. James said he already included that and I know I need to add a boolean. Did you want date as well as date-time? Reinhard said yes -we also have time values (time without date). They are especially interesting. James had not ever had use for something like that so I'm not sure where I would graft that in. Query-2: Passing parameters to Forms Abstract-2: James Thompson (jamest) asked how did parameter sup- port in forms change recently? He reported the trigger namespace func- tion referencesGFForm.parameters -which no longer exists. Reinhard said every GFForm should have a parameters. James said he was using parameters in on-startup. Reinhard said that's probably the only place where they don't work. James said that I'm thinking about moving that to on-activation instead of on-startup anyway as it should still work for a main form -but i still wonder if the on-startup parameter issue should be considered a bug -as it shouldn't choke. Reinhard was sure it should be considered a bug but I have no idea how to fix it. We haven't found a way to deal with parameters that works for every case. I don't know if there is any chance to pass the parameters to the form before it is acti- vated. James asked how are parameters handled now? Reinhard replied that they are passed to activateForm so they are available from activa- tion for the -main-form, the command line parameters are passed and for dialogs, the parameters are passed that were given in runDialog.</p><p>Example 1: Sample queries and associated human-written query-based summaries for a chat log.</p><p>rization focus on news or other well-written docu- ments, while research on summarizing multiparty written conversations (e.g., chats, emails) has been limited. This is because traditional NLP ap- proaches developed for formal texts often are not satisfactory when dealing with multiparty written conversations, which are typically in a casual style and do not display a clear syntactic structure with proper grammar and spelling. Even though some works try to address the problem of summarizing multiparty written conversions (e.g., <ref type="bibr" target="#b20">(Mehdad et al., 2013b;</ref><ref type="bibr" target="#b23">Murray et al., 2010;</ref><ref type="bibr" target="#b32">Zhou and Hovy, 2005;</ref><ref type="bibr" target="#b9">Gillick et al., 2009)</ref>), they do so in a generic way (not query- based) and focus on only one conversational do- main (e.g., meetings). Moreover, most of the pro- posed systems for conversation summarization are extractive.</p><p>To address such limitations, we propose a fully automatic unsupervised abstract generation frame- work based on phrasal queries for multimodal con- versation summarization. Our key contributions in this work are as follows:</p><p>1) To the best of our knowledge, our framework is the first abstractive system that generates sum- maries based on users phrasal queries, instead of well-formed questions. As a by-product of our approach, we also propose an extractive summa- rization model based on phrasal queries to select the summary-worthy sentences in the conversation based on query terms and signature terms <ref type="bibr" target="#b17">(Lin and Hovy, 2000</ref>).</p><p>2) We propose a novel ranking strategy to select the best path in the constructed word graph by tak- ing the query content, overall information content and grammaticality (i.e., fluency) of the sentence into consideration.</p><p>3) Although most of the current summarization approaches use supervised algorithms as a part of their system (e.g., ( ), our method can be totally unsupervised and does not depend on human annotation. 4) Although different conversational modali- ties (e.g., email vs. chat vs. meeting) underline domain-specific characteristics, in this work, we take advantage of their underlying similarities to generalize away from specific modalities and de- termine effective method for query-based summa- rization of multimodal conversations. We evaluate our system over GNUe Traffic archive 2 Internet Relay Chat (IRC) logs, AMI meetings corpus ( <ref type="bibr" target="#b4">Carletta et al., 2005</ref>) and BC3 emails dataset ( <ref type="bibr" target="#b26">Ulrich et al., 2008)</ref>. Automatic evaluation on the chat dataset and manual eval- uation over the meetings and emails show that our system uniformly and statistically significantly outperforms baseline systems, as well as a state- of-the-art query-based extractive summarization system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Phrasal Query Abstraction Framework</head><p>Our phrasal query abstraction framework gener- ates a grammatical abstract from a conversation following three steps, as shown in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Utterance Extraction</head><p>Abstractive summary sentences can be created by aggregating and merging multiple sentences into an abstract sentence. In order to generate such a sentence, we need to identify which sentences from the original document should be extracted and combined to generate abstract sentences. In other words, we want to identify the summary- worthy sentences in the text that can be combined into an abstract sentence. This task can be con- sidered as content selection. Moreover, this step, stand alone, corresponds to an extractive summa- rization system.  Example 2: Sample signature terms for a part of a chat log.</p><p>In order to select and extract the informative summary-worthy utterances, based on the phrasal query and the original text, we consider two cri- teria: i) utterances should carry the essence of the original text; and ii) utterances should be relevant to the query. To fulfill such requirements we define the concepts of signature terms and query terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Signature Terms</head><p>Signature terms are generally indicative of the content of a document or collection of docu- ments. To identify such terms, we can use fre- quency, word probability, standard statistic tests, information-theoretic measures or log-likelihood ratio. In this work, we use log-likelihood ratio to extract the signature terms from chat logs, since log-likelihood ratio leads to better results ( <ref type="bibr" target="#b12">Gupta et al., 2007</ref>). We use a method described in <ref type="bibr" target="#b17">(Lin and Hovy, 2000</ref>) in order to identify such terms and their associated weight. Example 2 demon- strates a chat log and associated signature terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Query Terms</head><p>Query terms are indicative of the content in a phrasal query. In order to identify such terms, we first extract all content terms from the query. Then, following previous studies (e.g., <ref type="bibr" target="#b10">(Gonzalo et al., 1998)</ref>), we use the synsets relations in Word- Net for query expansion. We extract all concepts that are synonyms to the query terms and add them to the original set of query terms. Note that we limit our synsets to the nouns since verb syn- onyms do not prove to be effective in query ex- pansion <ref type="bibr" target="#b13">(Hunemark, 2010)</ref>. While signature terms are weighted, we assume that all query terms are equally important and they all have wight equal to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Utterance Scoring</head><p>To estimate the utterance score, we view both the query terms and the signature terms as the terms that should appear in a human query-based summary. To achieve this, the most relevant (summary-worthy) utterances that we select are the ones that maximize the coverage of such terms. Given the query terms and signature terms, we can estimate the utterance score as follows:</p><formula xml:id="formula_0">Score Q = 1 n n i=1 t(q) i (1) Score S = 1 n n i=1 t(s) i × w(s) i (2) Score = α · Score Q + β · Score S (3)</formula><p>where n is number of content words in the ut- terance, t(q) i = 1 if the term t i is a query term and 0 otherwise, and t(s) i = 1 if t i is a signature term and 0 otherwise, and w(s) i is the normalized associated weight for signature terms. The param- eters α and β are tuned on a development set and sum up to 1.</p><p>After all the utterances are scored, the top scored utterances are selected to be sent to the next step. We estimate the percentage of the retrieved utterances based on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Redundancy Removal</head><p>Utterances selected in previous step often in- clude redundant information, which is semanti- cally equivalent but may vary in lexical choices. By identifying the semantic relations between the sentences, we can discover what information in one sentence is semantically equivalent, novel, or more/less informative with respect to the content of the other sentences. Similar to earlier work <ref type="bibr" target="#b3">(Berant et al., 2011;</ref><ref type="bibr" target="#b0">Adler et al., 2012)</ref>, we set this problem as a variant of the Textual Entail- ment (TE) recognition task ( <ref type="bibr" target="#b5">Dagan and Glickman, 2004</ref>). Using entailment in this phase is moti- vated by taking advantage of semantic relations instead of pure statistical methods (e.g., Maximal Marginal Relevance) and shown to be more effec- tive ( <ref type="bibr" target="#b19">Mehdad et al., 2013a</ref>). We follow the same practice as ( <ref type="bibr" target="#b19">Mehdad et al., 2013a</ref>) to build an en- tailment graph for all selected sentences to identify relevant sentences and eliminate the redundant (in terms of meaning) and less informative ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Abstract Generation</head><p>In this phase, our goal is to generate understand- able informative abstract sentences that capture the content of the source sentences and represents the information needs defined by queries. There are several ways of generating abstract sentences (e.g. ( <ref type="bibr" target="#b1">Barzilay and McKeown, 2005;</ref><ref type="bibr" target="#b18">Liu and Liu, 2009;</ref><ref type="bibr" target="#b8">Ganesan et al., 2010;</ref><ref type="bibr" target="#b23">Murray et al., 2010)</ref>); however, most of them rely heavily on the sen- tence structure. We believe that such approaches are suboptimal, especially in dealing with conver- sational data, because multiparty written conversa- tions are often poorly structured. Instead, we ap- ply an approach that does not rely on syntax, nor on a standard NLG architecture. Moreover, since dealing with user queries efficiency is an impor- tant aspect, we aim for an approach that is also motivated by the speed with which the abstracts are obtained. We perform the task of abstract gen- eration in three steps, as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Clustering</head><p>In order to generate an abstract summary, we need to identify which sentences from the previous step (i.e., redundancy removal) can be clustered and combined in generated abstract sentences. This task can be viewed as sentence clustering, where each sentence cluster can provide the content for an abstract sentence.</p><p>We use the K-mean clustering algorithm by co- sine similarity as a distance function between sen- tence vectors composed of tf.idf scores. Also no- tice that the lexical similarity between sentences in one cluster facilitates both the construction of the word graph and finding the best path in the word graph, as described next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Word Graph</head><p>In order to construct a word graph, we adopt the method recently proposed by <ref type="bibr" target="#b19">(Mehdad et al., 2013a;</ref><ref type="bibr" target="#b7">Filippova, 2010</ref>) with some optimizations. Below, we show how the word graph is applied to generate the abstract sentences.</p><p>Let G = (W, L) be a directed graph with the set of nodes W representing words and a set of directed edges L representing the links between words. Given a cluster of related sentences S = {s 1 , s 2 , ..., s n }, a word graph is constructed by it- eratively adding sentences to it. In the first step, the graph represents one sentence plus the start and end symbols. A node is added to the graph for each word in the sentence, and words adjacent are linked with directed edges. When adding a new sentence, a word from the sentence is merged in an existing node in the graph providing that they have the same POS tag and they satisfy one of the following conditions: i) They have the same word form; ii) They are connected in WordNet by the syn- onymy relation. In this case the lexical choice for the node is selected based on the tf.idf score of each node;</p><p>iii) They are from a hypernym/hyponym pair or share a common direct hypernym. In this case, both words are replaced by the hypernym; iv) They are in an entailment relation. In this case, the entailing word is replaced by the entailed one.</p><p>The motivation behind merging non-identical words is to enrich the common terms between the phrases to increase the chance that they could merge into a single phrase. This also helps to move beyond the limitation of original lexical choices. In case the merging is not possible a new node is created in the graph. When a node can be merged with multiple nodes (i.e., merging is ambiguous), either the preceding and following words in the sentence and the neighboring nodes in the graph or the frequency is used to select the candidate node.</p><p>We connect adjacent words with directed edges.</p><p>For the new nodes or unconnected nodes, we draw an edge with a weight of 1. In contrast, when two already connected nodes are added (merged), the weight of their connection is increased by 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Path Ranking</head><p>A word graph, as described above, may contain many sequences connecting start and end. How- ever, it is likely that most of the paths are not read- able. We are aiming at generating an informative abstractive sentence for each cluster based on a user query. Moreover, the abstract sentence should be grammatically correct.</p><p>In order to satisfy both requirements, we have devised the following ranking strategy. First, we prune the paths in which a verb does not exist, to filter ungrammatical sentences. Then we rank other paths as follows: Query focus: to identify the summary sentence with the highest coverage of query content, we propose a score that counts the number of query terms that appear in the path. In order to reward the ranking score to cover more salient terms in the query content, we also consider the tf.idf score of query terms in the coverage formulation.</p><formula xml:id="formula_1">Q(P ) = q i ∈P tfidf (q i ) q i ∈G tfidf (q i )</formula><p>where the q i are the query terms. Fluency: in order to improve the grammaticality of the generated sentence, we coach our ranking model to select more fluent (i.e., grammatically correct) paths in the graph. We estimate the gram- maticality of generated paths (P r(P )) using a lan- guage model. Path weight: The purpose of this function is two- fold: i) to generate a grammatical sentence by fa- voring the links between nodes (words) which ap- pear often; and ii) to generate an informative sen- tence by increasing the weight of edges connecting salient nodes. For a path P with m nodes, we de- fine the edge weight w(n i , n j ) and the path weight W (P ) as below:</p><formula xml:id="formula_2">w(n i , n j ) = freq(n i ) + freq(n j ) P ∈G n i ,n j ∈P diff (P , n i , n j ) −1 W (P ) = m−1 i=1 w(n i , n i+1 ) m − 1</formula><p>where the function diff(P , n i , n j ) refers to the distance between the offset positions pos(P , n i ) of nodes n i and n j in path P (any path in G con- taining n i and n j ) and is defined as |pos(P , n j ) − pos(P , n i )|.</p><p>Overal ranking score: In order to generate a query-based abstract sentence that combines the scores above, we employ a ranking model. The purpose of such a model is three-fold: i) to cover the content of query information optimally; ii) to generate a more readable and grammatical sen- tence; and iii) to favor strong connections between the concepts. Therefore, the final ranking score of path P is calculated over the normalized scores as:</p><formula xml:id="formula_3">Score(P ) = α · Q(P ) + β · P r(P ) − γ · W (P )</formula><p>Where α, β and γ are the coefficient factors to tune the ranking score and they sum up to 1. In or- der to rank the graph paths, we select all the paths that contain at least one verb and rerank them us- ing our proposed ranking function to find the best path as the summary of the original sentences in each cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In this section, we show the evaluation results of our proposed framework and its comparison to the baselines and a state-of-the-art query-focused ex- tractive summarization system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>One of the challenges of this work is to find suit- able conversational datasets that can be used for evaluating our query-based summarization sys- tem. Most available conversational corpora do not contain any human written summaries, or the gold standard human written summaries are generic <ref type="bibr" target="#b4">(Carletta et al., 2005;</ref><ref type="bibr" target="#b16">Joty et al., 2013)</ref>. In this work, we use available corpora for emails and chats for written conversations, while for spoken conversation, we employ an available corpus in multiparty meeting conversations. Chat: to the best of our knowledge, the only pub- licly available chat logs with human written sum- maries can be downloaded from the GNUe Traffic archive ( <ref type="bibr" target="#b32">Zhou and Hovy, 2005;</ref><ref type="bibr" target="#b27">Uthus and Aha, 2011;</ref><ref type="bibr" target="#b28">Uthus and Aha, 2013)</ref>. Each chat log has a human created summary in the form of a digest. Each digest summarizes IRC logs for a period and consists of few summaries over each chat log with a unique title for the associated human written summary. In this way, the title of each summary can be counted as a phrasal query and the cor- responding summary is considered as the query- based abstract of the associated chat log includ- ing only the information most relevant to the title. Therefore, we can use the human-written query- based abstract as gold standards and evaluate our system automatically. Our chat dataset consists of 66 query-based (title-based) human written sum- maries with their associated queries (titles) and chat logs, created from 40 original chat logs. The average number of tokens are 1840, 325 and 6 for chat logs, query-based summaries and queries, re- spectively. Meeting: we use the AMI meeting corpus <ref type="bibr" target="#b4">(Carletta et al., 2005</ref>) that consists of 140 multiparty meetings with a wide range of annotations, includ- ing generic abstractive summaries for each meet- ing. In order to create queries, we extract three key-phrases from generic abstractive summaries using TextRank algorithm ( <ref type="bibr" target="#b22">Mihalcea and Tarau, 2004</ref>). We use the extracted key-phrases as queries to generate query-based abstracts. Since there is no human-written query-based summary for AMI corpus, we randomly select 10 meetings and eval- uate our system manually. Email: we use BC3 ( <ref type="bibr" target="#b26">Ulrich et al., 2008)</ref>, which contains 40 threads from the W3C corpus. BC3 corpus is annotated with generic human-written abstractive summaries, and it has been used in sev- eral previous works (e.g., <ref type="bibr" target="#b15">(Joty et al., 2011)</ref>). In order to adapt this corpus to our framework, we followed the same query generation process as for the meeting dataset. Finally, we randomly select 10 emails threads and evaluate the results manu- ally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baselines</head><p>We compare our approach with the following baselines:</p><p>1) Cosine-1st: we rank the utterances in the chat log based on the cosine similarity between the ut- terance and query. Then, we select the first ut- trance as the summary;</p><p>2) Cosine-all: we rank the utterances in the chat log based on the cosine similarity between the ut- terance and query and then select the utterances with a cosine similarity greater than 0;</p><p>3) TextRank: a widely used graph-based rank- ing model for single-document sentence extraction that works by building a graph of all sentences in a document and use similarity as edges to compute the salience of sentences in the graph (Mihalcea and Tarau, 2004); 4) LexRank: another popular graph-based con- tent selection algorithm for multi-document sum- marization ( <ref type="bibr" target="#b6">Erkan and Radev, 2004</ref>); 5) Biased LexRank: is a state-of-the-art query- focused summarization that uses LexRank algo- rithm in order to recursively retrieve additional passages that are similar to the query, as well as to the other nodes in the graph ( <ref type="bibr" target="#b24">Otterbacher et al., 2009)</ref>.</p><p>Moreover, we compare our abstractive system with the first part of our framework (utterance ex- traction in <ref type="figure">Figure 1</ref>), which can be presented as an extractive query-based summarization system (our extractive system). We also show the results of the version we use in our pipeline (our pipeline ex- tractive system). The only difference between the two versions is the length of the generated sum- maries. In our pipeline we aim at higher recall, since we later filter sentences and aggregate them to generate new abstract sentences. In contrast, in the stand alone version (extractive system) we limit the number of retrieved sentences to the de- sired length of the summary. We also compare the results of our full system (i.e., with tuning) with a non-optimized version when the ranking coef- ficients are distributed equally (α = β = γ = 0.33). For parameters estimation, we tune all pa- rameters (utterance selection and path ranking) ex- haustively with 0.1 intervals using our develop- ment set.</p><p>For manual evaluation of query-based abstracts (meeting and email datasets), we perform a sim- ple user study assessing the following aspects: i) Overall quality given a query (5-point scale)?; and ii) Responsiveness: how responsive is the gener- ated summary to the query (5-point scale)? Each query-based abstract was rated by two annotators (native English speaker). Evaluators are presented with the original conversation, query and gener- ated summary. For the manual evaluation, we only compare our full system with LexRank (LR) and Biased LexRank (Biased LR). We also ask the evaluators to select the best summary for each query and conversation, given our system gener- ated summary and the two baselines.</p><p>To evaluate the grammaticality of our generated summaries, following common practice ( <ref type="bibr" target="#b1">Barzilay and McKeown, 2005</ref>), we randomly selected 50 sentences from original conversations and system <ref type="table" target="#tab_2">Cosine-1st  71  5  8  30  3  5  Cosine-all  30  68  38  18  40  22  TextRank  25  76  34  15  44  20  LexRank  36  50  37  14  20  15  Biased LexRank  36  51  38  15  21</ref>   <ref type="table">Table 1</ref>: Performance of different summarization algorithms on chat logs for query-based chat sum- marization. Statistically significant improvements (p &lt; 0.01) over the biased LexRank system are marked with *. † indicates statistical significance (p &lt; 0.01) over extractive approaches <ref type="bibr">(TextRank and LexRank)</ref>. Systems in italics use the query in generating the summary.</p><formula xml:id="formula_4">Models ROUGE-1 (%) ROUGE-2 (%) Prc Rec F-1 Prc Rec F-1</formula><p>generated abstracts, for each dataset. Then, we asked annotators to give one of three possible rat- ings for each sentence based on grammaticality: perfect (2 pts), only one mistake (1 pt) and not ac- ceptable (0 pts), ignoring capitalization or punc- tuation. Each sentence was rated by two annota- tors. Note that each sentence was evaluated indi- vidually, so the human judges were not affected by intra-sentential problems posed by coreference and topic shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Settings</head><p>For preprocessing our dataset we use OpenNLP 3 for tokenization, stemming and part-of-speech tagging. We use six randomly selected query- logs from our chat dataset (about 10% of the dataset) for tuning the coefficient parameters. We set the k parameter in our clustering phase to 10 based on the average number of sentences in the human written summaries. For our lan- guage model, we use a tri-gram smoothed lan- guage model trained using the newswire text pro- vided in the English Gigaword corpus ( <ref type="bibr" target="#b11">Graff and Cieri, 2003)</ref>. For the automatic evaluation we use the official ROUGE software with standard op- tions and report ROUGE-1 and ROUGE-2 preci- sion, recall and F-1 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Automatic Evaluation (Chat dataset)</head><p>Abstractive vs. Extractive: our full query- based abstractive summariztion system show sta- tistically significant improvements over baselines 3 http://opennlp.apache.org/ and other pure extractive summarization systems for ROUGE-1 4 . This means our systems can ef- fectively aggregate the extracted sentences and generate abstract sentences based on the query content. We can also observe that our full system produces the highest ROUGE-1 precision score among all models, which further confirms the suc- cess of this model in meeting the user informa- tion needs imposed by queries. The absolute im- provement of 10% in precision for ROUGE-1 in our abstractive model over our extractive model (our pipeline) further confirms the effectiveness of our ranking method in generating the abstract sen- tences considering the query related information. Our extractive query-based method beats all other extractive systems with a higher ROUGE- 1 and ROUGE-2 which shows the effectiveness of our utterance extraction model in comparison with other extractive models. In other words, using our extractive model described in section 2.1, as a stand alone system, is an effective query-based extractive summarization model. We also observe that our extractive model outperforms our abstrac- tive model for ROUGE-2 score. This can be due to word merging and word replacement choices in the word graph construction, which sometimes change or remove a word in a bigram and conse- quently may decrease the bigram overlap score. Query Relevance: another interesting observa- tion is that relying only on the cosine similarity (i.e., cosine-all) to measure the query relevance presents a quite strong baseline. This proves the importance of query content in our dataset and fur- ther supports the main claim of our work that a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overal Quality</head><p>Responsiveness Preference Our Sys Biased LR LR Our Sys Biased LR LR Our Sys Biased LR LR Meeting 2.9 2.5 2.1 3.8 3.2 1.8 70% 30% 0% Email 2.7 1.8 1.7 3.7 3.0 1.5 60% 30% 10%  <ref type="table">Table 3</ref>: Average rating and distribution over grammaticality scores for phrasal query abstraction system in comparison with original sentences.</p><p>good summary should express a brief and well- organized abstract that answers the user's query. Moreover, a precision of 71% for ROUGE-1 from the simple cosine-1st baseline confirms that some utterances contain more query relevant informa- tion in conversational discussions.</p><p>Query-based vs. Generic: the high recall and low precision in TextRank baseline, both for the ROUGE-1 and ROUGE-2 scores, shows the strength of the model in extracting the generic in- formation from chat conversations while missing the query-relevant content. The LexRank baseline improves the results of the TextRank system by increasing the precision and balancing the preci- sion and recall scores for ROUGE-1 score. We believe that this is due to the robustness of the LexRank method in dealing with noisy texts (chat conversations) ( <ref type="bibr" target="#b6">Erkan and Radev, 2004</ref>). In addi- tion, the Biased LexRank model slightly improves the generic LexRank system. Considering this marginal improvement and relatively high results of pure extractive systems, we can infer that the Biased LexRank extracted summaries do not carry much query relevant content. In contrast, the sig- nificant improvement of our model over the ex- tractive methods demonstrates the success of our approach in presenting the query related content in generated abstracts. An example of a short chat log, its related query and corresponding manual and automatic sum- maries are shown in Example 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Manual Evaluation</head><p>Content and User Preference: <ref type="table" target="#tab_2">Table 2</ref> demon- strates overall quality, responsiveness (query re- latedness) and user preference scores for the ab- stracts generated by our system and two base- lines. Results indicate that our system signif- icantly outperforms baselines in overall quality and responsiveness, for both meeting and email datasets. This confirms the validity of the re- sults we obtained by conducting automatic evalu- ation over the chat dataset. We also can observe that the absolute improvements in overall qual- ity and responsiveness for emails (0.9 and 0.7) is greater than for meetings (0.4 and 0.6). This is expected since dealing with spoken conversations is more challenging than written ones. Note that the responsiveness scores are greater than over- all scores. This further proves the effectiveness of our approach in dealing with phrasal queries. We also evaluate the users' summary preferences. For both datasets (meeting and email), in majority of cases (70% and 60% respectively), the users prefer the query-based abstractive summary generated by our system. Grammaticality: <ref type="table">Table 3</ref> shows grammaticality scores and distributions over the three possible scores for all datasets. The chat dataset results demonstrate the highest scores: 73% of the sen- tences generated by our phrasal query abstrac- tion model are grammatically correct and 24% of the generated sentences are almost correct with only one grammatical error, while only 3% of the abstract sentences are grammatically incor- rect. However, the results varies moving to other datasets. For meeting dataset, the percentage of completely grammatical sentences drops dramati- cally. This is due to the nature of spoken conver- sations which is more error prone and ungrammat- ical. The grammaticality score of the original sen- tences also proves that the sentences from meet-Query: Trigger namespace and the self property Chat log: A: good morning B: good morning C: good morning everyone D: good morning D: good night all F: New GNUe Traffic online F: loadsa deep metaphyisical stuff this week F: D &amp; E discuss the meaning of 'self' ;-) E: yes, and he took the more metaphysical route, where I took the more scientific route E: I say self's meaning is derived from one's ancestry E: self's meaning is derived from how others use you E: okay, analogy extended too far, I guess :) F: is this a friends vs family debate? E: also noted that the cool part about that is if you have code that needs to happen both on a pre-insert and a pre-update -but only a few lines of the code is different E: you could have one block of trigger code that used self.action to find out why it had been called and branch accordingly. E: there was a big jump from the previous paragraph to that E: that took that out of context E: iirc, I was saying an alternative was that "self" could refer to neither the trigger's owner nor to the trigger's caller E: but to the event itself E: so self.action could be what action is being performed E: self.parent could be the trigger's owner E: and self.context could be the caller E: and self.name could be the name of the trigger F: umm, I'm afraid apparant non-sequiturs are always a hazard of doing summaries ;-) E: iow, I was presenting a 3rd alternative where self referred to some- thing specific to the trigger F: I normally try to write around them, but not 100% successful E: I'm just convulsing my thoughts to the irc log E: for an errata next week :) E: I think convulsing is a good description F: heh TexRank: There was a big jump from the previous paragraph to that. that took that out of context iirc, I was saying an alternative was that "self" could refer to neither the trigger's owner nor to the trigger's caller. but to the event itself. so self.action could be what action is being per- formed, self.parent could be the trigger's owner, and self.context could be the caller and self.name could be the name of the trigger. umm, I'm afraid apparant non-sequiturs are always a hazard of doing summaries ;-) LexRank: good morning everyone. heh. I'm just convulsing my thoughts to the irc log good morning. Jason also noted that the cool part about that is if you have code that needs to happen both on a pre- insert and a pre-update -but only a few lines of the code is different - you could have one block of trigger code that used self.action to find out why it had been called and branch accordingly. for an errata next week :) self's meaning is derived from how others use you. I think convulsing is a good description reinhard &amp; jcater discuss the meaning of 'self' ;-) Biased-LexRank: good morning everyone. heh. I'm just convulsing my thoughts to the irc log. Jason also noted that the cool part about that is if you have code that needs to happen both on a pre-insert and a pre-update -but only a few lines of the code is different -you could have one block of trigger code that used self.action to find out why it had been called and branch accordingly. yes, and he took the more metaphysical route, where I took the more scientific route there was a big jump from the previous paragraph to that but to the event itself. iow, I was presenting a 3rd alternative where self referred to something specific to the trigger. Our system: self could refer to neither the triggers owner nor caller. I was saying an alternative where self referred to something specific to the trigger. and self.name could be the name. so self.action could be what action is being performed, self.parent the triggers owner and self.context caller. Gold: Further to, E clarified that he had suggested that "self" could refer to neither the trigger's owner nor to the trigger's caller -but to the event itself. So self.action could be what action is being performed, self.parent could be the trigger's owner, and self.context could be the caller. In other words, I was presenting a 3rd alternative where self referred to something specific to the trigger.</p><p>Example 3. Summaries generated by our system and other baselines in comparison with the human- written summary for a short chat log. Speaker in- formation have been anonymized. ing transcripts, although generated by humans, are not fully grammatical. In comparison with the original sentences, for all datasets, our model re- ports slightly lower results for the grammaticality score. Considering the fact that the abstract sen- tences are automatically generated and the orig- inal sentences are human-written, the grammat- icality score and the percentage of fully gram- matical sentences generated by our system, with higher ROUGE or quality scores in comparison with other methods, demonstrates that our system is an effective phrasal query abstraction frame- work for both spoken and written conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have presented an unsupervised framework for abstractive summarization of spoken and written conversations based on phrasal queries. For con- tent selection, we propose a sentence extraction model that incorporates query relevance and con- tent importance into the extraction process. For the generation phase, we propose a ranking strat- egy which selects the best path in the constructed word graph based on fluency, query relevance and content. Both automatic and manual evalua- tion of our model show substantial improvement over extraction-based methods, including Biased LexRank, which is considered a state-of-the-art system. Moreover, our system also yields good grammaticality score for human evaluation and achieves comparable scores with the original sen- tences. Our future work is four-fold. First, we are trying to improve our model by incorporating conversational features (e.g., speech acts). Sec- ond, we aim at implementing a strategy to or- der the clusters for generating more coherent ab- stracts. Third, we try to improve our generated summary by resolving coreferences and incorpo- rating speaker information (e.g., names) in the clustering and sentence generation phases. Fi- nally, we plan to take advantage of topic shifts to better segment the relevant parts of conversations in relation to phrasal queries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Original</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>conversation</head><label></label><figDesc></figDesc><table>Query 

Extracted 
utterances 
Filtered 
utterances 

Extraction 

Redundancy 
Removal 

Generation 

Clusters Word graphs 

Top ranked 
sentences 
Query-based 
abstract 

Clustering Word Graph 
Ranking 

Construction 

Figure 1: Phrasal query abstraction framework. The steps (arrows) influenced by the query are high-
lighted. 

Signature terms: navigator, functionality, reports, UI, schema, gnu 
Chat log: 
-but watching them build a UI in the flash demo's is pretty damn im-
pressive... and have started moving my sales app to all UI being built 
via ... 
-i'll be expanding the technotes in navigator for a while ... 
-... in terms of functionality of the underlying databases ... 
-you mean if I start GNU again I have to read bug reports too? 
-no, just in case you want to enter bug report 
-...I expand the schema before populating with test data ... 
-i'm willing to scrap it if there is a better schema hidden in gnue some-
where :) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Manual evaluation scores for our phrasal query abstraction system in comparison with Biased LexRank and LexRank (LR).</head><label>2</label><figDesc></figDesc><table>Dataset 
Grammar 
G=2 
G=1 
G=0 
Orig Sys Orig 
Sys 
Orig 
Sys 
Orig Sys 
Chat 
1.8 
1.6 84% 73% 16% 24% 
0% 
3% 
Meeting 
1.5 
1.3 50% 40% 50% 55% 
0% 
5% 
Email 
1.9 
1.6 85% 60% 15% 35% 
0% 
5% 

</table></figure>

			<note place="foot" n="1"> http://www-nlpir.nist.gov/projects/duc/index.html</note>

			<note place="foot" n="2"> http://kt.earth.li/GNUe/index.html</note>

			<note place="foot" n="4"> The statistical significance tests was calculated by approximate randomization, as described in (Yeh, 2000).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous review-ers for their valuable comments and suggestions to improve the paper, and the NSERC Business In-telligence Network for financial support. We also would like to acknowledge the early discussions on the related topics with Frank Tompa.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Entailment-based text exploration with application to the health-care domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meni</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations, ACL &apos;12</title>
		<meeting>the ACL 2012 System Demonstrations, ACL &apos;12<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="79" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<title level="m">Sentence Fusion for Multidocument News Summarization</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global Learning of Typed Entailment Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The AMI meeting corpus: A pre-announcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Bourban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslav</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasilis</forename><surname>Karaiskos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Kronenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lathoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MLMI</title>
		<meeting>MLMI<address><addrLine>Mike Lincoln, Agnes Lisowska, and Mccowan Wilfried Post Dennis Reidsma</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic Textual Entailment: Generic applied modeling of language variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PASCAL Workshop on Learning Methods for Text Understanding and Mining</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lexrank: graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-sentence compression: finding shortest paths in word graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A global optimization framework for meeting summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korbinian</forename><surname>Riedhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICASSP</title>
		<meeting>IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4769" to="4772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Indexing with wordnet synsets can improve text retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">M</forename><surname>Cigarrn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">English Gigaword Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Cieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring importance and query relevance in topicfocused multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surabhi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Query expansion using search logs and WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Hunemark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">University, mar. Masters thesis in Computational Linguistics</title>
		<meeting><address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information overload and the message dynamics of online interaction spaces: A theoretical model and empirical exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Ravid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheizaf</forename><surname>Rafaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Info. Sys. Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="194" to="210" />
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Supervised topic segmentation of email conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<idno>ICWSM11. AAAI</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Topic segmentation and labeling in asynchronous conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shafiq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="521" to="573" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The automated acquisition of topic signatures for text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Of the COLING Conference</title>
		<meeting>Of the COLING Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="495" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From extractive to abstractive meeting summaries: can it be done by sentence compression?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACLIJCNLP 2009 Conference Short Papers, ACLShort &apos;09</title>
		<meeting>the ACLIJCNLP 2009 Conference Short Papers, ACLShort &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="261" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards Topic Labeling with Phrase Entailment and Aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond Ng T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2013</title>
		<meeting>NAACL 2013<address><addrLine>Atlanta, USA, June</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="179" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Abstractive meeting summarization with entailment and fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Tompa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th European Workshop on Natural Language Generation</title>
		<meeting>the 14th European Workshop on Natural Language Generation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="136" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Advanced Metasearch Engine Technology. Synthesis Lectures on Data Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Morgan and Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">TextRank: Bringing order into texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generating and validating abstracts of meeting conversations: a user study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Natural Language Generation Conference, INLG &apos;10</title>
		<meeting>the 6th International Natural Language Generation Conference, INLG &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="105" to="113" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Biased lexrank: Passage retrieval using random walks with question-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gnes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="54" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generic summaries for indexing in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen Sparck-Jones</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;01<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A publicly available annotated corpus for supervised email summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carenini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI08 EMAIL Workshop</title>
		<meeting><address><addrLine>Chicago, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Plans toward automated chat summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Automatic Summarization for Different Genres, Media, and Languages, WASDGML &apos;11</title>
		<meeting>the Workshop on Automatic Summarization for Different Genres, Media, and Languages, WASDGML &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The ubuntu chat corpus for multiparticipant chat analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Analyzing Microtext</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Domainindependent abstract generation for focused meeting summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1395" to="1405" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A sentence compression based framework to query-focused multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hema</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1384" to="1394" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">More accurate tests for the statistical significance of result differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference on Computational Linguistics</title>
		<meeting>the 18th Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="947" to="953" />
		</imprint>
	</monogr>
	<note>COLING &apos;00</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Digesting virtual &quot;geek&quot; culture: The summarization of technical internet relay chats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="298" to="305" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
