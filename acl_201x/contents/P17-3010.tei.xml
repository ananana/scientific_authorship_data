<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Variation Autoencoder Based Network Representation Learning for Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozheng</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenglu</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Odagaki</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">College of Computer and Control Engineering</orgName>
								<orgName type="institution">Nankai University</orgName>
								<address>
									<settlement>Tianjin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Variation Autoencoder Based Network Representation Learning for Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="56" to="61"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3010</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Network representation is the basis of many applications and of extensive interest in various fields, such as information retrieval, social network analysis , and recommendation systems. Most previous methods for network representation only consider the incomplete aspects of a problem, including link structure , node information, and partial integration. The present study introduces a deep network representation model that seamlessly integrates the text information and structure of a network. The model captures highly non-linear relationships between nodes and complex features of a network by exploiting the variational au-toencoder (VAE), which is a deep unsu-pervised generation algorithm. The representation learned with a paragraph vector model is merged with that learned with the VAE to obtain the network representation, which preserves both structure and text information. Comprehensive experiments is conducted on benchmark datasets and find that the introduced model performs better than state-of-the-art techniques.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Information network representation is an impor- tant research issue because it is the basis of many applications, such as document classification in citation networks, functional label prediction in protein-protein interaction networks, and potential friend recommendations in social networks. Al- though there are not a few recent work proposed to study the issue <ref type="bibr" target="#b0">(Belkin and Niyogi, 2003;</ref><ref type="bibr" target="#b10">Tenenbaum et al., 2001;</ref><ref type="bibr" target="#b2">Cao et al., 2015;</ref><ref type="bibr" target="#b11">Tian et al., 2014;</ref><ref type="bibr" target="#b1">Cao, 2016)</ref>, it is still far from satisfactory because of the intrinsic difficulty. In essence, the rich and complex information (i.e., link structure and node contents) embedded in information net- works poses a significant challenge in the effective representation of networks.</p><p>Network-distributed representation learning can be viewed as a problem using low-dimensional vectors to represent nodes in a network. Most net- work representation methods are based on a net- work structure. The traditional representation is based on matrix decomposition and uses eigenvec- tors as representation <ref type="bibr" target="#b0">(Belkin and Niyogi, 2003;</ref><ref type="bibr" target="#b8">Roweis and Saul, 2000;</ref><ref type="bibr" target="#b10">Tenenbaum et al., 2001</ref>). Furthermore, they extend to high-order informa- tion ( <ref type="bibr" target="#b2">Cao et al., 2015)</ref>. However, these meth- ods are not applicable to large-scale networks, and although many approximate approaches have been developed to solve this problem, they are not effective enough. Some methods are based on optimization objective functions ( <ref type="bibr" target="#b9">Tang et al., 2015;</ref><ref type="bibr" target="#b6">Pan et al., 2016;</ref><ref type="bibr" target="#b12">Yang et al., 2015)</ref>. Al- though they are suitable for large-scale network data, they adopt shallow models that are limited in terms of performance and are difficult to use to obtain highly non-linear relationships that are vital to the preservation of network structure. In- spired by deep learning techniques in natural lan- guage processing, ( <ref type="bibr" target="#b7">Perozzi et al., 2014;</ref><ref type="bibr" target="#b3">Grover and Leskovec, 2016</ref>) adopted several stunted ran- dom walks in networks to generate node se- quences serving as sentence corpus and then ap- plied the skip-gram model to these sequences to learn node representation. However, they cannot easily handle additional information during ran- dom walks in a network.</p><p>To capture highly non-linear structures for large-scale networks, ( <ref type="bibr" target="#b11">Tian et al., 2014;</ref><ref type="bibr" target="#b1">Cao, 2016)</ref> introduced an autoencoder to model train- ing instead of using a sampling based method to generate linear sequences. Motivated by this model, we develop the variational autoencoder (VAE) <ref type="bibr" target="#b4">(Kingma and Welling, 2014)</ref>, which is a deep generation model, instead of a basic autoen- coder. Most previous studies utilized only one type of information in networks. The work in <ref type="bibr" target="#b5">(Le and Mikolov, 2014</ref>) focused on node content, and others ( <ref type="bibr" target="#b3">Grover and Leskovec, 2016;</ref><ref type="bibr" target="#b7">Perozzi et al., 2014</ref>) explored link structure. Although a few previous models <ref type="bibr" target="#b6">(Pan et al., 2016;</ref><ref type="bibr" target="#b12">Yang et al., 2015</ref>) combined both text information and net- work structure, they did not preserve the complete network structure and only partially utilized node content. A straightforward method is to learn rep- resentations from text features and network struc- ture independently, and then concatenate the two separate representations.</p><p>To address the above issues, we introduce a deep generative model to learn network represen- tation by modeling both node content information and network structure comprehensively. First, the representation based on node content through the paragraph vector model is obtained. Then, we feed the network adjacency matrix and representation obtained into a deep generative model, the build- ing block of which is the VAE. After stacking sev- eral layers of the VAE, the result of the first layer is chosen before decoding as the final representation. Intuitively, we can obtain the representation con- taining both content information and structure in a d-dimensional feature space. The experimental evaluation demonstrates the superior performance of the model on the benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminary</head><p>Notation: Let G = (V, E, C) denote a given net- work, where V = {v i } i=1...N is the node set and E = {e ij } is the edge set that indicates the re- lation of nodes. If a direct link exists between v i and v j then e ij = 1; otherwise, e ij = 0 when network is unweighted. C = {c i } is the set of content information. let A denote the adjacency matrix for a network, and let x = {e i,k , ..., e n,k } be an adjacency vector. Our goal is to seek a low- dimensional vector y j for each node v i of a given network. Autoencoder: We first provide a brief description of a basic autoencoder and the VAE. The basic au- toencoder first compresses the input into a small form and then transforms it back into an approx- imation of the input. The encoding part aims to find the compression representation z of a given data x, and the decoding part is a reflection of the encoder used to reconstruct the original input x. The VAE ( <ref type="bibr" target="#b4">Kingma and Welling, 2014</ref>) imposes a prior distribution on the hidden layer vector of the autoencoder and re-parameterizes the network according to the parameters of the prior distribu- tion. Through the parameterization process, the means and variance values of the input data can be learned. We extended VAE to generate two means and variances of input data, which can be considered correspond to the content and structure respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Description</head><p>The architecture of the proposed model is shown in <ref type="figure">Fig. 1</ref>. The whole architecture consists of two main modules, namely, the content2vec module and the union training module. For an informa- tion network, such as a paper citation network, we can obtain the node link and content information (e.g., paper abstract). We learn an effective feature representation vector that preserves both structure information and node content information and can thus be applied to many tasks (e.g., paper classifi- cation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Content2vec Module</head><p>We employ the state-of-the-art approach called doc2vec ( <ref type="bibr" target="#b5">Le and Mikolov, 2014)</ref>, which uti- lizes text to learn vector representations of docu- ments, as our content2vec module. Specifically, if one node contains other information (e.g., author name), we treat it as a word and merge it into the comprehensive text information (e.g., the abstract of the paper in the citation network) as the con- tent of the node. A representation u i that includes the node content information is obtained from this module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Union-training Module</head><p>The union training module is the core part of our model, in which content information and structure information are integrated. The details are shown in <ref type="figure">Fig 1.</ref> The VAE is adopted as the main block. Given a network, the adjacency matrix A can be obtained. A can describe the relationship among the nodes and reflect the overall structure of the network. We extract each adjacency vector a i and concatenate it with the corresponding u i as the in- put x i of our model. Therefore, the content and <ref type="figure">Figure 1</ref>: Architecture of our model. w i can be seen as a word of the content information, u i is a node in the network, u i is a representation vector learned by the Content2Vec Module, x i is a vector of the adjacency matrix. The input of the union-training module is combination of x i and u i , the encoder and decoder are stack full-connected layer, σ i1 , σ i2 , µ i1 , µ i2 can be seen the mean and variance of the distribution of the content and structure data, respectively. ε i1 and ε i2 are the sample data from two Gaussian distributions.</p><p>structure information is able to be learned simul- taneously.</p><p>During the encoding phase, we adapt several fully connected layers composed of multiple non- linear mapping functions to map the input data to a highly nonlinear latent space. Therefore, given the input x i , the output h k for the k th layer is shown as follow:</p><formula xml:id="formula_0">h 1 = π(W 1 x i + b 1 ) h k = π(W k h k−1 + b k ), k = 1, 2...K (1)</formula><p>where π is the nonlinear activation function of each layer. The value of K varies with the data. In the last layer of encoder, we obtain four out- put: µ i1 , σ i1 µ i2 and σ i2 . They can be treated as the means and variances of the distribution of content information and structure information re- spectively. Furthermore, we sample two values ε i1 and ε i2 from two previous distributions (e.g., Gaussian distribution). Then we can obtain the re- parameterized z i 1 and z 2 1. Through concatenate z i 1 and z 2 1, content and structure information can be integrated together, y i is the representation of the network. Nonlinear operations are not per- formed in this phase. Thus, the gradient descent method can be safely applied in optimization. The operations can be expressed as follows:</p><formula xml:id="formula_1">z ik = f (µ ik , σ ik , ε i ), k = 1, 2 y i = M erge[z i1 , z i2 ]<label>(2)</label></formula><p>where f is a linear function that can re- parameterize y i , M erge concatenate the two vec- tors together directly. The decoding phase is a reflection of the en- coder; its outputˆxoutputˆ outputˆx i should be close to the input x i . The loss function of this module that should be minimized is as follows:</p><formula xml:id="formula_2">L(x i ) = − 2 k=1 KL(q(z ik |x i )||p(z ik ))+H(x i , ˆ x i )<label>(3)</label></formula><p>where KL is the KL divergence which is always used as a measure of the difference between two distributions, H is a cross-entropy function that is used to measure the difference between x i andˆxandˆ andˆx i .</p><p>Finally, We choose the output of the layer y i as the final representation of each node.  We compare our approach with the following methods:</p><p>• One-Hot uses adjacency matrix, which car- ries the structure information as the high- dimension representation, and directly feed into the classifier.</p><p>• DeepWalk ( <ref type="bibr" target="#b7">Perozzi et al., 2014</ref>) is exploited by statistical models, which employs trun- cated random walks to learns nodes embed- ding by treating walk as the equivalent of sen- tences.</p><p>• Node2vec (Grover and Leskovec, 2016) learns the network representation by design- ing a biased random walk procedure which efficiently explores diverse neighborhoods.</p><p>• Doc2vec ( <ref type="bibr" target="#b5">Le and Mikolov, 2014</ref>) is the Para- graph Vector model that learns document rep- resentation by predicting the words appeared.</p><p>• DW+D2V is simply to concatenate the rep- resentation result learned by DeepWalk and Doc2vec.</p><p>• TADW ( <ref type="bibr" target="#b12">Yang et al., 2015</ref>) is text-based DeepWalk, which incorporates text informa- tion into network structure by matrix factor- ization.</p><p>• TriDNR (Pan et al., 2016) uses node text, la- bel, and structure to jointly learn node repre- sentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance on Node Classification</head><p>We conduct the paper classification task on two benchmark citation networks to evaluate the per- formance of our method. To reduce the impact of sophisticated classifiers on the performance, we employ a linear SVM, which is a common tech- nique used by the exiting work ( <ref type="bibr" target="#b6">Pan et al., 2016)</ref>.</p><p>The results are shown in <ref type="table" target="#tab_0">Table 1 and Table 2</ref>, re- spectively. The reported parameters for our model are set: dimension d=100 on CiteseerM10 and d=300 on DBLP. The dimension for other algo- rithms is the same as ours, and the other parame- ters are set as their papers report, i.e., window size b=10 in DeepWalk and Node2vec, in-out parame- ter q=2 in Node2vec, text weight ∂=0.8 in TADW and TriDNR. We use Macro-F1 which is the same as that adopted by other algorithms to measure the classification performance. The experiments are independently conducted 10 times for each setting, and the average values are reported. The propor- tion of training data with labels is range from 10% to 70%. Our model is evaluated by comparing it with seven approaches. One-Hot uses the original structure data, and its performance is poor because it is discrete and the context relation of nodes can not be captured. DeepWalk and Node2vec are structure-based methods that exhibit inferior per- formance mainly because they only use the shal- low structure information and the network is rather sparse, while the information of the complex non- linear structure cannot be employed. The perfor- mance of Doc2vec is not as good as ours which demonstrates the effectiveness of our proposed model. TADW and TriDNR are inferior to our approach, although these two methods also con- sider the text and structure. Nevertheless, they cannot capture the complex non-linear structure. The reason for the superior of our method is that our model can effectively capture the inter- relationship between node content and link struc- ture, and the intro-relationship among nodes and links, which are essential to learn the represen- tation of networks. Furthermore, our model can capture the information of highly non-linear struc- ture instead of the shallow structure (e.g., Deep- Walk) by exploiting VAE. Moreover, our approach does not require heavy text information which is utilized by the other state-of-the-art strategies (e.g.,TriDNR). Our model exhibits consistent su- perior performance, and is up to 16% better than the state-of-the-art methods (i.e., the Macro-F1 score of our model is 94% when the proportion of training data with labels is 70% conducted on the Citeseer-M10 Network dataset).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parameter Setting</head><p>A significant hyperparameter in our model is the dimension d. The performance of different meth- ods with varying dimensions has been evaluated. The result is illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>. We obtain very good performance on the CiteSeer-M10 dataset, i.e., the Macro-F1 score is 94% and the perfor- mance tends to be stable as b becomes larger. It validates the effectiveness of our algorithm and the reason is due to the ability of our model that can capture the complex network structure and the text information. <ref type="figure" target="#fig_1">From Fig. 2</ref>, we can see that the per- formance gets better when d increases from 100 to 600. We think the main reason is because more in- formation can be preserved in higher dimensional space of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we have introduced an effective network representation model, which comprehen- sively integrates the text information and the net- work structure. We introduced Paragraph Model as a preliminary module. And we have exploited Variational Autoencoder as the main block of our model, that could capture highly non-linear struc- ture of the network. The comprehensive experi- mental evaluation on two benchmark datasets has demonstrated the effectiveness of the model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1</head><label></label><figDesc>http://citeseerx.ist.psu.edu/ 2 http://arnetminer.org/citation (V4 version is used)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance of each strategy on different training proportion p</figDesc><graphic url="image-2.png" coords="5,72.00,62.81,113.37,96.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Macro-F1 score on Citeseer-M10 Network %p One-Hot Deepwalk Node2vec Doc2vec DW+D2V TADW TriDNR Ours</head><label>1</label><figDesc></figDesc><table>10% 
0.254 
0.297 
0.314 
0.503 
0.526 
0.475 
0.683 
0.889 
30% 
0.321 
0.334 
0.331 
0.536 
0.615 
0.488 
0.744 
0.913 
50% 
0.352 
0.346 
0.346 
0.547 
0.633 
0.495 
0.760 
0.924 
70% 
0.363 
0.344 
0.339 
0.534 
0.630 
0.495 
0.773 
0.940 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Macro-F1 score on DBLP Network 

%p One-Hot Deepwalk Node2vec Doc2vec DW+D2V TADW TriDNR Ours 

10% 
0.328 
0.379 
0.448 
0.574 
0.495 
0.660 
0.724 
0.751 
30% 
0.362 
0.454 
0.473 
0.598 
0.586 
0.687 
0.742 
0.753 
50% 
0.371 
0.459 
0.475 
0.604 
0.614 
0.697 
0.747 
0.762 
70% 
0.372 
0.461 
0.476 
0.605 
0.628 
0.699 
0.748 
0.763 

CiteSeerM10 1 . It contains 10 distinct categories 
with 10,310 papers and 77,218 citations. Titles 
are treated as the text information because no 
more text information is available; and (2) DBLP 
dataset 2 . We treat abstracts as text information 
and choose 4 research areas with the same setting 
as that of (Pan et al., 2016), which are database 
(SIGMOD, ICDE, VLDB, EDBT, PODS, ICDT, 
DASFAA, SSDBM, CIKM), data mining (KDD, 
ICDM, SDM, PKDD, PAKDD), artificial intelli-
gent (IJCAI, AAAI, NIPS, ICML, ECML, ACML, 
IJCNN, UAI, ECAI, COLT, ACL, KR), computer 
vision (CVPR, ICCV, ECCV, ACCV, MM, ICPR, 
ICIP, ICME). Therefore we get a network contains 
30,422 nodes and 41,206 edges. 
</table></figure>

			<note place="foot" n="4"> Experiments 4.1 Experimental setup Paper citation networks is a classical social information network. To evaluate the quality of the proposed model, we conduct three important tasks on two benchmark citation network datasets: (1)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research is supported by the National Nat-ural Science Foundation of China: U1636116, 11431006, Research Fund for International Young Scientists: 61650110510, Ministry of Education of Humanities and Social Science: 16YJC790123.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Laplacian eigenmaps for dimensionality reduction and data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1373" to="1396" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">deep neural network for learning graph representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaosheng</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaosheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiongkai</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">Grarep:learning graph representations with global structural information</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Autoencoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tri-party deep network representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Shirui Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingquan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Nonlinear dimensionality reduction by locally linear embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A global geometric framework for nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vin</forename><forename type="middle">De</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2319" to="2323" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Inproceedings</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Network representation learning with rich text information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
