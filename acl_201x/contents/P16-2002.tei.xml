<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Semi-Supervised Query Classification Using Matrix Sketching</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
							<email>stratos@cs.columbia.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Columbia University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
							<email>{ybkim, ruhi.sarikaya}@microsoft.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Corporation</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Semi-Supervised Query Classification Using Matrix Sketching</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="8" to="13"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The enormous scale of unlabeled text available today necessitates scalable schemes for representation learning in natural language processing. For instance, in this paper we are interested in classifying the intent of a user query. While our labeled data is quite limited, we have access to virtually an unlimited amount of unlabeled queries, which could be used to induce useful representations: for instance by principal component analysis (PCA). However, it is prohibitive to even store the data in memory due to its sheer size, let alone apply conventional batch algorithms. In this work, we apply the recently proposed matrix sketching algorithm to entirely obviate the problem with scalability (Liberty, 2013). This algorithm approximates the data within a specified memory bound while preserving the covariance structure necessary for PCA. Using matrix sketching, we significantly improve the user intent classification accuracy by leveraging large amounts of unlabeled queries.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The large amount of high quality unlabeled data available today provides an opportunity to im- prove performance in tasks with limited supervi- sion through a semi-supervised framework: learn useful representations from the unlabeled data and use them to augment supervised models. Un- fortunately, conventional exact methods are no longer feasible on such data due to scalability is- sues. Even algorithms that are considered rela- tively scalable (e.g., the Lanczos algorithm <ref type="bibr" target="#b3">(Cullum and Willoughby, 2002</ref>) for computing eigen- value decomposition of large sparse matrices) fall apart in this scenario, since the data cannot be stored in the memory of a single machine. Con- sequently, approximate methods are needed.</p><p>In this paper, we are interested in improving the performance for sentence classification task by leveraging unlabeled data. For this task, supervi- sion is precious but the amount of unlabeled sen- tences is essentially unlimited. We aim to learn sentence representations from as many unlabeled queries as possible via principal component anal- ysis (PCA): specifically, learn a projection matrix for embedding a bag-of-words vector into a low- dimensional dense feature vector. However, it is not clear how we can compute an effective PCA when we are unable to even store the data in the memory.</p><p>Recently, Liberty (2013) proposed a scheme, called matrix sketching, for approximating a ma- trix while preserving its covariance structure. This algorithm, given a memory budget, deterministi- cally processes a stream of data points while never exceeding the memory bound. It does so by occa- sionally computing singular value decomposition (SVD) on a small matrix. Importantly, the algo- rithm has a theoretical guarantee on the accuracy of the approximated matrix in terms of its covari- ance structure, which is the key quantity in PCA calculation.</p><p>We propose to combine the matrix sketching al- gorithm with random hashing to completely re- move limitations on data sizes. In experiments, we significantly improve the intent classification ac- curacy by learning sentence representations from huge amounts of unlabeled sentences, outperform- ing a strong baseline based on word embeddings trained on 840 billion tokens ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Deterministic Matrix Sketching</head><p>PCA is typically performed to reduce the dimen- sion of each data point. Let X ∈ R n×d be a data matrix whose n rows correspond to n data points in R d . For simplicity, assume that X is pre- processed to have zero column means. The key quantity in PCA is the empirical covariance ma- trix X X ∈ R d×d (up to harmless scaling). It is well-known that the m length-normalized eigen- vectors u 1 . . . u m ∈ R d of X X corresponding to the largest eigenvalues are orthogonal directions along which the variance of the data is maximized. Then if Π ∈ R d×m be a matrix whose i-th col- umn is u i , the PCA representation of X is given by XΠ. PCA has been a workhorse in representation learning, e.g., inducing features for face recogni- tion ( <ref type="bibr" target="#b22">Turk et al., 1991)</ref>.</p><p>Frequently, however, the number of samples n is simply too large to work with. As n tends to billions and trillions, storing the entire matrix X in memory is practically impossible. Processing large datasets often require larger memory than the capacity of a typical single enterprise server. Clusters may enable a aggregating many boxes of memory on different machines, to build distributed memory systems achieving large memory capac- ity. However, building and maintaining these in- dustry grade clusters is not trivial and thus not ac- cessible to everyone. It is critical to have tech- niques that can process large data within a lim- ited memory budget available in most typical en- terprise servers.</p><p>One solution is to approximate the matrix with some Y ∈ R l×d where l n. Many matrix ap- proximation techniques have been proposed, such as random projection ( <ref type="bibr" target="#b17">Papadimitriou et al., 1998;</ref><ref type="bibr" target="#b23">Vempala, 2005</ref>), sampling ( <ref type="bibr" target="#b4">Drineas and Kannan, 2003;</ref><ref type="bibr" target="#b19">Rudelson and Vershynin, 2007;</ref><ref type="bibr" target="#b9">Kim and Snyder, 2013;</ref><ref type="bibr" target="#b11">Kim et al., 2015b)</ref>, and hashing <ref type="bibr" target="#b24">(Weinberger et al., 2009</ref>). Most of these tech- niques involve randomness, which can be undesir- able in certain situations (e.g., when experiments need to be exactly reproducible). Moreover, many are not designed directly for the objective that we care about: namely, ensuring that the covariance matrices X X and Y Y remain "similar".</p><formula xml:id="formula_0">Input: data stream x1 . . . xn ∈ R d , sketch size l 1. Initialize zero-valued Y ∈ 0 l×d . 2. For i = 1 . . . n, (a) Insert xi to the first zero-valued row of Y . (b) If Y has no zero-valued row, i. Compute SVD of Y = U ΣV where Σ = diag(σ1 . . . σ l ) with σ1 ≥ · · · ≥ σ l .</formula><p>ii. Compute a diagonal matrix Σ with at least l/2 zeros by setting A recent result by Liberty <ref type="formula" target="#formula_2">(2013)</ref> gives a de- terministic matrix sketching algorithm that tightly preserves the covariance structure needed for PCA. Specifically, given a sketch size l, the algo-</p><formula xml:id="formula_1">Σj,j = max Σ 2 j,j − σ 2 l/2 , 0 iii. Set Y = ΣV . Output:Y ∈ R l×d s.t. X X − Y Y 2 ≤ 2 ||X|| 2 F /l</formula><formula xml:id="formula_2">rithm computes Y ∈ R l×d such that X X − Y Y 2 ≤ 2 ||X|| 2 F /l<label>(1)</label></formula><p>This result guarantees that the error decreases in O(1/l); in contrast, other approximation tech- niques have a significantly worse convergence</p><formula xml:id="formula_3">bound of O(1/ √ l).</formula><p>The algorithm is pleasantly simple and is given in <ref type="figure" target="#fig_0">Figure 1</ref> for completeness. It processes one data point at a time to update the sketch Y in an on- line fashion. Once the sketch is "full", its SVD is computed and the rows that fall below a threshold given by the median singular value are eliminated. This operation ensures that every time SVD is per- formed at least a half of the rows are discarded. Consequently, we perform no more than O(2n/l) SVDs on a small matrix Y ∈ R l×d . The analy- sis of the bound (1) is an extension of the "median trick" for count sketching and is also surprisingly elementary; we refer to Liberty (2013) for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Matrix Sketching for Sentence Representations</head><p>Our goal is to leverage enormous quantities of un- labeled sentences to augment supervised training for intent classification. We do so by learning a PCA projection matrix Π from the unlabeled data and applying it on both training and test sentences. The matrix sketching algorithm in <ref type="figure" target="#fig_0">Figure 1</ref> en- ables us to compute Π on arbitrarily large data. There are many design considerations for using the sketching algorithm for our task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Original sentence representations</head><p>We use a bag-of-words vector to represent a sentence. Specifically, each sentence is a d- dimensional vector x ∈ R d where d is the size of the vocabulary and x i is the count of an n-gram i in the sentence (we use up to n = 3 in exper- iments); we denote this representation by SENT. In experiments, we also use a modification of this representation, denoted by SENT+, in which we explicitly define features over the first two words in a query and also use intent predictions made by a supervised model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Random hashing</head><p>When we process an enormous corpus, it can be computationally expensive just to obtain the vo- cabulary size d in the corpus. We propose using random hashing to avoid this problem. Specif- ically, we pre-define the hash size H we want, and then on encountering any word w we map w → {1 . . . H} using a fixed hash function. This allows us to compute a bag-of-words vector for any sentence without knowing the vocabulary size. See <ref type="bibr" target="#b24">Weinberger et al. (2009)</ref> for a justification of the hashing trick for kernel methods (applicable in our setting since PCA has a kernel (dual) interpre- tation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parallelization</head><p>The sketching algorithm works in a sequential manner, processing each sentence at a time. While it leaves a small memory footprint, it can take pro- hibitively long time to process a large corpus. <ref type="bibr" target="#b15">Liberty (2013)</ref> shows it is trivial to parallelize the al- gorithm: one can compute several sketches in par- allel and then sketch the conjoined sketches. The theory guarantees that such layered sketches does not degrade the bound (1). We implement this par- allelization to obtain an order of magnitude speed- up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Final sentence representation:</head><p>Once we learn a PCA projection matrix Π, we use it in both training and test times to obtain a dense feature vector of a bag-of-words sentence repre- sentation. Specifically, if x is the original bag-of- words sentence vector, the new representation is given by</p><formula xml:id="formula_4">x new = x ||x|| ⊕ xΠ ||xΠ|| (2)</formula><p>where ⊕ is the vector concatenation operation. This representational scheme is shown to be effec- tive in previous work (e.g., see <ref type="bibr" target="#b20">Stratos and Collins (2015)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Experiment</head><p>To test our proposed method, we conduct in- tent classification experiments <ref type="bibr" target="#b6">(Hakkani-Tür et al., 2013;</ref><ref type="bibr" target="#b0">Celikyilmaz et al., 2011;</ref><ref type="bibr" target="#b7">Ji et al., 2014;</ref><ref type="bibr" target="#b5">El-Kahky et al., 2014;</ref><ref type="bibr" target="#b1">Chen et al., 2016</ref>) across a suite of 22 domains shown in <ref type="table">Table 1</ref>. An in- tent is defined as the type of content the user is seeking. This task is part of the spoken language understanding problem ( <ref type="bibr" target="#b14">Li et al., 2009;</ref><ref type="bibr" target="#b21">Tur and De Mori, 2011;</ref><ref type="bibr" target="#b12">Kim et al., 2015c;</ref><ref type="bibr" target="#b16">Mesnil et al., 2015;</ref><ref type="bibr" target="#b10">Kim et al., 2015a;</ref><ref type="bibr" target="#b25">Xu and Sarikaya, 2014;</ref><ref type="bibr" target="#b11">Kim et al., 2015b;</ref><ref type="bibr" target="#b13">Kim et al., 2015d</ref>).</p><p>The amount of training data we used ranges from 12k to 120k (in number of queries) across different domains, the test data was from 2k to 20k. The number of intents ranges from 5 to 39 per domains. To learn a PCA projection matrix from the unlabeled data, we collected around 17 billion unlabeled queries from search logs, which give the original data matrix whose columns are bag-of-n-grams vector (up to trigrams) and has di- mensions approximately 17 billions by 41 billions, more specifically, X ∈ R 17,032,086,719×40,986,835,008</p><p>We use a much smaller sketching matrix Y ∈ R 1,000,000×1,000,000 to approximate X. Note that column size is hashing size. We parallelized the sketching computation over 1,000 machines; we will call the number of machines parallelized over "batch". In all our experiments, we train a linear multi-class SVM <ref type="bibr" target="#b2">(Crammer and Singer, 2002</ref>). <ref type="table">Table 1</ref> shows the performance of intent classifica- tion across domains. For the baseline, SVM with- out embedding (w/o Embed) achieved 91.99% ac- curacy, which is already very competitive. How- ever, the models with word embedding trained on w/o Embed 6B-50d 840B-300d  <ref type="table">Table 1</ref>: Performance comparison between different embeddings style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Results of Intent Classification Task</head><p>6 billion tokens (6B-50d) and 840 billion tokens (840B-300d) ( <ref type="bibr" target="#b18">Pennington et al., 2014</ref>) achieved 92.89% and 93.00%, respectively. 50d and 300d denote size of embedding dimension. To use word embeddings as a sentence representation, we sim- ply use averaged word vectors over a sentence, normalized and conjoined with the original rep- resentation as in <ref type="bibr">(2)</ref>. Surprisingly, when we use sentence representation (SENT) induced from the sketching method with our data set, we can boost the performance up to 93.49%, corresponding to a 18.78% decrease in error relative to a SVM without representation. Also, we see that the ex- tended sentence representation (SENT+) can get additional gains.</p><p>As in <ref type="table" target="#tab_2">Table 2</ref> , we also measured performance of our method (SENT+) as a function of the per- centage of unlabeled data we used from total un- labeled sentences. The overall trend is clear: as the number of sentences are added to the data for inducing sentence representation, the test perfor- mance improves because of both better coverage and better quality of embedding. We believe that if we consume more data, we can boost up the per- formance even more.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Results of Parallelization</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Matrix sketching algorithm by Liberty (2013). In the output, X ∈ R n×d denotes the data matrix with rows x 1. .. x n .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 shows</head><label>3</label><figDesc>89.16 89.83 90.04 90.26 90.88 91.9 92.41 92.41 92.95 93.72 94.3 music 87.87 89.12 89.61 90.4 90.83 91.26 91.31 91.33 91.38 91.33 91.33 tv 91.42 92.28 92.83 93.61 93.96 94.67 94.91 95.12 95.34 95.44 95.47</figDesc><table>the sketching results for vari-
ous batch size. To evaluate parallelization, we 
first randomly generate a matrix R 1,000,000×100 
and it is sketched to R 100×100 . And then we 
sketch run with different batch size. The results 
show that as the number of batch increases, we 
can speed up dramatically, keeping residual value 



X X − Y Y 



2 . It indeed satisfies the bound 

value, ||X|| 2 
F /l, which was 100014503.16. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Performance for selected domains as the number of unlabeled data increases.</head><label>2</label><figDesc></figDesc><table>Batch Size 



X X − Y Y 



2 
time 
1 
1019779.69 
100.21 
2 
1019758.22 
50.31 
4 
1019714.19 
26.50 
5 
1019713.43 
21.67 
8 
1019679.67 
14.53 
10 
1019692.67 
12.13 
16 
1019686.35 
8.53 
20 
1019709.03 
7.35 
25 
1019650.51 
6.40 
40 
1019703.24 
4.97 
50 
1019689.33 
4.48 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results for corresponding batch size. 
Second column indicates the norm of gap between 
original and sketching matrix. Time represents the 
running time for sketching methods, measured in 
seconds. </table></figure>

			<note place="foot" n="4"> Conclusion We introduced how to use matrix sketching algorithm of (Liberty, 2013) for scalable semisupervised sentence classification. This algorithm approximates the data within a specified memory bound while preserving the covariance structure necessary for PCA. Using matrix sketching, we significantly improved the classification accuracy by leveraging very large amounts of unlabeled sentences.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Leveraging web query logs to learn user intent via bayesian discrete latent variable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tür</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Zero-shot learning of intent embeddings for expansion by convolutional deep structured semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICASSP</title>
		<meeting>of ICASSP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the learnability and design of output codes for multiclass problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="201" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph A</forename><surname>Cullum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Willoughby</surname></persName>
		</author>
		<title level="m">Lanczos Algorithms for Large Symmetric Eigenvalue Computations</title>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pass efficient algorithms for approximating large matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petros</forename><surname>Drineas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SODA</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="223" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Extending domain coverage of language understanding systems via intent transfer between domains using knowledge graphs and search query click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>El-Kahky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4067" to="4071" />
		</imprint>
	</monogr>
	<note>2014 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A weakly-supervised approach for discovering new user intents from search query logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Larry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3780" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A variational bayesian model for user intent detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>ICASSP</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="4072" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimal data set selection: An application to graphemeto-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1196" to="1205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly supervised slot tagging with partially labeled sequences from web search click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on the North American Chapter of the Association for Computational Linguistics-Human Language Technologies</title>
		<meeting>of the Conference on the North American Chapter of the Association for Computational Linguistics-Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compact lexicon selection with spectral methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pre-training of hidden-unit crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="192" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">New transfer learning techniques for disparate label sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extracting structured information from user queries with semi-supervised conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 32nd international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple and deterministic matrix sketching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edo</forename><surname>Liberty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="581" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using recurrent neural networks for slot filling in spoken language understanding. Audio, Speech, and Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="530" to="539" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latent semantic indexing: A probabilistic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Christos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisao</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Tamaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vempala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems</title>
		<meeting>the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empiricial Methods in Natural Language Processing</title>
		<meeting>the Empiricial Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sampling from large matrices: An approach through geometric functional analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Rudelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Vershynin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simple semisupervised pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Spoken language understanding: Systems for extracting semantic information from speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Face recognition using eigenfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">P</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="586" to="591" />
		</imprint>
	</monogr>
	<note>IEEE Computer Society Conference on</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The random projection method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vempala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>American Mathematical Soc</publisher>
			<biblScope unit="volume">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feature hashing for large scale multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Attenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Contextual domain classification in spoken language understanding systems using recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="136" to="140" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
