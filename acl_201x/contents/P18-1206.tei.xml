<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Efficient Large-Scale Neural Domain Classification with Personalized Attention</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018. 2214</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongchan</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjishnu</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amazon</forename><surname>Alexa</surname></persName>
						</author>
						<title level="a" type="main">Efficient Large-Scale Neural Domain Classification with Personalized Attention</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2214" to="2224"/>
							<date type="published">July 15-20, 2018. 2018. 2214</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we explore the task of mapping spoken language utterances to one of thousands of natural language understanding domains in intelligent personal digital assistants (IPDAs). This scenario is observed in mainstream IPDAs in industry that allow third parties to develop thousands of new domains to augment built-in first party domains to rapidly increase domain coverage and overall IPDA capabilities. We propose a scalable neu-ral model architecture with a shared en-coder, a novel attention mechanism that incorporates personalization information and domain-specific classifiers that solves the problem efficiently. Our architecture is designed to efficiently accommodate incremental domain additions achieving two orders of magnitude speed up compared to full model retraining. We consider the practical constraints of real-time production systems, and design to minimize memory footprint and runtime la-tency. We demonstrate that incorporating personalization significantly improves domain classification accuracy in a setting with thousands of overlapping domains.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Intelligent personal digital assistants (IPDAs) are one of the most advanced and successful artifi- cial intelligence applications that have spoken lan- guage understanding (SLU). Many IPDAs have recently emerged in industry including Amazon Alexa, Google Assistant, Apple Siri, and Mi- crosoft Cortana <ref type="bibr" target="#b34">(Sarikaya, 2017)</ref>. IPDAs have tra- ditionally supported only dozens of well-separated domains, each defined in terms of a specific ap- plication or functionality such as calendar and lo- cal search <ref type="bibr" target="#b38">(Tur and de Mori, 2011;</ref>. To rapidly increase domain coverage and extend capabilities, some IPDAs have released Software Development Toolkits (SDKs) to allow third-party developers to quickly build and inte- grate new domains, which we refer to as skills henceforth. Amazon's Alexa Skills Kit ( <ref type="bibr" target="#b26">Kumar et al., 2017a</ref>), Google's Actions and Microsoft's Cortana Skills Kit are all examples of such SDKs. Alexa Skills Kit is the largest of these services with over 40,000 skills.</p><p>For IPDAs, finding the most relevant skill to handle an utterance is an open problem for three reasons. First, the sheer number of skills makes the task difficult. Unlike traditional systems that have on the order of 10-20 built-in domains, large- scale IPDAs can have up to 40,000 skills. Sec- ond, the number of skills is rapidly expanding with 100+ new skills added per week. Large- scale IPDAs should be able to accommodate new skills efficiently without compromising perfor- mance. Third, unlike traditional built-in domains that are carefully designed to be disjoint by a cen- tral team, skills are built independently by differ- ent developers and can cover overlapping func- tionalities. For instance, there are over 50 recipe skills in Alexa that can handle recipe-related utter- ances.</p><p>One simple solution to this problem has been to require the user to explicitly mention a skill name and follow a strict invocation pattern as in "Ask {Uber} to {get me a ride}." However, this signif- icantly limits the natural interaction with IPDAs. Users have to remember skill names and invoca- tion patterns, and it places a cognitive burden on users who tend to forget both. Skill discovery is difficult with a pure voice user interface, it is hard for users to know the capabilities of thousands of skills a priori, which may leads to limited user en-gagement with skills and potentially with IPDAs.</p><p>In this paper, we propose a solution that ad- dresses all three practical challenges without re- quiring skill names or invocation patterns. Our approach is based on a scalable neural model ar- chitecture with a shared encoder, a skill atten- tion mechanism and skill-specific classification networks that can efficiently perform large-scale skill classification in IPDAs using a weakly su- pervised training dataset. We demonstrate that our model achieves a high accuracy on a manu- ally transcribed test set after being trained with weak supervision. Moreover, our architecture is designed to efficiently integrate new skills that ap- pear in-between full model retraining cycles into the model. Besides accuracy, we also keep prac- tical constraints in mind and focus on minimiz- ing memory footprint and runtime latency, while ensuring architecture is scalable to thousands of skills, all of which are important for real-time pro- duction systems. Furthermore, we investigate two different ways of incorporating user personaliza- tion information into the model, our naive base- line method adds the information as a 1-bit flag in the feature space of the skill-specific networks, the personalized attention technique computes a con- vex combination of skill embeddings for the user's enabled skills and significantly outperforms the naive personalization baseline. We show the ef- fectiveness of our approach with extensive exper- iments using 1,500 skills from a deployed IPDA system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Traditional multi-domain SLU/NLU systems are designed hierarchically, starting with domain clas- sification to classify an incoming utterance into one of many possible domains, followed by fur- ther semantic analysis with domain-specific intent classification and slot tagging (Tur and <ref type="bibr" target="#b38">de Mori, 2011)</ref>. Traditional systems have typically been limited to a small number of domains, designed by specialists to be well-separable. Therefore, domain classification has been considered a less complex task compared to other semantic anal- ysis such as intent and slot predictions. Tradi- tional domain classifiers are built using simple lin- ear models such as Multinomial Logistic Regres- sion or Support Vector Machines in a one-versus- all setting for multi-class prediction. The models typically use word n-gram features and also those based on static lexicon match, and there have been several recent studies applying deep learning tech- niques ( <ref type="bibr" target="#b40">Xu and Sarikaya, 2014)</ref>.</p><p>There is also a line of prior work on enhanc- ing sequential text classification or tagging. Hier- archical character-to-word level LSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997</ref>) architectures similar to our models have been explored for the Named Entity Recognition task by <ref type="bibr" target="#b28">Lample et al. (2016)</ref>. Character-informed sequence models have also been explored for simple text classification with small sets of classes by <ref type="bibr" target="#b39">Xiao and Cho (2016)</ref>. <ref type="bibr" target="#b12">Joulin et al. (2016)</ref> explored highly scalable text classification using a shared hierarchical encoder, but their hierarchical softmax-based output formu- lation is unsuitable for incremental model updates. Work on zero-shot domain classifier expansion by <ref type="bibr" target="#b27">Kumar et al. (2017b)</ref> struggled to rank incom- ing domains higher than training domains. The attention-based approach of <ref type="bibr" target="#b19">Kim et al. (2017d)</ref> does not require retraining from scratch, but it requires keeping all models stored in memory which is computationally expensive. Multi-Task learning was used in the context of SLU by <ref type="bibr" target="#b37">Tur (2006)</ref> and has been further explored using neu- ral networks for phoneme recognition <ref type="bibr" target="#b36">(Seltzer and Droppo, 2013)</ref> and semantic parsing <ref type="bibr" target="#b7">(Fan et al., 2017;</ref><ref type="bibr" target="#b1">Bapna et al., 2017)</ref>. There have been many other pieces of prior work on improving NLU sys- tems with pre-training ( <ref type="bibr" target="#b20">Kim et al., 2015b;</ref><ref type="bibr" target="#b22">Kim et al., 2017e)</ref>, multi-task learning ( <ref type="bibr" target="#b42">Zhang and Wang, 2016;</ref><ref type="bibr" target="#b29">Liu and Lane, 2016;</ref><ref type="bibr" target="#b17">Kim et al., 2017b</ref>), transfer learning <ref type="bibr">(ElKahky et al., 2014;</ref><ref type="bibr">Kim et al., 2015a,c;</ref><ref type="bibr" target="#b4">Chen et al., 2016a;</ref><ref type="bibr" target="#b41">Yang et al., 2017)</ref>, domain adaptation ( <ref type="bibr" target="#b11">Jaech et al., 2016;</ref><ref type="bibr" target="#b30">Liu and Lane, 2017;</ref><ref type="bibr" target="#b19">Kim et al., 2017d</ref>,c) and contextual signals <ref type="bibr" target="#b2">(Bhargava et al., 2013;</ref><ref type="bibr" target="#b5">Chen et al., 2016b;</ref><ref type="bibr" target="#b10">Hori et al., 2016;</ref><ref type="bibr" target="#b16">Kim et al., 2017a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Weakly Supervised Training Data Generation</head><p>Our model addresses the domain classification task in SLU systems. In traditional IPDA systems, these domains are hand-crafted by experts to be well separable and can easily be annotated by hu- mans because they are small in number. The emer- gence of self-service SLU results in a large num- ber of potentially mutually overlapping SLU do- mains. This means that eliciting large volumes of high quality human annotations to train our model  is no longer feasible, and we cannot assume that domains are designed to be well separable.</p><p>Instead we can generate training data by adopt- ing the weak supervision paradigm introduced by <ref type="bibr" target="#b9">(Hoffmann et al., 2011</ref>), which proposes using heuristic labeling functions generate large num- bers of noisy data samples. Clean data generation with weak supervision is a challenging problem, so we address it by decomposing it into two sim- pler problems, of candidate generation and noise suppression, however it remains important for our model to be noise robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Programming</head><p>The key insight of the Data Programming ap- proach is that O(1) simple labeling functions can be used to approximate O(n) human annotated data points with much less effort. We adopt the formalism used by <ref type="bibr" target="#b33">(Ratner et al., 2016</ref>) to treat each of instance data generation rule as a rich gen- erative model, defined by a labeling function λ and describe different families of labeling functions. Our data programming pipeline is analogous to the noisy channel model proposed for spelling correc- tion by <ref type="bibr" target="#b14">(Kernighan et al., 1990)</ref>, and consists of a set of candidate generation and noise detection functions.</p><p>arg max</p><formula xml:id="formula_0">µ P (µ|s i ) = arg max µ P (s i |µ). P (µ)</formula><p>where µ and s i represent utterances and the ith skill respectively. P (s i |µ) the probability of a skill being valid for an utterance is approximated by simple functions that act as candidate data genera- tors λ g ∈ Λ g based on recognitions produced by a family of query patterns λ q ∈ Λ q . P (µ) is repre- sented by a family of simple functions that act as noise detectors λ n ∈ Λ n , which mark utterances as likely being noise.</p><p>We apply the technique to the query logs of a popular IPDA, which has support for personalized third party domains. Looking at the structure of utterances that match query pattern λ q , each utter- ance of form "Ask {Uber} to {get me a car}" can be considered as being parametrized by the under- lying latent command µ z , that is "Get me a car", a target domain corresponding to service s t , which in this case is Uber and the query recognition pat- tern λ q , in this case "Ask {s t } to {µ z }". Next we assume that the distribution of latent commands over domains are independent of the query pattern.</p><formula xml:id="formula_1">P (µ z , s t ) ≈ P (µ, s t , λ q )</formula><p>Making this simple distributional approximation allows us to generate a large number of noisy train- ing samples. The family of generator functions λ g ∈ Λ g is thus defined such that u z = λ i g (µ, λ i q )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Noise Reduction</head><p>The distribution defined above contains a large number of noisy positive samples. Related to P (µ) in the noisy channel in the spell correction context, we defined a small family of heuristic noise detection functions λ n ∈ Λ n that discards training data instances that are not likely to be well formed. For instance,</p><p>• λ 1 n requires u to contain a minimum thresh- old of information by removing those with µ z that has token length fewer than 3. Utter- ances shorter than this mostly consist of non- actionable commands.</p><p>• λ 2 n discards all data samples below a certain threshold of occurrences in live traffic, since utterances that are rarely observed are more likely to be ASR errors or unnatural.</p><p>• λ 3 n discards the data samples for a domain if they come from an overly broad pattern with a catch-all behavior.</p><p>• λ 4 n discards utterances that belong to shared intents provided by the SLU SDK.</p><p>The end result of this stage is to retain utter- ances such as 'call me a cab' from 'Ask Uber to call me a cab' but discard 'Boston' from 'Ask Ac- cuweather for Boston'. One can easily imagine extending this framework with other high recall noise detectors, for example, using language mod- els to discard candidates that are unlikely to be spoken sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model Architecture</head><p>Our model consists of a shared encoder network consisting of an orthography-sensitive hierarchical LSTM encoder that feeds into a set of domain spe- cific classification layers trained to make a binary decision for each output label.</p><p>Our main novel contribution is the extension of this architecture with a personalized attention mechanism which uses the attention mechanism of ( <ref type="bibr" target="#b0">Bahdanau et al., 2014</ref>) to attend to memory lo- cations corresponding to the specific domains en- abled by a user, and allows the system to learn semantic representations of each domain via do- main embeddings. As we will show, incorporat- ing personalization features is key to disambiguat- ing between multiple overlapping domains 1 , and the personalized attention mechanism outperforms more naive forms of personalization. The person- alized attention mechanism first computes an at- tention weight for each of enabled domains, per- forms a convex combination to compute a context vector and then concatenates this vector to the en- coded utterance before the final domain classifica- tion. <ref type="figure" target="#fig_0">Figure 1</ref> depicts the model in detail.</p><p>Our model can efficiently accommodate new domains not seen during initial training by keep- ing the shared encoder frozen, bootstrapping a do- main embedding based on existing ones, then opti- mizing a small number of network parameters cor- responding to domain-specific classifier, which is orders of magnitude faster and more data efficient than retraining the full classifier.</p><p>We make design decisions to ensure that our model has a low memory and latency footprint. We avoid expensive large vocabulary matrix mul- tiplications on both the input and output stages, and instead use a combination of character embed- dings and word embeddings in the input stage. <ref type="bibr">2</ref> The output matrix is lightweight because each domain-specific classifier is a matrix of only 201×2 parameters. The inference task can be triv- ially parallelized across cores since there's no re- quirement to compute a partition function across a high-dimensional softmax layer, which is the slowest component of large label multiclass neu- ral networks. Instead, we achieve comparability between the probability scores generated by indi- vidual models by using a customized loss formu- lation. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Shared Encoder</head><p>First we describe our shared hierarchical utterance encoder, which is marked by the almond colored box in <ref type="figure" target="#fig_0">Figure 1</ref>. Our hierarchical character to word to utterance design is motivated by the need to make the model operate on an open vocabulary in terms of words and to make it robust to small changes in orthography resulting from fluctuations in the upstream ASR system, all while avoiding expensive large matrix multiplications associated with one-hot word encoding in large vocabulary systems.</p><p>We denote an LSTM simply as a mapping φ :</p><formula xml:id="formula_2">R d × R d → R d that takes a d dimensional in- put</formula><note type="other">vector x and a d dimensional state vector h to output a new d dimensional state vector h = φ(x, h). Let C denote the set of characters and W the set of words in a given utterance. Let ⊕ denote the vector concatenation operation. We encode an utterance using BiLSTMs, and the model parame- ters Θ associated with this BiLSTM layer are • Char embeddings e c ∈ R 25 for each c ∈ C • Char LSTMs φ C f , φ C b : R 25 × R 25 → R 25 • Word embeddings e w ∈ R 50 for each w ∈ W • Word LSTMs φ</note><formula xml:id="formula_3">W f , φ W b : R 100 × R 50 → R 50</formula><p>Let w 1 . . . w n ∈ W denote a word sequence where word w i has character w i (j) ∈ C at position j. First, the model computes a character-sensitive word representation v i ∈ R 100 as</p><formula xml:id="formula_4">f C j = φ C f e w i (j) , f C j−1 ∀j = 1 . . . |w i | b C j = φ C b e w i (j) , b C j+1 ∀j = |w i | . . . 1 v i = f C |w i | ⊕ b C 1 ⊕ e w i</formula><p>for each i = 1 . . . n. <ref type="bibr">4</ref> These word representa- tion vectors are encoded by forward and backward LSTMs for word φ W f , φ W b as</p><formula xml:id="formula_5">f W i = φ W f v i , f W i−1 ∀i = 1 . . . n b W i = φ W b v i , b W i+1 ∀i = n . . . 1</formula><p>and induces a character and context-sensitive word representation h i ∈ R 100 as</p><formula xml:id="formula_6">h i = f W i ⊕ b W i</formula><p>for each i = 1 . . . n. For convenience, we write the entire operation as a mapping BiLSTM Θ :</p><formula xml:id="formula_7">(h 1 . . . h n ) ← BiLSTM Θ (w 1 . . . w n ) ¯ h = n i=1 h i<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Domain Classification</head><p>Our Multitask domain classification formulation is motivated by a desire to avoid computing the full partition function during test time, which tends to be the slowest component of a multiclass neural network classifer, as has been documented before by <ref type="bibr" target="#b13">(Jozefowicz et al., 2016)</ref> and ( <ref type="bibr" target="#b32">Mikolov et al., 2013)</ref>, amongst others. <ref type="bibr">4</ref> For simplicity, we assume some random initial state vec- tors such as f C 0 and b C |w i |+1 when we describe LSTMs.</p><p>However, we also want access to reliable proba- bility estimates instead of raw scores -we accom- plish this by constructing a custom loss function. During training, each domain classifier receives in-domain (IND) and out-of-domain (OOD) utter- ances, and we adapt the one-sided selection mech- anism of ( <ref type="bibr" target="#b25">Kubat et al., 1997</ref>) to prevent OOD ut- terances from overpowering IND utterances, thus an utterance in a domain d ∈ D is considered as an IND utterance in the viewpoint of domain d and OOD for all other domains.</p><p>We first use the shared encoder to compute the utterance representation ¯ h as previously described. Then we define the probability of domaiñ d for the utterance by mapping ¯ h to a 2-dimensional out- put vector with a linear transformation for each domaiñ d as</p><formula xml:id="formula_8">z ˜ d = σ(W ˜ d · ¯ h + b ˜ d ) p( ˜ d| ¯ h) ∝    exp [z ˜ d ] IN D , if˜dif˜ if˜d = d exp [z ˜ d ] OOD , otherwise</formula><p>where σ is scaled exponential linear unit (SeLU) for normalized activation outputs ( <ref type="bibr" target="#b24">Klambauer et al., 2017)</ref> and [z We define the joint domain classification loss L D as the summation of positive (L P ) and neg- ative (L N ) class loss functions 5 :</p><formula xml:id="formula_9">L P Θ, Θ ˜ d = − log p ˜ d| ¯ h L N Θ, Θ ˜ d = − 1 k − 1   ¯ d∈D, ¯ d = ˜ d log p ¯ d| ¯ h   L D Θ, Θ ˜ d = L P Θ, Θ ˜ d + L N Θ, Θ ˜ d</formula><p>where k is the total number of domains. We di- vide the second term by k − 1 so that L P and L N are balanced in terms of the ratio of the training examples for a domain to those for other domains. While a softmax over the entire domains tends to highlight only the ground-truth domain while sup- pressing all the rest, the our joint domain classifi- cation with a softmax over two classes is designed to produce a more balanced confidence score per domain independent of other domains.</p><p>5 Θ ˜ d denotes the additional parameters in the classification layer for domaiñ d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Personalized Attention</head><p>We explore encoding a user's domain preferences in two ways. Our baseline method is a 1-bit flag that is appended to the input features of each domain-specific classifier. Our novel personalized attention method induces domain embeddings by supervising an attention mechanism to attend to a user's enabled domains with different weights depending on their relevance. The domain em- bedding matrix in <ref type="figure" target="#fig_0">Figure 1</ref> represents the embed- dings of a user's enabled domains. We hypothe- size that attention enables the network learn richer representations of user preferences and domain co-occurrence features. Let e D ( ˜ d) ∈ R 100 and ¯ h ∈ R 100 denote the domain embeddings for domaiñ d and the utter- ance representation calculated by Eq. (1), respec- tively. The domain attention weights for a given user u who has a preferred domain list</p><formula xml:id="formula_10">d (u) = ˜ d (u) 1 , . . . , ˜ d (u) k</formula><p>are calculated by the dot-product operation,</p><formula xml:id="formula_11">a i = ¯ h · e D ˜ d (u) i ∀i = 1 . . . k</formula><p>The final, normalized attention weights ¯ a are ob- tained after normalization via a softmax layer,</p><formula xml:id="formula_12">¯ a i = exp(a i ) k j=1 exp(a j ) ∀i = 1 . . . k</formula><p>The weighted combination of domain embeddings is</p><formula xml:id="formula_13">¯ S attended = k i=1 ¯ a i · e D ˜ d (u) i</formula><p>Finally the two representations of enabled do- mains, namely the attention model and 1-bit flag are then concatenated with the utterance represen- tation and used to make per-domain predictions via domain-specific affine transformations:</p><formula xml:id="formula_14">¯ z att = ¯ h ⊕ ¯ S attended ¯ z 1bit = ¯ h ⊕ I( ˜ d ∈ enabled)</formula><p>Here I( ¯ d ∈ enabled) is a 1-bit indicator for whether the domain is enabled by the user or not. ¯ z att and ¯ z 1bit represent the encoded hidden state of the Attention and 1-Bit Flag configura- tions of the model from the experiment section. In our experiments we will compare these two ways of encoding personalization information, as well as evaluate a variant that combines the two. In this way we can ascertain whether the two personal- ization signals are complementary via an ablation study on the full model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Domain Bootstrapping</head><p>Our model separates the responsibilities for utter- ance representation and domain classification be- tween the shared encoder and the domain-specific classifiers. That is, the shared encoder needs to be retrained only if it cannot encode an utter- ance well (e.g., a new domain introduces com- pletely new words) and the existing domain clas- sifiers need to be retrained only when the shared encoder changes. For adding new domains effi- ciently without full retraining, the only two com- ponents in the architecture need to be updated for each new domaiñ d new , are the domain embed- dings for the new domain and its domain-specific classifier. <ref type="bibr">6</ref> We keep the weights of the encoder network frozen and use the hidden state vector ¯ h, calculated by Eq. 1, as a feature vector to feed into the downstream classifiers. To initialize the m-dimensional domain embeddings e ˜ dnew , we use the column-wise average of all utterance vectors in the training data ¯ h avg , and project it to the domain embedding space using a matrix U ∈ R m×m . Thus,</p><formula xml:id="formula_15">e ˜ dnew = U * · ¯ h avg</formula><p>The parameters of U * are learned using the column-wise average utterance vectors ¯ h avg j and learned domain vectors for all existing domains d j  <ref type="table">Table 1</ref>: The performance of different variants of our neural model in terms of top-N accuracy. Binary trains a separate binary classifier for each skill. MultiClass has a shared encoder followed by a softmax. MultiTask replaces the softmax with per-skill classifiers. 1-Bit Flag adds a sin- gle bit for personalization to each skill classifier in MultiTask.</p><formula xml:id="formula_16">U * = arg min U ||U · ¯ h avg j − e d j || ∀d j ∈ D</formula><p>Attention extends MultiTask with personalized attention.</p><p>The last 3 models are personalized. *Best single encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section we aim to demonstrate the effec- tiveness of our model architecture in two settings.</p><p>First, we will demonstrate that attention based per- sonalization significantly outperforms the baseline approach. Secondly, we will show that our model new domain bootstrapping procedure results in ac- curacies comparable to full retraining while re- quiring less than 1% of the orignal training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Weak: This is a weakly supervised dataset was generated by preprocessing utterances with strict invocation patterns according to the setup men- tioned in Section 3. The dataset consists of 5.34M utterances from 637,975 users across 1,500 differ- ent skills. Since we are interested in capturing the temporal effects of the dataset as well as personal- ization effects, we partitioned the data based both on user and time. Our core training data for the ex- periments in this paper was drawn from one month of live usage, the validation data came from the next 15 days of usage, and the test data came from the subsequent 15 days. The training, validation and test sets are user-independent, and each user belongs to only one of the three sets to ensure no leakage of information.</p><p>MTurk: Since the Weak dataset is generated by weak supervision, we verified the performance of our approach with human generated utterances. A random sample of 12,428 utterances from the test partition of users were presented to 300 human judges, who were asked to produce two natural ways to issue the same command. This dataset is treated as a representative clean held out test set on which we can observe the generalization of our weakly supervised training and validation data to natural language.</p><p>New Skills: In order to simulate the scenario in which new skills appear within a week be- tween model updates, we selected 250 new skills which do not overlap with the skills in the Weak dataset. The vocabulary size of 1,500 skills is 200K words, and on average, 5% of the vocabu- lary for new skills is not covered. We randomly sampled 4,000 unique utterances for each skill us- ing the same weak supervision method, and split them into 3,000 utterances for training and 1,000 for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussion</head><p>Generalization from Weakly Supervised to Natural Utterances We first show the progres- sion of model performance as we add more com- ponents to show their individual contribution. Sec- ondly, we show that training our models on a weakly supervised dataset can generalize to nat- ural speech by showing their test performance on the human-annotated test data. Finally, we com- pare two personalization strategies. The full results are summarized in <ref type="table">Table 1</ref>, which shows the top-N test results separately for the Weak dataset (weakly supervised) and MTurk dataset (human-annotated). We report top-N ac- curacy to show the potential for further re-ranking or disambiguation downstream. For top-1 results on the Weak dataset, using a separate binary clas- sifier for each domain (Binary) shows a prediction accuracy at 78.29% and using a softmax layer on top of the shared encoder (MultiClass) shows a comparable accuracy at 78.58%. The performance shows a slight improvement when using the Mul- titask neural loss structure, but adding personal- ization signals to the Multitask structure showed a significant boost in performance. We noted the large difference between the 1-bit and attention ar- chitecture. At 94.83% accuracy, attention resulted in 35.6% relative error reduction over the 1-bit baseline 91.97% on the Weak validation set and 23.25% relative on the MTurk test set. We hypoth- esize that this may be because the attention mecha- nism allows the model to focus on complementary features in case of overlapping domains as well as learning domain co-occurrence statistics, both of which are not possible with the simple 1-bit flag.</p><p>When both personalization representations were combined, the performance peaked at 95.19% for the Weak dataset and a more modest  and top-1 accuracy (%) on an NVIDIA Tesla M40 GPU.</p><p>89.65% for the MTurk dataset. The improvement trend is extremely consistent across all top-N re- sults for both of the Weak and MTurk datasets across all experiments. The disambiguation task is complex due to similar and overlapping skills, but the results suggest that incorporating person- alization signals equip the models with much bet- ter discriminative power. The results also suggest that the two mechanisms for encoding personal- ization provide a small amount of complementary information since combining them together is bet- ter than using them individually. Although the per- formance on the Weak dataset tends to be more optimistic, the best performance on the human- annotated test data is still close to 90% for top-1 accuracy, which suggests that training our model with the samples derived from the invocation pat- terns can generalize well to natural utterances.</p><p>Rapid Bootstrapping of New Skills We show the results when new domains are added to an IPDA and the model needs to efficiently accom- modate them with a limited number of data sam- ples. We show the classification performance on the skills in the New Skills dataset while as- suming we have access to the WEAK dataset to pre-train our model for transfer learning. In the Binary setting, a domain-specific binary classi- fier is trained for each domain. Expand describes the case in which we incrementally train on top of an existing model. Refresh is the setting in which the model is fully retrained from scratch with the new data -which would be ideal in case there were no time constraints.</p><p>We record the average training time for each epoch and the performance is measured with top-1 classification accuracy over new skills. The exper- iment results can be found in <ref type="table" target="#tab_3">Table 2</ref>. Adapting a new skill is two orders of magnitude faster (30.34 seconds) than retraining the model (5300.18 sec- onds) while achieving 94.03% accuracy which is comparable to 94.58% accuracy of full retraining. The first two techniques can also be easily paral- lelized unlike the Refresh configuration.  <ref type="table">Table 3</ref>: Top-N prediction accuracy (%) on the full skill set (Full) and only enabled skills (Enabled).</p><p>Behavior of Attention Mechanism Our expec- tation is that the model is able to learn to attend the relevant skills during the inference process. To study the behavior of the attention layer, we compute the top-N prediction accuracy based on the most relevant skills defined by the attention weights. In this experiment, we considered the subset of users who had enabled more than 20 do- mains to exclude trivial cases <ref type="bibr">7</ref> . The results are shown in <ref type="table">Table 3</ref>. When the model attends to the entire set of 1500 (Full), the top-5 prediction accuracy is 20.41%, which indicates that a large number of skills can process the utterance, and thus it is highly likely to miss the correct one in the top-5 predictions. This ambiguity issue can be significantly improved by users' enabled do- main lists as proved by the accuracies (Enabled): 85.62% for top-1, 96.15% for top-3, and 98.06% for top-5. 8 Thus the attention mechanism can thus be viewed as an initial soft selection which is then followed by a fine-grained selection at the classifi- cation stage.</p><p>End-to-End User Evaluation All intermediate metrics on this task are proxies to a human cus- tomer's eventual evaluation. In order to assess the user experience, we need to measure its end-to- end performance. For a brief end-to-end system evaluation, 983 utterances from 283 domains were randomly sampled from the test set in the large- scale IPDA setting. 15 human judges (male=12, female=3) rated the system responses, 1 judge per utterance, on a 5-point Likert scale with 1 being Terrible and 5 being Perfect. The judgment score of 3 or above was taken as SUCCESS and 2 or be- low as DEFECT. The end-to-end SUCCESS rate, <ref type="bibr">7</ref> Thus, the random prediction accuracy on enabled do- mains is less than 5% and across the Full domain list is 0.066% 8 Visual inspection of the embeddings confirms that mean- ingful clusters are learned. We see clusters related to home automation, commerce, cooking, trivia etc, we show some examples in <ref type="figure" target="#fig_2">Figure 2</ref>, 3 and 4. However there are still other clusters where the the relationships cannot be established as easily. An example of these is show in <ref type="figure" target="#fig_5">Figure 5</ref>. The per- sonalized attention mechanism is learned using the semantic content as well as personalization signals, so we hypothesize clusters like this may be capturing user tendencies to enable these domains in a correlated manner. thus user satisfaction, was shown to be 95.52%. The discrepancy between this score and the score produced on MTurk dataset indicates that even in cases in which the model makes classification mis- takes, some of these interpretations remain percep- tually meaningful to humans.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We have described a neural model architecture to address large-scale skill classification in an IPDA used by tens of millions of users every day. We have described how personalization features and an attention mechanism can be used for handling ambiguity between domains. We have also shown that the model can be extended efficiently and in- crementally for new domains, saving multiple or- ders of magnitude in terms of training time. The model also addresses practical constraints of hav- ing a low memory footprint, low latency and be- ing easily parallelized, all of which are important characteristics for real-time production systems. In future work, we plan to incorporate various types of context (e.g. anaphora, device-specific capabilities) and dialogue history into a large-scale NLU system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The overall architecture of the personalized dynamic domain classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>˜</head><label></label><figDesc>d ] IN D and [z ˜ d ] OOD denote the values in the IND and OOD position of vector z ˜ d .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Embeddings of different domain categories visualized in 2D using TSNE (van der Maaten and Hinton, 2008). Different colors represent different categories, for e.g. the large blue cluster on the left is Home Automation.</figDesc><graphic url="image-1.png" coords="9,72.00,62.81,453.54,151.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A large cluster of home automation domains.</figDesc><graphic url="image-2.png" coords="9,72.00,372.84,226.77,137.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A cluster of domains related to cooking.</figDesc><graphic url="image-3.png" coords="9,72.00,580.72,226.77,137.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A mixed cluster with several different domain categories represented.</figDesc><graphic url="image-4.png" coords="9,307.28,266.12,226.77,137.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Comparison of per-epoch training time (seconds)</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> We assume that users can customize their IPDA settings to enable certain domains.</note>

			<note place="foot" n="2"> Using a one-hot representation of word vocabulary size 60,000 and hidden dimension 100 would require learning a matrix of size 60000 x 100-using 100-dim word embeddings requires only a O(1) lookup followed by a 100 x 100 matrix, thus allowing our model to be significantly smaller and faster despite having what is effectively an open vocabulary 3 Current inference consumes 50MB memory and the p99 latency is 15ms.</note>

			<note place="foot" n="6"> We have assumed that the shared encoder covers most of the vocabulary of new domains; otherwise, the entire network may need to be retrained. Based on our observation of live usage data, this assumption is reasonable since the shared encoder after initial training is still shown to cover 95% of the vocabulary of new domains added in the subsequent week.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Towards zero shot frame semantic parsing for domain scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Easy contextual intent prediction and slot detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dilek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Hakkanitur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8337" to="8341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new pre-training method for training deep learning models with application to spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3255" to="3259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Zero-shot learning of intent embeddings for expansion by convolutional deep structured semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="6045" to="6049" />
		</imprint>
	</monogr>
	<note>2016 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">End-toend memory networks with knowledge carryover for multi-turn spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Extending domain coverage of language understanding systems via intent transfer between domains using knowledge graphs and search query click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>El-Kahky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4067" to="4071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Transfer learning for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilio</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lambert</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<idno>abs/1706.04326</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledgebased weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Context-sensitive and roledependent spoken language understanding using bidirectional and attention lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiori</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John R</forename><surname>Hershey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interspeech</title>
		<imprint>
			<biblScope unit="page" from="3236" to="3240" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Domain adaptation of recurrent neural networks for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Jaech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A spelling correction program based on a noisy channel model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">W</forename><surname>Mark D Kernighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William A</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th conference on Computational linguistics</title>
		<meeting>the 13th conference on Computational linguistics</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="205" to="210" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weakly supervised slot tagging with partially labeled sequences from web search click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Speaker-sensitive dual memory networks for multi-turn slot tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="547" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Onenet: Joint domain, intent, slot prediction for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding Workshop</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="547" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adversarial adaptation of synthetic or stale data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongchan</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1297" to="1307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Domain attention with an ensemble of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongchan</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pre-training of hidden-unit crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="192" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Frustratingly easy neural domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="387" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A framework for pre-training hidden-unit conditional random fields and its extension to long short term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">New transfer learning techniques for disparate label sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="473" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Self-normalizing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno>abs/1706.02515</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Addressing the curse of imbalanced training sets: one-sided selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miroslav</forename><surname>Kubat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<meeting><address><addrLine>Nashville, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Just ask: Building an architecture for extensible self-service spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjishnu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Hoffmeister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00549</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Zero-shot learning across heterogeneous overlapping domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjishnu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavankumar</forename><surname>Reddy Muddireddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Hoffmeister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2914" to="2918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention-based recurrent neural network models for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="685" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-domain adversarial learning for slot filling in spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Conversational AI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing high-dimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data programming: Creating large training sets, quickly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher M De</forename><surname>Alexander J Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3567" to="3575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The technology behind personal digital assistants: An overview of the system architecture and key components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="81" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An overview of end-to-end language understanding and dialog management for personal digital assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Robichaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">Zia</forename><surname>Rochette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohu</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="391" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multitask learning in deep neural networks for improved phoneme recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasha</forename><surname>Seltzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Droppo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6965" to="6969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multitask learning for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2006 IEEE International Conference on</title>
		<editor>I-I. IEEE</editor>
		<meeting>2006 IEEE International Conference on</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Acoustics, Speech and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><surname>De Mori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley and Sons</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Efficient character-level document classification by combining convolution and recurrent layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.00367</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Contextual domain classification in spoken language understanding systems using recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="136" to="140" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transfer learning for sequence tagging with hierarchical recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A joint model of intent determination and slot filling for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2993" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
