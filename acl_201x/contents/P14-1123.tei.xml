<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:57+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shallow Analysis Based Assessment of Syntactic Complexity for Automated Speech Scoring</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suma</forename><surname>Bhat</surname></persName>
							<email>spbhat2@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beckman</forename><surname>Institute</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huichao</forename><surname>Xue</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-Youn</forename><surname>Yoon</surname></persName>
							<email>syoon@ets.org</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Illinois</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Educational Testing Service Princeton</orgName>
								<orgName type="institution">University of Pittsburgh Pittsburgh</orgName>
								<address>
									<region>PA, NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shallow Analysis Based Assessment of Syntactic Complexity for Automated Speech Scoring</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1305" to="1315"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Designing measures that capture various aspects of language ability is a central task in the design of systems for automatic scoring of spontaneous speech. In this study, we address a key aspect of language proficiency assessment-syntactic complexity. We propose a novel measure of syntactic complexity for spontaneous speech that shows optimum empirical performance on real world data in multiple ways. First, it is both robust and reliable, producing automatic scores that agree well with human rating compared to the state-of-the-art. Second, the measure makes sense theoretically, both from algorithmic and native language acquisition points of view.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Assessment of a speaker's proficiency in a second language is the main task in the domain of au- tomatic evaluation of spontaneous speech <ref type="bibr" target="#b37">(Zechner et al., 2009)</ref>. Prior studies in language ac- quisition and second language research have con- clusively shown that proficiency in a second lan- guage is characterized by several factors, some of which are, fluency in language production, pro- nunciation accuracy, choice of vocabulary, gram- matical sophistication and accuracy. The design of automated scoring systems for non-native speaker speaking proficiency is guided by these studies in the choice of pertinent objective measures of these key aspects of language proficiency.</p><p>The focus of this study is the design and per- formance analysis of a measure of the syntactic complexity of non-native English responses for use in automatic scoring systems. The state-of- the art automated scoring system for spontaneous speech <ref type="bibr" target="#b37">(Zechner et al., 2009;</ref><ref type="bibr" target="#b14">Higgins et al., 2011)</ref> currently uses measures of fluency and pronuncia- tion (acoustic aspects) to produce scores that are in reasonable agreement with human-rated scores of proficiency. Despite its good performance, there is a need to extend its coverage to higher order as- pects of language ability. Fluency and pronunci- ation may, by themselves, already be good indi- cators of proficiency in non-native speakers, but from a construct validity perspective 1 , it is neces- sary that an automatic assessment model measure higher-order aspects of language proficiency. Syn- tactic complexity is one such aspect of proficiency. By "syntactic complexity", we mean a learner's ability to use a wide range of sophisticated gram- matical structures.</p><p>This study is different from studies that fo- cus on capturing grammatical errors in non-native speakers <ref type="bibr" target="#b11">(Foster and Skehan, 1996;</ref><ref type="bibr" target="#b16">Iwashita et al., 2008)</ref>. Instead of focusing on grammatical errors that are found to be highly representative of lan- guage proficiency, our interest is in capturing the range of forms that surface in language production and the degree of sophistication of such forms, collectively referred to as syntactic complexity in <ref type="bibr" target="#b23">(Ortega, 2003)</ref>.</p><p>The choice and design of objective measures of language proficiency is governed by two crucial constraints:</p><p>1. Validity: a measure should show high dis- criminative ability between various levels of language proficiency, and the scores pro- duced by the use of this measure should show high agreement with human-assigned scores. 2. Robustness: a measures should be derived automatically and should be robust to errors in the measure generation process. A critical impediment to the robustness con- straint in the state-of-the-art is the multi-stage au-tomated process, where errors in the speech recog- nition stage (the very first stage) affect subsequent stages. Guided by studies in second language de- velopment, we design a measure of syntactic com- plexity that captures patterns indicative of profi- cient and non-proficient grammatical structures by a shallow-analysis of spoken language, as opposed to a deep syntactic analysis, and analyze the per- formance of the automatic scoring model with its inclusion. We compare and contrast the proposed measure with that found to be optimum in <ref type="bibr" target="#b36">Yoon and Bhat (2012)</ref>.</p><p>Our primary contributions in this study are:</p><p>• We show that the measure of syntactic com- plexity derived from a shallow-analysis of spoken utterances satisfies the design con- straint of high discriminative ability between proficiency levels. In addition, including our proposed measure of syntactic complexity in an automatic scoring model results in a statis- tically significant performance gain over the state-of-the-art.</p><p>• The proposed measure, derived through a completely automated process, satisfies the robustness criterion reasonably well.</p><p>• In the domain of native language acquisition, the presence or absence of a grammatical structure indicates grammatical development. We observe that the proposed approach ele- gantly and effectively captures this presence- based criterion of grammatical development, since the feature indicative of presence or ab- sence of a grammatical structure is optimal from an algorithmic point of view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Speaking in a non-native language requires diverse abilities, including fluency, pronunciation, into- nation, grammar, vocabulary, and discourse. In- formed by studies in second language acquisition and language testing that regard these factors as key determiners of spoken language proficiency, some researchers have focused on the objective measurement of these aspects of spoken language in the context of automatic assessment of language ability. Notable are studies that have focused on assessment of fluency ( <ref type="bibr" target="#b8">Cucchiarini et al., 2000;</ref><ref type="bibr" target="#b9">Cucchiarini et al., 2002</ref>), pronunciation <ref type="bibr" target="#b32">(Witt and Young, 1997;</ref><ref type="bibr" target="#b33">Witt, 1999;</ref><ref type="bibr" target="#b12">Franco et al., 1997;</ref><ref type="bibr" target="#b22">Neumeyer et al., 2000</ref>), and intonation ( <ref type="bibr" target="#b37">Zechner et al., 2009)</ref>. The relative success of these studies has yielded objective measures of acoustic aspects of speaking ability, resulting in a shift in focus to more complex aspects of assessment of gram- mar ( <ref type="bibr" target="#b1">Bernstein et al., 2010;</ref><ref type="bibr" target="#b4">Chen and Yoon, 2011;</ref><ref type="bibr" target="#b5">Chen and Zechner, 2011</ref>), topic development ( <ref type="bibr" target="#b35">Xie et al., 2012)</ref>, and coherence ( <ref type="bibr" target="#b31">Wang et al., 2013)</ref>.</p><p>In an effort to assess grammar and usage in a second language learning environment, numerous studies have focused on identifying relevant quan- titative measures. These measures have been used to estimate proficiency levels in English as a sec- ond language (ESL) writing with reasonable suc- cess. <ref type="bibr" target="#b34">Wolf-Quintero et al. (1998)</ref>, <ref type="bibr" target="#b23">Ortega (2003)</ref>, and <ref type="bibr" target="#b19">Lu (2010)</ref> found that measures such as mean length of T-unit 2 and dependent clauses per clause (henceforth termed as length-based measures) are well correlated with holistic proficiency scores suggesting that these quantitative measures can be used as objective indices of grammatical develop- ment.</p><p>In the context of spoken ESL, these measures have been studied as well but the results have been inconclusive. The measures could only broadly discriminate between students' proficiency levels, rated on a scale with moderate to weak correla- tions, and strong data dependencies on the par- ticipant groups were observed <ref type="bibr" target="#b13">(Halleck, 1995;</ref><ref type="bibr" target="#b16">Iwashita et al., 2008;</ref><ref type="bibr" target="#b17">Iwashita, 2010)</ref>.</p><p>With the recent interest in the area of auto- matic assessment of speech, there is a concur- rent need to assess the grammatical development of ESL students automatically. Studies that ex- plored the applicability of length-based measures in an automated scoring system <ref type="bibr" target="#b5">(Chen and Zechner, 2011;</ref><ref type="bibr" target="#b4">Chen and Yoon, 2011</ref>) observed another important drawback of these measures in that set- ting. Length-based measures do not meet the con- straints of the design, that, in order for measures to be effectively incorporated in the automated speech scoring system, they must be generated in a fully automated manner, via a multi-stage au- tomated process that includes speech recognition, part of speech (POS) tagging, and parsing.</p><p>A major bottleneck in the multi-stage process of an automated speech scoring system for second language is the stage of automated speech recog- nition (ASR). Automatic recognition of non-native speakers' spontaneous speech is a challenging task as evidenced by the error rate of the state-of-the-art speech recognizer. For instance, Chen and Zechner (2011) reported a 50.5% word error rate (WER) and <ref type="bibr" target="#b36">Yoon and Bhat (2012)</ref> reported a 30% WER in the recognition of ESL students' spoken responses. These high error rates at the recogni- tion stage negatively affect the subsequent stages of the speech scoring system in general, and in particular, during a deep syntactic analysis, which operates on a long sequence of words as its con- text. As a result, measures of grammatical com- plexity that are closely tied to a correct syntac- tic analysis are rendered unreliable. Not surpris- ingly, Chen and Zechner (2011) studied measures of grammatical complexity via syntactic parsing and found that a Pearson's correlation coefficient of 0.49 between syntactic complexity measures (derived from manual transcriptions) and profi- ciency scores, was drastically reduced to near non- existence when the measures were applied to ASR word hypotheses. This suggests that measures that rely on deep syntactic analysis are unreliable in current ASR-based scoring systems for sponta- neous speech.</p><p>In order to avoid the problems encountered with deep analysis-based measures, Yoon and Bhat (2012) explored a shallow analysis-based ap- proach, based on the assumption that the level of grammar sophistication at each proficiency level is reflected in the distribution of part-of-speech (POS) tag bigrams. The idea of capturing dif- ferences in POS tag distributions for classification has been explored in several previous studies. In the area of text-genre classification, POS tag dis- tributions have been found to capture genre differ- ences in text ; in a language testing context, it has been used in grammatical error detection and essay scoring <ref type="bibr" target="#b6">(Chodorow and Leacock, 2000;</ref><ref type="bibr" target="#b30">Tetreault and Chodorow, 2008</ref>). We will see next what as- pects of syntactic complexity are captured by such a shallow-analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Shallow-analysis approach to measuring syntactic complexity</head><p>The measures of syntactic complexity in this ap- proach are POS bigrams and are not obtained by a deep analysis (syntactic parsing) of the structure of the sentence. Hence we will refer to this approach as 'shallow analysis'. In a shallow-analysis ap- proach to measuring syntactic complexity, we rely on the distribution of POS bigrams at every profi- ciency level to be representative of the range and sophistication of grammatical constructions at that level. At the outset, POS-bigrams may seem too simplistic to represent any aspect of true syntactic complexity. We illustrate to the contrary, that they are indeed able to capture certain grammatical er- rors and sophisticated constructions by means of the following instances. Consider the two sentence fragments below taken from actual responses (the bigrams of interest and their associated POS tags are bold-faced).</p><p>1. They can/MD to/TO survive . . . 2. They created the culture/NN that/WDT now/RB is common in the US.</p><p>We notice that Example 1 is not only less gram- matically sophisticated than Example 2 but also has a grammatical error. The error stems from the fact that it has a modal verb followed by the word "to". On the other hand, Example 2 contains a relative clause composed of a noun introduced by "that". Notice how these grammatical expressions (one erroneous and the other sophisticated) can be detected by the POS bigrams "MD-TO" and "NN- WDT", respectively.</p><p>The idea that the level of syntactic complex- ity (in terms of its range and sophistication) can be assessed based on the distribution of POS-tags is informed by prior studies in second language acquisition. It has been shown that the usage of certain grammatical constructions (such as that of the embedded relative clause in the second sen- tence above) are indicators of specific milestones in grammar development ( <ref type="bibr" target="#b7">Covington et al., 2006</ref>). In addition, studies such as <ref type="bibr" target="#b11">Foster and Skehan (1996)</ref> have successfully explored the utility of frequency of grammatical errors as objective mea- sures of grammatical development.</p><p>Based on this idea, Yoon and Bhat (2012) de- veloped a set of features of syntactic complex- ity based on POS sequences extracted from a large corpus of ESL learners' spoken responses, grouped by human-assigned scores of proficiency level. Unlike previous studies, it did not rely on the occurrence of normative grammatical con- structions. The main assumption was that each score level is characterized by different types of prominent grammatical structures. These repre- sentative constructions are gathered from a collec- tion of ESL learners' spoken responses rated for overall proficiency. The syntactic complexity of a test spoken response was estimated based on its similarity to the proficiency groups in the refer- ence corpus with respect to the score-specific con- structions. A score was assigned to the response based on how similar it was to the high score group. In Section 4.1, we go over the approach in further detail.</p><p>Our current work is inspired by the shallow analysis-based approach of <ref type="bibr" target="#b36">Yoon and Bhat (2012)</ref> and operates under the same assumptions of cap- turing the range and sophistication of grammati- cal constructions at each score level. However, the approaches differ in the way in which a spo- ken response is assigned to a score group. We first analyze the limitations of the model studied in <ref type="bibr" target="#b36">(Yoon and Bhat, 2012)</ref> and then describe how our model can address those limitations. The result is a new measure based on POS bigrams to assess ESL learners' mastery of syntactic complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Models for Measuring Grammatical Competence</head><p>We mentioned that the measure proposed in this study is derived from assumptions similar to those studied in <ref type="bibr" target="#b36">(Yoon and Bhat, 2012</ref>). Accordingly, we will summarize the previously studied model, outline its limitations, show how our proposed measure addresses those limitations and compare the two measures for the task of automatic scoring of speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Vector-Space Model based approach</head><p>Yoon and Bhat (2012) explored an approach in- spired by information retrieval. They treat the con- catenated collection of responses from a particular score-class as a 'super' document. Then, regard- ing POS bigrams as terms, they construct POS- based vector space models for each score-class (there are four score classes denoting levels of pro- ficiency as will be explained in Section 5.2), thus yielding four score-specific vector-space models (VSMs). The terms of the VSM are weighted by the term frequency-inverse document frequency (tf -idf ) weighting scheme ( <ref type="bibr" target="#b28">Salton et al., 1975</ref>).</p><p>The intuition behind the approach is that responses in the same proficiency level often share similar grammar and usage patterns. The similarity be- tween a test response and a score-specific vector is then calculated by a cosine similarity metric. Al- though a total of 4 cosine similarity scores (one per score group) were generated, only cos 4 from among the four similarity scores, and cosmax, were selected as features.</p><p>• cos 4 : the cosine similarity score between the test response and the vector of POS bigrams for the highest score class (level 4); and, • cosmax: the score level of the VSM with which the given response shows maximum similarity. Of these, cos 4 was selected based on its empir- ical performance (it showed the strongest corre- lation with human-assigned scores of proficiency among the distance-based measures). In addition, an intuitive justification for the choice is that the score-4 vector is a grammatical "norm" represent- ing the average grammar usage distribution of the most proficient ESL students. The measure of syn- tactic complexity of a response, cos 4 , is its simi- larity to the highest score class.</p><p>The study found that the measures showed rea- sonable discriminative ability across proficiency levels. Despite its encouraging empirical perfor- mance, the VSM method of capturing grammati- cal sophistication has the following limitations.</p><p>First, the VSM-based method is likely to over- estimate the contribution of the POS bigrams when highly correlated bigrams occur as terms in the VSM. Consider the presence of a grammar pat- tern represented by more than one POS bigram. For example, both "NN-WDT" and "WDT-RB" in Sentence 2 reflect the learner's usage of a relative clause. However, we note that the two bigrams are correlated and including them both results in an over-estimation of their contribution. The VSM set-up has no mechanism to handle correlated fea- tures.</p><p>Second, the tf -idf weighting scheme for rela- tively rare POS bigrams does not adequately cap- ture their underlying distribution with respect to score groups. Grammatical expressions that occur frequently in one score level but rarely in other levels can be assumed to be characteristic of a specific score level. Therefore, the more uneven the distribution of a grammatical expression across score classes, the more important that grammatical expression should be as an indicator of a particular score class. However, the simple idf scheme can- not capture this uneven distribution. A pattern that occurs rarely but uniformly across different score groups can get the same weight as a pattern which is unevenly distributed to one score group. Mar- tineau and <ref type="bibr" target="#b21">Finin (2009)</ref> observed this weakness of the tf -idf weighting in the domain of sentiment analysis. When using tf -idf weighting to extract words that were strongly associated with positive sentiment in a movie review corpus (they consid- ered each review as a document and a word as a term), it was found that a substantial proportion of words with the highest tf -idf were rare words (e.g., proper nouns) which were not directly asso- ciated with the sentiment.</p><p>We propose to address these important limita- tions of the VSM approach by the use of a method that accounts for each of the deficiencies. This is done by resorting to a maximum entropy model based approach, to which we turn next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Maximum Entropy-Based model</head><p>In order to address the limitations discussed in 4.1, we propose a classification-based approach. Tak- ing an approach different from previous studies, we formulate the task of assigning a score of syn- tactic complexity to a spoken response as a classi- fication problem: given a spoken response, assign the response to a proficiency class. A classifier is trained in an inductive fashion, using a large cor- pus of learner responses that is divided into pro- ficiency scores as the training data and then used to test data that is similar to the training data. A distinguishing feature of the current study is that the measure is based on a comparison of charac- teristics of the test response to models trained on large amounts of data from each score point, as op- posed to measures that are simply characteristics of the responses themselves (which is how mea- sures have been considered in prior studies).</p><p>The inductive classifier we use here is the maximum-entropy model (MaxEnt) which has been used to solve several statistical natural lan- guage processing problems with much success <ref type="bibr" target="#b0">(Berger et al., 1996;</ref><ref type="bibr" target="#b2">Borthwick et al., 1998;</ref><ref type="bibr" target="#b3">Borthwick, 1999;</ref><ref type="bibr" target="#b24">Pang et al., 2002;</ref><ref type="bibr" target="#b18">Klein et al., 2003;</ref><ref type="bibr" target="#b27">Rosenfeld, 2005</ref>). The productive feature en- gineering aspects of incorporating features into the discriminative MaxEnt classifier motivate the model choice for the problem at hand. In partic- ular, the ability of the MaxEnt model's estimation routine to handle overlapping (correlated) features makes it directly applicable to address the first lim- itation of the VSM model. The second limitation, related to the ineffective weighting of terms via the the tf -idf scheme, seems to be addressed by the fact that the MaxEnt model assigns a weight to each feature (in our case, POS bigrams) on a per-class basis (in our case, score group), by tak- ing every instance into consideration. Therefore, a MaxEnt model has an advantage over the model described in 4.1 in that it uses four different weight schemes (one per score level) and each scheme is optimized for each score level. This is beneficial in situations where the features are not evenly im- portant across all score levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>Our experiments seek answers to the following questions.</p><p>1. To what extent does a MaxEnt-score of syn- tactic complexity discriminate between levels of proficiency? 2. What is the effect of including the proposed measure of syntactic complexity in the state- of-the-art automatic scoring model? 3. How robust is the measure to errors in the var- ious stages of automatic generation?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Tasks</head><p>In order to answer the motivating questions of the study, we set-up two tasks. In the first task, we compare the extent to which the VSM-based mea- sure and the MaxEnt-based measure (outlined in 4.1 and 4.2 above) discriminate between levels of syntactic complexity. Additionally, we compare the performance of an automatic scoring model of overall proficiency that includes the measures of syntactic complexity from each of the two mod- els being compared and analyze the gains with re- spect to the state-of-the-art. In the second task, we study the measures' robustness to errors incurred by ASR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Data</head><p>In this study, we used a collection of responses from an international English language assess- ment. The assessment consisted of questions to which speakers were prompted to provide sponta- neous spoken responses lasting approximately 45- 60 seconds per question. Test takers read and/or listened to stimulus materials and then responded to questions based on the stimuli. All questions so- licited spontaneous, unconstrained natural speech. A small portion of the available data with inad- equate audio quality and lack of student response was excluded from the study. The remaining re- sponses were partitioned into two datasets: the ASR set and the scoring model training/test (SM) set. The ASR set, with 47,227 responses, was used for ASR training and POS similarity model training. The SM set, with 2,950 responses, was used for feature evaluation and automated scoring model evaluation. There was no overlap in speak- ers between the ASR set and the SM set.</p><p>Each response was rated for overall proficiency by trained human scorers using a 4-point scoring scale, where 1 indicates low speaking proficiency and 4 indicated high speaking proficiency. The distribution of proficiency scores, along with other details of the data sets, are presented in <ref type="table">Table 1</ref>.</p><p>As seen in <ref type="table">Table 1</ref>, there is a strong bias towards the middle scores (score 2 and 3) with approxi- mately 84-85% of the responses belonging to these two score levels. Although the skewed distribution limits the number of score-specific instances for the highest and lowest scores available for model training, we used the data without modifying the distribution since it is representative of responses in a large-scale language assessment scenario.</p><p>Human raters' extent of agreement in the sub- jective task of rating responses for language pro- ficiency constrains the extent to which we can ex- pect a machine's score to agree with that of hu- mans. An estimate of the extent to which human raters agree on the subjective task of proficiency assessment, is obtained by two raters scoring ap- proximately 5% of data (2,388 responses from ASR set and 140 responses from SM set). Pear- son correlation r between the scores assigned by the two raters was 0.62 in ASR set and 0.58 in SM set. This level of agreement will guide the evalua- tion of the human-machine agreement on scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Stages of Automatic Grammatical Competence Assessment</head><p>Here we outline the multiple stages involved in the automatic syntactic complexity assessment. The first stage, ASR, yields an automatic transcription, which is followed by the POS tagging stage. Sub- sequently, the feature extraction stage (a VSM or a MaxEnt model as the case may be) generates the syntactic complexity feature which is then incor- porated in a multiple linear regression model to generate a score. The steps for automatic assessment of overall proficiency follow an analogous process (either in- cluding the POS tagger or not), depending on the objective measure being evaluated. The various objective measures are then combined in the mul- tiple regression scoring model to generate an over- all score of proficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Automatic Speech Recognizer</head><p>An HMM recognizer was trained using ASR set (approximately 733 hours of non-native speech collected from 7,872 speakers). A gender inde- pendent triphone acoustic model and combination of bigram, trigram, and four-gram language mod- els were used. A word error rate (WER) of 31% on the SM dataset was observed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">POS tagger</head><p>POS tags were generated using the POS tagger implemented in the Open-NLP toolkit <ref type="bibr">3</ref> . It was trained on the Switchboard (SWBD) corpus. This POS tagger was trained on about 528K word/tag pairs. A combination of 36 tags from the Penn Treebank tag set and 6 tags generated for spoken languages were used in the tagger.</p><p>The tagger achieved a tagging accuracy of 96.3% on a Switchboard evaluation set composed of 379K words, suggesting high accuracy of the tagger. However, due to substantial amount of speech recognition errors in our data, the POS error rate (resulting from the combined errors of ASR and automated POS tagger) is expected to be higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.3">VSM-based Model</head><p>We used the ASR data set to train a POS-bigram VSM for the highest score class and generated cos 4 and cosmax reported in <ref type="bibr" target="#b36">Yoon and Bhat (2012)</ref>, for the SM data set as outlined in Sec- tion 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.4">Maximum Entropy Model Classifier</head><p>The input to the classifier is a set of POS bi- grams (1366 bigrams in all) obtained from the POS-tagged output of the data. We considered binary-valued features (whether a POS bigram oc- curred or not), occurrence frequency, and relative frequency as input for the purpose of experimen- tation. We used the maximum entropy classifier implementation in the MaxEnt toolkit <ref type="bibr">4</ref> . The clas- sifier was trained using the LBFGS algorithm for parameter estimation and used equal-scale gaus- sian priors for smoothing. The results that fol- low are based on MaxEnt classifier's parameter settings initialized to zero. Since a preliminary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data set</head><p>No. of <ref type="table" target="#tab_0">No. of  Score  Score distribution  responses  speakers  Mean  SD  1  2  3  4  ASR  47,227  7,872  2.67  0.73  1,953  16,834  23,106  5,334  4%  36%  49%  11%  SM  2,950  500  2.61  0.74  166  1,103  1,385  296  6%  37%  47%  10%   Table 1</ref>: Data size and score distribution analysis of the effect of varying the feature (bi- nary or frequency) revealed that the binary-valued feature was optimal (in terms of yielding the best agreement between human and machine scores), we only report our results for this case. The ASR data set was used to train the MaxEnt classifier and the features generated from the SM data set were used for evaluation. One straightforward way of using the maximum entropy classifier's prediction for our case is to directly use its predicted score-level -1, 2, 3 or 4. However, this forces the classifier to make a coarse-grained choice and may over-penalize the classifier's scoring errors. To illustrate this, con- sider a scenario where the classifier assigns two responses A and B to score level 2 (based on the maximum a posteriori condition). Suppose that, for response A, the score class with the second highest probability corresponds to score level 1 and that, for response B, it corresponds to score level 3. It is apparent that the classifier has an overall tendency to assign a higher score to B, but looking at its top preference alone (2 for both re- sponses), masks this tendency.</p><p>We thus capture the classifier's finer-grained scoring tendency by calculating the expected value of the classifier output. For a given response, the MaxEnt classifier calculates the conditional prob- ability of a score-class given the response, in turn yielding conditional probabilities of each score group given the observation -p i for score group i ∈ {1, 2, 3, 4}. In our case, we consider the pre- dicted score of syntactic complexity to be the ex- pected value of the class label given the observa- tion as, mescore = 1×p 1 +2×p 2 +3×p 3 +4×p 4 . This permits us to better represent the score as- signed by the MaxEnt classifier as a relative pref- erence over score assignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.5">Automatic Scoring System</head><p>We consider a multiple regression automatic scor- ing model as studied in <ref type="bibr" target="#b37">Zechner et al. (2009;</ref><ref type="bibr" target="#b5">Chen and Zechner (2011;</ref><ref type="bibr" target="#b14">Higgins et al. (2011)</ref>. In its state-of-the-art set-up, the following model uses the features -HMM acoustic model score (global normalized), speaking rate, word types per sec- ond, average chunk length in words and language model score (global normalized). We use these features by themselves (Base), and also in con- junction with the VSM-based feature (cva4) and the MaxEnt-based feature (mescore).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation Metric</head><p>We evaluate the measures using the metrics cho- sen in previous studies <ref type="bibr" target="#b37">(Zechner et al., 2009;</ref><ref type="bibr" target="#b5">Chen and Zechner, 2011;</ref><ref type="bibr" target="#b36">Yoon and Bhat, 2012)</ref>. A measure's utility has been evaluated according to its ability to discriminate between levels of pro- ficiency assigned by human raters. This is done by considering the Pearson correlation coefficient between the feature and the human scores. In an ideal situation, we would have compared machine score with scores of grammatical skill assigned by human raters. In our case, however, with only access to the overall proficiency scores, we use scores of language proficiency as those of gram- matical skill.</p><p>A criterion for evaluating the performance of the scoring model is the extent to which the au- tomatic scores of overall proficiency agree with the human scores. As in prior studies, here too the level of agreement is evaluated by means of the weighted kappa measure as well as unrounded and rounded Pearson's correlations between ma- chine and human scores (since the output of the re- gression model can either be rounded or regarded as is). The feature that maximizes this degree of agreement will be preferred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>First, we compare the discriminative ability of measures of syntactic complexity (VSM-model based measure with that of the MaxEnt-based measure) across proficiency levels.  <ref type="table" target="#tab_0">Table 2</ref>: Pearson correlation coefficients between measures and holistic proficiency scores. All values are significant at level 0.01. Only the measures cos 4 and mescore were compared for robustness using manual and ASR transcriptions.</p><p>notice that of the measures compared, mescore shows the highest correlation with scores of syn- tactic complexity. The correlation was approxi- mately 0.1 higher in absolute value than that of cos 4 , which was the best performing feature in the VSM-based model and the difference is statisti- cally significant.</p><p>Seeking to study the robustness of the mea- sures derived using a shallow analysis, we next compare the two measures studied here, with re- spect to the impact of speech recognition errors on their correlation with scores of syntactic complex- ity. Towards this end, we compare mescore and cos 4 when POS bigrams are extracted from man- ual transcriptions (ideal ASR) and ASR transcrip- tions.</p><p>In <ref type="table" target="#tab_0">Table 2</ref>, noticing that the correlations de- crease going along a row, we can say that the er- rors in the ASR system caused both mescore and cos 4 to under-perform. However, the performance drop (around 0.05) resulting from a shallow anal- ysis is relatively small compared to the drop ob- served while employing a deep syntactic analysis. <ref type="bibr" target="#b5">Chen and Zechner (2011)</ref> found that while using measures of syntactic complexity obtained from transcriptions, errors in ASR transcripts caused over 0.40 drop in correlation from that found with manual transcriptions <ref type="bibr">5</ref> . This comparison suggests that the current POS-based shallow analysis ap- proach is more robust to ASR errors compared to a syntactic analysis-based approach.</p><p>The effect of the measure of syntactic complex- ity is best studied by including it in an automatic scoring model of overall proficiency. We com- pare the performance gains over the state-of-the- art with the inclusion of additional features (VSM- based and MaxEnt-based, in turn). <ref type="table">Table 3</ref> shows the system performance with different grammar sophistication measures. The results reported are averaged over a 5-fold cross validation of the mul- tiple regression model, where 80% of the SM data set is used to train the model and the evaluation is done using 20% of the data in every fold.</p><p>As seen in <ref type="table">Table 3</ref>, using the proposed measure, mescore, leads to an improved agreement be- tween human and machine scores of proficiency. Comparing the unrounded correlation results in <ref type="table">Table 3</ref> we notice that the model Base+mescore shows the highest correlation of predicted scores with human scores. In addition, we test the sig- nificance of the difference between two depen- dent correlations using Steiger's Z-test (via the paired.r function in the R statistical package <ref type="bibr" target="#b25">(Revelle, 2012)</ref>). We note that the performance gain of Base+mescore over Base as well as over Base + cos4 is statistically significant at level = 0.01. The performance gain of Base+cos4 over Base, however, is not statistically significant at level = 0.01. Thus, the inclusion of the MaxEnt- based measure of syntactic complexity results in improved agreement between machine and hu- man scores compared to the state-of-the-art model (here, Base).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussions</head><p>We now discuss some of the observations and re- sults of our study with respect to the following items.</p><p>Improved performance: We sought to verify empirically that the MaxEnt model really outper- forms the VSM in the case of correlated POS bigrams. To see this, we separate the test set into three subsets A, B, C. Set A contains re- sponses where MaxEnt outperforms VSM; set B contains responses where VSM outperforms Max- Ent; set C contains responses where their predic- tions are comparable. For each group of responses s ∈ {A, B, C}, we calculate the percentage of re- sponses P s where two highly correlated POS bi- grams occur <ref type="bibr">6</ref> . We found that the percentages fol- low the order: P A = 12.93% &gt; P C = 7.29% &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation method</head><p>Base Base+cos4 Base+mescore Weighted kappa 0.503 0.524 0.546 Correlation (unrounded) 0.548 0.562 0.592 Correlation (rounded) 0.482 0.492 0.519 <ref type="table">Table 3</ref>: Comparison of scoring model performances using features of syntactic complexity studied in this paper along with those available in the state-of-the-art. Here, Base is the scoring model without the measures of syntactic complexity. All correlations are significant at level 0.01.</p><p>P B = 4.41%. This suggests that when correlated POS bigrams occur, MaxEnt is more likely to pro- vide better score predictions than VSM does.</p><p>Feature design: In the case of MaxEnt, the observation that binary-valued features (pres- ence/absence of POS bigrams) yield better perfor- mance than features indicative of the occurrence frequency of the bigram has interesting implica- tions. This was also observed in <ref type="bibr" target="#b24">Pang et al. (2002)</ref> where it was interpreted to mean that overall senti- ment is indicated by the presence/absence of key- words, as opposed to topic of a text, which is in- dicated by the repeated use of the same or simi- lar terms. An analogous explanation is applicable here.</p><p>At first glance, the use of the presence/absence of grammatical structures may raise concerns about a potential loss of information (e.g. the dis- tinction between an expression that is used once and another that is used multiple times is lost). However, when considered in the context of lan- guage acquisition studies, this approach seems to be justified. Studies in native language acquisi- tion, have considered multiple grammatical devel- opmental indices that represent the grammatical levels reached at various stages of language acqui- sition. For instance, <ref type="bibr" target="#b7">Covington et al. (2006)</ref> pro- posed the revised D-level scale which was origi- nally studied by <ref type="bibr" target="#b26">Rosenberg and Abbeduto (1987)</ref>. The D-Level Scale categorizes grammatical de- velopment into 8 levels according to the pres- ence of a set of diverse grammatical expressions varying in difficulty (for example, level 0 con- sists of simple sentences, while level 5 consists of sentences joined by a subordinating conjunc- tion). Similarly, <ref type="bibr" target="#b29">Scarborough (1990)</ref> proposed the Index of Productive Syntax (IPSyn), accord- ing to which, the presence of particular grammati- cal structures, from a list of 60 structures (ranging from simple ones such as including only subjects and verbs, to more complex constructions such as conjoined sentences) is evidence of language ac- quisition milestones.</p><p>Despite the functional differences between the indices, there is a fundamental operational simi- larity -that they both use the presence or absence of grammatical structures, rather than their oc- currence count, as evidence of acquisition of cer- tain grammatical levels. The assumption that a presence-based view of grammatical level acquisi- tion is also applicable to second language assess- ment helps validate our observation that binary- valued features yield a better performance when compared with frequency-valued features.</p><p>Generalizability: The training and test sets used in this study had similar underlying distribu- tions -they both sought unconstrained responses to a set of items with some minor differences in item type. Looking ahead, an important question is the extent to which our measure is sensitive to a mismatch between training and test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>Seeking alternatives to measuring syntactic com- plexity of spoken responses via syntactic parsers, we study a shallow-analysis based approach for use in automatic scoring.</p><p>Empirically, we show that the proposed mea- sure, based on a maximum entropy classification, satisfied the constraints of the design of an objec- tive measure to a high degree. In addition, the pro- posed measure was found to be relatively robust to ASR errors. The measure outperformed a related measure of syntactic complexity (also based on shallow-analysis of spoken response) previously found to be well-suited for automatic scoring. In- cluding the measure of syntactic complexity in an automatic scoring model resulted in statisti- cally significant performance gains over the state- of-the-art. We also make an interesting observa- tion that the impressionistic evaluation of syntactic complexity is better approximated by the presence or absence of grammar and usage patterns (and not by their frequency of occurrence), an idea sup- ported by studies in native language acquisition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 sum- marizes our experimental results for this task. We</head><label>2</label><figDesc></figDesc><table>Features 

Manual Transcriptions ASR 
mescore 
0.57 
0.52 
cos4 
0.48 
0.43 
cosmax 
-
0.31 

</table></figure>

			<note place="foot" n="1"> Construct validity is the degree to which a test measures what it claims, or purports, to be measuring and an important criterion in the development and use of assessments or tests.</note>

			<note place="foot" n="2"> T-units are defined as &quot;the shortest grammatically allowable sentences into which writing can be split.&quot; (Hunt, 1965)</note>

			<note place="foot" n="3"> http://opennlp.apache.org 4 http://homepages.inf.ed.ac.uk/ lzhang10/maxent_toolkit.html.</note>

			<note place="foot" n="5"> Due to differences in the dataset and ASR system, a direct comparison between the current study and the cited prior study was not possible.</note>

			<note place="foot" n="6"> We consider two POS bigrams to be highly correlated, when the their pointwise-mutual information is higher than 4.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pietra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="71" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fluency and structural complexity as predictors of L2 oral proficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of InterSpeech</title>
		<meeting>InterSpeech</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1241" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploiting diverse knowledge sources via maximum entropy in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Borthwick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Sixth Workshop on Very Large Corpora</title>
		<meeting>of the Sixth Workshop on Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A maximum entropy approach to named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Borthwick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>New York University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detecting structural events for assessing non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-Youn</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Innovative Use of NLP for Building Educational Applications, IUNLPBEA &apos;11</title>
		<meeting>the 6th Workshop on Innovative Use of NLP for Building Educational Applications, IUNLPBEA &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Computing and evaluating syntactic complexity features for automated scoring of spontaneous non-native speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="722" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An unsupervised method for detecting grammatical errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="140" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How complex is that sentence? a proposed revision of the rosenberg and abbeduto d-level scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congzhou</forename><surname>Michael A Covington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cati</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorina</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Naci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brown</surname></persName>
		</author>
		<ptr target="http://www.ai.uga.edu/caspr/2006-01-Covington.pdf." />
	</analytic>
	<monogr>
		<title level="j">ReVision. Washington</title>
		<imprint>
			<date type="published" when="2006-05-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Quantitative assessment of second language learners&apos; fluency by means of automatic speech recognition technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catia</forename><surname>Cucchiarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmer</forename><surname>Strik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Boves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="989" to="999" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quantitative assessment of second language learners&apos; fluency: comparisons between read and spontaneous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catia</forename><surname>Cucchiarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmer</forename><surname>Strik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Boves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2862" to="2873" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Part-of-speech histograms for genre classification of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Sergey Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><forename type="middle">R</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4781" to="4784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The influence of planning and task type on second language performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauline</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Skehan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Second Language Acquisition</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="299" to="324" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic pronunciation scoring for language instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Neumeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orith</forename><surname>Ronen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1471" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Assessing oral proficiency: a comparison of holistic and objective measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Halleck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Modern Language Journal</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="234" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A three-stage approach to the automated scoring of spontaneous spoken responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="282" to="306" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Grammatical structures written at three grade levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kellogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hunt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Assessed levels of second language speaking proficiency: How distinct?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriko</forename><surname>Iwashita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sally O&amp;apos;</forename><surname>Hagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applied Linguistics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Features of oral proficiency in task performance by efl and jfl learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriko</forename><surname>Iwashita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Selected proceedings of the Second Language Research Forum</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="32" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Named entity recognition with character-level models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Smarr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003</title>
		<meeting>the seventh conference on Natural language learning at HLT-NAACL 2003</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="180" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic analysis of syntactic complexity in second language writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Corpus Linguistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="474" to="496" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Filtering web text to match target genres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><forename type="middle">R</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3705" to="3708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Delta tfidf: An improved feature space for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Martineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic scoring of pronunciation quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Neumeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilios</forename><surname>Digalakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchel</forename><surname>Weintraub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="page" from="88" to="93" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Syntactic complexity measures and their relationship to L2 proficiency: A research synthesis of college-level L2 writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lourdes</forename><surname>Ortega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="492" to="518" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">psych: Procedures for Psychological, Psychometric, and Personality Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Revelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Evanston, Illinois</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note>R package version 1.2.1</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Indicators of linguistic competence in the peer group conversational behavior of mildly retarded adults</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheldon</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Abbeduto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psycholinguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="19" to="32" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adaptive statistical language modeling: a maximum entropy approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Rosenfeld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Ph.D. thesis. IBM</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A vector space model for automatic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anita</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Shu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Index of productive syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hollis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scarborough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Psycholinguistics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The ups and downs of preposition error detection in ESL writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">R</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Coherence modeling for the automated assessment of spontaneous spoken responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keelan</forename><surname>Evanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="814" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Performance measures for phone-level pronunciation teaching in CALL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silke</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of STiLL</title>
		<meeting>STiLL</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="99" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Use of the speech recognition in computer-assisted language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silke</forename><surname>Witt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Cambridge, U.K</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cambridge University Engineering department</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished dissertation</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Second language development in writing: Measures of fluency, accuracy, and complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Wolf-Quintero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunji</forename><surname>Inagaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hae-Young</forename><surname>Kim</surname></persName>
		</author>
		<idno>17</idno>
	</analytic>
	<monogr>
		<title level="m">Second Language Teaching and curriculum Center</title>
		<meeting><address><addrLine>Honolulu, HI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>The University of Hawai&apos;i</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Exploring content features for automated speech scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keelan</forename><surname>Evanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL-HLT</title>
		<meeting>the NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Assessment of esl learners&apos; syntactic competence based on similarity measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suma</forename><surname>Su-Youn Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="600" to="608" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automatic scoring of non-native spontaneous speech in tests of spoken english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="883" to="895" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
