<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Information Extraction over Structured Data: Question Answering with Freebase Center for Language and Speech Processing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University Baltimore</orgName>
								<address>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">Van</forename><surname>Durme</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University Baltimore</orgName>
								<address>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Information Extraction over Structured Data: Question Answering with Freebase Center for Language and Speech Processing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="956" to="966"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Answering natural language questions using the Freebase knowledge base has recently been explored as a platform for advancing the state of the art in open domain semantic parsing. Those efforts map questions to sophisticated meaning representations that are then attempted to be matched against viable answer candidates in the knowledge base. Here we show that relatively modest information extraction techniques, when paired with a web-scale corpus, can outperform these sophisticated approaches by roughly 34% relative gain.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering (QA) from a knowledge base (KB) has a long history within natural language processing, going back to the 1960s and 1970s, with systems such as Baseball <ref type="bibr" target="#b15">(Green Jr et al., 1961)</ref> and <ref type="bibr">Lunar (Woods, 1977)</ref>. These systems were limited to closed-domains due to a lack of knowledge resources, computing power, and abil- ity to robustly understand natural language. With the recent growth in KBs such as <ref type="bibr">DBPedia (Auer et al., 2007)</ref>, <ref type="bibr">Freebase (Bollacker et al., 2008)</ref> and <ref type="bibr">Yago2 (Hoffart et al., 2011</ref>), it has be- come more practical to consider answering ques- tions across wider domains, with commercial sys- tems including Google Now, based on Google's Knowledge Graph, and Facebook Graph Search, based on social network connections.</p><p>The AI community has tended to approach this problem with a focus on first understanding the in- tent of the question, via shallow or deep forms of semantic parsing (c.f. ยง3 for a discussion). Typ- ically questions are converted into some mean- ing representation (e.g., the lambda calculus), then mapped to database queries. Performance is thus bounded by the accuracy of the original seman- tic parsing, and the well-formedness of resultant database queries. <ref type="bibr">1</ref> The Information Extraction (IE) community ap- proaches QA differently: first performing rela- tively coarse information retrieval as a way to triage the set of possible answer candidates, and only then attempting to perform deeper analysis.</p><p>Researchers in semantic parsing have recently explored QA over Freebase as a way of moving beyond closed domains such as GeoQuery ( <ref type="bibr" target="#b34">Tang and Mooney, 2001</ref>). While making semantic pars- ing more robust is a laudable goal, here we provide a more rigorous IE baseline against which those efforts should be compared: we show that "tradi- tional" IE methodology can significantly outper- form prior state-of-the-art as reported in the se- mantic parsing literature, with a relative gain of 34% F 1 as compared to <ref type="bibr" target="#b1">Berant et al. (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We will view a KB as an interlinked collection of "topics". When given a question about one or sev- eral topics, we can select a "view" of the KB con- cerning only involved topics, then inspect every related node within a few hops of relations to the topic node in order to extract the answer. We call such a view a topic graph and assume answers can be found within the graph. We aim to maximally automate the answer extraction process, by mas- sively combining discriminative features for both the question and the topic graph. With a high per- formance learner we have found that a system with millions of features can be trained within hours, leading to intuitive, human interpretable features. For example, we learn that given a question con- cerning money, such as: what money is used in ukraine, the expected answer type is likely cur- rency. We formalize this approach in ยง4.</p><p>One challenge for natural language querying against a KB is the relative informality of queries as compared to the grammar of a KB. For exam- ple, for the question: who cheated on celebrity A, answers can be retrieved via the Freebase rela- tion celebrity.infidelity.participant, but the con- nection between the phrase cheated on and the formal KB relation is not explicit. To allevi- ate this problem, the best attempt so far is to map from <ref type="bibr">ReVerb (Fader et al., 2011</ref>) predicate- argument triples to Freebase relation triples <ref type="bibr" target="#b5">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b1">Berant et al., 2013)</ref>. Note that to boost precision, ReVerb has already pruned down less frequent or credible triples, yielding not as much coverage as its text source, ClueWeb. Here we instead directly mine relation mappings from ClueWeb and show that both direct relation mapping precision and indirect QA F 1 improve by a large margin. Details in ยง5.</p><p>Finally, we tested our system, jacana- freebase, 2 on a realistic dataset generously contributed by <ref type="bibr" target="#b1">Berant et al. (2013)</ref>, who collected thousands of commonly asked questions by crawling the Google Suggest service. Our method achieves state-of-the-art performance with F 1 at 42.0%, a 34% relative increase from the previous F 1 of 31.4%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>QA from a KB faces two prominent challenges: model and data. The model challenge involves finding the best meaning representation for the question, converting it into a query and exe- cuting the query on the KB. Most work ap- proaches this via the bridge of various interme- diate representations, including combinatory cat- egorial grammar <ref type="bibr" target="#b39">(Zettlemoyer and Collins, 2005</ref><ref type="bibr" target="#b30">, 2009</ref><ref type="bibr" target="#b23">Kwiatkowski et al., 2010</ref><ref type="bibr" target="#b24">Kwiatkowski et al., , 2011</ref><ref type="bibr" target="#b25">Kwiatkowski et al., , 2013</ref>, synchronous context-free grammars <ref type="bibr" target="#b36">(Wong and Mooney, 2007)</ref>, dependency trees ( <ref type="bibr" target="#b26">Liang et al., 2011;</ref><ref type="bibr" target="#b1">Berant et al., 2013)</ref>, string kernels ( <ref type="bibr" target="#b19">Kate and Mooney, 2006;</ref><ref type="bibr" target="#b6">Chen and Mooney, 2011)</ref>, and tree transducers ( <ref type="bibr" target="#b18">Jones et al., 2012</ref>). These works successfully showed their effectiveness in QA, despite the fact that most of them require hand-labeled logic annotations. More recent re- search started to minimize this direct supervision by using latent meaning representations <ref type="bibr" target="#b1">(Berant et al., 2013;</ref><ref type="bibr" target="#b25">Kwiatkowski et al., 2013)</ref> or distant su- pervision ( <ref type="bibr" target="#b22">Krishnamurthy and Mitchell, 2012)</ref>.</p><p>We instead attack the problem of QA from a KB from an IE perspective: we learn directly the pat- tern of QA pairs, represented by the dependency parse of questions and the Freebase structure of answer candidates, without the use of intermedi- ate, general purpose meaning representations.</p><p>The data challenge is more formally framed as ontology or (textual) schema matching <ref type="bibr" target="#b16">(Hobbs, 1985;</ref><ref type="bibr" target="#b32">Rahm and Bernstein, 2001;</ref><ref type="bibr" target="#b8">Euzenat and Shvaiko, 2007)</ref>: matching structure of two on- tologies/databases or (in extension) mapping be- tween KB relations and NL text. In terms of the latter, <ref type="bibr" target="#b5">Cai and Yates (2013)</ref> and <ref type="bibr" target="#b1">Berant et al. (2013)</ref> applied pattern matching and relation inter- section between Freebase relations and predicate- argument triples from the ReVerb OpenIE sys- tem <ref type="bibr" target="#b9">(Fader et al., 2011</ref>). <ref type="bibr" target="#b25">Kwiatkowski et al. (2013)</ref> expanded their CCG lexicon with Wik- tionary word tags towards more domain indepen- dence. <ref type="bibr" target="#b10">Fader et al. (2013)</ref> learned question para- phrases from aligning multiple questions with the same answers generated by WikiAnswers. The key factor to their success is to have a huge text source. Our work pushes the data challenge to the limit by mining directly from ClueWeb, a 5TB collection of web data.</p><p>Finally, the KB community has developed other means for QA without semantic parsing ( <ref type="bibr" target="#b28">Lopez et al., 2005;</ref><ref type="bibr" target="#b11">Frank et al., 2007;</ref><ref type="bibr" target="#b35">Unger et al., 2012;</ref><ref type="bibr" target="#b38">Yahya et al., 2012;</ref><ref type="bibr" target="#b33">Shekarpour et al., 2013</ref>). Most of these work executed SPARQL queries on in- terlinked data represented by RDF (Resource De- scription Framework) triples, or simply performed triple matching. Heuristics and manual templates were also commonly used ( <ref type="bibr" target="#b7">Chu-Carroll et al., 2012)</ref>. We propose instead to learn discriminative features from the data with shallow question anal- ysis. The final system captures intuitive patterns of QA pairs automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Graph Features</head><p>Our model is inspired by an intuition on how ev- eryday people search for answers. If you asked someone: what is the name of justin bieber brother, <ref type="bibr">3</ref> and gave them access to Freebase, that person might first determine that the question is about Justin Bieber (or his brother), go to Justin Bieber's Freebase page, and search for his brother's name. Unfortunately Freebase does not contain an exact relation called brother, but in- stead sibling. Thus further inference (i.e., brother โ male sibling) has to be made. In the following we describe how we represent this process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Question Graph</head><p>In answering our example query a person might take into consideration multiple constraints. With regards to the question, we know we are looking for the name of a person based on the following:</p><p>โข the dependency relation nsubj(what, name) and prep of(name, brother) indicates that the question seeks the information of a name; 4</p><p>โข the dependency relation prep of(name, brother) indicates that the name is about a brother (but we do not know whether it is a person name yet);</p><p>โข the dependency relation nn(brother, bieber) and the facts that, (i) Bieber is a person and (ii) a person's brother should also be a person, indi- cate that the name is about a person. This motivates the design of dependency-based features. We show one example in <ref type="figure" target="#fig_0">Figure 1(a)</ref>, left side. The following linguistic information is of interest:</p><p>โข question word (qword), such as what/who/how many. We use a list of 9 common qwords. 5</p><p>โข question focus (qfocus), a cue of expected an- swer types, such as name/money/time. We keep our analysis simple and do not use a ques- tion classifier, but simply extract the noun de- pendent of qword as qfocus.</p><p>โข question verb (qverb), such as is/play/take, ex- tracted from the main verb of the question. Question verbs are also good hints of answer types. For instance, play is likely to be followed by an instrument, a movie or a sports team.</p><p>โข question topic (qtopic). The topic of the ques- tion helps us find relevant Freebase pages. We simply apply a named entity recognizer to find the question topic. Note that there can be more than one topic in the question. Then we convert the dependency parse into a more generic question graph, in the following steps:</p><p>1. if a node was tagged with a question feature, then replace this node with its question feature, e.g., what โ qword=what;</p><p>2. (special case) if a qtopic node was tagged as a named entity, then replace this node with its its named entity form, e.g., bieber โ qtopic=person;</p><p>3. drop any leaf node that is a determiner, prepo- sition or punctuation. The converted graph is shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a), right side. We call this a question feature graph, with every node and relation a potential feature for this question. Then features are extracted in the following form: with s the source and t the target node, for every edge e(s, t) in the graph, extract s, t, s | t and s | e | t as features. For the edge, prep of(qfocus=name, brother), this would mean the following features: qfocus=name, brother, qfocus=name|brother, and qfocus=name|prep of|brother.</p><p>We show with examples why these features make sense later in ยง6 <ref type="table">Table 6</ref>. Furthermore, the reason that we have kept some lexical features, such as brother, is that we hope to learn from training a high correlation between brother and some Freebase relations and properties (such as sibling and male) if we do not possess an exter- nal resource to help us identify such a correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Freebase Topic Graph</head><p>Given a topic, we selectively roll out the Free- base graph by choosing those nodes within a few hops of relationship to the topic node, and form a topic graph. Besides incoming and/or outgo- ing relationships, nodes also have properties: a string that describes the attribute of a node, for instance, node type, gender or height (for a per- son). One major difference between relations and properties is that both arguments of a relation are nodes, while only one argument of a property is a node, the other a string. Arguments of relations are usually interconnected, e.g., London can be the place of birth for Justin Bieber, or capital of the UK. Arguments of properties are attributes that are only "attached" to certain nodes and have no outgoing edges.  we would not have known the node Jaxon Bieber represents a male person. These properties, along with the sibling relationship to the topic node, are important cues for answering the question. Thus for the Freebase graph, we use relations (with di- rections) and properties as features for each node. Additionally, we have analyzed how Freebase relations map back to the question. Some of the mapping can be simply detected as paraphras- ing or lexical overlap. For example, the per- son.parents relationship helps answering ques- tions about parenthood. However, most Freebase relations are framed in a way that is not com- monly addressed in natural language questions. For instance, for common celebrity gossip ques- tions like who cheated on celebrity A, it is hard for a system to find the Freebase relation celebrity.infidelity.participant as the target rela- tion if it had not observed this pattern in training.</p><p>Thus assuming there is an alignment model that is able to tell how likely one relation maps to the original question, we add extra alignment-based features for the incoming and outgoing relation of each node. Specifically, for each relation rel in a topic graph, we compute P (rel | question) to rank the relations. Finally the ranking (e.g., top 1/2/5/10/100 and beyond) of each relation is used as features instead of a pure probability. We de- scribe such an alignment model in ยง 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Feature Production</head><p>We combine question features and Freebase fea- tures (per node) by doing a pairwise concatena- tion. In this way we hope to capture the associa- tion between question patterns and answer nodes. For instance, in a loglinear model setting, we ex- pect to learn a high feature weight for features like:</p><p>qfocus=money|node type=currency and a very low weight for:</p><p>qfocus=money|node type=person. This combination greatly enlarges the total number of features, but owing to progress in large- scale machine learning such feature spaces are less of a concern than they once were (concrete num- bers in ยง 6 Model Tuning).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Relation Mapping</head><p>In this section we describe a "translation" table be- tween Freebase relations and NL words was built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Formula</head><p>The objective is to find the most likely rela- tion a question prompts. For instance, for the question who is the father of King George VI, the most likely relation we look for is peo- ple.person.parents. To put it more formally, given a question Q of a word vector w, we want to find out the relation R that maximizes the prob- ability P (R | Q).</p><p>More</p><note type="other">interestingly, for the question who is the father of the Periodic Table, the ac- tual relation that encodes its original mean- ing is law.invention.inventor, rather than peo- ple.person.parents. This simple example points out that every part of the question could change what the question inquires eventually. Thus we need to count for each word w in Q. Due to the bias and incompleteness of any data source, we approximate the true probability of P withหPwithห withหP un- der our specific model. For the simplicity of com- putation, we assume conditional independence be- tween words and apply Naive Bayes:</note><formula xml:id="formula_0">ห P (R | Q) โ ห P (Q | R) ห P (R) โ ห P (w | R) ห P (R) โ w ห P (w | R) ห P (R)</formula><p>whereหPwhereห whereหP (R) is the prior probability of a relation R andหPandห andหP (w | R) is the conditional probability of word w given R.</p><p>It is possible that we do not observe a certain relation R when computing the above equation. In this case we back off to the "sub-relations": a relation R is a concatenation of a series of sub- relations R = r = r 1 .r 2 .r 3 . . . .. For instance, the sub-relations of people.person.parents are peo- ple, person, and parents. Again, we assume con- ditional independence between sub-relations and apply Naive Bayes:</p><formula xml:id="formula_1">ห P backoff (R | Q) โ ห P (r | Q) โ r ห P (r | Q) โ r ห P (Q | r) ห P (r) โ r w ห P (w | r) ห P (r)</formula><p>One other reason that we estimatedหP estimatedห estimatedหP (w | r) andหPandห andหP (r) for sub-relations is that Freebase relations share some com- mon structures in between them.</p><p>For in- stance, both people.person.parents and fictional universe.fictional character.parents indicate the parent relationship but the latter is much less commonly annotated. We hope that the shared sub-relation, parents, can help better esti- mate for the less annotated. Note that the backoff model would have a much smaller value than the original, due to double multiplication r w . In practice we normalize it by the sub-relations size to keep it at the same scale withหPwithห withหP (R | Q).</p><p>Finally, to estimate the prior and conditional probability, we need a massive data collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Steps</head><p>The ClueWeb09 6 dataset is a collection of 1 billion webpages (5TB compressed in raw HTML) in 10 languages by Carnegie Mellon University in 2009. FACC1, the Freebase Annotation of the ClueWeb Corpus version 1 ( , con- tains index and offset of Freebase entities within the English portion of ClueWeb. Out of all 500 million English documents, 340 million were au- tomatically annotated with at least one entity, with an average of 15 entity mentions per document. The precision and recall of annotation were esti- mated at 80โ85% and 70โ85% ( <ref type="bibr" target="#b31">Orr et al., 2013)</ref>.</p><p>Given these two resources, for each binary Free- base relation, we can find a collection of sentences each of which contains both of its arguments, then simply learn how words in these sentences are as- sociated with this relation, i.e., ห P (w | R) andหP andห andหP (w | r). By counting how many times each rela- tion R was annotated, we can estimateหPestimateห estimateหP (R) andหP andห andหP (r). The learning task can be framed in the fol- lowing short steps: 1. We split each HTML document by sentences ( <ref type="bibr" target="#b20">Kiss and Strunk, 2006</ref>) using NLTK ( <ref type="bibr" target="#b2">Bird and Loper, 2004</ref>) and extracted those with at least two Freebase entities which has at least one di- rect established relation according to Freebase. 2. The extraction formed two parallel corpora, one with "relation -sentence" pairs (for esti- matingหPmatingห matingหP (w | R) andหPandห andหP (R)) and the other with "subrelations -sentence" pairs (forหPforห forหP (w | r) andหPandห andหP (r)). Each corpus has 1.2 billion pairs. 3. The tricky part was to align these 1.2 billion pairs. Since the relations on one side of these pairs are not natural sentences, we ran the most simple IBM alignment Model 1 ( <ref type="bibr" target="#b4">Brown et al., 1993</ref>) to estimate the translation proba- bility with GIZA++ ( <ref type="bibr" target="#b29">Och and Ney, 2003)</ref>. To speed up, the 1.2 billion pairs were split into 6 http://lemurproject.org/clueweb09/ 0 โค 10 โค 10 2 โค 10 3 โค 10 4 &gt; 10 4 7.0% 0.7% 1.2% 0.4% 1.3% 89.5% <ref type="table">Table 1</ref>: Percentage of answer relations (the in- coming relation connected to the answer node) with respect to how many sentences we learned this relation from in CluewebMapping. For in- stance, the first column says there are 7% of an- swer relations for which we cannot find a mapping (so we had to use the backoff probability estima- tion); the last column says there are 89.5% of an- swer relations that we were able to learn the map- ping between this relation and text based on more than 10 thousand relation-sentence pairs. The total number of answer relations is 7886. 100 even chunks. We ran 5 iterations of EM on each one and finally aligned the 1.2 billion pairs from both directions. To symmetrize the align- ment, common MT heuristics INTERSECTION, UNION, GROW-DIAG-FINAL, and GROW-DIAG- FINAL-AND ( <ref type="bibr" target="#b21">Koehn, 2010)</ref> were separately ap- plied and evaluated later.</p><p>4. Treating the aligned pairs as observation, the co-occurrence matrix between aligning rela- tions and words was computed. There were 10,484 relations and sub-relations in all, and we kept the top 20,000 words.</p><p>5. From the co-occurrence matrix we computedหP computedห computedหP (w | R), ห P (R), ห P (w | r) andหPandห andหP (r).</p><p>Hand-checking the learned probabilities shows both success, failure and some bias. For in- stance, for the film.actor.film relation (mapping from film names to actor names), the top words given byหPbyห byหP (w | R) are won, star, among, show. For the film.film.directed by relation, some im- portant stop words that could indicate this re- lation, such as by and with, rank directly after director and direct. However, due to signifi- cant popular interest in certain news categories, and the resultant catering by websites to those information desires, then for example we also learned a heavily correlated connection between Jennifer Aniston and celebrity.infidelity.victim, and between some other you-know-who names and celebrity.infidelity.participant.</p><p>We next formally evaluate how the learned map- ping help predict relations from words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation</head><p>Both ClueWeb and its Freebase annotation has a bias. Thus we were firstly interested in the cov- erage of mined relation mappings. As a com- parison, we used a dataset of relation mapping contributed by <ref type="bibr" target="#b1">Berant et al. (2013)</ref> and <ref type="bibr" target="#b27">Lin et al. (2012)</ref>. The idea is very similar: they intersected Freebase relations with predicates in (arg1, predi- cate, arg2) triples extracted from ReVerb to learn the mapping between Freebase relations and triple predicates. Note the scale difference: although ReVerb was also extracted from ClueWeb09, there were only 15 million triples to intersect with the relations, while we had 1.2 billion alignment pairs. We call this dataset ReverbMapping and ours CluewebMapping.</p><p>The evaluation dataset, WEBQUESTIONS, was also contributed by <ref type="bibr" target="#b1">Berant et al. (2013)</ref>. It con- tains 3778 training and 2032 test questions col- lected from the Google Suggest service. All ques- tions were annotated with answers from Freebase. Some questions have more than one answer, such as what to see near sedona arizona?.</p><p>We evaluated on the training set in two aspects: coverage and prediction performance. We define answer node as the node that is the answer and answer relation as the relation from the answer node to its direct parent. Then we computed how much and how well the answer relation was trig- gered by ReverbMapping and CluewebMapping. Thus for the question, who is the father of King George VI, we ask two questions: does the map- ping, 1. (coverage) contain the answer relation people.person.parents? 2. (precision) predict the answer relation from the question? <ref type="table">Table 1</ref> shows the coverage of CluewebMap- ping, which covers 93.0% of all answer rela- tions. Among them, we were able to learn the rule mapping using more than 10 thousand relation- sentence pairs for each of the 89.5% of all an- swer relations. In contrast, ReverbMapping covers 89.7% of the answer relations.</p><p>Next we evaluated the prediction performance, using the evaluation metrics of information re- trieval. For each question, we extracted all rela- tions in its corresponding topic graph, and ranked each relation with whether it is the answer re- lation. For instance, for the previous exam- ple question, we want to rank the relation peo- ple.person.parents as number 1. We com- puted standard MAP (Mean Average Precision) and MRR (Mean Reciprocal Rank), shown in Ta- ble 2(a). As a simple baseline, "word overlap" counts the overlap between relations and the ques- tion. CluewebMapping ranks each relation byหP byห byหP (R | Q). ReverbMapping does the same, ex- cept that we took a uniform distribution oรฑ P (w | R) andหPandห andหP (R) since the contributed dataset did not include co-occurrence counts to estimate these probabilities. <ref type="bibr">7</ref> Note that the median rank from CluewebMapping is only 12, indicating that half of all answer relations are ranked in the top 12. <ref type="table" target="#tab_1">Table 2</ref>(b) further shows the percentage of answer relations with respect to their rank- ing. CluewebMapping successfully ranked 19% of answer relations as top 1.</p><p>A sample of these includes person.place of birth, loca- tion.containedby, country.currency used, reg- ular tv appearance.actor, etc. These percentage numbers are good clue for feature design: for in- stance, we may be confident in a relation if it is ranked top 5 or 10 by CluewebMapping.</p><p>To conclude, we found that CluewebMapping provides satisfying coverage on the 3778 training questions: only 7% were missing, despite the bi- ased nature of web data. Also, CluewebMapping gives reasonably good precision on its prediction, despite the noisy nature of web data. We move on to fully evaluate the final QA F 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate the final F 1 in this section. The sys- tem of comparison is that of <ref type="bibr" target="#b1">Berant et al. (2013)</ref>. Data We re-used WEBQUESTIONS, a dataset collected by <ref type="bibr" target="#b1">Berant et al. (2013)</ref>. It contains 5810 questions crawled from the Google Suggest ser- vice, with answers annotated on Amazon Mechan- ical Turk. All questions contain at least one an- swer from Freebase. This dataset has been split by 65%/35% into <ref type="bibr">TRAIN</ref>   <ref type="bibr">, 2013a)</ref>.All named entities 8 in a question were sent to this API, which returned a ranked list of rele- vant topics. We also evaluated how well the search API served the IR purpose. WEBQUESTIONS not only has answers annotated, but also which Free- base topic nodes the answers come from. Thus we evaluated the ranking of retrieval with the gold standard annotation on TRAIN-ALL, shown in Ta- ble 3. The top 2 results of the Search API con- tain gold standard topics for more than 90% of the questions and the top 10 results contain more than 95%. We took this as a "good enough" IR front- end and used it on TEST.</p><p>Once a topic is obtained we query the Freebase Topic API <ref type="bibr" target="#b13">(Freebase, 2013b)</ref> to retrieve all rele- vant information, resulting in a topic graph. The API returns almost identical information as dis- played via a web browser to a user viewing this topic. Given that turkers annotated answers based on the topic page via a browser, this supports the assumption that the same answer would be located in the topic graph, which is then passed to the QA engine for feature extraction and classification.   <ref type="table">Table 3</ref>: Evaluation on the Freebase Search API: how many questions' top n retrieved results con- tain the gold standard topic. Total number of ques- tions is 3778 (size of TRAIN-ALL). There were only 5 questions with no retrieved results. Model Tuning We treat QA on Freebase as a binary classification task: for each node in the topic graph, we extract features and judge whether it is the answer node. Every question was pro- cessed by the Stanford CoreNLP suite with the caseless model. Then the question features ( ยง4.1) and node features ( ยง4.2) were combined ( ยง4.3) for each node. The learning problem is chal- lenging: for about 3000 questions in TRAIN, there are 3 million nodes (1000 nodes per topic graph), and 7 million feature types. We em- ployed a high-performance machine learning tool, Classias <ref type="bibr" target="#b30">(Okazaki, 2009)</ref>. Training usually took around 4 hours. We experimented with vari- ous discriminative learners on DEV, including lo- gistic regression, perceptron and SVM, and found L1 regularized logistic regression to give the best result. The L1 regularization encourages sparse features by driving feature weights towards zero, which was ideal for the over-generated feature space. After training, we had around 30 thousand features with non-zero weights, a 200 fold reduc- tion from the original features.</p><p>Also, we did an ablation test on DEV about how additional features on the mapping between Freebase relations and the original questions help, with three feature settings: 1) "basic" features in- clude feature productions read off from the fea- ture graph ( <ref type="figure" target="#fig_0">Figure 1</ref>); 2) "+ word overlap" adds additional features on whether sub-relations have overlap with the question; and 3) "+ CluewebMap- ping" adds the ranking of relation prediction given the question according to CluewebMapping. <ref type="table">Ta- ble 4</ref> shows that the additional CluewebMapping P R F 1 Gold Retrieval 45.4 52.2 48.6 Freebase Search API 38.8 45.8 42.0 <ref type="bibr" target="#b1">Berant et al. (2013)</ref> - - 31.4 <ref type="table">Table 5</ref>: F 1 on TEST with Gold Retrieval and Freebase Search API as the IR front end. <ref type="bibr" target="#b1">Berant et al. (2013)</ref> actually reported accuracy on this dataset. However, since their system predicted an- swers for almost every question (p.c.), it is roughly that precision=recall=F 1 =accuracy for them.</p><p>features improved overall F 1 by 5%, a 13% rel- ative improvement: a remarkable gain given that the model already learned a strong correlation be- tween question types and answer types (explained more in discussion and <ref type="table">Table 6</ref> later).</p><p>Finally, the ratio of positive vs. negative exam- ples affect final F 1 : the more positive examples, the lower the precision and the higher the recall. Under the original setting, this ratio was about 1 : 275. This produced precision around 60% and recall around 35% (c.f. <ref type="table">Table 4</ref>). To optimize for F 1 , we down-sampled the negative examples to 20%, i.e., a new ratio of 1 : 55. This boosted the final F 1 on DEV to 48%. We report the final TEST result under this down-sampled training. In prac- tice the precision/recall balance can be adjusted by the positive/negative ratio. Test Results <ref type="table">Table 5</ref> gives the final F 1 on TEST. "Gold Retrieval" always ranked the correct topic node top 1, a perfect IR front-end assumption. In a more realistic scenario, we had already evaluated that the Freebase Search API returned the correct topic node 95% of the time in its top 10 results (c.f. <ref type="table">Table 3</ref>), thus we also tested on the top 10 results returned by the Search API. To keep things sim- ple, we did not perform answer voting, but sim- ply extracted answers from the first (ranked by the Search API) topic node with predicted answer(s) found. The final F 1 of 42.0% gives a relative im- provement over previous best result <ref type="bibr" target="#b1">(Berant et al., 2013</ref>) of 31.4% by one third.</p><p>One question of interest is whether our system, aided by the massive web data, can be fairly com- pared to the semantic parsing approaches (note that <ref type="bibr" target="#b1">Berant et al. (2013)</ref> also used ClueWeb in- directly through ReVerb). Thus we took out the word overlapping and CluewebMapping based features, and the new F 1 on TEST was 36.9%.</p><p>The other question of interest is that whether our system has acquired some level of "machine wgt. feature  <ref type="table">Table 6</ref>: A sample of the top 50 most positive/neg- ative features. Features are production between question and node features (c.f. <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>intelligence": how much does it know what the question inquires? We discuss it below through feature and error analysis.</p><p>Discussion The combination between questions and Freebase nodes captures some real gist of QA pattern typing, shown in <ref type="table">Table 6</ref> with sampled fea- tures and weights. Our system learned, for in- stance, when the question asks for geographic ad- jacency information (qverb=border), the correct answer relation to look for is location.adjoins. Detailed comparison with the output from Berant et al. <ref type="formula">(2013)</ref> is a work in progress and will be pre- sented in a follow-up report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We proposed an automatic method for Question Answering from structured data source (Free- base). Our approach associates question features with answer patterns described by Freebase and has achieved state-of-the-art results on a balanced and realistic QA corpus. To compensate for the problem of domain mismatch or overfitting, we exploited ClueWeb, mined mappings between KB relations and natural language text, and showed that it helped both relation prediction and an- swer extraction. Our method employs relatively lightweight machinery but has good performance. We hope that this result establishes a new baseline against which semantic parsing researchers can measure their progress towards deeper language understanding and answering of human questions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 ((</head><label>1</label><figDesc>b) shows an example. Both relationship and property of a node are important to identifying the answer. They con- nect the nodes with the question and describe some unique characteristics. For instance, with- out the properties type:person and gender:male, what is name the brother justin bieber nsubj cop nn prep_of det nn qword qtopic qfocus qtopic qword= what qfocus= name brother qtopic= person qtopic= person nsubj nn prep_of nn qverb= be cop qverb (a) Dependence parse with annotated question features in dashed boxes (left) and converted feature graph (right) with only relevant and general information about the original question kept. Note that the left is a real but incorrect parse.b) A view of Freebase graph on the Justin Bieber topic with nodes in solid boxes and properties in dashed boxes. The hatching node, Jaxon Bieber, is the answer. Freebase uses a dummy parent node for a list of nodes with the same relation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Dependency parse and excerpted Freebase topic graph on the question what is the name of justin bieber brother.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Evaluation on answer relation ranking 
prediction on 3778 training questions. 

lot of questions in WEBQUESTIONS contain more 
than one answer. 
Search With an Information Retrieval (IR) 
front-end, we need to locate the exact Freebase 
topic node a question is about. For this pur-
pose we used the Freebase Search API (Freebase</table></figure>

			<note place="foot" n="1"> As an example, 50% of errors of the CCG-backed (Kwiatkowski et al., 2013) system were contributed by parsing or structural matching failure.</note>

			<note place="foot" n="2"> https://code.google.com/p/jacana</note>

			<note place="foot" n="3"> All examples used in this paper come from the training data crawled from Google Suggest. They are lowercased and some contain typos.</note>

			<note place="foot" n="4"> We use the Stanford collapsed dependency form. 5 who, when, what, where, how, which, why, whom, whose.</note>

			<note place="foot" n="7"> The way we used ReverbMapping was not how Berant et al. (2013) originally used it: they employed a discriminative log-linear model to judge relations and that might yield better performance. As a fair comparison, ranking of CluewebMapping under uniform distribution is also included in Table 2(a).</note>

			<note place="foot" n="8"> When no named entities are detected, we fall back to noun phrases.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBPedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sรถren</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The semantic web</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic Parsing on Freebase from Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">NLTK: The Natural Language Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</title>
		<meeting>the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to Interpret Natural Language Navigation Instructions from Observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding needles in the haystack: Search and candidate generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Boguraev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sheinwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Welty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jรฉrรดme</forename><surname>Euzenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Shvaiko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Paraphrase-Driven Learning for Open Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Question answering from structured knowledge sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Ulrich</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berthold</forename><surname>Crysmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brigitte</forename><surname>Jรถrg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Schรคfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Logic</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="48" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Freebase Search API</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freebase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Freebase Topic API</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freebase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Release date</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2013" to="2019" />
		</imprint>
	</monogr>
	<note>Format version 1, Correction level 0</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Baseball: an automatic question-answerer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">K</forename><surname>Bert F Green</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Chomsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laughery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">western joint IRE-AIEE-ACM computer conference</title>
		<imprint>
			<biblScope unit="page" from="219" to="224" />
			<date type="published" when="1961-05-09" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
	<note>In Papers presented at the</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ontological promiscuity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Yago2: exploring and querying world knowledge in time, space, context, and many languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><forename type="middle">De</forename><surname>Lewis-Kelham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference companion on World Wide Web</title>
		<meeting>the 20th international conference companion on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="229" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic parsing with bayesian tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keeley</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using string-kernels for learning semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised multilingual sentence boundary detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tibor</forename><surname>Kiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Strunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="485" to="525" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scaling Semantic Parsers with On-the-fly Ontology Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning Dependency-Based Compositional Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Entity Linking at Web Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Knowledge Extraction Workshop (AKBC-WEKEX)</title>
		<meeting>Knowledge Extraction Workshop (AKBC-WEKEX)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="84" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aqualog: An ontology-portable question answering system for the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Pasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: Research and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="546" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Classias: a collection of machine-learning algorithms for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">11 billion clues in 800 million documents: A web research corpus annotated with freebase concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amar</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<ptr target="http://googleresearch.blogspot.com/2013/07/11-billion-clues-in-800-million.html" />
		<imprint>
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A survey of approaches to automatic schema matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhard</forename><surname>Rahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Philip A Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the VLDB Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="334" to="350" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Question answering on interlinked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sรถren</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Using multiple clause constructors in inductive logic programming for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: ECML 2001</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="466" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Template-based question answering over RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>Bรผhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st international conference on World Wide Web</title>
		<meeting>the 21st international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Lunar rocks in natural english: Explorations in natural language question answering. Linguistic structures processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William A Woods</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="521" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Natural language questions for the web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
			<publisher>UAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning context-dependent mappings from sentences to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACLCoNLL</title>
		<meeting>ACLCoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
