<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantics for Large-Scale Multimedia: New Challenges for NLP</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2014-06">June 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
							<email>fmetze@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichi</forename><surname>Shinoda</surname></persName>
							<email>shinoda@cs.titech.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semantics for Large-Scale Multimedia: New Challenges for NLP</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Tutorials</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics: Tutorials <address><addrLine>Baltimore, Maryland, USA, 22</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="volume">6</biblScope>
							<date type="published" when="2014-06">June 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Koichi Shinoda</head><p>Tokyo Institute of Technology shinoda@cs.titech.ac.jp</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Description</head><p>Thousands of videos are constantly being up- loaded to the web, creating a vast resource, and an ever-growing demand for methods to make them easier to retrieve, search, and index. As it becomes feasible to extract both low-level as well as high- level (symbolic) audio, speech, and video features from this data, these need to be processed further, in order to learn and extract meaningful relations between these. The language processing commu- nity has made huge process in analyzing the vast amounts of very noisy text data that is available on the Internet. While it is very difficult to create semantic units of low-level image descriptors or non-speech sounds by themselves, it is compara- tively easy to ground semantics in the word output of a speech recognizer, or text data that is loosely associated with a video. This creates an opportu- nity for NLP researchers to use their unique skills, and make significant contributions to solve tasks on data that is even noisier than web text, but (we argue) even more interesting and challenging.</p><p>This tutorial aims to present to the NLP com- munity the state of the art in audio and video processing, by discussing the most relevant tasks at NIST's TREC Video Retrieval Evaluation (TRECVID) workshop series. We liken "Seman- tic Indexing" (SIN) task, in which a system must identify occurrences of concepts such as "desk", or "dancing" in a video to the word spotting ap- proach. We then proceed to explain more recent, and challenging tasks, "Multimedia Event Detec- tion" (MED) and "Multimedia Event Recounting" (MER), which can be compared to transcription and summarization tasks. Finally, we will present an easy way to get started in multi-media analysis using Virtual Machines from the "Speech Recog- nition Virtual Kitchen", which will enable tutorial participants to perform hands-on experiments dur- ing the tutorial, and at home.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Outline</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>• Content based video retrieval • What is the "Semantic Gap"?</p><p>• </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The TRECVid workshop and its tasks 2. Semantic Indexing • State-of-the art frameworks • Extension of Bag-of-Word model • Multi-modality 3. Multimedia Event Detection &amp; Recounting • State-of-the art frameworks • Multimodal fusion • Semi-supervised and active learning • Video Summarization 4. Challenges for NLP • How to design visual concepts? • Intermediate representations? • Are there any grammars in video? 5. Practice session • Virtual Machines in the Speech Recognition Virtual Kitchen (http://speechkitchen.org/) 3 Instructors Florian Metze received his PhD from Universitat Karlsruhe (TH) in 2005. He worked as a Senior Research Scientist at Deutsche Telekom Labora- tories (T-Labs) and joined Carnegie Mellon Uni- versity's faculty in 2009. His interests includes speech and audio processing, and user interfaces. Koichi Shinoda received his D. Eng. from Tokyo Institute of Technology in 2001. In 1989, he joined NEC Corporation. From 1997 to 1998, he was a visiting scholar with Bell Labs, Lucent Technolo- gies. He is currently a Professor at the Tokyo In- stitute of Technology. His research interests in- clude speech recognition, video information re- trieval, and human interfaces. 6</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
