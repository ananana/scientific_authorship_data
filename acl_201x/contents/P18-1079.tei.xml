<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantically Equivalent Adversarial Rules for Debugging NLP Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><forename type="middle">Tulio</forename><surname>Ribeiro</surname></persName>
							<email>marcotcr@cs.uw.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
							<email>sameer@uci.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
							<email>guestrin@cs.uw.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Washington</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semantically Equivalent Adversarial Rules for Debugging NLP Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="856" to="865"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>856</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Complex machine learning models for NLP are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs)-semantic-preserving perturbations that induce changes in the model&apos;s predictions. We generalize these adversaries into semantically equivalent adversarial rules (SEARs)-simple, universal replacement rules that induce adversaries on many instances. We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains: machine comprehension, visual question-answering, and sentiment analysis. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable: retraining models using data augmentation significantly reduces bugs, while maintaining accuracy.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With increasing complexity of models for tasks like classification ( <ref type="bibr" target="#b5">Joulin et al., 2016)</ref>, machine compre- hension ( <ref type="bibr" target="#b17">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b20">Seo et al., 2017)</ref>, and visual question answering ( <ref type="bibr" target="#b26">Zhu et al., 2016)</ref>, models are becoming increasingly challenging to debug, and to determine whether they are ready for deployment. In particular, these complex models are prone to brittleness: different ways of phrasing the same sentence can often cause the model to  output different predictions. While held-out accu- racy is often useful, it is not sufficient: practitioners consistently overestimate their model's generaliza- tion ( <ref type="bibr" target="#b16">Patel et al., 2008</ref>) since test data is usually gathered in the same manner as training and vali- dation. When deployed, these seemingly accurate models encounter sentences that are written very differently than the ones in the training data, thus making them prone to mistakes, and fragile with re- spect to distracting additions ( <ref type="bibr" target="#b4">Jia and Liang, 2017</ref>). These problems are exacerbated by the variability in language, and by cost and noise in annotations, making such bugs challenging to detect and fix. A particularly challenging issue is oversensitiv- ity ( <ref type="bibr" target="#b4">Jia and Liang, 2017)</ref>: a class of bugs where models output different predictions for very similar inputs. These bugs are prevalent in image classifi-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformation Rules #Flips</head><p>(WP is→WP's) 70 (1%) <ref type="bibr">(?→??)</ref> 202(3%)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Example Rules</head><p>Original: What is the oncorhynchus also called? A: chum salmon Changed: What's the oncorhynchus also called? A: keta (b) Example for (WP is→WP's)</p><p>Original: How long is the Rhine? A: 1,230 km Changed: How long is the Rhine?? A: more than 1,050,000</p><p>(c) Example for (?→??)</p><p>Figure 2: Semantically Equivalent Adversarial Rules: For the task of question answering, the proposed approach identifies transformation rules for questions in (a) that result in paraphrases of the queries, but lead to incorrect answers (#Flips is the number of times this happens in the validation data). We show examples of rephrased questions that result in incorrect answers for the two rules in (b) and (c).</p><p>cation ( <ref type="bibr" target="#b21">Szegedy et al., 2014</ref>), a domain where one can measure the magnitude of perturbations, and many small-magnitude changes are imperceptible to the human eye. For text, however, a single word addition can change semantics (e.g. adding "not"), or have no semantic impact for the task at hand. Inspired by adversarial examples for images, we introduce semantically equivalent adver- saries (SEAs) -text inputs that are perturbed in semantics-preserving ways, but induce changes in a black box model's predictions (example in <ref type="figure" target="#fig_1">Figure  1</ref>). Producing such adversarial examples systemati- cally can significantly aid in debugging ML models, as it allows users to detect problems that happen in the real world, instead of oversensitivity only to malicious attacks such as intentionally scram- bling, misspelling, or removing words ( <ref type="bibr" target="#b0">Bansal et al., 2014;</ref><ref type="bibr" target="#b1">Ebrahimi et al., 2018;</ref>.</p><p>While SEAs describe local brittleness (i.e. are specific to particular predictions), we are also inter- ested in bugs that affect the model more globally. We represent these via simple replacement rules that induce SEAs on multiple predictions, such as in <ref type="figure">Figure 2</ref>, where a simple contraction of "is"after Wh pronouns (what, who, whom) (2b) makes 70 (1%) of the previously correct predictions of the model "flip" (i.e. become incorrect). Perhaps more surprisingly, adding a simple "?" induces mistakes in 3% of examples. We call such rules semantically equivalent adversarial rules (SEARs).</p><p>In this paper, we present SEAs and SEARs, de- signed to unveil local and global oversensitivity bugs in NLP models. We first present an approach to generate semantically equivalent adversaries, based on paraphrase generation techniques ( <ref type="bibr" target="#b11">Lapata et al., 2017)</ref>, that is model-agnostic (i.e. works for any black box model). Next, we generalize SEAs into semantically equivalent rules, and outline the properties for optimal rule sets: semantic equiva- lence, high adversary count, and non-redundancy. We frame the problem of finding such a set as a submodular optimization problem, leading to an accurate yet efficient algorithm.</p><p>Including the human into the loop, we demon- strate via user studies that SEARs help users un- cover important bugs on a variety of state-of-the-art models for different tasks (sentiment classification, visual question answering). Our experiments indi- cate that SEAs and SEARs make humans signifi- cantly better at detecting impactful bugs -SEARs uncover bugs that cause 3 to 4 times more mistakes than human-generated rules, in much less time. Fi- nally, we show that SEARs are actionable, enabling the human to close the loop by fixing the discov- ered bugs using a data augmentation procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Semantically Equivalent Adversaries</head><p>Consider a black box model f that takes a sentence x and makes a prediction f (x), which we want to debug. We identify adversaries by generating paraphrases of x, and getting predictions from f until the original prediction is changed.</p><p>Given an indicator function SemEq(x, x ) that is 1 if x is semantically equivalent to x and 0 oth- erwise, we define a semantically equivalent adver- sary (SEA) as a semantically equivalent instance that changes the model prediction in Eq (1). Such adversaries are important in evaluating the robust- ness of f , as each is an undesirable bug.</p><formula xml:id="formula_0">SEA(x, x ) = 1 SemEq(x, x )∧f (x) = f (x )<label>(1)</label></formula><p>While there are various ways of scoring semantic similarity between pairs of texts based on embed- dings ( <ref type="bibr" target="#b12">Le and Mikolov, 2014;</ref><ref type="bibr" target="#b23">Wieting and Gimpel, 2017)</ref>, they do not explicitly penalize unnatural sen- tences, and generating sentences requires surround- ing context ( <ref type="bibr" target="#b12">Le and Mikolov, 2014)</ref> or training a separate model. We turn instead to paraphras- ing based on neural machine translation ( <ref type="bibr" target="#b11">Lapata et al., 2017)</ref>, where P (x |x) (the probability of a paraphrase x given original sentence x) is propor- tional to translating x into multiple pivot languages and then taking the score of back-translating the translations into the original language. This ap- proach scores semantics and "plausibility" simulta- neously (as translation models have "built in" lan- guage models) and allows for easy paraphrase gen- eration, by linearly combining the paths of each back-decoder when back-translating. Unfortunately, given source sentences x and z, P (x |x) is not comparable to P (z |z), as each has a different normalization constant, and heavily de- pends on the shape of the distribution around x or z. If there are multiple perfect paraphrases near x, they will all share probability mass, while if there is a paraphrase much better than the rest near z, it will have a higher score than the ones near x, even if the paraphrase quality is the same. We thus de- fine the semantic score S(x, x ) as a ratio between the probability of a paraphrase and the probability of the sentence itself:</p><formula xml:id="formula_1">S(x, x ) = min 1, P (x |x) P (x|x)<label>(2)</label></formula><p>We define SemEq(x,</p><formula xml:id="formula_2">x ) = 1[S(x, x ) ≥ τ ], i.e.</formula><p>x is semantically equivalent to x if the similarity score between x and x is greater than some thresh- old τ (which we crowdsource in Section 5). In order to generate adversaries, we generate a set of paraphrases Π x around x via beam search and get predictions on Π x using the black box model until an adversary is found, or until S(x, x ) &lt; τ . We may be interested in the best adversary for a partic- ular instance, i.e. argmax x ∈Πx S(x, x )SEA x (x ), or we may consider multiple SEAs for generaliza- tion purposes. We illustrate this process in <ref type="figure">Figure 3</ref>, where we generate SEAs for a VQA model by gen- erating paraphrases around the question, and check- ing when the model prediction changes. The first two adversaries with highest S(x, x ) are semanti- cally equivalent, the third maintains the semantics enough for it to be a useful adversary, and the fourth is ungrammatical and thus not useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantically Equivalent Adversarial Rules (SEARs)</head><p>While finding the best adversary for a particular instance is useful, humans may not have time or patience to examine too many SEAs, and may not be able to generalize well from them in order to understand and fix the most impactful bugs. In this section, we address the problem of generaliz- ing local adversaries into Semantically Equivalent</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What color is the tray? Pink</head><p>What colour is the tray? Green Which color is the tray? Green What color is it? Green How color is tray? Green <ref type="figure">Figure 3</ref>: Visual QA Adversaries: Paraphrasing questions to find adversaries for the original ques- tion (top, in bold) asked of a given image. Adver- saries are sorted by decreasing semantic similarity.</p><p>Adversarial Rules for Text (SEARs), search and re- place rules that produce semantic adversaries with little or no change in semantics, when applied to a corpus of sentences. Assuming that humans have limited time, and are thus willing to look at B rules, we propose a method for selecting such a set of rules given a reference dataset X. A rule takes the form r = (a→c), where the first instance of the antecedent a is replaced by the consequent c for every instance that includes a, as we previously illustrated in <ref type="figure">Figure 2a</ref>. The output after applying rule r on a sentence x is represented as the function call r(x), e.g. if r =(movie→film), r("Great movie!") = "Great film!".</p><p>Proposing a set of rules: In order to generalize a SEA x into a candidate rule, we must represent the changes that took place from x → x . We will use x = "What color is it?" and x = "Which color is it?" from <ref type="figure">Figure 4</ref> as a running example.</p><p>One approach is exact matching: selecting the minimal contiguous sequence that turns x into x , (What→Which) in the example. Such changes may not always be semantics preserving, so we also propose further rules by including the immediate context (previous and/or next word with respect to the sequence), e.g. (What color→Which color). Adding such context, however, may make rules very specific, thus restricting their value. To al- low for generalization, we also represent the an- tecedent of proposed rules by a product of their raw text with coarse and fine-grained Part-of-Speech tags, and allow these tags to happen in the con- sequent if they match the antecedent. In the running example, we would propose rules like (What color→Which color), (What NOUN →Which NOUN ), (WP color→Which color), etc.</p><p>We generate SEAs and propose rules for every x ∈ X, which gives us a set of candidate rules (second box in <ref type="figure">Figure 4</ref>, for loop in Algorithm 1). <ref type="figure">Figure 4</ref>: SEAR process. (1) SEAs are generalized into candidate rules, (2) rules that are not semantically equivalent are filtered out, e.g. r5: (What→Which), (3) rules are selected according to <ref type="bibr">Eq (3)</ref>, in order to maximize coverage and avoid redundancy (e.g. rejecting r2, valuing r1 more highly than r4), and (4) a user vets selected rules and keeps the ones that they think are bugs.</p><p>Selecting a set of rules: Given a set of candidate rules, we want to select a set R such that |R| ≤ B, and the following properties are met:</p><p>1. Semantic Equivalence: Application of the rules in the set should produce semantically equiv- alent instances. This is equivalent to considering rules that have a high probability of inducing se- mantically equivalent instances when applied, i.e. E[SemEq(x, r(x))] ≥ 1 − δ. This is the Filter step in Algorithm 1. For example, consider the rule (What→Which) in <ref type="figure">Fig 4</ref> which produces some se- mantically equivalent instances, but also produces many instances that are unnatural (e.g. "What is he doing?" → "Which is he doing?"), and is thus filtered out by this criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">High adversary count:</head><p>The rules in the set should induce as many SEAs as possible in valida- tion data. Furthermore, each of the induced SEAs should have as high of a semantic similarity score as possible, i.e. for each rule r ∈ R we want to maximize x∈X S(x, r(x))SEA(x, r(x)). In <ref type="figure">Fig- ure 4</ref>, r1 induces more and more similar mistakes when compared to r4, and is thus superior to r4.</p><p>3. Non-redundancy: Different rules in the set may induce the same SEAs, or may induce different SEAs for the same instances. Ideally, rules in the set should cover as many instances in the validation as possible, rather than focus on a small set of fragile predictions. Furthermore, rules should not be repetitive to the user. In <ref type="figure">Figure 4</ref> (mid), r1 covers a superset of r2's adversaries, making r2 completely redundant and thus not included in R.</p><p>Properties 2 and 3 combined suggest a weighted coverage problem, where a rule r covers an in- stance x if SEA(x, r(x)), the weight of the connec- tion being given by S(x, r(x)). We thus want to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Generating SEARs for a model</head><formula xml:id="formula_3">Require: Classifier f , Correct instances X Require: Hyperparameters, δ, τ , Budget B R ← {}{Set of rules} for all x ∈ X do X = GenParaphrases(X, τ ) A ← {x ∈ X | f (x) = f (x )} {SEAs; §2} R ← R ∪ Rules(A) end for R ← Filter(R, δ, τ ) {Remove low scoring SEARs} R ← SubMod(R, B) {high count / score, diverse } return R</formula><p>find the set of semantically equivalent rules that:</p><formula xml:id="formula_4">max R,|R|&lt;B x∈X max r∈R S(x, r(x))SEA(x, r(x)) (3)</formula><p>While Eq (3) is NP-hard, the objective is monotone submodular ( <ref type="bibr" target="#b9">Krause and Golovin, 2014</ref>), and thus a greedy algorithm that iteratively adds the rule with the highest marginal gain offers a constant- factor approximation guarantee of 1 − 1/e to the optimum. This is the SubMod procedure in Algo- rithm 1, represented pictorially in <ref type="figure">Figure 4</ref>, where the output is a set of rules given to a human, who judges if they are really bugs or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Illustrative Examples</head><p>Before evaluating the utility of SEAs and SEARs with user studies, we show examples in state-of-the- art models for different tasks. Note that we treat these models as black boxes, not using internals or gradients in any way when discovering these bugs.</p><p>Machine Comprehension: We take the Al- lenNLP ( <ref type="bibr" target="#b2">Gardner et al., 2017</ref>  <ref type="table">Table 2</ref>: SEARs for Visual QA we display two example questions with the corre- sponding SEA, the prediction (with corresponding change) and the percentage of "flips" -instances previously predicted correctly on the validation data, but predicted incorrectly after the application of the rule. The rule (What VBZ→What's) general- izes the SEA on <ref type="figure" target="#fig_1">Figure 1</ref>, and shows that the model is fragile with respect to contractions (flips 2% of all correctly predicted instances on the validation data). The second rule uncovers a bug with respect to simple question rephrasing, while the third and fourth rules show that the model is not robust to a more conversational style of asking questions.</p><p>Visual QA: We show SEARs for a state-of-the- art visual question-answering model ( <ref type="bibr" target="#b26">Zhu et al., 2016</ref>) in <ref type="table">Table 2</ref>. Even though the contexts are different (paragraphs for machine comprehension, images for VQA), it is interesting that both models display similar bugs. The fact that VQA is fragile to "Which" questions is because questions of this form are not in the training set, while (color→colour) probably stems from an American bias in data col- lection. Changes induced by these four rules flip more than 10% of the predictions in the validation data, which is of critical concern if the model is being evaluated for production.   <ref type="table" target="#tab_2">Table 3</ref> we dis- play SEARs for a fastText ( <ref type="bibr" target="#b5">Joulin et al., 2016)</ref> model for sentiment analysis trained on movie re- views. Surprisingly, many of its predictions change for perturbations that have no sentiment connota- tions, even in the presence of polarity-laden words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEAR</head><note type="other">Reviews / SEAs f (x) Flips movie → Yeah,</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">User Studies</head><p>We compare automatically discovered SEAs and SEARs to user-generated adversaries and rules, and propose a way to fix the bugs induced by SEARs. Our evaluation benchmark includes two tasks: visual question answering (VQA) and sentiment analysis on movie review sentences. We choose these tasks because a human can quickly look at a prediction and judge if it is correct or incorrect, can easily perturb instances, and judge if two instances in a pair are semantically equivalent or not. Since our focus is debugging, throughout the experiment we only considered SEAs and SEARs on examples that are originally predicted correctly (i.e. every adversary is also by construction a mistake). The user interfaces for all experiments in this section are included in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation Details</head><p>The paraphrasing model ( <ref type="bibr" target="#b11">Lapata et al., 2017</ref>) re- quires translation models to and from different languages. We train neural machine translation models using the default parameters of OpenNMT- py ( <ref type="bibr" target="#b6">Klein et al., 2017</ref>) for English↔Portuguese and English↔French models, on 2 million and 1 million parallel sentences (respectively) from Eu- roParl, news, and other sources <ref type="bibr" target="#b22">(Tiedemann, 2012)</ref>.</p><p>We use the spacy library (http://spacy.io) for POS tagging. For SEAR generation, we set δ = 0.1 (i.e. at least 90% equivalence). We gener- ate a set of candidate adversaries as described in Section 2, and ask mechanical turkers to judge them   <ref type="table">Table 4</ref>: Finding Semantically Equivalent Ad- versaries: we compare how often humans produce semantics-preserving adversaries, when compared to our automatically generated adversaries (SEA, left) and our adversaries filtered by humans (HSEA, right). There are four possible outcomes: neither produces a semantic equivalent adversary (i.e. they either do not produce an adversary or the adversary produced is not semantically equivalent), both do, or only one is able to do so.</p><p>for semantic equivalence. Using these evaluations, we identify τ = 0.0008 as the value that minimizes the entropy in the induced splits, and use it for the remaining experiments. Source code and pre- trained language models are available at https: //github.com/marcotcr/sears. For VQA, we use the multiple choice telling system and dataset of <ref type="bibr" target="#b26">Zhu et al. (2016)</ref>, using their implementation, with default parameters. The training data consists of questions that begin with "What", "Where", "When", "Who", "Why", and "How". The task is multiple choice, with four pos- sible answers per instance. For sentiment analy- sis, we train a fastText ( <ref type="bibr" target="#b5">Joulin et al., 2016</ref>) model with unigrams and bigrams (embedding size of 50) on RottenTomato movie reviews (Pang and <ref type="bibr" target="#b15">Lee, 2005)</ref>, and evaluate it on IMDB sentence-sized reviews ( <ref type="bibr" target="#b8">Kotzias et al., 2015)</ref>, simulating the com- mon case where a model trained on a public dataset is applied to new data from a similar domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Can humans find good adversaries?</head><p>In this experiment, we compare our method for generating SEAs with user's ability to discover semantic-preserving adversaries. We take a ran- dom sample of 100 correctly-predicted instances for each task. In the first condition (human), we display each instance to 3 Amazon Mechanical Turk workers, and give them 10 attempts at creating semantically equivalent adversaries (with immedi- ate feedback as to whether or not their attempts changed the prediction). Next, we ask them to choose the adversary that is semantically closest to the original instance, out of the candidates they generated. In the second condition (SEA), we gen- erate adversaries for each of the instances, and pick the best adversary according to the semantic scorer. The third condition (HSEA) is a collaboration be- tween our method and humans: we take the top 5 adversaries ranked by S(x, x ), and ask workers to pick the one closest to the original instance, rather than asking them to generate the adversaries.</p><p>To evaluate whether the proposed adversaries are semantically equivalent, we ask a separate set of workers to evaluate the similarity between each adversary and the original instance (with the image as context for VQA), on a scale of 1 (completely unrelated) to 5 (exactly the same meaning). Each adversary is evaluated by at least 10 workers, and considered equivalent if the median score ≥ 4. We thus obtain 300 comparisons between human and SEA, and 300 between human and HSEA.</p><p>The results in <ref type="table">Table 4a</ref> and 4b are consistent across tasks: both models are susceptible to SEAs for a large fraction of predictions, and our fully au- tomated method is able to produce SEAs as often as humans (left columns). On the other hand, asking humans to choose from generated SEAs (HSEA) yields much better results than asking humans to generate them (right columns), or using the high- est scored SEA. The semantic scorer does make mistakes, so the top adversary is not always seman- tically equivalent, but a good quality SEA is often in the top 5, and is easily identified by users.</p><p>On both datasets, the automated method or hu- mans were able to generate adversaries at the ex- clusion of the other roughly one third of the time, which indicates that they do not generate the same adversaries. Humans generate paraphrases differ- ently than our method: the average character edit distance of our SEAs is 6.2 for VQA and 9.0 for Sentiment, while for humans it is 18.1 and 43.3, re- spectively. This is illustrated by examples in <ref type="table">Table  5 -in Table 5a</ref> we see examples where very com- pact changes generate adversaries (humans were not able to find these changes though). The exam- ples in <ref type="table">Table 5b</ref> indicate that humans can generate adversaries that: (1) make use of the visual context in VQA, which our method does not, and (2) sig-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Original SEA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VQA</head><p>Where are the men? Where are the males? What kind of meat is on the boy's plate?</p><p>What sort of meat is on the boy's plate?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentiment</head><p>They are so easy to love, but even more easy to identify with.</p><p>They're so easy to love, but even more easy to identify with. Photography and directing were on point.</p><p>(b) Human generated adversaries, examples where our approach failed to generate SEAs (Only Human) <ref type="table">Table 5</ref>: Examples of generated adversaries nificantly change the sentence structure, which the translation-based semantic scorer does not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Can experts find high-impact bugs?</head><p>Here we investigate whether experts are able to detect high-impact global bugs, i.e. devise rules that flip many predictions, and compare them to generated SEARs. Instead of AMT workers, we have 26 expert subjects: students, graduates, or pro- fessors who have taken at least a graduate course in machine learning or NLP 1 . The experiment setup is as follows: for each task, subjects are given an interface where they see examples in the validation data, perturb those examples, and get predictions. The interface also allows them to create search and replace rules, with immediate feedback on how many mistakes are induced by their rules. They also see the list of examples where the rules apply, so they can verify semantic equivalence. Subjects are instructed to try to maximize the number of mis- takes induced in the validation data (i.e. maximize "mistake coverage"), but only through semantically equivalent rules. They can try as many rules as they like, and are asked to select the best set of at most 10 rules at the end. This is quite a challeng- ing task for humans (yet another reason to prefer algorithmic approaches), but we are not aware of any existing automated methods. Finally, we in- <ref type="bibr">1</ref> We have an IRB/consent form, and personal information was only collected as needed to compensate subjects  Discovering rules Evaluating SEARs <ref type="figure">Figure 6</ref>: Time for users to create rules (green) and to evaluate SEARs (blue), with standard error bars struct subjects they could finish each task in about 15 minutes (some took longer, some ended earlier), in order to keep the total time reasonable.</p><p>After creating their rules for VQA and sentiment analysis, the subjects evaluate 20 SEARs (one rule at a time) for each task, and accept only semanti- cally equivalent rules. When a subject rejects a rule, we recompute the remaining set according to <ref type="bibr">Eq (3)</ref> in real time. If a subject accepts more than 10 rules, only the first 10 are considered, in order to ensure a fair comparison against the expert-generated rules.</p><p>We compare expert-generated rules with ac- cepted SEARs (each subject's rules are compared to the SEARs they accepted) in terms of the per- centage of the correct predictions that "flip" when the rules are applied. This is what we asked the subjects to maximize, and all the rules were ones deemed to be semantic equivalent by the subjects themselves. We also consider the union of expert- generated rules and accepted SEARs. The results in <ref type="figure" target="#fig_3">Figure 5</ref> show that on both datasets, the filtered SEARs induce a much higher rate of mistakes than the rules the subjects themselves created, with a small increase when the union of both sets is taken. Furthermore, subjects spent less time evaluating  <ref type="table">Table 6</ref>: Fixing bugs using SEARs: Effect of re- training models using SEARs, both on original validation and on sensitivity dataset. Retraining significantly reduces the number of bugs, with sta- tistically insignificant changes to accuracy.</p><p>SEARs than trying to create their own rules <ref type="figure">(Fig- ure 6)</ref>. SEARs for sentiment analysis contain fewer POS tags, and are thus easier to evaluate for seman- tic equivalence than for VQA. Discovering these bugs is hard for humans (even experts) without SEARs: not only do they need to imagine rules that maintain semantic equivalence, they must also discover the model's weak spots. Making good use of POS tags is also a challenge: only 50% of subjects attempt rules with POS tags for VQA, 36% for sentiment analysis.</p><p>Experts accepted 8.69 rules (on average) out of 20 for VQA as semantically equivalent, and 17.32 out of 20 for sentiment analysis. Similar to the previous experiment, errors made by the seman- tic scorer lead to rules that are not semantically equivalent (e.g. <ref type="table">Table 7</ref>). With minimal human intervention, however, SEARs vastly outperform human experts in finding impactful bugs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Fixing bugs using SEARs</head><p>Once such bugs are discovered, it is natural to want to fix them. The global and deterministic nature of SEARs make them actionable, as they represent bugs in a systematic manner. Once impactful bugs are identified, we use a simple data augmentation procedure: applying SEARs to the training data, and retraining the model on the original training augmented with the generated examples.</p><p>We take the rules that are accepted by ≥ 20 sub- jects as accepted bugs, a total of 4 rules (in <ref type="table">Table 2</ref>) for VQA, and 16 rules for sentiment (including ones in <ref type="table" target="#tab_2">Table 3</ref>). We then augment the training data by applying these rules to it, and retrain the models. To check if the bugs are still present, we create a sensitivity dataset by applying these SEARs to instances predicted correctly on the validation. A model not prone to the bugs described by these rules should not change any of its predictions, and should thus have error rate 0% on this sensitivity data. We also measure accuracy on the original validation data, to make sure that our bug-fixing procedure is not decreasing accuracy. <ref type="table">Table 6</ref> shows that the incidence of these errors is greatly reduced after augmentation, with negli- gible changes to the validation accuracy (on both tasks, the changes are consistent with the effect of retraining with different seeds). These results show that SEARs are useful not only for discover- ing bugs, but are also actionable through a simple augmentation technique for any model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Previous work on debugging primarily focuses on explaining predictions in validation data in order to uncover bugs ( <ref type="bibr" target="#b18">Ribeiro et al., 2016</ref><ref type="bibr" target="#b19">Ribeiro et al., , 2018</ref><ref type="bibr" target="#b10">Kulesza et al., 2011</ref>), or find labeling errors ( <ref type="bibr" target="#b24">Zhang et al., 2018;</ref><ref type="bibr" target="#b7">Koh and Liang, 2017)</ref>. Our work is com- plementary to these techniques, as they provide no mechanism to detect oversensitivity bugs. We are able to uncover these bugs even when they are not present in the data, since we generate sentences.</p><p>Adversarial examples for image recognition are typically indistinguishable to the human eye ( <ref type="bibr" target="#b21">Szegedy et al., 2014</ref>). These are more of a security concern than bugs per se, as images with adversarial noise are not "natural", and not expected to occur in the real world outside of tar- geted attacks. Adversaries are usually specific to predictions, and even universal adversarial pertur- bations <ref type="bibr" target="#b14">(Moosavi-Dezfooli et al., 2017)</ref> are not natural, semantically meaningful to humans, or ac- tionable. "Imperceptible" adversarial noise does not carry over from images to text, as adding or changing a single word in a sentence can drastically alter its meaning. <ref type="bibr" target="#b4">Jia and Liang (2017)</ref> recognize that a true analog to detect oversensitivity would need semantic-preserving perturbations, but do not pursue an automated solution due to the difficulty of paraphrase generation. Their adversaries are whole sentence concatenations, generated by man- ually defined rules tailored to reading comprehen- sion, and each adversary is specific to an individual instance. <ref type="bibr" target="#b25">Zhao et al. (2018)</ref> generate natural text adversaries by projecting the input data to a la- tent space using a generative adversarial networks (GANs), and searching for adversaries close to the original instance in this latent space. Apart from the challenge of training GANs to generate high quality text, there is no guarantee that an example close in the latent space is semantically equiva- lent. <ref type="bibr" target="#b1">Ebrahimi et al. (2018)</ref>, along with propos- ing character-level changes that are not semantic- preserving, also propose a heuristic that replaces single words adversarially to preserve semantics. This approach not only depends on having white- box access to the model, but is also not able to generate many adversaries (only ∼ 1.6% for sen- timent analysis, compare to ∼ 33% for SEAs in <ref type="table">Table 4b</ref>). Developed concurrently with our work, <ref type="bibr" target="#b3">Iyyer et al. (2018)</ref> proposes a neural paraphrase model based on back-translated data, which is able to produce paraphrases that have different sentence structures from the original. They use paraphrases to generate adversaries and try to post-process non- sensical outputs, but they do not explicitly reject non-semantics preserving ones, nor do they try to induce rules from individual adversaries. In any case, their adversaries are also useful for data aug- mentation, in experiments similar to ours.</p><p>In summary, previous work on text adversaries change semantics, only generate local (instance- specific) adversaries ( <ref type="bibr" target="#b25">Zhao et al., 2018;</ref><ref type="bibr" target="#b3">Iyyer et al., 2018)</ref>, or are tailored for white-box mod- els ( <ref type="bibr" target="#b1">Ebrahimi et al., 2018)</ref> or specific tasks <ref type="bibr" target="#b4">(Jia and Liang, 2017)</ref>. In contrast, SEAs expose oversensi- tivity for specific predictions of black-box models for a variety of tasks, while SEARs are intuitive and actionable global rules that induce a high num- ber of high-quality adversaries. To our knowledge, we are also the first to evaluate human performance in adversarial generation (semantics-preserving or otherwise), and our extensive evaluation shows that SEAs and SEARs detect individual bugs and gen- eral patterns better than humans can.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Limitations and Future Work</head><p>Having demonstrated the usefulness of SEAs and SEARs in a variety of domains, we now describe their limitations and opportunities for future work.</p><p>Semantic scoring errors: Paraphrasing is still an active area of research, and thus our semantic scorer is sometimes incorrect in evaluating rules for semantic equivalence. We show examples of SEARs that are rejected by users in <ref type="table">Table 7</ref> -the se- mantic scorer does not sufficiently penalize preposi- tion changes, and is biased towards common terms. The presence of such errors is why we still need humans in the loop to accept or reject SEARs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SEAR</head><p>Questions / SEAs f (x) on →in What is on in the background? A building Mountains What is on? in Lights The television</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VBP→is</head><p>Where are is the water bottles  <ref type="table">Table 7</ref>: SEARs for VQA that are rejected by users</p><p>Other paraphrase limitations: Paraphrase models based on neural machine translation are biased towards maintaining the sentence structure, and thus do not produce certain adversaries (e.g. <ref type="table">Table 5b</ref>), which recent work on para- phrasing ( <ref type="bibr" target="#b3">Iyyer et al., 2018)</ref> or generation using GANs ( <ref type="bibr" target="#b25">Zhao et al., 2018</ref>) may address. More critically, existing models are inaccurate for long texts, restricting SEAs and SEARs to sentences.</p><p>Better bug fixing: Our data augmentation has the human users accept/reject rules based on whether or not they preserve semantics. Develop- ing more effective ways of leveraging the expert's time to close the loop, and facilitating more inter- active collaboration between humans and SEARs are exciting areas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We introduced SEAs and SEARs -adversarial ex- amples and rules that preserve semantics, while causing models to make mistakes. We presented examples of such bugs discovered in state-of-the- art models for various tasks, and demonstrated via user studies that non-experts and experts alike are much better at detecting local and global bugs in NLP models by using our methods. We also close the loop by proposing a simple data augmentation solution that greatly reduced oversensitivity while maintaining accuracy. We demonstrated that SEAs and SEARs can be an invaluable tool for debug- ging NLP models, while indicating their current limitations and avenues for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>In the United States especially, several high-profile cases such as Debra LaFave, Pamela Rogers, and Mary Kay Letourneau have caused increased scrutiny on teacher misconduct. (a) Input Paragraph Q: What has been the result of this publicity? A: increased scrutiny on teacher misconduct (b) Original Question and Answer Q: What haL been the result of this publicity? A: teacher misconduct (c) Adversarial Q &amp; A (Ebrahimi et al., 2018) Q: What's been the result of this publicity? A: teacher misconduct (d) Semantically Equivalent Adversary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Adversarial examples for question answering, where the model predicts the correct answer for the question and input paragraph (1a and 1b). It is possible to fool the model by adversarially changing a single character (1c), but at the cost of making the question nonsensical. A Semantically Equivalent Adversary (1d) results in an incorrect answer while preserving semantics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Human</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Mistakes induced by expert-generated rules (green), SEARs (blue), and a combination of both (pink), with standard error bars.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>SEARs for Sentiment Analysis 

Sentiment Analysis: Finally, in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>vs SEA Human vs HSEA</head><label></label><figDesc></figDesc><table>Neither 
145 (48%) 
127 (42%) 
Only Human 
47 (16%) 
38 (13%) 
Only SEA 
54 (18%) 
72 (24%) 
Both 
54 (18%) 
63 (21%) 

(a) Visual Question-Answering 

Human vs SEA Human vs HSEA 

Neither 
177 (59%) 
161 (54%) 
Only Human 
45 (15%) 
40 (13%) 
Only SEA 
47 (16%) 
63 (21%) 
Both 
31 (10%) 
36 (12%) 

(b) Sentiment Analysis 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Today the graphics are crap. Today, graphics are bullshit.</head><label>Today</label><figDesc></figDesc><table>(a) Automatically generated adversaries, examples where hu-
mans failed to generate SEAs (Only SEA) 

Dataset 
Original 
Human-generated SEA 

VQA 
How many suitcases? 
How many suitcases are sit-
ting on the shelf? 
Where is the blue van? 
What is the blue van's loca-
tion? 

Sentiment 
(very serious spoilers) this 
movie was a huge disap-
pointment. 

serious spoilers this movie 
did not deliver what I hoped 

Also great directing and 
photography. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table Vending Maching Where are is the people gathered living room kitchen</head><label>Vending</label><figDesc></figDesc><table>VERB on 
→ 
What is on the background? 
A building Mountains 

VERB 
What are the planes parked on? Concrete landing strip 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Dan Weld, Robert L. Logan IV, and to the anonymous reviewers for their feedback. This work was supported in part by ONR award #N00014-13-1-0023, in part by NSF award #IIS-1756023, and in part by funding from FICO. The views expressed are of the authors and do not reflect the policy or opinion of the funding agencies.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards transparent systems: Semantic characterization of failure modes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">HotFlip: White-Box Adversarial Examples for NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javid</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anyi</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deijing</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adversarial example generation with syntactically controlled paraphrase networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Opennmt: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Understanding black-box predictions via influence functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From group to individual labels using deep features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Kotzias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Submodular function maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Golovin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tractability: Practical Approaches to Hard Problems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Whyoriented end-user debugging of naive bayes text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Stumpf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weng-Keen</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">M</forename><surname>Burnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Jensen</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Oberst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TiiS</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Paraphrasing revisited with neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Mallinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Chapter of the ACL (EACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Understanding neural networks through representation erasure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>CoRR abs/1612.08220</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Universal adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alhussein</forename><surname>Seyed-Mohsen Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Investigating statistical machine learning as a tool for software development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kayur</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fogarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">A</forename><surname>Landay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beverly</forename><surname>Harrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Anchors: High-precision modelagnostic explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Marco Tulio Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in opus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Language Resources and Evaluation (LREC)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Revisiting recurrent networks for paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Training set debugging using trusted items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating natural adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Visual7W: Grounded Question Answering in Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Feifei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
