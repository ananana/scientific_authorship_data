<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Annotating Relation Inference in Context via Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Ilan University Ramat-Gan</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Ilan University Ramat-Gan</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Annotating Relation Inference in Context via Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="249" to="255"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new annotation method for collecting data on relation inference in context. We convert the inference task to one of simple factoid question answering, allowing us to easily scale up to 16,000 high-quality examples. Our method corrects a major bias in previous evaluations, making our dataset much more realistic.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recognizing entailment between natural-language relations (predicates) is a key challenge in many semantic tasks. For instance, in question answer- ing (QA), it is often necessary to "bridge the lex- ical chasm" between the asker's choice of words and those that appear in the answer text. Relation inference can be notoriously difficult to automat- ically recognize because of semantic phenomena such as polysemy and metaphor: Q: Which drug treats headaches?</p><p>A: Aspirin eliminates headaches.</p><p>In this context, "eliminates" implies "treats" and the answer is indeed "aspirin". However, this rule does not always hold for other cases -"eliminates patients" has a very different meaning from "treats patients". Hence, context-sensitive methods are required to solve relation inference.</p><p>Many methods have tried to address relation inference, from DIRT ( <ref type="bibr" target="#b20">Lin and Pantel, 2001</ref>) through Sherlock ( <ref type="bibr" target="#b27">Schoenmackers et al., 2010)</ref> to the more recent work on PPDB ( <ref type="bibr" target="#b25">Pavlick et al., 2015b</ref>) and RELLY ( <ref type="bibr" target="#b12">Grycner et al., 2015)</ref>. How- ever, the way these methods are evaluated remains largely inconsistent. Some papers that deal with phrasal inference in general ( <ref type="bibr" target="#b2">Beltagy et al., 2013;</ref><ref type="bibr">Pavlick et al., 2015a;</ref><ref type="bibr" target="#b14">Kruszewski et al., 2015)</ref> use an extrinsic task, such as a recent recognizing tex- tual entailment (RTE) benchmark <ref type="bibr" target="#b21">(Marelli et al., 2014)</ref>. By nature, extrinsic tasks incorporate a va- riety of linguistic phenomena, making it harder to analyze the specific issues of relation inference.</p><p>The vast majority of papers that do focus on re- lation inference perform some form of post-hoc evaluation ( <ref type="bibr" target="#b20">Lin and Pantel, 2001;</ref><ref type="bibr" target="#b28">Szpektor et al., 2007;</ref><ref type="bibr" target="#b27">Schoenmackers et al., 2010;</ref><ref type="bibr" target="#b31">Weisman et al., 2012;</ref><ref type="bibr" target="#b18">Lewis and Steedman, 2013;</ref><ref type="bibr" target="#b26">Riedel et al., 2013;</ref><ref type="bibr">Rocktäschel et al., 2015;</ref><ref type="bibr" target="#b11">Grycner and Weikum, 2014;</ref><ref type="bibr" target="#b12">Grycner et al., 2015;</ref><ref type="bibr" target="#b25">Pavlick et al., 2015b</ref>). Typically, the proposed algorithm gen- erates several inference rules between two rela- tion templates, which are then evaluated manu- ally. Some studies evaluate the rules out of con- text (is the rule "X eliminates Y "→"X treats Y " true?), while others apply them to textual data and evaluate the validity of the rule in context (given "aspirin eliminates headaches", is "aspirin treats headaches" true?). Not only are these post-hoc evaluations oblivious to recall, their "human in the loop" approach makes them expensive and virtu- ally impossible to accurately replicate.</p><p>Hence, there is a real need for pre-annotated datasets for intrinsic evaluation of relation infer- ence in context. <ref type="bibr" target="#b32">Zeichner et al. (2012)</ref> constructed such a dataset by applying DIRT-trained inference rules to sampled texts, and then crowd-annotating whether each original text (premise) entails the text generated from applying the inference rule (hypothesis). However, this process is biased; by using DIRT to generate examples, the dataset is inherently blind to the many cases where relation inference exists, but is not captured by DIRT.</p><p>We present a new dataset for evaluating rela- tion inference in context, which is unbiased to- wards one method or another, and natural to anno- tate. To create this dataset, we design a QA setting where annotators are presented with a single ques- tion and several automatically-retrieved text frag- ments. The annotators' goal is to mark which of the text fragments provide a potential answer to the question (see <ref type="figure" target="#fig_0">Figure 1)</ref>. Since the entities in the text fragments are aligned with those in the question, this process implicitly annotates which relations entail the one in the question. For exam- ple, in <ref type="figure" target="#fig_0">Figure 1</ref>, if "[US PRESIDENT] increased taxes" provides an answer to "Which US president raised taxes?", then "increased" implies "raised" in that context. Because this task is so easy to an- notate, we were able to scale up to 16,371 anno- tated examples (3,147 positive) with 91.3% preci- sion for only $375 via crowdsourcing.</p><p>Finally, we evaluate a collection of existing methods and common practices on our dataset, and observe that even the best combination of methods cannot recall more than 25% of the pos- itive examples without dipping below 80% preci- sion. This places into perspective the huge amount of relevant cases of relation inference inherently ignored by the bias in ( <ref type="bibr" target="#b32">Zeichner et al., 2012)</ref>. Moreover, this result shows that while our anno- tation task is easy for humans, it is difficult for existing algorithms, making it an appealing chal- lenge for future research on relation inference. Our code 1 and data 2 are publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Relation Inference Datasets</head><p>To the best of our knowledge, there are only three pre-annotated datasets for evaluating rela- tion inference in context. <ref type="bibr">3</ref> Each example in these datasets consists of two binary relations, premise and hypothesis, and a label indicat-ing whether the hypothesis is inferred from the premise. These relations are essentially Open IE ( <ref type="bibr" target="#b1">Banko et al., 2007</ref>) assertions, and can be repre- sented as (subject, relation, object) tuples. <ref type="bibr" target="#b3">Berant et al. (2011)</ref> annotated inference between typed relations (" <ref type="bibr">[DRUG]</ref> eliminates <ref type="bibr">[SYMPTOM]</ref>"→" <ref type="bibr">[DRUG]</ref> treats [SYMP- TOM]"), restricting the definition of "context". They also used the non-standard type-system from ( <ref type="bibr" target="#b27">Schoenmackers et al., 2010)</ref>, which limits the dataset's applicability to other corpora.  annotated inference between in- stantiated relations sharing at least one argument ("aspirin eliminates headaches"→"drugs treat headaches"). While this format captures a more natural notion of context, it also conflates the task of relation inference with that of entity inference ("aspirin"→"drug"). Both datasets were annotated by experts.</p><p>Zeichner et al. <ref type="formula">(2012)</ref> annotated inference be- tween instantiated relations sharing both argu- ments:</p><p>aspirin eliminates headaches → aspirin treats headaches aspirin eliminates headaches aspirin murders headaches This format provides a broad definition of context on one hand, while isolating the task of relation inference. In addition, methods that can be evalu- ated on this type of data, can also be directly em- bedded into downstream applications, motivating subsequent work to use it as a benchmark <ref type="bibr" target="#b23">(Melamud et al., 2013;</ref><ref type="bibr" target="#b0">Abend et al., 2014;</ref><ref type="bibr" target="#b19">Lewis, 2014)</ref>. We therefore create our own dataset in this format.</p><p>The main drawback of Zeichner et al.'s process is that it is biased towards a specific relation infer- ence method, DIRT <ref type="bibr" target="#b20">(Lin and Pantel, 2001</ref>). Essen- tially, Zeichner et al. conducted a post-hoc eval- uation of DIRT and recorded the results. While their approach does not suffer from the major dis- advantages of post-hoc evaluation -cost and ir- replicability -it ignores instances that do not be- have according to DIRT's assumptions. These in- visible examples amount to an enormous chunk of the inference performed when answering ques- tions, which are covered by our approach (see §4).</p><p>ner; (2) to allow for cheap, consistent, and scalable annotations based on an intuitive QA setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Methodology Overview</head><p>We start by collecting factoid questions. Each question is captured as a tuple q = (q type , q rel , q arg ), for example:</p><formula xml:id="formula_0">Which qtype food q rel is included in qarg chocolate ?</formula><p>In addition to "Which?" questions, this template captures other WH-questions such as "Who?" (q type = person).</p><p>We then collect a set of candidate answers for each question q. A candidate answer is also represented as a tuple (a answer , a rel , a arg ) or (a arg , a rel , a answer ), for example:</p><formula xml:id="formula_1">aarg chocolate a rel</formula><p>is made from aanswer the cocoa bean We collect answer candidates according to the following criteria:</p><p>1. a arg = q arg 2. a answer is a type of q type 3. a rel = q rel These criteria isolate the task of relation inference from additional inference tasks, because they en- sure that a's arguments are entailing q's. In addi- tion, the first two criteria ensure that enough can- didate answers actually answer the question, while the third discards trivial cases. In contrast to <ref type="bibr" target="#b32">(Zeichner et al., 2012</ref>) and post-hoc evaluations, these criteria do not impose any bias on the relation pair a rel , q rel . Furthermore, we show in §3.2 that both a and q are both independent naturally-occurring texts, and are not machine-generated by applying a specific set of inference rules.</p><p>For each (a, q) pair, Mechanical Turk annota- tors are asked whether a provides an answer to q. This natural approach also enables batch annota- tion; for each question, several candidate answers can be presented at once without shifting the anno- tator's focus. To make sure that the annotators do not use their world knowledge about a answer , we mask it during the annotation phase and replace it with q type (see <ref type="figure" target="#fig_0">Figure 1 and  §3.3)</ref>.</p><p>Finally, we instantiate q type with a answer , so that each (a, q) pair fits Zeichner's format: instan- tiated predicates sharing both arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Collection</head><p>We automatically collected 30,703 pairs of ques- tions and candidate answers for annotation. Our process is largely inspired by <ref type="bibr" target="#b8">(Fader et al., 2014</ref>).</p><p>Questions We collected 573 questions by manu- ally converting questions from TREC <ref type="bibr" target="#b30">(Voorhees and Tice, 2000</ref>), <ref type="bibr">WikiAnswers (Fader et al., 2013</ref>), <ref type="bibr">WebQuestions (Berant et al., 2013</ref>), to our "Which q type q rel q arg ?" format. Though many questions did fit our format, a large portion of them were about sports and celebrities, which were not appli- cable to our choice of corpus (Google books) and taxonomy (WordNet). <ref type="bibr">4</ref> Corpus QA requires some body of knowledge from which to retrieve candidate answers. We follow <ref type="bibr" target="#b7">Fader et al. (2013;</ref>, and use a col- lection of Open IE-style assertions ( <ref type="bibr" target="#b1">Banko et al., 2007)</ref> as our knowledge base. Specifically, we used hand-crafted syntactic rules 5 to extract over 63 million unique subject-relation-object triplets from Google's Syntactic N-grams <ref type="bibr" target="#b10">(Goldberg and Orwant, 2013</ref>). The assertions may include multi- word phrases as relations or arguments, as illus- trated earlier. This process yields some ungram- matical or out-of-context assertions, which are later filtered during annotation (see §3.3).</p><p>Answer Candidates In §3.1 we defined three cri- teria for matching an answer candidate to a ques- tion, which we now translate into a retrieval pro- cess. We begin by retrieving all assertions where one of the arguments (subject or object) is equal to q arg , ignoring stopwords and inflections. The matching argument is named a arg , while the other (non-matching) argument becomes a answer .</p><p>To implement the second criterion (a answer is a type of q type ) we require a taxonomy T , as well as a word-sense disambiguation (WSD) al- gorithm to match natural-language terms to enti- ties in T . In this work, we employ WordNet's hy- pernymy graph <ref type="bibr">(Fellbaum, 1998) as T and</ref><ref type="bibr" target="#b15">Lesk (Lesk, 1986)</ref> for WSD (both via NLTK ( <ref type="bibr" target="#b6">Bird et al., 2009)</ref>). While automatic WSD is prone to some errors, these cases are usually annotated as non- sensical in the final phase.</p><p>Lastly, we remove instances where a rel = q rel . 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Crowdsourced Annotation</head><p>Masking Answers We noticed that exposing a answer to the annotator may skew the annota- tion; rather than annotating whether a rel implies q rel in the given context, the annotator might an- notate whether a answer answers q according to her general knowledge. For example:</p><p>Q: Which country borders Ethiopia?</p><p>A: Eritrea invaded Ethiopia.</p><p>An annotator might be misled by knowing in ad- vance that Eritrea borders Ethiopia. Although an invasion typically requires land access, it does not imply a shared border, even in this context; "Italy invaded Ethiopia" also appears in our corpus, but it is not true that "Italy borders Ethiopia". Effectively, what the annotator might be doing in this case is substituting q type ("country") with a answer ("Eritrea") and asking herself if the as- sertion (a answer , q rel , q arg ) is true ("Does Eritrea border Ethiopia?"). As demonstrated, this ques- tion may have a different answer from the infer- ence question in which we are interested ("If a country invaded Ethiopia, does that country bor- der Ethiopia?"). We therefore mask a answer dur- ing annotation by replacing it with q type as a place- holder:</p><formula xml:id="formula_2">A: [COUNTRY] invaded Ethiopia.</formula><p>This forces the annotator to ask herself whether a rel implies q rel in this context, i.e. does invading Ethiopia imply sharing a border with it?</p><p>Labels Each annotator was given a single ques- tion with several matching candidate answers (20 on average), and asked to mark each candidate an- swer with one of three labels:</p><p>The sentence answers the question.</p><p>The sentence does not answer the question.</p><p>? The sentence does not make sense, or is severely non-grammatical. <ref type="figure" target="#fig_0">Figure 1</ref> shows several annotated examples. The third annotation (?) was useful in weeding out noisy assertions (23% of candidate answers).</p><p>Aggregation Overall, we created 1,500 question- naires, 7 spanning a total of 30,703 (a, q) pairs. Each questionnaire was annotated by 5 differ- 7 Each of our 573 questions had many candidate answers. These were split into smaller chunks (questionnaires) of less than 25 candidate answers each. ent people, and aggregated using the unanimous- up-to-one (at least 4/5) rule. Examples that did not exhibit this kind of inter-annotator agreement were discarded, and so were examples which were determined as nonsensical/ungrammatical (anno- tated with ?). After aggregating and filtering, we were left with 3,147 positive () and 13,224 neg- ative () examples. <ref type="bibr">8</ref> To evaluate this aggregation rule, we took a ran- dom subset of 32 questionnaires (594 (a, q) pairs) and annotated them ourselves (expert annotation). We then compared the aggregated crowdsourced annotation on the same (a, q) pairs to our own. The crowdsourced annotation yielded 91.3% pre- cision on our expert annotations (i.e. only 8.7% of the crowd-annotated positives were expert- annotated as negative), while recalling 86.2% of expert-annotated positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Performance of Existing Methods</head><p>To provide a baseline for future work, we test the performance of two inference-rule resources and two methods of distributional inference on our dataset, as well as a lemma-similarity baseline. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baselines</head><p>Lemma Baseline We implemented a baseline that takes into account four features from the premise relation (a rel ) and the hypothesis relation (q rel ) af- ter they have been lemmatized: (1) Does a rel con- tain all of q rel 's content words? (2) Do the re- lations share a verb? (3) Does the relations' ac- tive/passive voice match their arguments' align- ments? (4) Do the relations agree on negation? The baseline will classify the example as positive if all features are true. PPDB 2.0 We used the largest collection of paraphrases (XXXL) from PPDB ( <ref type="bibr" target="#b25">Pavlick et al., 2015b</ref>). These paraphrases include argument slots for cases where word order changes (e.g. pas- sive/active).</p><p>Entailment Graph We used the publicly- available inference rules derived from Berant et al.'s (2011) entailment graph. These rules con- tain typed relations and can also be applied in a context-sensitive manner. However, ignoring the types and applying the inference rules out of con- text worked better on our dataset, perhaps because Berant et al.'s taxonomy was learned from a dif- ferent corpus.</p><p>Relation Embeddings Similar to DIRT <ref type="bibr" target="#b20">(Lin and Pantel, 2001</ref>), we create vector representations for relations, which are then used to measure relation similarity. From the set of assertions extracted in §3.2, we create a dataset of relation-argument pairs, and use word2vecf ( <ref type="bibr" target="#b16">Levy and Goldberg, 2014</ref>) to train the embeddings. We also tried to use the arguments' embeddings to induce a context- sensitive measure of similarity, as suggested by <ref type="bibr" target="#b24">Melamud et al. (2015)</ref>; however, this method did not improve performance on our dataset.</p><p>Word Embeddings Using Google's Syntactic N-grams ( <ref type="bibr" target="#b10">Goldberg and Orwant, 2013)</ref>, from which candidate answers were extracted, we trained dependency-based word embeddings with word2vecf ( <ref type="bibr" target="#b16">Levy and Goldberg, 2014)</ref>. We used the average word vector to represent multi-word relations, and cosine to measure their similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Under the assumption that collections of inference rules are more precision-oriented, we also try dif- ferent combinations of rule-based and embedding- based methods by first applying the rules and then calculating the embedding-based similarity only on instances that were not identified as positive by the rules. Since the embeddings produce a similarity score, not a classification, we plot all methods' performance on a single precision-recall curve ( <ref type="figure" target="#fig_1">Figure 2</ref>).</p><p>All methods used the lemma baseline as a first step to identify positive examples; without it, per- formance drops dramatically. This is probably more of a dataset artifact than an observation about the baselines; just like we filtered examples where a rel = q rel , we could have used a more aggressive policy and removed all pairs that share lemmas.</p><p>It seems that most methods provide little value beyond the lemma baseline -the exception being Berant et al.'s (2011) entailment graph. Unify- ing the entailment graph with PPDB (and, implic- itly, the lemma baseline) slightly improves perfor- mance, and provides a significantly better starting point for the method based on word embeddings. Even so, performance is still quite poor in absolute terms, with less than 25% recall at 80% precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The Ramifications of Low Recall</head><p>These results emphasize the huge false-negative rate of existing methods. This suggests that a mas- sive amount of inference examples, which are nec- essary for answering questions, are inherently ig- nored in <ref type="bibr" target="#b32">(Zeichner et al., 2012</ref>) and post-hoc eval- uations. Our dataset remedies this bias, and poses a new challenge for future research on relation in- ference.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A screenshot from our annotation task.</figDesc><graphic url="image-1.png" coords="2,72.01,62.81,218.26,65.47" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The performance of existing methods on our dataset. All methods are run on top of the lemma baseline. All Rules is the union of PPDB and the entailment graph. Rules + W Embs is a combination of All Rules and our word embeddings.</figDesc><graphic url="image-2.png" coords="5,307.28,63.81,218.27,171.08" type="bitmap" /></figure>

			<note place="foot" n="1"> http://bitbucket.org/omerlevy/ relation_inference_via_qa 2 http://u.cs.biu.ac.il/ ˜ nlp/resources/ downloads/relation_inference_via_qa 3 It is worth noting the lexical substitution datasets (McCarthy and Navigli, 2007; Biemann, 2013; Kremer et al., 2014) also capture instances of relation inference. However, they do not focus on relations and are limited to single-word substitutions. Furthermore, the annotators are tasked with generating substitutions, whereas we are interested in judging (classifying) an existing substitution.</note>

			<note place="foot" n="3"> Collection &amp; Annotation Process Our data collection and annotation process is designed to achieve two goals: (1) to efficiently sample premise-hypothesis pairs in an unbiased man</note>

			<note place="foot" n="4"> This is the only part in our process that might introduce some bias. However, this bias is independent of existing relation inference methods such as DIRT. 5 See supplementary material for a detailed description. 6 Several additional filters were applied to prune nongrammatical assertions (see supplementary material).</note>

			<note place="foot" n="8"> This harsh filtering process is mainly a result of poor annotator quality. See supplementary material for a detailed description of the steps we took to improve annotator quality. 9 To recreate the embeddings, see supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the German Research Foundation via the German-Israeli Project Coop-eration (grant DA 1600/1-1), the Israel Science Foundation grant 880/12, and by grants from the MAGNET program of the Israeli Office of the Chief Scientist (OCS).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lexical inference over multi-word predicates: A distributional approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="644" to="654" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Banko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI 2007, Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting><address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-01-06" />
			<biblScope unit="page" from="2670" to="2676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Montague meets markov: Deep semantics with probabilistic logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity</title>
		<meeting>the Main Conference and the Shared Task: Semantic Textual Similarity<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11" to="21" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global learning of typed entailment rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="610" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA,</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Creating a system for lexical substitutions from scratch using crowdsourcing. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="97" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1608" to="1618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1156" to="1165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A dataset of syntactic-ngrams over time from a very large corpus of english books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Orwant2013</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Orwant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity</title>
		<meeting>the Main Conference and the Shared Task: Semantic Textual Similarity<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="241" to="247" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Harpy: Hypernyms and alignment of relational paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Grycner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Grycner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2195" to="2204" />
		</imprint>
		<respStmt>
			<orgName>August. Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relly: Inferring hypernym relationships between relational phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Grycner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="971" to="981" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">What substitutes tell us-analysis of an &quot;all-words&quot; lexical substitution corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kremer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="540" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deriving boolean structures from distributional vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="375" to="388" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Annual International Conference on Systems Documentation</title>
		<meeting>the 5th Annual International Conference on Systems Documentation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="24" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dependency-based word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Focused entailment graphs for open ie propositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="87" to="97" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Combining distributional and logical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steedman2013] Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Combined Distributional and Logical Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dirt: Discovery of inference rules from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pantel2001] Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the seventh ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="323" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A sick cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Marelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<editor>Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard</editor>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis; Reykjavik, Iceland, May</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="14" to="1314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semeval-2007 task 10: English lexical substitution task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navigli2007] Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)</title>
		<meeting>the Fourth International Workshop on Semantic Evaluations (SemEval-2007)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A two level model for context sensitive inference rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Melamud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1331" to="1340" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple word embedding model for lexical substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Melamud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Denver, Colorado; Malvina Nissim, Charley Beller, Benjamin Van Durme, and Chris Callison-Burch; Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="1512" to="1522" />
		</imprint>
	</monogr>
	<note>Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ppdb 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="425" to="430" />
		</imprint>
	</monogr>
	<note>Pavlick et al.2015b. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Injecting logical background knowledge into embeddings for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>Rocktäschel et al.2015] Tim Rocktäschel, Sameer Singh, and Sebastian Riedel</editor>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Atlanta, Georgia; Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="1119" to="1129" />
		</imprint>
	</monogr>
	<note>Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning first-order horn clauses from web text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenmackers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-10" />
			<biblScope unit="page" from="1088" to="1098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Instance-based evaluation of entailment rule acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Idan Szpektor, Eyal Shnarch, and Ido Dagan</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="456" to="463" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tice2000] Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning verb inference rules from linguistically-motivated evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Weisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="194" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Crowdsourcing inference-rule evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zeichner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="156" to="160" />
		</imprint>
	</monogr>
	<note>Naomi Zeichner, Jonathan Berant, and Ido Dagan</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
