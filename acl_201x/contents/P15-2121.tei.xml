<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Constrained Semantic Forests for Improved Discriminative Semantic Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Information Systems Technology and Design</orgName>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Constrained Semantic Forests for Improved Discriminative Semantic Parsing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="737" to="742"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we present a model for improved discriminative semantic parsing. The model addresses an important limitation associated with our previous state-of-the-art discriminative semantic parsing model-the relaxed hybrid tree model by introducing our constrained semantic forests. We show that our model is able to yield new state-of-the-art results on standard datasets even with simpler features. Our system is available for download from http://statnlp.org/research/sp/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper addresses the problem of parsing natu- ral language sentences into their corresponding se- mantic representations in the form of formal logi- cal representations. Such a task is also known as semantic parsing <ref type="bibr" target="#b3">(Kate and Mooney, 2006;</ref><ref type="bibr" target="#b11">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b8">Lu et al., 2008;</ref><ref type="bibr" target="#b4">Kwiatkowski et al., 2010)</ref>.</p><p>One state-of-the-art model for semantic pars- ing is our recently introduced relaxed hybrid tree model <ref type="bibr" target="#b9">(Lu, 2014)</ref>, which performs integrated lexi- con acquisition and semantic parsing within a sin- gle framework utilizing efficient algorithms for training and inference. The model allows natural language phrases to be recursively mapped to se- mantic units, where certain long-distance depen- dencies can be captured. It relies on representa- tions called relaxed hybrid trees that can jointly represent both the sentences and semantics. The model is essentially discriminative, and allows rich features to be incorporated.</p><p>Unfortunately, the relaxed hybrid tree model has an important limitation: it essentially does not allow certain sentence-semantics pairs to be jointly encoded using the proposed relaxed hy- brid tree representations. Thus, the model is un- able to identify joint representations for certain sentence-semantics pairs during the training pro- cess, and is unable to produce desired outputs for certain inputs during the evaluation process. In this work, we propose a solution addressing the above limitation, which makes our model more ro- bust. Through experiments, we demonstrate that our improved discriminative model for semantic parsing, even when simpler features are used, is able to obtain new state-of-the-art results on stan- dard datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Semantic parsing has recently attracted a signif- icant amount of attention in the community. In this section, we provide a relatively brief discus- sion of prior work in semantic parsing. The hy- brid tree model ( <ref type="bibr" target="#b8">Lu et al., 2008</ref>) and the Bayesian tree transducer based model ( <ref type="bibr" target="#b2">Jones et al., 2012)</ref> are generative frameworks, which essentially as- sume natural language and semantics are jointly generated from an underlying generative process. Such models are efficient, but are limited in their predictive power due to the simple independence assumptions made.</p><p>On the other hand, discriminative models are able to exploit arbitrary features and are usually able to give better results. Examples of such mod- els include the WASP system ( <ref type="bibr" target="#b10">Wong and Mooney, 2006</ref>) which regards the semantic parsing prob- lem as a statistical machine translation problem, the UBL system ( <ref type="bibr" target="#b4">Kwiatkowski et al., 2010</ref>) which performs CCG-based semantic parsing using a log-linear model, as well as the relaxed hybrid tree model ( <ref type="bibr" target="#b9">Lu, 2014</ref>) which extends the generative hybrid tree model. This extension results in a dis- criminative model that incorporates rich features and allows long-distance dependencies to be cap- tured. The relaxed hybrid tree model has achieved the state-of-the-art results on standard benchmark datasets across different languages.</p><p>Performing semantic parsing under other forms  (b) ma (w1 w2) w3 w4 w5 w6 w7 w8 w9 (w10) m b (w3 w4 w5) w6 (w7 w8) w9 <ref type="figure" target="#fig_2">Figure 1</ref>: The semantics-sentence pair (a), an example hybrid tree (b), and an example relaxed hybrid tree (c).</p><formula xml:id="formula_0">m d (w9) mc (w6) (c)</formula><p>of supervision is also possible. <ref type="bibr" target="#b0">Clarke et al. (2010)</ref> proposed a model that learns a semantic parser for answering questions without relying on semantic annotations. <ref type="bibr" target="#b1">Goldwasser et al. (2011)</ref> presented a confidence-driven approach to semantic parsing based on self-training. <ref type="bibr" target="#b6">Liang et al. (2013)</ref> in- troduced semantic parsers based on dependency based semantics (DCS) that map sentences into their denotations. In this work, we focus on pars- ing sentences into their formal semantic represen- tations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Relaxed Hybrid Trees</head><p>We briefly discuss our previously proposed re- laxed hybrid tree model ( <ref type="bibr" target="#b9">Lu, 2014</ref>) in this section. The model is a discriminative semantic parsing model which extends the generative hybrid tree model ( <ref type="bibr" target="#b8">Lu et al., 2008)</ref>. Both systems are publicly available <ref type="bibr">1</ref> .</p><p>Let us use m to denote a complete semantic representation, n to denote a complete natural lan- guage sentence, and h to denote a complete latent structure that jointly represents both m and n. The model defines the conditional probability for ob- serving a (m, h) pair for a given natural language sentence n using a log-linear approach:</p><formula xml:id="formula_1">P Λ (m, h|n) = e Λ·Φ(n,m,h) m ,h ∈H(n,m ) e Λ·Φ(n,m ,h ) (1)</formula><p>where Λ is the set of parameters (weights of fea- tures) used by the model.  its corresponding semantic representation. Typi- cally, to limit the space of latent structures, certain assumptions have to be made to h. In our work, we assume that h must be from a space consisting of relaxed hybrid tree structures ( <ref type="bibr" target="#b9">Lu, 2014)</ref>.</p><p>The relaxed hybrid trees are analogous to the hybrid trees, which was earlier introduced as a generative framework. One major distinction be- tween these two types of representations is that the relaxed hybrid tree representations are able to capture unbounded long-distance dependencies in a principled way. Such dependencies were un- able to be captured by hybrid tree representations largely due to their generative settings. <ref type="figure" target="#fig_2">Figure 1</ref> gives an example of a hybrid tree and a relaxed hybrid tree representation encoding the sentence w 1 w 2 w 3 w 4 w 5 w 6 w 7 w 8 w 9 w 10 and the se- mantics m a (m b (m c , m d )).</p><p>In the hybrid tree structure, each word is strictly associated with a semantic unit. For example the word w 3 is associated with the semantic unit m b . In the relaxed hybrid tree, however, each word is not only directly associated with exactly one se- mantic unit m, but also indirectly associated with all other semantic units that are predecessors of m. For example, the word w 3 now is directly associ- ated with m b , but is also indirectly associated with m a . These indirect associations allow the long- distance dependencies to be captured. Both the hybrid tree and relaxed hybrid tree models define patterns at each level of their latent structure which specify how the words and child semantic units are organized at each level. For example, within the semantic unit m a , we have a pattern wXw which states that we first have words that are directly associated with m a , fol- lowed by some words covered by its first child se- mantic unit, then another sequence of words di- rectly associated with m a .</p><formula xml:id="formula_2">m a m b m d m c m a w 1 w 2 . . . m b w 1 w 2 m d (w 2 ) m c (w 1 ) m a m b m d w 2 m c w 1 w 1 w 2 (a) (b) (c)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Limitations</head><p>One important difference between the hybrid tree representations and the relaxed hybrid tree repre- sentations is the exclusion of the pattern X in the latter. This ensured relaxed hybrid trees with an infinite number of nodes were not considered ( <ref type="bibr" target="#b9">Lu, 2014</ref>) when computing the denominator term of Equation 1. In relaxed hybrid tree, H(n, m) was implemented as a packed forest representation for exponentially many possible relaxed hybrid trees where pattern X was excluded.</p><p>By allowing pattern X, we allow certain seman- tic units with no natural language word counter- part to exist in the joint relaxed hybrid tree repre- sentation. This may lead to possible relaxed hy- brid tree representations consisting of an infinite number of internal nodes (semantic units), as seen in <ref type="figure" target="#fig_4">Figure 3 (b)</ref>. When pattern X is allowed, both m a and m b are not directly associated with any natural language word, so we are able to further insert arbitrarily many (compatible) semantic units between the two units m a and m b while the re- sulting relaxed hybrid tree remains valid. There- fore we can construct a relaxed hybrid tree repre- sentation that contains the given natural language sentence w 1 w 2 with an infinite number of nodes. This issue essentially prevents us from comput- ing the denominator term of Equation 1 since it involves an infinite number of possible m and h . To eliminate relaxed hybrid trees consisting of an infinite number of nodes, pattern X is dis- allowed in the relaxed hybrid trees model <ref type="bibr" target="#b9">(Lu, 2014)</ref>. However, disallowing pattern X has led to other issues. Specifically, for certain semantics- sentence pairs, it is not possible to find relaxed hy- brid trees that jointly represent them. In the exam- ple semantics-sentence pair given in <ref type="figure" target="#fig_4">Figure 3</ref> (a), it is not possible to find any relaxed hybrid tree that contains both the sentence and the semantics since each semantic unit which takes one argument must be associated with at least one word. On the other hand, it is still possible to find a hybrid tree repre- sentation for both the sentence and the semantics where pattern X is allowed (see <ref type="figure" target="#fig_4">Figure 3 (c)</ref>).</p><formula xml:id="formula_3">#Args Patterns 0 w 1 [w]X[w] 2 [w]X[w]Y[w], [w]Y[w]X[w]</formula><p>In practice, we can alleviate this issue by ex- tending the lengths of the sentences. For example, we can append the special beginning-of-sentence symbol s and end-of-sentence symbol /s to all sentences to increase their lengths, allowing the relaxed hybrid trees to be constructed for cer- tain sentence-semantics pairs with short sentences. However, such an approach does not resolve the theoretical limitation of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Constrained Semantic Forests</head><p>To address this limitation, we allow pattern X to be included when building our new discrimina- tive semantic parsing model. However, as men- tioned above, doing so will lead to latent struc- tures (relaxed hybrid tree representations) of infi- nite heights. To resolve such an issue, we instead add an additional constraint -limiting the height of a semantic representation to a fixed constant c, where c is larger than the maximum height of all the trees appearing in the training set. <ref type="table" target="#tab_0">Table 1</ref> summarizes the list of patterns that our model considers. This is essentially the same as those considered by the hybrid tree model.</p><p>Our new objective function is as follows:</p><formula xml:id="formula_4">P Λ (m, h|n) = e Λ·Φ(n,m,h) m ∈M,h ∈H (n,m ) e Λ·Φ(n,m ,h ) (2)</formula><p>where M refers to the set of all possible seman- tic trees whose heights are less than or equal to c, and H (n, m ) refers to the set of possible relaxed hybrid tree representations where the pattern X is allowed.</p><p>The main challenge now becomes the compu- tation of the denominator term in Equation 2, as the set M is still very large. To properly handle all such semantic trees in an efficient way, we in- troduce a constrained semantic forest (CSF) rep- resentation of M here. Such a constrained seman- tic forest is a packed forest representation of ex- ponentially many possible unique semantic trees, where we set the height of the forest to c. By con- trast, it was not possible in our previous relaxed hybrid tree model to introduce such a compact representation over all possible semantic trees. In our previous model's implementation, we directly constructed for each sentence n a different com- pact representation over all possible relaxed hy- brid trees containing n.</p><p>Setting the maximum height to c effectively guarantees that all semantic trees contained in the constrained semantic forest have a height no greater than c. We then constructed the (exponen- tially many) relaxed hybrid tree representations based on the constrained semantic forest M and each input sentence n. We used a single packed forest representation to represent all such relaxed hybrid tree representations. This allows the com- putation of the denominator to be performed ef- ficiently using similar dynamic programming al- gorithms described in <ref type="bibr" target="#b9">(Lu, 2014)</ref>. Optimization of the model parameters were done by using L- BFGS ( <ref type="bibr" target="#b7">Liu and Nocedal, 1989)</ref>, where the gradi- ents were computed efficiently using an analogous dynamic programming algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Our experiments were conducted on the publicly available multilingual GeoQuery dataset. Vari- ous previous works on semantic parsing used this dataset for evaluations <ref type="bibr" target="#b10">(Wong and Mooney, 2006;</ref><ref type="bibr" target="#b3">Kate and Mooney, 2006;</ref><ref type="bibr" target="#b8">Lu et al., 2008;</ref><ref type="bibr" target="#b2">Jones et al., 2012</ref>). The dataset consists of 880 natural language sentences where each sentence is cou- pled with a formal tree-structured semantic repre- sentation. The early version of this dataset was annotated with English only ( <ref type="bibr" target="#b10">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b3">Kate and Mooney, 2006</ref>), and <ref type="bibr" target="#b2">Jones et al. (2012)</ref> released a version that is annotated with three additional languages: German, Greek and Thai. To make our system directly comparable to previous works, we used the same train/test split used in those works ( <ref type="bibr" target="#b2">Jones et al., 2012;</ref><ref type="bibr" target="#b9">Lu, 2014</ref>) for evaluation. We also followed the standard ap- proach for evaluating the correctness of an output semantic representation from our system. Specifi- cally, we used a standard script to construct Prolog queries based on the outputs, and used the queries to retrieve answers from the GeoQuery database. Following previous works, we regarded an out- put semantic representation as correct if and only if it returned the same answers as the gold stan- dard ( <ref type="bibr" target="#b2">Jones et al., 2012;</ref><ref type="bibr" target="#b9">Lu, 2014)</ref>.</p><p>The results of our system as well as those of several previous systems are given in <ref type="table">Table 2</ref>. We compared our system's performance against those of several previous works. The WASP sys- tem ( <ref type="bibr" target="#b10">Wong and Mooney, 2006</ref>) is based on statis- tical machine translation technique while the HY- BRIDTREE+ system ( <ref type="bibr" target="#b8">Lu et al., 2008</ref>) is based on the generative hybrid tree model augmented with a discriminative re-ranking stage where certain global features are used. UBL-S ( <ref type="bibr" target="#b4">Kwiatkowski et al., 2010</ref>) is a CCG-based semantic parsing sys- tem. TREETRANS ( <ref type="bibr" target="#b2">Jones et al., 2012</ref>) is the sys- tem based on tree transducers. RHT <ref type="bibr" target="#b9">(Lu, 2014</ref>) is the discriminative semantic parsing system based on relaxed hybrid trees.</p><p>In practice, we set c (the maximum height of a semantic representation) to 20 in our experi-  <ref type="table">Table 2</ref>: Performance of various works across four different languages. Acc.: accuracy percentage, F:</p><formula xml:id="formula_5">F 1 -measure percentage.</formula><p>ments, which we determined based on the heights of the semantic trees that appear in the training data. Results showed that our system consistently yielded higher results than all the previous sys- tems, including our state-of-the-art relaxed hybrid tree system (the full model, when all the features are used), in terms of both accuracy score and F 1 - measure. We would like to highlight two potential advantages of our new model over the old RHT model. First, our model is able to handle certain sentence-semantics pairs which could not be han- dled by RHT during both training and evaluation as discussed in Section 3.1. Second, our model considers the additional pattern X and therefore has the capability to capture more accurate depen- dencies between the words and semantic units.</p><p>We note that in our experiments we used a small subset of the features used by our relaxed hy- brid tree work. Specifically, we did not use any long-distance features, and also did not use any character-level features. As we have mentioned in <ref type="bibr" target="#b9">(Lu, 2014)</ref>, although the RHT model is able to capture unbounded long-distance dependencies, for certain languages such as German such long- distance features appeared to be detrimental to the performance of the system (Lu, 2014, <ref type="table">Table  4</ref>). Here in this work, we only used simple un- igram features (concatenation of a semantic unit and an individual word that appears directly below that unit in the joint representation), pattern fea- tures (concatenation of a semantic unit and the pat- tern below that unit) as well as transition features (concatenation of two semantic units that form a parent-child relationship) described in <ref type="bibr" target="#b9">(Lu, 2014)</ref>. While additional features could potentially lead to better results, using simpler features would make our model more compact and more interpretable. We summarized in <ref type="table">Table 3</ref> the number of features used in both the previous RHT system and our sys- tem across four different languages. It can be seen that our system only required about 2-3% of the  <ref type="table">Table 3</ref>: Number of features involved for both the RHT system and our new system using con- strained semantic forests, across four different lan- guages.</p><p>features used in the previous system.</p><p>We also note that the training time for our model is longer than that of the relaxed hybrid tree model since the space for H (n, m ) is now much larger than the space for H(n, m ). In practice, to make the overall training process faster, we im- plemented a parallel version of the original RHT algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we presented an improved discrim- inative approach to semantic parsing. Our ap- proach does not have the theoretical limitation associated with our previous state-of-the-art ap- proach. We demonstrated through experiments that our new model was able to yield new state- of-the-art results on a standard dataset across four different languages, even though simpler features were used. Since our new model involves simpler features, including unigram features defined over individual semantic unit -word pairs, we believe our new model would aid the joint modeling of both distributional and logical semantics ( <ref type="bibr" target="#b5">Lewis and Steedman, 2013</ref>) within a single framework. We plan to explore this avenue in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 (</head><label>1</label><figDesc>a) gives an example sentence-semantics pair. A real example taken from the GeoQuery dataset is shown in Fig- ure 2. Note that h is a complete latent structure that jointly represents a natural language sentence and 1 http://statnlp.org/research/sp/ QUERY : answer(RIVER) RIVER : exclude(RIVER, RIVER) RIVER : traverse(STATE) STATE : stateid(STATENAME) STATENAME : ( tn ) RIVER : river(all) What rivers do not run through Tennessee ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example tree-structured semantic representation (above) and its corresponding natural language sentence (below).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a) Example semantics-sentence pair that cannot be jointly represented with relaxed hybrid trees if pattern X is disallowed. (b) Example relaxed hybrid tree that consists of an infinite number of nodes when pattern X is allowed. (c) Example hybrid tree jointly representing both the semantics and the sentence (where pattern X is allowed).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The patterns allowed for our model. [w] 
denotes an optional sequence of natural language 
words. E.g., [w]X[w] refers to the following 4 
patterns: wX, Xw, wXw, and X (the pattern ex-
cluded by the relaxed hybrid tree model). 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknoledgments</head><p>The author would like to thank the anonymous reviewers for their helpful comments. This work was supported by SUTD grant SRG ISTD 2013 064 and was partially supported by project 61472191 under the National Natural Science Foundation of China.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CONLL &apos;10</title>
		<meeting>of CONLL &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Confidence driven unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL &apos;11</title>
		<meeting>of ACL &apos;11</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1486" to="1495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing with bayesian tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keeley</forename><surname>Bevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL &apos;12</title>
		<meeting>of ACL &apos;12</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="488" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using string-kernels for learning semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING/ACL</title>
		<meeting>of COLING/ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inducing probabilistic ccg grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP&apos;10</title>
		<meeting>EMNLP&apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combining distributional and logical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="446" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the limited memory bfgs method for large scale optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="503" to="528" />
			<date type="published" when="1989-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP &apos;08</title>
		<meeting>of EMNLP &apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic parsing with relaxed hybrid trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP &apos;14</title>
		<meeting>of EMNLP &apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT/NAACL &apos;06</title>
		<meeting>of HLT/NAACL &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL &apos;07</title>
		<meeting>of ACL &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
