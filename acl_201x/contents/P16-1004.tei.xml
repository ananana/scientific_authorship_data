<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Language to Logical Form with Neural Attention</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
							<email>li.dong@ed.ac.uk, mlap@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Language to Logical Form with Neural Attention</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="33" to="43"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domain-or representation-specific. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing is the task of translating text to a formal meaning representation such as log- ical forms or structured queries. There has re- cently been a surge of interest in developing ma- chine learning methods for semantic parsing (see the references in Section 2), due in part to the existence of corpora containing utterances anno- tated with formal meaning representations. <ref type="figure" target="#fig_0">Fig- ure 1</ref> shows an example of a question (left hand- side) and its annotated logical form (right hand- side), taken from JOBS ( <ref type="bibr" target="#b38">Tang and Mooney, 2001</ref>), a well-known semantic parsing benchmark. In or- der to predict the correct logical form for a given utterance, most previous systems rely on prede- fined templates and manually designed features, which often render the parsing model domain-or representation-specific. In this work, we aim to use a simple yet effective method to bridge the gap between natural language and logical form with minimal domain knowledge. Encoder-decoder architectures based on recur- rent neural networks have been successfully ap- plied to a variety of NLP tasks ranging from syn- tactic parsing ( , to machine translation ( <ref type="bibr" target="#b16">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b7">Cho et al., 2014;</ref><ref type="bibr" target="#b36">Sutskever et al., 2014</ref>), and image description generation <ref type="bibr">(Karpathy and FeiFei, 2015;</ref><ref type="bibr" target="#b43">Vinyals et al., 2015b</ref>). As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we adapt the general encoder-decoder paradigm to the semantic parsing task. Our model learns from natural language descriptions paired with meaning representations; it encodes sentences and decodes logical forms using recur- rent neural networks with long short-term memory (LSTM) units. We present two model variants, the first one treats semantic parsing as a vanilla sequence transduction task, whereas our second model is equipped with a hierarchical tree decoder which explicitly captures the compositional struc- ture of logical forms. We also introduce an atten- tion mechanism ( <ref type="bibr" target="#b3">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b27">Luong et al., 2015b</ref>) allowing the model to learn soft align- ments between natural language and logical forms and present an argument identification step to han- dle rare mentions of entities and numbers.</p><p>Evaluation results demonstrate that compared to previous methods our model achieves similar or better performance across datasets and meaning representations, despite using no hand-engineered domain-or representation-specific features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>33</head><p>Our work synthesizes two strands of research, namely semantic parsing and the encoder-decoder architecture with neural networks.</p><p>The problem of learning semantic parsers has received significant attention, dating back to <ref type="bibr" target="#b46">Woods (1973)</ref>. Many approaches learn from sen- tences paired with logical forms following vari- ous modeling strategies. Examples include the use of parsing models <ref type="bibr" target="#b29">(Miller et al., 1996;</ref><ref type="bibr" target="#b10">Ge and Mooney, 2005;</ref><ref type="bibr" target="#b25">Lu et al., 2008;</ref><ref type="bibr" target="#b52">Zhao and Huang, 2015)</ref>, inductive logic programming ( <ref type="bibr" target="#b49">Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b37">Tang and Mooney, 2000;</ref><ref type="bibr" target="#b39">Thomspon and Mooney, 2003)</ref>, probabilistic automata ( <ref type="bibr" target="#b13">He and Young, 2006</ref>), string/tree-to-tree transfor- mation rules ( <ref type="bibr" target="#b19">Kate et al., 2005)</ref>, classifiers based on string kernels <ref type="bibr" target="#b18">(Kate and Mooney, 2006</ref>), ma- chine translation <ref type="bibr" target="#b44">(Wong and Mooney, 2006;</ref><ref type="bibr" target="#b45">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b0">Andreas et al., 2013)</ref>, and combinatory categorial grammar induction tech- niques <ref type="bibr" target="#b50">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b51">Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b21">Kwiatkowski et al., 2010;</ref><ref type="bibr" target="#b22">Kwiatkowski et al., 2011</ref>). Other work learns semantic parsers without relying on logical- from annotations, e.g., from sentences paired with conversational logs (Artzi and Zettlemoyer, 2011), system demonstrations ( <ref type="bibr" target="#b6">Chen and Mooney, 2011;</ref><ref type="bibr" target="#b11">Goldwasser and Roth, 2011;</ref>, question-answer pairs <ref type="bibr" target="#b8">(Clarke et al., 2010;</ref><ref type="bibr" target="#b24">Liang et al., 2013)</ref>, and distant supervi- sion ( <ref type="bibr" target="#b20">Krishnamurthy and Mitchell, 2012;</ref><ref type="bibr" target="#b5">Cai and Yates, 2013;</ref><ref type="bibr" target="#b34">Reddy et al., 2014)</ref>.</p><p>Our model learns from natural language de- scriptions paired with meaning representations. Most previous systems rely on high-quality lex- icons, manually-built templates, and features which are either domain-or representation- specific. We instead present a general method that can be easily adapted to different domains and meaning representations. We adopt the general encoder-decoder framework based on neural net- works which has been recently repurposed for var- ious NLP tasks such as syntactic parsing ), machine translation <ref type="bibr" target="#b16">(Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b7">Cho et al., 2014;</ref><ref type="bibr" target="#b36">Sutskever et al., 2014</ref>), image description generation <ref type="bibr" target="#b17">(Karpathy and Fei-Fei, 2015;</ref><ref type="bibr" target="#b43">Vinyals et al., 2015b</ref>), ques- tion answering ( <ref type="bibr" target="#b14">Hermann et al., 2015)</ref>, and sum- marization ( <ref type="bibr" target="#b35">Rush et al., 2015)</ref>. <ref type="bibr" target="#b28">Mei et al. (2016)</ref> use a sequence-to-sequence model to map navigational instructions to actions.</p><p>Our model works on more well-defined meaning representations (such as Prolog and lambda cal- culus) and is conceptually simpler; it does not employ bidirectionality or multi-level alignments. <ref type="bibr" target="#b12">Grefenstette et al. (2014)</ref> propose a different ar- chitecture for semantic parsing based on the com- bination of two neural network models. The first model learns shared representations from pairs of questions and their translations into knowledge base queries, whereas the second model generates the queries conditioned on the learned representa- tions. However, they do not report empirical eval- uation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Our aim is to learn a model which maps natural language input q = x 1 · · · x |q| to a logical form representation of its meaning a = y 1 · · · y |a| . The conditional probability p (a|q) is decomposed as:</p><formula xml:id="formula_0">p (a|q) = |a| t=1 p (y t |y &lt;t , q)<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">y &lt;t = y 1 · · · y t−1 .</formula><p>Our method consists of an encoder which en- codes natural language input q into a vector repre- sentation and a decoder which learns to generate y 1 , · · · , y |a| conditioned on the encoding vector. In the following we describe two models varying in the way in which p (a|q) is computed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sequence-to-Sequence Model</head><p>This model regards both input q and output a as sequences. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, the encoder and decoder are two different L-layer recurrent neural networks with long short-term memory (LSTM) units which recursively process tokens one by one. The first |q| time steps belong to the encoder, while the following |a| time steps belong to the decoder. Let h l t ∈ R n denote the hidden vector at time step t and layer l. h l t is then computed by:</p><formula xml:id="formula_2">h l t = LSTM h l t−1 , h l−1 t (2)</formula><p>where LSTM refers to the LSTM function being used. In our experiments we follow the architec- ture described in <ref type="bibr" target="#b48">Zaremba et al. (2015)</ref>, however other types of gated activation functions are pos- sible (e.g., <ref type="bibr" target="#b7">Cho et al. (2014)</ref>). For the encoder,</p><formula xml:id="formula_3">h 0 t = W q e(x t )</formula><p>is the word vector of the current input token, with W q ∈ R n×|Vq| being a parame- ter matrix, and e(·) the index of the corresponding token. For the decoder, h 0 t = W a e(y t−1 ) is the word vector of the previous predicted word, where W a ∈ R n×|Va| . Notice that the encoder and de- coder have different LSTM parameters.</p><p>Once the tokens of the input sequence x 1 , · · · , x |q| are encoded into vectors, they are used to initialize the hidden states of the first time step in the decoder. Next, the hidden vector of the topmost LSTM h L t in the decoder is used to pre- dict the t-th output token as:</p><formula xml:id="formula_4">p (y t |y &lt;t , q) = softmax W o h L t e (y t ) (3)</formula><p>where W o ∈ R |Va|×n is a parameter matrix, and e (y t ) ∈ {0, 1} |Va| a one-hot vector for computing y t 's probability from the predicted distribution. We augment every sequence with a "start-of- sequence" &lt;s&gt; and "end-of-sequence" &lt;/s&gt; to- ken. The generation process terminates once &lt;/s&gt; is predicted. The conditional probability of gener- ating the whole sequence p (a|q) is then obtained using Equation (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sequence-to-Tree Model</head><p>The SEQ2SEQ model has a potential drawback in that it ignores the hierarchical structure of logical forms. As a result, it needs to memorize various pieces of auxiliary information (e.g., bracket pairs) to generate well-formed output. In the following we present a hierarchical tree decoder which is more faithful to the compositional nature of mean- ing representations. A schematic description of the model is shown in <ref type="figure">Figure 3</ref>.</p><p>The present model shares the same encoder with the sequence-to-sequence model described in Sec- tion 3.1 (essentially it learns to encode input q as vectors). However, its decoder is fundamentally different as it generates logical forms in a top- down manner. In order to represent tree structure,  <ref type="figure">Figure 3</ref>: Sequence-to-tree (SEQ2TREE) model with a hierarchical tree decoder.</p><p>we define a "nonterminal" &lt;n&gt; token which in- dicates subtrees. As shown in <ref type="figure">Figure 3</ref>, we pre- process the logical form "lambda $0 e (and (&gt;(de- parture time $0) 1600:ti) (from $0 dallas:ci))" to a tree by replacing tokens between pairs of brackets with nonterminals. Special tokens &lt;s&gt; and &lt;(&gt; denote the beginning of a sequence and nontermi- nal sequence, respectively (omitted from <ref type="figure">Figure 3</ref> due to lack of space). Token &lt;/s&gt; represents the end of sequence. After encoding input q, the hierarchical tree de- coder uses recurrent neural networks to generate tokens at depth 1 of the subtree corresponding to parts of logical form a. If the predicted token is &lt;n&gt;, we decode the sequence by conditioning on the nonterminal's hidden vector. This process terminates when no more nonterminals are emit- ted. In other words, a sequence decoder is used to hierarchically generate the tree structure.</p><p>In contrast to the sequence decoder described in Section 3.1, the current hidden state does not only depend on its previous time step. In order to better utilize the parent nonterminal's information, we introduce a parent-feeding connection where the hidden vector of the parent nonterminal is con- catenated with the inputs and fed into LSTM.</p><p>As an example, <ref type="figure" target="#fig_3">Figure 4</ref> shows the decoding tree corresponding to the logical form "A B (C)", where y 1 · · · y 6 are predicted tokens, and t 1 · · · t 6 denote different time steps. Span "(C)" corre- sponds to a subtree. Decoding in this example has two steps: once input q has been encoded, we first generate y 1 · · · y 4 at depth 1 until token &lt;/s&gt; is   predicted; next, we generate y 5 , y 6 by condition- ing on nonterminal t 3 's hidden vectors. The prob- ability p (a|q) is the product of these two sequence decoding steps:</p><formula xml:id="formula_5">p (a|q) = p (y 1 y 2 y 3 y 4 |q) p (y 5 y 6 |y ≤3 , q) (4)</formula><p>where Equation <ref type="formula">(3)</ref> is used for the prediction of each output token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Attention Mechanism</head><p>As shown in Equation <ref type="formula">(3)</ref>, the hidden vectors of the input sequence are not directly used in the decoding process. However, it makes intuitively sense to consider relevant information from the in- put to better predict the current token. Following this idea, various techniques have been proposed to integrate encoder-side information (in the form of a context vector) at each time step of the de- coder ( <ref type="bibr" target="#b3">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b27">Luong et al., 2015b;</ref><ref type="bibr" target="#b47">Xu et al., 2015</ref>).</p><p>As shown in <ref type="figure">Figure 5</ref>, in order to find rele- vant encoder-side context for the current hidden state h L t of decoder, we compute its attention score with the k-th hidden state in the encoder as:</p><formula xml:id="formula_6">s t k = exp{h L k · h L t } |q| j=1 exp{h L j · h L t } (5)</formula><p>where h L 1 , · · · , h L |q| are the top-layer hidden vec- tors of the encoder. Then, the context vector is the weighted sum of the hidden vectors in the encoder:</p><formula xml:id="formula_7">c t = |q| k=1 s t k h L k<label>(6)</label></formula><p>In lieu of Equation <ref type="formula">(3)</ref>, we further use this con- text vector which acts as a summary of the encoder to compute the probability of generating y t as:</p><formula xml:id="formula_8">h att t = tanh W 1 h L t + W 2 c t (7) LSTM LSTM LSTM LSTM LSTM</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Scores</head><p>Figure 5: Attention scores are computed by the current hidden vector and all the hidden vectors of encoder. Then, the encoder-side context vector c t is obtained in the form of a weighted sum, which is further used to predict y t .</p><formula xml:id="formula_9">p (y t |y &lt;t , q) = softmax W o h att t e (y t ) (8)</formula><p>where W o ∈ R |Va|×n and W 1 , W 2 ∈ R n×n are three parameter matrices, and e (y t ) is a one-hot vector used to obtain y t 's probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model Training</head><p>Our goal is to maximize the likelihood of the gen- erated logical forms given natural language utter- ances as input. So the objective function is:</p><formula xml:id="formula_10">minimize − (q,a)∈D log p (a|q)<label>(9)</label></formula><p>where D is the set of all natural language-logical form training pairs, and p (a|q) is computed as shown in Equation (1). The RMSProp algorithm <ref type="bibr" target="#b40">(Tieleman and Hinton, 2012</ref>) is employed to solve this non-convex optimization problem. Moreover, dropout is used for regularizing the model ( <ref type="bibr" target="#b48">Zaremba et al., 2015)</ref>. Specifically, dropout operators are used between different LSTM layers and for the hidden lay- ers before the softmax classifiers. This technique can substantially reduce overfitting, especially on datasets of small size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Inference</head><p>At test time, we predict the logical form for an in- put utterance q by:</p><formula xml:id="formula_11">ˆ a = arg max a p a |q<label>(10)</label></formula><p>where a represents a candidate output. How- ever, it is impractical to iterate over all possible results to obtain the optimal prediction. Accord- ing to Equation (1), we decompose the probabil- ity p (a|q) so that we can use greedy search (or beam search) to generate tokens one by one.</p><p>Algorithm 1 describes the decoding process for SEQ2TREE. The time complexity of both de- coders is O(|a|), where |a| is the length of out- put. The extra computation of SEQ2TREE com- pared with SEQ2SEQ is to maintain the nonter- minal queue, which can be ignored because most of time is spent on matrix operations. We imple- ment the hierarchical tree decoder in a batch mode, so that it can fully utilize GPUs. Specifically, as shown in Algorithm 1, every time we pop multi- ple nonterminals from the queue and decode these nonterminals in one batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Argument Identification</head><p>The majority of semantic parsing datasets have been developed with question-answering in mind. In the typical application setting, natural language questions are mapped into logical forms and ex- ecuted on a knowledge base to obtain an answer. Due to the nature of the question-answering task, many natural language utterances contain entities or numbers that are often parsed as arguments in the logical form. Some of them are unavoidably rare or do not appear in the training set at all (this is especially true for small-scale datasets). Con- ventional sequence encoders simply replace rare words with a special unknown word symbol (Lu- ong et al., 2015a; Jean et al., 2015), which would be detrimental for semantic parsing.</p><p>We have developed a simple procedure for ar- gument identification. Specifically, we identify entities and numbers in input questions and re- place them with their type names and unique IDs. For instance, we pre-process the training example "jobs with a salary of 40000" and its logical form "job(ANS), salary greater than(ANS, 40000, year)" as "jobs with a salary of num 0 " and "job(ANS), salary greater than(ANS, num 0 , year)". We use the pre-processed examples as training data. At inference time, we also mask en- tities and numbers with their types and IDs. Once we obtain the decoding result, a post-processing step recovers all the markers type i to their corre- sponding logical constants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare our method against multiple previ- ous systems on four datasets. We describe these datasets below, and present our experimental set- tings and results. Finally, we conduct model anal- ysis in order to understand what the model learns. The code is available at https://github. com/donglixp/lang2logic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Our model was trained on the following datasets, covering different domains and using different meaning representations. Examples for each do- main are shown in <ref type="table">Table 1</ref>. GEO This is a standard semantic parsing bench- mark which contains 880 queries to a database of U.S. geography. GEO has 880 instances split into a training set of 680 training examples and 200 test examples <ref type="bibr" target="#b50">(Zettlemoyer and Collins, 2005)</ref>. We used the same meaning representation based on lambda-calculus as <ref type="bibr" target="#b22">Kwiatkowski et al. (2011</ref> what microsoft jobs do not require a bscs? answer(company(J,'microsoft'),job(J),not((req deg(J,'bscs')))) GEO 7.60 <ref type="bibr">19.10</ref> what is the population of the state with the largest area? (population:i (argmax $0 (state:t $0) (area:i $0))) ATIS 11.10 28.10 dallas to san francisco leaving after 4 in the afternoon please (lambda $0 e (and (&gt;(departure time $0) 1600:ti) (from $0 dallas:ci) (to $0 san francisco:ci))) IFTTT</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.95">21.80</head><p>Turn on heater when temperature drops below 58 degree TRIGGER: Weather -Current temperature drops below -((Temperature (58)) (Degrees in (f))) ACTION: WeMo Insight Switch -Turn on -((Which switch? (""))) <ref type="table">Table 1</ref>: Examples of natural language descriptions and their meaning representations from four datasets. The average length of input and output sequences is shown in the second column.</p><p>recipes from the IFTTT website <ref type="bibr">1</ref> . Recipes are sim- ple programs with exactly one trigger and one ac- tion which users specify on the site. Whenever the conditions of the trigger are satisfied, the action is performed. Actions typically revolve around home security (e.g., "turn on my lights when I ar- rive home"), automation (e.g., "text me if the door opens"), well-being (e.g., "remind me to drink water if I've been at a bar for more than two hours"), and so on. Triggers and actions are se- lected from different channels (160 in total) rep- resenting various types of services, devices (e.g., Android), and knowledge sources (such as ESPN or Gmail). In the dataset, there are 552 trigger functions from 128 channels, and 229 action func- tions from 99 channels. We used <ref type="bibr">Quirk et al.'s (2015)</ref> original split which contains 77, 495 train- ing, 5, 171 development, and 4, 294 test examples. The IFTTT programs are represented as abstract syntax trees and are paired with natural language descriptions provided by users (see <ref type="table">Table 1</ref>). Here, numbers and URLs are identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Settings</head><p>Natural language sentences were lowercased; mis- spellings were corrected using a dictionary based on the Wikipedia list of common misspellings. Words were stemmed using NLTK ( <ref type="bibr" target="#b4">Bird et al., 2009</ref>). For IFTTT, we filtered tokens, channels and functions which appeared less than five times in the training set. For the other datasets, we fil- tered input words which did not occur at least two times in the training set, but kept all tokens in the logical forms. Plain string matching was em- ployed to identify augments as described in Sec- tion 3.6. More sophisticated approaches could be used, however we leave this future work.</p><p>Model  on the training set for JOBS and GEO. We used the standard development sets for ATIS and IFTTT. We used the RMSProp algorithm (with batch size set to 20) to update the parameters. The smoothing constant of RMSProp was 0.95. Gradients were clipped at 5 to alleviate the exploding gradient problem ( <ref type="bibr" target="#b30">Pascanu et al., 2013)</ref>. Parameters were randomly initialized from a uniform distribution U (−0.08, 0.08). A two-layer LSTM was used for IFTTT, while a one-layer LSTM was employed for the other domains. The dropout rate was se- lected from {0.2, 0.3, 0.4, 0.5}. Dimensions of hidden vector and word embedding were selected from {150, 200, 250}. Early stopping was used to determine the number of epochs. Input sen- tences were reversed before feeding into the en- coder ( <ref type="bibr" target="#b36">Sutskever et al., 2014</ref>). We use greedy search to generate logical forms during inference.</p><p>Notice that two decoders with shared word em- beddings were used to predict triggers and actions for IFTTT, and two softmax classifiers are used to classify channels and functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We first discuss the performance of our model on JOBS, GEO, and ATIS, and then examine our re- sults on IFTTT. <ref type="table" target="#tab_4">Tables 2-4</ref> present comparisons against a variety of systems previously described Method Accuracy SCISSOR ( <ref type="bibr" target="#b10">Ge and Mooney, 2005)</ref> 72.3 KRISP ( <ref type="bibr" target="#b18">Kate and Mooney, 2006)</ref> 71.7 WASP ( <ref type="bibr" target="#b44">Wong and Mooney, 2006)</ref> 74.8 λ-WASP ( <ref type="bibr" target="#b45">Wong and Mooney, 2007)</ref> 86.6 LNLZ08 ( <ref type="bibr" target="#b25">Lu et al., 2008)</ref> 81.8 ZC05 ( <ref type="bibr" target="#b50">Zettlemoyer and Collins, 2005)</ref> 79.3 ZC07 ( <ref type="bibr" target="#b51">Zettlemoyer and Collins, 2007)</ref> 86.1 UBL ( <ref type="bibr" target="#b21">Kwiatkowski et al., 2010)</ref> 87.9 FUBL <ref type="figure" target="#fig_0">(Kwiatkowski et al., 2011)</ref> 88.6 KCAZ13 ( <ref type="bibr" target="#b23">Kwiatkowski et al., 2013)</ref> 89.0 DCS+L <ref type="figure" target="#fig_0">(Liang et al., 2013)</ref> 87.9 TISP ( <ref type="bibr" target="#b52">Zhao and Huang, 2015)</ref> 88 <ref type="table">Table 3</ref>: Evaluation results on GEO. 10-fold cross- validation is used for the systems shown in the top half of the table. The standard split of ZC05 is used for all other systems.</p><note type="other">.9 SEQ2SEQ 84.6 − attention 72.9 − argument 68.6 SEQ2TREE 87.1 − attention 76.8</note><p>Method Accuracy ZC07 ( <ref type="bibr" target="#b51">Zettlemoyer and Collins, 2007)</ref> 84.6 UBL ( <ref type="bibr" target="#b21">Kwiatkowski et al., 2010)</ref> 71.4 FUBL ( <ref type="bibr" target="#b22">Kwiatkowski et al., 2011)</ref> 82.8 GUSP-FULL <ref type="bibr" target="#b31">(Poon, 2013)</ref> 74.8 GUSP++ <ref type="bibr" target="#b31">(Poon, 2013)</ref> 83.5 TISP ( <ref type="bibr" target="#b52">Zhao and Huang, 2015)</ref> 84  in the literature. We report results with the full models (SEQ2SEQ, SEQ2TREE) and two abla- tion variants, i.e., without an attention mechanism (−attention) and without argument identification (−argument). We report accuracy which is de- fined as the proportion of the input sentences that are correctly parsed to their gold standard logical forms. Notice that DCS+L, KCAZ13 and GUSP output answers directly, so accuracy in this setting is defined as the percentage of correct answers. Overall, SEQ2TREE is superior to SEQ2SEQ. This is to be expected since SEQ2TREE ex- plicitly models compositional structure. On the JOBS and GEO datasets which contain logical forms with nested structures, SEQ2TREE out- performs SEQ2SEQ by 2.9% and 2.5%, respec- tively. SEQ2TREE achieves better accuracy over SEQ2SEQ on ATIS too, however, the difference is smaller, since ATIS is a simpler domain without complex nested structures. We find that adding at-   <ref type="figure" target="#fig_5">Figure 6</ref>. Moreover, our results show that argument identification is critical for small- scale datasets. For example, about 92% of city names appear less than 4 times in the GEO train- ing set, so it is difficult to learn reliable parame- ters for these words. In relation to previous work, the proposed models achieve comparable or better performance. Importantly, we use the same frame- work (SEQ2SEQ or SEQ2TREE) across datasets and meaning representations (Prolog-style logi- cal forms in JOBS and lambda calculus in the other two datasets) without modification. Despite this relatively simple approach, we observe that SEQ2TREE ranks second on JOBS, and is tied for first place with ZC07 on ATIS.  <ref type="table">(  lambda  $0  e  (  exists  $1  (  and  (  round_trip  $1</ref> </p><formula xml:id="formula_12">) ( class_type $1 first:cl ) ( from $1 ci0 ) ( to $1 ci1 ) ( = ( fare $1 ) $0 ) ) ) ) &lt;/s&gt;</formula><p>(b) what's first class fare round trip from ci0 to ci1  We illustrate examples of alignments produced by SEQ2SEQ in <ref type="figure" target="#fig_5">Figures 6a and 6b</ref>. Alignments produced by SEQ2TREE are shown in Figures 6c and 6d. Matrices of attention scores are com- puted using Equation (5) and are represented in grayscale. Aligned input words and logical form predicates are enclosed in (same color) rectan- gles whose overlapping areas contain the attention scores. Also notice that attention scores are com- puted by LSTM hidden vectors which encode con- text information rather than just the words in their current positions. The examples demonstrate that the attention mechanism can successfully model the correspondence between sentences and logi- cal forms, capturing reordering <ref type="figure" target="#fig_5">(Figure 6b</ref>), many- to-many <ref type="figure" target="#fig_5">(Figure 6a)</ref>, and many-to-one alignments <ref type="figure" target="#fig_5">(Figures 6c,d</ref>).</p><formula xml:id="formula_13">&lt;/s&gt; tomorrow ci1 to ci0 from flight earliest the is what &lt;s&gt; argmin $0 ( and ( flight $0 ) ( from $0 ci0 ) ( to $0 ci1 ) ( tomorrow $0 ) ) ( departure_time $0 ) &lt;/s&gt; (c</formula><p>For IFTTT, we follow the same evaluation pro- tocol introduced in <ref type="bibr" target="#b33">Quirk et al. (2015)</ref>. The dataset is extremely noisy and measuring accu- racy is problematic since predicted abstract syn- tax trees (ASTs) almost never exactly match the gold standard. Quirk et al. view an AST as a set of productions and compute balanced F1 in- stead which we also adopt. The first column in <ref type="table" target="#tab_8">Table 5</ref> shows the percentage of channels selected correctly for both triggers and actions. The sec- ond column measures accuracy for both channels and functions. The last column shows balanced F1 against the gold tree over all productions in the proposed derivation. We compare our model against posclass, the method introduced in Quirk et al. and several of their baselines. posclass is reminiscent of KRISP ( <ref type="bibr" target="#b18">Kate and Mooney, 2006</ref>), it learns distributions over productions given in- put sentences represented as a bag of linguistic features. The retrieval baseline finds the closest description in the training data based on charac- ter string-edit-distance and returns the recipe for that training program. The phrasal method uses phrase-based machine translation to generate the recipe, whereas sync extracts synchronous gram- mar rules from the data, essentially recreating WASP ( <ref type="bibr" target="#b44">Wong and Mooney, 2006</ref>). Finally, they use a binary classifier to predict whether a produc- tion should be present in the derivation tree corre- sponding to the description. <ref type="bibr" target="#b33">Quirk et al. (2015)</ref> report results on the full test data and smaller subsets after noise filter- ing, e.g., when non-English and unintelligible de- scriptions are removed <ref type="table" target="#tab_8">(Tables 5a and 5b</ref>). They also ran their system on a high-quality subset of description-program pairs which were found in the gold standard and at least three humans managed to independently reproduce <ref type="table" target="#tab_8">(Table 5c</ref>). Across all subsets our models outperforms posclass and re- lated baselines. Again we observe that SEQ2TREE consistently outperforms SEQ2SEQ, albeit with a small margin. Compared to the previous datasets, the attention mechanism and our argument iden-tification method yield less of an improvement. This may be due to the size of <ref type="bibr" target="#b33">Quirk et al. (2015)</ref> and the way it was created -user curated descrip- tions are often of low quality, and thus align very loosely to their corresponding ASTs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Error Analysis</head><p>Finally, we inspected the output of our model in order to identify the most common causes of errors which we summarize below.</p><p>Under-Mapping The attention model used in our experiments does not take the alignment his- tory into consideration. So, some question words, expecially in longer questions, may be ignored in the decoding process. This is a common prob- lem for encoder-decoder models and can be ad- dressed by explicitly modelling the decoding cov- erage of the source words ( <ref type="bibr" target="#b41">Tu et al., 2016;</ref><ref type="bibr" target="#b9">Cohn et al., 2016)</ref>. Keeping track of the attention his- tory would help adjust future attention and guide the decoder towards untranslated source words.</p><p>Argument Identification Some mentions are incorrectly identified as arguments. For example, the word may is sometimes identified as a month when it is simply a modal verb. Moreover, some argument mentions are ambiguous. For instance, 6 o'clock can be used to express either 6 am or 6 pm. We could disambiguate arguments based on contextual information. The execution results of logical forms could also help prune unreasonable arguments.</p><p>Rare Words Because the data size of JOBS, GEO, and ATIS is relatively small, some question words are rare in the training set, which makes it hard to estimate reliable parameters for them. One solution would be to learn word embeddings on unannotated text data, and then use these as pre- trained vectors for question words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we presented an encoder-decoder neural network model for mapping natural lan- guage descriptions to their meaning representa- tions. We encode natural language utterances into vectors and generate their corresponding log- ical forms as sequences or trees using recur- rent neural networks with long short-term mem- ory units. Experimental results show that en- hancing the model with a hierarchical tree de- coder and an attention mechanism improves per- formance across the board. Extensive compar- isons with previous methods show that our ap- proach performs competitively, without recourse to domain-or representation-specific features. Di- rections for future work are many and varied. For example, it would be interesting to learn a model from question-answer pairs without access to tar- get logical forms. Beyond semantic parsing, we would also like to apply our SEQ2TREE model to related structured prediction tasks such as con- stituency parsing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Input utterances and their logical forms are encoded and decoded with neural networks. An attention layer is used to learn soft alignments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Sequence-to-sequence (SEQ2SEQ) model with two-layer recurrent neural networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A SEQ2TREE decoding example for the logical form "A B (C)".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>JOBS</head><label></label><figDesc>This benchmark dataset contains 640 queries to a database of job listings. Specifically, questions are paired with Prolog-style queries. We used the same training-test split as Zettlemoyer and Collins (2005) which contains 500 training and 140 test instances. Values for the variables company, degree, language, platform, location, job area, and number are identified.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Alignments (same color rectangles) produced by the attention mechanism (darker color represents higher attention score). Input sentences are reversed and stemmed. Model output is shown for SEQ2SEQ (a, b) and SEQ2TREE (c, d).</figDesc><graphic url="image-2.png" coords="8,228.97,82.26,76.35,152.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>). Values for the variables city, state, country, river, and number are identified. ATIS This dataset has 5, 410 queries to a flight booking system. The standard split has 4, 480 training instances, 480 development instances, and 450 test instances. Sentences are paired with lambda-calculus expressions. Values for the vari- ables date, time, city, aircraft code, airport, airline, and number are identified. IFTTT Quirk et al. (2015) created this dataset by extracting a large number of if-this-then-that</figDesc><table>Dataset Length Example 

JOBS 
9.80 
22.90 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 : Evaluation results on JOBS.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Evaluation results on ATIS.</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Evaluation results on IFTTT. 

tention substantially improves performance on all 
three datasets. This underlines the importance of 
utilizing soft alignments between inputs and out-
puts. We further analyze what the attention layer 
learns in </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing as machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st ACL</title>
		<meeting>the 51st ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 EMNLP</title>
		<meeting>the 2011 EMNLP<address><addrLine>United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
	<note>inburgh</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">TACL</biblScope>
			<biblScope unit="page" from="49" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICLR</title>
		<meeting>the ICLR<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic parsing freebase: Towards open-domain semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Joint Conference on Lexical and Computational Semantics</title>
		<meeting><address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="328" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th AAAI</title>
		<meeting>the 15th AAAI<address><addrLine>San Francisco, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 EMNLP</title>
		<meeting>the 2014 EMNLP<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CONLL</title>
		<meeting>CONLL<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Incorporating structural alignment biases into an attentional neural translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong Duy Vu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Vymolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 NAACL</title>
		<meeting>the 2016 NAACL<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A statistical semantic parser that integrates syntax and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning from natural instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd IJCAI</title>
		<meeting>the 22nd IJCAI<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1794" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A deep architecture for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl Moritz</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Workshop on Semantic Parsing</title>
		<meeting>the ACL 2014 Workshop on Semantic Parsing<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semantic processing using the hidden vector state model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="262" to="275" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1684" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 53rd ACL and 7th IJCNLP</title>
		<meeting>53rd ACL and 7th IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 EMNLP</title>
		<meeting>the 2013 EMNLP<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep visualsemantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR<address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3128" to="3137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Using string-kernels for learning semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st COLING and 44th ACL</title>
		<meeting>the 21st COLING and 44th ACL<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to transform natural to formal languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th AAAI</title>
		<meeting>the 20th AAAI<address><addrLine>Pittsburgh, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1062" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 EMNLP</title>
		<meeting>the 2012 EMNLP<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="754" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higher-order unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 EMNLP</title>
		<meeting>the 2010 EMNLP<address><addrLine>Cambridge, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 EMNLP</title>
		<meeting>the 2011 EMNLP<address><addrLine>Edinburgh, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1512" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 EMNLP</title>
		<meeting>the 2013 EMNLP<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1545" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="446" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 EMNLP</title>
		<meeting>the 2008 EMNLP<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Addressing the rare word problem in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd ACL and 7th IJCNLP</title>
		<meeting>the 53rd ACL and 7th IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 EMNLP</title>
		<meeting>the 2015 EMNLP<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="Portu" to=" gal" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Listen, attend, and walk: Neural mapping of navigational instructions to action sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI</title>
		<meeting>the 30th AAAI<address><addrLine>Phoenix, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A fully statistical approach to natural language interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Stallard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bobrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="55" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ICML</title>
		<meeting>the 30th ICML<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Grounded unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st ACL</title>
		<meeting>the 51st ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="933" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Towards a theory of natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th IUI</title>
		<meeting>the 8th IUI<address><addrLine>Miami, Florida</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Language to code: Learning semantic parsers for if-this-then-that recipes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 53rd ACL and 7th IJCNLP</title>
		<meeting>53rd ACL and 7th IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="878" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 EMNLP</title>
		<meeting>the 2015 EMNLP<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="379" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automated construction of database interfaces: Intergrating statistical and relational learning for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 EMNLP</title>
		<meeting>the 2000 EMNLP<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="133" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Using multiple clause constructors in inductive logic programming for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ECML</title>
		<meeting>the 12th ECML<address><addrLine>Freiburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="466" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Acquiring word-meaning mappings for natural language interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><forename type="middle">A</forename><surname>Thomspon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artifical Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="44" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Lecture 6.5RmsProp: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling coverage for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th ACL</title>
		<meeting>the 54th ACL<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2755" to="2763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR<address><addrLine>Boston, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 NAACL</title>
		<meeting>the 2006 NAACL<address><addrLine>New York, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th ACL</title>
		<meeting>the 45th ACL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="960" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Progress in natural language understanding: An application to lunar geology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Computer Conference and Exposition</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1973-06-04" />
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
	<note>Proceedings of the</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd ICML</title>
		<meeting>the 32nd ICML<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recurrent neural network regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICLR</title>
		<meeting>the ICLR<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th AAAI</title>
		<meeting>the 19th AAAI<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st UAI</title>
		<meeting>the 21st UAI<address><addrLine>Toronto, ON</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLPCoNLL</title>
		<meeting>the EMNLPCoNLL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Type-driven incremental semantic parsing with polymorphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 NAACL</title>
		<meeting>the 2015 NAACL<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1416" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
