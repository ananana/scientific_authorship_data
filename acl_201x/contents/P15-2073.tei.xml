<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">∆BLEU: A Discriminative Metric for Generation Tasks with Intrinsically Diverse Targets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">DIRO</orgName>
								<orgName type="institution">Université de Montréal</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>QC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<settlement>Atlanta</settlement>
									<region>GA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Facebook AI Research</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">∆BLEU: A Discriminative Metric for Generation Tasks with Intrinsically Diverse Targets</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="445" to="450"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce Discriminative BLEU (∆BLEU), a novel metric for intrinsic evaluation of generated text in tasks that admit a diverse range of possible outputs. Reference strings are scored for quality by human raters on a scale of [−1, +1] to weight multi-reference BLEU. In tasks involving generation of conversational responses, ∆BLEU correlates reasonably with human judgments and outperforms sentence-level and IBM BLEU in terms of both Spearman&apos;s ρ and Kendall&apos;s τ .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many natural language processing tasks involve the generation of texts where a variety of outputs are acceptable or even desirable. Tasks with intrin- sically diverse targets range from machine transla- tion, summarization, sentence compression, para- phrase generation, and image-to-text to generation of conversational interactions. A major hurdle for these tasks is automation of evaluation, since the space of plausible outputs can be enormous, and it is it impractical to run a new human evaluation every time a new model is built or parameters are modified.</p><p>In Statistical Machine Translation (SMT), the automation problem has to a large extent been ame- liorated by metrics such as BLEU ( <ref type="bibr" target="#b12">Papineni et al., 2002</ref>) and METEOR ( <ref type="bibr" target="#b0">Banerjee and Lavie, 2005</ref>) Although BLEU is not immune from criticism (e.g., <ref type="bibr" target="#b1">Callison-Burch et al. (2006)</ref>), its properties are well understood, BLEU scores have been shown to cor- relate well with human judgments (Doddington, *The entirety of this work was conducted while at Mi- crosoft Research.</p><p>† Corresponding author: mgalley@microsoft.com <ref type="bibr" target="#b3">2002;</ref><ref type="bibr" target="#b2">Coughlin, 2003;</ref><ref type="bibr" target="#b5">Graham and Baldwin, 2014;</ref><ref type="bibr" target="#b6">Graham et al., 2015</ref>) in SMT, and it has allowed the field to proceed. BLEU has been less successfully applied to non- SMT generation tasks owing to the larger space of plausible outputs. As a result, attempts have been made to adapt the metric. To foster diversity in paraphrase generation, <ref type="bibr" target="#b17">Sun and Zhou (2012)</ref> propose a metric called iBLEU in which the BLEU score is discounted by a BLEU score computed be- tween the source and paraphrase. This solution, in addition to being dependent on a tunable pa- rameter, is specific only to paraphrase. In image captioning tasks, <ref type="bibr">Vendantam et al. (2015)</ref>, employ a variant of BLEU in which n-grams are weighted by tf ·idf. This assumes the availability of a corpus with which to compute tf ·idf. Both the above can be seen as attempting to capture a notion of target goodness that is not being captured in BLEU.</p><p>In this paper, we introduce Discriminative BLEU (∆BLEU), a new metric that embeds human judg- ments concerning the quality of reference sen- tences directly into the computation of corpus-level multiple-reference BLEU. In effect, we push part of the burden of human evaluation into the automated metric, where it can be repeatedly utilized.</p><p>Our testbed for this metric is data-driven con- versation, a field that has begun to attract inter- est ( <ref type="bibr" target="#b14">Ritter et al., 2011;</ref><ref type="bibr" target="#b16">Sordoni et al., 2015)</ref> as an alternative to conventional rule-driven or scripted dialog systems. Intrinsic evaluation in this field is exceptionally challenging because the semantic space of possible responses resists definition and is only weakly constrained by conversational inputs.</p><p>Below, we describe ∆BLEU and investigate its characteristics in comparison to standard BLEU in the context of conversational response generation. We demonstrate that ∆BLEU correlates well with human evaluation scores in this task and thus can provide a basis for automated training and evalua- tion of data-driven conversation systems-and, we ultimately believe, other text generation tasks with inherently diverse targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluating Conversational Responses</head><p>Given an input message m and a prior conversation history c, the goal of a response generation system is to produce a hypothesis h that is both well-formed and a pertinent response to message m (example in <ref type="figure" target="#fig_0">Fig. 1</ref>). We assume that a set of J references {r i,j } is available for the context c i and message m i , where i ∈ {1 . . . I} is an index over the test set. In the case of BLEU, 1 the automatic score of the system output h 1 . . . h I is defined as:</p><formula xml:id="formula_0">BLEU = BP · exp n log p n<label>(1)</label></formula><p>with:</p><formula xml:id="formula_1">BP = 1 if η &gt; ρ e (1−ρ/η) otherwise (2)</formula><p>where ρ and η are respectively hypothesis and refer- ence lengths. <ref type="bibr">2</ref> Then corpus-level n-gram precision is defined as:</p><formula xml:id="formula_2">p n = i g ∈ n-grams(h i ) max j # g (h i , r i,j ) i g ∈ n-grams(h i ) # g (h i )</formula><p>where # g (·) is the number of occurrences of n-gram g in a given sentence, and</p><formula xml:id="formula_3"># g (u, v) is a shorthand for min # g (u), # g (v) .</formula><p>It has been demonstrated that metrics such as BLEU show increased correlation with human judg- ment as the number of references increases <ref type="bibr" target="#b13">(Przybocki et al., 2008;</ref><ref type="bibr" target="#b4">Dreyer and Marcu, 2012)</ref>. Unfor- tunately, gathering multiple references is difficult in the case of conversations. Data gathered from naturally occurring conversations offer only one response per message. One could search (c, m) pairs that occur multiple times in conversational data with the hope of finding distinct responses, but this solution is not feasible. Indeed, the larger the context, the less likely we are to find pairs that match exactly. Furthermore, while it is feasible to have writers create additional references when the downstream task is relatively unambiguous (e.g., MT), this approach is more questionable in the case of more subjective tasks such as conversa- tional response generation. Our solution is to mine candidate responses from conversational data and have judges rate the quality of these responses. Our new metric thus naturally incorporates qualitative weights associated with references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discriminative BLEU</head><p>Discriminative BLEU, or ∆BLEU, extends BLEU by exploiting human qualitative judgments w i,j ∈ [−1, +1] associated with references r i,j . It is dis- criminative in that it both rewards matches with "good" reference responses (w &gt; 0) and penalizes matches with "bad" reference responses (w &lt; 0). Formally, ∆BLEU is defined as in Equation 1 and 2, except that p n is instead defined as:</p><formula xml:id="formula_4">i g ∈ n-grams(h i ) max j:g ∈ r i,j w i,j ·# g (h i , r i,j ) i g ∈ n-grams(h i ) max j w i,j ·# g (h i )</formula><p>In a nutshell, this is saying that each n-gram match is weighted by the highest scoring reference in which it occurs, and this weight can sometimes be negative. To ensure that the denominator is never zero, we assume that, for each i there exists at least one reference r i,j whose weight w i,j is strictly pos- itive. In addition to its discriminative nature, this metric has two interesting properties. First, if all weights w i,j are equal to 1, then the metric score is identical to BLEU. As such, ∆BLEU admits BLEU as a special case. Second, as with IBM BLEU, the maximum theoretical score is also 1. If the hy- pothesis happens to match the highest weighted reference for each sentence, the numerator equals the denominator and the metric score becomes 1. While we find this metric particularly appropriate for response generation, the metric makes no as- sumption on the task and is applicable to other text generation tasks such as MT and image captioning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multi-reference Datasets</head><p>To create the multi-reference BLEU dev and test sets used in this study, we adapted and extended the methodology of <ref type="bibr" target="#b16">Sordoni et al. (2015)</ref>. From a cor- pus of 29M Twitter context-message-response con- versational triples, we randomly extracted approxi- Message m Response r Score i was about to text you and my two cousins got excited cause they thought you were "rihanna" aww, i can imagine their disappointment they were very disappointed!!! 0.6 yes. my ex-boyfriend, killed my cat. like i say, it was the start of a bad time... i can imagine! yes. luckily, the whole thing feels very much of the past now.  <ref type="table">Table 1</ref>: Sample reference sets created by our multi-reference extraction algorithm, along with the weights used in ∆BLEU.</p><p>Triples from which additional references are extracted are in italics. Boxed sentences are in our multi-reference dev set.</p><p>mately 33K candidate triples that were then judged for conversational quality on a 5-point Likert-type scale by 3 crowdsourced annotators. Of these, 4232 triples scored an average 4 or higher; these were randomly binned to create seed dev and test sets of 2118 triples and 2114 triples respectively. Note that the dev set is not used in the experiments of this paper, since ∆BLEU and IBM BLEU are met- rics that do not require training. However, the dev set is released along with a test set in the dataset release accompanying this paper.</p><p>We then sought to identify candidate triples in the 29M corpus for which both message and re- sponse are similar to the original messages and responses in these seed sets. To this end, we em- ployed an information retrieval algorithm with a bag-of-words BM25 similarity function ( <ref type="bibr" target="#b15">Robertson et al., 1995)</ref>, as detailed in <ref type="bibr" target="#b16">Sordoni et al. (2015)</ref>, to extract the top 15 responses for each message- response pair. Unlike <ref type="bibr" target="#b16">Sordoni et al. (2015)</ref>, we further appended the original messages (as if par- roted back). The new triples were then scored for quality of the response in light of both context and message by 5 crowdsourced raters each on a 5- point Likert-type scale. <ref type="bibr">3</ref> Crucially, and again in contradistinction to <ref type="bibr" target="#b16">Sordoni et al. (2015)</ref>, we did not impose a score cutoff on these synthetic multi- reference sets. Instead, we retained all candidate responses and scaled their scores into <ref type="bibr">[−1, +1]</ref>. <ref type="table">Table 1</ref> presents representative multi-reference examples (from the dev set) together with their con- verted scores. The context and messages associated with the supplementary mined responses are also shown for illustrative purposes to demonstrate the range of conversations from which they were taken. In the table, negative-weighted mined responses are semantically orthogonal to the intent of their newly assigned context and message. Strongly negatively weighted responses are completely out of the ball- park ("the weather in Russia is very cool", "well then! Why were the biscuits needed?"); others are a little more plausible, but irrelevant or possibly topic changing ("ohh I love that song"). Higher-valued positive-weighted mined responses are typically reasonably appropriate and relevant (even though extracted from a completely unrelated conversa- tion), and in some cases can outscore the original response, as can be seen in the third set of exam- ples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Human Evaluation of System Outputs</head><p>Responses generated by the 7 systems used in this study on the 2114-triple test set were hand evalu- ated by 5 crowdsourced raters each on a 5-point Likert-type scale. From these 7 systems, 12 system pairs were evaluated, for a total of about pairwise 126K ratings <ref type="bibr">(12 · 5 · 2114)</ref>. Here too, raters were asked to evaluate responses in terms of their rele- vance to both context and message. Outputs from different systems were randomly interleaved for presentation to the raters. We obtained human rat- ings on the following systems:</p><p>Phrase-based MT: A phrase-based MT system similar to <ref type="bibr" target="#b14">(Ritter et al., 2011</ref>), whose weights have been manually tuned. We also included four variants of that system, which we tuned with MERT <ref type="bibr" target="#b11">(Och, 2003)</ref>. These variants differ in their number of features, and augment ( <ref type="bibr" target="#b14">Ritter et al., 2011</ref>) with the following phrase-level features: edit distance between source and target, cosine similar- ity, Jaccard index and distance, length ratio, and DSSM score ( <ref type="bibr" target="#b8">Huang et al., 2013)</ref>. RNN-based MT: the log-probability according to the RNN model of ( <ref type="bibr" target="#b16">Sordoni et al., 2015)</ref>. Baseline: a random baseline.</p><p>While ∆BLEU relies on human qualitative judg- ments, it is important to note that human judgments on multi-references ( § 4.1) and those on system out- puts were collected completely independently. We also note that the set of systems listed above specif- ically does not include a retrieval-based model, as this might have introduced spurious correlation be- tween the two datasets ( § 4.1 and § 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Setup</head><p>We use two rank correlation coefficients- Kendall's τ and Spearman's ρ-to assess the level of correlation between human qualitative ratings ( §4.2) and automated metric scores. More formally, we compute each correlation coefficient on a series of paired observations (m 1 , q 1 ), · · · , (m N , q N ). Here, m i and q i are respectively differences in auto- matic metric scores and qualitative ratings for two given systems A and B on a given subset of the test set. <ref type="bibr">4</ref> While much prior work assesses automatic metrics for MT and other tasks <ref type="bibr" target="#b9">(Lavie and Agarwal, 2007;</ref><ref type="bibr" target="#b7">Hodosh et al., 2013</ref>) by computing correla- tions on observations consisting of single-sentence system outputs, it has been shown (e.g., <ref type="bibr" target="#b13">Przybocki et al. (2008)</ref>) that correlation coefficients signifi- cantly increase as observation units become larger. For instance, corpus-level or system-level correla- tions tend to be much higher than sentence-level correlations; <ref type="bibr" target="#b5">Graham and Baldwin (2014)</ref> show that BLEU is competitive with more recent and ad- vanced metrics when assessed at the system level. <ref type="bibr">5</ref> Therefore, we define our observation unit size to be M = 100 sentences (responses), <ref type="bibr">6</ref> unless stated otherwise. We evaluate q i by averaging human rat- ings on the M sentences, and m i by computing metric scores on the same set of sentences. <ref type="bibr">7</ref> We compare three different metrics: BLEU, ∆BLEU, and sentence-level BLEU (sBLEU). The last com- putes sentence-level BLEU scores ( <ref type="bibr" target="#b10">Nakov et al., 2012)</ref> and averages them on the M sentences (akin to macro-averaging). Finally, unless otherwise noted, all versions of BLEU use n-gram order up to 2 (BLEU-2), as this achieves better correlation for all metrics on this data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>The main results of our study are shown in <ref type="table" target="#tab_2">Table 2</ref>. ∆BLEU achieves better correlation with human than BLEU, when comparing the best configura- tion of each metric. 8 In the case of Spearman's ρ, the confidence intervals of BLEU (.265, .416) and   ∆BLEU (.415, .546) barely overlap, while interval overlap is more significant in the case of Kendall's τ . Correlation coefficients degrade for BLEU as we go from w ≥ 0.6 to using all references. This is expected, since BLEU treats all references as equal and has no way of discriminating between them. On the other hand, correlation coefficients increase for ∆BLEU after adding lower scoring ref- erences. It is also worth noticing that BLEU and sBLEU obtain roughly comparable correlation co- efficients. This may come as a surprise, because it has been suggested elsewhere that sBLEU has much worse correlation than BLEU computed at the cor- pus level ( <ref type="bibr" target="#b13">Przybocki et al., 2008)</ref>. We surmise that (at least for this task and data) the differences in correlations between BLEU and sBLEU observed in prior work may be less the result of a difference between micro-and macro-averaging than they are the effect of different observation unit sizes (as discussed in §5). Finally, <ref type="figure" target="#fig_3">Figure 2</ref> shows how Spearman's ρ is affected along three dimensions of study. In par- ticular, we see that ∆BLEU actually benefits from the references with negative ratings. While the im- provement is not pronounced, we note that most ref- erences have positive ratings. Negatively-weighted references could have a greater effect if, for exam- ple, randomly extracted responses had also been annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>∆BLEU correlates well with human quality judg- ments of generated conversational responses, out- performing both IBM BLEU and sentence-level BLEU in this task and demonstrating that it can serve as a plausible intrinsic metric for system de- velopment. <ref type="bibr">9</ref> An upfront cost is paid for human evaluation of the reference set, but following that, the need for further human evaluation can be min- imized during system development. ∆BLEU may help other tasks that use multiple references for intrinsic evaluation, including image-to-text, sen- tence compression, and paraphrase generation, and even statistical machine translation. Evaluation of ∆BLEU in these tasks awaits future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of consecutive utterances of a dialog.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Metric</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A comparison of BLEU, sentence-level BLEU, and ∆BLEU along three dimensions: (A) decreasing the threshold on reference scores wi,j; (B) increasing the unit size for the correlation study from a single sentence (M =1) to a size of 100; (C) going from BLEU-1 to BLEU-4 for the different versions of BLEU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Human correlations for IBM BLEU, sentence-level 
BLEU, and ∆BLEU with 95% confidence intervals. This 
compares 3 types of references: single only, high scoring 
references (w ≥ 0.6), and all references. 

</table></figure>

			<note place="foot" n="1"> Unless mentioned otherwise, BLEU refers to the original IBM BLEU as first described in (Papineni et al., 2002). 2 In the case of multiple references, BLEU selects the reference whose length is closest to that of the hypothesis.</note>

			<note place="foot" n="3"> For this work, we sought 2 additional annotations of the seed responses for consistency with the mined responses. As a result, scores for some seed responses slipped below our initial threshold of 4. Nonetheless, these responses were retained.</note>

			<note place="foot" n="4"> For each given observation pair (mi, qi), we randomize the order in which A and B are presented to the raters in order to avoid any positional bias. 5 We do not intend to minimize the benefit of a metric that would be competitive at the sentence-level, which would be particularly useful for detailed error analyses. However, our main goal is to reliably evaluate generation systems on test sets of thousands of sentences, in which case any metric with good corpus-level correlation (such as BLEU, as shown in (Graham and Baldwin, 2014)) would be sufficient. 6 Enumerating all possible ways of assigning sentences to observations would cause a combinatorial explosion. Instead, for all our results we sample 1K assignments and average correlations coefficients over them (using the same 1K assignments across all metrics). These assignments are done in such a way that all sentences within an observation belong to the same system pair. 7 We refrained from using larger units, as creating larger observation units M reduces the total number of units N. This would have caused confidence intervals to be so wide as to make this study inconclusive. 8 This is also the case on single reference. While ∆BLEU and BLEU would have the same correlation if original references all had the same score of 1, it is not unusual for original references to get ratings below 1.</note>

			<note place="foot" n="9"> An implementation of ∆BLEU, multi-reference dev and test sets, and human rated outputs are available at: http://research.microsoft.com/convo</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Jian-Yun Nie, and Alan Ritter for their helpful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>of ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Re-evaluating the role of BLEU in machine translation research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Correlating automated and human assessments of machine translation quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><surname>Coughlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT Summit IX</title>
		<meeting>of MT Summit IX</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram cooccurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT</title>
		<meeting>of HLT</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">HyTER: Meaning-equivalent semantics for translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT-NAACL</title>
		<meeting>of HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Testing for significance of increased correlation with human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="172" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Accurate evaluation of segment-level machine translation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitika</forename><surname>Mathur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1183" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Framing image description as a ranking task: Data, models and evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="853" to="899" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 22nd ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>of the 22nd ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for mt evaluation with high levels of correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhaya</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on Statistical Machine Translation (StatMT)</title>
		<meeting>of the Workshop on Statistical Machine Translation (StatMT)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="228" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimizing for Sentence-Level BLEU+1 Yields Short Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Metrics for MAchine TRanslation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bronsart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">challenge</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Official results of the NIST</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Okapi at TREC-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meg</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint learning of a dual SMT system for paraphrase generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="38" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CIDEr: Consensus-based image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Ramakrishna Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
