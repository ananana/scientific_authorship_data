<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">One-Shot Neural Cross-Lingual Transfer for Paradigm Completion</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
						</author>
						<title level="a" type="main">One-Shot Neural Cross-Lingual Transfer for Paradigm Completion</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1993" to="2003"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1182</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a low-resource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Low-resource natural language processing <ref type="bibr">(NLP)</ref> remains an open problem for many tasks of interest. Furthermore, for most languages in the world, high- cost linguistic annotation and resource creation are unlikely to be undertaken in the near future. In the case of morphology, out of the 7000 currently spo- ken <ref type="bibr">(Lewis, 2009)</ref> languages, only about 200 have computer-readable annotations <ref type="bibr" target="#b51">(Sylak-Glassman et al., 2015</ref>) -although morphology is easy to an- notate compared to syntax and semantics. Transfer learning is one solution to this problem: it exploits annotations in a high-resource language to train a system for a low-resource language. In this work, we present a method for cross-lingual transfer of inflectional morphology using an encoder-decoder recurrent neural network (RNN). This allows for the development of tools for computational mor- phology with limited annotated data.</p><p>In many languages, individual lexical entries may be realized as distinct inflections of a single lemma depending on the syntactic context. For ex- ample, the 3SgPresInd of the English verbal lemma to bring is brings. In morphologically rich lan- guages, a lemma can have hundreds of individ- ual forms. Thus, both generation and analysis of such morphological inflections are active areas of research in NLP and morphological process- ing has been shown to be a boon to several other down-stream applications, e.g., machine transla- tion ( <ref type="bibr" target="#b18">Dyer et al., 2008)</ref>, speech recognition ( <ref type="bibr" target="#b15">Creutz et al., 2007)</ref>, parsing (Seeker and C ¸ etino˘ glu, 2015), keyword spotting ( <ref type="bibr" target="#b36">Narasimhan et al., 2014</ref>) and word embeddings ( <ref type="bibr" target="#b14">Cotterell et al., 2016b</ref>), inter alia. In this work, we focus on paradigm comple- tion, a form of morphological generation that maps a given lemma to a target inflection, e.g., (bring, Past) → brought (with Past being the target tag). RNN sequence-to-sequence models <ref type="bibr" target="#b4">Bahdanau et al., 2015)</ref> are the state of the art for paradigm completion <ref type="bibr" target="#b30">Kann and Schütze, 2016a;</ref><ref type="bibr">Cotterell et al., 2016a</ref>). However, these models require a large amount of data to achieve competitive perfor- mance; this makes them unsuitable for out-of-the- box application to paradigm completion in the low-resource scenario. To mitigate this, we con- sider transfer learning: we train an end-to-end neu- ral system jointly with limited data from a low- resource language and a larger amount of data from a high-resource language. This technique allows the model to apply knowledge distilled from the high-resource training data to the low-resource lan- guage as needed.</p><p>We conduct experiments on 21 language pairs from four language families, emulating a low- resource setting. Our results demonstrate success- ful transfer of morphological knowledge. We show improvements in accuracy and edit distance of up to 58% (accuracy) and 4.62 (edit distance) over the same model with only in-domain language data on the paradigm completion task. We further obtain up to 44% (resp. 14%) improvement in accuracy for the one-shot (resp. zero-shot) setting, i.e., one (resp. zero) in-domain language sample per target tag. We also show that the effectiveness of morpho- logical transfer depends on language relatedness, measured by lexical similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Inflectional Morphology and Paradigm Completion</head><p>Many languages exhibit inflectional morphology, i.e., the form of an individual lexical entry mutates to show properties such as person, number or case.</p><p>The citation form of a lexical entry is referred to as the lemma and the collection of its possible inflec- tions as its paradigm. Tab. 1 shows an example of a partial paradigm; we display several forms for the Spanish verbal lemma soñar. We may index the entries of a paradigm by a morphological tag, e.g., the 2SgPresInd form sueñas in Tab. 1. In generation, the speaker must select an entry of the paradigm given the form's context. In general, the presence of rich inflectional morphology is problematic for NLP systems as it greatly increases the token-type ratio and, thus, word form sparsity. An important task in inflectional morphology is paradigm completion <ref type="bibr" target="#b17">(Durrett and DeNero, 2013;</ref><ref type="bibr" target="#b2">Ahlberg et al., 2014;</ref><ref type="bibr" target="#b38">Nicolai et al., 2015;</ref><ref type="bibr" target="#b13">Cotterell et al., 2015;</ref>. Its goal is to map a lemma to all individual inflections, e.g., (soñar, 1SgPresInd) → sueño. There are good solu- tions for paradigm completion when a large amount of annotated training data is available ( <ref type="bibr">Cotterell et al., 2016a)</ref>. <ref type="bibr">1</ref> In this work, we address the low- resource setting, a yet unsolved challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transferring Inflectional Morphology</head><p>In comparison to other NLP annotations, e.g., part- of-speech (POS) and named entities, morphologi- cal inflection is especially challenging for transfer learning: we can define a universal set of POS tags <ref type="bibr" target="#b41">(Petrov et al., 2012</ref>) or of entity types (e.g., coarse- grained types like person and location or fine- grained types <ref type="bibr" target="#b56">(Yaghoobzadeh and Schütze, 2015)</ref>), but inflection is much more language-specific. It is infeasible to transfer morphological knowledge from Chinese to Portuguese as Chinese does not use inflected word forms. Transferring named entity recognition, however, among Chinese and European languages works well ( <ref type="bibr" target="#b54">Wang and Manning, 2014a</ref>). But even transferring inflectional paradigms from morphologically rich Arabic to Portuguese seems difficult as the inflections often mark dissimilar subcategories. In contrast, trans- ferring morphological knowledge from Spanish to Portuguese, two languages with similar conjuga- tions and 89% lexical similarity, appears promis- ing. Thus, we conjecture that transfer of inflec- tional morphology is only viable among related languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Formalization of the Task</head><p>We now offer a formal treatment of the cross- lingual paradigm completion task and develop our notation. Let Σ be a discrete alphabet for lan- guage and let T be a set of morphological tags for . Given a lemma w in , the morphological paradigm (inflectional table) π can be formalized as a set of pairs</p><formula xml:id="formula_0">π(w ) = f k [w ], t k k∈T (w )<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">f k [w ] ∈ Σ +</formula><p>is an inflected form, t k ∈ T is its morphological tag and T (w ) is the set of slots in the paradigm; e.g., a Spanish paradigm is:</p><formula xml:id="formula_2">π(soñar) = sueño, 1SgPresInd</formula><p>, . . . ,</p><formula xml:id="formula_3">soñaran, 3PlPastSbj</formula><p>Paradigm completion consists of predicting miss- ing slots in the paradigm π(w ) of a given lemma w .</p><p>In cross-lingual paradigm completion, we con- sider a high-resource source language s (lots of training data available) and a low-resource target language t (little training data available). We denote the source training examples as D s (with |D s | = n s ) and the target training examples as D t (with |D t | = n t ). The goal of cross-lingual paradigm completion is to populate paradigms in the low-resource target language with the help of data from the high-resource source language, using only few in-domain examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross-Lingual Transfer as Multi-Task Learning</head><p>We describe our probability model for morpho- logical transfer using terminology from multi-task learning <ref type="bibr" target="#b6">(Caruana, 1997;</ref><ref type="bibr" target="#b10">Collobert et al., 2011</ref>). We consider two tasks, training a paradigm com- pletor (i) for a high-resource language and (ii) for a low-resource language. We want to train jointly, so we reap the benefits of having related languages. Thus, we define the log-likelihood as</p><formula xml:id="formula_4">L(θ) = (k,w t )∈Dt log p θ (f k [w t ] | w t , t k , λ t ) (2) + (k,w s )∈Ds log p θ (f k [w s ] | w s , t k , λ s )</formula><p>where we tie parameters θ for the two languages together to allow the transfer of morphological knowledge between languages. The λs are special language tags, cf. Sec. 3.2. Each probability dis- tribution p θ defines a distribution over all possible realizations of an inflected form, i.e., a distribution over Σ * . For example, consider the related Ro- mance languages Spanish and French; focusing on one term from each of the summands in Eq. (2) (the past participle of the translation of to visit in each language), we arrive at</p><formula xml:id="formula_5">L visit (θ) = log p θ (visitado | visitar, PastPart, ES) + log p θ (visité | visiter, PastPart, FR)<label>(3)</label></formula><p>Our cross-lingual setting forces both transductions to share part of the parameter vector θ, to represent morphological regularities between the two lan- guages in a common embedding space and, thus, to enable morphological transfer. This is no different from monolingual multi-task settings, e.g., jointly training a parser and tagger for transfer of syntax. Based on recent advances in neural transducers, we parameterize each distribution as an encoder- decoder RNN, as in ( <ref type="bibr" target="#b31">Kann and Schütze, 2016b</ref>). In their setup, the RNN encodes the input and predicts the forms in a single language. In contrast, we force the network to predict two or more languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Encoder-Decoder RNN</head><p>We parameterize the distribution p θ as an encoder- decoder gated RNN (GRU) with attention ( <ref type="bibr" target="#b4">Bahdanau et al., 2015)</ref>, the state-of-the-art solution for the monolingual case ( <ref type="bibr" target="#b31">Kann and Schütze, 2016b)</ref>. A bidirectional gated RNN encodes the input se- quence ( <ref type="bibr" target="#b7">Cho et al., 2014</ref>) -the concatenation of (i) the language tag, (ii) the morphological tag of the form to be generated and (iii) the characters of the input word -represented by embeddings. The input to the decoder consists of concatenations of − → h i and ← − h i , the forward and backward hidden states of the encoder. The decoder, a unidirectional RNN, uses attention: it computes a weight α i for each h i . Each weight reflects the importance given to that input position. Using the attention weights, the probability of the output sequence given the input sequence is:</p><formula xml:id="formula_6">p(y | x 1 , . . . , x |X| ) = |Y | t=1 g(y t−1 , s t , c t ) (4)</formula><p>where y = (y 1 , . . . , y |Y | ) is the output sequence (a sequence of |Y | characters), x = (x 1 , . . . x |X| ) is the input sequence (a sequence of |X| characters), g is a non-linear function, s t is the hidden state of the decoder and c t is the sum of the encoder states h i , weighted by attention weights α i (s t−1 ) which depend on the decoder state: </p><formula xml:id="formula_7">c t = |X| i=1 α i (s t−1 )h i (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Input Format</head><p>Each source form is represented as a sequence of characters; each character is represented as an em- bedding. In the same way, each source tag is repre- sented as a sequence of subtags, and each subtag is represented as an embedding. More formally, we define the alphabet Σ = ∪ ∈L Σ as the set of characters in the languages in L, with L being the set of languages in the given experiment. Next, we define S as the set of subtags that occur as part of the set of morphological tags T = ∪ ∈L T ; e.g., if 1SgPresInd ∈ T , then 1, Sg, Pres, Ind ∈ S. Note that the set of subtags S is defined as attributes from the UNIMORPH schema (Sylak-Glassman, 2016) and, thus, is universal across languages; the schema is</p><formula xml:id="formula_8">! h 1 ! h 2 ! h 3 ! h N h 1 h 2 h 3 h N s o ñ r s u e s 1 s 2 s 3 s N y 1 = y 2 = y 3 = M …</formula><p>Figure 1: Encoder-decoder RNN for paradigm com- pletion. The lemma soñar is mapped to a target form (e.g., sueña). For brevity, language and target tags are omitted from the input. Thickness of red arrows symbolizes the degree to which the model attends to the corresponding hidden state of the encoder.</p><p>derived from research in linguistic typology. <ref type="bibr">2</ref> The format of the input to our system is S + Σ + . The output format is Σ + . Both input and output are padded with distinguished BOW and EOW symbols. What we have described is the representation of <ref type="bibr" target="#b31">Kann and Schütze (2016b)</ref>. In addition, we preprend a symbol λ ∈ L to the input string (e.g., λ = Es, also represented by an embedding), so the RNN can handle multiple languages simulta- neously and generalize over them. Thus, our final input is of the form λS + Σ + .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Languages and Language Families</head><p>To verify the applicability of our method to a wide range of languages, we perform experiments on example languages from several different families.</p><p>Romance languages, a subfamily of Indo- European, are widely spoken, e.g., in Europe and Latin America. Derived from the common ances- tor Vulgar Latin ( <ref type="bibr" target="#b25">Harris and Vincent, 2003)</ref>, they share large parts of their lexicon and inflectional morphology; we expect knowledge among them to be easily transferable. <ref type="bibr">2</ref> Note that while the subtag set is universal, which subtags a language actually uses is language-specific; e.g., Spanish does not mark animacy as Russian does. We contrast this with the universal POS set ( <ref type="bibr" target="#b41">Petrov et al., 2012)</ref>, where it is more likely that we see all 17 tags in most languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PT</head><p>CA IT FR similarity to ES 89% 85% 82% 75% <ref type="table">Table 2</ref>: Lexical similarities for Romance <ref type="bibr">(Lewis, 2009)</ref>.</p><p>We experiment on Catalan, French, Italian, Por- tuguese and Spanish. Tab. 2 shows that Spanish - which takes the role of the low-resource language in our experiments -is closely related with the other four, with Portuguese being most similar. We hypothesize that the transferability of morpholog- ical knowledge between source and target corre- sponds to the degree of lexical similarity; thus, we expect Portuguese and Catalan to be more benefi- cial for Spanish than Italian and French.</p><p>The Indo-European Slavic language family has its origin in eastern-central Europe <ref type="bibr" target="#b11">(Corbett and Comrie, 2003)</ref>. We experiment on Bulgar- ian, Macedonian, Russian and Ukrainian (Cyrillic script) and on Czech, Polish and Slovene (Latin script). Macedonian and Ukranian are low-resource languages, so we assign them the low-resource role. For Romance and for Uralic, we experiment with groups containing three or four source languages. To arrive at a comparable experimental setup for Slavic, we run two experiments, each with three source and one target language: (i) from Russian, Bulgarian and Czech to Macedonian; and (ii) from Russian, Polish and Slovene to Ukrainian.</p><p>We hope that the paradigm completor learns sim- ilar embeddings for, say, the characters "e" in Pol- ish and "" in Ukrainian. Thus, the use of two scripts in Slavic allows us to explore transfer across different alphabets.</p><p>We further consider a non-Indo-European lan- guage family, the Uralic languages. We exper- iment on the three most commonly spoken lan- guages -Finnish, Estonian and Hungarian (Abon- dolo, 2015) -as well as Northern Sami, a language used in Northern Scandinavia. While Finnish and Estonian are closely related (both are members of the Finnic subfamily), Hungarian is a more dis- tant cousin. Estonian and Northern Sami are low- resource languages, so we assign them the low- resource role, resulting in two groups of exper- iments: (i) Finnish, Hungarian and Estonian to Northern Sami; (ii) Finnish, Hungarian and North- ern Sami to Estonian.</p><p>Arabic (baseline) is a Semitic language (part of the Afro-Asiatic family <ref type="bibr" target="#b26">(Hetzron, 2013)</ref>) that is spoken in North Africa, the Arabian Peninsula and other parts of the Middle East. It is unrelated to all other languages used in this work. Both in terms of form (new words are mainly built using a tem- platic system) and categories (it has tags such as construct state), Arabic is very different. Thus, we do not expect it to support morphological knowl- edge transfer and use it as a baseline for all target languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We run four experiments on 21 distinct pairings of languages to show the feasibility of morphological transfer and analyze our method. We first discuss details common to all experiments.</p><p>We keep hyperparameters during all experi- ments (and for all languages) fixed to the following values. Encoder and decoder RNNs each have 100 hidden units and the size of all subtag, character and language embeddings is 300. For training we use ADADELTA <ref type="bibr" target="#b58">(Zeiler, 2012</ref>) with minibatch size 20. All models are trained for 300 epochs. Fol- lowing <ref type="bibr" target="#b33">Le et al. (2015)</ref>, we initialize all weights in the encoder, decoder and the embeddings except for the GRU weights in the decoder to the identity matrix. Biases are initialized to zero.</p><p>Evaluation metrics: (i) 1-best accuracy: the percentage of predictions that match the true an- swer exactly; (ii) average edit distance between prediction and true answer. The two metrics differ in that accuracy gives no partial credit and incorrect answers may be drastically different from the anno- tated form without incurring additional penalty. In contrast, edit distance gives partial credit for forms that are closer to the true answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Exp. 1: Transfer Learning for Paradigm Completion</head><p>In this experiment, we investigate to what extent our model transfers morphological knowledge from a high-resource source language to a low-resource target language. We experimentally answer three questions. (i) Is transfer learning possible for mor- phology? (ii) How much annotated data do we need in the low-resource target language? (iii) How closely related must the two languages be to achieve good results?</p><p>Data. Based on complete inflection tables from unimorph.org ( <ref type="bibr" target="#b32">Kirov et al., 2016)</ref>, we cre- ate datasets as follows. Each training set con- sists of 12,000 samples in the high-resource source 50·2 0 50·2 1 50·2 2 50·2 3 50·2 4 50·2 5 50·2 6 50·2 <ref type="bibr">7</ref> Number language and n t ∈{50, 200} samples in the low- resource target language. We create target lan- guage dev and test sets of sizes 1600 and 10,000, respectively. 3 For Romance and Arabic, we cre- ate learning curves for n t ∈{100, 400, 800, 1600, 3200, 6400, 12000}. Due to the data available to us, we use only verbs for the Romance and Uralic language families, but nouns, verbs and adjectives for the Slavic language family and Arabic. Lem- mata and inflections are randomly selected from all available paradigms. Results and Discussion. Tab. 3 shows the ef- fectiveness of transfer learning. There are two baselines. (i) "0": no transfer, i.e., we consider only in-domain data; (ii) "AR": Arabic, which is unrelated to all target languages.</p><p>With the exception of the 200 sample case of ET→SME, cross-lingual transfer is always better than the two baselines; the maximum improvement is 0.58 (0.58 vs. 0.00) in accuracy for the 50 sam- ple case of CA→ES. More closely related source languages improve performance more than distant ones. French, the Romance language least simi- lar to Spanish, performs worst for →ES. For the target language Macedonian, Bulgarian provides most benefit. This can again be explained by simi- larity: Bulgarian is closer to Macedonian than the other languages in this group. The best result for Ukrainian is <ref type="bibr">RU→UK</ref>  <ref type="table">Table 3</ref>: Accuracy (acc; the higher the better; indicated by ↑) and edit distance (ED; the lower the better; indicated by ↓) of cross-lingual transfer learning for paradigm completion. The target language is indicated by "→", e.g., it is Spanish for "→ES". Sources are indicated in the row "source"; "0" is the monolingual case. Except for Estonian, we train on n s = 12,000 source samples and n t ∈ {50, 200} target samples (as indicated by the row). There are two baselines in the table. (i) "0": no transfer, i.e., we consider only in-domain data; (ii) "AR": the Semitic language Arabic is unrelated to all target languages and functions as a dummy language that is unlikely to provide relevant information. All languages are denoted using the official codes (SME=Northern Sami).</p><p>the importance of the alphabet for transfer. Still, the results also demonstrate that transfer works across alphabets (although not as well); this sug- gests that similar embeddings for similar characters have been learned. Finnish is the language that is closest to Estonian and it again performs best as a source language for Estonian. For Northern Sami, transfer works least well, probably because the dis- tance between sources and target is largest in this case. The distance of the Sami languages from the Finnic (Estonian, Finnish) and Ugric (Hungar- ian) languages is much larger than the distances within Romance and within Slavic. However, even for Northern Sami, the worst performing language, adding an additional language is still always bene- ficial compared to the monolingual baseline.</p><p>Learning curves for Romance and Arabic fur- ther support our finding that language similarity is important. <ref type="figure" target="#fig_1">In Fig. 2</ref>, knowledge is transferred to Spanish, and a baseline -a model trained only on Spanish data -shows the accuracy obtained with- out any transfer learning. Here, Catalan and Italian help the most, followed by Portuguese, French and, finally, Arabic. This corresponds to the order of lexical similarity with Spanish, except for the per- formance of Portuguese (cf. Tab. 2). A possible explanation is the potentially confusing overlap of lemmata between the two languages -cf. dis- cussion in the next subsection. That the transfer learning setup improves performance for the unre- lated language Arabic as source is at first surprising. However, adding new samples to a small training set helps prevent overfitting (e.g., rote memoriza- tion) even if the source is a morphologically unre- lated language; effectively acting as a regularizer.</p><p>Following <ref type="bibr" target="#b31">(Kann and Schütze, 2016b</ref>) we did not use standard regularizers. To verify that the effect of Arabic is mainly a regularization effect, we ran a small monolingual experiment on ES (200 setting) with dropout 0.5 ( <ref type="bibr" target="#b48">Srivastava et al., 2014</ref>). The resulting accuracy is 0.57, very similar to the comparable Arabic number of 0.54 in the table.</p><p>The accuracy for dropout and 50 ES samples stays at 0.00, showing that in extreme low-resource set- tings an unrelated language might be preferable to a standard regularizer.</p><p>Error Analysis for Romance. Even for only 50 Spanish instances, many inflections are correctly produced in transfer. For, e.g., (criar, 3PlFutSbj) → criaren, model outputs are: fr: criaren, ca: criaren, es: crntaron, it: criaren, ar: ecriren, pt: criaren (all correct except for the two baselines). Many errors involve accents, e.g., (contrastar, 2Pl- FutInd) → contrastaréis; model outputs are: fr: con- trastareis, ca: contrastareis, es: conterarían, it: contrastareis, ar: contastarías, pt: contrastareis. Some inflected forms are produced incorrectly by all systems, mainly because they apply the inflec- tional rules of the source language directly to the target. Finally, the output of the model trained on Portuguese contains a class of errors that are unlike those of other systems. Example: (contraatacar, 1SgCond) → contraatacaría with the following so- lutions: fr: contratacaríam, ca: contraatacaría, es: concarnar, it: contratacé, ar: cuntataría and pt: contra-atacaría. The Portuguese model inserts "-" because Portuguese train data contains contraat- acar and "-" appears in its inflected form. Thus, it seems that shared lemmata between the high- resource source language and the low-resource tar- get language hurt our model's performance. <ref type="bibr">4</ref>   example for the generally improved performance across languages for 200 Spanish training samples is (contrastar, 2PlIndFut) → contrastaréis: all mod- els now produce the correct form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Exp. 2: Multiple Source Languages</head><p>We now want to investigate the effect of multiple source languages. Data. Our experimental setup is similar to §5.1: we use the same dev, test and low-resource train sets as before. However, we limit this experiment to the Romance language family and the high- resource train data consists of samples from two different source languages at once. Choosing those which have the highest accuracies on their own, we experiment with the following pairs: CA&amp;PT, as well as CA&amp;IT. In order to keep all experiments easily comparable, we use half of each source lan- guage's data, again ending up with a total of 12,000 high-resource samples.</p><p>Results and Discussion. Results are shown in Tab. 4. Training on two source languages improves over training on a single one. Increases in accuracy are minor, but edit distance is reduced by up to 0.13 (50 low-resource samples) and 0.08 (200 low- resource samples). That using data from multiple languages is beneficial might be due to a weaker tendency of the final model to adapt wrong rules from the source language, since different alterna- tives are presented during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Exp. 3: Zero-Shot/One-Shot Transfer</head><p>In §5.1, we investigated the relationship between in- domain (target) training set size and performance. Here, we look at the extreme case of training set sizes 1 (one-shot) and 0 (zero-shot) for a tag. We train our model on a single sample for half of the tags appearing in the low-resource language, i.e., training samples. Accuracy on test increases by 0.09 despite the reduced size of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">PT CA IT FR AR →ES</head><p>one shot acc ↑ 0.00 0.44 0.39 0.23 0.13 0.00 ED ↓ 6.26 1.01 1.27 1.83 2.87 7.00 zero shot acc ↑ 0.00 0.14 0.08 0.01 0.02 0.00 ED ↓ 7.18 1.95 1.99 3.12 4.27 7.50 <ref type="table">Table 5</ref>: Results for one-shot and zero-shot transfer learning. Formatting is the same as for Tab. 3. We still use n s = 12000 source samples. In the one- shot (resp. zero-shot) case, we observe exactly one form (resp. zero forms) for each tag in the target language at training time.</p><p>if T is the set of morphological tags for the target language, train set size is |T |/2. As before, we add 12,000 source samples. We report one-shot accuracy (resp. zero-shot ac- curacy), i.e., the accuracy for samples with a tag that has been seen once (resp. never) during train- ing. Note that the model has seen the individual subtags each tag is composed of. <ref type="bibr">5</ref> Data. Now, we use the same dev, test and high- resource train sets as in §5.1. However, the low- resource data is created in the way specified above. To remove a potentially confounding variable, we impose the condition that no two training samples belong to the same lemma.</p><p>Results and Discussion. Tab. 5 shows that the Spanish and Arabic systems do not learn anything useful for either half of the tags. This is not sur- prising as there is not enough Spanish data for the system to generalize well and Arabic does not contribute exploitable information. The systems trained on French and Italian, in contrast, get a non- zero accuracy for the zero-shot case as well as 0.13 and 0.23, respectively, in the one-shot case. This shows that a single training example is sometimes sufficient for successful generation although gener- alization to tags never observed is rarely possible. Catalan and Portuguese show the best performance in both settings; this is intuitive since they are the languages closest to the target (cf. Tab. 2). In fact, adding Portuguese to the training data yields an ab- solute increase in accuracy of 0.44 (0.44 vs. 0.00) for one-shot and 0.14 (0.14 vs. 0.00) for zero-shot with corresponding improvements in edit distance.</p><p>Overall, this experiment shows that with transfer learning from a closely related language the per-formance of zero-shot morphological generation improves over the monolingual approach, and, in the one-shot setting, it is possible to generate the right form nearly half the time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Exp. 4: True Transfer vs. Other Effects</head><p>We would like to separate the effects of regulariza- tion that we saw for Arabic from true transfer.</p><p>To this end, we generate a random cipher (i.e., a function γ : Σ ∪ S → Σ ∪ S) and apply it to all word forms and morphological tags of the high-resource train set; target language data are not changed. Ciphering makes it harder to learn true "linguistic" transfer of morphology. Consider the simplest case of transfer: an identical mapping in two languages, e.g., (visitar, 1SgPresInd) → visito in both Portuguese and Spanish. If we transform Portuguese using the cipher γ(iostv...) = kltqa..., then visito becomes aktkql in Portuguese and its tag becomes similarly unrecognizable as being iden- tical to the Spanish tag 1SgPresInd. Our intuition is that ciphering will disrupt transfer of morphol- ogy. <ref type="bibr">6</ref> On the other hand, the regularization effect we observed with Arabic should still be effective.</p><p>Data. We use the Portuguese-Spanish and Arabic-Spanish data from §5.1. We generate a ran- dom cipher and apply it to morphological tags and word forms for Portuguese and Arabic. The lan- guage tags are kept unchanged. Spanish is also not changed. For comparability with Tab. 3, we use the same dev and test sets as before.</p><p>Results and Discussion. Tab. 6 shows that per- formance of PT→ES drops a lot: from 0.48 to 0.09 for 50 samples and from 0.62 to 0.54 for 200 sam- ples. This is because there are no overt similarities between the two languages left after applying the cipher, e.g., the two previously identical forms vis- ito are now different.</p><p>The impact of ciphering on AR→ES varies: slightly improved in one case (0.54 vs. 0.56), slightly worse in three cases. We also apply the cipher to the tags and Arabic and Spanish share sub- tags, e.g., Sg. Just the knowledge that something is a subtag is helpful because subtags must not be generated as part of the output. We can explain the tendency of ciphering to decrease performance on AR→ES by the "masking" of common subtags. <ref type="bibr">6</ref> Note that ciphered input is much harder than transfer between two alphabets (Latin/Cyrillic) because it creates am- biguous input. In the example, Spanish "i" is totally different from Portuguese "i" (which is really "k"), but the model must use the same representation.  <ref type="table">Table 6</ref>: Results for ciphering. "0→ES" and "orig" are original results, copied from Tab. 3; "ciph" is the result after the cipher has been applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>0→ES</head><p>For 200 samples and ciphering, there is no clear difference in performance between Portuguese and Arabic. However, for 50 samples and ciphering, Portuguese (0.09) seems to perform better than Ara- bic (0.02) in accuracy. Portuguese uses suffixation for inflection whereas Arabic is templatic and in- flectional changes are not limited to the end of the word. This difference is not affected by ciphering. Perhaps even ciphered Portugese lets the model learn better that the beginnings of words just need to be copied. For 200 samples, the Spanish dataset may be large enough, so that ciphered Portuguese no longer helps in this regard.</p><p>Comparing no transfer with transfer from a ci- phered language to Spanish, we see large perfor- mance gains, at least for the 200 sample case: 0.38 (0→ES) vs. 0.54 (PT→ES) and 0.56 (AR→ES). This is evidence that our conjecture is correct that the baseline Arabic mainly acts as a regularizer that prevents the model from memorizing the training set and therefore improves performance. So per- formance improves even though no true transfer of morphological knowledge takes place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Cross-lingual transfer learning has been used for many tasks, e.g., automatic speech recognition ( <ref type="bibr" target="#b27">Huang et al., 2013</ref>), parsing <ref type="bibr" target="#b9">(Cohen et al., 2011;</ref><ref type="bibr" target="#b47">Søgaard, 2011;</ref><ref type="bibr" target="#b37">Naseem et al., 2012;</ref><ref type="bibr" target="#b3">Ammar et al., 2016)</ref>, language modeling ( , entity recognition ( <ref type="bibr" target="#b55">Wang and Manning, 2014b</ref>) and machine translation <ref type="bibr" target="#b28">(Johnson et al., 2016;</ref><ref type="bibr" target="#b24">Ha et al., 2016)</ref>.</p><p>One straightforward method is to translate datasets and then train a monolingual model <ref type="bibr" target="#b21">(Fortuna and Shawe-Taylor, 2005;</ref><ref type="bibr" target="#b39">Olsson et al., 2005</ref>). Also, aligned corpora have been used to project information from annotations in one language to another <ref type="bibr" target="#b57">(Yarowsky et al., 2001;</ref><ref type="bibr" target="#b40">Padó and Lapata, 2005</ref>). The drawback is that machine translation errors cause errors in the target. Therefore, alter- native methods have been proposed, e.g., to port a model trained on the source language to the target language ( <ref type="bibr" target="#b44">Shi et al., 2010</ref>).</p><p>In the realm of morphology, <ref type="bibr" target="#b5">Buys and Botha (2016)</ref> recently adapted methods for the training of POS taggers to learn weakly supervised mor- phological taggers with the help of parallel text. <ref type="bibr">Barzilay (2008a, 2008b</ref>) developed a non-parametric Bayesian model for morpholog- ical segmentation. They performed identification of cross-lingual abstract morphemes and segmen- tation simultaneously and reported, similar to us, best results for related languages.</p><p>Work on paradigm completion has recently been encouraged by the SIGMORPHON 2016 shared task on morphological reinflection <ref type="bibr">(Cotterell et al., 2016a</ref>). Some work first applies an unsupervised alignment model to source and tar- get string pairs and then learns a string-to-string mapping <ref type="bibr" target="#b17">(Durrett and DeNero, 2013;</ref><ref type="bibr" target="#b38">Nicolai et al., 2015)</ref>, using, e.g., a semi-Markov conditional ran- dom field ( <ref type="bibr" target="#b42">Sarawagi and Cohen, 2004</ref>). Encoder- decoder RNNs ( <ref type="bibr" target="#b1">Aharoni et al., 2016;</ref><ref type="bibr" target="#b31">Kann and Schütze, 2016b</ref>), a method which our work further develops for the cross-lingual sce- nario, define the current state of the art.</p><p>Encoder-decoder RNNs were developed in par- allel by <ref type="bibr" target="#b7">Cho et al. (2014)</ref> and  for machine translation and extended by <ref type="bibr" target="#b4">Bahdanau et al. (2015)</ref> with an attention mechanism, support- ing better generalization. They have been applied to NLP tasks like speech recognition ( <ref type="bibr" target="#b23">Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b22">Graves et al., 2013</ref>), parsing <ref type="bibr" target="#b53">(Vinyals et al., 2015</ref>) and segmentation ( <ref type="bibr" target="#b29">Kann et al., 2016)</ref>.</p><p>More recently, a number of papers have used encoder-decoder RNNs in multitask and transfer learning settings; this is mainly work in machine translation: <ref type="bibr" target="#b16">(Dong et al., 2015;</ref><ref type="bibr" target="#b59">Zoph and Knight, 2016;</ref><ref type="bibr" target="#b8">Chu et al., 2017;</ref><ref type="bibr" target="#b28">Johnson et al., 2016;</ref><ref type="bibr" target="#b35">Luong et al., 2016;</ref><ref type="bibr" target="#b20">Firat et al., 2016;</ref><ref type="bibr" target="#b24">Ha et al., 2016)</ref>, inter alia. Each of these papers has both similar- ities and differences with our approach. (i) Most train several distinct models whereas we train a single model on input augmented with an explicit encoding of the language (similar to <ref type="bibr" target="#b28">(Johnson et al., 2016)</ref>). (ii) Let k and m be the number of dif- ferent input and output languages. We address the case k ∈ {1, 2, 3} and m = k. Other work has addressed cases with k &gt; 3 or m &gt; 3; this would be an interesting avenue of future research for paradigm completion. (iii) Whereas training RNNs in machine translation is hard, we only expe- rienced one difficult issue in our experiments (due to the low-resource setting): regularization. (iv) Some work is word-or subword-based, our work is character-based. The same way that similar word embeddings are learned for the inputs cow and vache (French for "cow") in machine translation, we expect similar embeddings to be learned for sim- ilar Cyrillic/Latin characters. (v) Similar to work in machine translation, we show that zero-shot (and, by extension, one-shot) learning is possible.</p><p>( <ref type="bibr" target="#b24">Ha et al., 2016</ref>) (which was developed in par- allel to our transfer model although we did not prepublish our paper on arxiv) is most similar to our work. Whereas <ref type="bibr" target="#b24">Ha et al. (2016)</ref> address ma- chine translation, we focus on the task of paradigm completion in low-resource settings and establish the state of the art for this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a cross-lingual transfer learning method for paradigm completion, based on an RNN encoder-decoder model. Our experiments showed that information from a high-resource language can be leveraged for paradigm completion in a related low-resource language. Our analysis indicated that the degree to which the source language data helps for a certain target language depends on their re- latedness. Our method led to significant improve- ments in settings with limited training data -up to 58% absolute improvement in accuracy -and, thus, enables the use of state-of-the-art models for paradigm completion in low-resource languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Future Work</head><p>In the future, we want to develop methods to make better use of languages with different alphabets or morphosyntactic features, in order to increase the applicability of our knowledge transfer method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 shows the encoder-decoder. See Bahdanau et al. (2015) for further details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning curves showing the accuracy on Spanish test when training on language λ ∈ {PT, CA, IT, FR, AR, ES}. Except for λ=ES, each model is trained on 12,000 samples from λ and "Number of Samples" (x-axis) of Spanish.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. Unlike Polish and Slowe- nian, Russian is the only language in this group that uses the same script as Ukrainian, showing</figDesc><table>Romance 

Slavic I 
Slavic II 
Uralic I 
Uralic II 
source 
0 AR PT CA IT FR 
0 AR RU BG CS 
0 AR RU PL SL 
0 AR FI HU ET 
0 AR FI HU SME 
target 
→ES 
→MK 
→UK 
→SME 
→ET 

50 
acc ↑ 0.00 0.04 0.48 0.58 0.46 0.29 0.00 0.00 0.23 0.47 0.13 0.01 0.01 0.47 0.16 0.07 0.00 0.01 0.07 0.05 0.03 0.02 0.01 0.35 0.21 0.17 
ED ↓ 5.42 4.06 0.85 0.80 1.15 1.82 5.71 5.59 1.61 0.87 2.32 5.23 4.80 0.77 2.14 3.12 6.21 5.47 2.88 3.46 3.71 4.50 4.51 1.55 2.19 2.60 
200 
acc ↑ 0.38 0.54 0.62 0.78 0.74 0.60 0.21 0.40 0.62 0.77 0.57 0.16 0.21 0.64 0.55 0.50 0.13 0.24 0.26 0.28 0.13 0.34 0.53 0.74 0.71 0.66 
ED ↓ 1.37 0.87 0.57 0.39 0.44 0.82 1.93 1.12 0.68 0.36 0.72 2.09 1.60 0.49 0.73 0.82 2.94 1.89 1.78 1.61 2.46 1.47 0.98 0.41 0.48 0.62 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results for transfer from pairs of source 
languages to ES. Results from single languages are 
repeated for comparison. 

</table></figure>

			<note place="foot" n="1"> The SIGMORPHON 2016 shared task (Cotterell et al., 2016a) on morphological reinflection, a harder generalization of paradigm completion, found that ≥ 98% accuracy can be achieved in many languages with neural sequence-to-sequence models, improving the state of the art by 10%.</note>

			<note place="foot" n="3"> For Estonian, we use 7094 (not 12,000) train and 5000 (not 10,000) test samples as more data is unavailable.</note>

			<note place="foot" n="4"> To investigate this in more detail we retrain the Portuguese model with 50 Spanish samples, but exclude all lemmata that appear in Spanish train/dev/test, resulting in only 3695</note>

			<note place="foot" n="5"> It is very unlikely that due to random selection a subtag will not be in train; this case did not occur in our experiments.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their insightful comments. We are grateful to Siemens and Volkswagenstiftung for their generous support. This research would not have been possi-ble without the organizers of the SIGMORPHON shared task, especially John Sylak-Glassman and Christo Kirov, who created the resources we use.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Uralic Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Abondolo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving sequence to sequence learning for morphological inflection generation: The BIU-MIT systems for the SIGMORPHON 2016 shared task for morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMORPHON</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of morphological paradigms and lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malin</forename><surname>Ahlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Markus Forsberg, and Mans Hulden</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>EACL</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Many languages, one parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="431" to="444" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cross-lingual morphological tagging for low-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation: Encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An empirical comparison of simple domain adaptation methods for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhui</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Dabre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
		<idno>1701.03214</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised structure prediction with non-parallel multilingual guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Shay B Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greville</forename><surname>Corbett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Comrie</surname></persName>
		</author>
		<title level="m">The Slavonic Languages. Routledge</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Jason Eisner, and Mans Hulden. 2016a. The SIGMORPHON 2016 shared taskmorphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMORPHON</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling word forms using latent underlying morphs and phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="433" to="447" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Morphological smoothing and extrapolation of word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analysis of morph-based speech recognition and the modeling of out-ofvocabulary words across languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Hirsimäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Puurula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Pylkkönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Siivola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Varjokallio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACLHLT</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Ebru Arisoy, Murat Saraçlar, and Andreas Stolcke</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-task learning for multiple language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Supervised learning of complete morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generalizing word lattice translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Morphological inflection generation using character sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Multi-way, multilingual neural machine translation with a shared attention mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>CoRR abs/1601.01073</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The use of machine translation tools for cross-lingual text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaz</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Learning with Multiple Views</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Abdel-Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>In IEEE</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Toward multilingual neural machine translation with universal encoder and decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Le</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Waibel</surname></persName>
		</author>
		<idno>1611.04798</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Romance languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The Semitic Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hetzron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cross-language knowledge transfer using multilingual deep neural network with shared hidden layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Google&apos;s multilingual neural machine translation system: Enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><forename type="middle">B</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Macduff</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<idno>CoRR abs/1611.04558</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural morphological analysis: Encodingdecoding canonical segments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Singlemodel encoder-decoder with explicit morphological representation for reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MED: The LMU system for the SIGMORPHON 2016 shared task on morphological reinflection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Very-large scale parsing and normalization of wiktionary morphological paradigms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Que</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A simple way to initialize recurrent networks of rectified linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>CoRR abs/1504.00941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Ethnologue: Languages of the World. SIL International</title>
		<editor>M Paul Lewis</editor>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>16 edition</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-task sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Morphological segmentation for keyword spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damianos</forename><surname>Karakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stavros</forename><surname>Tsakalidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Selective sharing for multilingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Inflection generation as discriminative string transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrett</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cross-language text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Scott Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGIR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Crosslinguistic projection of role-semantic information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<editor>HLT/EMNLP</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A universal part-of-speech tagset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semimarkov conditional random fields for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A graphbased lattice dependency parser for joint morphological segmentation and syntactic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cross language text classification by model translation and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjun</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Crosslingual propagation for morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Unsupervised multilingual learning for morphological segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<editor>ACL-HLT</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Data point selection for crosslanguage adaptation of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACLHLT</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In NIPS</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The composition and use of the universal morphological feature schema (unimorph schema)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A language-independent feature schema for inflectional morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Que</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACLIJCNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Polyglot neural language models: A case study in cross-lingual phonetic representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunayana</forename><surname>Sitaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mortensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Cross-lingual projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Cross-lingual pseudo-projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Corpus-level fine-grained entity typing using contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Inducing multilingual text analysis tools via robust projection across aligned corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">ADADELTA: an adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno>CoRR abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multi-source neural translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
