<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Convolutional and Recurrent Neural Networks in Sequential Labelling for Dialogue Topic Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokhwan</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Department Institute for Infocomm Research</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Department Institute for Infocomm Research</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Department Institute for Infocomm Research</orgName>
								<address>
									<postCode>138632</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Convolutional and Recurrent Neural Networks in Sequential Labelling for Dialogue Topic Tracking</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="963" to="973"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Dialogue topic tracking is a sequential labelling problem of recognizing the topic state at each time step in given dialogue sequences. This paper presents various artificial neural network models for dialogue topic tracking, including convolutional neural networks to account for semantics at each individual utterance, and recurrent neural networks to account for conversational contexts along multiple turns in the dialogue history. The experimental results demonstrate that our proposed models can significantly improve the tracking performances in human-human conversations.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A human conversation often involves a series of multiple topics contextually related to each other. In this scenario, every participant in the conversa- tion is required to understand the on-going topic discussed at each moment, detect any topic shift made by others, and make a decision to self- initiate a new topic. These human capabilities for handling topics are also expected from dialogue systems to achieve natural and human-like conver- sations.</p><p>Many studies have been conducted on multi- domain or multi-task dialogue systems by means of sentence-level topic identification as a sub- task of natural language understanding ( <ref type="bibr">Lin et al., 1999;</ref><ref type="bibr">Nakata et al., 2002;</ref><ref type="bibr" target="#b21">Lagus and Kuusisto, 2002;</ref><ref type="bibr" target="#b0">Adams and Martell, 2008;</ref><ref type="bibr" target="#b11">Ikeda et al., 2008;</ref><ref type="bibr" target="#b4">Celikyilmaz et al., 2011</ref>). In these ap- proaches, a given user input at each turn is cate- gorized into topic classes, each of which triggers the corresponding sub-system specializing in the particular topic. Despite many previous efforts, the sentence categorization methods still have the following limitations. Firstly, the effectiveness of the approaches is limited only in user-initiative conversations, because the categorization is per- formed mainly based on the user's input men- tioned at a given turn. Secondly, no correlation be- tween different topics is considered neither in the topic decision process nor in each topic-specific sub-system operated independently from the oth- ers. Lastly, the conversational coherence in a given dialogue history sequence has limited effects on determining the current topic.</p><p>Another direction for multi-topic dialogue sys- tems has been towards utilizing human knowledge represented in domain models <ref type="bibr">(Roy and Subramaniam, 2006</ref>) and agendas <ref type="bibr" target="#b3">(Bohus and Rudnicky, 2003;</ref><ref type="bibr" target="#b24">Lee et al., 2008</ref>). The knowledge-based approaches make the system capable of having more control of dialogue flows including topic se- quences. This aspect contributes to better deci- sions of topics in system-initiative cases, but it can adversely affect the flexibility to deal with un- expected inputs against the system's suggestions. Moreover, the high cost of building the required resources is another problem that these methods face from a practical point of view.</p><p>Recently, some researchers ( <ref type="bibr">Morchid et al., 2014a;</ref><ref type="bibr">Morchid et al., 2014b;</ref><ref type="bibr" target="#b9">Esteve et al., 2015)</ref> have worked on topic identification for analyzing human-human dialogues. Although they don't aim at building components in dialogue systems di- rectly, the human behaviours learned from the con- versations can suggest directions for further ad- vancement of conversational agents. However, the problem defined in the studies is under the as- sumption that every dialogue session is assigned with just a single theme category, which means any topic shift occurred in a session is left out of consideration in the analyses.</p><p>On the other hand, we previously addressed the problem of detecting multiple topic transitions in mixed-initiative human-human conversations, which is called dialogue topic tracking <ref type="bibr" target="#b15">(Kim et al., 2014a;</ref><ref type="bibr" target="#b16">Kim et al., 2014b</ref>). In these studies, the tracking task is formulated as a classification problem for each utterance-level, similar to the sentence categorization approaches. But the target of the classification is not just an individual topic category to which each input sentence belongs, but the decision whether a topic transition occurs at a given turn as well as what the most probable topic category will follow after the transition.</p><p>This paper presents our work also on dialogue topic tracking mainly focusing on the following is- sues. Firstly, in addition to transitions between di- alogue segments from different topics, transitions between segments belonging to the same topic are also detected. This focuses the task more on de- tailed aspects of topic handling that are relevant to other subtasks such as natural language under- standing and dialogue state tracking, rather than the conventional tracking of changes in topic cat- egories only. Another contribution of this work is that we introduce a way to use convolutional neu- ral networks in topic tracking to improve the clas- sification performances with the learned convolu- tional features. In addition, we also propose the architectures based on recurrent neural networks to incorporate the temporal coherence that has not played an important role in previous approaches.</p><p>The remainder of this paper is structured as fol- lows. We present a problem definition of dialog topic tracking in Section 2. We describe our pro- posed approaches to this task using convolutional and recurrent neural networks in Section 3. We report the evaluation result of the methods in Sec- tion 4 and conclude this paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dialogue Topic Tracking</head><p>Dialogue topic tracking is defined as a multi-class classification problem to categorize the topic state at each time step into the labels encoded in BIO tagging scheme <ref type="bibr">(Ramshaw and Marcus, 1995)</ref> as follows:</p><formula xml:id="formula_0">f (t) =            B-{c ∈ C} if u t is at the beginning</formula><p>of a segment belongs to c, I-{c ∈ C} else if u t is inside a segment belongs to c, O otherwise, where u t is the t-th utterance in a given dialogue session and C is a closed set of topic categories. <ref type="table" target="#tab_5">How can I help you?  B-OPEN  2  Tourist  Can you recommend some good places to  visit in Singapore?  B-ATTR   3  Guide  Well if you like to visit an icon of Singa- pore, Merlion will be a nice place to visit.  I-ATTR   4  Tourist  Okay. But I'm particularly interested in  amusement parks.  B-ATTR   5  Guide  Then, what about Universal Studio?  I-ATTR  6  Tourist  Good! How can I get there</ref>   <ref type="figure">Figure 1</ref>: Examples of dialogue topic tracking on a tour guide dialogue labelled with BIO tags. ATTR, TRSP and FOOD denotes the topic categories of attraction, transportation, and food, respectively. <ref type="figure">Figure 1</ref> shows an example of topic tracking on a dialogue fragment between a tour guide and a tourist. Since each tag starting with 'B' should oc- cur at the beginning of a new segment after a topic transition from its previous one, the label sequence indicates that this conversation is divided into six segments at t = {2, 4, 6, 11, 13}. The initiativity of each segment can be also found from who the speaker of the first utterance of the segment is. In this example, three of the cases are initiated by the tourist at t = {2, 4, 6}, but the others are leaded by the tour guide, which means it is a mixed-initiative type of conversation.</p><formula xml:id="formula_1">t Speaker Utterance (ut) f (t) 1 Guide</formula><p>Different from the former studies ( <ref type="bibr" target="#b15">Kim et al., 2014a;</ref><ref type="bibr" target="#b16">Kim et al., 2014b</ref>) that were only fo- cused on detecting transitions between different topic categories, this work subdivides each dia- logue sequence which belongs to a single topic category, but discusses more than one subject that can be more specifically differentiated from each other. The above example also has two cases of transitions with no change of topic categories at t = {4, 11}: the first one is due to the tourist's re- quest for an alternative attraction from the recom- mendation in the previous segment, and the other transition is triggered by the tour guide to sug- gest another option of transportation which is also available for the route discussed previously.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models</head><p>The classifier f can be built with supervised ma- chine learning techniques, when a set of exam- ple dialogues manually annotated with gold stan- dard labels are available as a training set. The earlier studies <ref type="bibr" target="#b15">(Kim et al., 2014a;</ref><ref type="bibr" target="#b16">Kim et al., 2014b</ref>) also proposed supervised classification ap- proaches particularly focusing on kernel methods to incorporate domain knowledge obtained from external resources into the linear vector space models based on bag-of-words features extracted from the training dialogues.</p><p>This work, on the other hand, aims at improving the classification capabilities only with the inter- nal contents in given dialogues rather than making better uses of external knowledge. To overcome the limitations of the simple vector space mod- els used in the previous work, we propose models based on convolutional and recurrent neural net- work architectures. These models are presented in the remainder of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Convolutional Neural Networks</head><p>A convolutional neural network (CNN) automat- ically learns the filters in its convolutional layers which are applied to extract local features from inputs. Then, these lower-level features are com- bined into higher-level representations following a given network architecture. These aspects of CNNs make themselves a good fit to solve the problems which are invariant to the location where each feature is extracted on its input space and also depend on the compositional relationships between local and global features, which is the reason why CNNs have succeed in computer vi- sion ( <ref type="bibr" target="#b23">LeCun et al., 1998)</ref>. As implied by the successes of bag-of-words or bag-of-ngrams con- sidering the existence of each linguistic unit in- dependently and the important roles of composi- tional structures in linguistics, CNN models have recently achieved significant improvements also in some natural language processing tasks <ref type="bibr" target="#b5">(Collobert et al., 2011;</ref><ref type="bibr">Shen et al., 2014;</ref><ref type="bibr">Yih et al., 2014;</ref><ref type="bibr" target="#b13">Kalchbrenner et al., 2014a;</ref><ref type="bibr" target="#b19">Kim, 2014</ref>).</p><p>The model for dialogue topic tracking (  <ref type="bibr" target="#b19">Kim (2014)</ref> for sentence classification tasks. In the architecture, a sentence of length n is repre- sented as a matrix with the size of n × k con- catenated with n rows each of which is the k- dimensional word vector x i ∈ R k representing the i-th word in the sentence. This embedding layer can be learned from scratch with random initial- ization or fine-tuned from pre-trained word vec- tors ( <ref type="bibr">Mikolov et al., 2013</ref>) with back propagation during training the network.</p><p>Unlike other sentence classification tasks, dia- logue topic tracking should consider not only a single sentence given at each time step, but also the other utterances previously mentioned. To in- corporate the dependencies to the dialogue his- tory into the topic tracking model, the input at the time step t is composed of three different chan- nels each of which represents the current utterance u t , the previous utterance u t−1 , and the other ut- terances u t−h+1:t−2 within h time steps, respec- tively, where u t is the t-th utterance in a session, u i:j is the concatenation of the utterances occurred from the i-th to the j-th time steps in the history, and h is the size of history window. The height of the n × k matrices of the first two channels for the current and previous utterances is fixed to the length of the longest utterance in the whole train- ing dataset, and then all the remaining rows after the end of each utterance are zero-padded to make all inputs same size. Since the other channel is made up by concatenating the utterances from the (t − h + 1)-th to the (t − 2)-th time steps, it has a matrix with the dimension of ((h − 2) · n) × k where all the gaps between contiguous utterances in the matrix are filled with zero.</p><p>In the convolutional layer, each filter F ∈ R km which has the same width k as the input matrix and a given window size m as its height slides over from the first row to the (n − m + 1)-th row of the input matrix. At the i-th position, the filter is applied to generate a feature c i = g (F · x i:i+m−1 + b), where x i:j is the subregion from the i-th row to the j-th row in the input, b ∈ R is a bias term, and g is a non-linear acti- vation function such as rectified linear units. This series of convolution operations produces a feature map c = [c 1 · · · c n−m+1 ] ∈ R n−m+1 for the fil- ter F. Then, the maximum value c = max( c) is selected from each feature map considered as the most important feature for the particular filter in the max-pooilng layer.</p><p>Every filter is shared across all the three differ- ent channels, but both the convolution and max- pooling operations are performed individually for each channel. Thus, the total number of feature values generated in the pooling layer is three times the number of filters. Finally, these values are for- warded to the fully-connected layer with softmax which generates the probabilistic distribution over the topic labels for a given input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Recurrent Neural Networks</head><p>Dialogue topic tracking is conceptually performed on a sequence of interactions exchanged by the participants in a given session from its beginning to each turn. Thus, the contents discussed previ- ously in the dialogue history are likely to have an important influence on tracking the current topic at a given turn, which is a fundamental difference from other text categorization problems that con- sider each input independently from all others.</p><p>To make use of the sequential dependencies in dialogue topic tracking, we propose the models based on recurrent neural networks (RNN) which learn the temporal dynamics by recurrent compu- tations applied to every time step in a given in-   put sequence. In a traditional RNN, hidden states connecting between input sequences and output labels are repeatedly updated with the operation</p><formula xml:id="formula_2">s t = g(U x t + W s t−1 )</formula><p>, where x t is the t-th ele- ment in a given input sequence, s t ∈ R |s| is the hidden state at t with |s| hidden units, and g is a non-linear activation function. The parameters U and W are shared all the time steps.</p><p>RNNs have been successfully applied to several natural language processing tasks including lan- guage modeling ( <ref type="bibr">Mikolov et al., 2010</ref>), text gener- ation <ref type="bibr">(Sutskever et al., 2011</ref>), and machine trans- lation ( <ref type="bibr" target="#b1">Auli et al., 2013;</ref><ref type="bibr">Liu et al., 2014</ref>), all of which focus on dealing with variable length word sequences. On the other hand, an input sequence to be handled in dialogue topic tracking is com- posed of utterance-level units instead of words.</p><p>In our model <ref type="figure" target="#fig_4">(Figure 3</ref>), each utterance is rep- resented by the k-dimensional vector u t ∈ R k assigned with pre-trained sentence-level embed- dings ( <ref type="bibr" target="#b22">Le and Mikolov, 2014)</ref>. And then, a se- quence of the utterance vectors within h time steps are connected in the recurrent layers. The de- fault sequence of applying the recurrent operation is the ascending order from the former to the re- cent utterances, which is performed in the forward layer. But the opposite direction can be also con- sidered in the backward layer which is stacked on top of the forward layer to build a bidirectional RNN ( <ref type="bibr">Schuster and Paliwal, 1997</ref>) which outputs the concatenation of both forward and backward states as an outcome of the recurrent operations. Then, these hidden states from the recurrent lay- ers are passed to the fully-connected softmax layer to generate the output distributions for every time step in the sequence.</p><formula xml:id="formula_3">… Inputs … ut-1 ut ut-2 ut-h+1</formula><p>Convolutional layer</p><p>Forward layer</p><formula xml:id="formula_4">s f t-1 s f t s f t-2 s f t-h+1</formula><p>Backward layer</p><formula xml:id="formula_5">s b t-1 s b t s b t-2 s b t-h+1</formula><p>Output labels</p><formula xml:id="formula_6">yt-1 yt yt-2 yt-h+1</formula><p>Max pooling layer The output from the model at a given time step t is a label sequence [y t−h+1 , · · · , y t ] for the recent h utterances. Since the labels for the earlier utter- ances should have been already decided at the cor- responding turns, only y t is taken as the final out- come for the current time step. The hypothesis to be examined with this model is whether the other h − 1 predictions that are not directly reflected to the results could help to improve the tracking per- formances by being considered together in the pro- cess of determining the current topic status.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Recurrent Convolutional Networks</head><p>The last approach proposed in this work aims at combining the two models described in the previ- ous sections. In this model <ref type="figure" target="#fig_5">(Figure 4)</ref>, each feature vector generated through the embedding, convolu- tional, and max pooling layers in the CNN net- work (Section 3.1) is connected to the recurrent layers in the RNN model <ref type="bibr">(Section 3.2)</ref>. This com- bination is expected to play a significant role in overcoming the limitations of the sentence-level embedding considered as a feature representation in the RNN model. While the previous approach depends only on a pre-trained and non-tunable em- bedding model, all the parameters in the com- bined network can be fine-tuned with back prop- agation by considering the convolutional features extracted at each time step and also the tempo- ral dependencies occurred through multiple time steps in given dialogue sequences.</p><p>In computer vision, this kind of models con- necting RNNs on top of CNNs is called recurrent convolutional neural networks (RCNN), which have been mostly used for exploring the dependen- cies between local convolutional features within a single image ( <ref type="bibr">Pinheiro and Collobert, 2014;</ref><ref type="bibr">Liang and Hu, 2015)</ref>. Recently, they are also applied in video processing ( <ref type="bibr" target="#b8">Donahue et al., 2015</ref>) where vi- sual features are extracted from the image at each frame using CNNs and the temporal aspects are learned with RNNs from the frame sequence of an input video. Our proposed model for dialogue topic tracking was originally motivated by this success of RCNNs particularly in video recogni- tion considering that video and dialogue are anal- ogous from the structural point of view. Each in- stance of a video and a dialogue consists of a tem- poral sequence of static units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>To demonstrate the effectiveness of our proposed models, we performed experiments on TourSG corpus released for the fourth dialogue state track- ing challenge (DSTC4) ( <ref type="bibr" target="#b18">Kim et al., 2016</ref>). The dataset consists of 35 dialogue sessions collected from human-human conversations about tourism in Singapore between tour guides and tourists. All the dialogues have been manually transcribed and annotated with the labels for the challenge tasks. For the multi-topic dialogue state tracking which is the main task of the challenge, each dialogue session is divided into sub-dialogues and each seg- ment is assigned with its topic category. Since the task particularly focuses on filling out the topic- specific frame structure with the detailed infor- mation representing the dialogue states of a given segment, it has been performed under the assump- tion that the manual annotations for both segmen- tations and topic categories are provided as parts of every input. But, in this work for dialogue topic tracking, these labels are considered as the targets to be generated automatically by the models.</p><p>Every segment in the dataset belongs to one of eight topic categories. Following the nature of the tourism domain, the 'attraction' category accounts for the highest portion at 40.12% of the segments, which is followed by 'transportation', 'food', 'ac- commodation', 'shopping', 'closing' and 'open- ing' in order according to decreasing frequencies. The other 10.53% considered as beyond the scope of the task are annotated with 'other'. <ref type="figure" target="#fig_7">Figure 5</ref> shows the distributions of the segments by not only the topic categories, but also the transi- tion types from two different points of views: the first one is which speaker initiates each segment, and the other is whether the segmentation causes  Guide-initiative/Intra-categorical Tourist-initiative/Intra-categorical Guide-initiative/Inter-categorical Tourist-initiative/Inter-categorical  For our experiments, all these segment-level an- notations were converted into utterance-level BIO tags each of which belongs to one of 15 classes: ({B-, I-} × {c : c ∈ C; and c = 'other'}) ∪ {O}, where C consists of all the eight topic categories. The partition of the dataset <ref type="table" target="#tab_3">(Table 1)</ref> have been kept the same as the one used for the state track- ing task in DSTC4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models</head><p>Based on the dataset, we built 16 different models classified into the following five model families.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Baseline 1: Support Vector Machines</head><p>The first baseline uses support vector machine (SVM) <ref type="bibr" target="#b6">(Cortes and Vapnik, 1995</ref>) models trained with the following features:</p><p>• BoN t : bag of uni/bi/tri-grams in u t weighted by tf-idf which is the product of term fre- quency in u t and inverse document frequency across all the training utterances.</p><p>• BoN t−1 : bag of n-grams computed in the same way as BoN t for the previous utterance.</p><p>• BoN history = h j=0 λ j · BoN j : weighted sum of n-gram vectors in the recent h = 10 utterances with a decay factor λ = 0.9.</p><p>• SPK t , SPK t−1 : speakers of the current and the previous utterances.</p><p>• SPK {t−1,t} : bi-gram of SPK t and SPK t−1 .</p><p>Another variation replaces the bag of n-grams with the utterance-level neural embeddings inferred by the pre-trained 300 dimensional doc2vec ( <ref type="bibr" target="#b22">Le and Mikolov, 2014</ref>) model on 2.9M sentences with 37M words in 553k Singapore-related posts col- lected from travel forums. Then, the third model takes the concatenation of both bag of n-grams and doc2vec features. All three baselines were implemented based on the one-against-all approach with the same number of binary classifiers as the total num- ber of classes for multi-label classification. SVM light (Joachims, 1999) was used for building each binary classfier with the linear kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Baseline 2: Conditional Random Fields</head><p>To incorporate the temporal aspects also into the linear models, conditional random fields (CRFs) ( <ref type="bibr" target="#b20">Lafferty et al., 2001</ref>) which have been successfully applied for other sequential labelling problems were used for the second set of base- lines. Similar to our proposed RNN architec- ture (Section 3.2), the recent utterances occurred within the window size of h = 10 composed the first-order linear-chain CRFs. Three CRF models were built using CRFsuite <ref type="bibr">(Okazaki, 2007)</ref> with the same feature sets as in the SVM models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">CNN-based models</head><p>For the CNN architecture (Section 3.1), we com- pared two different models: the first one learned the word embeddings from scratch with ran- dom parameters, while the other was initialized with word2vec ( <ref type="bibr">Mikolov et al., 2013</ref>) trained on the same dataset for the doc2vec model in Sec- tion 4.2.1. Both approaches generated a dense vec- tor with a dimension of k = 300 for each word in utterances. Then, the embedded vectors were con- catenated into three matrices representing the cur- rent, previous, and history utterances, respectively. While the first two channels for a single utterance, u t or u t−1 , had a size of 65 × 300 according to the maximum number of words n = 65 in the training utterances, the number of rows in the other matrix was 520 which is eight times as large as the oth- ers to represent the history utterances from u t−9 to u t−2 where h = 10.</p><p>In the convolutional layer, 100 feature maps were learned for each of three different filter sizes m = {3, 4, 5} by sliding them over the utterances, which produced 900 feature values in total after the max-pooling operations for all three channels. In addition to these learned features, SPK t and SPK t−1 values introduced in Section 4.2.1 were appended to each feature vector to take the speaker information into account as in the baselines. Be- fore the fully-connected layer, dropout was per- formed with the rate of 0.25 for regularization. And then, training was done with stochastic gra- dient descent (SGD) by minimizing categorical cross entropy loss on the training set.</p><p>All the neural network-based models in this work were implemented using Theano ( <ref type="bibr" target="#b2">Bergstra et al., 2010</ref>) with the parameters obtained from the grid search on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">RNN and RCNN-based models</head><p>Each proposed recurrent network (Section 3.2 and 3.3) was implemented with four variations categorized by whether the backward layer is in- cluded in each model or not and also which ar- chitecture is used in the recurrent layers between traditional RNNs and long short-term memories (LSTMs) <ref type="bibr" target="#b10">(Hochreiter and Schmidhuber, 1997)</ref>. The RCNN models based on LSTMs are particu- larly called long-term recurrent convolutional net- works (LRCN) ( <ref type="bibr" target="#b8">Donahue et al., 2015</ref>). All the RCNN-based models were initialized with the pre- trained word2vec model in the training phase.</p><p>The dimension of the hidden layers of the recur- rent cells was chosen to be |s| = 500 based on the development set. And the other settings including the parameters, the training algorithm, and the loss fuction were the same as in Section 4.2.3.   <ref type="table" target="#tab_5">Table 2</ref> compares the performances of the mod- els trained on the combination of the training and development sets and evaluated on the test set. The parameters for each model were decided in the development phase which built the models un- der various different settings only on the train- ing set and validated them with the development set. The evaluations were performed with preci- sion, recall, and F-measure to the manual anno- tations under three different schedules at tourist turns, guide turns, and all the turns. Then, the sta- tistical significance for every pair was computed using approximate randomization <ref type="bibr">(Yeh, 2000)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>Comparing between two baseline families, the sequential extensions with the CRF models con- tributed to significant improvements (p &lt; 0.05) from the SVM models in all the schedules. But in both SVM and CRF models, doc2vec features failed to achieve comparable performances to the simplest bag-of-ngrams features. Even the im- provements by combining them to the word fea- tures were not statistically significant.</p><p>While these sentence-level embeddings trained in the unsupervised manner exposed the limi- tations in dialogue topic tracking performances, our proposed CNN-based models outperformed all these baselines. Especially, the CNN initialized with the pre-trained word2vec model achieved higher performances by 8.38%, 6.41%, and 7.21% in F-measure under each schedule, respectively, than the best baseline results.   <ref type="figure" target="#fig_9">Figure 6</ref> presents the differences between two CNN models observed in the development phase. As the number of epochs increases, the perfor- mances of both models also increase up to cer- tain points of saturation. But the model with ran- dom initialization required much longer time to be ready to gain scores in earlier iterations and its sat- urated performance was also lower than the other one learned on top of word2vec. In contrast to the success of the CNN mod- els, the proposed RNN architectures were not able to produce quality results, which was also caused by the limitations of doc2vec representa- tions as already shown in the baseline results. Al- though some RNN models showed little perfor- mance gains over the SVM baselines only with doc2vec features, they were even worse than the CRF model with the same features.</p><p>On the other hand, the RCNN models con- necting the results of CNNs to the RNNs con- tributed to performance improvements not only from the baselines, but also from the CNN mod- els. While the uni-directional RNN was pre- ferred in the RNN models only with doc2vec, the bi-directional LSTM showed better results in the RCNN architectures. As a result, the bi- directional LRCN model achieved the best perfor- mances against all the others, which were statisti- cally significant (p &lt; 0.01) compared to the sec- ond best results with bi-directional RCNN. <ref type="table" target="#tab_7">Table 3</ref> shows the segmentation performances evaluated by considering only the beginning of each segment predicted by the best model of each architecture family. The proposed CNN and LRCN models demonstrated better capabilities of detecting topic transitions in both intra-categorical and inter-categorical conditions than the base- lines. While the CNN model tended to have a higher coverage in segmentation than the others, the LRCN model produced more precise decisions to recognize the boundaries on the strength of the consideration of conversational coherences in dia- logue history sequences.</p><p>However, the segmentation performances even with the best models were still very limited espe- cially for inter-categorical transitions. And most of the models in the experiment had better per- formances in tourist turns than guide turns, as shown in <ref type="table" target="#tab_5">Table 2</ref>. Considering the general char- acteristics of the target domain conversations that guide-driven and inter-categorical transitions are more likely to be dependent on human back- ground knowledge than tourist-driven and intra- categorical cases, respectively, the current limita- tions are expected to be tackled by leveraging ex- ternal resources into the models in future.</p><p>Finally, the generated errors from the models were categorized into the following error types:   • Missing predictions: when the reference be- longs to one of the labels other than 'O', but the model predicts it as 'O'.</p><formula xml:id="formula_7">Intra-categorical Inter-categorical All Models P R F P R F P R F SVM (BoN+SPK+D2V) 40</formula><p>• Extraneous labelling: when the reference be- longs to 'O', but the model predicts it as an- other label.</p><p>• Wrong categorizations: when the reference belongs to a category other than 'O', but the model predicts it as another wrong category.</p><p>• Wrong boundary detections: when the model outputs the correct category, but with a wrong prediction from 'B' to 'I' or from 'I' to 'B'.</p><p>The error distributions in <ref type="figure" target="#fig_10">Figure 7</ref> indicate that the significantly decreased numbers of wrong cat- egories were the decisive factor in performance improvements by our proposed approaches from the baselines. Besides, the enhanced capabilities of the models in distinguishing between 'O' and other labels were demonstrated by the reduced numbers of missing and extraneous predictions. The sequential architectures in CRF and LRCN models also showed its effectiveness especially in boundary detection, as expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper presented various neural network ar- chitectures for dialogue topic tracking. Convolu- tional neural networks were proposed to capture the semantic aspects of utterances given at each moment, while recurrent neural networks were in- tended to incorporate temporal aspects in dialogue histories into tracking models. Experimental re- sults showed that the proposed approaches helped to improve the topic tracking performance with re- spect to the linear baseline models.</p><p>Furthering this work, there would be still much room for improvement in future. Firstly, the ar- chitectures based on a single convolutional layer and a single bi-directional recurrent layer in the proposed models can be extended by adding more layers as well as utilizing more advanced compo- nents including hierarchical CNNs ( <ref type="bibr" target="#b14">Kalchbrenner et al., 2014b</ref>) to deal with utterance composition- alities or attention mechanisms <ref type="bibr" target="#b7">(Denil et al., 2012)</ref> to focus on more important segments in dialogue sequences.</p><p>Secondly, the use of external knowledge could be a key to success in dialogue topic tracking, as proved in the previous studies. However, this work only takes internal dialogue information into ac- count for making decisions. If we develop a good way of leveraging other useful resources into the neural network architectures, better performance can be expected especially for guide-driven and inter-categorical topic transitions that are consid- ered to be more dependent on background knowl- edge of the speakers.</p><p>The other direction of our future work is to in- vestigate joint models for tracking dialogue topics and states simultaneously. Although the previous multi-topic state tracking task has assumed that the topics should be given as inputs to state trackers, we expect that a joint approach can contribute to both problems by dealing with the bi-directional relationships between them. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Embedding layer with three different channels for current, previous, and history utterances Convolutional layer with multiple kernel sizes Max pooling layer Dense layer w softmax output</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Convolutional neural network architecture for dialogue topic tracking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig- ure 2) is basically based on the CNN archi- tecture proposed by Collobert et al. (2011) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Recurrent neural network architecture for dialogue topic tracking. The backward layer with the dotted lines is enabled only with its bidirectional extension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Recurrent convolutional network architecture for dialogue topic tracking. The backward layer is only for the bi-directional mode.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>967</head><label>967</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Distributions of the segments in TourSG corpus by topic categories and transition types. ATTR, TRSP, FOOD, ACCO and SHOP denotes the topic categories of attraction, transportation, food, accommodation, and shopping, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Comparisons of the topic tracking performances of the CNN models with different word embedding approaches according to the number of epochs for training in the development phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Distributions of errors generated from the best model of each architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>0 500 1000 1500 2000 Number of segments SHOP ACCO FOOD TRSP ATTR Topic categories</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Statistics of TourSG corpus. The whole dataset is divided into three subsets for training, development, and test purposes.</figDesc><table>Set 
# sessions # segments # utterances 
Train 
14 
2,104 
12,759 
Dev 
6 
700 
4,812 
Test 
15 
2,210 
13,463 
Total 
35 
5,014 
31,034 

a topic category shift or not. The most frequent 
type found in the dataset is guide-initiative and 
intra-categorical transitions. 63.86% and 61.31% 
of the total segments are initiated by guides and 
segmented keeping topic categories, respectively. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>969 Schedule: Tourist Turns Schedule: Guide Turns</head><label>969</label><figDesc></figDesc><table>Schedule: All 
Models 
P 
R 
F 
P 
R 
F 
P 
R 
F 
SVM (BoN+SPK) 
61.60 62.18 61.89 58.65 58.42 58.53 59.85 59.94 59.90 
SVM (D2V+SPK) 
45.05 51.32 47.98 47.78 52.98 50.24 46.66 52.31 49.32 
SVM (BoN+SPK+D2V) 61.60 62.18 61.89 58.74 58.53 58.63 59.91 60.01 59.96 
CRF (BoN+SPK) 
61.18 62.72 61.94 59.27 59.78 59.52 60.05 60.97 60.51 
CRF (D2V+SPK) 
61.53 49.42 54.81 61.94 49.68 55.13 61.77 49.57 55.00 
CRF (BoN+SPK+D2V) 61.22 62.76 61.98 59.30 59.81 59.55 60.08 61.00 60.54 
CNN (from scratch) 
64.74 63.46 64.10 63.29 62.48 62.88 63.88 62.87 63.37 
CNN (with W2V) 
69.26 71.49 70.36 65.29 66.65 65.96 66.91 68.61 67.75 
Uni-directional RNN 
49.46 54.34 51.79 49.54 53.36 51.38 49.51 53.75 51.55 
Bi-directional RNN 
48.54 49.96 49.24 48.86 49.72 49.29 48.73 49.82 49.27 
Uni-directional LSTM 
49.52 50.81 50.15 49.41 49.85 49.63 49.45 50.23 49.84 
Bi-directional LSTM 
48.39 49.05 48.72 48.44 48.58 48.51 48.42 48.77 48.59 
Uni-directional RCNN 
69.49 71.59 70.52 65.43 66.68 66.05 67.08 68.67 67.86 
Bi-directional RCNN 
69.81 72.50 71.13 65.49 67.28 66.37 67.25 69.39 68.30 
Uni-directional LRCN 
69.37 71.45 70.40 66.22 67.41 66.81 67.50 69.04 68.26 
Bi-directional LRCN 
69.85 72.56 71.18 66.04 67.62 66.82 67.60 69.62 68.59 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparisons of the topic tracking performances with different models. D2V and W2V denote 
the vectors from doc2vec and word2vec, respectively. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head></head><label></label><figDesc>.22 30.19 34.49 8.68 28.14 13.26 18.65 29.51 22.85 CRF (BoN+SPK+D2V) 36.42 25.92 30.28 11.57 24.40 15.70 21.58 25.41 23.34 CNN (with W2V) 41.25 41.50 41.37 17.02 40.87 24.03 28.06 41.29 33.41 Bi-directional LRCN 44.82 38.28 41.29 17.87 40.72 24.84 29.41 39.09 33.57</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparisons of the segmentation performances with different models. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>46th Annual Meeting of the Association for Com- putational Linguistics: Human Language Technolo- gies, pages 630-637.</head><label></label><figDesc></figDesc><table>M. Liang and X. Hu. 2015. Recurrent convolutional 
neural network for object recognition. In Proceed-
ings of the IEEE Conference on Computer Vision 
and Pattern Recognition, pages 3367-3375. 

B. Lin, H. Wang, and L. Lee. 1999. A distributed 
architecture for cooperative spoken dialogue agents 
with coherent dialogue state and history. In Pro-
ceedings of the IEEE Automatic Speech Recognition 
and Understanding Workshop (ASRU). 

S. Liu, N. Yang, M. Li, and M. Zhou. 2014. A re-
cursive recurrent neural network for statistical ma-
chine translation. In Proceedings of the 52nd An-
nual Meeting of the Association for Computational 
Linguistics (ACL), pages 1491-1500. 

T. Mikolov, M. Karafiát, L. Burget, J. Cernock`Cernock`y, and 
S. Khudanpur. 2010. Recurrent neural network 
based language model. In INTERSPEECH, vol-
ume 2, page 3. 

T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and 
J. Dean. 2013. Distributed representations of words 
and phrases and their compositionality. In Advances 
in neural information processing systems (NIPS), 
pages 3111-3119. 

M. Morchid, R. Dufour, M. Bouallegue, G. Linares, 
and R. De Mori. 2014a. Theme identification 
in human-human conversations with features from 
specific speaker type hidden spaces. In INTER-
SPEECH, pages 248-252. 

M. Morchid, R. Dufour, P.M. Bousquet, M. Boual-
legue, G. Linares, and R. De Mori. 2014b. Im-
proving dialogue classification using a topic space 
representation and a gaussian classifier based on the 
decision rule. In Acoustics, Speech and Signal Pro-
cessing (ICASSP), 2014 IEEE International Confer-
ence on, pages 126-130. IEEE. 

T. Nakata, S. Ando, and A. Okumura. 2002. Topic de-
tection based on dialogue history. In Proceedings of 
the 19th international conference on Computational 
linguistics (COLING), pages 1-7. 

N. Okazaki. 2007. Crfsuite: a fast implementation of 
conditional random fields (crfs). 

P. Pinheiro and R. Collobert. 2014. Recurrent con-
volutional neural networks for scene labeling. In 
Proceedings of the 31st International Conference on 
Machine Learning (ICML-14), pages 82-90. 

L. A. Ramshaw and M. P. Marcus. 1995. Text chunk-
ing using transformation-based learning. In Pro-
ceedings of the 3rd Workshop on Very Large Corpus, 
pages 88-94. 

S. Roy and L. V. Subramaniam. 2006. Automatic gen-
eration of domain models for call centers from noisy 
transcriptions. In Proceedings of COLING/ACL, 
pages 737-744. 

M. Schuster and K. K. Paliwal. 1997. Bidirectional 
recurrent neural networks. Signal Processing, IEEE 
Transactions on, 45(11):2673-2681. 

Y. Shen, X. He, J. Gao, L. Deng, and G. Mesnil. 
2014. Learning semantic representations using con-
volutional neural networks for web search. In Pro-
ceedings of the 23rd International Conference on 
World Wide Web (WWW), pages 373-374. Interna-
tional World Wide Web Conferences Steering Com-
mittee. 

I. Sutskever, J. Martens, and G. E. Hinton. 2011. Gen-
erating text with recurrent neural networks. In Pro-
ceedings of the 28th International Conference on 
Machine Learning (ICML-11), pages 1017-1024. 

A. Yeh. 2000. More accurate tests for the statistical 
significance of result differences. In Proceedings 
of the 18th conference on Computational linguistics-
Volume 2, pages 947-953. 

W. Yih, X. He, and C. Meek. 2014. Semantic pars-
ing for single-relation question answering. In Pro-
ceedings of the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages 
643-648. </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Topic detection and extraction in chat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Martell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 IEEE International Conference on Semantic Computing</title>
		<meeting>the 2008 IEEE International Conference on Semantic Computing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="581" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint language and translation modeling with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1044" to="1054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Theano: A cpu and gpu math compiler in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Python in Science Conf</title>
		<meeting>9th Python in Science Conf</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ravenclaw: dialog management using hierarchical task decomposition and an expectation agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Speech, Communication and Technology</title>
		<meeting>the European Conference on Speech, Communication and Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="597" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Approximate inference for domain detection in spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH)</title>
		<meeting>the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="713" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch. The Journal of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning where to attend with deep architectures for image tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2151" to="2184" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long-term recurrent convolutional networks for visual recognition and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Anne</forename><surname>Hendricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2625" to="2634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Integration of word and semantic features for theme identification in telephone conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Esteve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bouallegue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lailler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morchid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dufour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Linares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matrouf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">De</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language Dialog Systems and Intelligent Assistants</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Extensibility verification of robust domain selection against out-of-grammar utterances in multi-domain spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ikeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Komatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ogata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Okuno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th INTERSPEECH</title>
		<meeting>the 9th INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="487" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Making large-scale SVM learning practical</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel MethodsSupport Vector Learning</title>
		<editor>B. Schölkopf, C. Burges, and A. Smola</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="169" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A composite kernel approach for dialog topic tracking with structured domain knowledge from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="19" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wikipediabased kernels for dialogue topic tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>ICASSP</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<title level="m">IEEE International Conference on</title>
		<imprint>
			<biblScope unit="page" from="131" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The fourth dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Spoken Dialogue Systems (IWSDS)</title>
		<meeting>the 7th International Workshop on Spoken Dialogue Systems (IWSDS)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Topic identification in natural language dialogues using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lagus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kuusisto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd SIGdial workshop on Discourse and dialogue</title>
		<meeting>the 3rd SIGdial workshop on Discourse and dialogue</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust dialog management with n-best hypotheses using dialog examples and agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
