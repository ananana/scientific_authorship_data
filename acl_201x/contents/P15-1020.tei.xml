<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Syntax-based Simultaneous Translation through Prediction of Unseen Syntactic Constituents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology Takayamacho</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Ikoma</settlement>
									<region>Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology Takayamacho</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Ikoma</settlement>
									<region>Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology Takayamacho</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Ikoma</settlement>
									<region>Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology Takayamacho</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Ikoma</settlement>
									<region>Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Information Science</orgName>
								<orgName type="institution">Nara Institute of Science and Technology Takayamacho</orgName>
								<address>
									<postCode>630-0192</postCode>
									<settlement>Ikoma</settlement>
									<region>Nara</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Syntax-based Simultaneous Translation through Prediction of Unseen Syntactic Constituents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="198" to="207"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Simultaneous translation is a method to reduce the latency of communication through machine translation (MT) by dividing the input into short segments before performing translation. However, short segments pose problems for syntax-based translation methods, as it is difficult to generate accurate parse trees for sub-sentential segments. In this paper, we perform the first experiments applying syntax-based SMT to simultaneous translation , and propose two methods to prevent degradations in accuracy: a method to predict unseen syntactic constituents that help generate complete parse trees, and a method that waits for more input when the current utterance is not enough to generate a fluent translation. Experiments on English-Japanese translation show that the proposed methods allow for improvements in accuracy, particularly with regards to word order of the target sentences.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Speech translation is an application of machine translation (MT) that converts utterances from the speaker's language into the listener's language. One of the most identifying features of speech translation is the fact that it must be performed in real time while the speaker is speaking, and thus it is necessary to split a constant stream of words into translatable segments before start- ing the translation process. Traditionally, speech translation assumes that each segment corresponds to a sentence, and thus performs sentence bound- ary detection before translation ( <ref type="bibr" target="#b14">Matusov et al., 2006</ref>). However, full sentences can be long, par- ticularly in formal speech such as lectures, and if translation does not start until explicit ends of sentences, listeners may be forced to wait a con- siderable time until receiving the result of trans- lation. For example, when the speaker continues to talk for 10 seconds, listeners must wait at least 10 seconds to obtain the result of translation. This is the major factor limiting simultaneity in tradi- tional speech translation systems.</p><p>Simultaneous translation (Section 2) avoids this problem by starting to translate before observing the whole sentence, as shown in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>. However, as translation starts before the whole sentence is observed, translation units are often not syntactically or semantically complete, and the performance may suffer accordingly. The dele- terious effect of this missing information is less worrying in largely monotonic language pairs (e.g. English-French), but cannot be discounted in syn- tactically distant language pairs (e.g. English- Japanese) that often require long-distance reorder- ing beyond translation units.</p><p>One way to avoid this problem of missing infor- mation is to explicitly predict information needed to translate the content accurately. An ambitious first step in this direction was recently proposed by <ref type="bibr" target="#b6">Grissom II et al. (2014)</ref>, who describe a method that predicts sentence-final verbs using reinforce- ment learning (e.g. <ref type="figure" target="#fig_0">Figure 1</ref> (b)). This approach has the potential to greatly decrease the delay in translation from verb-final languages to verb- initial languages (such as German-English), but is also limited to only this particular case.</p><p>In this paper, we propose a more general method that focuses on a different variety of in- formation: unseen syntactic constituents. This method is motivated by our desire to apply trans- lation models that use source-side parsing, such as tree-to-string (T2S) translation <ref type="bibr" target="#b9">(Huang et al., 2006</ref>) or syntactic pre-ordering ( <ref type="bibr" target="#b26">Xia and McCord, 2004)</ref>, which have been shown to greatly improve translation accuracy over syntactically divergent language pairs. However, conventional methods for parsing are not directly applicable to the par- tial sentences that arise in simultaneous MT. The reason for this, as explained in detail in Section 3, is that parsing methods generally assume that they are given input that forms a complete syntac- tic phrase. Looking at the example in <ref type="figure" target="#fig_0">Figure 1</ref>, after the speaker has spoken the words "I think" we have a partial sentence that will only be com- plete once we observe the following SBAR. Our method attempts to predict exactly this informa- tion, as shown in <ref type="figure" target="#fig_0">Figure 1 (c)</ref>, guessing the re- maining syntactic constituents that will allow us to acquire a proper parse tree.</p><p>Specifically the method consists of two parts: First, we propose a method that trains a statisti- cal model to predict future syntactic constituents based on features of the input segment (Section 4). Second, we demonstrate how to apply this syntac- tic prediction to MT, including the proposal of a heuristic method that examines whether a future constituent has the potential to cause a reordering problem during translation, and wait for more in- put in these cases (Section 5).</p><p>Based on the proposed method, we perform ex- periments in simultaneous translation of English- Japanese talks (Section 6). As this is the first work applying T2S translation to simultaneous MT, we first compare T2S to more traditional phrase-based techniques. We find that T2S translation is effec- tive with longer segments, but drops off quickly with shorter segments, justifying the need for tech- niques to handle translation when full context is not available. We then compare the proposed method of predicting syntactic constituents, and find that it improves translation results, particu- larly with respect to word ordering in the output sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Simultaneous Translation</head><p>In simultaneous translation, we assume that we are given an incoming stream of words f , which we are expected to translate. As the f is long, we would like to begin translating before we reach the end of the stream. Previous methods to do so can generally be categorized into incremental decod- ing methods, and sentence segmentation methods.</p><p>In incremental decoding, each incoming word is fed into the decoder one-by-one, and the decoder updates the search graph with the new words and decides whether it should begin translation. Incre- mental decoding methods have been proposed for phrase-based ( <ref type="bibr" target="#b24">Sankaran et al., 2010;</ref><ref type="bibr" target="#b27">Yarmohammadi et al., 2013;</ref><ref type="bibr" target="#b3">Finch et al., 2014</ref>) and hierar- chical phrase-based ( <ref type="bibr" target="#b25">Siahbani et al., 2014</ref>) SMT models. 1 Incremental decoding has the advantage of using information about the decoding graph in the choice of translation timing, but also requires significant changes to the internal workings of the decoder, precluding the use of standard decoding tools or techniques.</p><p>Sentence segmentation methods <ref type="figure" target="#fig_1">(Figure 2</ref>) provide a simpler alternative by first divid- ing f into subsequences of 1 or more words [f (1) , . . . , f (N ) ]. These segments are then trans- lated with a traditional decoder into output se- quences [e (1) , . . . , e (N ) ], which each are output as soon as translation finishes. Many methods have been proposed to perform segmentation, includ- ing the use of prosodic boundaries <ref type="bibr" target="#b4">(Fügen et al., 2007;</ref><ref type="bibr" target="#b0">Bangalore et al., 2012)</ref>, predicting punc- tuation marks <ref type="bibr" target="#b27">(Rangarajan Sridhar et al., 2013)</ref>, reordering probabilities of phrases ( <ref type="bibr" target="#b5">Fujita et al., 2013)</ref>, or models to explicitly optimize translation accuracy ( <ref type="bibr" target="#b19">Oda et al., 2014</ref>). Previous work often assumes that f is a single sentence, and focus on sub-sentential segmentation, an approach we fol- low in this work.</p><p>Sentence segmentation methods have the obvi- ous advantage of allowing for translation as soon as a segment is decided. However, the use of the shorter segments also makes it necessary to trans- late while part of the utterance is still unknown. As a result, segmenting sentences more aggressively often results in a decrease translation accuracy. This is a problem in phrase-based MT, the frame- work used in the majority of previous research on simultaneous translation. However, it is an even larger problem when performing translation that relies on parsing the input sentence. We describe the problems caused by parsing a segment f (n) , and solutions, in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parsing Incomplete Sentences</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Difficulties in Incomplete Parsing</head><p>In standard phrase structure parsing, the parser as- sumes that each input string is a complete sen- tence, or at least a complete phrase. For example, <ref type="figure" target="#fig_2">Figure 3</ref> (a) shows the phrase structure of the com- plete sentence "this is a pen." However, in the case of simultaneous translation, each translation unit 1 There is also one previous rule-based system that uses syntax in incremental translation, but it is language specific and limited domain ( <ref type="bibr" target="#b23">Ryu et al., 2006</ref>), and thus difficult to compare with our SMT-based system. It also does not predict unseen constituents, relying only on the observed segment. is not necessarily segmented in a way that guar- antees that the translation unit is a complete sen- tence, so each translation unit should be treated not as a whole, but as a part of a spoken sentence. As a result, the parser input may be an incomplete sequence of words (e.g. "this is," "is a"), and a standard parser will generate an incorrect parse as shown in Figures 3(b) and 3(c).</p><p>The proposed method solves this problem by supplementing unseen syntactic constituents be- fore and after the translation unit. For example, considering parse trees for the complete sentence in <ref type="figure" target="#fig_2">Figure 3</ref>(a), we see that a noun phrase (NP) can be placed after the translation unit "this is." If we append the syntactic constituent NP as a "black box" before parsing, we can create a syntactically desirable parse tree as shown in <ref type="figure" target="#fig_2">Figure 3</ref> For the other example "is a," we can create the parse tree in <ref type="figure" target="#fig_2">Figure 3</ref>(e1) by appending NP before the unit and NN after the unit, or can cre- ate the tree in <ref type="figure" target="#fig_2">Figure 3</ref>(e2) by appending only NN after the unit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Formulation of Incomplete Parsing</head><p>A typical model for phrase structure parsing is the probabilistic context-free grammar (PCFG). Pars- ing is performed by finding the parse tree T that maximizes the PCFG probability given a sequence of words w ≡ [w 1 , w 2 , · · · , w n ] as shown by Eq. (2):</p><formula xml:id="formula_0">T * ≡ arg max T Pr(T |w) (1) ≃ arg max T [ ∑ (X→[Y,···])∈T log Pr(X → [Y, · · ·]) + ∑ (X→w i )∈T log Pr(X → w i ) ],<label>(2)</label></formula><p>where</p><formula xml:id="formula_1">Pr(X → [Y, · · ·])</formula><p>represents the genera- tive probabilities of the sequence of constituents</p><formula xml:id="formula_2">[Y, · · ·]</formula><p>given a parent constituent X, and Pr(X → w i ) represents the generative probabilities of each word</p><formula xml:id="formula_3">w i (1 ≤ i ≤ n) given a parent constituent X.</formula><p>To consider parsing of incomplete sentences with appended syntactic constituents, We define</p><formula xml:id="formula_4">L ≡ [L |L| , · · · , L 2 , L 1 ]</formula><p>as the sequence of pre- ceding syntactic constituents of the translation unit and R ≡ [R 1 , R 2 , · · · , R |R| ] as the sequence of following syntactic constituents of the translation unit. For the example <ref type="figure" target="#fig_0">Figure 3(d1)</ref>, we assume that L = [ ] and R = <ref type="bibr">[ NP ]</ref>.</p><p>We assume that both sequences of syntactic constituents L and R are predicted based on the sequence of words w before the main parsing step. Thus, the whole process of parsing incomplete sentences can be described as the combination of predicting both sequences of syntactic constituents represented by Eq. <ref type="formula" target="#formula_5">(3)</ref> and <ref type="formula" target="#formula_6">(4)</ref> and parsing with predicted syntactic constituents represented by Eq. (5):</p><formula xml:id="formula_5">L * ≡ arg max L Pr(L|w),<label>(3)</label></formula><formula xml:id="formula_6">R * ≡ arg max R Pr(R|w),<label>(4)</label></formula><formula xml:id="formula_7">T * ≡ arg max T Pr(T |L * , w, R * ).<label>(5)</label></formula><p>Algorithmically, parsing with predicted syntac- tic constituents can be achieved by simply treating each syntactic constituent as another word in the input sequence and using a standard parsing algo- rithm such as the CKY algorithm. In this process, the only difference between syntactic constituents and normal words is the probability, which we de- fine as follows:</p><formula xml:id="formula_8">Pr(X → Y ) ≡ { 1, if Y = X 0, otherwise.<label>(6)</label></formula><p>It should be noted that here L refers to syntac- tic constituents that have already been seen in the past. Thus, it is theoretically possible to store past parse trees as history and generate L based on this history, or condition Eq. 3 based on this infor- mation. However, deciding which part of trees to use as L is not trivial, and applying this approach requires that we predict L and R using different methods. Thus, in this study, we use the same method to predict both sequences of constituents for simplicity.</p><p>In the next section, we describe the actual method used to create a predictive model for these strings of syntactic constituents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Predicting Syntactic Constituents</head><p>In order to define which syntactic constituents should be predicted by our model, we assume that each final parse tree generated by w, L and R must satisfy the following conditions:</p><p>1. The parse tree generated by w, L and R must be "complete." Defining this formally, this means that the root node of the parse tree for the segment must correspond to a node in the parse tree for the original complete sentence.</p><p>2. Each parse tree contains only L, w and R as terminal symbols.</p><p>3. The number of nodes is the minimum neces- sary to satisfy these conditions.</p><p>As shown in the <ref type="figure" target="#fig_2">Figure 3</ref>, there is ambiguity re- garding syntactic constituents to be predicted (e.g. we can choose either <ref type="bibr">[ NP ]</ref> or <ref type="bibr">[ DT , NN ]</ref> as R for w = [ "this", "is" ]). These conditions avoid ambiguity of which syntactic constituents should predicted for partial sentences in the training data. Looking at the example, Figures 3(d1) and 3(e1) satisfy these conditions, but 3(d2) and 3(e2) do not. <ref type="figure" target="#fig_4">Figure 4</ref> shows the statistics of the lengths of L and R sequences extracted according to these criteria for all substrings of the WSJ datasets 2 to 23 of the Penn Treebank ( <ref type="bibr" target="#b13">Marcus et al., 1993</ref>), a standard training set for English syntactic parsers. From the figure we can see that lengths of up to 2 constituents cover the majority of cases for both L and R, but a significant number of cases require longer strings. Thus methods that predict a fixed number of constituents are not appropriate here. In Algorithm 1, we show the method we propose to First, our method forcibly parses the input se- quence w and retrieves a potentially incorrect parse tree T ′ , which is used to calculate features for the prediction model. The next syntactic con- stituent R + is then predicted using features ex- tracted from w, T ′ , and the predicted sequence history R * . This prediction is repeated recurrently until the end-of-sentence symbol ("nil" in Algo- rithm 1) is predicted as the next symbol.</p><p>In this study, we use a multi-label classifier based on linear SVMs ( <ref type="bibr" target="#b2">Fan et al., 2008</ref>) to predict new syntactic constituents with features shown in <ref type="table" target="#tab_0">Table 1</ref>. We treat the input sequence w and predicted syntactic constituents R * as a concate- nated sequence w + + R * . For example, if we have w = [ this, is, a ] and R * = <ref type="bibr">[ NN ]</ref>, then the word features "3 rightmost 1-grams" will take the values "is," "a," and NN . Tags of semi-terminal nodes in T ′ are used as part-of-speech (POS) tags for corresponding words and the POS of each pre- dicted syntactic constituent is simply its tag. "nil" is used when some information is not available. For example, if we have w = [ this, is ] and R * = [ ] then "3 rightmost 1-grams" will take the values "nil," "this," and "is." Algorithm 1 and Ta- ble 1 shows the method used to predict R * but L * can be predicted by performing the prediction pro- cess in the reverse order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Tree-to-string SMT with Syntactic Constituents</head><p>Once we have created a tree from the sequence L * + + w + + R * by performing PCFG parsing with predicted syntactic constituents according to Eqs.</p><p>(2), (5), and (6), the next step is to use this tree in translation. In this section, we focus specifically on T2S translation, which we use in our experi- ments, but it is likely that similar methods are ap- plicable to other uses of source-side syntax such as pre-ordering as well.</p><formula xml:id="formula_9">Algorithm 1 Prediction algorithm for following constituents R * T ′ ← arg max T Pr(T |w) R * ← [ ] loop R + ← arg max R Pr(R|T ′ , R * ) if R + = nil then return R * end if R * ← R * + +[R + ] end loop</formula><p>It should be noted that using these trees in T2S translation models is not trivial because each esti- mated syntactic constituent should be treated as an aggregated entity representing all possibilities of subtrees rooted in such a constituent. Specifically, there are two problems: the possibility of reorder- ing an as-of-yet unseen syntactic constituent into the middle of the translated sentence, and the cal- culation of language model probabilities consider- ing syntactic constituent tags.</p><p>With regards to the first problem of reordering, consider the example of English-Japanese transla- tion in <ref type="figure" target="#fig_5">Figure 5(b)</ref>, where a syntactic constituent PP is placed at the end of the English sequence (R * ), but the corresponding entity in the Japanese translation result should be placed in the middle of the sentence. In this case, if we attempt to translate immediately, we will have to omit the as-of-yet unknown PP from our translation and translate it later, resulting in an unnatural word ordering in the Thus, if any of the syntactic constituents in R are placed anywhere other than the end of the translation result, we can assume that this is a hint that the current segmentation boundary is not ap- propriate. Based on this intuition, we propose a heuristic method that ignores segmentation bound- aries that result in a translation of this type, and in- stead wait for the next translation unit, helping to avoid problems due to inappropriate segmentation boundaries. Algorithm 2 formally describes this waiting method.</p><p>The second problem of language model proba- bilities arises because we are attempting to gener- ate a string of words, some of which are not actual words but tags representing syntactic constituents. Creating a language model that contains probabil- ities for these tags in the appropriate places is not trivial, so for simplicity, we simply assume that ev- ery syntactic constituent tag is an unknown word, and that the output of translation consists of both translated normal words and non-translated tags as shown in <ref type="figure" target="#fig_5">Figure 5</ref>. We relegate a more complete handling of these tags to future work. <ref type="bibr">2</ref> It is also potentially possible to create a predictive model for the actual content of the PP as done for sentence-final verbs by <ref type="bibr" target="#b6">Grissom II et al. (2014)</ref>, but the space of potential prepositional phrases is huge, and we leave this non-trivial task for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Waiting algorithm for T2S SMT</head><formula xml:id="formula_10">w ← [ ] loop w ← w + + NextSegment() L * ← arg max L Pr(L|w) R * ← arg max R Pr(R|w) T * ← arg max T Pr(T |L * , w, R * ) e * ← arg max e Pr(e|T * ) if elements of R * are rightmost in e * then Output(e * ) w ← [ ] end if end loop</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiment Settings</head><p>We perform 2 types of experiments to evaluate the effectiveness of the proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Predicting Syntactic Constituents</head><p>In the first experiment, we evaluate prediction ac- curacies of unseen syntactic constituents L and R. To do so, we train a predictive model as described in Section 4 using an English treebank and evalu- ate its performance. To create training and testing data, we extract all substrings w s.t. |w| ≥ 2 in the Penn Treebank and calculate the correspond- ing syntactic constituents L and R by according to the original trees and substring w. We use the 90% of the extracted data for training a classifier and the remaining 10% for testing estimation re- call, precision and F-measure. We use the Ckylark parser( <ref type="bibr" target="#b20">Oda et al., 2015</ref>) to generate T ′ from w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Simultaneous Translation</head><p>Next, we evaluate the performance of T2S si- multaneous translation adopting the two proposed methods. We use data of TED talks from the English-Japanese section of WIT3 ( <ref type="bibr" target="#b1">Cettolo et al., 2012)</ref>, and also append dictionary entries and ex- amples in Eijiro 3 to the training data to increase the vocabulary of the translation model. The total number of sentences/entries is 2.49M (WIT3, Ei- jiro), 998 (WIT3), and 468 (WIT3) sentences for training, development, and testing respectively.</p><p>We use the Stanford Tokenizer 4 for English tokenization, <ref type="bibr">KyTea (Neubig et al., 2011</ref>) for Japanese tokenization, GIZA++ <ref type="bibr" target="#b17">(Och and Ney, 2003)</ref> to construct word alignment, and <ref type="bibr">KenLM (Heafield et al., 2013</ref>) to generate a 5-gram target language model. We use the Ckylark parser, which we modified to implement the parsing method of Section 3.2, to generate T * from L * , w and R * .</p><p>We use Travatar <ref type="bibr" target="#b16">(Neubig, 2013)</ref> to train the T2S translation model used in the proposed method, and also Moses ( <ref type="bibr" target="#b11">Koehn et al., 2007</ref>) to train phrase-based translation models that serve as a baseline. Each translation model is tuned us- ing MERT <ref type="bibr" target="#b18">(Och, 2003)</ref> to maximize BLEU ( <ref type="bibr" target="#b21">Papineni et al., 2002</ref>). We evaluate translation ac- curacies by BLEU and also RIBES ( <ref type="bibr" target="#b10">Isozaki et al., 2010</ref>), a reordering-focused metric which has achieved high correlation with human evaluation on English-Japanese translation tasks.</p><p>We perform tests using two different sentence segmentation methods. The first is n-words seg- mentation <ref type="bibr" target="#b27">(Rangarajan Sridhar et al., 2013</ref>), a sim- ple heuristic that simply segments the input ev- ery n words. This method disregards syntactic and semantic units in the original sentence, al- lowing us to evaluate the robustness of translation against poor segmentation boundaries. The second method is the state-of-the-art segmentation strat- egy proposed by <ref type="bibr" target="#b19">Oda et al. (2014)</ref>, which finds segmentation boundaries that optimize the accu- racy of the translation output. We use BLEU+1 ( <ref type="bibr" target="#b12">Lin and Och, 2004</ref>) as the objective of this seg- mentation strategy.</p><p>We evaluate the following baseline and pro- posed methods:</p><p>PBMT is a baseline using phrase-based SMT.</p><p>T2S uses T2S SMT with parse trees generated from only w.</p><p>T2S-Tag further predicts unseen syntactic con- stituents according to Section 4. Before eval- uation, all constituent tags are simply deleted from the output.</p><p>T2S-Wait uses T2S-Tag and adds the waiting strategy described in Section 5.</p><p>We also show PBMT-Sent and T2S-Sent which are full sentence-based PBMT and T2S systems. <ref type="table" target="#tab_1">Table 2</ref> shows the recall, precision, and F-measure of the estimated L and R sequences. The table shows results of two evaluation settings, where the order of generated constituents is considered or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">Predicting Syntactic Constituents</head><p>We can see that in each case recall is lower than the corresponding precision and the performance of L differs between ordered and unordered re- sults. These trends result from the fact that the model generates fewer constituents than exist in the test data. However, this trend is not entirely un- expected because it is not possible to completely accurately guess syntactic constituents from every substring w. For example, parts of the sentence "in the next 18 minutes" can generate the sequence "in the next CD NN " and " IN DT JJ 18 min- utes," but the constituents CD in the former case and DT and JJ in the latter case are not neces- sary in all situations. In contrast, NN and IN will probably be inserted most cases. As a result, the appearance of such ambiguous constituents in the training data is less consistent than that of nec- essary syntactic constituents, and thus the predic- tion model avoids generating such ambiguous con- stituents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">Simultaneous Translation</head><p>Next, we evaluate the translation results achieved by the proposed method. <ref type="figure" target="#fig_6">Figures 6 and 7</ref> show the relationship between the mean number of words in the translation segments and translation accuracy of BLEU and RIBES respectively. Each horizon- tal axis of these graphs indicates the mean number of words in translation units that are used to gen- erate the actual translation output, and these can be assumed to be proportional to the mean waiting time for listeners. In cases except T2S-Wait, these values are equal to the mean length of translation unit generated by the segmentation strategies, and in the case of T2S-Wait, this value shows the length of the translation units concatenated by the waiting strategy. First looking at the full sentence results (rightmost points in each graph), we can see that T2S greatly outperforms PBMT on full sentences, underlining the importance of considering syntax for this language pair. Turning to simultaneous translation, we first consider the case of n-words segmentation, which will demonstrate robustness of each method to poorly formed translation segments. When we compare PBMT and T2S, we can see that T2S is superior for longer segments, but on shorter seg- ments performance is greatly reduced, dropping below that of PBMT in BLEU at an average of 6 words, and RIBES at an average of 4 words. This trend is reasonable, considering that shorter trans- lation units will result in syntactically inconsistent units and thus incorrect parse trees. Next look- ing at the results for T2S-Tag, we can see that in the case of the n-words segmentation, it is able to maintain the same translation performance of PBMT, even at the shorter settings. Furthermore, T2S-Wait also maintains the same performance of T2S-Tag in BLEU and achieves much higher performance than any of the other methods in RIBES, particularly with regards to shorter trans- lation units. This result shows that the method of waiting for more input in the face of potential re- ordering problems is highly effective in maintain- ing the correct ordering of the output.</p><p>In the case of the optimized segmentation, all three T2S methods maintain approximately the same performance, consistently outperforming PBMT in RIBES, and crossing in BLEU around 5- 6 words. From this, we can hypothesize that the optimized segmentation strategy learns features that maintain some syntactic consistency, which plays a similar role to the proposed method. How- ever, RIBES scores for T2S-Wait is still generally higher than the other methods, demonstrating that waiting maintains its reordering advantage even in the optimized segmentation case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, we proposed the first method to apply SMT using source syntax to simultaneous translation. Especially, we proposed methods to maintain the syntactic consistency of translation units by predicting unseen syntactic constituents, and waiting until more input is available when it is necessary to achieve good translation results. Ex-periments on an English-Japanese TED talk trans- lation task demonstrate that our methods are more robust to short, inconsistent translation segments.</p><p>As future work, we are planning to devise more sophisticated methods for language model- ing using constituent tags, and ways to incorpo- rate previously translated segments into the esti- mation process for left-hand constituents. Next, our method to predict additional constituents does not target the grammatically correct translation units for which L = [ ] and R = [ ], although there is still room for improvement in this assump- tion. In addition, we hope to expand the meth- ods proposed here to a more incremental setting, where both parsing and decoding are performed incrementally, and the information from these pro- cesses can be reflected in the decision of segmen- tation boundaries.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Simultaneous translation where the source sentence is segmented after "I think" and translated according to (a) the standard method, (b) Grissom II et al. (2014)'s method of final verb prediction, and (c) our method of predicting syntactic constituents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Process of English-Japanese simultaneous translation with sentence segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Phrase structures with surrounding syntactic constituents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(d1) We also can construct another tree as shown in Fig- ure 3(d2) by appending two constituents DT and NN .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Statistics of numbers of syntactic constituents to be predicted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Waiting for the next translation unit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Mean #words and BLEU scores of each method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Features used in predicting syntactic con-
stituents. 
Type Feature 
Words 3 leftmost 1,2-grams in w + + R  *  
3 rightmost 1,2-grams in w + + R  *  
Left/rightmost pair in w + + R  *  
POS 
Same as "Words" 
Parse Tag of the root node 
Tags of children of the root node 
Pairs of root and children nodes 
Length |w| 
|R  *  | 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Performance of syntactic constituent pre-
diction. 
Target 
P % 
R % 
F % 
L 
(ordered) 
31.93 
7.27 11.85 
(unordered) 51.21 11.66 19.00 
R 
(ordered) 
51.12 33.78 40.68 
(unordered) 52.77 34.87 42.00 

</table></figure>

			<note place="foot" n="3"> http://eijiro.jp/ 4 http://nlp.stanford.edu/software/tokenizer.shtml</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>Part of this work was supported by JSPS KAK-ENHI Grant Number 24240032, and Grant-in-Aid for JSPS Fellows Grant Number 15J10649.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Real-time incremental speech-tospeech translation of dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kumar Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakash</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ladan</forename><surname>Kolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aura</forename><surname>Golipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jimenez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">WIT 3 : Web inventory of transcribed and translated talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EAMT</title>
		<meeting>EAMT</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>and Marcello Federico</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An exploration of segmentation strategies in stream decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWSLT</title>
		<meeting>IWSLT</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Simultaneous translation of lectures and speeches. Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Fügen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muntsin</forename><surname>Kolss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple, lexicalized choice of translation timing for simultaneous speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dont until the final verb wait: Reinforcement learning for simultaneous machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Grissom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jonathan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clark</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistical syntax-directed translation with extended domain of locality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AMTA</title>
		<meeting>AMTA</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic evaluation of translation quality for distant language pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL<address><addrLine>Christine Moran, Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra Constantin, and Evan Herbst</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ORANGE: a method for evaluating automatic evaluation metrics for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The Penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic sentence segmentation and punctuation prediction for spoken language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Mauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWSLT</title>
		<meeting>IWSLT</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pointwise prediction for robust, adaptable japanese morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosuke</forename><surname>Nakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACLHLT</title>
		<meeting>ACLHLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Travatar: A forest-to-string machine translation engine based on tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimizing segmentation strategies for simultaneous speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ckylark: A more robust PCFG-LA parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACLHLT</title>
		<meeting>NAACLHLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Andrej Ljolje, and Rathinavelu Chengalvarayan. 2013. Segmentation strategies for streaming speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kumar Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bangalore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simultaneous english-japanese spoken language translation based on incremental dependency parsing and transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichiro</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeki</forename><surname>Matsubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuyoshi</forename><surname>Inagaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incremental decoding for phrase-based statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajeet</forename><surname>Baskaran Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WMT</title>
		<meeting>WMT</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Incremental translation using hierarchical phrasebased translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Siahbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramtin</forename><forename type="middle">Mehdizadeh</forename><surname>Seraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baskaran</forename><surname>Sankaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improving a statistical MT system with automatically learned rewrite patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Incremental segmentation and decoding strategies for simultaneous translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahsa</forename><surname>Yarmohammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Kumar Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baskaran</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sankaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
