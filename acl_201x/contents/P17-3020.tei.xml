<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Situations in Neural Chat Bots</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoetsu</forename><surname>Sato</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Toyoda</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaru</forename><surname>Kitsuregawa</surname></persName>
						</author>
						<title level="a" type="main">Modeling Situations in Neural Chat Bots</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="120" to="127"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3020</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Social media accumulates vast amounts of online conversations that enable data-driven modeling of chat dialogues. It is, however, still hard to utilize the neural network-based SEQ2SEQ model for dialogue modeling in spite of its acknowledged success in machine translation. The main challenge comes from the high degrees of freedom of outputs (responses). This paper presents neural conversational models that have general mechanisms for handling a variety of situations that affect our responses. Response selection tests on massive dialogue data we have collected from Twitter confirmed the effectiveness of the proposed models with situations derived from utterances, users or time.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The increasing amount of dialogue data in social media has opened the door to data-driven model- ing of non-task-oriented, or chat, dialogues <ref type="bibr" target="#b14">(Ritter et al., 2011</ref>). The data-driven models assume a response generation as a sequence to sequence mapping task, and recent ones are based on neural SEQ2SEQ models ( <ref type="bibr" target="#b19">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b16">Shang et al., 2015;</ref><ref type="bibr">Li et al., 2016a,b;</ref><ref type="bibr" target="#b24">Xing et al., 2017)</ref>. However, the adequacy of responses generated by these neural models is somewhat insufficient, in contrast to the acknowledged success of the neural SEQ2SEQ models in machine translation <ref type="bibr" target="#b3">(Johnson et al., 2016)</ref>.</p><p>The contrasting outcomes in machine transla- tion and chat dialogue modeling can be explained by the difference in the degrees of freedom on out- put for a given input. An appropriate response to a given utterance is not monolithic in chat di- alogue. Nevertheless, since only one ground truth response is provided in the actual dialogue data, the supervised systems will hesitate when choos- ing from the vast range of possible responses.</p><p>So, how do humans decide how to respond? We converse with others while (implicitly) consider- ing not only the utterance but also other various conversational situations ( § 2) such as time, place, and the current context of conversation and even our relationship with the addressee. For example, when a friend says "I feel so sleepy." in the morn- ing, a probable response could be "Were you up all night?" <ref type="figure" target="#fig_0">(Figure 1</ref>). If the friend says the same thing at midnight, you might say "It's time to go to bed." Or if the friend is driving a car with you, you might answer "If you fall asleep, we'll die."</p><p>Modeling situations behind conversations has been an open problem in chat dialogue modeling, and this difficulty has partly forced us to focus on task-oriented dialogue systems <ref type="bibr" target="#b22">(Williams and Young, 2007)</ref>, the response of which has a low de- gree of freedom thanks to domain and goal speci- ficity. Although a few studies have tried to exploit conversational situations such as speakers' emo-tions ( <ref type="bibr" target="#b1">Hasegawa et al., 2013)</ref> or personal charac- teristics ( <ref type="bibr" target="#b7">Li et al., 2016b</ref>) and topics ( <ref type="bibr" target="#b24">Xing et al., 2017)</ref>, the methods are specially designed for and evaluated using specific types of situations.</p><p>In this study, we explore neural conversational models that have general mechanisms to incorpo- rate various types of situations behind chat con- versations ( § 3.2). These models take into account situations on the speaker's side and the addressee's side (or those who respond) when encoding ut- terances and decoding its responses, respectively. To capture the conversational situations, we design two mechanisms that differ in how strong of an ef- fect a given situation has on generating responses.</p><p>In experiments, we examined the proposed con- versational models by incorporating three types of concrete conversational situations ( § 2): utter- ance, speaker/addressee (profiles), and time (sea- son), respectively. Although the models are capa- ble of generating responses, we evaluate the mod- els with a response selection test to avoid known issues in automatic evaluation metrics of gener- ated responses ( <ref type="bibr" target="#b8">Liu et al., 2016a</ref>). Experimental results obtained using massive dialogue data from Twitter showed that modeling conversational situ- ations improved the relevance of responses ( § 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Conversational situations</head><p>Various types of conversational situations could affect our response (or initial utterance) to the ad- dressee. Since neural conversational models need massive data to train a reliable model, our study investigates conversational situations that are nat- urally given or can be identified in an unsupervised manner to make the experimental settings feasible.</p><p>In this study, we represent conversational situ- ations as discrete variables. That allows models to handle unseen situations in testing by classify- ing them into appropriate situation types via dis- tributed representations or the like as described be- low, and helps to analyze the outputs. We consider the following conversational situations to each ut- terance and response in our dialogue dataset ( § 4), and cluster the situations to assign specific situa- tion types to the utterances and responses in the training data of our conversational models.</p><p>Utterance The input utterance (to be responded to by the system) is a primary conversational sit- uation and is already modeled by the encoder in the neural SEQ2SEQ model. However, we may be able to induce a different aspect of situations that are represented in the utterance but are not cap- tured by the SEQ2SEQ sequential encoder ( <ref type="bibr" target="#b15">Sato et al., 2016)</ref>. We first represent each utterance of utterance-response pairs in our dialogue dataset by a distributed representation obtained by averaging word2vec 1 vectors (pre-trained from our dialogue datasets ( § 4.1)) for words in the utterances. The utterances are then classified by k-means cluster- ing to identify utterance types. <ref type="bibr">2</ref> User (profiles) User characteristics should af- fect his/her responses as <ref type="bibr" target="#b7">Li et al. (2016b)</ref> have al- ready discussed. We classify profiles provided by each user in our dialogue dataset ( § 4.1) to acquire conversational situations specific to the speakers and addressees. The same as with the input utter- ance, we first construct a distributed representation of each user's profile by averaging the pre-trained word2vec vectors for verbs, nouns and adjectives in the user profiles. The users are then classified by k-means clustering to identify user types. 3</p><p>Time (season) Our utterances can be affected by when we speak as illustrated in § 1, so we adopted time as one conversational situation. On the ba- sis of timestamp of the utterance and the response in our dataset, we split the conversation data into four season types: namely, spring (Mar. -May.), summer (Jun. -Aug), autumn (Sep. -Nov.), and winter (Dec. -Feb.). This splitting reflects the cli- mate in Japan since our data are in Japanese whose speakers mostly live in Japan.</p><p>In training our neural conversational models, we use each of the above conversational situation types for the speaker side and addressee (who re- spond) side, respectively. Note that the utterance situation is only considered for the speaker side since its response is unseen in response genera- tion. In testing, the conversational situation types for input utterances (or speaker and addressee's profiles) are identified by finding the closest cen- troid obtained by the k-means clustering of the ut- terances (profiles) in the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our neural conversational models are based on the SEQ2SEQ model ( ) and inte- grate mechanisms to incorporate various conversa- tional situations ( § 2) at speaker side and addressee side. In the following, we briefly introduce the SEQ2SEQ conversational model ( <ref type="bibr" target="#b19">Vinyals and Le, 2015)</ref> and then describe two mechanisms for in- corporating conversational situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">SEQ2SEQ conversational model</head><p>The SEQ2SEQ conversational model <ref type="bibr" target="#b19">(Vinyals and Le, 2015)</ref> consists of two recurrent neural net- works (RNNs) called an encoder and a decoder. The encoder takes each word of an utterance as input and encodes the input sequence to a real- valued vector representing the utterance. The de- coder then takes the encoded vector as its initial state and continues to generate the most probable next word and to input the word to itself until it finally outputs EOS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Situation-aware conversational models</head><p>The challenge in designing situation-aware neu- ral conversational models is how to inject given conversational situations into RNN encoders or de- coders. In this paper, we present two situation- aware neural conversational models that differ in how strong of an effect a given situation has.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Local-global SEQ2SEQ</head><p>Motivated by a recent success in multi-task learn- ing for a deep neural network ( <ref type="bibr">Liu et al., 2016c,b;</ref><ref type="bibr" target="#b0">Gupta et al., 2016;</ref><ref type="bibr" target="#b11">Luong et al., 2016)</ref>, our local- global SEQ2SEQ trains two types of RNN encoder and decoder for modeling situation-specific dia- logues and universal dialogues jointly <ref type="figure" target="#fig_1">(Figure 2)</ref>.</p><p>Local-RNNs are meant to model dialogues in individual conversational situations at both the speaker and addressee sides. Each local-RNN is trained (i.e., its parameters are updated) only on dialogues under the corresponding situation. A salient disadvantage of this modeling is that the size of training data given to each local-RNN de- creases as the number of situation types increases.</p><p>To address this problem, we combine another global-RNN encoder and decoder trained on all the dialogue data and take the weighted sum of the hidden states hs of the two RNNs for both the en- coder and decoder to obtain the output as:</p><formula xml:id="formula_0">h (enc) i =W (enc) G RNN (enc) G (h (enc) i−1 , x i )+ W (enc) L RNN (enc) L k (h (enc) i−1 , x i ),<label>(1)</label></formula><formula xml:id="formula_1">h (dec) j =W (dec) G RNN (dec) G (h (dec) j−1 , y j−1 )+ W (dec) L RNN (dec) L k (h (dec) j−1 , y j−1 ), (2) where RNN (·) G (·) and RNN (·)</formula><p>L (·) denote global-RNN and local-RNN, respectively, and the W s are train- able matrices for the weighted sum. The embed- ding and softmax layers of the RNNs are shared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">SEQ2SEQ with situation embeddings</head><p>The local-global SEQ2SEQ ( § 3.2.1) assumes that dialogues with different situations involve differ- ent domains (or tasks) that are independent of each other. However, this assumption could be too strong in some cases and thus we devise another weakly situation-aware conversational model.</p><p>We represent the given situations at speaker and addressee sides, s k and s k , as situation embed- dings and then feed them to the encoder and de- coder prior to processing sequences ( <ref type="figure" target="#fig_2">Figure 3)</ref> as:</p><formula xml:id="formula_2">h (enc) 0 =RNN(h init , s k ),<label>(3)</label></formula><formula xml:id="formula_3">h (enc) i =RNN(h (enc) i−1 , x i−1 ),<label>(4)</label></formula><formula xml:id="formula_4">h (dec) 0 =RNN(h (enc) I+1 , s k ),<label>(5)</label></formula><formula xml:id="formula_5">h (dec) j =RNN(h (dec) j−1 , y j−1 ),<label>(6)</label></formula><p>where h init is a vector filled with zeros and h</p><formula xml:id="formula_6">(enc) I+1</formula><p>is the last hidden state of the encoder. <ref type="table">Table 1</ref>: Statistics of our dialogue datasets (train- ing, validation, and test portions are merged here).</p><note type="other">Average length in words (utterances) 15.7 Average length in words (responses) 10.1 Average length in words (user profiles) 37.4 Number of users 386,078</note><p>This encoding was inspired by a neural machine translation system <ref type="bibr" target="#b3">(Johnson et al., 2016</ref>) that en- ables multilingual translation with a single model. Whereas it inputs the target language embedding only to the encoder to control the target language, we input the speaker-side situation to the encoder and the addressee-side one to the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>In this section, we evaluate our situation-aware neural conversational models on massive dialogue data obtained from Twitter. We compare our mod- els ( § 3.2) with SEQ2SEQ baseline ( § 3.1) using a response selection test instead of evaluating gen- erated responses, since <ref type="bibr" target="#b8">Liu et al. (2016a)</ref> recently pointed out several problems of existing metrics such as BLEU ( <ref type="bibr" target="#b13">Papineni et al., 2002</ref>) for evaluat- ing generated responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Settings</head><p>Data We built massive dialogue datasets from our Twitter archive that have been compiled since March, 2011. In this archive, timelines of about 1.5 million users <ref type="bibr">4</ref> have been continuously col- lected with the official API. It is therefore suitable for extracting users' conversations in timelines.</p><p>On Twitter, a post (tweet) and a mention to it can be considered as an utterance-response pair. We randomly extracted 23,563,865 and 1,200,000 pairs from dialogues in 2014 as training and vali- dation datasets, and extracted 6000 pairs in 2015 as a test dataset in accordance with the follow- ing procedure. Because we want to exclude ut- terances that need contexts in past dialogue ex- changes to respond from our evaluation dataset, we restrict ourselves to only tweets that are not mentions to other tweets (in other words, utter- ances without past dialogue exchanges are chosen for evaluation). For each utterance-response pair in the test dataset, we randomly chose four (in to- tal, 24,000) responses in 2015 as false response <ref type="bibr">4</ref> Our collection started from 26 popular Japanese users in March 2011, and the user set has iteratively expanded to those who are mentioned or retweeted by already targeted users.   Models In our experiments, we compare our situation-aware neural conversational models (we refer to the model in § 3.2.1 as L/G SEQ2SEQ and the model in § 3.2.2 as SEQ2SEQ emb) with situation-unaware baseline ( § 3.1) for taking each type of conversational situations ( § 2) into con- sideration. We also evaluate the model in § 3.2.1 without global-RNNs (referred to as L SEQ2SEQ) to observe the impact of global-RNNs. We used a long-short term memory (LSTM) ( <ref type="bibr" target="#b25">Zaremba et al., 2014</ref>) as the RNN encoder and decoder, sampled softmax ( <ref type="bibr" target="#b2">Jean et al., 2015)</ref> to accelerate the training, and TensorFlow 8 to imple- ment the models. Our LSTMs have three layers and are optimized by Adam ( <ref type="bibr" target="#b4">Kingma and Ba, 2015)</ref>. The hyperparameters are fixed as in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Evaluation procedure We use the above mod- els to rank response candidates for a given utter- ance in the test set. We compute the averaged cross-entropy loss for words in each response can- didate (namely, its perplexity) by giving the can- didate following the input utterance to each con- versational model, and used the resulting values for ranking candidates to choose top-k plausible ones. We adopt 1 in t P@k ( ) as the evaluation metric, which indicates the ratio of utterances that are provided the single ground truth in top k responses chosen from t candidates. Here we use 1 in 2 P@1, 9 1 in 5 P@1, and 1 in 5 P@2.  <ref type="table">Table 3</ref>: Results of the response selection test. <ref type="table">Table 3</ref> lists the results of the response selection test. The proposed conversational models success- fully improved the relevance of selected responses by incorporating conversational situations. The proposed model that performed best is dif- ferent depending on the situation type. We found from the dataset that many of the conversations did not seem to be affected by the seasons, that is, time (season) situation is less influential than other sit- uations. This explains the poor performance of L SEQ2SEQ with time (season) situations due to the data sparseness in training local-RNNs, although the sparseness is mostly addressed by global RNNs in L/G SEQ2SEQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model 1 in 2 P@1 1 in 5 P@1 1 in 5 P@2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>As stated in § 3.2.2, L/G SEQ2SEQ is ex- pected to capture situations more strongly than SEQ2SEQ emb. To confirm this, we plotted scat- tergrams of the utterance vectors <ref type="figure">(Figure 4</ref>) and the user profile vectors ( <ref type="figure" target="#fig_5">Figure 5</ref>) in the training data by using t-SNE <ref type="bibr" target="#b12">(Maaten and Hinton, 2008)</ref>. We provide cluster descriptions by manually look- ing into the content of the utterances and user pro- files in each cluster. The descriptions are followed by if L/G SEQ2SEQ performed better than SEQ2SEQ emb in terms of 1 in 5 P@1 for test utterances with the corresponding situation type, by if the opposite and by → if comparable (dif- ferences are within ± 1.0%). Elements of clusters were randomly sampled.</p><p>L/G SEQ2SEQ tends to perform better for ut- terances with densely concentrated (or coherent) speaker profile clusters ( <ref type="figure" target="#fig_5">Figure 5</ref>). This is because utterances given by the speakers in these coherent clusters (and the associate responses) have similar conversations, situations of which are captured by local-RNNs in the local-global SEQ2SEQ. Diverse topics ր Opinions, q estions ր Food, sightseeing ր Emotional ց Self-explos re ր Good morning ր Desires ր Coming home ր Good night ր Reporting ret rn ր <ref type="figure">Figure 4</ref>: The scattergram of sampled utterance vectors visualized using t-SNE. This explains the reason why L/G SEQ2SEQ outperformed the other situation-aware conversa- tional models when utterance situations are con- sidered ( <ref type="figure">Figure 4)</ref>. Conversations in the same clusters are naturally consistent, and conversations assigned to the same clusters form typical activ- ities or specific tasks (e.g., greetings, following other users, and questions (and answering)) in Twitter conversation. L/G SEQ2SEQ, designed as a kind of multi-task SEQ2SEQ, literally captures these task-specific behaviors in the conversations.</p><p>Although some utterance clusters have general conversations (e.g., diverse topics), the response performances in those clusters have still improved. This is because these general clusters are free from harmful common responses that are quarantined into situation-specific clusters (e.g., greetings etc.) and the corresponding local-RNNs should avoid generating those common responses. Note that this problem has been pointed out and addressed by <ref type="bibr" target="#b6">Li et al. (2016a)</ref> in a totally different way.</p><p>Situation: utterance (opinions, questions) Input:</p><p>BOT (I've recently been followed by many bot accounts.) Baseline (You've gotta be tired.) L/G SEQ2SEQ (Let's block them.) Situation: addressee profiles (girls) Input:</p><p>(Why am I starting Granblue Fantasy? I have to write the paper...) Baseline (Hey, are you okay?) SEQ2SEQ emb♥ (Let's be friends♥) Situation: time (season) (summer) Input: 7</p><p>(July is too warm to wear a hoodie.) Baseline ! (Yes!) SEQ2SEQ emb!? (Do you still wear one?) <ref type="table">Table 4</ref>: Responses selected by the systems.</p><p>Examples <ref type="table">Table 4</ref> lists the response candidate selected by the baseline and our models. As we had expected, the situation-aware conversational models are better at selecting ground-truth re- sponses for situation-specific conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Conversational situations have been implicitly ad- dressed by preparing datasets specific to the target situations and by solving the problem as a task- oriented conversation task <ref type="bibr" target="#b22">(Williams and Young, 2007)</ref>; examples include troubleshooting (Vinyals and Le, 2015), navigation <ref type="bibr" target="#b20">(Wen et al., 2015)</ref>, in- terviewing ( <ref type="bibr" target="#b5">Kobori et al., 2016)</ref>, and restaurant search <ref type="bibr" target="#b21">(Wen et al., 2017)</ref>. In what follows, we in- troduce non-task-oriented conversational models that explicitly consider conversational situations. <ref type="bibr" target="#b1">Hasegawa et al. (2013)</ref> presented a conversa- tional model that generates a response so that it elicits a certain emotion (e.g., joy) in the addressee mind. Their model is based on statistical ma- chine translation and linearly interpolates two con- versational models that are trained from a small emotion-labeled dialogue corpus and a large non- labeled dialogue corpus, respectively. This model is similar to our local-global SEQ2SEQ but differs in that it has hyperparameters for the interpolation, whereas our local-global SEQ2SEQ automatically learns W G and W L from the training data. <ref type="bibr" target="#b7">Li et al. (2016b)</ref> proposed a neural conversa- tional model that generates responses taking into consideration speakers' personalities such as gen- der or living place. Because they fed a specific speaker ID to their model and represent individual (known) speakers with embeddings, Their model cannot handle unknown speakers. In contrast, our model can consider any speakers with profiles be- cause we represent each cluster of profiles with an embedding and find an appropriate profile type for the given profile by nearest-neighbor search. <ref type="bibr" target="#b17">Sordoni et al. (2015)</ref> encoded a given utter- ance and the past dialogue exchanges, and com- bined the resulting representations for RNN to de- code a response. <ref type="bibr" target="#b26">Zhao et al. (2017)</ref> used a condi- tional variational autoencoder and automatically- induced dialogue acts to handle discourse-level di- versity in the encoder. While these sophisticated architectures are designed to take dialogue histo- ries into consideration, our simple models can eas- ily exploit various situations.</p><p>Recently, <ref type="bibr" target="#b24">Xing et al. (2017)</ref> proposed to explic- itly consider topics of utterances to generate topic- coherent responses. Although they used latent Dirichlet allocation while we use k-means clus- tering, both methods confirmed the importance of utterance situations. The way to obtain specific situations is still an open research problem. As demonstrated in this study, our primary contribu- tion is the invention of neural mechanisms that can consider various conversational situations.</p><p>Our local-global SEQ2SEQ model is closely re- lated to a many-to-many multi-task SEQ2SEQ pro- posed by <ref type="bibr" target="#b11">Luong et al. (2016)</ref>. The critical dif- ference is in that their model assumes only lo- cal tasks, while our model assumes many local tasks (situation-specific dialogue modeling) and one global task (general dialogue modeling).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed two situation-aware neural conver- sational models that have general mechanisms for handling various conversational situations rep- resented by discrete variables: (1) local-global SEQ2SEQ that combines two SEQ2SEQ models ( § 3.2.1) to handle situation-specific dialogues and universal dialogues jointly, and (2) SEQ2SEQ with situation embeddings ( § 3.2.2) that feeds the situa- tions directly to a SEQ2SEQ model. The response selection tests on massive Twitter datasets con- firmed the effectiveness of using situations such as utterances, user (profiles), or time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Conversational situations and responses.</figDesc><graphic url="image-1.png" coords="1,314.92,283.91,202.99,69.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Local-global SEQ2SEQ.</figDesc><graphic url="image-2.png" coords="3,71.59,59.52,218.68,167.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: SEQ2SEQ with situation embeddings.</figDesc><graphic url="image-3.png" coords="3,321.47,58.78,189.90,118.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Vocabulary</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The scattergram of sampled user profile vectors visualized using t-SNE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Hyperparameters for training. 

candidates which together constitute five response 
candidates for the response selection test. Each 
utterance and response (candidate) is tokenized by 
MeCab 5 with NEologd 6 dictionary to feed the se-
quence to the word-based encoder decoder. 7 Ta-
ble 1 shows statistics on our dialogue datasets. 

</table></figure>

			<note place="foot" n="1"> https://code.google.com/p/word2vec/ 2 We set k to 10. Although the space limitations preclude results when varying k, this does not affect our conclusions. 3 We set k to 10, and add another cluster for users whose profiles were not available (6.3% of the users in our datasets).</note>

			<note place="foot" n="5"> http://taku910.github.io/mecab/ 6 https://github.com/neologd/ mecab-ipadic-neologd 7 The number of words in the utterances and the response candidates in the test set is limited to equal or less than 20, since very long posts do not constitute usual conversation. 8 https://www.tensorflow.org/ 9 We randomly selected one false response candidate from the four pre-selected ones when t = 2.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Table filling multi-task recurrent neural network for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Andrassy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING-16)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2537" to="2547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Predicting and eliciting addressee&apos;s emotion in online dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Toyoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="964" to="972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP-16)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP-16)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Google&apos;s multilingual neural machine translation system: Enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04558</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third International Conference on Learning Representations</title>
		<meeting>the third International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICLR-15</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Small talk improves user impressions of interview dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takahiro</forename><surname>Kobori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikio</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoaki</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL-16)</title>
		<meeting>the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="370" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT-16)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Georgios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL-16)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP-16)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep multi-task learning with shared memory for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP-16)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentyFifth International Joint Conference on Artificial Intelligence (IJCAI-16)</title>
		<meeting>the TwentyFifth International Joint Conference on Artificial Intelligence (IJCAI-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2873" to="2879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-task sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth International Conference on Learning Representations</title>
		<meeting>the fifth International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR-16</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL-02)</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics (ACL-02)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">UT dialogue system at NTCIR-12 STC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoetsu</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga Shonosuke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Ishiwatari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaru</forename><surname>Toyoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 12th NTCIR Conference on Evaluation of Information Access Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="518" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP-15)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT-15)</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems (NIPS-14)</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems (NIPS-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A neural conversational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Deep Learning Workshop held at the 31st International Conference on Machine Learning (ICML-15)</title>
		<meeting>Deep Learning Workshop held at the 31st International Conference on Machine Learning (ICML-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantically conditioned lstm-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP15)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1711" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A networkbased end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M Rojas</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL-17)</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL-17)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Partially observable markov decision processes for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ranking responses oriented to conversational relevance in chat-bots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING-16)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="652" to="662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Topic aware neural response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI-17)</title>
		<meeting>the 31st AAAI Conference on Artificial Intelligence (AAAI-17)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3351" to="3357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recurrent neural network regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third International Conference on Learning Representations</title>
		<meeting>the third International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ICLR-14</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning discourse-level diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL-17)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL-17)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
