<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discourse-sensitive Automatic Identification of Generic Expressions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
							<email>{afried,pinkal}@coli.uni-saarland.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">Saarland University</orgName>
								<address>
									<settlement>Saarbrücken</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discourse-sensitive Automatic Identification of Generic Expressions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1272" to="1281"/>
							<date type="published">July 26-31, 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes a novel sequence labeling method for identifying generic expressions , which refer to kinds or arbitrary members of a class, in discourse context. The automatic recognition of such expressions is important for any natural language processing task that requires text understanding. Prior work has focused on identifying generic noun phrases; we present a new corpus in which not only subjects but also clauses are annotated for generic-ity according to an annotation scheme motivated by semantic theory. Our context-aware approach for automatically identifying generic expressions uses conditional random fields and outperforms previous work based on local decisions when evaluated on this corpus and on related data sets (ACE-2 and ACE-2005).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Distinguishing between statements about particu- lar individuals or situations and generic sentences is an important part of human language under- standing. Consider example (1): sentence (a) names characteristic attributes of a kind, which are inherent to every (typical) individual, and sentence (b) describes a specific individual. The above example illustrates that generic and non-generic sentences differ substantially in their semantic impact and entailment properties. It can be inferred from sentence (1a) that a typical horse has a life expectancy of 25 to 30 years, and if we know that Nelly is a horse, we can infer that its life expectancy is 25 to 30 years. Sentence (1b) has no such properties, it only allows inferences about the particular individual Old Billy.</p><p>An automatic classifier that recognizes generic expressions would be extremely valuable for var- ious kinds of natural language processing sys- tems: for text understanding and question answer- ing systems, through the improvement of textual entailment methods, and for systems acquiring machine-readable knowledge from text. Machine- readable knowledge bases have different repre- sentations for statements corresponding to generic knowledge about kinds and knowledge about spe- cific individuals. The non-generic sentence (1b) roughly speaking provides ABox content for a machine-readable knowledge base, i.e., knowl- edge about particular instances, e.g, "A is an in- stance of B / has property X". In contrast, the generic sentence (1a) feeds the TBox, i.e., knowl- edge of the form "All B are C / have property X". <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref> provide a detailed discus- sion of the relevance of the distinction between classes and instances for automatic ontology con- struction.</p><p>In this paper, we present a new corpus anno- tated in a linguistically motivated way for gener- icity, and a context-sensitive computational model for labeling sequences of clauses or noun phrases (NPs) with their genericity status. Both manual annotation and automatic recognition of generic expressions are challenging tasks: virtually all NP types -definites, indefinites and quantified NPs, full NPs, pronouns, and even proper names (e.g. species names such as Elephas maximus) -can be found in generic and non-generic uses depending on their clausal context.</p><p>In this work, we call clauses generic if they pro- vide a general characterization of entities of a cer- tain kind, and we call mentions of NPs generic if they refer to kinds or arbitrary members of a class. Although genericity on the clause-and NP-level are strongly interrelated, the concepts do not al- ways coincide. As example (2) shows, sentences describing episodic events can have a generic NP as their subject. Note that references to species are kind-referring / generic on the NP level (following <ref type="bibr" target="#b13">Krifka et al. (1995)</ref>, see p. 65).</p><p>(2) In September 2013 the blobfish was voted the "World's Ugliest Animal". (subject generic, clause non-generic)</p><p>Genericity often cannot be annotated without paying attention to the wider discourse context. Clearly, coreference information is needed for the genericity classification of pronouns. Often, even genericity of full NPs or entire clauses cannot be decided in isolation, as illustrated by example (3). Sentence (b) could be part of a particular narrative about a tree, or it could be a generic statement. Only the context given by (a) clarifies that (b) in- deed makes reference to any year's new twigs and is to be interpreted as generic. In computational linguistics, most research on detecting genericity has been done in relation to the ACE corpora ( <ref type="bibr" target="#b21">Mitchell et al., 2003;</ref><ref type="bibr" target="#b32">Walker et al., 2006</ref>), focusing on assigning genericity la- bels to noun phrases ( <ref type="bibr" target="#b28">Reiter and Frank, 2010)</ref>, see Section 2. Our work is based on these approaches, most notably on the work of <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref>, and extends upon them in the following essential ways.</p><p>The major contributions of this work are: (1) We create a new corpus of Wikipedia articles an- notated with linguistically motivated genericity la- bels both on the subject-and clause-level (see Sec- tion 3). The corpus is balanced with respect to genericity and about 10,000 clauses in size. (2) We present a discourse-sensitive genericity labeler. Technically, we use conditional random fields as a sequence labeling method (Section 4). We train and evaluate our method on the Wikipedia dataset and the ACE corpora, evaluating both the tasks of predicting NP genericity and the task of predicting clause-level genericity. Our labeler outperforms the state-of-the-art by a margin of 6.6-11.9% (de- pending on the data set) in terms of accuracy, at the same time increasing F 1 -score. Much of the per- formance gain is due to the inclusion of discourse information. For the discussion of our experimen- tal results, see Section 5.</p><p>In this paper, we do not address the following two important aspects of genericity. First, habit- ual sentences form a class of generalizing state- ments which bear a close relation to generics. As can be seen in example (4), they describe a char- acterizing property of either a specific entity or a class by generalizing over situations instead of or in addition to entities <ref type="bibr" target="#b3">(Carlson, 2005</ref>). We clas- sify habitual sentences with a generic subject as generic, and habitual sentences which describe a specific entity as non-generic, leaving the task of habituality detection for future work.</p><p>(4) (a) John smokes after dinner.</p><p>(b) Gentlemen smoke after dinner.</p><p>Second, generic clauses express regularities within classes of entities, and thus are similar to universally quantified sentences in their truth con- ditions and entailment properties. However, their truth-conditional interpretation is tricky, since they express typicality, describe stereotypes and al- low exceptions, for example Dutchmen are good sailors is not false even if most Dutchmen do not sail at all <ref type="bibr" target="#b2">(Carlson, 1977)</ref>. We concentrate on the decision of whether a clause is generic or not, and leave the truth-conditional interpretation for fur- ther work. For a detailed discussion of the seman- tics of generics expressions see the comprehensive survey by <ref type="bibr" target="#b13">Krifka et al. (1995)</ref>; a short and instruc- tive overview can be found in the first part of <ref type="bibr" target="#b28">(Reiter and Frank, 2010</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we first briefly review previously developed annotation schemes for genericity. We then describe work on automatically predicting the genericity of NPs or different types of clauses.</p><p>Annotation. ACE-2 ( <ref type="bibr" target="#b21">Mitchell et al., 2003)</ref> and <ref type="bibr">ACE-2005</ref><ref type="bibr" target="#b32">(Walker et al., 2006</ref>) are the two most notable annotation projects for labeling genericity of NPs to date. In the ACE-2 corpus, 40106 en- tity mentions in 520 newswire and broadcast doc- uments are marked with regard to whether they re- fer to "any member of the set in question" (GEN, generic) rather than "some particular, identifiable member of that set" (SPC, specific/non-generic). The major drawback of ACE-2 is that genericity is basically defined as lack of specificity, which leads to uncertainty and inconsistencies in the annota- tion process, and to a heterogeneous set of NPs labeled with GEN, including quantificational NPs and NPs in modalized, future, conditional, hypo- thetical, negated, uncertain, and question contexts. In addition, in both ACE-2 and ACE-2005, pred- icative and modifier uses of nouns, to which the genericity distinction is not applicable, also re- ceive labels (e.g. John seems to be a nice person / a subway system).</p><p>In the updated guidelines of ACE-2005, the la- bel USP (underspecified) is introduced for non- generic non-specific reference, including NPs in the various contexts mentioned above that were improperly labeled as generic in ACE-2. The class also contains mentions of an entity whose identity would be 'difficult to locate' (Officials re- ported ...). Moreover, annotators are asked to mark truly ambiguous cases that have both a generic and a non-generic reading as USP. Finally, NEG (negated) marks negatively quantified entities that refer to the empty set of the kind mentioned.</p><p>While we agree that in general there are under- specified cases, the guidelines for ACE-2005 mix other phenomena into the USP class, resulting in a high confusion between USP and both of the labels SPC and GEN in the manual annotations ( <ref type="bibr" target="#b9">Friedrich et al., 2015)</ref>. Data from two annota- tors is available, and we compute an agreement of Cohen's κ = 0.53 over the four labels. The ACE corpora consist only of news data, and the distribu- tions of labels are highly skewed towards specific mentions. For some criticism of the ACE annota- tion scheme, see also Suh (2006).</p><p>Several linguistically motivated annotation studies targeting genericity of noun phrases bear similarity to our annotation scheme (Section 3), but comprise very little data <ref type="bibr" target="#b26">(Poesio, 2004;</ref><ref type="bibr" target="#b11">Herbelot and Copestake, 2009</ref>). In the ARRAU corpus ( <ref type="bibr" target="#b25">Poesio and Artstein, 2008)</ref>, about 24321 mark- ables are tagged for genericity. <ref type="bibr" target="#b23">Nedoluzhko (2013)</ref> survey the treatment of genericity phenomena within coreference resolu- tion research; they find a consistent definition of genericity to be lacking. <ref type="bibr" target="#b8">Friedrich and Palmer (2014b)</ref> present an annotation scheme for situa- tion types including generic sentences, which they find to be infrequent in their corpus consisting of news, jokes and (fund-raising) letters. Our new WikiGenerics corpus contains more than 10,000 clauses, approximately half of which are generic.</p><p>Automatic Identification of Genericity. <ref type="bibr" target="#b31">Suh et al. (2006)</ref> propose a rule-based approach, which extracts only bare plurals and singular NPs quanti- fied with every or any as generic. <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref> use a wide range of syntactic and semantic features to train a supervised classifier for identi- fying generic NPs. We compare to their method (described in detail in Section 5.2) as a highly- competitive baseline.</p><p>Palmer et al. <ref type="formula">(2007)</ref> classify clauses into several types of situation entities including states, events, generalizing sentences (habitual utterances refer- ring to specific individuals) and generic sentences. They find that using context by using the labels of preceding clauses as features improves the classi- fication of clause types, but generic sentences are extremely sparse in their data set. Our present ap- proach uses a sequence labeling model that com- putes the best labeling for an entire sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">WikiGenerics: Data and Annotations</head><p>In order to study generics in a genre other than news (as in ACE), we turn to an encyclopedia, in which we expect many generics. We create our WikiGenerics corpus 1 as follows. We aim to cre- ate a corpus that is balanced in the sense that it contains many generic and non-generic sentences, and also generics from many different domains. We collect 102 texts about animals, organised crime, ethnic groups, games, sports, medicine, music, politics, religion, scientific disciplines and biographies from Wikipedia. For example, some sentences make statements about a 'natural' kind (Blobfish are typically shorter than 30 cm), others express definitions such as the rules of a football game (The offensive team must line up in a legal formation before they can snap the ball).</p><p>Generic clauses have the typical form of a pred- icative statement about the sentence topic, which is normally realized as the grammatical subject in English. Intuitions about NP-level genericity and its relation to clause-level genericity are quite reli- able for topic NPs of clauses, which also typically occur in subject position in English. Since gener- ics in non-subject positions are less frequent and hard to interpret (see the discussion of "dependent generics" by <ref type="bibr" target="#b16">Link (1995)</ref>), we decided to annotate subject NPs only. We are aware that we are miss- ing relevant cases (e.g. the less preferred reading of Cats chase mice, which attributes to mice the property of being chased by cats), but in this work, we want to study the "easier" subject cases as a first step.</p><p>We use the discourse parser SPADE <ref type="bibr" target="#b29">(Soricut and Marcu, 2003)</ref> to automatically segment the first 70 sentences of each article into clauses. Each clause is manually annotated with the following information (for more details on the annotation scheme, see <ref type="bibr" target="#b9">(Friedrich et al., 2015)</ref>):</p><p>• Task NP: whether or not the subject NP of the clause refers to a class or kind (generic vs. non- generic); • Task Cl: whether the clause is generic, defined as a clause that makes a characterizing state- ment about a class or kind, or non-generic.</p><p>• Task Cl+NP: using the information from Task NP and Cl above, we automatically derive the following classification for each clause (com- pare to the explanation of example <ref type="formula">(2)</ref>). -GEN gen: generic clause, subject is generic by definition (The lion is a predatory cat); -NON-GEN non-gen: non-generic clause with a non-generic subject ( Simba roared); -or NON-GEN gen: episodic clause with a generic subject (Dinosaurs died out). -GEN non-gen does not exist by definition.</p><p>We construct the gold standard for our experi- ments via majority voting over the labels given by three paid annotators, students of computational linguistics. Annotators were given a written man- ual and a short training on documents not included in the corpus. They are given the option to indicate segmentation errors, e.g. that two segments should actually be one, or that one segment contains mul- tiple clauses. In the latter case, we ask them to give labels for the first clause in the segment. 10240 (86%) of all pre-segmented clauses received labels for all three tasks from all annotators, who were allowed to skip clauses that do not contain a finite verb. Our gold standard includes an additional 115 segments that did not receive a label by one an- notator but were unanimously labeled by the other two. The other segments are disregarded in the ex- periments. Some of them have expletive subjects, and most others are non-finite verb phrases such as to-infinites or headlines that consist of only a NP. Inter-annotator agreement measured as <ref type="bibr">Fleiss' κ (Fleiss, 1971</ref>) on the segments labeled by all three annotators is 0.70, 0.73 and 0.69 for Task NP, Task Cl and Task Cl+NP respectively, indicating sub- stantial agreement <ref type="bibr" target="#b15">(Landis and Koch, 1977)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Sequence Labeling Model for Genericity</head><p>This section describes our method for identifying generic clauses and NPs in context. We apply the following methods on each of the three different prediction tasks NP, Cl and Cl+NP introduced in Section 3, varying only the type of labels on which we train and test. In contrast to prior work, our computational model integrates not only informa- tion from each local instance, but also informa- tion about the genericity status of surrounding in- stances. The final labeling for the sequence of in- stances of an entire document is optimized with regard to these two types of information, which, as we have argued in Section 1, both play a cru- cial role in determining genericity. The sequences to be labeled contain all clauses or NPs of a doc- ument. We also tried labeling sequences for para- graphs instead of documents, but the performance was similar. A reason might be that paragraphs are quite often linked by mentioning the same entities (Friedrich and Palmer, 2014a).</p><p>Computational model. We use linear chain conditional random fields ( <ref type="bibr" target="#b14">Lafferty et al., 2001</ref>) to label sequences of mentions or sequences of clauses with regard to their genericity. Conditional random fields (CRFs) are well suited for our label- ing task as they do not make an independence as- sumption between the features. CRFs predict the conditional probability of label sequence y given an observation sequence x as follows:</p><formula xml:id="formula_0">P ( y| x) = 1 Z( x) exp( n j=1 m i=1 λ i f i (y j−1 , y j , x, j))</formula><p>Z( x) is a normalization constant, the sum over the scores of all possible label sequences for an observation sequence with the length of x. The weights λ i of the feature functions are the param- eters to be learned. They do not depend on the cur- rent position j in the sequence. The feature func- tions f i are in general allowed to look at the cur- rent label y j , the previous label y j−1 and the entire observation sequence x. We use a simple instan- tiation of a linear chain CRF whose feature func- tions take two forms, f i (y j , x j ) and f i (y j−1 , y j ). We create a linear chain CRF model using the CRF++ toolkit 2 , using all the default parameters. <ref type="table">Table 1</ref>: Features. WN=WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NP-BASED FEATURES</head><note type="other">number sg, pl person 1, 2, 3 countability from Celex, e.g. count noun type common, proper, pronoun determiner type def, indef, demon part-of-speech POS of head bare plural true, false WN granularity number of edges to top node WN sense [0 − 2] WN senses (head+hypernyms) WN senseTop top sense in hypernym hierarchy WN lexical filename person, artifact, event, ... CLAUSE-BASED FEATURES dependency [0 − 4] dependency relation between head and governor etc. tense tense, aspect and voice informa- tion, e.g. pres perf active coarseTense pres, past, fut progressive true, false perfective true, false passive true, false temporal modifier true, false number of modifiers numeric part-of-speech POS of head predicate lemma of head adjunct-degree positive, comparative, superlative adjunct-pred lemma of adverbial clauses' head</note><p>Feature functions. We extract the set of features listed in <ref type="table">Table 1</ref> for each instance. This set of fea- tures is inspired by <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref>, see also Section 5.2. In the case of the WikiGener- ics corpus, the NP features are extracted for the subject of the clause. We parse the data using the Stanford parser ( <ref type="bibr" target="#b12">Klein and Manning, 2002</ref>) and obtain the subject NPs from the collapsed depen- dencies. For the ACE data, the NP features are extracted for all mentions in the gold standard and the clause features are extracted from the clause in which the mention appears. Our feature func- tions f i (y j , x j ) are indicator functions combining the current label and one of the feature values of the current mention or clause, for example: f = if (yj = GENERIC and xj.np.person=3) return 1 else return 0</p><p>We create two versions of the CRF model: the bigram 3 model additionally uses indicator func- tions f (y j−1 , y j ) for each combination of labels, thus taking context into account. The unigram model does not use these feature functions, it is thus similar to a maximum entropy model (with a different normalization). Log-linear models work very well for many NLP tasks, especially if fea- tures are correlated as it is the case here, so in or- <ref type="bibr">3</ref> Following CRF++ terminology. der to get a fair estimate of the impact of using the context (via the transition feature functions), we give numbers for this 'unigram' model in ad- dition, rather than simply comparing the bigram- CRF to a Bayesian network, which is used by <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref>. Using more complex feature functions did not result in significant per- formance gains, so we chose the simplest model. Note that even though the feature functions only formulate relationships between adjacent labels in the sequence, the optimal labeling is computed for the entire sequence: the choices of labels assigned to non-adjacent clauses do influence each other.</p><p>Two-step Approach for Task Cl+NP. Task Cl+NP can be regarded as a combination of the two decisions made in Task NP and Task Cl. Therefore, we approach Task Cl+NP in two ways. (a) We train a CRF which directly outputs the three labels. (b) The two-step approach combines the output from the labelers trained for Task NP and Task Cl into one label in a rule-based way. This leads to the additional class GEN non-gen, of which no gold instances exist by definition. As we evaluate in terms of F 1 -score and accuracy for the existing classes, items classified into this arti- ficial class will simply be counted as wrong and lack from the recall counts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>This section reports on our experiments, which we evaluate in terms of precision (P), recall (R) and F 1 -measure per class. We compute macro- averages as P macro = 1 |c| * |c| i=1 P i etc., where |c| stands for the number of classes. Macro-F 1 is the harmonic mean of macro-average P and R. To re- port on statistical significance of differences in ac- curacy, we apply McNemar's test with p &lt; 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings and Data</head><p>We report results for cross validation (CV). Be- cause we leverage contextual information by la- beling sequences of clauses from entire docu- ments, for all experiments presented in this sec- tion, if not indicated otherwise, we put all in- stances of one document into the same fold as one sequence. Fold sizes differ slightly from each other, but folds are kept constant for all experi- ments.</p><p>On WikiGenerics, we carry out all three predic- tion tasks as defined in Section 3. On the ACE cor- pora, we only conduct Task NP because there are   <ref type="table">Table 2</ref>: Results of reimplemented baseline on ACE-2 (original, unbalanced data set), 40106 instances (annotated noun phrases). Weka's stratified 10-fold cross validation, using all features.</p><p>no labels corresponding to Task Cl or Task Cl+NP.</p><p>For the experiments on WikiGenerics, we use leave-one-document-out CV, i.e., we train on 101 of the 102 documents and test on the remain- ing document in each fold. The total number of clauses is 10355. From ACE-2005, we use the newswire and broadcast news subsections. <ref type="bibr">4</ref> Due to low frequency, we omit instances of NEG in our experiments, and apply a three-way classification task (GEN, SPC, USP). We present results for all remaining 40106 mentions and for the subset of 18029 subject mentions, each time using 10-fold CV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline: Local Classifier</head><p>The system for identifying generic NPs of <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref>, henceforth R&amp;F, makes use of the English ParGram LFG grammar for the XLE parser ( <ref type="bibr" target="#b1">Butt et al., 2002</ref>). As this grammar is not publicly available, we implement a similar system using exclusively the Stanford CoreNLP toolsuite ( <ref type="bibr" target="#b18">Manning et al., 2014</ref>), the Celex database of En- glish nouns ( <ref type="bibr" target="#b0">Baayen et al., 1996)</ref> and WordNet <ref type="bibr" target="#b5">(Fellbaum, 1999)</ref>. Our system is based on dkpro ( <ref type="bibr" target="#b4">de Castilho and Gurevych, 2014</ref>). We extract the features listed in <ref type="table">Table 1</ref> based on the POS tags and syntactic dependencies assigned by the Stan- ford parser ( <ref type="bibr" target="#b12">Klein and Manning, 2002</ref>). We could not reimplement several tense-and aspect-related ParGram-specific features. In order to compen- sate for this, we add an additional feature (tense) with finer-grained tense and voice information, us- ing the rules described by <ref type="bibr" target="#b17">Loaiciga et al. (2014)</ref>. Other additional features did not improve perfor- mance, which shows that R&amp;F's set of features captures the syntactic-semantic information rele- vant to genericity classification quite well. There- fore, we use this feature set also for the sequence labeling model. Using the same feature set allows us to attribute any performance gain to the context-awareness of our model rather than the features.</p><p>R&amp;F train a Bayesian network using Weka <ref type="figure">(Hall et al., 2009)</ref>. The decisions of this clas- sifier are local to each clause. They report the performance of their system on the ACE-2 cor- pus: <ref type="table">Table 2</ref> shows that the performance of our re- implemented feature set 5 is comparable to the sys- tem of R&amp;F. <ref type="bibr">6</ref> In all other other tables, "BayesNet R&amp;F" refers to our re-implemented system. R&amp;F present the "Person baseline" as a sim- ple informed baseline (see <ref type="table">Table 2</ref>). We trained a J48 decision tree on this feature alone, which confirmed that only second-person mentions (the generic "you") are classified as generic, while all other mentions are classified as non-generic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and Discussion</head><p>In this section, we first discuss the results of our experiments in terms of identifying generic NPs or clauses. Then we present some additional experi- ments testing the influence of the different feature classes and of other discourse-related information.</p><p>All tasks, WikiGenerics. The observations de- scribed in this paragraph are the same for all three prediction tasks on WikiGenerics. <ref type="table" target="#tab_2">As Tables 3 and  4</ref> show, our CRF models outperform the baseline system of R&amp;F by a large margin both in terms of accuracy and F 1 -score on the WikiGenerics cor- pus. In Task NP and Task Cl, precision and re- call are quite balanced (not shown in tables). The performance of the bigram model is significantly better than that of the unigram model, increasing accuracy by about 3%, at the same time increas- ing F 1 . In an oracle experiment, we use the pre- vious gold label instead of the predicted one for f i (y j−1 , y j ), and scores increase by up to 6.6% compared to the unigram model. These results provide strong empirical evidence for our hypoth-   esis that using context information is useful for identifying the genericity of NPs or clauses.</p><note type="other">Task NP: Genericity of Subject Task Cl: Genericity of Clause generic non-</note><note type="other">-only clause features 79.2 71.6 75.5 76.0 79.3 78.3 78.8 78.8 -only NP features 76.8 70.8 73.8 74.1 70.7 72.6 71.8 71.7 CRF (bigram, gold) 85.0 80.4 82.7 83.0 82.9 82.6 82.8 82.8</note><p>Task Cl+NP, WikiGenerics. In Task Cl+NP (see <ref type="table" target="#tab_3">Table 4</ref>), only about 6% of the instances have the gold label NON-GEN gen (i.e., a non- generic sentence with a generic subject), the other instances are distributed roughly evenly between the other two labels. The difficulty of Task Cl+NP thus consists in identifying this infrequent case. The three-way CRF outperforms the two-step ap- proach both in terms of accuracy and macro- average F 1 -score. The precision-recall tradeoff differs: for the NON-GEN gen class, P and R of the CRF are 55.2% and 24.5% and those of the two-step-approach are 23.8% and 35.9%. The two-step approach labels more instances as NON- GEN gen but does so in a less precise way. While the performance of our model leaves room for im- provement on Task Cl+NP, especially with regard to the class NON-GEN gen, it is worth noting that the computational model captures something about the nature of this latter class; its instances do look different in the feature space. The context- aware CRF using three labels performs best.</p><p>Feature set ablation. In this ablation test, shown in <ref type="table" target="#tab_2">Tables 3 and 4</ref>, our best model (CRF bi- gram) uses either the set of clause-based or the set of NP-based features at a time. Clause-based fea- tures are more important than the NP-based fea- tures for all three classification tasks. An inter- esting observation is that the NP features alone are not able to separate the infrequent class NON- GEN gen from the other two at all, the F 1 -score of 2.5 shows that almost all instances of this class were labeled as one of the other two classes. In sum, this shows that whether an NP is interpreted as generic or not strongly depends on how it is used in the clause.</p><p>Task NP, ACE. Both on ACE-2 (see <ref type="table" target="#tab_5">Table 5</ref>) and on ACE-2005 (see <ref type="table" target="#tab_6">Table 6</ref>), the CRF outper- forms the system of <ref type="bibr" target="#b28">Reiter and Frank (2010)</ref> in terms of accuracy, and has a higher F 1 -score. We give results also for subjects only as this parallels the setting of the WikiGenerics experiments (rea- sons for the restriction to subjects were given in Section 3). For subjects, the majority class SPC is less frequent (compare the accuracies of the two majority class baselines); only 7% of the sub- jects are marked as GEN, the rest are labeled as USP. The bigram model does not outperform the unigram model, but our oracle experiments show that context information is indeed useful: accuracy increases significantly and F 1 increases consider- ably, especially for subjects.    We identify two reasons for the fact that when evaluating on the ACE corpora, oracle information is needed to show the benefit of using bigram fea- ture functions: (a) The frequency of GEN men- tions in the ACE corpora is low -news contains only little generic information, so the context in- formation is harder to leverage. (b) The ACE an- notation guidelines contain some vagueness (see Section 3); this makes it harder for an automatic system to learn about regularities.</p><p>Higher-order Markov models. Another re- search question is whether models incorporating not only the previous label, but more preceding la- bels would perform even better. We turn to the Mallet toolkit <ref type="bibr" target="#b20">(McCallum, 2002</ref>), whose CRF im- plementation allows for using higher-order mod- els. <ref type="bibr">7</ref> For example, an order-2 model considers the two previous labels. We use L1-regularization dur- ing training. <ref type="figure" target="#fig_0">Figure 1</ref> shows that the optimum is reached for order-1 (bigram) models for each of the classification tasks for accuracy, the same ten- <ref type="bibr">7</ref> The CRF++ toolkit, which we use in all other exper- iments, does not allow for higher-order models. We use CRF++ in the main experiments as it comes with a concise documentation; this helps to make our experiments easily replicable. Using coreference information. In our approx- imately balanced WikiGenerics corpus, 54% of all pronouns are marked as generic and 46% are marked as non-generic, which shows that there is no preference for pronouns to occur with either class. Some of the features (countability, noun type, determiner type, bare plural, and the Word- Net related features) are not informative when ap- plied to personal or relative pronouns. Sometimes, it is not even possible to determine number with- out referring to the antecedent (e.g., in the case of the relative pronoun 'who'). We conduct the following experiment: we automatically resolve coreference using the Stanford coreference reso- lution system <ref type="bibr" target="#b27">(Raghunathan et al., 2010)</ref>. We re- place the NP features of each pronominal instance with the features of the first link of the coreference chain. We did not obtain a significant performance gain. One reason is that this change of features only applies to about 13% of the data. We observe that any positive changes in the classification go along with some negative changes which were of- ten due to coreference resolution errors. One dif- ficult step in manually annotating, and hence also in automatically resolving coreference is to deter- mine whether a NP is generic or not <ref type="bibr" target="#b23">(Nedoluzhko, 2013)</ref>. The task of identifying generic NPs and coreference resolution are intertwined. We plan to manually annotate at least part of our corpus with coreference information in order to test to what ex- tent the classification of the pronouns' genericity status can profit from including antecedent infor- mation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented a novel method for labeling se- quences of clauses or their subjects with regard to their genericity, showing that genericity should be treated as a discourse-sensitive phenomenon. Our experiments prove that context information improves automatic labeling results, and that our model outperforms previous approaches by a large margin.</p><p>The major contributions of this work include the study of genericity both on the NP-and clause- level, and the study of the interaction of these two levels. Our results of Task Cl+NP show that our model indeed captures the three different types of clauses resulting from the combination of NP- level and clause-level genericity.</p><p>During the development of our annotation scheme, we found that it is beneficial to focus on genericity, disentangling it from the issue of specificity. Our work provides a step forward to finding reliable ways to apply semantic theories of genericity in practice, and we also provide a new state-of-the-art system for automatically la- beling generic expressions. This in turn lays foun- dations for natural language processing tasks re- quiring text understanding.</p><p>Future Work. Our present approach for anno- tating and automatically classifying targets the subjects of each clause. We have not attempted to tackle the task of classifying the genericity sta- tus of other dependents, as they are even harder to classify than subjects, and a concise annotation scheme has to be worked out in order achieve an acceptable inter-annotator agreement on this task. Another related distinction is the one between ha- bitual, stative and episodic sentences <ref type="bibr" target="#b19">(Mathew and Katz, 2009)</ref>, which applies to both what we call generic and non-generic sentences. No large cor- pora exist to date, but studying the interaction of these phenomena is on our research agenda.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>( 1 )</head><label>1</label><figDesc>(a) The modern domestic horse has a life expectancy of 25 to 30 years. (generic) (a) Old Billy lived to the age of 62. (non-generic)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 3 )</head><label>3</label><figDesc>(a) Sugar maples also have a tendency to color unevenly in fall. (generic) (b) The recent year's growth twigs are green and turn dark brown. (generic)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Labeling results for CRF models of various orders on WikiGenerics corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results on WikiGenerics for Task NP and Task C. * †Difference statistically significant. 

Task Cl+NP: Genericity of Clause (three-way) 
GEN gen NON-GEN non-gen NON-GEN gen 
macro-avg 
System 
F1 
F1 
F1 
P 
R 
F1 
accuracy 

Majority class 
67.1 
0.0 
0.0 
16.8 33.3 22.4 
50.4 
BayesNet (R&amp;F) 
69.1 
69.1 
26.1 
54.5 58.4 56.4 
65.2 
CRF (unigram) 
78.5 
72.6 
35.4 
67.2 60.0 63.4 
74.0* 
CRF (bigram) 
81.3 
76.9 
33.4 
70.3 61.8 65.8 
77.4* 
-two-step 
80.8 
75.8 
28.6 
61.5 62.3 61.9 
73.4 
-only clause feat. 
79.4 
72.6 
25.3 
67.0 57.2 61.8 
74.3 
-only NP feat. 
72.9 
71.4 
2.5 
53.0 49.9 51.4 
70.0 
CRF (bigram, gold) 
84.0 
80.6 
39.1 
72.8 65.7 69.0 
80.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results on WikiGenerics for Task Cl+NP. *Difference statistically significant. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on ACE-2 for Task NP, 10-fold CV, folds contain complete documents. *Difference 
statistically significant. 

macro-avg 
System 
P 
R 
F1 accuracy 
all 18029 annotated mentions 
Majority class 
27.0 33.3 29.9 
81.1 
BayesNet (R&amp;F) 
50.8 57.2 53.8 
74.5 
CRF (unigram) 
61.6 51.8 55.1 
83.2* 
CRF (bigram) 
60.6 51.7 54.8 
83.0 
CRF (bigram, gold) 63.9 54.9 58.2 
83.9* 
5670 subject mentions 
Majority class 
25.0 33.3 28.6 
75.1 
BayesNet (R&amp;F) 
51.5 53.9 52.7 
72.5 
CRF (unigram) 
58.0 51.3 53.6 
77.7* 
CRF (bigram) 
58.3 51.3 53.7 
77.8 
CRF (bigram, gold) 62.4 56.1 58.6 
79.6* 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Results on ACE-2005 (bn+nw), 
Task NP, 10-fold CV, 3 classes: SPC, GEN, USP. 
*Difference statistically significant. 

</table></figure>

			<note place="foot" n="1"> The WikiGenerics corpus is freely available at: www.coli.uni-saarland.de/projects/sitent</note>

			<note place="foot" n="2"> https://code.google.com/p/crfpp</note>

			<note place="foot" n="4"> The rest of the data comprise broadcast conversation, weblog and forum texts as well as transcribed conversational telephone, and would require specialized preprocessing.</note>

			<note place="foot" n="5"> Implementation available at: www.coli.uni-saarland.de/projects/sitent 6 Table 6 in Reiter and Frank&apos;s paper contains some typographical errors here. We thank Nils Reiter for making available his ARFF files, so we can provide this updated version.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Alexis Palmer, Nils Reiter and Melissa Peate Sørensen for their helpful comments related to this work, and our annotators Christine Bocionek and Kleo-Isidora Mavridou. This research was supported in part by the Cluster of Excellence "Multimodal Computing and Interaction" of the German Excel-lence Initiative (DFG), and the first author is sup-ported by an IBM PhD Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><forename type="middle">R</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Piepenbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Gulikers</surname></persName>
		</author>
		<title level="m">CELEX2. Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The parallel grammar project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miriam</forename><surname>Butt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Dyvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><forename type="middle">Holloway</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Masuichi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Rohrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 workshop on Grammar engineering</title>
		<meeting>the 2002 workshop on Grammar engineering</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Reference to kinds in English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gregory Norman Carlson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">N</forename><surname>Carlson</surname></persName>
		</author>
		<title level="m">Encyclopedia of Language and Linguistics</title>
		<editor>Alex Barber</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Generics, Habituals and Iteratives</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A broad-coverage collection of portable NLP components for building shareable analysis pipelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Eckart De Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING</title>
		<meeting>the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Measuring nominal scale agreement among many raters. Psychological bulletin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joseph L Fleiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">378</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Centering Theory in natural text: a large-scale corpus study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KONVENS 2014</title>
		<meeting>KONVENS 2014</meeting>
		<imprint>
			<publisher>Universitätsbibliothek Hildesheim</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Situation entity annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Annotation Workshop VIII</title>
		<meeting>the Linguistic Annotation Workshop VIII</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Annotating genericity: a survey, a scheme, and a corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><forename type="middle">Peate</forename><surname>Srensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th Linguistic Annotation Workshop</title>
		<meeting>the 9th Linguistic Annotation Workshop<address><addrLine>Denver, Colorado, US</addrLine></address></meeting>
		<imprint>
			<publisher>LAW IX</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The WEKA data mining software: an update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Annotating genericity: How do humans decide? (A case study in ontology extraction)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelie</forename><surname>Herbelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in Generative Grammar</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page">103</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast exact inference with a factored model for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Genericity: An Introduction. The Generic Book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Krifka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">Jeffrey</forename><surname>Pelletier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">N</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Ter Meulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Godehard</forename><surname>Link</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gennaro</forename><surname>Chierchia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning, ICML &apos;01</title>
		<meeting>the Eighteenth International Conference on Machine Learning, ICML &apos;01<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Generic information and dependent generics. The Generic Book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Godehard</forename><surname>Link</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="358" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">English-French Verb Phrase Alignment in Europarl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharid</forename><surname>Loaiciga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescubelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP Natural Language Processing Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Supervised Categorization of Habitual and Episodic Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Graham</forename><surname>Mathew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Midwest Computational Linguistics Colloquium</title>
		<meeting><address><addrLine>Bloomington, Indiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Indiana University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">MALLET: A Machine Learning for Language Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew K Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Brunstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sundheim</surname></persName>
		</author>
		<idno>ACE-2 Version 1.0</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ldc2003t11</forename><surname>Philadelphia</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generic noun phrases and annotation of coreference and bridging relations in the Prague Dependency Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A sequencing model for situation entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elias</forename><surname>Ponvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlota</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Anaphoric Annotation in the ARRAU Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Discourse annotation and semantic annotation in the GNOME corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACL Workshop on Discourse Annotation</title>
		<meeting>the 2004 ACL Workshop on Discourse Annotation</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="72" to="79" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A multipass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Identifying Generic Noun Phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="40" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sentence level discourse parsing using syntactic and lexical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Extracting common sense knowledge from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangweon</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Halpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Web Content Mining with Human Language Technologies at ISWC</title>
		<meeting>the Workshop on Web Content Mining with Human Language Technologies at ISWC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Extracting Generic Statements for the Semantic Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangweon</forename><surname>Suh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<title level="m">ACE 2005 Multilingual Training Corpus LDC2006T06. Philadelphia: Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
