<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<addrLine>969 West Wenyi Road</addrLine>
									<postCode>311121</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<addrLine>969 West Wenyi Road</addrLine>
									<postCode>311121</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<addrLine>969 West Wenyi Road</addrLine>
									<postCode>311121</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1705" to="1714"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1705</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes a novel hierarchical attention network for reading comprehension style question answering, which aims to answer questions for a given narrative paragraph. In the proposed method, attention and fusion are conducted horizontally and vertically across layers at different levels of granularity between question and paragraph. Specifically, it first encode the question and paragraph with fine-grained language embeddings, to better capture the respective representations at semantic level. Then it proposes a multi-granularity fusion approach to fully fuse information from both global and attended representations. Finally, it introduces a hierarchical attention network to focuses on the answer span progressively with multi-level soft-alignment. Extensive experiments on the large-scale SQuAD and TriviaQA datasets validate the effectiveness of the proposed method. At the time of writing the paper (Jan. 12th 2018), our model achieves the first position on the SQuAD leader-board for both single and ensemble models. We also achieves state-of-the-art results on TriviaQA, AddSent and AddOne-Sent datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a brand new field in question answering com- munity, reading comprehension is one of the key problems in artificial intelligence, which aims to read and comprehend a given text, and then an- swer questions based on it. This task is chal- lenging which requires a comprehensive under- standing of natural languages and the ability to do further inference and reasoning. Restricted by the limited volume of the annotated dataset, early studies mainly rely on a pipeline of NLP models to complete this task, such as seman- tic parsing and linguistic annotation ( <ref type="bibr" target="#b6">Das et al., 2014</ref>). Not until the release of large-scale cloze- style dataset, such as Children's Book Test <ref type="bibr" target="#b9">(Hill et al., 2015)</ref> and CNN/Daily Mail ( <ref type="bibr" target="#b8">Hermann et al., 2015)</ref>, some preliminary end-to-end deep learning methods have begun to bloom and achieve supe- rior results in reading comprehension task <ref type="bibr" target="#b8">(Hermann et al., 2015;</ref><ref type="bibr" target="#b5">Cui et al., 2016)</ref>.</p><p>However, these cloze-style datasets still have their limitations, where the goal is to predict the single missing word (often a named entity) in a passage. It requires less reasoning than previously thought and no need to comprehend the whole pas- sage ( . Therefore, Stanford pub- lish a new large-scale dataset <ref type="bibr">SQuAD (Rajpurkar et al., 2016)</ref>, in which all the question and an- swers are manually created through crowdsourc- ing. Different from cloze-style reading compre- hension dataset, SQuAD constrains answers to all possible text spans within the reference passage, which requires more logical reasoning and content understanding.</p><p>Benefiting from the availability of SQuAD benchmark dataset, rapid progress has been made these years. The work ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref> and <ref type="bibr" target="#b24">(Seo et al., 2016</ref>) are among the first to investigate into this dataset, where Wang and Jiang propose an end-to-end architecture based on match-LSTM and pointer networks ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref>, and Seo et al. introduce the bi-directional atten- tion flow network which captures the question- document context at different levels of granular- ity ( <ref type="bibr" target="#b24">Seo et al., 2016</ref>). Chen et al. devise a sim- ple and effective document reader, by introducing a bilinear match function and a few manual fea- tures ( <ref type="bibr" target="#b1">Chen et al., 2017a</ref>). <ref type="bibr">Wang et al. propose</ref> a gated attention-based recurrent network where self-match attention mechanism is first incorpo- rated ( <ref type="bibr" target="#b28">Wang et al., 2017</ref>). In ( <ref type="bibr" target="#b17">Liu et al., 2017b)</ref> and , the multi-turn memory net- works are designed to simulate multi-step reason- ing in machine reading comprehension.</p><p>The idea of our approach derives from the nor- mal human reading pattern. First, people scan through the whole passage to catch a glimpse of the main body of the passage. Then with the ques- tion in mind, people make connection between passage and question, and understand the main in- tent of the question related with the passage theme. A rough answer span is then located from the pas- sage and the attention can be focused on to the lo- cated context. Finally, to prevent from forgetting the question, people come back to the question and select a best answer according to the previously lo- cated answer span.</p><p>Inspired by this, we propose a hierarchical at- tention network which can gradually focus the at- tention on the right part of the answer boundary, while capturing the relation between the question and passage at different levels of granularity, as il- lustrated in <ref type="figure" target="#fig_1">Figure 1</ref>. Our model mainly consists of three joint layers: 1) encoder layer where pre- trained language models and recurrent neural net- works are used to build representation for ques- tions and passages separately; 2) attention layer in which hierarchical attention networks are de- signed to capture the relation between question and passage at different levels of granularity; 3) match layer where refined question and passage are matched under a pointer-network ( <ref type="bibr" target="#b26">Vinyals et al., 2015</ref>) answer boundary predictor.</p><p>In encoder layer, to better represent the ques- tions and passages in multiple aspects, we com- bine two different embeddings to give the funda- mental word representations. In addition to the typical glove word embeddings, we also utilize the ELMo embeddings ( <ref type="bibr" target="#b22">Peters et al., 2018</ref>) de- rived from a pre-trained language model, which shows superior performance in a wide range of NLP problems. Different from the original fusion way for intermediate layer representations, we de- sign a representation-aware fusion method to com- pute the output ELMo embeddings and the context information is also incorporated by further passing through a bi-directional LSTM network.</p><p>The key in machine reading comprehension so- lution lies in how to incorporate the question con- text into the paragraph, in which attention mech- anism is most widely used. Recently, many dif- ferent attention functions and types have been de- signed ( <ref type="bibr" target="#b29">Xiong et al., 2016;</ref><ref type="bibr" target="#b24">Seo et al., 2016;</ref><ref type="bibr" target="#b28">Wang et al., 2017)</ref>, which aims at properly aligning the question and passage. In our attention layer, we propose a hierarchical attention network by leveraging both the co-attention and self-attention mechanism, to gradually focus our attention on the best answer span. Different from the previous attention-based methods, we constantly comple- ment the aligned representations with global infor- mation from the previous layer, and an additional fusion layer is used to further refine the represen- tations. In this way, our model can make some minor adjustment so that the attention will always be on the right place.</p><p>Based on the refined question and passage rep- resentation, a bilinear match layer is finally used to identify the best answer span with respect to the question. Following the work of ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref>, we predict the start and end bound- ary within a pointer-network output layer.</p><p>The proposed method achieves state-of-the-art results against strong baselines. Our single model achieves 79.2% EM and 86.6% F1 score on the hidden test set, while the ensemble model further boosts the performance to 82.4% EM and 88.6% F1 score. At the time of writing the paper (Jan. 12th 2018), our model SLQA+ (Semantic Learn- ing for Question Answering) achieves the first po- sition on the SQuAD leaderboard 1 for both single and ensemble models. Besides, we are also among the first to surpass human EM performance on this golden benchmark dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Machine Reading Comprehension</head><p>Traditional reading comprehension style question answering systems rely on a pipeline of NLP mod- els, which make heavy use of linguistic annota- tion, structured world knowledge, semantic pars- ing and similar NLP pipeline outputs ( <ref type="bibr" target="#b8">Hermann et al., 2015)</ref>. Recently, the rapid progress of ma- chine reading comprehension has largely bene- fited from the availability of large-scale bench- mark datasets and it is possible to train large end-to-end neural network models. Among them, CNN/Daily Mail ( <ref type="bibr" target="#b8">Hermann et al., 2015)</ref> and Chil- dren's Book Test <ref type="bibr" target="#b9">(Hill et al., 2015)</ref> are the first large-scale datasets for reading comprehension task. However, these datasets are in cloze-style, in which the goal is to predict the missing word (often a named entity) in a passage. Moreover, Chen at al. have also shown that these cloze- style datasets requires less reasoning than previ- ously thought . Different from the previous datasets, the SQuAD provides a more challenging benchmark dataset, where the goal is to extract an arbitrary answer span from the origi- nal passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Attention-based Neural Networks</head><p>The key in MRC task lies in how to incorpo- rate the question context into the paragraph, in which attention mechanism is most widely used.</p><p>In spite of a variety of model structures and atten- tion types ( <ref type="bibr" target="#b5">Cui et al., 2016;</ref><ref type="bibr" target="#b29">Xiong et al., 2016;</ref><ref type="bibr" target="#b24">Seo et al., 2016;</ref><ref type="bibr" target="#b28">Wang et al., 2017;</ref><ref type="bibr" target="#b4">Clark and Gardner, 2017)</ref>, a typical attention-based neural network model for MRC first encodes the symbolic repre- sentation of the question and passage in an embed- ding space, then identify answers with particular attention functions in that space. In terms of the question and passage attention or matching strat- egy, we roughly categorize these attention-based models into two large groups: one-way attention and two-way attention.</p><p>In one-way attention model, question is first summarized into a single vector and then directly matched with the passage. Most of the end-to- end neural network methods on the cloze-style datasets are based on this model ( <ref type="bibr" target="#b8">Hermann et al., 2015;</ref><ref type="bibr" target="#b14">Kadlec et al., 2016;</ref><ref type="bibr" target="#b7">Dhingra et al., 2016</ref>). Hermann et al. are the first to apply the attention-based neural network meth- ods to MRC task and introduce an attentive reader and an impatient reader ( <ref type="bibr" target="#b8">Hermann et al., 2015)</ref>, by leveraging a two layer LSTM network. ) further design a bilin- ear attention function based on the attentive reader, which shows superior performance on CNN/Daily Mail dataset. However, part of information may be lost when summarizing the question and a fine- grained attention on both the question and passage words should be more reasonable.</p><p>Therefore, the two-way attention model un- folds both the question and passage into respective word embeddings, and compute the attention in a two-dimensional matrix. Most of the top-ranking methods on SQuAD leaderboard are based on this attention mechanism ( <ref type="bibr" target="#b28">Wang et al., 2017;</ref><ref type="bibr" target="#b30">Xiong et al., 2017;</ref><ref type="bibr">Liu et al., 2017b,a)</ref>. ( <ref type="bibr" target="#b5">Cui et al., 2016)</ref> and <ref type="bibr" target="#b29">(Xiong et al., 2016</ref>) intro- duce the co-attention mechanism to better couple the representations of the question and document. Seo et al. propose a bi-directional attention flow network to capture the relevance at different lev- els of granularity ( <ref type="bibr" target="#b24">Seo et al., 2016)</ref>. ( <ref type="bibr" target="#b28">Wang et al., 2017)</ref> further introduce the self-attention mecha- nism to refine the representation by matching the passage against itself, to better capture the global passage information. Huang et al. introduce a fully-aware attention mechanism with a novel history-of-word concept ( ).</p><p>We propose a hierarchical attention network by leveraging both co-attention and self-attention mechanisms in different layers, which can capture the relevance between the question and passage at different levels of granularity. Different from the above methods, we further devise a fusion func- tion to combine both the aligned representation and the original representation from the previous layer within each attention. In this way, the model can always focus on the right part of the passage, while keeping the global passage topic in mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Machine Comprehension Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Description</head><p>Typical machine comprehension systems take an evidence text and a question as input, and pre- dict a span within the evidence that answers the question. Based on this definition, given a pas- sage and a question, the machine needs to first read and understand the passage, and then finds the an- swer to the question. The passage is described as a sequence of word tokens P = , where n is the number of words in the passage, and m is the number of words in the question. In general, n m. The answer can have differ- ent types depending on the task. In the SQuAD dataset ( <ref type="bibr" target="#b23">Rajpurkar et al., 2016</ref>), the answer A is guaranteed to be a continuous span in the pas- sage P. The object function for machine read- ing comprehension is to learn a function f(q, p) = arg max a∈A(p) P(a|q, p). The training data is a set of the question, passage and answer tuples &lt; Q, P, A &gt;. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Encode-Interaction-Pointer Framework</head><p>We will now describe our framework from the bot- tom up. As show in <ref type="figure" target="#fig_1">Figure 1</ref>, the proposed frame- work consists of four typical layers to learn differ- ent concepts of semantic representations:</p><p>• Encoder Layer as a language model, utilizes contextual cues from surrounding words to re- fine the embedding of the words. It converts the passage and question from tokens to semantic representation; • Attention Layer attempts to capture relations between question and passage. Besides the aligned context, the contextual embeddings are also merged by a fusion function. Moreover, the multi-level of this operation forms a "work- ing memory"; • Match Layer employs a bi-linear match func- tion to compute the relevance between the question and passage representation on a span level; • Output Layer uses a pointer network to search the answer span of question.</p><p>The main contribution of this work is the atten- tion layer, in order to capture the relationship be- tween question and passage, a hierarchical strat- egy is used to progressively make the answer boundary clear with the refined attention mecha- nism. A fine-grained fusion function is also in- troduced to better align the contextual representa- tions from different levels. The detailed descrip- tion of the model is provided as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Hierarchical Attention Fusion Network</head><p>Our design is based on a simple but natural in- tuition: performing fine-grained mechanism re- quires first to roughly see the potential answer do- main and then progressively locate the most dis- criminative parts of the domain.</p><p>The overall framework of our Hierarchical At- tention Fusion Network is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. It consists of several parts: a basic co-attention layer with shallow semantic fusion, a self-attention layer with deep semantic fusion and a memory- wise bilinear alignment function. The proposed network has two distinctive characteristics: (i) A fine-grained fusion approach to blend atten- tion vectors for a better understanding of the re- lationship between question and passage; (ii) A multi-granularity attention mechanism applied at the word and sentence-level, enabling it to prop- erly attend to the most important content when constructing the question and passage representa- tion. Experiments conducted on SQuAD and ad- versarial example datasets <ref type="bibr" target="#b12">(Jia and Liang, 2017)</ref> demonstrate that the proposed framework outper- form previous methods by a large margin. Details of different components will be described in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Language Model &amp; Encoder Layer</head><p>Encoder layer of the model transform the dis- crete word tokens of question and passage to a se- quence of continuous vector representations. We use a pre-trained word embedding model and a char embedding model to lay the foundation for our model. For the word embedding model, we adopt the popular glove embeddings <ref type="bibr" target="#b21">(Pennington et al., 2014</ref>) which are widely used in deep learning-based NLP domain. For the char em- bedding model, the ELMo language model <ref type="bibr" target="#b22">(Peters et al., 2018</ref>) is used due to its superior perfor- mance in a wide range of NLP tasks. As a result, we obtain two types of encoding vectors, i.e., word embeddings To further utilize contextual cues from sur- rounding words to refine the embedding of the words, we then put a shared Bi-LSTM network on top of the embeddings provided by the previ- ous layers to model the temporal interactions be- tween words. Before feeding into the Bi-LSTM contextual network, we concat the word embed- dings and char embeddings for a full understand- ing of each word. The final output of our encoder layer is shown as below,</p><formula xml:id="formula_0">u Q t = BiLSTM Q ([e Q t , c Q t ]), c Q t<label>(1)</label></formula><formula xml:id="formula_1">u P t = BiLSTM P ([e P t , c P t ]), c P t<label>(2)</label></formula><p>where we further concat the output of the con- textual Bi-LSTM network with the pre-trained char embeddings for its good performance ( <ref type="bibr" target="#b22">Peters et al., 2018)</ref>. This can be regarded as a residual connection between word representations in dif- ferent levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Hierarchical Attention &amp; Fusion Layer</head><p>The attention layer is responsible for linking and fusing information from the question and passage representation, which is the most critical in most MRC tasks. It aims to align the question and pas- sage so that we can better locate on the most rele- vant passage span with respect to the question. We propose a hierarchical attention structure by com- bining the co-attention and self-attention mecha- nism in a multi-hop style. Besides, we think that the original representation and the aligned repre- sentation via attention can reflect the content se- mantics in different granularities. Therefore, we also apply a particular fusion function after each attention function, so that different levels of se- mantics can be better incorporated towards a better understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Co-attention &amp; Fusion</head><p>Given the question and passage representation u Q t and u P t , a soft-alignment matrix S has been built to calculate the shallow semantic similarity between question and passage as follows:</p><formula xml:id="formula_2">Sij = Att(u Q t , u P t ) = ReLU(W lin u Q t ) · ReLU(W lin u P t )<label>(3)</label></formula><p>where W lin is a trainable weight matrix. This decomposition avoids the quadratic com- plexity that is trivially parallelizable ( <ref type="bibr" target="#b20">Parikh et al., 2016</ref>). Now we use the unnormalized attention weights S ij to compute the attentions between question and passage, which is further used to ob- tain the attended vectors in passage to question and question to passage direction, respectively.</p><p>P2Q Attention signifies which question words are most relevant to each passage word, given as below:</p><formula xml:id="formula_3">α j = softmax(S :j )<label>(4)</label></formula><p>where α j represents the attention weights on the question words. The aligned passage representation from ques- tion Q = u Q t m t=1 can thus be derived as,</p><formula xml:id="formula_4">˜ Q :t = j α tj · Q :j , ∀j ∈ [1, ..., m]<label>(5)</label></formula><p>Q2P Attention signifies which passage words have the closest similarity to one of the question words and are hence critical for answering the question. We utilize the same way to calculate this atten- tion as in the passage to question attention (P2Q), except for that in the opposite direction:</p><formula xml:id="formula_5">β i = softmax(S i: )<label>(6)</label></formula><formula xml:id="formula_6">˜ P k: = i β ik · P i: , ∀i ∈ [1, ..., n]<label>(7)</label></formula><p>where˜Pwhere˜ where˜P indicates the weighted sum of the most important words in the passage with respect to the question. With the aligned passage and question represen- tations˜Qtations˜ tations˜Q and˜Pand˜ and˜P derived, a particular fusion unit has been designed to combine the original contex- tual representations and the corresponding atten- tion vectors for question and passage separately:</p><formula xml:id="formula_7">P = Fuse(P, ˜ Q)<label>(8)</label></formula><formula xml:id="formula_8">Q = Fuse(Q, ˜ P)<label>(9)</label></formula><p>where Fuse(·, ·) is a typical fusion kernel. The simplest way of fusion is a concatenation or addition of the two representations, followed by some linear or non-linear transformation. Re- cently, a heuristic matching trick with difference and element-wise product is found effective in combining different representations ( <ref type="bibr" target="#b18">Mou et al., 2016;</ref><ref type="bibr" target="#b2">Chen et al., 2017b</ref>):</p><formula xml:id="formula_9">m(P, ˜ Q) = tanh(W f [P; ˜ Q; P • ˜ Q; P − ˜ Q] + b f )<label>(10)</label></formula><p>where • denotes the element-wise product, and W f , b f are trainable parameters. The output di- mension is projected back to the same size as the original representation P or Q via the projected matrix W f .</p><p>Since we find that the original contextual repre- sentations are important in reflecting the semantics at a more global level, we also introduce differ- ent levels of gating mechanism to incorporate the projected representations m(·, ·) with the original contextual representations. As a result, the final fused representations of passage and question can be formulated as:</p><formula xml:id="formula_10">P = g(P, ˜ Q) · m(P, ˜ Q) + (1 − g(P, ˜ Q)) · P (11) Q = g(Q, ˜ P) · m(Q, ˜ P) + (1 − g(Q, ˜ P)) · Q (12)</formula><p>where g(·, ·) is a gating function. To capture the relation between the representations in differ- ent granularities, we also design a scalar-based, a vector-based and a matrix-based sigmoid gating function, which are compared in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Self-attention &amp; Fusion</head><p>Borrowing the idea from wide and deep net- work ( <ref type="bibr" target="#b3">Cheng et al., 2016)</ref>, manual features have also been added to combine with the outputs of previous layer for a more comprehensive repre- sentation. In our model, these features are con- catenated with the refined question-aware passage representation as below:</p><formula xml:id="formula_11">D = BiLSTM([P ; feat man ])<label>(13)</label></formula><p>where feat man denotes the word-level manual pas- sage features.</p><p>In this layer, we separately consider the se- mantic representations of question and passage, and further refine the obtained information from the co-attention layer. Since fusing informa- tion among context words allows contextual in- formation to flow close to the correct answer, the self-attention layer is used to further align the question and passage representation against it- self, so as to keep the global sequence informa- tion in memory. Benefiting from the advantage of self-alignment attention in addressing the long- distance dependence ( <ref type="bibr" target="#b28">Wang et al., 2017)</ref>, we adopt a self-alignment fusion process in this level. To al- low for more freedom of the aligning process, we introduce a bilinear self-alignment attention func- tion on the passage representation:</p><formula xml:id="formula_12">L = softmax(D · W l · D )<label>(14)</label></formula><formula xml:id="formula_13">˜ D = L · D<label>(15)</label></formula><p>Another fusion function Fuse(·, ·) is again adopted to combine the question-aware passage representation D and self-aware representatioñ D, as below:</p><formula xml:id="formula_14">D = Fuse(D, ˜ D)<label>(16)</label></formula><p>Finally, a bidirectional LSTM is used to get the final contextual passage representation:</p><formula xml:id="formula_15">D = BiLSTM(D )<label>(17)</label></formula><p>As for question side, since it is generally shorter in length and could be adequately represented with less information, we follow the question encoding method used in <ref type="bibr" target="#b1">(Chen et al., 2017a</ref>) and adopt a linear transformation to encode the question rep- resentation to a single vector.</p><p>First, another contextual bidirectional LSTM network is applied on top of the fused question representation: Q = BiLSTM(Q ). Then we ag- gregate the resulting hidden units into one single question vector, with a linear self-alignment:</p><formula xml:id="formula_16">γ = softmax(w q · Q )<label>(18)</label></formula><formula xml:id="formula_17">q = j γ j · Q :j , ∀j ∈ [1, ..., m]<label>(19)</label></formula><p>where w q is a weight vector to learn, we self-align the refined question representation to a single vec- tor according to the question self-attention weight, which can be further used to compute the match- ing with the passage words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Model &amp; Output Layer</head><p>Instead of predicting the start and end positions based only on D , a top-level bilinear match func- tion is used to capture the semantic relation be- tween question q and paragraph D in a matching style, which actually works as a multi-hop match- ing mechanism. Different from the co-attention layer that gen- erates coarse candidate answers and the self- attention layer that focus the relevant context of passage to a certain intent of question, the top model layer uses a bilinear matching function to capture the interaction between outputs from pre- vious layers and finally locate on the right answer span.</p><p>The start and end distribution of the passage words are calculated in a bilinear matching way as below,</p><formula xml:id="formula_18">P start = softmax(q · W s · D ) (20) P end = softmax(q · W e · D )<label>(21)</label></formula><p>where W s and W e are trainable matrices of the bilinear match function. The output layer is application-specific, in MRC task, we use pointer networks to predict the start and end position of the answer, since it re- quires the model to find the sub-phrase of the pas- sage to answer the question.</p><p>In training process, with cross entropy as met- ric, the loss for start and end position is the sum of the negative log probabilities of the true start and end indices by the predicted distributions, av- eraged over all examples:</p><formula xml:id="formula_19">L(θ) = − 1 N N i log p s (y s i ) + log p e (y e i ) (22)</formula><p>where θ is the set of all trainable weights in the model, and p s is the probability of start index, p e is the probability of end index, respectively. y s i and y e i are the true start and end indices. During prediction, we choose the answer span with the maximum value of p s · p e under a con- straint that s ≤ e ≤ s + 15, which is selected via a dynamic programming algorithm in linear time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we first present the datasets used for evaluation. Then we compare our end-to-end Hierarchical Attention Fusion Networks with ex- isting machine reading models. Finally, we con- duct experiments to validate the effectiveness of our proposed components. We evaluate our model on the task of question answering using recently released SQuAD and TriviaQA Wikipedia ( <ref type="bibr" target="#b13">Joshi et al., 2017)</ref>, which have gained a huge attention over the past year. An adversarial evaluation for the Stanford Question Answering SQuAD is also used to demonstrate the robust of our model under adversarial attacks (Jia and Liang, 2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We focus on the SQuAD dataset to train and evalu- ate our model. SQuAD is a popular machine com- prehension dataset consisting of 100,000+ ques- tions created by crowd workers on 536 Wikipedia articles. Each context is a paragraph from an ar- ticle and the answer to each question is guaran- teed to be a span in the context. The answer to each question is always a span in the context. The model is given a credit if its answer matches one of the human chosen answers. Two metrics are used to evaluate the model performance: Exact Match (EM) and a softer metric F1 score, which measures the weighted average of the precision and recall rate at a character level. <ref type="table">Table 1</ref>: The performance of our SLQA model and competing approaches on SQuAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dev Set Test Set</head><p>Single model EM / F1 EM / F1 LR Baseline ( <ref type="bibr" target="#b23">Rajpurkar et al., 2016)</ref> 40.0 / 51.0 40.4 / 51.0 Match-LSTM ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref> 64 TriviaQA is a newly available machine compre- hension dataset consisting of over 650K context- query-answer triples. The contexts are automat- ically generated from either Wikipedia or Web search results. The length of contexts in TriviaQA (average 2895 words) is much more longer than the one in SQuAD (average 122 words).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details</head><p>We use the AdaMax optimizer, with a mini-batch size of 32 and initial learning rate of 0.002. A dropout rate of 0.4 is used for all LSTM layers. To directly optimize our target against the evaluation metrics, we further fine-tune the model with some well-defined strategy. During fine-tuning, Focal Loss ( <ref type="bibr">Lin et al., 2017)</ref> and Reinforce Loss which take F1 score as reward are incorporated with Cross Entropy Loss. The training process takes roughly 20 hours on a single Nvidia Tesla M40 GPU. We also train an ensemble model consisting of 15 training runs with the identical framework and hyper-parameters. At test time, we choose the answer with the highest sum of confidence scores amongst the 15 runs for each question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head><p>The results of our model and competing ap- proaches on the hidden test set are summarized in <ref type="table">Table 1</ref>. The proposed SLQA+ ensemble model achieves an EM score of 82.4 and F1 score of 88.6, outperforming all previous approaches, which val- idates the effectiveness of our hierarchical atten- tion and fusion network structure.</p><p>We also conduct experiments on the adversarial <ref type="table">Table 2:</ref> The F1 scores of different models on AddSent and AddOneSent datasets (S: Single Model, E: Ensemble).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>AddSent AddOneSent Logistic ( <ref type="bibr" target="#b23">Rajpurkar et al., 2016)</ref> 23.2 30.4 Match-S ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref> 27.3 39.0 Match-E ( <ref type="bibr" target="#b27">Wang and Jiang, 2016)</ref> 29.4 41.8 BiDAF-S ( <ref type="bibr" target="#b24">Seo et al., 2016)</ref> 34.3 45.7 BiDAF-E ( <ref type="bibr" target="#b24">Seo et al., 2016)</ref> 34.2 46.9 ReasoNet-S (  39.4 50.3 ReasoNet-E (  39.4 49.8 Mnemonic-S ( <ref type="bibr" target="#b10">Hu et al., 2017)</ref> 46.6 56.0 Mnemonic-E ( <ref type="bibr" target="#b10">Hu et al., 2017)</ref> 46.2 55.3 QANet-S ( <ref type="bibr">Yu et al., 2018)</ref> 45.2 55.7 FusionNet-E (  51.4 60.7 SLQA-S (our) 52.1 62.7 SLQA-E (our) 54.8 64.2</p><p>SQuAD dataset ( <ref type="bibr" target="#b12">Jia and Liang, 2017)</ref> to study the robustness of the proposed model. In the dataset, one or more sentences are appended to the origi- nal SQuAD context, aiming to mislead the trained models. We use exactly the same model as in our SQuAD dataset, the performance comparison re- sult is shown in <ref type="table">Table 2</ref>. It can be seen that the proposed model can still get superior results than all the other competing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablations</head><p>In order to evaluate the individual contribution of each model component, we run an ablation study. <ref type="table" target="#tab_1">Table 3</ref> shows the performance of our model and its ablations on SQuAD dev set. The bi-linear alignment plus fusion between passage and ques- tion is most critical to the performance on both metrics which results in a drop of nearly 15%. The reason may be that in top-level attention layer, the similar semantics between question and pas- sage are strong evidence to locate the correct an- swer span. The ELMo accounts for about 5% of the performance degradation, which clearly shows the effectiveness of language model. We conjec- ture that language model layer efficiently encodes different types of syntactic and semantic informa- tion about words-in-context, and improves the task performance. To evaluate the performance of hier- archical architecture, we reduce the multi-hop fu- sion with the standard LSTM network. The result shows that multi-hop fusion outperforms the stan- dard LSTM by nearly 5% on both metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Fusion Functions</head><p>In this section, we experimentally demonstrate how different choices of the fusion kernel impact the performance of our model. The compared fu- sion kernels are described as follows:</p><p>Simple Concat: a simple concatenation of two  </p><formula xml:id="formula_20">g(P, ˜ Q) = g p<label>(23)</label></formula><p>where g p is a trainable scalar parameter.</p><p>Vector-based Fusion: the gating function con- tains a weight vector to learn, which acts as a one- dimensional sigmoid gating, where W g is a trainable weight matrix. The comparison results of different fusion ker- nels can be found in <ref type="table" target="#tab_2">Table 4</ref>. We can see that different fusion methods contribute differently to the final performances, and the vector-based fu- sion method performs best, with a moderate pa- rameter size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Attention Hierarchy and Function</head><p>In the proposed model, attention layer is the most important part of the framework. At the bottom of <ref type="table">Table 5</ref> we show the performances on SQuAD <ref type="table">Table 5</ref>: Comparison of different attention styles on the SQuAD dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Hierarchy</head><p>EM / F1 1-layer attention (only qp co-attention) 61.9 / 68.4 2-layer attention (add self-attention) 65.4 / 71.7 3-layer attention (add bilinear match) 80.0 / 87.0 Attention Function EM / F1 dot product 62.9 / 69.3 linear attention 78.0 / 84.9 bilinear attention (linear + relu) 80.0 / 87.0 trilinear attention 78.9 / 85.8 for four common attention functions. Empirically, we find bilinear attention which add ReLU after linearly transforming does significantly better than the others. At the top of <ref type="table">Table 5</ref> we show the effect of vary- ing the number of attention layers on the final per- formance. We see a steep and steady rise in accu- racy as the number of layers is increased from N = 1 to 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Experiments on TriviaQA</head><p>To further examine the robustness of the proposed model, we also test the model performance on TriviaQA dataset. The test performance of dif- ferent methods on the leaderboard (on Jan. 12th 2018) is shown in <ref type="table" target="#tab_3">Table 6</ref>. From the results, we can see that the proposed model can also obtain state-of-the-art performance in the more complex TriviaQA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We introduce a novel hierarchical attention net- work, a state-of-the-art reading comprehension model which conducts attention and fusion hor- izontally and vertically across layers at different levels of granularity between question and para- graph. We show that our proposed method is very powerful and robust, which outperforms the previous state-of-the-art methods in various large- scale golden MRC datasets: SQuAD, TriviaQA, AddSent and AddOneSent. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Hierarchical Attention Fusion Network.</figDesc><graphic url="image-1.png" coords="4,72.00,62.81,224.50,217.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>]+b g ) (24) where w g is trainable weight vector, b g is trainable bias, and σ is sigmoid function. Matrix-based Fusion: the gating function con- tains a weight matrix to learn, which acts as a two- dimensional sigmoid gating,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning curve of F1 / EM score on the SQuAD dev set</figDesc><graphic url="image-2.png" coords="9,315.27,62.81,199.56,158.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 : Ablation tests of SLQA single model on the SQuAD dev set.</head><label>3</label><figDesc></figDesc><table>SLQA single model 
EM / F1 
SLQA+ 
80.0 / 87.0 
-Manual Features 
79.2 / 86.2 
-Language Embedding (ELMo) 77.6 / 84.9 
-Self Matching 
79.5 / 86.4 
-Multi-hop 
79.1 / 86.1 
-Bi-linear Match 
65.4 / 72.0 
-Fusion (simple concat) 
78.8 / 85.8 
-Fusion, -Multi-hop 
77.5 / 84.8 
-Fusion, -Bi-linear Match 
63.1 / 69.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparison of different fusion kernels 
on the SQuAD dev set. 

Fusion Kernel 
EM / F1 
Simple Concat 
78.8 / 85.8 
Add Full Projection (FPU) 
79.1 / 86.1 
Scalar-based Fusion (SFU) 
79.5 / 86.5 
Vector-based Fusion (VFU) 80.0 / 87.0 
Matrix-based Fusion (MFU) 
79.8 / 86.8 

channel inputs. 
Full Projection: the heuristic matching and 
projecting function as in Equ. 10. 
Scalar-based Fusion: the gating function is a 
trainable scalar parameter (a coarse fusion level): 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Published and unpublished results on the 
TriviaQA wikipedia leaderboard. 

Full 
Verified 
Model 
EM / F1 
EM / F1 
BiDAF (Seo et al., 2016) 
40.26 / 45.74 
47.47 / 53.70 
MEMEN (Pan et al., 2017) 
43.16 / 46.90 
49.28 / 55.83 
M-Reader (Hu et al., 2017) 
46.94 / 52.85 
54.45 / 59.46 
QANet (Yu et al., 2018) 
51.10 / 56.60 
53.30 / 59.20 
document-qa (Clark and Gardner, 2017) 
63.99 / 68.93 
67.98 / 72.88 
dirkweissenborn (unpublished) 
64.60 / 69.90 
72.77 / 77.44 
SLQA-Single 
66.56 / 71.39 
74.83 / 78.74 

</table></figure>

			<note place="foot" n="1"> https://rajpurkar.github.io/SQuAD-explorer/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the Stanford NLP Group and the Univer-sity of Washington NLP Group for evaluating our results on the SQuAD and the TriviaQA test set.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A thorough examination of the cnn/daily mail reading comprehension task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02858</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Reading wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00051</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural language inference with external knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04289</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng-Tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremiah</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishi</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
		<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Attention-overattention neural networks for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04423</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Framesemantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Gated-attention readers for text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>William W Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01549</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02301</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Reinforced mnemonic reader for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<idno>abs/1705.02798</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Fusionnet: Fusing via fullyaware attention with application to machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsin-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07341</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2021" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Daniel S Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bajgar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01547</idno>
		<title level="m">Text understanding with the attention sum reader network</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Dollár. 2017. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02002</idno>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Phase conductor on multi-layered attentions for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiguang</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Chikina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10504</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Stochastic answer networks for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03556</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural language inference by tree-based convolution and heuristic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 54th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">130</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Memen: Multi-layer embedding with memory networks for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Boyuan Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09098</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Bin Cao, Deng Cai, and Xiaofei He</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Matthew E Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reasonet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1047" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Machine comprehension using match-lstm and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01604</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Dcn+: Mixed objective and deep residual coattention for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00106</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
