<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discourse Mode Identification in Essays</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiji</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
						</author>
						<title level="a" type="main">Discourse Mode Identification in Essays</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="112" to="122"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1011</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Discourse modes play an important role in writing composition and evaluation. This paper presents a study on the manual and automatic identification of narration, exposition , description, argument and emotion expressing sentences in narrative essays. We annotate a corpus to study the characteristics of discourse modes and describe a neural sequence labeling model for identification. Evaluation results show that discourse modes can be identified automatically with an average F1-score of 0.7. We further demonstrate that discourse modes can be used as features that improve automatic essay scoring (AES). The impacts of discourse modes for AES are also discussed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discourse modes, also known as rhetorical modes, describe the purpose and conventions of the main kinds of language based communi- cation.Most common discourse modes include narration, description, exposition and argument. A typical text would make use of all the modes, although in a given one there will often be a main mode. Despite their importance in writing composition and assessment <ref type="bibr" target="#b6">(Braddock et al., 1963)</ref>, there is relatively little work on analyzing discourse modes based on computational models. We aim to contribute for automatic discourse mode identification and its application on writing assessment.</p><p>The use of discourse modes is important in writ- ing composition, because they relate to several as- pects that would influence the quality of a text.</p><p>First, discourse modes reflect the organization of a text. Natural language texts consist of sen- tences which form a unified whole and make up the discourse <ref type="bibr" target="#b15">(Clark et al., 2013)</ref>. Recognizing the structure of text organization is a key part for dis- course analysis. <ref type="bibr" target="#b38">Meurer (2002)</ref> points that dis- course modes stand for unity as they constitute general patterns of language organization strate- gically used by the writer. <ref type="bibr" target="#b44">Smith (2003)</ref> also pro- poses to study discourse passages from a linguistic view of point through discourse modes. The orga- nization of a text can be realized by segmenting text into passages according to the set of discourse modes that are used to indicate the functional re- lationship between the several parts of the text. For example, the writer can present major events through narration, provide details with description and establish ideas with argument. The combi- nation and interaction of various discourse modes make an organized unified text.</p><p>Second, discourse modes have rhetorical significance. Discourse modes are closely related to rhetoric <ref type="bibr" target="#b19">(Connors, 1981;</ref><ref type="bibr" target="#b8">Brooks and Warren, 1958)</ref>, which offers a principle for learning how to express material in the best way. Discourse modes have different preferences on expressive styles. Narration mainly controls story progression by introducing and connecting events; exposition is to instruct or explain so that the language should be precise and informative; argument is used to convince or persuade through logical and inspiring statements; description attempts to bring detailed observations of people and scenery, which is related to the writing of figurative language; the way to express emotions may relate to the use of rhetorical devices and poetic language. Discourse modes reflect the variety of expressive styles. The flexible use of various discourse modes should be important evidence of language proficiency.</p><p>According to the above thought, we propose the discourse mode identification task. In particular, we make the following contributions:</p><p>• We build a corpus of narrative essays written by Chinese students in native language. Sentence level discourse modes are annotated with acceptable inter-annotator agreement. Corpus analysis reveals the characteristics of discourse modes in several aspects, including discourse mode distribution, co-occurrence and transition patterns.</p><p>• We describe a multi-label neural sequence la- beling approach for discourse mode identi- fication so that the co-occurrence and tran- sition preferences can be captured. Experi- mental results show that discourse modes can be identified with an average F1-score of 0.7, indicating that automatic discourse mode i- dentification is feasible.</p><p>• We demonstrate the effectiveness of taking discourse modes into account for automatic essay scoring. A higher ratio of description and emotion expressing can indicate essay quality to a certain extent. Discourse modes can be potentially used as features for other NLP applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Discourse Analysis</head><p>Discourse analysis is an important subfield of natural language processing <ref type="bibr" target="#b49">(Webber et al., 2011)</ref>. Discourse is expected to be both cohesive and coherent. Many principles are proposed for discourse analysis, such as coherence relations <ref type="bibr" target="#b27">(Hobbs, 1979;</ref><ref type="bibr" target="#b36">Mann and Thompson, 1988)</ref>, the centering theory for local coherence ( <ref type="bibr" target="#b25">Grosz et al., 1995)</ref> and topic-based text segmentation <ref type="bibr" target="#b26">(Hearst, 1997)</ref>. In some domains, discourse can be segmented according to specific discourse ele- ments <ref type="bibr" target="#b29">(Hutchins, 1977;</ref><ref type="bibr" target="#b48">Teufel and Moens, 2002;</ref><ref type="bibr" target="#b16">Clerehan and Buchbinder, 2006;</ref><ref type="bibr" target="#b45">Song et al., 2015)</ref>. This paper focuses on discourse modes influenced by <ref type="bibr" target="#b44">Smith (2003)</ref>. From the linguistic view of point, discourse modes are supposed to have different distributions of situation entity types such as event, state and generic <ref type="bibr" target="#b44">(Smith, 2003;</ref><ref type="bibr" target="#b37">Mavridou et al., 2015)</ref>. Therefore, there is work on automatically labeling clause level situation entity types <ref type="bibr" target="#b40">(Palmer et al., 2007;</ref><ref type="bibr" target="#b23">Friedrich et al., 2016)</ref>. Actually, situation entity type identification is also a challenging problem. It is even harder for processing Chinese language, since Chinese doesn't have grammatical tense <ref type="bibr" target="#b50">(Xue and Zhang, 2014</ref>) and sentence components are often omitted. This increases the difficulties for situation entity type based discourse mode identification. In this paper, we investigate an end-to-end approach to directly model discourse modes without the necessity of identifying situation entity types first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Automatic Writing Assessment</head><p>Automatic writing assessment is an important ap- plication of natural language processing. The task aims to let computers have the ability to appreciate and criticize writing. It would be hugely benefi- cial for applications like automatic essay scoring (AES) and content recommendation.</p><p>AES is the task of building a computer-aided scoring system, in order to reduce the involvement of human raters. Traditional approaches are based on supervised learning with designed feature templates <ref type="bibr" target="#b33">(Larkey, 1998;</ref><ref type="bibr" target="#b9">Burstein, 2003;</ref><ref type="bibr" target="#b2">Attali and Burstein, 2006;</ref><ref type="bibr" target="#b12">Chen and He, 2013;</ref><ref type="bibr" target="#b42">Phandi et al., 2015;</ref><ref type="bibr" target="#b20">Cummins et al., 2016)</ref>. Recently, automatic feature learning based on neural networks starts to draw attentions ( <ref type="bibr" target="#b0">Alikaniotis et al., 2016;</ref><ref type="bibr" target="#b21">Dong and Zhang, 2016;</ref><ref type="bibr" target="#b46">Taghipour and Ng, 2016)</ref>.</p><p>Writing assessment involves highly technical aspects of language and discourse. In addition to give a score, it would be better to provide explainable feedbacks to learners at the same time. Some work has studied several aspects such as spelling errors <ref type="bibr" target="#b7">(Brill and Moore, 2000</ref>), grammar errors ( <ref type="bibr" target="#b43">Rozovskaya and Roth, 2010)</ref>, coherence ( <ref type="bibr" target="#b4">Barzilay and Lapata, 2008)</ref>, organization of argumentative essays <ref type="bibr" target="#b41">(Persing et al., 2010</ref>) and the use of figurative language <ref type="bibr" target="#b34">(Louis and Nenkova, 2013)</ref>. This paper extends this line of work by taking discourse modes into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Neural Sequence Modeling</head><p>A main challenge of discourse analysis is hard to collect large scale data due to its complexity, which may lead to data sparseness problem. Recently, neural networks become popular for natural language processing ( <ref type="bibr" target="#b5">Bengio et al., 2003;</ref><ref type="bibr" target="#b18">Collobert et al., 2011</ref>). One of the advantages is the ability of automatic representation learning. Representing words or relations with continuous vectors ( <ref type="bibr" target="#b39">Mikolov et al., 2013;</ref><ref type="bibr" target="#b30">Ji and Eisenstein, 2014</ref>) embeds semantics in the same space, which benefits alleviating the data sparseness problem and enables end-to-end and multi-task learning. Recurrent neural networks (RNNs) <ref type="bibr" target="#b24">(Graves, 2012)</ref> and the variants like Long Short-Term Memory (LSTM) <ref type="bibr" target="#b28">(Hochreiter and Schmidhuber, 1997)</ref> and Gated Recurrent (GRU) ( <ref type="bibr" target="#b14">Cho et al., 2014</ref>) neural networks show good performance for capturing long distance dependencies on tasks like Named Entity Recognition (NER) ( <ref type="bibr" target="#b13">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b35">Ma and Hovy, 2016)</ref>, dependency parsing ( <ref type="bibr" target="#b22">Dyer et al., 2015)</ref> and semantic composition of documents ( <ref type="bibr" target="#b47">Tang et al., 2015)</ref>. This work describes a hierarchical neural architecture with multiple label outputs for modeling the discourse mode sequence of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discourse Mode Annotation</head><p>We are interested in the use of discourse modes in writing composition. This section describes the discourse modes we are going to study, an anno- tated corpus of student essays and what we learn from corpus analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discourse Modes</head><p>Discourse modes have several taxonomies in the literature. Four basic discourse modes are narration, description, exposition and argument in English composition and rhetoric <ref type="bibr" target="#b3">(Bain, 1890)</ref>. <ref type="bibr" target="#b44">Smith (2003)</ref> proposes five modes for studying discourse passages:</p><p>narrative, description, report, information and argument. In Chinese composition, discourse modes are categorized into narration, description, exposition, argument and emotion expressing <ref type="bibr" target="#b51">(Zhu, 1983)</ref>.</p><p>These taxonomies are similar. Their elements can mostly find corresponding ones in other tax- onomies literally or conceptually, e.g., exposition mode has similar functions to information mode. Emotion expressing that is to express the writer's emotions is relatively special. It can be realized by expressing directly or through lyrical writing with beautiful and poetic language. It is also related to appeal to emotion, which is a method for argumen- tation by the manipulation of the recipient's emo- tions in classical rhetoric ( <ref type="bibr" target="#b1">Aristotle and Kennedy, 2006</ref>). Proper emotion expressing can touch the hearts of the readers and improve the expressive- ness of writing. Therefore, considering it as an independent mode is also reasonable.</p><p>We cope with essays written in Chinese in this work so that we follow the Chinese convention with five discourse modes. Emotion expressing is added on the basis of four recognized discourse modes and Smith's report mode is viewed as a sub- type of description mode: dialogue description.</p><p>In summary, we study the following discourse modes:</p><p>• Narration introduces an event or series of events into the universe of discourse. The events are temporally related according to narrative time. E.g., Last year, we drove to San Francisco along the State Route 1 (SR 1).</p><p>• Exposition has a function to explain or in- struct. It provides background information in narrative context. The information presented should be general and (expected to be) well accepted truth. E.g., SR 1 is a major north-south state high- way that runs along most of the Pacific coast- line of the U.S.</p><p>• Description re-creates, invents, or vividly show what things are like according to the five senses so that the reader can picture that which is being described. E.g., Along SR 1 are stunning rugged coastline, coastal forests and cliffs, beautiful little towns and some of the West coast's most amazing nature.</p><p>• Argument makes a point of view and proves its validity towards a topic in order to con- vince or persuade the reader. E.g., Point Arena Lighthouse is a must see along SR 1, in my opinion.</p><p>• Emotion expressing 1 presents the writer's e- motions, usually in a subjective, personal and lyrical way, to involve the reader to experi- ence the same situations and to be touched. E.g., I really love the ocean, the coastline and all the amazing scenery along the route. When could I come back again?</p><p>The distinction between discourse modes is ex- pected to be clarified conceptually by considering their different communication purposes. However, there would still be specific ambiguous and vague cases. We will describe the data annotation and corpus analysis in the following parts. <ref type="bibr">1</ref> In some cases, we use emotion for short. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Annotation</head><p>Discourse modes are almost never found in a pure form but are embedded one within another to help the writer achieve the purpose, but the empha- sis varies in different types of writing. We focus on narrative essays. A good narrative composi- tion must properly manipulate multiple discourse modes to make it vivid and impressive. The corpus has 415 narrative essays written by high school students in their native Chinese lan- guage.The average number of sentences is 32 and the average length is 670 words.</p><p>We invited two high school teachers to annotate discourse modes at sentence level, expecting their background help for annotation. A detail manual was discussed before annotation.</p><p>We notice that discourse modes can mix in the same sentence. Therefore, the annotation standard allows that one sentence can have multiple modes. But we require that every sentence should have a dominant mode. The annotators should try to think in the writer's perspective and guess the writer's main purpose of writing the sentence in order to decide the dominant mode.</p><p>Among the discourse modes, description can be applied in various situations. We focus on the following description types: portrait, appearance, action, dialogue, psychological, environment and detail description. If a sentence has any type of de- scription, it would be assigned a description label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Corpus Analysis</head><p>We conducted corpus analysis on the annotated data to gain observations on several aspects. Inter-Annotator Agreement: 50 essays were in- dependently annotated by two annotators. We e- valuate the inter-annotator agreement on the dom- inant mode. The two annotators' annotations are used as the golden answer and prediction respec- tively. We compute the precision, recall and F1- score for each discourse mode separately to mea- sure the inter-annotator agreement. Precision and recall are symmetric for the two annotators.</p><p>The result of the first round annotation is shown in the INITIAL columns of <ref type="table">Table 1</ref>. The agreement on argument mode is low, while the agreement on other modes is acceptable. The average F1-score is 0.69. The Cohen's Kappa ( <ref type="bibr" target="#b17">Cohen et al., 1960</ref>) is 0.55 over all judgements on the dominant mode.</p><p>The main disagreement on argument lies in the confusion with emotion expressing. Consider the following sentence:</p><p>Father's love is the fire that lights the lamp of hope.</p><p>One annotator thought that it is expressed in an emotional and lyrical way so that the discourse mode should be emotion expressing. The other one thought that it (implicitly) gives a point and should be an argument. Many disagreements hap- pened in cases like this.</p><p>Based on the observations of the first round an- notation, we discussed and updated the manual and let the annotators rechecked their annotations. The final result is shown in the FINAL columns of <ref type="table">Table 1</ref>. The agreement on description decreas- es. Annotators seem to be more conservative on labeling description as the dominant mode. The overall average F1-score increases to 0.78 and the Cohen's Kappa is 0.72. This indicates that humans can reach an acceptable agreement on the domi- nant discourse mode of sentences after training. Discourse mode distribution: After the training phase, the annotators labeled the whole corpus. <ref type="figure" target="#fig_0">Figure 1</ref> shows the distribution of dominant <ref type="table" target="#tab_1">Nar  5285  11  2552  65  2  Exp  - 148  11  1  1  Des  - - 2538  105  8  Emo  - - - 1947  63  Arg  - - - - 318</ref>    <ref type="table" target="#tab_1">Table 2</ref> shows the co-occurrence of discourse modes. The numbers that are in the diagonal represent the distribution of discourse modes of sentences with only one mode. The numbers that are not in the diagonal indicate the co-occurrence of modes in the same sentences. We can see that description tends to co-occur with narration and emotion expressing. Description can provide states that happen together with events and emotion-evoking scenes are often described to elicit a strong emotional response, for example:</p><note type="other">Mode Nar Exp Des Emo Arg</note><p>The bright moon hanging on the distant sky reminds me of my hometown miles away.</p><p>Emotion expressing and argument also co-occur in some cases. It is reasonable, since a successful emotional appeal can enhance the effectiveness of an argument.</p><p>Generally, these observations are consistent with intuition.</p><p>Properly combining multiple modes could produce impressive sentences. <ref type="table" target="#tab_2">Table 3</ref> shows the transition matrix between the dominant modes of consecutive sentences within the same paragraphs. All modes tend to transit to themselves except exposition, which is rare and usually brief. This means that discourse modes of adjacent sentences have high correlation. We also see that narration and emotion are more often at the beginning and the end of essays. The above observations indicate that discourse modes have local preferred patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transition:</head><p>To summarize, the implications of corpus analysis include: (1) Manual identification of discourse modes is feasible with an acceptable inter-annotator agreement; (2) The distribution of discourse modes in narrative essays is imbalanced; (3) About 22% sentences have multiple discourse modes; (4) Discourse modes have local transition patterns that consecutive discourse modes have high correlation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discourse Mode Identification based on Neural Sequence Labeling</head><p>This section describes the proposed method for discourse mode identification. According to the corpus analysis, sentences often have multiple dis- course modes and prefer local transition patterns. Therefore, we view this task as a multi-label se- quence labeling problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model</head><p>We propose a hierarchical neural sequence label- ing model to capture multiple level information. <ref type="figure">Figure 2(</ref> (b) The detail of the Mul-Label layer <ref type="figure">Figure 2</ref>: The multi-label neural sequence labeling model for discourse mode identification.</p><p>we use the GRU ( <ref type="bibr" target="#b14">Cho et al., 2014</ref>) as the recurrent unit. The GRU is to make each recurrent unit to adaptively capture dependencies of different time scales. The output of the last time-step is used as the representation of a sentence. Discourse level bidirectional-GRU layer: An es- say consists of a sequence of sentences. Access- ing information of past and future sentences pro- vides more contextual information for current pre- diction. Therefore, we use a bidirectional RNN to connect sentences. We use the GRU as the recurrent unit, which is also shown effective on semantic composition of documents for sentiment classification ( <ref type="bibr" target="#b47">Tang et al., 2015</ref>). The BiGRU rep- resents the concatenation of the hidden states of the forward GRU and the backward GRU units. Multi-Label layer: Since one sentence can have more than one discourse mode, our model allows multiple label outputs. <ref type="figure">Figure 2</ref>(b) details the Mul-Label layer in <ref type="figure">Figure 2</ref>(a). The representation of each sentence after the bidirectional-GRU layer is first fully connected to a hidden layer. The hidden layer output is then fully connected to a five-way output layer, corresponding to five discourse modes. The sigmoid activation function is applied to each way to get the probability that whether corresponding discourse mode should be assigned to the sentence. In the training phase, the probability of any la- beled discourse modes is set to 1 and the others are set to 0. In the prediction phase, if the predicted probability of a discourse mode is larger than 0.5, the discourse mode would be assigned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Considering Paragraph Boundaries</head><p>Different from NER that processes a single sentence each time, our task processes sequences of sentences in discourse, which are usually grouped by paragraphs to split the whole discourse into several relatively independent segments. Sentences from different paragraphs should have less effect to each other, even though they are adjacent.</p><p>To capture paragraph boundary information, we insert an empty sentence at the end of every para- graph to indicate a paragraph boundary. The emp- ty sentence is represented by a zero vector and its outputs are set to zeros as well. We expect this modification can better capture position related in- formation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We implement the model using the Keras library. <ref type="bibr">2</ref> The models are trained with the binary cross-entropy objective. The optimizer is Adam ( <ref type="bibr" target="#b32">Kingma and Ba, 2014</ref>). The word embedding dimension is 50. The dimension of the hidden layer in Mul-Label layer is 100. The length of sentences is fixed as 40. All other parameters are set by default parameter values. We adopt early stopping strategy ( <ref type="bibr" target="#b11">Caruana et al., 2000</ref>) to decide when the training process stops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Data</head><p>We use 100 essays as the test data. The remain- ing ones are used as the training data. 10% of the shuffled training data is used for validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Comparisons</head><p>We compare the following systems:</p><p>• SVM: We use bag of ngram (unigram and bi- gram) features to train a support vector clas- sifier for sentence classification.</p><p>• CNN: We implement a convolutional neural network (CNN) based method <ref type="bibr" target="#b31">(Kim, 2014)</ref>, as it is the state-of-the-art for sentence classi- fication.</p><p>• GRU: We use the sentence level representa- tion in <ref type="figure">Figure 2</ref>(a) for sentence classification.</p><p>• GRU-GRU(GG): This method is introduced in this paper in §4.1, but it doesn't consider paragraph information.</p><p>• GRU-GRU-SEG (GG-SEG): The model con- siders paragraph information on the top of G- G as introduced in §4.1.1.</p><p>The first three classification based methods classify sentences independently. To deal with multiple labels, the classifiers are trained for each discourse mode separately. At prediction time, if the classifier for any discourse mode predicts a sentence as positive, the corresponding discourse mode would be assigned. <ref type="table">Table 4</ref> shows the experimental results. We evalu- ate the systems for each discourse mode with F1- score, which is the harmonic mean of precision and recall. The best performance is in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Evaluation Results</head><p>The SVM performs worst among all systems. The reason is due to the data sparseness and term- mismatch problem, since the size of the annotated dataset is not big enough. In contrast, systems based on neural networks with pre-trained word embeddings achieve much better performance.</p><p>The CNN and GRU have comparable perfor- mance. The GRU is slightly better. The two meth- ods don't consider the semantic representations of adjacent sentences.</p><p>The GG and GG-SEG explore the semantic in- formation of sentences in a sequence by the bidi- rectional GRU layer. The results demonstrate that considering such information improve the perfor- mance on all discourse modes. This proves the ad- vantage of sequential identification compared with isolated sentence classification.</p><p>We can see that the GG-SEG further improves the performance on three minority discourse modes compared with GG. This means that the minority modes may have stronger preference to special locations. Exposition benefits most, since many exposition sentences in our dataset are isolated.  <ref type="table">Table 4</ref>: The F1-scores of systems on each dis- course mode.</p><note type="other">Model \ Mode Nar Des Emo Arg Exp SVM 0</note><p>The performance on argument is not so good. As we discussed in corpus analysis, argument and emotion expressing mode interact frequently. Be- cause the amount of emotion expressing sentences is much more, distinguishing argument from them is hard. Actually, their functions in narrative es- says seem to be similar that both are to deepen the author's response or evoke the reader's response to the story.</p><p>The overall average F1-score can reach to 0.7 and the performance on identifying three most common discourse modes are consistent, with an average F1-score above 0.76 using the proposed neural sequence labeling models. Automatic discourse mode identification should be feasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Essay Scoring with Discourse Modes</head><p>Discourse mode identification can potentially pro- vide features for downstream NLP applications. This section describes our attempt to explore dis- course modes for automatic essay scoring (AES).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Essay Scoring Framework</head><p>We adopt the standard regression framework for essay scoring. We use support vector regression (SVR) and Bayesian linear ridge regression (BLR- R), which are used in recent work ( <ref type="bibr" target="#b42">Phandi et al., 2015)</ref>. The key is to design effective features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Features</head><p>The basic feature sets are based on ( <ref type="bibr" target="#b42">Phandi et al., 2015)</ref>.The original feature sets include:</p><p>• Length features</p><p>• Part-Of-Speech (POS) features</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Prompt features</head><p>• Bag of words features We re-implement the feature extractors exact- ly according to the description in ( <ref type="bibr" target="#b42">Phandi et al., 2015</ref>) except for the POS features, since we don't Score Prompt #Essays Avg. len <ref type="table" target="#tab_1">Range Median  1  4000  628  0-60  46  2  4000  660  0-50  41  3  3300  642  0-50  41   Table 5</ref>: Details of the three datasets for AES.</p><p>have correct POS ngrams for Chinese. We com- plement two additional features: (1) The number of words occur in Chinese Proficiency Test 6 vo- cabulary; (2) The number of Chinese idioms used. We further design discourse mode related fea- tures for each essay:</p><p>• Mode ratio: For each discourse mode, we compute its mode ratio according to ratio = #sentences with the discourse mode #sentences in the essay . Such features indicate the distribution of discourse modes.</p><p>• Bag of ngrams of discourse modes: We use the number of unigrams and bigrams of the dominant discourse modes of the sequence of sentences in the essay as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Settings</head><p>The experiments were conducted on narrative es- says written by Chinese middle school students in native language during regional tests. There are three prompts and students are required to write an essay related to the given prompt with no less than 600 Chinese characters. All these essays were evaluated by professional teachers. We randomly sampled essays from each promp- t for experiments. <ref type="table">Table 5</ref> shows the details of the datasets. We ran experiments on each prompt dataset respectively by 5-fold cross-validation.</p><p>The GG-SEG model was used to identify dis- course modes of sentences. Notice that a sentence can have multiple discourse modes. The mode ra- tio features are computed for each mode separate- ly. When extracting the bag of ngrams of discourse modes features, the discourse mode with highest prediction probability was chosen as the dominant discourse mode.</p><p>We use the Quadratic Weighted Kappa (QWK) as the evaluation metric.   matter which algorithm is adopted, adding dis- course mode features make positive contributions for AES compared with using basic feature sets. The trends are consistent over all three datasets. Impact of discourse mode ratio on scores: We are interested in which discourse mode correlates to essay scores best. <ref type="table" target="#tab_7">Table 7</ref> shows the Pearson correlation coefficient between the mode ratio and essay score. LEN represents the correlation of essay length and is listed as a reference. We can see that the ratio of narration has a negative correlation, which means just narrating stories without auxiliary discourse modes would lead to poor scores. The description mode ratio has the strongest positive correlation to essay scores. This may indicate that using vivid language to provide detail information is essential in writing narrative essays. Emotion expressing also has a positive correlation. It is reasonable since emotional writing can involve readers into the stories. The ratio of argument shows a negative correlation. The reason may be that: first, the identification of argument is not good enough; second, the existence of an argument doesn't mean the quality of argumentation is good. Exposition has little effect on essay scores. Generally, the distribution of discourse modes shows correlations to the quality of essays. This may relate to the difficulties of manipulating dif- ferent discourse modes. It is easy for students to use narration, but it is more difficult to manipulate description and emotion expressing well. As a re- sult, the ability of descriptive and emotional writ-  ing should be an indicator of language proficiency and can better distinguish the quality of writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation Results</head><p>Impact on scoring essays with various length: It is easy to understand that length is a strong indi- cator for essay scoring. It is interesting to study that when the effect of length becomes weaker, e.g., the lengths of essays are close, how does the performance of the AES system change?</p><p>We conducted experiments on essays with vari- ous lengths. Only essays that the length is no less than a given threshold are selected for evaluation. The threshold is set to 100, 200, 400 and 600 Chi- nese characters respectively. We ran 5-fold cross- validation with BLRR on the datasets after essay selection. <ref type="figure" target="#fig_1">Figure 3</ref> shows the results on three datasets. We can see the following trends: (1) The QWK scores decrease along with shorter essays are removed gradually; (2) Adding discourse mode features al- ways improves the performance; (3) As the thresh- old becomes larger, the improvements by adding discourse mode features become larger.</p><p>The results indicate that the current AES sys- tem can achieve a high correlation score when the lengths of essays differ obviously. Even the sim- ple features like length can judge that short es- says tend to have low scores. However, when the lengths of essays are close, AES would face greater challenges, because it is required to deep- er understand the properties of well written es- says. In such situations, features that can model more advanced aspects of writing, such as dis- course modes, should play a more important role. It should be also essential for evaluating essays written in the native language of the writer, when spelling and grammar are not big issues any more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper has introduced a fundamental but less studied task in NLP-discourse mode identifica- tion, which is designed in this work to automati- cally identify five discourse modes in essays.</p><p>A corpus of narrative student essays was man- ually annotated with discourse modes at sentence level, with acceptable inter-annotator agreement. The corpus analysis revealed several aspects of characteristics of discourse modes including the distribution, co-occurrence and transition patterns.</p><p>Considering these characteristics, we proposed a neural sequence labeling approach for identi- fying discourse modes. The experimental results demonstrate that automatic discourse mode iden- tification is feasible.</p><p>We evaluated discourse mode features for auto- matic essay scoring and draw preliminary observa- tions. Discourse mode features can make positive contributions, especially in challenging situation- s when simple surface features don't work well. The ratio of description and emotion expressing is shown to be positively correlated to essay scores.</p><p>In future, we plan to exploit discourse mode i- dentification for providing novel features for more downstream NLP applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The distribution of dominant modes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: QWK scores on essays satisfying different length thresholds on three prompts. Basic: the basic feature sets; mode: discourse mode features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Co-occurrence of discourse modes in the 
same sentences. The numbers in diagonal indicate 
the number of sentences with a single mode. 

from \ to 
Nar 
Exp Des Emo Arg 
Nar 
72% 
-
17% 
7% 
1% 
Exp 
59% 8% 
8% 
16% 
6% 
Des 
42% 
-
53% 
3% 
-
Emo 
25% 2% 
4% 
66% 
1% 
Arg 
27% 
-
4% 
12% 54% 
Begin with 50% 3% 
6% 
32% 
7% 
End with 
12% 1% 
2% 
76% 
6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Transition between discourse modes of 
consecutive sentences and the distribution of dis-
course modes that essays begin with and end with. 

discourse modes. The distribution is imbalanced. 
Narration, description and emotion expressing 
are the main discourse modes in narrative essays, 
while exposition and argument are rare. 
Co-occurrence: Statistics show that 78% of sen-
tences have only one discourse mode, and 19% 
have two discourse modes, and 3% have more than 
two discourse modes. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>a) shows the basic architecture. We in- troduce it from the bottom up. Word level embedding layer: We transform words into continuous vectors, word embeddings. Vector representation of words is useful for capturing semantic relatedness. This should be effective in our case, since large amount of training data is not available. It is unrealistic to learn the embedding parameters on limited data so that we just look up embeddings of words from a pre-trained word embedding table. The pre-trained word embeddings were learned with the Word2Vec toolkit (Mikolov et al., 2013) on a domain corpus which consists of about 490,000 student essays. The embeddings are kept unchanged during learning and prediction. Sentence level GRU layer: Each sentence is a sequence of words. We feed the word embeddings into a forward recurrent neural networks. Here,</figDesc><table>BiGRU 

BiGRU 
BiGRU 

Mul-Label 
Mul-Label 

Discourse level 
BiGRU layer 

GRU 
GRU 
GRU 




Sentence level 
GRU layer 

s 1 
s 2 
s m 

w 21 
w 22 
w 2n 

Word level 
Embeddings 

Discourse 
Modes 

Mul-Label 

Mul-Label 

(a) The basic hierarchical architecture. 




BiGRU 

s 




Fully connected 

Hidden Layer 

Fully connected 

Sigmoid 

ys,1 ys,2 ys,3 ys,4 ys,5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 6 shows</head><label>6</label><figDesc>the evaluation results of AES on three datasets. We can see that the BLRR algorith- m performs better than the SVR algorithm. No</figDesc><table>QWK Score 
Prompt 
1 
2 
3 
SVR-Basic 
0.554 0.468 0.457 
+ mode 
0.6 
0.501 0.481 
BLRR-Basic 0.683 0.557 0.513 
+ mode 
0.696 0.565 0.527 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Evaluation results of AES on three 
datasets. Basic: the basic feature sets; mode: dis-
course mode features. 

Prompt 
1 
2 
3 
Avg 
LEN 
0.59 
0.52 
0.45 
0.52 
Des 
0.23 
0.24 
0.24 
0.24 
Emo 
0.09 
0.15 
0.12 
0.12 
Exp 
-0.07 
0.01 
0.01 
-0.03 
Arg 
-0.08 -0.06 
-0.1 
-0.08 
Nar 
-0.11 -0.15 -0.12 -0.13 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Pearson correlation coefficients of mode 
ratio to essay score. LEN represents essay length. 

</table></figure>

			<note place="foot" n="2"> https://github.com/fchollet/keras/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic text scoring using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Alikaniotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2016</title>
		<meeting>ACL 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="715" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">On rhetoric: A theory of civic discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Aristotle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automated essay scoring with e-rater R v. 2. The Journal of Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigal</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and Assessment</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">English composition and rhetoric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Bain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1890" />
			<publisher>Longmans, Green &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling local coherence: An entity-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Research in written composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Reed</forename><surname>Braddock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Lloyd-Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lowell</forename><surname>Schoer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<publisher>JSTOR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An improved error model for noisy channel spelling correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert C</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2000</title>
		<meeting>ACL 2000</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Modern rhetoric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cleanth</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert Penn</forename><surname>Warren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1958" />
			<pubPlace>Harcourt, Brace</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The e-rater R scoring engine: Automated essay scoring with natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Finding the write stuff: Automatic identification of discourse structure in student essays. Intelligent Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="39" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2000</title>
		<meeting>NIPS 2000</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="402" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automated essay scoring by maximizing human-machine agreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1741" to="1752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer Caglar Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>Fethi Bougares Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The handbook of computational linguistics and natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shalom</forename><surname>Lappin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Toward a more valid account of functional text quality: The case of the patient information leaflet. Text &amp; Talk-An Interdisciplinary Journal of Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosemary</forename><surname>Clerehan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachelle</forename><surname>Buchbinder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discourse Communication Studies</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="68" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and psychological measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The rise and fall of the modes of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Connors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">College Composition and Communication</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="444" to="455" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Constrained multi-task learning for automated essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Cummins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2016</title>
		<meeting>ACL 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="789" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic features for essay scoring-an empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2016</title>
		<meeting>EMNLP 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1072" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2015</title>
		<meeting>ACL 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Situation entity types: automatic classification of clause-level aspect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2016</title>
		<meeting>ACL 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1757" to="1768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Supervised sequence labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Supervised Sequence Labelling with Recurrent Neural Networks</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barbara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind K</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Texttiling: Segmenting text into multi-paragraph subtopic passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marti A Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coherence and coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerry R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="90" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the structure of scientific texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hutchins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UEA Papers in Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="18" to="39" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Representation learning for text-level discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic essay grading using text categorization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leah S Larkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR 1998</title>
		<meeting>SIGIR 1998</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="90" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">What makes writing great? first experiments on article quality prediction in the science journalism domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="341" to="352" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2016</title>
		<meeting>ACL 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
		<title level="m">Rhetorical structure theory: Toward a functional theory of text organization. Text-Interdisciplinary Journal for the Study of Discourse</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="243" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Linking discourse modes and situation entity types in a cross-linguistic corpus study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kleio-Isidora</forename><surname>Mavridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annemarie</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>Melissa Peate Sørensen, Alexis Palmer, and Manfred Pinkal</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Genre as diversity, and rhetorical mode as unity in language use. Ilha do Desterro A Journal of English Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Luiz</forename><surname>Meurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Literatures in English and Cultural Studies</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="61" to="082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS 2013</title>
		<meeting>NIPS 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A sequencing model for situation entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elias</forename><surname>Ponvert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlota</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2007</title>
		<meeting>ACL 2007</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="896" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling organization in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2010</title>
		<meeting>EMNLP 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="229" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Flexible domain adaptation for automated essay scoring using correlated linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Phandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">A</forename><surname>Kian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2015</title>
		<meeting>EMNLP 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="431" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Generating confusion sets for context-sensitive error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2010</title>
		<meeting>EMNLP 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Modes of discourse: The local structure of texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Discourse element identification in student essays based on global and local cohesion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiji</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2015</title>
		<meeting>EMNLP 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2255" to="2261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A neural approach to automated essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaveh</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2016</title>
		<meeting>EMNLP 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1882" to="1891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2015</title>
		<meeting>EMNLP 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Summarizing scientific articles: experiments with relevance and rhetorical status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="445" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Discourse structure and language technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Egg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valia</forename><surname>Kordoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="437" to="490" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Buy one get one free: Distant annotation of chinese tense, event type and modality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2014</title>
		<meeting>LREC 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1412" to="1416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Î(An Introduction to Writing)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boshi</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Hubei Educational Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
