<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HarriGT: Linking news articles to scientific literature</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ravenscroft</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Scientific Computing</orgName>
								<orgName type="institution">University of Warwick</orgName>
								<address>
									<postCode>CV4 7AL</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<addrLine>96 Euston Rd</addrLine>
									<postCode>NW1 2DBB</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Filament AI</orgName>
								<address>
									<addrLine>CargoWorks, 1-2 Hatfields</addrLine>
									<postCode>SE1 9PG</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Clare</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aberystwyth University</orgName>
								<address>
									<postCode>SY23 3DB</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre for Scientific Computing</orgName>
								<orgName type="institution">University of Warwick</orgName>
								<address>
									<postCode>CV4 7AL</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<addrLine>96 Euston Rd</addrLine>
									<postCode>NW1 2DBB</postCode>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HarriGT: Linking news articles to scientific literature</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="19" to="24"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>19</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Being able to reliably link scientific works to the newspaper articles that discuss them could provide a breakthrough in the way we rationalise and measure the impact of science on our society. Linking these articles is challenging because the language used in the two domains is very different , and the gathering of online resources to align the two is a substantial information retrieval endeavour. We present HarriGT, a semi-automated tool for building corpora of news articles linked to the scientific papers that they discuss. Our aim is to facilitate future development of information-retrieval tools for newspa-per/scientific work citation linking. Har-riGT retrieves newspaper articles from an archive containing 17 years of UK web content. It also integrates with 3 large external citation networks, leveraging named entity extraction, and document classification to surface relevant examples of scientific literature to the user. We also provide a tuned candidate ranking algorithm to highlight potential links between scientific papers and newspaper articles to the user, in order of likelihood. HarriGT is provided as an open source tool (http: //harrigt.xyz).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For scientists, understanding the ways in which their work is being reported by journalists and the subsequent societal impact of these reports re- mains an overwhelming task. Research funding councils have also become increasingly interested in the impact that the research that they fund pro- duces. These motivating factors, combined with suggestions that traditional citation-based metrics such as JIF ( <ref type="bibr">Garfield, 2006</ref>) and h-index <ref type="bibr">(Hirsch, 2005</ref>) are not as transparent as once thought <ref type="bibr">(Cronin, 1984;</ref><ref type="bibr" target="#b1">Bornmann and Daniel, 2008)</ref> have catalyzed the development of metrics to measure scientific impact in society, policy and the econ- omy (recently termed "comprehensive scientific impact" <ref type="bibr">(Ravenscroft et al., 2017)</ref>). Evaluation programmes such as the UK's Research Excel- lence Framework (REF) Impact Case Study <ref type="bibr">(REF 2014</ref><ref type="bibr">(REF , 2012</ref>) and the United States' STAR Metrics programme <ref type="bibr">(Lane and Bertuzzi, 2010</ref>) set the cur- rent state of the art in comprehensive scientific im- pact metrics. However, both processes involve sig- nificant manual labour and introduce human sub- jectivity into their evaluation processes. <ref type="bibr">Ravenscroft et al. (2017)</ref> recently showed that there is negligible correlation between citation-based met- rics and REF scores and called for the develop- ment of an objective, automated metric for mea- suring comprehensive impact. As part of the US- funded FUSE project, <ref type="bibr">McKeown et al. (2016)</ref> de- veloped a method for measuring the use of techni- cal terms over time in scientific works as a proxy for scientific impact. McKeown's work, whilst primarily focusing on scientific literature, repre- sents a significant step towards deeper understand- ing of scientific impact beyond citations.</p><p>Our assumption is that the perception of re- searchers' work as reflected in the mainstream me- dia is an important means of measuring compre- hensive impact, useful both to researchers them- selves as well as funding bodies. However, one of the main barriers to building an automated solu- tion to assessing such comprehensive impact is a lack of training data. In this paper, we present and discuss our tool, HarriGT, which facilitates ground truth collection for a corpus of news articles linked to the scientific works that they discuss. In this way we aim to lay the groundwork for future stud-ies that help scientists understand societal percep- tion and impact of their work through the media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Citation extraction from news articles reporting on scientific topics remains a challenging and rela- tively unexplored task. There are no conventions, formal or informal, for citing a scientific work in a news article. Scientific journalists often omit key information about who funded or even carried out a given study from their reports making identifica- tion of the work very difficult ( <ref type="bibr" target="#b2">Bubela et al., 2009)</ref>. Journalists also frequently quote academics who were not directly involved in a scientific work in their stories, further confusing attempts to auto- mate citation extraction <ref type="bibr" target="#b4">(Conrad, 1999)</ref>. <ref type="bibr">Louis and Nenkova (2013)</ref> found that the quality of scientific reporting varies greatly even between journalists within the same publishing venue.</p><p>On the other hand, parsing and understanding citations between scientific works is a domain that has seen a lot of attention from academia in recent years. Citations in scientific papers are relatively well structured and formulaic. As such, pattern-based extraction mechanisms have been found to yield good citation extraction re- sults ( <ref type="bibr" target="#b5">Councill et al., 2008)</ref>. Disambiguation of the scientific work and authors to which a cita- tion refers can be a much more challenging task. This especially applies in cases where authors have ambiguous names (e.g. J. Smith). One ap- proach is to assign scientific works and authors unique identifiers such that there is no ambigu- ity in cited works (DOI and ORCID respectively) <ref type="bibr">(Paskin, 2015;</ref><ref type="bibr" target="#b3">Butler, 2012)</ref>. A more pragmatic approach is needed to disambiguate publications and authors for which no DOI or ORCID ID have been assigned. <ref type="bibr">Huang and Ertekin (2006)</ref> present a method for disambiguation of authors using a learned distance metric that takes into account au- thor's known names, affiliations and venues that they typically publish at. Similar approaches have led to the creation of citation networks that store relationships between huge volumes of scientific works. Networks such as CiteSeerX ( <ref type="bibr">Wu et al., 2014</ref>), Microsoft Academic Knowledge Graph and Scopus provide external access via APIs for research and application development purposes.</p><p>Beyond academia, references to scientific work are common across a number of domains. The popular encyclopedia website, Wikipedia, relies upon outbound citation to establish its veracity concerning matters of science <ref type="bibr">(Nielsen, 2007)</ref>. Whilst DOI links to articles are often used, in many cases, only the title, publication name and author names are provided leading to a structured extraction and disambiguation problem similar to that outlined above. <ref type="bibr">(Nielsen, 2007;</ref><ref type="bibr">Kousha and Thelwall, 2017;</ref><ref type="bibr">Nielsen et al., 2017)</ref>.</p><p>Since academia as a whole has begun to adapt to online publishing, academics have become in- dividually accustomed to sharing work through digital channels and social media. This has led to the development of systems such as Altmet- ric.com <ref type="bibr" target="#b0">(Adie and Roe, 2013)</ref>, that monitor social media posts as well as some mainstream media outlets for mentions of scientific works via DOI links. By their own admission, altmetric toolmak- ers still struggle to identify all mentions of scien- tific works, focusing only on articles with a DOI or some other unique identifier ( <ref type="bibr">Liu and Adie, 2013)</ref>.</p><p>Extraction and disambiguation of references to scientific works in news articles is the task that has motivated the development of HarriGT. We seek to facilitate construction of a human-curated cor- pus of newspaper articles that have been explic- itly linked to scientific works. Such corpora could be used to build machine learning models that are able to connect news articles to scientific works automatically. Using HarriGT we have already started the creation of such a corpus. At time of writing the corpus consists of 304 newspaper ar- ticles linked to one or more scientific paper. The corpus is growing incrementally and can be down- loaded via the tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Overview</head><p>Figure 1: HarriGT Web UI shows a news article and related candidate scientific papers HarriGT provides a system that brings together historical news articles from web archives stored in the widely used open source WARC format. The system automatically ingests and parses news- paper articles and searches citation graphs for rel- evant candidate papers that the user is able to link or hide or mark as spam. A diagram explain- ing this process is available on the HarriGT web- site. In this paper, we worked with a UK national web archive (JISC and the Internet Archive, 2013) and candidate scientific papers connected to cita- tion graphs from Microsoft, Scopus and Springer. The news article and candidate scientific papers are presented in a web interface, enabling a user to quickly decide whether each candidate is linked to the news article or not. This section discusses the components involved in this process in detail and outlines some of the challenges we faced in the system creation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">News Corpus Retrieval</head><p>In order to build a comprehensive corpus of news articles, we worked with the JISC Web Archive, a comprehensive scrape of the .uk top-level domain between 1996 and 2013. Content is stored in Web Archive (WARC) compressed format and an in- dex file containing metadata about every URL that was scraped and a pointer to the related content within the WARC structure was made available. The JISC Web Archive is approximately 62 Ter- abytes in size, so identifying and filtering relevant content became a primary concern <ref type="bibr">1</ref> .</p><p>We initially decided to restrict our investigation to news articles between 2011 and late 2013 which coincided with REF 2014. We compiled a list of web addresses for local and national UK news out- lets via a Wikipedia article 2 in order to reduce the number of hostnames that our tool should inspect down to 205. The archive index files also provided metadata about the type of each WARC entry and whether the original scrape was successful or not (e.g. whether the URL was invalid). This brought down the total number of WARC entries to be ex- amined to approximately 11.5 million. Requests to the BLOB store hosting the web archive were optimised through a script that identified batches of URLS archived in the same BLOB. <ref type="bibr">1</ref> The JISC Web Archive is accessible for research purposes at data.webarchive.org.uk/opendata/ ukwa.ds.2/ 2 https://en.wikipedia.org/wiki/List_ of_newspapers_in_the_United_Kingdom</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">News Article Pre-Processing &amp; Filtering</head><p>The contents of the archives were typically HTML and thus we needed to extract the title and body of each news story. HTML layouts can vary signifi- cantly between sites but news articles follow a typ- ical layout and thus extraction of content fields can be carried out using</p><note type="other">rules and patterns rather than a machine learning approach. For our purposes we found that the open source library newspaper 3 was highly effective and gave us access to an article's title, authors, publication date and other metadata. During the process we realised that some news articles had been duplicated in the archive. This can occur when a web crawler retrieves a URL that has been generated erroneously by the scraper script or the website being scraped. This can lead to multiple links to the same content. Examples include incorrectly appending search keywords, pagination information and other parameters into URLs that do not require these parameters.</note><p>To get around this problem, we introduced a hashing system, taking the SHA256 hash of the ti- tle body text from each article and only accepting new content if its hash is not already known.</p><p>We found that using the science section of the newspapers to filter suitable articles led to ex- clusion of relevant material. A second approach was to only accept articles that pass two high- level keyword filters. The first, simpler check is to see whether or not an article contains one or more keywords: science, scientist, professor, doc- tor, academic, journal, research, publish, report. We deliberately chose these keywords as a sim- plistic filter to reduce the amount of current af- fairs/celebrity gossip news that was initially ac- cepted into our system. For the second of our fil- ters, we ran a Named Entity Recognition (NER) algorithm 4 that provided multi-word expression identification and classification for names, loca- tions and geo-political entities. From the results of the NER execution, we only accepted articles with at least one organisation containing Univer- sity, College or Institute.</p><p>The final step in the pre-processing pipeline is identification of each article's publication date. Publication date is one of the most salient features in our paper candidate scoring algorithm discussed below. Recent digital news articles give their date of publication in their HTML metadata. However, for many of the old articles in the web archive, this information was not present. For articles with no known publication date, we first attempted to re- trieve the same URL from the live internet where much of the original content is still available but with updated layouts and metadata. If the content can't be found, we used a set of regular expres- sions (found within the newspaper library men- tioned above) to try and find the date in the article HTML. Failing all else, we simply asked the user to try and identify the publication date manually within the user interface. The retrieval and pre-processing steps are rather time consuming, taking a modern workstation (In- tel i7 Quad Core @ 3.5Ghz, 16GB RAM) approx- imately 24 hours to process 20k news articles. We therefore ingest content into HarriGT in batches using a small Apache Hadoop cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">'Spam' Filtering</head><p>Our keyword filter during pre-processing removes a large number of general interest articles that do not discuss scientific work. There are still a num- ber of articles that pass this initial screening that are off topic. We address this issue by includ- ing a machine learned "spam" model into Har- riGT. Within the user interface, news articles can be marked as spam if they contain little relevant scientific content. The model is re-trained using new examples from the spam and link categories as the user continues to tag articles.</p><p>We trained two machine learning models to ad- dress the problem, a Naive Bayes classifier and a Support Vector Machine. We used Grid Search to identify the best training hyper-parameters for fea- ture extraction and the models. The optimal fea- ture hyper-parameters were found to be unigram and bigram bag-of-words features with TF-IDF weighting, maximum document frequency of 75% and a maximum vocabulary size of 10,000. We found that an SVM with a linear kernel and C = 1 produced the best results and used this model in the live system. <ref type="table">Table 3</ref>.3 shows our model results after 4 iterations of training and use.</p><p>Given the size of the corpus, the hardware en- vironment that the model was required to support and the positive results from the SVM mode, we decided not to explore deep learning approaches to spam filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Citation Graph Integration</head><p>In order to provide candidate scientific works for each newspaper article, we required integration with rich sources of metadata for as many sci- entific disciplines as possible. We decided to integrate HarriGT with the Microsoft Academic Knowledge 5 , Scopus 6 and Springer 7 APIs. These APIs all provide broad, up to date coverage of known academic works. Each API had a differ- ent search endpoint with differing query languages and syntax that had to be catered for. Each of the APIs returns metadata such as title, names and affiliations of authors, name of pub- lishing venue and date of publication. In most cases each API returned a DOI so that each work could be uniquely identified and hyperlinked via the HarriGT interface. This allowed us to de- duplicate items returned by more than one API.</p><p>Articles typically talk about the institution that a scientific work was carried out at and indepen- dently the name of the author e.g. "Cambridge Researchers have found that... Dr Smith who led the study said..." making automatic extraction of reference information very difficult. Therefore, we use NER to identify all names and institutions in the article and run citation graph queries for each permutation. For example: "A study run by Oxford and Cambridge universities found that... Dr Jones who led the study said..." would yield two queries: (Jones, Oxford), (Jones, Cambridge). Searches are bounded by the article's publication date plus-or-minus 90 days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Candidate Scoring Implementation</head><p>The retrieval mechanism described above tends to overgenerate links between news articles and scientific publications, resulting in 0.19 precision. Therefore it is important to have a mechanism for ranking these further, to avoid spurious links and only show the user the most prominent ones for further verification. To address this we propose a simple but effective mechanism based on the Lev- enshtein Ratio. Each news article is associated with a set of C candidate scientific works c i where i ∈ [0, C] are found using the retrieval method discussed above. News articles contain two sets of entity mentions of interest: A set of N peoples' names n j and a set of O organization names o j . We also record the number of times each entity is mentioned M j . For each candidate scientific work c i , we identify a set of A i authors' names a k i and their respective academic affiliations u k i . We also note the publication date of each news article D and the publication date of each candidate scien- tific work P i .</p><p>For a given news article, we score each candi- date scientific work c i by summing over the square of Levenshtein Ratio <ref type="figure">(L r (x, y)</ref>) of each pair of mentions of names and authors:</p><formula xml:id="formula_0">S per i = N j=0 M j A i k=0 L r (n j , a i k ) 2</formula><p>A similar calculation is carried out for organisa- tion mentions and affiliations.</p><formula xml:id="formula_1">S org i = O j=0 M j A i k=0 L r (o j , u i k ) 2</formula><p>The Levenshtein Ratio is a simple, effective measure that has been used for assessing NE sim- ilarity ( <ref type="bibr">Moreau et al., 2008</ref>). We also calculate ∆ D , the number of days between the publication date of the news article, D and the scientific work P i . In cases where the candidate article has mul- tiple publication dates (for example, online publi- cation versus print publication), ∆ D is calculated for all publication dates and the smallest value is retained.</p><formula xml:id="formula_2">∆ D = min n ( (D − P n i ) 2 )</formula><p>Finally, we calculate an overall score S i for each article by normalizing S per i and S org i by their re- spective numbers of distinct entity mentions and then dividing by ∆ D like so:</p><formula xml:id="formula_3">S i = ( S per i N + S org i O ) × 1 ∆ D</formula><p>Candidates are ranked according to their S i score in descending order so that the highest scor- ing candidates are presented to the user first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Candidate Scoring Evaluation</head><p>To evaluate our candidate scoring technique, we use it to retrieve the N-best candidates for news articles with known links to one or more scientific papers. For each of the news articles in our ground truth collection, we retrieved all candidate scien- tific works from the citation graphs as described in section 3.4 above. We then use the scoring al- gorithm from section 3.5 above to rank the candi- dates then check to see whether actual linked pa- pers appear in the top 1,3 and 5 results (Top-K ac- curacy).</p><p>Top-1 Top-3 Top-5 Accuracy 0.59 0.83 0.90 We identified a small number of reasons for sub- optimal ranking. Newspaper articles occasionally focus around candidate works published months earlier. In some cases, incorrect publication dates are being reported by the scientific paper APIs. In both cases, our system strongly penalizes candi- dates in terms of ∆ D . HarriGT's ranking algo- rithm also weakly penalizes candidates that have multiple authors in cases where only one author (often the lead) is mentioned in the newspaper text. This effect is amplified when work by the same lead author with fewer or no co-authors is also found since these candidates are preferred and fil- tered to the top of the list.</p><p>HarriGT's recall is not bounded by the candi- date ranking algorithm but by the queries and re- sults from our integration with Scopus, Microsoft and Springer APIs. HarriGT allows the user to hide news articles that are scientific but for which no relevant candidates are recommended. This ac- tion is distinct from marking an item as spam, which indicates that it has no scientific value and should be excluded from the corpus.</p><p>We evaluate the recall of our tool by considering items marked as link to be retrieved and deemed relevant and items marked as hide to be retrieved but for which no relevant items could be found. Thus defining recall as:</p><formula xml:id="formula_4">recall = |{linked}| |{linked} ∪ {hidden}|</formula><p>At the time of writing, the recall of the system is 0.57. This figure may be lower than the actual figure, since papers are occasionally classified as 'hidden' by annotators if several strong candidates are presented and they are unsure which paper to link to. We expect that this figure will get stronger with more use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion &amp; Future Work</head><p>We have presented HarriGT, the first tool for rapidly establishing links between scientific works and the newspaper articles that discuss them. We have shown that using a combination of NLP tech- niques and proposing a simple but effective candi- date ranking algorithm, it is possible to construct a linked corpus of scientific articles and news ar- ticles for future analysis of the impact of scien- tific articles in news media. The tool could also have other uses such as the discovery of primary sources for scientific news. Future work will ex- plore the role of time and other content in this task. Our open source tool has been constructed with use of the JISC corpus in mind, but could be used with other sources of news also. HarriGT pro- duces useful ranking and good recall and is ready for use with a large corpus. HarriGT is available to try out at http://www.harrigt.xyz and we welcome feedback from volunteer users.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Top-K Accuracy for Scoring Algorithm</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="3"> http://newspaper.readthedocs.io/en/ latest/ 4 SpaCy 2.0 https://spacy.io/</note>

			<note place="foot" n="5"> https://labs.cognitive.microsoft.com/ en-us/project-academic-knowledge 6 https://dev.elsevier.com/index.html 7 https://dev.springer.com/</note>

			<note place="foot">B Cronin. 1984. The citation process: The role and significance of citations in scientific communication.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the EPSRC (grant EP/L016400/1) for funding us through the University of Warwick's CDT in Urban Science, the Alan Turing Institute and British Library for providing resources.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Altmetric: Enriching scholarly content with article-level discussion and metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learned Publishing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="17" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">What do citation counts measure? A review of studies on citing behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bornmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="80" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bubela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science communication reconsidered</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="514" to="518" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scientists: your number is up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">485</biblScope>
			<biblScope unit="issue">7400</biblScope>
			<biblScope unit="page" from="564" to="564" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Uses of expertise: sources, quotes, and voice in the reporting of genetics in the news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Conrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Understanding of Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="285" to="302" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ParsCit: An open-source CRF Reference String Parsing Package</title>
	</analytic>
	<monogr>
		<title level="m">LREC &apos;08: Proceedings of the 6th International Conference on Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="661" to="667" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
