<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Naturalizing a Programming Language via Interactive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ginn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
						</author>
						<title level="a" type="main">Naturalizing a Programming Language via Interactive Learning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="929" to="938"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1086</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Our goal is to create a convenient natural language interface for performing well-specified but complex actions such as analyzing data, manipulating text, and querying databases. However, existing natural language interfaces for such tasks are quite primitive compared to the power one wields with a programming language. To bridge this gap, we start with a core programming language and allow users to &quot;naturalize&quot; the core language incremen-tally by defining alternative, more natural syntax and increasingly complex concepts in terms of compositions of simpler ones. In a voxel world, we show that a community of users can simultaneously teach a common system a diverse language and use it to build hundreds of complex voxel structures. Over the course of three days, these users went from using only the core language to using the naturalized language in 85.9% of the last 10K utterances.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In tasks such as analyzing and plotting data <ref type="bibr" target="#b6">(Gulwani and Marron, 2014)</ref>, querying databases ( <ref type="bibr" target="#b16">Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b3">Berant et al., 2013)</ref>, manipulating text ( <ref type="bibr" target="#b8">Kushman and Barzilay, 2013)</ref>, or controlling the Internet of <ref type="bibr">Things (Campagna et al., 2017</ref>) and robots <ref type="bibr" target="#b14">(Tellex et al., 2011</ref>), peo- ple need computers to perform well-specified but complex actions. To accomplish this, one route is to use a programming language, but this is inac- cessible to most and can be tedious even for ex- perts because the syntax is uncompromising and all statements have to be precise. Another route is to convert natural language into a formal lan- Cubes: initial -select left 6 -select front 8 -black 10x10x10 frame -black 10x10x10 frame -move front 10 -red cube size 6 -move bot 2 -blue cube size 6 -green cube size 4 -(some steps are omitted)</p><p>Monsters, Inc: initial -move forward -add green monster -go down 8 -go right and front -add brown floor -add girl -go back and down -add door -add black column 30 -go up 9 -finish door -(some steps for moving are omitted) Deer: initial -bird's eye view -deer head; up; left 2; back 2; { left antler }; right 2; {right antler} -down 4; front 2; left 3; deer body; down 6; {deer leg front}; back 7; {deer leg back}; left 4; {deer leg back}; front 7; {deer leg front} -(some steps omitted) <ref type="figure">Figure 1</ref>: Some examples of users building struc- tures using a naturalized language in Voxelurn: http://www.voxelurn.com guage, which has been the subject of work in se- mantic parsing <ref type="bibr" target="#b17">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr">Zettlemoyer, 2011, 2013;</ref><ref type="bibr" target="#b13">Pasupat and Liang, 2015)</ref>. However, the capability of seman- tic parsers is still quite primitive compared to the power one wields with a programming language. This gap is increasingly limiting the potential of both text and voice interfaces as they become more ubiquitous and desirable.</p><p>In this paper, we propose bridging this gap with an interactive language learning process which we call naturalization. Before any learning, we seed a system with a core programming language that is always available to the user. As users instruct the system to perform actions, they augment the lan- guage by defining new utterances -e.g., the user can explicitly tell the computer that 'X' means 'Y'. Through this process, users gradually and interac- tively teach the system to understand the language that they want to use, rather than the core language that they are forced to use initially. While the first users have to learn the core language, later users can make use of everything that is already taught. This process accommodates both users' preferences and the computer action space, where the final language is both interpretable by the com- puter and easier to produce by human users.</p><p>Compared to interactive language learning with weak denotational supervision ( <ref type="bibr" target="#b15">Wang et al., 2016)</ref>, definitions are critical for learning complex ac- tions ( <ref type="figure">Figure 1</ref>). Definitions equate a novel ut- terance to a sequence of utterances that the sys- tem already understands. For example, 'go left 6 and go front' might be defined as 'repeat 6 [go left]; go front', which eventually can be traced back to the expression 'repeat 6 [select left of this]; select front of this' in the core language. Unlike function definitions in programming lan- guages, the user writes concrete values rather than explicitly declaring arguments. The system auto- matically extracts arguments and learns to produce the correct generalizations. For this, we propose a grammar induction algorithm tailored to the learn- ing from definitions setting. Compared to stan- dard machine learning, say from demonstrations, definitions provide a much more powerful learn- ing signal: the system is told directly that 'a 3 by 4 red square' is '3 red columns of height 4', and does not have to infer how to generalize from ob- serving many structures of different sizes.</p><p>We implemented a system called Voxelurn, which is a command language interface for a voxel world initially equipped with a programming lan- guage supporting conditionals, loops, and variable scoping etc. We recruited 70 users from Ama- zon Mechanical Turk to build 230 voxel struc- tures using our system. All users teach the sys- tem at once, and what is learned from one user can be used by another user. Thus a community of users evolves the language to becomes more effi- cient over time, in a distributed way, through in- teraction. We show that the user community de- fined many new utterances-short forms, alterna- tive syntax, and also complex concepts such as 'add green monster, add yellow plate 3 x 3'. As the system learns, users increasingly prefer to use the naturalized language over the core language: 85.9% of the last 10K accepted utterances are in the naturalized language. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Voxelurn</head><p>World. A world state in Voxelurn contains a set of voxels, where each voxel has relations 'row', 'col', 'height', and 'color'. There are two domain- specific actions, 'add' and 'move', one domain- specific relation 'direction'. In addition, the state contains a selection, which is a set of positions. While our focus is Voxelurn, we can think more generally about the world as a set of objects equiped with relations -events on a calendar, cells of a spreadsheet, or lines of text.</p><p>Core language. The system is born understand- ing a core language called Dependency-based Ac- tion Language (DAL), which we created (see <ref type="table">Ta- ble 1</ref> for an overview).</p><p>The language composes actions using the usual but expressive control primitives such as 'if', 'foreach', 'repeat', etc. Actions usually take sets as arguments, which are represented using lambda dependency-based compositional seman- tics (lambda DCS) expressions <ref type="bibr" target="#b10">(Liang, 2013)</ref>. Be- sides standard set operations like union, intersec-Rule(s) Example(s) Description A→ A; A select left; add red perform actions sequentially A→ repeat N A repeat 3-1 add red top repeat action N times A→ if S A if has color red <ref type="bibr">[select origin]</ref> action if S is non-empty A→ while S A while not has color red <ref type="bibr">[select left of this]</ref> action while S is non-empty A→ foreach S A foreach this [remove has row row of this] action for each item in S A→ <ref type="bibr">[A]</ref> [select left or right; add red; add red top] group actions for precedence A→ {A} {select left; add red} scope only selection A→ isolate A isolate [add red top; select has color red] scope voxels and selection A→ select S select all and not origin set the selection A→ remove S remove has color red remove voxels A→ update R S update color [color of left of this] change property of selection S this current selection S all | none | origin all voxels, empty set, (0, 0)</p><p>R of S | has R S has color red or yellow | has row [col of this] lambda DCS joins not S | S and S | S or S this or left and not has color red set operations N | N +N | N -N 1,. . . ,10 | 1+2 | row of this + 1 numbers and arithmetic argmax R S | argmin R S argmax col has color red superlatives tion and complement, lambda DCS leverages the tree dependency structure common in natural lan- guage: for the relation 'color', 'has color red' refers to the set of voxels that have color red, and its reverse 'color of has row 1' refers to the set of colors of voxels having row number 1. Tree- structured joins can be chained without using any variables, e.g., 'has color [yellow or color of has row 1]'. We protect the core language from being rede- fined so it is always precise and usable. 1 In ad- dition to expressivity, the core language interpo- lates well with natural language. We avoid explicit variables by using a selection, which serves as the default argument for most actions. <ref type="bibr">2</ref> For example, 'select has color red; add yellow top; remove' adds yellow on top of red voxels and then removes the red voxels.</p><formula xml:id="formula_0">R color | row | col | height | top | left | · · · voxel relations C red | orange | green | blue | black | · · · color values D top | bot | front | back | left | right direction values S→ very D of S</formula><p>To enable the building of more complex struc-tures in a more modular way, we introduce a no- tion of scoping. Suppose one is operating on one of the palm trees in <ref type="figure" target="#fig_0">Figure 2</ref>. The user might want to use 'select all' to select only the voxels in that tree rather than all of the voxels in the scene. In general, an action A can be viewed as taking a set of voxels v and a selection s, and producing an updated set of voxels v and a modified selec- tion s . The default scoping is '[A]', which is the same as 'A' and returns (v , s ). There are two constructs that alter the flow: First, '{A}' takes (v, s) and returns (v , s), thus restoring the selec- tion. This allows A to use the selection as a tem- porary variable without affecting the rest of the program. Second, 'isolate [A]' takes (v, s), calls A with (s, s) (restricting the set of voxels to just the selection) and returns (v , s), where v con- sists of voxels in v and voxels in v that occupy empty locations in v . This allows A to focus only on the selection (e.g., one of the palm trees). Although scoping can be explicitly controlled via '[ ]', 'isolate', and '{ }', it is an unnatural concept for non-programmers. Therefore when the choice is not explicit, the parser generates all three pos- sible scoping interpretations, and the model learns which is intended based on the user, the rule, and potentially the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Learning interactively from definitions</head><p>The goal of the user is to build a structure in Vox- elurn. In <ref type="bibr" target="#b15">Wang et al. (2016)</ref>, the user provided interactive supervision to the system by selecting from a list of candidates. This is practical when there are less than tens of candidates, but is com- pletely infeasible for a complex action space such as Voxelurn. Roughly, 10 possible colors over the 3 × 3 × 4 box containing the palm tree in <ref type="figure" target="#fig_0">Figure 2</ref> yields 10 36 distinct denotations, and many more programs. Obtaining the structures in <ref type="figure">Figure 1</ref> by selecting candidates alone would be infeasible. This work thus uses definitions in addition to se- lecting candidates as the supervision signal. Each definition consists of a head utterance and a body, which is a sequence of utterances that the system understands. One use of definitions is paraphras- ing and defining alternative syntax, which helps naturalize the core language (e.g., defining 'add brown top 3 times' as 'repeat 3 add brown top'). The second use is building up complex concepts hierarchically. In <ref type="figure" target="#fig_0">Figure 2</ref>, 'add yellow palm tree' is defined as a sequence of steps for building the palm tree. Once the system understands an utter- ance, it can be used in the body of other defini- tions. For example, <ref type="figure">Figure 3</ref> shows the full defini- tion tree of 'add palm tree'. Unlike function defi- nitions in a programming language, our definitions do not specify the exact arguments; the system has to learn to extract arguments to achieve the correct generalization.</p><p>The interactive definition process is described in <ref type="figure">Figure 4</ref>. When the user types an utterance x, the system parses x into a list of candidate programs. If the user selects one of them (based on its de- notation), then the system executes the resulting program. If the utterance is unparsable or the user rejects all candidate programs, the user is asked to provide the definition body for x. Any utterances in the body not yet understood can be defined re- cursively. Alternatively, the user can first execute a sequence of commands X, and then provide a head utterance for body X.</p><p>When constructing the definition body, users def: add palm tree def: brown trunk height 3 def: add brown top 3 times repeat 3 [add brown top] def: go to top of tree select very top of has color brown def: add leaves here def: select all sides select left or right or front or back add green <ref type="figure">Figure 3</ref>: Defining 'add palm tree', tracing back to the core language (utterances without def:).</p><p>begin execute x: if x does not parse then define x; if user rejects all parses then define x; execute user choice begin define x:</p><p>repeat starting with X ← [ ] user enters x ; if x does not parse then define x ; if user rejects all x then define x ; X ← [X; x ]; until user accepts X as the def'n of x; <ref type="figure">Figure 4</ref>: When the user enters an utterance, the system tries to parse and execute it, or requests that the user define it.</p><p>can type utterances with multiple parses; e.g., 'move forward' could either modify the selec- tion ('select front') or move the voxel ('move front'). Rather than propagating this ambiguity to the head, we force the user to commit to one interpretation by selecting a particular candidate. Note that we are using interactivity to control the exploding ambiguity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model and learning</head><p>Let us turn to how the system learns and predicts. This section contains prerequisites before we de- scribe definitions and grammar induction in Sec- tion 5.</p><p>Semantic parsing. Our system is based on a se- mantic parser that maps utterances x to programs z, which can be executed on the current state s (set of voxels and selection) to produce the next state s = z s . Our system is implemented as the inter- active package in SEMPRE <ref type="figure" target="#fig_0">(Berant et al., 2013)</ref>;  <ref type="table">Rule.ID  ID of the rule  Rule.Type  core?</ref>, used?, used by others? Social.Author ID of author Social.Friends (ID of author, ID of user) Social.Self rule is authored by user? Span (left/right token(s), category) Scope type of scoping for each user  Following <ref type="bibr" target="#b17">Zettlemoyer and Collins (2005)</ref>, we define a log-linear model over derivations d given an utterance x produced by the user u:</p><formula xml:id="formula_1">p θ (d | x, u) ∝ exp(θ T φ(d, x, u)),<label>(1)</label></formula><p>where φ(d, x, u) ∈ R p is a feature vector and θ ∈ R p is a parameter vector. The user u does not appear in previous work on semantic parsing, but we use it to personalize the semantic parser trained on the community. We use a standard chart parser to construct a chart. For each chart cell, indexed by the start and end indices of a span, we construct a list of partial derivations recursively by selecting child derivations from subspans and applying a gram- mar rule. The resulting derivations are sorted by model score and only the top K are kept. We use chart(x) to denote the set of all partial deriva- tions across all chart cells. The set of grammar rules starts with the set of rules for the core lan- guage <ref type="table">(Table 1)</ref>, but grows via grammar induction when users add definitions (Section 5). Rules in the grammar are stored in a trie based on the right- hand side to enable better scalability to a large number of rules.</p><p>Features. Derivations are scored using a weighted combination of features. There are three types of features, summarized in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Rule features fire on each rule used to construct a derivation. ID features fire on specific rules (by ID). Type features track whether a rule is part of the core language or induced, whether it has been used again after it was defined, if it was used by someone other than its author, and if the user and the author are the same (5 + #rules features).</p><p>Social features fire on properties of rules that capture the unique linguistic styles of different users and their interaction with each other. Author features capture the fact that some users provide better, and more generalizable definitions that tend to be accepted. Friends features are cross products of author ID and user ID, which captures whether rules from a particular author are systematically preferred or not by the current user, due to stylistic similarities or differences (#users+#users×#users features).</p><p>Span features include conjunctions of the cate- gory of the derivation and the leftmost/rightmost token on the border of the span. In addition, span features include conjunctions of the category of the derivation and the 1 or 2 adjacent tokens just outside of the left/right border of the span. These capture a weak form of context-dependence that is generally helpful (&lt;≈ V 4 × #cats features for a vocabulary of size V ).</p><p>Scoping features track how the community, as well as individual users, prefer each of the 3 scoping choices (none, selection only '{A}', and voxels+selection 'isolate {A}'), as described in Section 2. 3 global indicators, and 3 indicators for each user fire every time a particular scoping choice is made (3 + 3 × #users features).</p><p>Parameter estimation. When the user types an utterance, the system generates a list of candidate next states. When the user chooses a particular next state s from this list, the system performs an online AdaGrad update ( <ref type="bibr" target="#b5">Duchi et al., 2010</ref>) on the parameters θ according to the gradient of the fol- lowing loss function:</p><formula xml:id="formula_2">− log d:prog(d)s=s p θ (d | x, u) + λ||θ|| 1 ,</formula><p>which attempts to increase the model probability on derivations whose programs produce the next state s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Grammar induction</head><p>Recall that the main form of supervision is via user definitions, which allows creation of user-defined concepts. In this section, we show how to turn these definitions into new grammar rules that can be used by the system to parse new utterances.</p><p>Previous systems of grammar induction for semantic parsing were given utterance-program pairs (x, z). Both the GENLEX (Zettlemoyer and <ref type="bibr" target="#b17">Collins, 2005</ref>) and higher-order unifica- tion ( <ref type="bibr" target="#b9">Kwiatkowski et al., 2010</ref>) algorithms over- generate rules that liberally associate parts of x with parts of z. Though some rules are immedi- ately pruned, many spurious rules are undoubtedly still kept. In the interactive setting, we must keep the number of candidates small to avoid a bad user experience, which means a higher precision bar for new rules.</p><p>Fortunately, the structure of definitions makes the grammar induction task easier. Rather than be- ing given an utterance-program (x, z) pair, we are given a definition, which consists of an utterance x (head) along with the body X = [x 1 , . . . , x n ], which is a sequence of utterances. The body X is fully parsed into a derivation d, while the head x is likely only partially parsed. These partial deriva- tions are denoted by chart(x).</p><p>At a high-level, we find matches-partial derivations chart(x) of the head x that also occur in the full derivation d of the body X. A grammar rule is produced by substituting any set of non- overlapping matches by their categories. As an example, suppose the user defines 'add red top times 3' as 'repeat 3 [add red top]'.</p><p>Then we would be able to induce the following two grammar rules:</p><formula xml:id="formula_3">A → add C D times N : λCDN.repeat N [add C D] A → A times N : λAN.repeat N [A]</formula><p>The first rule substitutes primitive values ('red', 'top', and '3') with their respective pre-terminal categories (C, D, N ). The second rule contains compositional categories like actions (A), which require some care. One might expect that greedily substituting the largest matches or the match that covers the largest portion of the body would work, but the following example shows that this is not the case:</p><formula xml:id="formula_4">A 1</formula><p>A 1 A 1 add red left and here = add red left; add red</p><formula xml:id="formula_5">A 2 A 2</formula><p>Here, both the highest coverage substitution (A 1 : 'add red', which covers 4 tokens of the body), and the largest substitution available (A 2 : 'add red left') would generalize incorrectly. The correct grammar rule only substitutes the primitive values ('red', 'left').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Highest scoring abstractions</head><p>We now propose a grammar induction procedure that optimizes a more global objective and uses the learned semantic parsing model to choose substi- tutions. More formally, let M be the set of partial derivations in the head whose programs appear in the derivation d X of the body X:</p><formula xml:id="formula_6">M def = {d ∈ chart(x) : ∃d ∈ desc(d X ) ∧ prog(d) = prog(d )},</formula><p>where desc(d X ) are the descendant derivations of d X . Our goal is to find a packing P ⊆ M , which is a set of derivations corresponding to non- overlapping spans of the head. We say that a pack- ing P is maximal if no other derivations may be added to it without creating an overlap. Let packings(M ) denote the set of maximal packings, we can frame our problem as finding the maximal packing that has the highest score under our current semantic parsing model:</p><formula xml:id="formula_7">P * L = argmax P ∈packings(M ); d∈P score(d).<label>(2)</label></formula><p>Finding the highest scoring packing can be done using dynamic programming on P * i for i = 0, 1, . . . , L, where L is the length of x and P * 0 = ∅. Since d ∈ M , start(d) and end(d) (exclusive) re- fer to span in the head x. To obtain this dynamic program, let D i be the highest scoring maximal packing containing a derivation ending exactly at position i (if it exists):</p><formula xml:id="formula_8">D i = {d i } ∪ P * start(d i ) ,<label>(3)</label></formula><formula xml:id="formula_9">d i = argmax d∈M ;end(d)=i score(d ∪ P * start(d) ).<label>(4)</label></formula><p>Then the maximal packing of up to i can be de- fined recursively as</p><formula xml:id="formula_10">P * i = argmax D∈{D s(i)+1 ,D s(i)+2 ,...,D i } score(D) (5) s(i) = max d:end(d)≤i start(d),<label>(6)</label></formula><formula xml:id="formula_11">Input : x, d X , P * Output: rule r ← x; f ← d X ; for d ∈ P * do r ← r[cat(d)/ span(d)] f ← λ cat(d).f [cat(d)/d]</formula><note type="other">return rule (cat(d X )→ r : f ) Algorithm 1: Extract a rule r from a derivation d X of body X and a packing P * . Here, f [t/s] means substituting s by t in f , with the usual care about names of bound variables. where s(i) is the largest index such that D s(i) is no longer maximal for the span</note><formula xml:id="formula_12">(0, i) (i.e. there is a d ∈ M on the span start(d) ≥ s(i) ∧ end(d) ≤ i.</formula><p>Once we have a packing P * = P * L , we can go through d ∈ P * in order of start(d), as in Algo- rithm 1. This generates one high precision rule per packing per definition. In addition to the highest scoring packing, we also use a "simple packing", which includes only primitive values (in Voxelurn, these are colors, numbers, and directions). Un- like the simple packing, the rule induced from the highest scoring packing does not always general- ize correctly. However, a rule that often general- izes incorrectly should be down-weighted, along with the score of its packings. As a result, a differ- ent rule might be induced next time, even with the same definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Extending the chart via alignment</head><p>Algorithm 1 yields high precision rules, but fails to generalize in some cases. Suppose that 'move up' is defined as 'move top', where 'up' does not parse, and does not match anything. We would like to infer that 'up' means 'top'. To handle this, we leverage a property of definitions that we have not used thus far: the utterances themselves. If we align the head and body, then we would in- tuitively expect aligned phrases to correspond to the same derivations. Under this assumption, we can then transplant these derivations from d X to chart(x) to create new matches. This is more con- strained than the usual alignment problem (e.g., in machine translation) since we only need to con- sider spans of X which corresponds to derivations in desc(d X ).</p><p>Algorithm 2 provides the algorithm for extend- ing the chart via alignments. The aligned function is implemented using the following two heuristics:</p><formula xml:id="formula_13">Input : x, X, d X for d ∈ desc(d X ), x ∈ spans(x) do if aligned(x , d, (x, X)) then d ← d; start(d ) ← start(x ); end(d ) ← end(x ); chart(x) ← chart(x) ∪ d end end</formula><p>Algorithm 2: Extending the chart by alignment: If d is aligned with x based on the utterance, then we pretend that x should also parse to d, and d is transplanted to chart(x) as if it parsed from x .</p><p>• exclusion: if all but 1 pair of short spans (1 or 2 tokens) are matched, the unmatched pair is considered aligned.</p><p>• projectivity:</p><formula xml:id="formula_14">if d 1 , d 2 ∈ desc(d X ) ∩ chart(x), then ances(d 1 , d 2 )</formula><p>is aligned to the corresponding span in x.</p><p>With the extended chart, we can run the algo- rithm from Section 5.1 to induce rules. The trans- planted derivations (e.g., 'up') might now form new matches which allows the grammar induction to induce more generalizable rules. We only per- form this extension when the body consists of one utterance, which tend to be a paraphrase. Bodies with multiple utterances tend to be new concepts (e.g., 'add green monster'), for which alignment is impossible. Because users have to select from candidates parses in the interactive setting, induc- ing low precision rules that generate many parses degrade the user experience. Therefore, we induce alignment-based rules conservatively-only when all but 1 or 2 tokens of the head aligns to the body and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>Setup. Our ultimate goal is to create a commu- nity of users who can build interesting structures in Voxelurn while naturalizing the core language. We created this community using Amazon Mechani- cal Turk (AMT) in two stages. First, we had quali- fier tasks, in which an AMT worker was instructed to replicate a fixed target exactly <ref type="figure" target="#fig_3">(Figure 5</ref>), ensur- ing that the initial users are familiar with at least some of the core language, which is the starting point of the naturalization process. Next, we allowed the workers who qualified to enter the second freebuilding task, in which they were asked to build any structure they wanted in 30 minutes. This process was designed to give users freedom while ensuring quality. The anal- ogy of this scheme in a real system is that early users (or a small portion of expert users) have to make some learning investment, so the system can learn and become easier for other users.</p><p>Statistics. 70 workers passed the qualifier task, and 42 workers participated in the final free- building experiment. They built 230 structures. There were over 103,000 queries consisting of 5,388 distinct token types. Of these, 64,075 utter- ances were tried and 36,589 were accepted (so an action was performed). There were 2,495 defini- tions combining over 15,000 body utterances with 6.5 body utterances per head on average (96 max). From these definitions, 2,817 grammar rules were induced, compared to less than 100 core rules. Over all queries, there were 8.73 parses per utter- ance on average (starting from 1 for core).</p><p>Is naturalization happening? The answer is yes according to <ref type="figure" target="#fig_4">Figure 6</ref>, which plots the cum- mulative percentage of utterances that are core, in- duced, or unparsable. To rule out that more in- duced utterances are getting rejected, we consider only accepted utterances in the middle of <ref type="figure" target="#fig_4">Fig- ure 6</ref>, which plots the percentage of induced rules among accepted utterances for the entire commu- nity, as well as for the 5 heaviest users. Since un- parsable utterances cannot be accepted, accepted core (which is not shown) is the complement of accepted induced. At the conclusion of the ex- periment, 72.9% of all accepted utterances are induced-this becomes 85.9% if we only consider the final 10,000 accepted utterances.</p><p>Three modes of naturalization are outlined in <ref type="table" target="#tab_2">Table 3</ref>. For very common operations, like moving the selection, people found 'select left' too ver- bose and shorterned this to l, left, &gt;, sel l. One user preferred 'go down and right' instead of 'se- lect bot; select right' in core and defined it as 'go down; go right'. Definitions for high-level concepts tend to be whole objects that are not pa- rameterized (e.g., 'dancer'). The bottom plot of <ref type="figure" target="#fig_4">Figure 6</ref> suggests that users are defining and us- ing higher level concepts, since programs become longer relative to utterances over time.</p><p>As a result of the automatic but implicit gram- mar induction, some concepts do not generalize correctly. In definition head '3 tall 9 wide white tower centered here', arguments do not match the body; for 'black 10x10x10 frame', we failed to to- kenize.</p><p>Short forms left, l, mov left, go left, &lt;, sel left br, black, blu, brn, orangeright, left3 add row brn left 5 := add row brown left 5 Alternative syntax go down and right := go down; go right select orange := select has color orange add red top 4 times := repeat 4 [add red top] l white := go left and add white mov up 2 := repeat 2 [select up] go up 3 := go up 2; go up Higher level add red plate 6 x 7, green cube size 4, add green monster, black 10x10x10 frame, flower petals, deer leg back, music box, dancer Learned parameters. Training using L1 regu- larization, we obtained 1713 features with non- zero parameters. One user defined many con- cepts consisting of a single short token, and the Social.Author feature for that user has the most negative weight overall. With user compatibil- ity (Social.Friends), some pairs have large pos- itive weights and others large negative weights. The 'isolate' scoping choice (which allows easier hierarchical building) received the most positive weights, both overall and for many users. The 2 highest scoring induced rules correspond to 'add row red right 5' and 'select left 2'.</p><p>Incentives. Having complex structures show that the actions in Voxelurn are expressive and that hierarchical definitions are useful. To incentivize this behavior, we created a leaderboard which ranked structures based on recency and upvotes (like Hacker News). Over the course of 3 days, we picked three prize categories to be released daily. The prize categories for each day were bridge, house, animal; tower, monster, flower; ship, dancer, and castle.</p><p>To incentivize more definitions, we also track citations. When a rule is used in an accepted ut- terance by another user, the rule (and its author) receives a citation. We pay bonuses to top users according to their h-index. Most cited definitions are also displayed on the leaderboard. Our qual- itative results should be robust to the incentives scheme, because the users do not overfit to the incentives-e.g., around 20% of the structures are not in the prize categories and users define com- plex concepts that are rarely cited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related work and discussion</head><p>This work is an evolution of <ref type="bibr" target="#b15">Wang et al. (2016)</ref>, but differs crucially in several ways: While <ref type="bibr" target="#b15">Wang et al. (2016)</ref> starts from scratch and relies on se- lecting candidates, this work starts with a pro- gramming language (PL) and additionally relies on definitions, allowing us to scale. Instead of having a private language for each user, the user community in this work shares one language. <ref type="bibr" target="#b2">Azaria et al. (2016)</ref> presents Learning by In- struction Agent (LIA), which also advocates learn- ing from users. They argue that developers can- not anticipate all the actions that users want, and that the system cannot understand the correspond- ing natural language even if the desired action is built-in. Like <ref type="bibr" target="#b7">Jia et al. (2017)</ref>, <ref type="bibr" target="#b2">Azaria et al. (2016)</ref> starts with an ad-hoc set of initial slot-filling com- mands in natural language as the basis of further instructions-our approach starts with a more ex- pressive core PL designed to interpolate with nat- ural language. Compared to previous work, this work studied interactive learning in a shared com- munity setting and hierarchical definitions result- ing in more complex concepts.</p><p>Allowing ambiguity and a flexible syntax is a key reason why natural language is easier to produce-this cannot be achieved by PLs such as Inform and COBOL which look like natural lan- guage. In this work, we use semantic parsing tech- niques that can handle ambiguity <ref type="bibr">Collins, 2005, 2007;</ref><ref type="bibr" target="#b9">Kwiatkowski et al., 2010;</ref><ref type="bibr" target="#b12">Liang et al., 2011;</ref><ref type="bibr" target="#b13">Pasupat and Liang, 2015)</ref>. In semantic parsing, the semantic representation and action space is usually designed to accommodate the natural language that is considered constant. In contrast, the action space is considered constant in the naturalizing PL approach, and the language adapts to be more natural while accommodating the action space.</p><p>Our work demonstrates that interactive defini- tions is a strong and usable form of supervision. In the future, we wish to test these ideas in more domains, naturalize a real PL, and handle para- phrasing and implicit arguments. In the process of naturalization, both data and the semantic gram- mar have important roles in the evolution of a lan- guage that is easier for humans to produce while still parsable by computers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Interface used by users to enter utterances and create definitions.</figDesc><graphic url="image-4.png" coords="2,307.28,223.69,218.27,168.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FeatureDescription</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>see Liang ( 2016 )</head><label>2016</label><figDesc>for a gentle exposition. A derivation d represents the process by which an utterance x turns into a program z = prog(d). More precisely, d is a tree where each node contains the corresponding span of the utterance (start(d), end(d)), the grammar rule rule(d), the grammar category cat(d), and a list of child derivations [d 1 , . . . , d n ].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The target used for the qualifier.</figDesc><graphic url="image-5.png" coords="8,153.85,62.81,54.57,54.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Learning curves. Top: percentage of all utterances that are part of the core language, the induced language, or unparsable by the system. Middle: percentage of accepted utterances belonging to the induced language, overall and for the 5 heaviest users. Bottom: expressiveness measured by the ratio of the length of the program to the length of the corresponding utterance.</figDesc><graphic url="image-8.png" coords="8,307.28,332.64,196.44,140.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Summary of features. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Example definitions. See CodaLab work- sheet for the full leaderboard.</figDesc><table></table></figure>

			<note place="foot">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 929-938 Vancouver, Canada, July 30-August 4, 2017. c 2017 Association for Computational Linguistics https://doi.org/10.18653/v1/P17-1086</note>

			<note place="foot" n="1"> Not doing so resulted in ambiguities that propagated uncontrollably, e.g., once &apos;red&apos; can mean many different colors. 2 The selection is like the turtle in LOGO, but can be a set.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Instructable intelligent personal agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2681" to="2689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Almond: The architecture of an open, crowdsourced, privacy-preserving, programmable virtual assistant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Campagna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="341" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">NLyze: interactive programming by natural language for spreadsheet data analysis and manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Management of Data, SIGMOD</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="803" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning concepts through conversations in spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using semantic unification to generate regular expressions from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="826" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higher-order unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4408</idno>
		<title level="m">Lambda dependency-based compositional semantics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning executable semantic parsers for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM 59</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Understanding natural language commands for robotic navigation and mobile manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning language games through interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
