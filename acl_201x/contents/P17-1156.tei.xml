<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Active Sentiment Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
						</author>
						<title level="a" type="main">Active Sentiment Domain Adaptation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1701" to="1711"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-1156</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Domain adaptation is an important technology to handle domain dependence problem in sentiment analysis field. Existing methods usually rely on sentiment classi-fiers trained in source domains. However , their performance may heavily decline if the distributions of sentiment features in source and target domains have significant difference. In this paper, we propose an active sentiment domain adaptation approach to handle this problem. Instead of the source domain sentiment classifiers, our approach adapts the general-purpose sentiment lexicons to target domain with the help of a small number of labeled samples which are selected and annotated in an active learning mode, as well as the domain-specific sentiment similarities among words mined from unlabeled samples of target domain. A unified model is proposed to fuse different types of sentiment information and train sentiment clas-sifier for target domain. Extensive experiments on benchmark datasets show that our approach can train accurate sentiment classifier with less labeled samples.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment classification is widely known as a domain-dependent problem <ref type="bibr" target="#b20">(Liu, 2012;</ref><ref type="bibr" target="#b24">Pang and Lee, 2008;</ref><ref type="bibr" target="#b1">Blitzer et al., 2007;</ref>. This is because different domains usually have many different sentiment expressions. For exam- ple, "lengthy" and "boring" are popularly used in Book domain to express negative sentiment. Ho- wever, they are rare in Kitchen appliance domain. Moreover, the same word or phrase may convey * Corresponding author. different sentiments in different domains. For in- stance, "unpredictable" is frequently used to ex- press positive sentiment in Movie domain (e.g., "The plot of this movie is fun and unpredictable"). However, it tends to be used as a negative word in Kitchen appliance domain (e.g., "Even holding heat is unpredictable. It is just terrible!"). Thus, every domain has many domain-specific sentiment expressions, which cannot be captured by other domains. The performance of directly applying a general sentiment classifier or a sentiment classi- fier trained in other domains to target domain is usually suboptimal.</p><p>Since there are a large number of domains in user-generated content, it is impractical to ma- nually annotate enough samples for each dom- ain to train an accurate domain-specific sentiment classifier. Thus, sentiment domain adaptation, which transfers the sentiment classifier trained in a source domain with sufficient labeled data to a target domain with no or scarce labeled data, has been widely studied <ref type="bibr" target="#b1">(Blitzer et al., 2007;</ref><ref type="bibr" target="#b13">He et al., 2011;</ref><ref type="bibr" target="#b9">Glorot et al., 2011</ref>). Existing sentiment domain adaptation methods are mainly based on transfer learning techniques. Many of them try to learn a new feature representation to augment or replace the original feature space in order to reduce the gap of sentiment feature distri- butions between source and target domains <ref type="bibr" target="#b9">Glorot et al., 2011</ref>). For example, <ref type="bibr" target="#b1">Blitzer et al. (2007)</ref> proposed to learn a latent re- presentation for domain-specific words from both source and target domains by using pivot features as bridge. The advantage of these methods is that no labeled data in target domain is needed. Howe- ver, when the distributions of sentiment features in source and target domains have significant diffe- rence, the performance of domain adaptation will heavily decline ( ). In some cases, the performance of adaptation is even lower than that without adaptation, which is usually known as negative transfer .</p><p>In this paper, we propose an active sentiment domain adaptation approach to handle this pro- blem by incorporating both general sentiment in- formation and a small number of actively selected labeled samples from target domain. More specifi- cally, in our approach the general sentiment infor- mation extracted from sentiment lexicons is adap- ted to target domain using domain-specific senti- ment similarities among words. The general sen- timent information is regarded as a "background" domain to transfer. The word similarities are ex- tracted from unlabeled samples of target domain using both syntactic rules and co-occurrence pat- terns. Then we actively select and annotate a small number of informative samples from target dom- ain in an active learning manner. These labeled samples are incorporated into our approach to im- prove the performance of sentiment domain adap- tation. A unified model is proposed to incorporate different types of sentiment information to train sentiment classifier for target domain. Extensive experiments were conducted on benchmark data- sets. The experimental results show that our ap- proach can train accurate sentiment classifiers and reduce the manual annotation effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sentiment Domain Adaptation</head><p>Sentiment classification is well known as a highly domain-dependent task, and domain adaptation is widely studied in sentiment analysis field to handle this problem <ref type="bibr" target="#b1">(Blitzer et al., 2007;</ref><ref type="bibr" target="#b13">He et al., 2011;</ref><ref type="bibr" target="#b9">Glorot et al., 2011</ref>). Existing sentiment domain adaptation methods are mainly based on transfer learning technique , where sentiment classifiers are trai- ned in one or multiple source domains with suf- ficient labeled samples, and then applied to target domain where there is no or only scarce labeled samples. In order to reduce the gap of sentiment feature distributions between source and target domains, many sentiment domain adaptation met- hods try to learn a new feature representation to augment or replace the original feature space. For example,  proposed a sentiment domain adaptation method based on spectral fea- ture alignment (SFA) algorithm. They first manu- ally selected several domain-independent features and computed the associations between domain- specific features and domain-independent featu- res. After that they built a bipartite graph where domain-independent and domain-specific featu- res were regarded as two types of nodes. Then domain-specific features were grouped into se- veral clusters using spectral clustering algorithm. These clusters were used to augment the original feature representations. <ref type="bibr" target="#b9">Glorot et al. (2011)</ref> propo- sed a sentiment domain adaptation method based on a deep learning technique, i.e., Stacked Denoi- sing Autoencoders. They learned the parameters of neural networks using unlabeled samples from both source and target domains, and used the hid- den nodes of the neural networks as the latent fe- ature representations of both domains. Then they trained sentiment classifiers using source domain labeled data in this new feature space and app- lied it to target domain. The advantage of these sentiment domain adaptation methods is that they do not rely on the labeled data in target dom- ain. However, they have a common shortcoming, i.e., when the distributions of sentiment features in source and target domains have significant diffe- rence, the performance of domain adaptation will heavily decline ( ). In some cases, negative transfer may happen <ref type="bibr" target="#b1">(Blitzer et al., 2007;</ref>, which means the performance of adaptation is worse than that without adapta- tion . Different from many existing sentiment domain adaptation methods, in our approach we adapt the general sentiment in- formation in sentiment lexicons to target domain with the help of a small number of labeled samples which are selected and annotated in an active lear- ning mode. Since the sentiment words in general- purpose sentiment lexicons usually convey con- sistent sentiment polarities in different domains, and the actively selected labeled samples contain rich domain-specific sentiment information of tar- get domain, our approach can effectively reduce the risk of negative transfer.</p><p>The usefulness of labeled samples from target domain in sentiment domain adaptation has been observed by previous research works ( <ref type="bibr" target="#b5">Choi and Cardie, 2009;</ref><ref type="bibr" target="#b4">Chen et al., 2011;</ref>. For example, <ref type="bibr" target="#b5">Choi and Cardie (2009)</ref> proposed to adapt a sentiment lexicon to a specific domain by exploiting both the relations among words which co-occur in the same senti- ment expressions and the relations between words and labeled sentiment expressions. However, the labeled samples used in these methods are rand- omly selected, while in our approach we actively select informative samples from target domain to annotate. Thus, our approach has the potential to reduce the manual annotation effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Active Learning</head><p>Active learning is a useful technique in scena- rios where unlabeled data is abundant but their labels are difficult or expensive to obtain <ref type="bibr" target="#b30">(Tong and Koller, 2002;</ref><ref type="bibr" target="#b27">Settles, 2010)</ref>. By actively se- lecting informative samples to label, active lear- ning can effectively reduce the annotation effort, and improve the classification performance with limited budget ( <ref type="bibr" target="#b18">Li et al., 2012</ref>). An important problem in active learning is how to evaluate the informativeness of unlabeled samples ( <ref type="bibr" target="#b8">Fu et al., 2013)</ref>. Different methods have been applied to se- lect informative samples, such as uncertainty sam- pling ( <ref type="bibr" target="#b41">Zhu et al., 2010;</ref><ref type="bibr" target="#b38">Yang et al., 2015)</ref>, query- by-committee ( <ref type="bibr" target="#b6">Freund et al., 1997;</ref> and so on. In our approach, uncertainty combined with density is used to measure the informative- ness of samples. A major difference between our approach and existing active learning methods is that in existing methods the parameters of the ini- tial classifier are either initialized as zero <ref type="bibr">(CesaBianchi et al., 2006</ref>) or learned from a set of rand- omly selected samples <ref type="bibr" target="#b27">(Settles, 2010)</ref>. In contrast, the initial sentiment classifier in our approach is constructed by adapting the general sentiment in- formation to target domain via the domain-specific sentiment similarities among words.</p><p>There are a few works that apply active learning methods to sentiment domain adaptation task <ref type="bibr" target="#b26">(Rai et al., 2010;</ref>. For example, <ref type="bibr" target="#b26">Rai et al. (2010)</ref> proposed an online active learning al- gorithm for sentiment domain adaptation. They started with a sentiment classifier trained on the labeled samples of a source domain. Then they sequentially selected informative samples in target domain to annotate with a probability positively related to classification uncertainty. The newly an- notated samples were used to update the sentiment classifier in an online learning manner.  proposed another active learning method for cross-domain sentiment classification. In their method they trained two sentiment classifiers, one on the labeled samples of source domain, and the other one on the labeled samples of target domain. Then query-by-committee strategy was used to se- lect the informative instances from target domain. Different from these methods, our approach does not rely on the labeled data of source domains. Instead, in our approach the general sentiment in- formation in sentiment lexicons is actively adapted to target domain, which usually has better genera- lization ability in various domains than the senti- ment classifier trained in a source domain. In ad- dition, our approach can incorporate the domain- specific sentiment similarities among words mined from unlabeled samples of target domain, which are not considered in these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Active Sentiment Domain Adaptation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Notations</head><p>First we introduce several notations that will be used in remaining part of this paper. Denote the general sentiment information extracted from a general-purpose sentiment lexicon as p ∈ R D×1 , where D is the vocabulary size. If the i th word is labeled as positive (or negative) in the sentiment lexicon, then p i = +1 (or p i = −1). Otherwise, p i = 0. Following many previous works in senti- ment classification field ( <ref type="bibr" target="#b1">Blitzer et al., 2007;</ref>), here we select linear classifier as sen- timent classifier, and denote the linear classifica- tion model as w ∈ R D×1 . We use f (x i , y i , w) to represent the loss of classifying the i th labe- led sample in target domain under the classifica- tion model w, where f is the classification loss function, x i ∈ R D×1 is the feature vector of this sample and y i is its sentiment label. In this paper we focus on binary sentiment classification and y i ∈ {+1, −1}. In addition, we select log loss for f . Thus, f (x i , y i , w) = log(1 + exp(−y i w T x i )). Besides, we use S ∈ R D×D to represent the senti- ment similarities among words extracted from un- labeled samples of target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Domain-Specific Sentiment Similarities</head><p>Next we introduce the extraction of domain- specific sentiment similarities among words from unlabeled samples of target domain. Two types of similarities are extracted in this paper. The first one is based on syntactic rules, which is inspired by <ref type="bibr" target="#b12">(Hatzivassiloglou and McKeown, 1997;</ref><ref type="bibr" target="#b17">Huang et al., 2014;</ref>. If two words have the same POS-tag such as adjective, verb, and adverb, and they are connected by coordinating conjunction "and" in the same sentence, then we regard they convey the same sentiment polarity. In addition, if two words are connected by adversa- tive conjunction "but" and have the same POS-tag, then they are assumed to have opposite sentiment polarities. Denote S r ∈ R D×D as the sentiment similarities extracted from unlabeled samples ac- cording to syntactic rules, and the similarity score between words i and j is defined as:</p><formula xml:id="formula_0">S r i,j = N s i,j − N o i,j N s i,j + N o i,j + α1 ,<label>(1)</label></formula><p>where N s i,j and N o i,j are the frequencies of words i and j having the same or opposite sentiments re- spectively according to the syntactic rules, and α 1 is a positive smoothing factor. If two words have much higher frequency of sharing the same senti- ment than opposite sentiments, then they will have a larger positive sentiment similarity score. Note that S r i,j can be negative according to Eq. (1). Here we focus on sentiment similarity rather than dissi- milarity, and set all the negative values in S r to zero. The range of S r i,j is [0, 1]. The second type of sentiment similarities are extracted according to the co-occurrence patterns among words. It is inspired by the observation that words frequently co-occurring with each ot- her not only have a high probability to have simi- lar semantics, but also tend to share similar senti- ments <ref type="bibr" target="#b32">(Turney, 2002;</ref><ref type="bibr" target="#b33">Velikovich et al., 2010;</ref><ref type="bibr" target="#b40">Yogatama and Smith, 2014;</ref><ref type="bibr" target="#b28">Tang et al., 2015;</ref><ref type="bibr" target="#b11">Hamilton et al., 2016)</ref>. In this paper, we compute the co-occurrence between words in the context of do- cument. Denote D as the set of all documents, and N i d as the frequency of word i appearing in docu- ment d. Then, the sentiment similarity score bet- ween words i and j based on their co-occurrence patterns is defined as:</p><formula xml:id="formula_1">S c i,j = d∈D min{N i d , N j d } d∈D max{N i d , N j d } + α2 ,<label>(2)</label></formula><p>where α 2 is a positive smoothing parameter. If two words frequently co-occur with each other in many documents, then they will have a high sen- timent similarity score according to Eq. (2). The range of S c i,j is also <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. Denote S c ∈ R D×D as the set of all sentiment similarities extracted ac- cording to co-occurrence patterns.</p><p>The sentiment similarities extracted according to syntactic rules are usually of high accuracy. However, their coverage is limited, because the word pairs detected by these syntactic rules are sparse. In contrast, the coverage of sentiment si- milarities extracted from co-occurrence patterns is quite wide because document is a long context, while their accuracies are not as high as the simi- larities based on syntactic rules. Thus, we pro- pose to combine these two types of sentiment si- milarities to obtain a balance between accuracy and coverage. Denote S ∈ R D×D as the final sentiment similarities among words, and S i,j = θS r i,j + (1 − θ)S c i,j , where θ ∈ [0, 1] is the combi- nation coefficient. In this paper we set θ to 0.5, which means that we regard these two types of sentiment similarities as equally important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Initial Sentiment Classifier Construction</head><p>In this section, we introduce the construction of the initial sentiment classifier to start the active le- arning process. Existing active learning methods usually randomly select a set of unlabeled sam- ples to annotate and then train the initial classifier on them <ref type="bibr" target="#b27">(Settles, 2010)</ref>. However, these randomly selected samples may be redundant and not infor- mative enough. In this paper, we propose to build the initial sentiment classifier by adapting the ge- neral sentiment information to target domain via domain-specific sentiment similarities as follows:</p><formula xml:id="formula_2">w0 = arg min w − D i=1 piwi + α D i=1 j =i Si,j(wi − wj) 2 ,<label>(3)</label></formula><p>where w 0 ∈ R D×1 is the initial sentiment clas- sifier, α is a positive regularization coefficient, p i is the prior sentiment polarity of word i in sen- timent lexicons, and S i,j is the sentiment simila- rity score between words i and j. Eq. (3) is mo- tivated by <ref type="bibr" target="#b0">(Bengio et al., 2006</ref>), and the quadratic cost criterion is equivalent to label propagation. In Eq. (3), − D i=1 p i w i means that if a word i is la- beled as a positive (or negative) word in a general- purpose sentiment lexicon, i.e., p i &gt; 0 (or p i &lt; 0), then we constrain that its sentiment weight in the sentiment classifier is also positive (or negative). Otherwise, a penalty will be added to the objective function. In addition, D i=1 j =i S i,j (w i − w j ) 2 represents that if two words share high sentiment similarity, then we constrain they have similar sen- timent weights in sentiment classifier. For exam- ple, if we find that "great" and "easy" have high sentiment similarities in Kitchen appliances dom- ain (e.g., "This is a great pan and easy to wash"), and "great" is a positive sentiment word in many sentiment lexicons, then we can infer that "easy" may also be a positive sentiment word in this dom- ain by propagating the sentiment information from "great" to "easy". In this way, the general senti- ment information can be adapted to many domain- specific sentiment expressions in target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Query Strategy</head><p>Active learning methods iteratively select the most informative instances to label and add them to the training set <ref type="bibr" target="#b27">(Settles, 2010)</ref>. Thus, an important is- sue in these methods is how to measure the infor- mativeness of unlabeled samples. In this paper, we select classification uncertainty as the informative- ness measure, which has been proven effective in many active learning methods ( <ref type="bibr" target="#b41">Zhu et al., 2010;</ref><ref type="bibr" target="#b38">Yang et al., 2015</ref>). Since we focus on binary sentiment classification and the classification loss function is log loss, the classification uncertainty of an unlabeled instance x is defined as:</p><formula xml:id="formula_3">U (x) = 1 − 1 − 2 1 + exp(−w T x) ,<label>(4)</label></formula><p>where w is the linear sentiment classification mo- del. The range of U (x) is <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. If |w T x| is large, which means that current sentiment classifier is confident in classifying this instance, then the un- certainty of x (i.e., U (x)) will be low. If |w T x| is close to 0, then the sentiment classifier is very un- certain about this instance, probably because the sentiment expressions in this instance are not co- vered by current sentiment classifier, and the un- certainty of the instance x will be high. In this case, annotating this instance and adding it to the training set are beneficial, because it can provide the information of unknown sentiment expressions and has the potential to quickly improve the qua- lity of target domain sentiment classifier. However, many researchers have found that un- labeled instances with high uncertainties can be outliers, whose labels are useless and even misle- ading <ref type="bibr" target="#b27">(Settles, 2010;</ref><ref type="bibr" target="#b41">Zhu et al., 2010</ref>). Thus, here we combine uncertainty with representativeness to avoid outliers. Density is proven to be an effective measure of representativeness in active learning methods ( <ref type="bibr" target="#b41">Zhu et al., 2010;</ref><ref type="bibr" target="#b10">Hajmohammadi et al., 2015</ref>). Here we use the k-nearest neighbour based density proposed by <ref type="bibr" target="#b41">Zhu et al. (2010)</ref> as the re- presentativeness measure, which is formulated as:</p><formula xml:id="formula_4">D(x) = 1 k x i ∈N (x) x T xi x2 · xi2 ,<label>(5)</label></formula><p>where N (x) is the set of k most similar instances of x. The final informativeness score of an unlabe- led sample is a linear combination of uncertainty and density which is formulated as follows:</p><formula xml:id="formula_5">I(x) = η(t)U (x) + (1 − η(t))D(x),<label>(6)</label></formula><p>where η(t) ∈ [0, 1] is the combination coeffi- cient at the t th iteration. In this paper, we select a monotonically increasing function for η(t), i.e.,</p><formula xml:id="formula_6">η(t) = 1 1+exp(2− 4t T )</formula><p>, where T is the total number of iterations. It means that at initial iterations we put more emphasis on instances with high repre- sentativeness, because the initial sentiment classi- fier built by adapting the general sentiment infor- mation via the domain-specific sentiment simila- rities is relatively weak, and we prefer to select instances with more popular sentiment expressi- ons to annotate. As more and more labeled sam- ples are added to the training set and the sentiment classifier becomes stronger, we gradually focus on more difficult instances, i.e., those having higher classification uncertainty scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Active Domain Adaptation</head><p>Based on previous discussions, in this section we introduce the complete procedure of our active sentiment domain adaptation (ASDA) approach. Different from existing sentiment domain adapta- tion methods which rely on the sentiment classi- fier trained in source domains to transfer, in our approach we regard the general sentiment infor- mation in sentiment lexicons as the "background" domain and adapt it to target domain with the help of a small number of labeled samples which are selected and annotated in an active learning mode. First, we build an initial sentiment classifier accor- ding to Eq. (3) by adapting the general sentiment information to target domain using the domain- specific sentiment similarities among words mined from unlabeled samples of target domain. Second, we compute the density of each unlabeled sample in U according to <ref type="bibr">Eq. (5)</ref>. Then we repeat fol- lowing steps until the annotation budget has run out. First, we compute the uncertainty of each un- labeled sample in U according to <ref type="bibr">Eq. (4)</ref>, and furt- her we compute their informativeness by combi- ning uncertainty with density according to Eq. (6). Next, we select the unlabeled sample with the hig- hest informativeness from U and manually anno- tate its sentiment polarity. Then we add it to the set of labeled samples L and remove it from U. Af- ter that we retrain the sentiment classifier for tar- get domain based on the general sentiment infor- mation p, the labeled samples L, and the domain-specific sentiment similarities S as follows:</p><formula xml:id="formula_7">arg min w − D i=1 piwi + α D i=1 j =i Si,j(wi − wj) 2 + β x i ∈L log(1 + exp(−yiw T xi)) + λw 2 2 ,<label>(7)</label></formula><p>where α, β, and λ are nonnegative coefficients. By the term − D i=1 p i w i we constrain that the target domain sentiment classifier learned by our approach is consistent with the general sentiment information. Through this way, the general sen- timent information extracted from sentiment lex- icons can be adapted to target domain. The term D i=1 j =i S i,j (w i − w j ) 2 is motivated by label propagation ( <ref type="bibr" target="#b0">Bengio et al., 2006</ref>). If two words tend to have high sentiment similarity with each other according to many unlabeled samples of tar- get domain, then we constrain that their senti- ment weights in the target domain sentiment clas- sifier are also similar. The term x i ∈L log(1 + exp(−y i w T x i )) means that we hope to minimize the empirical classification loss on labeled sam- ples of target domain. By this term the sentiment information in the labeled samples is incorporated into the learning of target domain sentiment clas- sifier. The L 2 -norm regularization term is introdu- ced to control model complexity. The sentiment classifier trained in Eq. <ref type="formula" target="#formula_7">(7)</ref> is further used at the next iteration of active sentiment domain adapta- tion until all the budget of manual annotation has been used. Then we obtain the final sentiment classifier of target domain. The complete algo- rithm of our active sentiment domain adaptation (ASDA) approach is summarized in Algorithm 1.</p><p>Algorithm 1 Active sentiment domain adaptation.</p><p>1: Input: The set of unlabeled samples U, the general sen- timent information p, the domain-specific sentiment si- milarities S, and the total annotation budget N . 2: Output: Target domain sentiment classifier w. 3: Train the initial sentiment classifier w0 (Eq. (3)). 4: Compute the density of each sample xi in U (Eq. (5)). 5: Initialize the set of labeled samples L = ∅, the iteration number t = 0, and the sentiment classifier w = w0. 6: while t &lt; N do 7: t = t + 1. 8:</p><p>Compute the uncertainty score of each sample xi in U (Eq. (4)). 9:</p><p>Compute the informativeness score of each sample xi in U (Eq. (6)). 10: Select x * from U which has the highest informati- veness score. 11:</p><p>Annotate x * and obtain its sentiment label y. 12:</p><formula xml:id="formula_8">L = L + {x * , y}, U = U − x * . 13:</formula><p>Update sentiment classifier w according to Eq. (7). 14: end while 4 Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>The dataset used in our experiments is the Amazon product review dataset 1 collected by <ref type="bibr" target="#b1">Blitzer et al. (2007)</ref>, which is widely used in sentiment analysis and domain adaptation research ( <ref type="bibr" target="#b2">Bollegala et al., 2011</ref>). This dataset contains pro- duct reviews in four domains, i.e., Book, DVD, Electronics, and Kitchen appliances. In each dom- ain, 1,000 positive and 1,000 negative reviews as well as a large number of unlabeled samples are included. The detailed statistics of this dataset are summarized in <ref type="table" target="#tab_1">Table 1</ref>  Following many previous works <ref type="bibr" target="#b1">(Blitzer et al., 2007;</ref><ref type="bibr" target="#b2">Bollegala et al., 2011</ref>), unigrams and bi- grams were used to build feature vectors in our experiments. We randomly split the labeled sam- ples in each domain into two parts with equal size. The first part was used as test data, and the second part was used as the pool of "unlabeled" samples to perform active learning. The general sentiment information was extracted from Bing Liu's senti- ment lexicon 2 ( <ref type="bibr" target="#b14">Hu and Liu, 2004</ref>), which is one of the state-of-the-art general-purpose sentiment lex- icons. The domain-specific sentiment similarities among words were extracted from the large-scale unlabeled samples. The total number of samples actively selected by our approach to annotate was set to 100. The values of α, β, and λ were set to 0.1, 1, and 1 respectively. We repeated each ex- periment 10 times independently and the average results were reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Algorithm Effectiveness</head><p>First we conducted several experiments to explore the effectiveness of our active sentiment domain adaptation (ASDA) approach. We hope to answer two questions via these experiments: 1) whether the domain-specific sentiment similarities among words mined from unlabeled samples of target domain are useful for adapting the general senti- ment information to target domain; 2) whether a small number of samples which are actively se- lected and annotated in target domain can help improve the domain adaptation performance. In our experiments, we implemented different versi- ons of our ASDA approach using different combi- nations of sentiment information. The first one is Lexicon, which means only using the general sen- timent information and no domain adaptation is conducted. It serves as a baseline. The second one is Lexicon+SentiSim, which means adapting gene- ral sentiment information to target domain using domain-specific sentiment similarities, but labe- led samples of target domain are not incorporated. The third one is Lexicon+SentiSim+Label, which is the complete ASDA approach. The experimental results are summarized in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>According to <ref type="figure" target="#fig_0">Fig. 1</ref>, the performance of Lexicon is suboptimal. This is because the general senti- ment lexicons cannot capture the domain-specific sentiment expressions in target domain <ref type="bibr" target="#b5">(Choi and Cardie, 2009)</ref>. Lexicon+SentiSim performs signi- ficantly better than Lexicon, which validates that the sentiment similarities among words extracted from unlabeled samples of target domain contain rich domain-specific sentiment information, and can help propagate the general sentiment informa- tion to many domain-specific sentiment expressi- ons. Besides, after incorporating a small number of labeled samples which are actively selected and annotated by our approach in an active learning mode, the performance of our sentiment dom- ain adaptation approach is significantly improved. This is because although these labeled samples are in limited size and cannot cover all the sentiment expressions in target domain, they can provide sentiment information of popular domain-specific sentiment expressions, which can be propagated to other sentiment expressions in target domain du- ring the domain adaptation process. Thus, above experimental results validate the effectiveness of our approach.</p><p>We also conducted several experiments to ve- rify the advantage of the actively selected samples over randomly selected samples and validate the effectiveness of our active learning algorithm. We also compared the dynamic weighting scheme for combining uncertainty and density with the con- stant weighting scheme. The experimental results are summarized in <ref type="figure" target="#fig_1">Fig. 2</ref>. According to <ref type="figure" target="#fig_1">Fig. 2</ref>, our approach with actively selected samples performs better than that with randomly selected samples. It indicates that these actively selected samples are more informative than randomly selected samples for sentiment domain adaptation. In addition, our approach with dynamic weighting scheme in com- bining uncertainty and density outperforms that with constant weighting scheme, which implies that it is beneficial to emphasize representative samples at initial iterations and gradually focus on difficult samples at later iterations. Thus, the ex- perimental results validate the effectiveness of our active learning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Evaluation</head><p>In this section we conducted experiments to eva- luate the performance of our approach by compa- ring it with several baseline methods. The met- hods to be compared include: 1) MPQA and Bing- Liu, using two state-of-the-art sentiment lexicons, i.e., MPQA <ref type="bibr" target="#b34">(Wilson et al., 2005</ref>) and Bing Liu's lexicon ( <ref type="bibr" target="#b14">Hu and Liu, 2004</ref>) for sentiment clas- sification following the suggestions in ( <ref type="bibr" target="#b14">Hu and Liu, 2004</ref>); 2) SVM, LS, and LR, three popular supervised sentiment classification methods, i.e., support vector machine ( <ref type="bibr" target="#b25">Pang et al., 2002</ref>), le- ast squares ( <ref type="bibr" target="#b15">Hu et al., 2013</ref>) and logistic regres- sion ( <ref type="bibr" target="#b36">Wu et al., 2015</ref>); 3) ZIAL, the zero initiali- zed active learning method <ref type="bibr" target="#b3">(Cesa-Bianchi et al., 2006</ref>); 4) LIAL, the active learning method ini- tialized by randomly selected labeled data <ref type="bibr" target="#b27">(Settles, 2010)</ref>; 5) SCL and SFA, two famous sentiment domain adaptation methods proposed in <ref type="bibr" target="#b1">(Blitzer et al., 2007)</ref> and  respectively; 6) ILP, adapting sentiment lexicons to target domain via integer linear programming <ref type="bibr" target="#b5">(Choi and Cardie, 2009)</ref>; 7) AODA, the active online domain adapta- tion method <ref type="bibr" target="#b26">(Rai et al., 2010</ref>); 8) ALCD, the active learning method for cross-domain sentiment clas- sification ( ); 9) ASDA, our active sentiment domain adaptation approach. For above methods, if labeled target domain samples are nee- ded in training, the number of labeled samples was set to 100, and if source domain labeled samples are needed in training, the number of labeled sam- ples was set to 1,000. The parameters in baseline methods were tuned via cross-validation. The ex- perimental results are summarized in <ref type="table" target="#tab_2">Table 2</ref>.  According to <ref type="table" target="#tab_2">Table 2</ref>, the performance of di- rectly applying sentiment lexicons to target dom- ain is suboptimal. This is because there are many domain-specific sentiment expressions that are not covered by these general-purpose sentiment lex- icons ( <ref type="bibr" target="#b5">Choi and Cardie, 2009)</ref>. In addition, the performance of supervised sentiment classifica- tion methods such as SVM, LS, and LR is also limited, because the labeled samples for training are extremely scarce. The active learning met- hods such as ZIAL ( <ref type="bibr" target="#b3">Cesa-Bianchi et al., 2006</ref>) and LIAL (Settles, 2010) perform relatively better, be- cause they can actively select informative samples to annotate and learn. Our approach can outper- form both of them. This is because besides the labeled samples, our approach also adapts the ge- neral sentiment information in sentiment lexicons to target domain and incorporates it into the le- arning of target domain sentiment classifier. Our approach also performs better than state-of-the-art domain adaptation methods such as SCL ( <ref type="bibr" target="#b1">Blitzer et al., 2007</ref>) and SFA ( . It im- plies that a small number of actively selected la- beled samples from target domain are beneficial for sentiment domain adaptation. ILP <ref type="bibr" target="#b5">(Choi and Cardie, 2009</ref>) tries to adapt a sentiment lexicon to target domain, which is similar with our ap- proach. ILP relies on labeled samples to extract the relations among words and relations between words and sentiment expressions. However, labe- led samples in target domain are usually limited and the sentiment information in many unlabeled samples is not exploited in ILP. Thus, our appro- ach can outperform it. Similar with our approach, AODA <ref type="bibr" target="#b26">(Rai et al., 2010</ref>) and ALCD (  also apply active learning to domain adaptation. The major difference is that in our approach the general sentiment information extracted from sen- timent lexicons is adapted to target domain, while in AODA and ALCD the sentiment classifier trai- ned in source domains is transferred. The superior performance of our approach implies that the ge- neral sentiment information has better generaliza- tion ability than the sentiment classifier trained in a specific source domain, and is more suitable for sentiment domain adaptation.  We further conducted several experiments to validate the advantage of our approach in trai- ning accurate sentiment classifier for target dom- ain with only a few labeled samples. We varied the annotation budget, i.e., the number of labeled sam- ples, from 100 to 1,000. The learning curve of our ASDA approach in Book domain is shown in <ref type="figure" target="#fig_3">Fig. 3</ref>. We also included a purely supervised sentiment classification method, i.e., SVM, in <ref type="figure" target="#fig_3">Fig. 3</ref> as a ba- seline for comparison. <ref type="figure" target="#fig_3">Fig. 3</ref> shows that our ASDA approach can consistently outperform SVM when the same number of labeled samples are used. The performance advantage of our approach is more significant when labeled samples are scarce. For example, the performance of our approach with only 200 labeled samples is similar to SVM with more than 800 labeled samples. Thus, the expe- rimental results validate that by adapting the ge- neral sentiment information to target domain and selecting the most informative samples to annotate and learn, our approach can effectively reduce the manual annotation effort, and can train accurate sentiment classifier for target domain with much less labeled samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Analysis</head><p>In this section, we conducted several experiments to explore the influence of parameter settings on the performance of our approach. α and β are the two most important parameters in our approach, which control the relative importance of domain- specific sentiment similarities and the actively se- lected samples in training sentiment classifier for target domain. The experimental results of para- meters α and β are summarized in <ref type="figure" target="#fig_4">Fig. 4</ref>.</p><p>According to <ref type="figure" target="#fig_4">Fig. 4</ref>, when α and β are too small, the performance of our approach is not op- timal. This is because the useful sentiment infor- mation in domain-specific sentiment similarities mined from unlabeled samples and the actively selected labeled samples of target domain is not fully exploited. Thus, the performance of our ap- proach improves when these parameters increase from a small value. However, when these para- meters become too large, the performance of our approach starts to decline. This is because when β is too large the sentiment classifier learned by our approach is mainly decided by the limited la- beled samples, and the general sentiment informa- tion extracted from sentiment lexicons is not fully exploited. When α is too large, the information in domain-specific sentiment similarities is over- emphasized, and many different words will have nearly the same sentiment weights. Thus, the per- formance of our approach in these scenarios is also not optimal. A moderate value of α and β is most suitable for our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we present an active sentiment dom- ain adaptation approach to train accurate senti- ment classifier for target domain with less labe- led samples. In our approach, the general senti- ment information in sentiment lexicons is adapted to target domain with the help of a small number of labeled samples which are selected and anno- tated in an active learning mode. Both classifica- tion uncertainty and density are considered when selecting informative samples to label. In addi- tion, we extract domain-specific sentiment simila- rities among words from unlabeled samples of tar- get domain based on both syntactic rules and co- occurrence patterns, and incorporate them into the domain adaptation process to propagate the gene- ral sentiment information to many domain-specific sentiment words in target domain. We also pro- pose a unified model to incorporate different types of sentiment information to train sentiment clas- sifier for target domain. Experimental results on benchmark datasets show that our approach can train accurate sentiment classifier and at same time reduce the manual annotation effort.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The performance of our approach with different combinations of sentiment information. Lexicon, SentiSim, and Label represent the general-purpose sentiment lexicon, the domainspecific sentiment similarities among words, and a small number of actively selected and annotated samples in target domain respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The performance of our approach with labeled samples selected by different strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>6543 0.6542 0.6692 0.6687 0.7194 0.7185 0.7479 0.7465 LR 0.6606 0.6582 0.6774 0.6742 0.7257 0.7226 0.7492 0.7480 RIAL 0.6693 0.6663 0.6850 0.6821 0.7310 0.7299 0.7574 0.7568 LIAL 0.6756 0.6731 0.6866 0.6838 0.7374 0.7360 0.7599 0.7595 SCL 0.7233 0.7201 0.7469 0.7438 0.7768 0.7730 0.8099 0.8095 SFA 0.7307 0.7285 0.7513 0.7485 0.7846 0.7812 0.8174 0.8153 ILP 0.6942 0.6931 0.7153 0.7124 0.7463 0.7445 0.7793 0.7768 AODA 0.6928 0.6912 0.7172 0.7165 0.7518 0.7512 0.7698 0.7690 ALCD 0.7237 0.7221 0.7369 0.7364 0.7768 0.7788 0.7979 0.7970 ASDA 0.7508 0.7501 0.7764 0.7759 0.8014 0.8011 0.8329 0.8328</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The performance of ASDA and SVM with different numbers of labeled samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The influence of the parameter settings of α and β on the performance of our approach.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>.</head><label></label><figDesc></figDesc><table>Book 
DVD 
Electronics Kitchen 
positive 
1,000 
1,000 
1,000 
1,000 
negative 
1,000 
1,000 
1,000 
1,000 
unlabeled 973,194 122,438 
21,009 
17,856 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>The statistics of the Amazon dataset.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Sentiment classification performance of 
different methods in different domains. Acc and 
Fscore represent accuracy and macro-averaged 
Fscore respectively. 

</table></figure>

			<note place="foot" n="1"> https://www.cs.jhu.edu/ ˜ mdredze/ datasets/sentiment/ 2 https://www.cs.uic.edu/liub/FBS/ sentiment-analysis.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is supported by the Key Research Project of the Ministry of Science and Technology of China (Grant no. 2016YFB0800402) and the Key Program of National Natural Science Founda-tion of China (Grant nos. U1536201, U1536207, and U1405254).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Label propagation and quadratic criterion. Semi-supervised learning 10</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology-new/P/P07/P07-1056" />
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using multiple sources to construct a sentiment sensitive thesaurus for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P11-1014" />
	</analytic>
	<monogr>
		<title level="m">ACL:HLT. pages</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Worst-case analysis of selective sampling for linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolo</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Gentile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Zaniboni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1205" to="1230" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Co-training for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2456" to="2464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="590" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Selective sampling using the query by committee algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="133" to="168" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="doi">10.1023/A:1007330508534</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1007330508534" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A survey on instance selection for active learning. Knowledge and Information Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingquan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<idno type="doi">10.1007/s10115-012-0507-8</idno>
		<ptr target="https://doi.org/10.1007/s10115-012-0507-8" />
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="249" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combination of active learning and self-training for cross-lingual sentiment classification with density analysis of unlabelled samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sadegh Hajmohammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roliana</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Selamat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamido</forename><surname>Fujita</surname></persName>
		</author>
		<idno type="doi">10.1016/j.ins.2015.04.003</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ins.2015.04.003" />
	</analytic>
	<monogr>
		<title level="j">Information sciences</title>
		<imprint>
			<biblScope unit="volume">317</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inducing domain-specific sentiment lexicons from unlabeled corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="595" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting the semantic orientation of adjectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kathleen R Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automatically extracting polarity-bearing topics for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harith</forename><surname>Alani</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P11-1013" />
	</analytic>
	<monogr>
		<title level="m">ACL:HLT. pages</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="doi">10.1145/1014052.1014073</idno>
		<ptr target="http://doi.acm.org/10.1145/1014052.1014073" />
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploiting social relations for sentiment analysis in microblogging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<idno type="doi">10.1145/2433396.2433465</idno>
		<ptr target="http://doi.acm.org/10.1145/2433396.2433465" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Automatic construction of domain-specific sentiment lexicon based on constrained label propagation. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhendong</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Shi</surname></persName>
		</author>
		<idno type="doi">10.1016/j.knosys.2013.11.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.knosys.2013.11.009" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-domain active learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<idno type="doi">10.1145/2339530.2339701</idno>
		<ptr target="http://doi.acm.org/10.1145/2339530.2339701" />
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1086" to="1094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Active learning for cross-domain sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoushan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxia</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2127" to="2133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Crossdomain sentiment classification via spectral feature alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochuan</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW. ACM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<idno type="doi">10.1145/1772690.1772767</idno>
		<ptr target="http://doi.acm.org/10.1145/1772690.1772767" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
		<idno type="doi">10.1109/TKDE.2009.191</idno>
		<ptr target="http://dx.doi.org/10.1109/TKDE.2009.191" />
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno type="doi">10.1561/1500000011</idno>
		<ptr target="http://dx.doi.org/10.1561/1500000011" />
	</analytic>
	<monogr>
		<title level="j">Foundations and trends in information retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
		<idno type="doi">10.3115/1118693.1118704</idno>
		<ptr target="https://doi.org/10.3115/1118693.1118704" />
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain adaptation meets active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W10-0104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing</title>
		<meeting>the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">11</biblScope>
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pte: Predictive text embedding through large-scale heterogeneous text networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD. ACM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1165" to="1174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<idno type="doi">10.1145/2783258.2783307</idno>
		<ptr target="http://doi.acm.org/10.1145/2783258.2783307" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Support vector machine active learning with applications to text classification. The Journal of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<idno type="doi">10.1162/153244302760185243</idno>
		<ptr target="http://dx.doi.org/10.1162/153244302760185243" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter D Turney</surname></persName>
		</author>
		<idno type="doi">10.3115/1073083.1073153</idno>
		<ptr target="http://dx.doi.org/10.3115/1073083.1073153" />
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The viability of web-derived polarity lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Velikovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Blair-Goldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerry</forename><surname>Hannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N10-1119" />
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="777" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity in phraselevel sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hoffmann</surname></persName>
		</author>
		<idno type="doi">10.3115/1220575.1220619</idno>
		<ptr target="http://dx.doi.org/10.3115/1220575.1220619" />
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="347" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sentiment domain adaptation with multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P16-1029" />
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="301" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Microblog sentiment classification with contextual knowledge regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2332" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sentiment domain adaptation with multi-level contextual sentiment knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangzhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Huang</surname></persName>
		</author>
		<idno type="doi">10.1145/2983323.2983851</idno>
		<ptr target="https://doi.org/10.1145/2983323.2983851" />
	</analytic>
	<monogr>
		<title level="m">CIKM. ACM</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="949" to="958" />
		</imprint>
	</monogr>
	<note>Songfang Huang, and Yong Qin</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multi-class active learning by uncertainty sampling with diversity maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiping</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="127" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<idno type="doi">10.1007/s11263-014-0781-x</idno>
		<ptr target="http://dx.doi.org/10.1007/s11263-014-0781-x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Making the most of bag of words: Sentence regularization with alternating direction method of multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="656" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Active learning with sampling by uncertainty and density for data annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Tsou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1323" to="1331" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<idno type="doi">10.1109/TASL.2009.2033421</idno>
		<ptr target="http://dx.doi.org/10.1109/TASL.2009.2033421" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
