<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiple Many-to-Many Sequence Alignment for Combining String-Valued Variables: A G2P Experiment</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
							<email>steeger@em.uni-frankfurt.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Text Technology Lab Goethe University Frankfurt am Main Frankfurt am Main</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiple Many-to-Many Sequence Alignment for Combining String-Valued Variables: A G2P Experiment</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="909" to="919"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate multiple many-to-many alignments as a primary step in integrating supplemental information strings in string transduction. Besides outlining DP based solutions to the multiple alignment problem, we detail an approximation of the problem in terms of multiple sequence segmentations satisfying a coupling constraint. We apply our approach to boosting baseline G2P systems using homogeneous as well as heterogeneous sources of supplemental information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>String-to-string translation (string transduction) is the problem of converting one string x over an alphabet Σ into another string y over a possi- bly different alphabet Γ. The most prominent applications of string-to-string translation in nat- ural language processing (NLP) are grapheme- to-phoneme conversion, in which x is a letter- string and y is a string of phonemes, translit- eration ( , lemmatiza- tion ( <ref type="bibr" target="#b11">Dreyer et al., 2008)</ref>, and spelling error cor- rection <ref type="bibr" target="#b6">(Brill and Moore, 2000</ref>). The classi- cal learning paradigm in each of these settings is to train a model on pairs of strings {(x, y)} and then to evaluate model performance on test data. Thereby, all state-of-the-art modelings we are aware of (e.g., <ref type="bibr" target="#b17">(Jiampojamarn et al., 2007;</ref><ref type="bibr" target="#b5">Bisani and Ney, 2008;</ref><ref type="bibr" target="#b19">Jiampojamarn et al., 2008;</ref><ref type="bibr" target="#b20">Jiampojamarn et al., 2010;</ref><ref type="bibr" target="#b30">Novak et al., 2012)</ref>) proceed by first aligning the string pairs (x, y) in the training data. Also, these modelings ac- knowledge that alignments may typically be of a rather complex nature in which several x sequence ph oe n i x f i n I ks <ref type="table">Table 1</ref>: Sample monotone many-to-many align- ment between x = phoenix and y = finIks.</p><p>characters may be matched up with several y se- quence characters; <ref type="table">Table 1</ref> illustrates. Once the training data is aligned, since x and y sequences are then segmented into equal number of seg- ments, string-to-string translation may be seen as a sequence labeling (tagging) problem in which x (sub-)sequence characters are observed variables and y (sub-)sequence characters are hidden states <ref type="bibr" target="#b17">(Jiampojamarn et al., 2007;</ref><ref type="bibr" target="#b20">Jiampojamarn et al., 2010)</ref>. In this work, we extend the problem of classi- cal string-to-string translation by assuming that, at training time, we have available (M + 2)-tuples of strings {(x, ˆ y (1) , . . . , ˆ y (M ) , y)}, where x is the input string, ˆ y (m) , for 1 ≤ m ≤ M , are sup- plemental information strings, and y is the de- sired output string; at test time, we wish to pre- dict y from (x, ˆ y (1) , . . . , ˆ y <ref type="bibr">(M )</ref> ). Generally, we may think ofˆyofˆ ofˆy <ref type="bibr">(1)</ref> , . . . , ˆ y (M ) as arbitrary strings over arbitrary alphabets Σ (m) , for 1 ≤ m ≤ M . For example, x might be a letter-string andˆyandˆ andˆy (m) might be a transliteration of x in language L m (cf. <ref type="bibr" target="#b4">Bhargava and Kondrak (2012)</ref>). Alternatively, and this is our model scenario in the current work, x might be a letter input string andˆyandˆ andˆy (m) might be the predicted string of phonemes, given x, pro- duced by an (offline) system T m . This situation is outlined in <ref type="table">Table 3</ref>. In the table, we also illus- trate a multiple (monotone) many-to-many align- ment of (x, ˆ y (1) , . . . , ˆ y (M ) , y). By this, we mean an alignment where (1) subsequences of all M + 2 strings may be matched up with each other (many-to-many alignments), and where (2) the match- ing up of subsequences obeys monotonicity. Note that such a multiple alignment generalizes classi- cal monotone many-to-many alignments between pairs of strings, as shown in <ref type="table">Table 1</ref>. Furthermore, such an alignment may apparently be quite useful. For instance, while none of the stringsˆystringsˆ stringsˆy (m) in the table equals the true phonetic transcription y of x, taking a position-wise majority vote of the multi- ple alignment of (ˆ y (1) , . . . , ˆ y (M ) ) yields y. More- over, analogously as in the case of pairs of aligned strings, we may perceive the so extended string- to-string translation problem as a sequence label- ing task once (x, ˆ y (1) , . . . , ˆ y (M ) , y) are multiply aligned, but now, with additional observed vari- ables (or features), namely, (sub-)sequence char- acters of each stringˆystringˆ stringˆy <ref type="bibr">(m)</ref> .</p><p>To further motivate our approach, consider the situation of training a new G2P system on the ba- sis of, e.g., <ref type="bibr">Combilex (Richmond et al., 2009</ref>). For each letter form in its database, Combilex provides a corresponding phonetic transcription. Now, suppose that, in addition, we can poll an external knowledge source such as Wiktionary for (its) phonetic transcriptions of the respective Com- bilex letter words as outlined in  tral question we want to answer is: can we train a system using this additional information which performs better than the 'baseline' system that ig- nores the extra information? Clearly, a system with more information should not perform worse than a system with less information (unless the ad- ditional information is highly noisy), but it is a priori not clear at all how the extra information can be included, as <ref type="bibr" target="#b4">Bhargava and Kondrak (2012)</ref> note: output predictions may be in distinct alpha- bets and/or follow different conventions, and sim- ple rule-based conversions may even deteriorate a baseline system's performance. Their solution to the problem is to let the baseline system out- put its n-best phonetic transcriptions, and then to re-rank these n-best predictions via an SVM re- ranker trained on the supplemental representations x = schizo s ch i z o ˆ y (1) = skaIz@U s k aI z @Uˆy @Uˆ @Uˆy (2) = saIz@U s -aI z @Uˆy @Uˆ @Uˆy (3) = skIts@ s k I ts @ ˆ y (4) = Sits@U S - i ts @Uˆy @Uˆ @Uˆy (5) = skIts@ s k I ts @ y = skIts@U s k I ts @U <ref type="table">Table 3</ref>: Left: Input string x, predictions of 5 systems, and output string y. Right: A multiple many-to-many alignment of (x, ˆ y (1) , . . . , ˆ y (5) , y). Skips are marked by a dash ('-').</p><p>(see their <ref type="figure">figure 2</ref>). Our approach is much differ- ent from this: we character (or substring) align the supplemental information strings with the in- put letter strings and then sequentially transduce input character substrings as in the standard G2P approach, but where the sequential transducer is aware of the corresponding subsequences of the supplemental information strings.</p><p>Our goals in the current work are first, in Sec- tion 2, to formally introduce the multiple many- to-many alignment problem, which, to our knowl- edge, has not yet been formally considered, and to indicate how it can be solved (by standard ex- tensions of well-known DP recursions). Secondly, we outline an 'approximation algorithm', also in Section 2, with much better runtime complexity, to solving the multiple many-to-many alignment problem. This proceeds by optimally segmenting individual strings to align under the global con- straint that the number of segments must agree across strings. Thirdly, we demonstrate exper- imentally, in Section 5, that multiple many-to- many alignments may be an extremely useful first step in boosting the performance of a G2P model. In particular, we show that by conjoining a base system with additional systems very high perfor- mance increases can be achieved. We also inves- tigate the effects of using our introduced approxi- mation algorithm instead of 'exactly' determining alignments. We discuss related work in Section 3, present data and systems in Section 4 and con- clude in Section 6.</p><p>2 Mult. Many-to-Many Alignm. Models</p><p>We now formally define the problem of multiply aligning several strings in a monotone and many- to-many alignment manner. For notational conve- nience, in this section, let the N strings to align be denoted by w 1 , . . . , w N (rather than x, ˆ y (m) , y, etc.). Let each w n , for 1 ≤ n ≤ N , be an arbitrary string over some alphabet Σ (n) . Let n = |w n | de- note the length of w n . Moreover, assume that a set S ⊆ N n=1 {0, . . . , n }\{0 N } of allowable steps is specified, where 0 N = (0, . . . , 0 N times ). <ref type="bibr">1</ref> We interpret the elements of S as follows: if (s 1 , s 2 , . . . , s N ) ∈ S, then subsequences of w 1 of length s 1 , subse- quences of w 2 of length s 2 , . . ., subsequences of w N of length s N may be matched up with each other. In other words, S defines the types of valid 'many-to-many match-up operations'. <ref type="bibr">2</ref> While we could drop S from consideration and simply al- low every possible matching up of character sub- sequences, it is convenient to introduce S because algorithmic complexity may then be specified in terms of S, and by choosing particular S, one may retrieve special cases otherwise considered in the literature (see next section).</p><p>As indicated, for us, a multiple alignment of (w 1 , . . . , w N ) is any scheme</p><formula xml:id="formula_0">w 1,1 w 1,2 · · · w 1,k w 2,1 w 2,2 · · · w 2,k . . . . . . . . . . . . w N,1 w N,2 · · · w N,k</formula><p>such that (|w 1,i | , . . . , |w N,i |) ∈ S, for all i = 1, . . . , k, and such that w n = w n,1 · · · w n,k , for all 1 ≤ n ≤ N . Let A S = A S (w 1 , . . . , w N ) denote the set of all multiple alignments of (w 1 , . . . , w N ). For an alignment a ∈ A S , de- note by score(a) = f (a) the score of align- ment a under alignment model f , where f :</p><formula xml:id="formula_1">A S (w 1 , . . . , w N ) → R.</formula><p>We now investigate solu- tions to the problem of finding the alignment with maximal score under different choices of align- ment models f , i.e., we search to efficiently solve</p><formula xml:id="formula_2">max a∈A S (w 1 ,...,w N ) f (a).<label>(1)</label></formula><p>Unigram alignment model For our first align- ment model f , we assume that f (a), for a ∈ A S , is the score</p><formula xml:id="formula_3">f (a) = k i=1 sim 1 (w 1,i , . . . , w N,i )<label>(2)</label></formula><p>1 Here, denotes the Cartesian product of sets. <ref type="bibr">2</ref> In the case of two strings, this is sometimes denoted in the manner M -N (e.g., 3-2, 1-0), indicating that M charac- ters of one string may be matched up with N characters of the other string. Analogously, we could write here s1-s2-s3-· · · . for a real-valued similarity function sim 1 : N n=1 Σ (n) * → R. We call the model f in (2) a unigram model because f (a) is the sum of the similarity scores of the matched-up subse- quences (w 1,i , . . . , w N,i ), ignoring context. Due to this independence assumption, solving max- imization problem in Eq. <ref type="formula" target="#formula_2">(1)</ref> under specifica- tion <ref type="formula" target="#formula_3">(2)</ref> is straightforward via a dynamic pro- gramming (DP) recursion. To do so, define by M S,sim 1 (i 1 , i 2 , . . . , i N ) the score of the best align- ment, under alignment model f = sim 1 and set of steps S, of (w 1 (1 :</p><formula xml:id="formula_4">i 1 ), . . . , w N (1 : i N )). 3 Then, M S,sim 1 (i 1 , . . . , i N ) is equal to max (j 1 ,...,j N )∈S M S,sim 1 (i1 − j1, . . . , iN − jN ) + sim1 w(i1 − j1 + 1 : i1), . . . , w(iN − jN + 1 : jN ) . (3)</formula><p>This recurrence directly leads to a DP algorithm, shown in Algorithm 1, for computing the score of the best alignment of (w 1 , . . . , w N ); the ac- tual alignment can be found by storing pointers to the maximizing steps taken. If similarity evalua- tions sim 1 (w 1,i , . . . , w N,i ) are thought of as tak- ing constant time, this algorithm's run time is O( N n=1 n · |S|). When = 1 = · · · = n and |S| = N − 1 ('worst case' size of S), then the al- gorithm's runtime is thus O( 2N ), which quickly becomes untractable as N , the number of strings to align, increases.</p><p>Of course, the unigram alignment model could be generalized to an m-gram alignment model. An m-gram alignment model would exhibit worst- case runtime complexity of O( (m+1)N ) under analogous DP recursions as for the unigram model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1</head><p>1: procedure UNIGRAM-ALIGN(w 1 , . . . , w N ; S, sim 1 )</p><p>2:</p><formula xml:id="formula_5">M (i 1 , . . . , i N ) ← −∞ for all (i 1 , . . . , i N ) ∈ Z N 3: M (0 N ) ← 0 4: for i 1 = 0 . . . 1 do 5:</formula><p>for · · · do 6:</p><formula xml:id="formula_6">for i N = 0 . . . N do 7: if (i 1 , . . . , i N ) = 0 N then 8: M (i1, . . . , iN ) ← Eq. (3) 9: return M ( 1 , . . . , N )</formula><p>Separable alignment models For our sec- ond model class, assume that, for any a ∈</p><formula xml:id="formula_7">A S (w 1 , . . . , w N ), f (a) decomposes into f (a) = Ψ fw 1 (w1,1 · · · w 1,k ), . . . , fw N (wN,1 · · · w N,k )<label>(4)</label></formula><p>for some models f w 1 , . . . , f w N and where Ψ :</p><formula xml:id="formula_8">R N → R is non-decreasing in its arguments (e.g., Ψ(f w 1 , . . . , f w N ) = N n=1 f wn ).</formula><p>If f (a) decom- poses in such a manner, then f (a) is called sep- arable. <ref type="bibr">4</ref> The advantage with separable models is that we can solve the 'subproblems' f w 1 , . . . , f w N independently. Thus, in order to find optimal multiple alignments of (w 1 , . . . , w N ) under such a specification, we would only have to find the best segmentations of sequences w n under mod- els f wn , for 1 ≤ n ≤ N , subject to the constraint that the segmentations must agree in their number of segments (the coupling variable). Let S wn ⊆ {0, 1, . . . , n } denote the constraints on segment lengths, similar to the interpretation of steps in S. If f wn is a unigram segmentation model then the problem of finding the best segmentation of w n with exactly j segments can be solved in time O( n |S wn | j). Thus, if each f wn is a unigram segmentation model, worst-case time complexity for each subproblem would be O( 3 n ) (if string w n can be segmented into at most n segments) and then the overall problem (1) under specifica- tion (4) is solvable in worst-case time N · O( 3 ). More generally, if each f wn is an m-gram seg- mentation model, then worst-case time complexity amounts to N · O( m+2 ). Importantly, this scales linearly with the number N of strings to align, rather than exponentially as the O( (m+1)N ) un- der the (non-separable) m-gram alignment model discussed above.</p><p>Unsupervised alignments The algorithms pre- sented may be applied iteratively in order to in- duce multiple alignments in an unsupervised (EM- like) fashion in which sim 1 is gradually learnt (e.g., starting from a uniform initialization of sim 1 ). We skip details of this, as we do not make us of it in our current experiments. Rather, in our experiments below, we directly specify sim 1 as a sum of pairwise similarity scores which we ex- tract from alignments produced by an off-the-shelf pairwise aligner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>Monotone alignments have a long tradition, both in NLP and bioinformatics.</p><p>The classical Needleman-Wunsch algorithm <ref type="bibr" target="#b28">(Needleman and Wunsch, 1970)</ref> computes the optimal alignment between two sequences when only single charac- ter matches, mismatches, and skips are allowed. It is a special case of the unigram model <ref type="formula" target="#formula_3">(2)</ref> in optimization problem (1) for which N = 2, S = {(1, 0), (0, 1), (1, 1)} and sim 1 takes on val- ues from {0, −1}, depending on whether com- pared input subsequences match or not. As is well-known, this alignment specification is equiv- alent to the edit distance problem <ref type="bibr" target="#b24">(Levenshtein, 1966)</ref> in which the minimal number of inser- tions, deletions and substitutions is sought that transforms one string into another. Substring- to-substring edit operations -or equivalently, (monotone) many-to-many alignments -have ap- peared in the NLP context, e.g., in <ref type="bibr" target="#b10">(Deligne et al., 1995)</ref>, <ref type="bibr" target="#b6">(Brill and Moore, 2000</ref>), <ref type="bibr" target="#b17">(Jiampojamarn et al., 2007)</ref>, <ref type="bibr" target="#b5">(Bisani and Ney, 2008)</ref>, <ref type="bibr" target="#b20">(Jiampojamarn et al., 2010)</ref>, or, significantly earlier, in <ref type="bibr" target="#b36">(Ukkonen, 1985)</ref>, <ref type="bibr">(Véronis, 1988)</ref>. Learning edit distance/monotone alignments in an unsuper- vised manner has been the topic of, e.g., <ref type="bibr" target="#b33">(Ristad and Yianilos, 1998)</ref>, <ref type="bibr" target="#b8">(Cotterell et al., 2014</ref>), besides the works already mentioned. All of these approaches are special cases of our uni- gram model outlined in Section 2 -i.e., they consider particular S (most prominently, S = {(1, 0), (0, 1), (1, 1)}) and/or restrict attention to only N = 2 strings. <ref type="bibr">5</ref> Alignments between multiple sequences, i.e., multiple sequence alignment, has also been an is- sue both in NLP (e.g., <ref type="bibr" target="#b9">Covington (1998)</ref>, <ref type="bibr" target="#b2">Bhargava and Kondrak (2009)</ref>) and bioinformatics (e.g., <ref type="bibr" target="#b12">Durbin et al. (1998)</ref>). An interesting applica- tion of alignments of multiple sequences is to de- termine what has been called median string <ref type="bibr" target="#b22">(Kohonen, 1985)</ref> or Steiner consensus string (Gus- field, 1997), defined as the string ¯ s that minimizes the sum of distances, for a given distance function d(x, y), to a list of strings s 1 , . . . , s N (Jiang et al., 2012); typically, d is the standard edit distance. As Gusfield (1997) shows, the Steiner consen- sus string may be retrieved from a multiple align-ment of s 1 , . . . , s N by concatenating the column- wise majority characters in the alignment, ignor- ing skips. Since median string computation (and hence also the multiple many-to-many alignment problem, as we consider) is an NP-hard problem <ref type="bibr" target="#b35">(Sim and Park, 2003)</ref></p><note type="other">, designing approximations is an active field of research. For example, Marti and Bunke (2001) ignore part of the search space by declaring matches-up of distant characters as un- likely, and Jiang et al. (2012) apply an approxima- tion based on string embeddings in vector spaces. Paul and Eisner (2012) apply dual decomposition to compute Steiner consensus strings. Via the ap- proach taken in this paper, median strings may be computed in case d is a (distance) function tak- ing substring-to-substring edit operations into ac- count, a seemingly straightforward, yet extremely useful generalization in several NLP applications, as indicated in the introduction.</note><p>Our approach may also be seen in the context of classifier combination for string-valued variables. While ensemble methods for structured prediction have been considered in several works (see, e.g., <ref type="bibr" target="#b29">Nguyen and Guo (2007)</ref>, <ref type="bibr" target="#b7">Cortes et al. (2014)</ref>, and references therein), a typical assumption in this situation is that the sequences to be combined have equal length, which clearly cannot be expected to hold when, e.g., the outputs of several G2P, transliteration, etc., systems must be combined. In fact, the multiple many-to-many alignment models investigated in this work could act as a preprocess- ing step in this setup, since the alignment precisely serves the functionality of segmenting the strings into equal number of segments/substructures. Of course, combining outputs with varying number of elements is also an issue in machine transla- tion (e.g., <ref type="bibr" target="#b25">Macherey and Och (2007)</ref>, <ref type="bibr" target="#b16">Heafield et al. (2009)</ref>), but, there, the problem is harder due to the potential non-monotonicities in the ordering of elements, which typically necessitates (additional) heuristics. One approach for constructing multi- ple alignments is here progressive multiple align- ment <ref type="bibr" target="#b14">(Feng and Doolittle, 1987)</ref> in which a multi- ple (typically one-to-one) alignment is iteratively constructed from successive pairwise alignments ( <ref type="bibr" target="#b0">Bangalore et al., 2001</ref>). <ref type="bibr" target="#b27">Matusov et al. (2006)</ref> apply word reordering and subsequent pairwise monotone one-to-one alignments for MT system combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data and systems 4.1 Data</head><p>We conduct experiments on the General Ameri- can (GA) variant of the Combilex data set ( <ref type="bibr" target="#b32">Richmond et al., 2009)</ref>. This contains about 144,000 grapheme-phoneme pairs as exemplarily illus- trated in <ref type="table" target="#tab_0">Table 2</ref>. In our experiments, we split the data into two disjoint parts, one for test- ing (about 28,000 word pairs) and one for train- ing/development (the remainder).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Systems</head><p>BASELINE Our baseline system is a linear-chain conditional random field model (CRF) <ref type="bibr">6 (Lafferty et al., 2001</ref>) which we apply in the manner in- dicated in the introduction: after many-to-many aligning the training data as in <ref type="table">Table 1</ref>, at training time, we use the CRF as a tagging model that is trained to label each input character subsequence with an output character subsequence. As fea- tures for the CRF, we use all n-grams of subse- quences of x that fit inside a window of size 5 centered around the current subsequence (context features). We also include linear-chain features which allow previously generated output character subsequences to influence current output charac- ter subsequences. In essence, our baseline model is a standard discriminative approach to G2P. It is, all in all, the same approach as described in <ref type="bibr" target="#b20">Jiampojamarn et al. (2010)</ref>, except that we do not include joint n-gram features. At test time, we first segment a new input string x and then apply the CRF. Thereby, we train the segmentation module on the segmented x sequences, as available from the aligned training data. <ref type="bibr">7</ref> BASELINE+X As competitors for the base- line system, we introduce systems that rely on the predictions of one or several additional (black box/offline) systems. At training time, we first multiply many-to-many align the input string x, the predictionsˆypredictionsˆ predictionsˆy (1) , . . . , ˆ y (M ) and the true tran- scription y as illustrated in <ref type="table">Table 3</ref> (see Section 4.3 for details). Then, as for the baseline sys- tem, we train a CRF to label each input character subsequence with the corresponding output char- acter subsequence. However, this time, the CRF has access to the subsequence suggestions (as the alignments indicate) produced by the offline sys- tems. As features for the extended models, we ad- ditionally include context features for all predicted stringsˆystringsˆ stringsˆy (m) (all n-grams in a window of size 3 centered around the current subsequence predic- tion). We also include a joint feature firing on the tuple of the current subsequence value of x, ˆ y (1) , . . . , ˆ y (M ) . To illustrate, when BASELINE+X tags position 2 in the (split up) input string in Ta- ble 3, it sees that its value is ch, that the previous input position contains s, that the next contains i, that the next two contain (i,z), that the predic- tion of the first system at position 2 is k, that the first system's next prediction is ai, and so forth. At test time, we first multiply many-to-many align x, ˆ y (1) , . . . , ˆ y (M ) , and then apply the enhanced CRF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Alignments</head><p>To induce multiple monotone many-to-many alignments of input strings, offline system predic- tions and output strings, we proceed in one of two manners.</p><p>Exact alignments Firstly, we specify sim 1 in Eq. (2), as sim 1 (x i , ˆ y</p><formula xml:id="formula_9">(1) i , . . . , ˆ y (M ) i , y i ) = M m=1 psim(x i , ˆ y (m) i ) + psim(x i , y i ),</formula><p>where psim is a pair-similarity function. The ad- vantage with this specification is that the similarity of a tuple of subsequences is defined as the sum of pairwise similarity scores, which we can directly estimate from pairwise alignments of <ref type="bibr">(x, ˆ y (m)</ref> ) that an off-the-shelf pairwise aligner can produce (we use the Phonetisaurus aligner for this). We set psim(u, v) as log-probability of observing the tu- ple (u, v) in the training data of pairwise aligned sequences. To illustrate, we define the similar- ity of (o,@U,@U,@,@U,@,@U) in the example in <ref type="table">Table  3</ref> as the pairwise similarity of (o,@U) (as inferred from pairwise alignments of x strings and sys- tem 1 transcriptions) plus the pairwise similarity of (o,@U) (as inferred from pairwise alignments of x strings and system 2 transcriptions), etc. At test time, we use the same procedure but drop the term psim(x i , y i ) when inducing alignments. For our current purposes, we label the outlined modus as exact (alignment) modus.</p><p>Approx. alignments Secondly, we derive the optimal multiple many-to-many alignment of the strings in question by choosing an alignment that satisfies the condition that (1) each individual string x, ˆ y (1) , . . . , ˆ y (M ) , y is optimally segmented (e.g., ph-oe-n-i-x rather than pho-eni-x, f-i-n-I-ks rather than f-inIk-s) subject to the global constraint that (2) the number of segments must agree across the strings to align. This constitutes a separa- ble alignment model as discussed in Section 2, and thus has much lower runtime complexity as the first model. Segmentation models can be di- rectly learned from the pairwise alignments that Phonetisaurus produces by focusing on either the segmented x or y/ˆ y (m) sequences; we choose to implement bigram individual segmentation mod- els. This second model type may be considered an approximation of the first, since in a good align- ment, we would not only expect individually good segmentations and agreement of segment numbers but also that subsegments are likely correlations of each other, precisely as our first model type captures. Therefore, we shall call this alignment modus approximate (alignment) modus, for our present purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We now describe two sets of experiments, a con- trolled experiment on the Combilex data set where we can design our offline/black box sys- tems ourselves and where the black box systems are trained on a similar distribution as the base- line and the extended baseline systems. In partic- ular, the black box systems operate on the same output alphabet as the extended baseline systems, which constitutes an 'ideal' situation. Thereafter, we investigate how our extended baseline system performs in a 'real-world' scenario: we train a system on Combilex that has as supplemental in- formation corresponding Wiktionary (and PTE, as explained below) transcriptions.</p><p>Throughout, we use as accuracy measures for all our systems word accuray (WACC). Word ac- curacy is defined as the number of correctly tran- scribed strings among all transcribed strings in a test sample. WACC is a strict measure that penal- izes even tiny deviations from the gold-standard transcriptions, but has nowadays become standard in G2P.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">A controlled experiment</head><p>In our first set of experiments, we let our of- fline/black box systems be the Sequitur G2P mod- eling toolkit <ref type="bibr" target="#b5">(Bisani and Ney, 2008</ref>) (S) and the Phonetisaurus modeling toolkit <ref type="bibr" target="#b30">(Novak et al., 2012</ref>) (P). We train them on disjoint sets of 20,000 grapheme-to-phoneme Combilex string pairs each. The performance of these two sys- tems, on the test set of size 28,000, is indicated in <ref type="table">Table 4</ref>. Next, we train BASELINE on dis- Phonetisaurus Sequitur WACC 72.12 71.70 <ref type="table">Table 4</ref>: Word-accuracy (in %) on the test data, for the two systems indicated.</p><p>joint sets (disjoint from both the training sets of P and S) of size 2,000, 5,000, 10,000 and 20,000. Making BASELINE's training sets disjoint from the training sets of the offline systems is both re- alistic (since a black box system would typically follow a partially distinct distribution from one's own training set distribution) and also prevents the extended baseline systems from fully adapting to the predictions of either P or S, whose train- ing set accuracy is an upward biased representa- tion of their true accuracy. As baseline extensions, we consider the systems BASELINE+P (+P), and BASELINE+P+S (+P+S). 8 Results are shown in <ref type="figure">Figures 1 and 2</ref>. We see that conjoining the base system with the predictions of the offline Phonetisaurus and Se- quitur models substantially increases the base- line WACC, especially in the case of little train- ing data. In fact, WACC increases here by al- most 100% when the baseline system is comple- mented byˆybyˆ byˆy (P) andˆyandˆ andˆy <ref type="bibr">(S)</ref> . As training set size increases, differences become less and less pro- nounced. Eventually, we would expect them to drop to zero, since beyond some training set size, the additional features may provide no new infor- mation. <ref type="bibr">9</ref> We also note that conjoining the two sys- tems is more valuable than conjoining only one system, and, in <ref type="figure">Figure 2</ref>, that the models which are based on exact multiple alignments outperform the models based on approximate alignments, but not by a wide margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0.3">0.35</head><p>0.4 0.45 0.5 0.55 0.6 0.65 0.7 0. Concerning differences in alignments between the two alignment types, exact vs. approximate, an illustrative example where the approximate model fails and the exact model does not is ('false' align- ment based on the approximate model indicated): r ee n t e r e d r i E n t @' r d r i E n t @' r d which nicely captures the inability of the approx- imate model to account for correlations between the matched-up subsequences. That is, while the segmentations of the three shown sequences ap- pear acceptable, a matching of graphemic t with phonemic n, etc., seems quite unlikely. Still, it is very promising to see that these differences in alignment quality translate into very small differ- ences in overall string-to-string translation model performance, as <ref type="figure">Figure 2</ref> outlines. Namely, dif- ferences in WACC are typically on the level of 1% or less (always in favor of the exact alignment model). This is a very important finding, as it in- dicates that string-to-string translation need not be (severely) negatively impacted by switching to the approximate alignment model, a tractable alterna- tive to the exact models, which quickly become practically infeasible as the number of strings to align increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Real-world experiments</head><p>To test whether our approach may also succeed in a 'real-world setting', we use as offline/black box systems GA Wiktionary transcriptions of our in- put forms as well as PhotoTransEdit (PTE) tran- scriptions, 10 a lexicon-based G2P system which offers both GA and RP (received pronunciation) transcription of English strings. We train and test on input strings for which both Combilex and PTE transcriptions are available, and for which both Combilex and Wiktionary transcriptions are avail- able. 11 Test set sizes are about 1,500 in the case of PTE and 3,500 in the case of Wiktionary. We only test here the performance of the exact alignment method, noting that, as before, approximate align- ments produced slightly weaker results.</p><p>Clearly, Wiktionary and PTE differ from the Combilex data. First, both Wiktionary and PTE use different numbers of phonemic symbols than Combilex, as  arise from the fact that, e.g., lengthening of vowels is indicated by two output letters in some data sets and only one in others. Also, phonemic transcrip- tion conventions differ, as becomes most strikingly evident in the case of RP vs. GA transcriptions - <ref type="table">Table 6</ref> illustrates. Finally, Wiktionary has many more phonetic symbols than the other datasets, a finding that we attribute to its crowd-sourced na- ture and lacking of normalization. Despite these differences in phonemic annotation standards be- tween Combilex, Wiktionary and PTE, we observe that conjoining input strings with predicted Wik- tionary or PTE transcriptions via multiple align- ments leads to very good improvements in WACC over only using the input string as information source. Indeed, as shown in <ref type="table" target="#tab_5">Table 7</ref>, for PTE, WACC increases by as much as 80% in case of small training sample (1,099 string pairs) and as much as 37% in case of medium-sized training sample (2,687 string pairs). Thus, comparing with the previous situation of homogenous systems, we also observe that the gain from including hetero- geneous system is relatively weaker, as we would expect due to distinct underlying assumptions, but still impressive. Performance increases when in- cluding Wiktionary are slightly lower, most likely because it constitutes a very heterogenous source of phonetic transcriptions with user-idiosyncratic annotations (however, training set sizes are also different  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have generalized the task description of string transduction to include supplemental information strings. Moreover, we have suggested multiple b o t ch i ng</p><formula xml:id="formula_10">b o t S I N b A -tS I N b a rr ed b a -d b A r d</formula><p>a s th m a t i c s ae s -m ae t I k s a z 0 m a t I k s <ref type="table">Table 6</ref>: Multiple alignments of input string, predicted PTE transcription and true (Combilex) transcrip- tion. Differences may be due to alternative phonemic conventions (e.g., Combilex has a single phonemic character representing the sound tS) and/or due to differences in pronunciation in GA and RP, resp. many-to-many alignments -and a subsequent standardly extended discriminative approach - for solving string transduction (here, G2P) in this generalized setup. We have shown that, in a real- world setting, our approach may significantly beat a standard discriminative baseline, e.g., when we add Wiktionary transcriptions or predictions of a rule-based system as additional information to the input strings. The appeal of this approach lies in the fact that almost any sort of external knowledge source may be integrated to improve the performance of a baseline system. For exam- ple, supplemental information strings may appear in the form of transliterations of an input string in other languages; they may be predictions of other G2P systems, whether carefully manually crafted or learnt from data; they might even ap- pear in the form of phonetic transcriptions of the input string in other dialects or languages. What distinguishes our solution to integrating supple- mental information strings in string transduction settings from other research (e.g., <ref type="bibr" target="#b3">(Bhargava and Kondrak, 2011;</ref><ref type="bibr" target="#b4">Bhargava and Kondrak, 2012)</ref>) is that rather than integrating systems on the global level of strings, we integrate them on the lo- cal level of smaller units, namely, substrings ap- propriated to the domain of application (e.g., in our context, phonemes/grapheme substructures). Both approaches may be considered complemen- tary. Finally, another important contribution of our work is to outline an 'approximation algorithm' to inducing multiple many-to-many alignments of strings, which is otherwise an NP-hard problem for which (most likely) no efficient exact solu- tions exist, and to investigate its suitability for the problem task. In particular, we have seen that ex- act alignments lead to better overall model perfor- mance, but that the margin over the approximation is not wide.</p><p>The scope for future research of our modeling is huge: multiple many-to-many alignments may be useful in aligning cognates in linguistic research; they may be the first necessary step for many other ensemble techniques in string transduction as we have considered ( <ref type="bibr" target="#b7">Cortes et al., 2014</ref>), and they may allow, on a large scale, to boost G2P (translit- eration, lemmatization, etc.) systems by inte- grating them with many traditional (or modern) knowledge resources such as rule-and dictionary- based lemmatizers, crowd-sourced phonetic tran- scriptions (e.g., based on Wiktionary), etc., with the outlook of significantly outperforming current state-of-the-art models which are based solely on input string information.</p><p>Finally, we note that we have thus far shown that supplemental information strings may be ben- eficial in case of overall little training data and that improvements decrease with data size. Further in- vestigating this relationship will be of importance. Morevoer, it will be insightful to compare the exact and approximate alignment algorithms pre- sented here with other (heuristic) alignment meth- ods, such as iterative pairwise alignments as em- ployed in machine translation, and to investigate how alignment quality of multiple strings impacts overall G2P performance in the setup of additional information strings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: WACC as a function of training set size for the system indicated. Exact align. modus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 . The cen-</head><label>2</label><figDesc></figDesc><table>Input form Wiktionary Combilex 
neutrino 
nju:tôi:noU 
nutrinF 
wooded 
wUdId 
wUd@d 
wrench 
ôEnúS 
rEn&lt; 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Input letter words, Wiktionary and Com-
bilex transcriptions. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 5 illustrates. Some differences</head><label>5</label><figDesc></figDesc><table>Dataset 
|Σ| 
Combilex 
54 
Wiktionary GA 107 
Wiktionary RP 116 
PTE GA 
44 
PTE RP 
57 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Sizes of phonetic inventaries of different 
data sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Top: WACC in % for baseline CRF 
model and the models that integrate PTE in the 
GA versions and RP versions, respectively. Bot-
tom: BASELINE and BASELINE+Wiktionary. 

</table></figure>

			<note place="foot" n="3"> We denote by x(a : b) the substring xaxa+1 · · · x b of the string x1x2 · · · xt.</note>

			<note place="foot" n="4"> Note the difference between Eqs. (2) and (4). While each fw n in (4) operates on a &apos;row&apos; of an alignment scheme, sim1 in (2) acts on the &apos;columns&apos;. In other words, the unigram alignment model correlates the multiply matched-up subsequences, while the separable alignment model assumes independence here.</note>

			<note place="foot" n="5"> In Cotterell et al. (2014), context influences alignments, so that the approach goes beyond the unigram model sketched in (2), but there, too, the focus is on the situation N = 2 and S = {(1, 0), (0, 1), (1, 1)}.</note>

			<note place="foot" n="6"> We made use of the CRF++ package available at https://code.google.com/p/crfpp/. 7 To be more precise on the training of the segmentation module, in an alignment as in Table 1, we consider the segmented x string-ph-oe-n-i-x-and then encode this segmentation in a binary string where 1&apos;s indicate splits. Thus, segmentation becomes, again, a sequence labling task; see, e.g., Bartlett et al. (2008) or Eger (2013) for details.</note>

			<note place="foot" n="8"> We omit BASELINE+S since it yielded similar results as BASELINE+P. 9 In fact, in follow-up work, we find that the additional information may also confuse the base system when training set sizes are large enough.</note>

			<note place="foot" n="10"> Downloadable from http://www.photransedit.com/. 11 This yields a clear method of comparison. An alternative would be to provide predictions for missing transcriptions. In any case, by our task definition, all systems must provide a hypothesis for an input string.</note>

			<note place="foot" n="12"> To provide, for the interested reader, a comparison with Phonetisaurus and Sequitur: for the Wiktionary GA data, performance of Phonetisaurus is 41.80% (training set size 2,000), 55.70% (5,000) and 62.47% (10,000). Respective numbers for Sequitur are 40.58%, 54.84%, and 61.58%. On PTE, results are, similarly, slightly higher than our baseline, but substantially lower than the extended baseline.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Computing consensus translation from multiple machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bodel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop (ASRU-2001</title>
		<meeting>IEEE Automatic Speech Recognition and Understanding Workshop (ASRU-2001</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="351" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic syllabification with structured svms for letter-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui</editor>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
	<note>The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple word alignment with Profile Hidden Markov Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Student Research Workshop and Doctoral Consortium<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="volume">917</biblScope>
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">How do you pronounce your name?: Improving g2p with transliterations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="399" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Leveraging supplemental representations for sequential transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="396" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Jointsequence models for grapheme-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Bisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="434" to="451" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An improved error model for noisy channel spelling correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, ACL &apos;00</title>
		<meeting>the 38th Annual Meeting on Association for Computational Linguistics, ACL &apos;00<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="286" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ensemble methods for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th International Conference on Machine Learning</title>
		<meeting>the 31th International Conference on Machine Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1134" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stochastic contextual edit distance and probabilistic FSTs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Baltimore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Alignment of multiple languages for historical comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Covington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</title>
		<meeting>the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics<address><addrLine>Montreal, Quebec, Canada, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="275" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Variable-length sequence matching for phonetic transcription using joint multigrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Deligne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franois</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bimbot</surname></persName>
		</author>
		<editor>EUROSPEECH. ISCA</editor>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Latent-variable modeling of string transductions with finite-state methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1080" to="1089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Durbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><forename type="middle">R</forename><surname>Eddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Mitchison</surname></persName>
		</author>
		<title level="m">Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sequence segmentation by enumeration: An exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Eger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prague Bull. Math. Linguistics</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="113" to="132" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Progressive sequence alignment as a prerequisite to correct phylogenetic trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Doolittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of molecular evolution</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="360" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gusfield</surname></persName>
		</author>
		<title level="m">Algorithms on Strings, Trees, and Sequences-Computer Science and Computational Biology</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Machine translation system combination with flexible word ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Hanneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2009 Fourth Workshop on Statistical Machine Translation</title>
		<meeting>the EACL 2009 Fourth Workshop on Statistical Machine Translation<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-03" />
			<biblScope unit="page" from="56" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarek</forename><surname>Kondrak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherif</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<title level="m">Proceedings of the Main Conference</title>
		<meeting>the Main Conference<address><addrLine>Rochester, New York</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="372" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint processing and discriminative training for letter-to-phoneme conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT, pages 905-913, Columbus</title>
		<meeting>ACL-08: HLT, pages 905-913, Columbus<address><addrLine>Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Integrating joint n-gram features into a discriminative training framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Sittichai Jiampojamarn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="697" to="700" />
		</imprint>
	</monogr>
	<note>HLTNAACL</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generalized median string computation by means of string embedding in vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jran</forename><surname>Wentker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miquel</forename><surname>Ferrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="842" to="852" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
		<title level="m">Median strings. Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="309" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th International Conf. on Machine Learning</title>
		<meeting>18th International Conf. on Machine Learning<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Binary Codes Capable of Correcting Deletions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vi Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insertions and Reversals. Soviet Physics Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">707</biblScope>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An empirical study on computing consensus translations from multiple machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Use of positional information in sequence alignment for multiple classifier combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs-Viktor</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple Classifier Systems</title>
		<editor>Josef Kittler and Fabio Roli</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">918</biblScope>
			<biblScope unit="page" from="388" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Ueffing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-04" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">D</forename><surname>Needleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1970-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comparisons of sequence labeling algorithms and extensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference Proceeding Series</title>
		<editor>Zoubin Ghahramani</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="page" from="681" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">WFST-based grapheme-to-phoneme conversion: Open source tools for alignment, model-building and decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><forename type="middle">R</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuaki</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keikichi</forename><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing</title>
		<meeting>the 10th International Workshop on Finite State Methods and Natural Language Processing<address><addrLine>Donostia-San Sebastin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="45" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Implicitly intersecting weighted automata using dual decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="232" to="242" />
		</imprint>
	</monogr>
	<note>HLT-NAACL</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust LTS rules with the Combilex speech technology lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Korin</forename><surname>Richmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1295" to="1298" />
		</imprint>
	</monogr>
	<note>ISCA</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning string-edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sven Ristad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="522" to="532" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Substringbased transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarek</forename><surname>Sherif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
		<editor>John A. Carroll, Antal van den Bosch, and Annie Zaenen</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>The Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The consensus string problem for a metric is np-complete</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seop</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunsoo</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Discrete Algorithms</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="117" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Algorithms for approximate string matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Esko Ukkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Control</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="100" to="118" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Computerized correction of phonographic errors. Computers and the Humanities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Véronis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
