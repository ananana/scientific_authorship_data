<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Domain Adaptation for Relation Extraction via Clustering Consistency</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Luan Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre for Quantum Computation &amp; Intelligent Systems</orgName>
								<orgName type="institution">University of Technology</orgName>
								<address>
									<settlement>Sydney</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">A</forename><surname>Kian</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chai</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">DSO National Laboratories</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">DSO National Laboratories</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute for Infocomm Research</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Domain Adaptation for Relation Extraction via Clustering Consistency</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="807" to="817"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a two-phase framework to adapt existing relation extraction classi-fiers to extract relations for new target domains. We address two challenges: negative transfer when knowledge in source domains is used without considering the differences in relation distributions; and lack of adequate labeled samples for rarer relations in the new domain, due to a small labeled data set and imbalance relation distributions. Our framework leverages on both labeled and unlabeled data in the target domain. First, we determine the relevance of each source domain to the target domain for each relation type, using the consistency between the clustering given by the target domain labels and the clustering given by the predic-tors trained for the source domain. To overcome the lack of labeled samples for rarer relations, these clusterings operate on both the labeled and unlabeled data in the target domain. Second, we trade-off between using relevance-weighted source-domain predictors and the labeled target data. Again, to overcome the imbalance distribution, the source-domain predictors operate on the unlabeled target data. Our method outperforms numerous baselines and a weakly-supervised relation extraction method on ACE 2004 and YAGO.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The World Wide Web contains information on real-world entities, such as persons, locations and organizations, which are interconnected by vari- ous semantic relations. Detecting these relations between two entities is important for many tasks on the Web, such as information retrieval <ref type="bibr" target="#b28">(Salton and McGill, 1986)</ref> and information extraction for question answering . Recent work on relation extraction has demonstrated that supervised machine learning coupled with intelli- gent feature engineering can provide state-of-the- art performance <ref type="bibr" target="#b15">(Jiang and Zhai, 2007b)</ref>. How- ever, most supervised learning algorithms require adequate labeled data for every relation type to be extracted. Due to the large number of relations among entities, it may be costly to annotate a large enough set of training data to cover each relation type adequately in every new domain of interest. Instead, it can be more cost-effective to adapt an existing relation extraction system to the new do- main using a small set of labeled data. This paper considers relation adaptation, where a relation ex- traction system trained on many source domains is adapted to a new target domain.</p><p>There are at least three challenges when adapt- ing a relation extraction system to a new domain. First, the same semantic relation between two en- tities can be expressed using different lexical or syntactic patterns. For example, the acquisition of company A by company B can be expressed with "B bought over by A", "A buys B" and "A pur- chases B". To extract a relation, we need to cap- ture the different ways in which it can be expressed across different open domains on the Web.</p><p>Second, the emphasis or interest on the different relation types varies from domain to domain. For example, in the organization domain, we may be more interested in extracting relations such as lo- catedIn (between a company and a location) and founderOf (between a company and a person), whereas in the person domain we may be more in- terested in extracting relations such as liveIn (be- tween a person and a location) and workAt (be- tween a person and a company). Therefore, al- though the two domains may have the same set of relations, they probably have different marginal distributions on the relations. This can produce a negative transfer phenomenon ( <ref type="bibr" target="#b27">Rosenstein et al., 2005)</ref>, where using knowledge from other do- mains degrades the performance on the target do- main. Hence, when transferring knowledge from multiple domains, it is overly optimistic to believe that all source domains will contribute positively. We call a source domain irrelevant when it has no or negative contribution to the performance of the target domain. One example is named entities ex- traction adaptation, where na¨ıvena¨ıve transfer of infor- mation from a mixed-case domain with capitaliza- tion information (e.g., news-wire) to a single-case domain (e.g., conversational speech transcripts) will miss most names in the single-case domain due to the absence of case information, which is typically important in the mixed-case domain.</p><p>Third, the annotated instances for the target do- main are typically much fewer than those for the source domains. This is primarily due to the lack of resources such as raw target domain documents, time, and people with the expertise. Together with imbalanced relation distributions inherent in the domain, this can cause some rarer relations to con- stitute only a very small proportion of the labeled data set. This makes learning a relation classifier for the target domain challenging.</p><p>To tackle these challenges, we propose a two- phase Robust Domain Adaptation (RDA) frame- work. In the first phase, Supervised Voting is used to determine the relevance of each source domain to each region in the target domain, using both la- beled and unlabeled data in the target domain. By using also unlabeled data, we alleviate the lack of labeled samples for rarer relations due to imbal- anced distributions in relation types.</p><p>The second phase uses the relevances deter- mined the first phase to produce a reference pre- dictor by weighing the source-domain predictors for each target domain sample separately. The in- tention is to alleviate the effect of mismatched dis- tributions. The final predictor in the target domain is trained on the labeled target domain data while taking reference from the reference predictions on the unlabeled target domain data. This ensures reasonable predictive performance even when all the source domains are irrelevant and augments the rarer classes with examples in the unlabeled data. We compare the proposed two-phase frame- work with state-of-the-art domain adaptation base- lines for the relation extraction task, and we find that our method outperforms the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Relation extraction is usually considered a classifi- cation problem: determine if two given entities in a sentence have a given relation. Kernel-based su- pervised methods such as dependency tree kernels ( <ref type="bibr" target="#b8">Culotta and Sorensen, 2004</ref>), subsequence ker- nels ( <ref type="bibr" target="#b6">Bunescu and Mooney, 2006</ref>) and convolution tree kernels ( <ref type="bibr" target="#b25">Qian et al., 2008</ref>) have been rather successful in learning this task. However, purely supervised relation extraction methods assume the availability of sufficient labeled data, which may be costly to obtain for new domains. We address this by augmenting a small labeled data set with other information in the domain adaptation setting.</p><p>Bootstrapping methods ( <ref type="bibr" target="#b37">Zhu et al., 2009;</ref><ref type="bibr" target="#b0">Agichtein and Gravano, 2000;</ref><ref type="bibr" target="#b33">Xu et al., 2010;</ref><ref type="bibr" target="#b23">Pasca et al., 2006;</ref><ref type="bibr" target="#b26">Riloff and Jones, 1999</ref>) to re- lation extraction are attractive because they re- quire fewer training instances than supervised ap- proaches. Bootstrapping methods are either ini- tialized with a few instances (often designated as seeds) of the target relation ( <ref type="bibr" target="#b37">Zhu et al., 2009;</ref><ref type="bibr" target="#b0">Agichtein and Gravano, 2000</ref>) or a few extraction patterns ( <ref type="bibr" target="#b33">Xu et al., 2010)</ref>. In subsequent itera- tions, new extraction patterns are discovered, and these are used to extract new instances. The qual- ity of the extracted relations depends heavily on the seeds ( <ref type="bibr" target="#b17">Kozareva and Hovy, 2010)</ref>. Different from bootstrapping, we not only use labeled tar- get domain data as seeds, but also leverage on ex- isting source-domain predictors to obtain a robust relation extractor for the target domain.</p><p>Open Information Extraction (Open IE) <ref type="bibr" target="#b19">Mesquita et al., 2013</ref>) is a domain-independent informa- tion extraction paradigm to extract relation tu- ples from collected corpus ( <ref type="bibr" target="#b29">Shinyama and Sekine, 2006</ref>) and Web ( . Open IE systems are initialized with a few domain-independent extraction patterns. To cre- ate labeled data, the texts are dependency-parsed, and the domain-independent patterns on the parses form the basis for extractions. Recently, to reduce labeling effort for relation extraction, distant su- pervision ( <ref type="bibr" target="#b21">Mintz et al., 2009;</ref><ref type="bibr" target="#b32">Takamatsu et al., 2012;</ref><ref type="bibr" target="#b20">Min et al., 2013;</ref><ref type="bibr" target="#b34">Xu et al., 2013</ref>) has been proposed. This is an unsupervised approach that exploits textual features in large unlabeled cor- pora. In contrast to Open IE, we tune the relation patterns for a domain of interest, using labeled re- lation instances in source and target domains and unlabeled instances in the target domain.</p><p>Our work is also different from the multi- schema matching in database integration ( <ref type="bibr" target="#b10">Doan et al., 2003)</ref>. Multi-schema matching finds rela- tions between columns of schemas, which have the same semantic. In addition, current weighted schema matching methods do not address negative transfer and imbalance class distribution.</p><p>Domain adaptation methods can be classi- fied broadly into weakly-supervised adaptation <ref type="bibr" target="#b9">(Daume and Marcu, 2007;</ref><ref type="bibr" target="#b3">Blitzer et al., 2006;</ref><ref type="bibr" target="#b14">Jiang and Zhai, 2007a;</ref><ref type="bibr" target="#b16">Jiang, 2009)</ref>, and unsuper- vised adaptation <ref type="bibr" target="#b22">(Pan et al., 2010;</ref><ref type="bibr" target="#b3">Blitzer et al., 2006;</ref><ref type="bibr" target="#b24">Plank and Moschitti, 2013</ref>). In the weakly- supervised approach, we have plenty of labeled data for the source domain and a few labeled in- stances in the target domain; in the unsupervised approach, the data for the target domain are not la- beled. Among these studies, Plank and Moschitti's is the closest to ours because it adapts relation extraction systems to new domains. Most other works focused on adapting from old to new re- lation types. Typical relation adaptation methods first identify a set of common features in source and target domains and then use those features as pivots to map source domain features to the target domain. These methods usually assume that each source domain is relevant to the task on the target domain. In addition, these methods do not handle the imbalanced distribution of relation data explic- itly. In this work, we study how to learn the target prediction using only a few seed instances, while dealing with negative transfer and imbalanced re- lation distribution explicitly. These issues are sel- dom explored in relation adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement</head><p>This section defines the domain adaptation prob- lem and describes our feature extraction scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Relation Extraction Domain Adaptation</head><p>Given two entities A and B in a sentence S, rela- tion extraction is the task of selecting the relation y between A and B from a fixed set of c relation types, which includes the not-a-relation type. We introduce a feature extraction χ that maps the triple (A, B, S) to its feature vector x. Learning relation extraction can then be abstracted to finding a func- tion p such that p(χ(A, B, S)) = p(x) = y.</p><p>For adaptation, we have k source domains and a target domain. We shall assume that all domains have the same set of relation types. The target do- main has a few labeled data D l = {(x i , y i )} n l i=1 and plenty of unlabeled data D u = {(x i )} n l +n u n l +1 , where n l and n u are the number of labeled and unla- beled samples respectively, x i is the feature vec- tor, y i is the corresponding label (if available). Let n = n l + n u . For the sth source domain, we have an adequate labeled data set D s . We define domain adaptation as the problem of learning a classifier p for relation extraction in the target domain using the data sets D l , D u and D s , s = 1, . . . , k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relational Feature Representation</head><p>We consider relation extraction as a classifica- tion problem, where each pair of entities A and B within a sentence S is a candidate relation in- stance. The contexts in which entities A and B co- occur provide useful features to the relations be- tween them. We use the term context to refer a window of text in which two entities co-occur. A context might not necessarily be a complete sen- tence S. Retrieving contexts in which two entities co-occur has been studied in previous works in- vestigating the relations between entities.</p><p>Given a pair of entities (A, B) in S, the first step is to express the relation between A and B with some feature representation using a feature ex- traction scheme χ. Lexical or syntactic patterns have been successfully used in numerous natu- ral language processing tasks, including relation extraction. <ref type="bibr" target="#b15">Jiang and Zhai (2007b)</ref> have shown that selected lexical and syntactic patterns can give good performance for relation extraction. Follow- ing their work 1 , we also use lexical and syntactic patterns extracted from the contexts to represent the relations between entities. We extract features from a sequence representation and a parse tree representation of each relation instance. The de- tails are as follows.</p><p>Entity Features Entity types and entity mention types are very useful for relation extraction. We use a subgraph in the relation instance graph <ref type="bibr" target="#b15">(Jiang and Zhai, 2007b</ref>) that contains only the node presenting the head word of the entity A, la- beled with the entity type or entity mention types, to describe a single entity attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequence Features</head><p>The sequence representation preserves the order of the tokens as they occur in the original sentence. Each node in the graph is a token augmented with its relevant attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic Features</head><p>The syntactic parse tree of the relation instance sentence can be augmented to represent the relation instance. Each node is aug- mented with relevant part-of-speech (POS) using the Python Natural Language Processing Tool Kit.</p><p>Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node corresponds to entity A, B, both, or neither. The nodes that represent the argument are also labeled with the entity type, subtype and mention type. We trim the parse tree of a relation instance so that it contains only the most essential tree components based on constituent dependen- cies ( <ref type="bibr" target="#b25">Qian et al., 2008</ref>). We also use unigram fea- tures and bigram features from a relation instance graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Robust Domain Adaptation</head><p>In this section, we describe our two-phase ap- proach, which comprises of a Supervised Voting scheme and a combined classifier learning phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Phase 1: Clustering Consistency via Supervised Voting</head><p>In this section, we use the concept of clustering consistency to determine the relevance of a source domain to particular regions in the target domain. Target domain input space with labels from the predictor trained on the source domain data set. This suggests that the source domain is very rele- vant for the bottom and right regions of the target input space, but less so for the top and left regions.</p><p>To apply this idea to relation classification, we have to (i) partition the target domain input space into regions and (ii) assign preliminary labels for all the examples. We approximate the target do- main input space with all the samples from D l and D u . With data from both the labeled and unlabeled data sets, we apply transductive inference or semi- supervised learning ( <ref type="bibr" target="#b36">Zhou et al., 2003)</ref> to achieve both (i) and (ii). By augmenting with unlabeled data D u , we aim to alleviate the effect of imbal- anced relation distribution, which causes a lack of labeled samples for rarer classes in a small set of labeled data. Briefly, the known labels in D l are propagated to the entire target input space by encouraging label smoothness in neighborhoods. The next three paragraphs give more details.</p><p>At present, we assume a similarity matrix W , where W i j is the similarity between the ith and the jth input samples in D l ∪ D u . Matrix W then de- termines the neighborhoods. Let Λ be a diagonal matrix where the (i, i)th entry is the sum of the ith row of W . Let us also encode the the labeled data D l in an n-by-c matrix H, such that H i j = 1 if sample i is labeled with relation class j in D l , and H i j = 0 otherwise. Our objective is the c- dimensional relation-class indicator vector F i for the ith sample, for every sample. This is achieved via a regularization framework ( <ref type="bibr" target="#b36">Zhou et al., 2003)</ref>:</p><formula xml:id="formula_0">min {F i } n i=1 n ∑ i, j=1 W i j F i √ Λ ii − F j Λ j j 2 + µ n ∑ i=1 F i − H i 2 .</formula><p>This trades off two criteria: the first term encour- ages nearby samples (under distance metric W ) to have the same labels, while the second encourages samples to take their labels from the labeled data. The closed-form solution is</p><formula xml:id="formula_1">F * = (I − (1 + µ) −1 L) −1 H,<label>(1)</label></formula><p>where</p><formula xml:id="formula_2">L = Λ −1/2 W Λ −1/2</formula><p>; and the n-by-c matrix F * is the concatenation of the F i s. Using vector F * i , we now assign preliminary la- bels to the samples. For a sample i, we transform F * i into probabilities p 1 i , p 2 i , . . . , p c i using softmax. Our propagated label i for sample i is then</p><formula xml:id="formula_3">i = not-a-relation if (max j p j i ) &lt; θ, arg max j p j i otherwise.<label>(2)</label></formula><p>The second clause is self-evident, but the first needs further explanation. Because not-a-relation is a background or default relation type in the re- lation classification task, and because it has rather high variation when manifested in natural lan- guage, we have found it difficult to obtain a dis- tance metric W that allows the not-a-relation sam- ples to form clusters naturally using transductive inference. Therefore, we introduce the first clause to assign the not-a-relation label to a sample when there is no strong evidence for any of the positive relation types. The amount of evidence needed is quantified by the parameter θ &gt; 1/c. In addition, the second clause will also assign not-a-relation to a sample if that probability is the highest. Next, we partition the data in D l ∪ D u into c re- gions, R 1 , R 2 , . . . , R c , corresponding to the c rela- tion types. The intuition is to use the true label in D l when available, or otherwise resort to using the propagated label. That is,</p><formula xml:id="formula_4">x i ∈ R y i if x i ∈ D l , R i if x i ∈ D u .</formula><p>We now have the necessary ingredients to quan- tify the clustering consistency between a source Phy Per Emp Agt Aff GPE Dis N/A BC BN NW CTS WL <ref type="figure">Figure 2</ref>: Heat map of the relevance scores w s, j between the target domain Usenet (UN) with the other domains on ACE 2004 data set. A lighter shade means a higher score, or more relevant. N/A refers to not-a-relation; for the other abbrevia- tions, see the second paragraph in section 5.</p><p>domain and a region in the target domain. Intu- itively, this is the agreement between the source- domain predictor and the preliminary predictor within the target domain. We use supervised vot- ing in the following manner. For every source do- main, say domain s, we first train a relation-type predictor p s based on its training data D s . Then, for every region R j , we compute the relevance score w s, j = ∑ x i ∈R j p s (x i ) = i /|R j |, where · is the Iverson bracket. <ref type="figure">Figure 2</ref> shows the heat map of the relevance scores w s, j between the target domain Usenet (UN) with the other domains in the ACE 2004 cor- pus. We observe, for example, that the Broad- cast News (BN) domain is more relevant in the Personal-Social region of the target domain than the Broadcast Conversation (BC) domain. These relevance scores will be used in the next phase of the framework to weigh the contributions of source-domain predictors to the eventual target- domain relation classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Phase 2: Target Classifier Learning</head><p>The second phase uses both the weighted predic- tions from all sources and the target labeled data D l to learn a relation classifier. This ensures that even when most of the source domains are irrele- vant, the performance of our method is no worse than using the target-domain labeled data alone.</p><p>The previous phase has computed the relevance w s, j for source domain s in region R j . We trans- late this to the relevance weight u s,i for an ex- ample x i : if x i ∈ R j , then u s,i = w s, j . At our dis- posal from the previous phase are also k source- domain predictors p s that have been trained on D s . Combining and weighing the predictions from multiple sources, we obtain the reference predic-tionˆrtionˆ tionˆr ji = ∑ k s=1 u s,i (2p s (x i ) = j − 1) for example x i belonging to relation j, using the ±1 encoding.</p><p>The relation classifier consists of c functions f 1 , . . . , f c using the one-versus-rest decoding for multi-class classification. <ref type="bibr">2</ref> Inspired by the Do- main Adaptive Machine ( <ref type="bibr" target="#b11">Duan et al., 2009</ref>), we combine the reference predictions and the labeled data of the target domain to learn these functions:</p><formula xml:id="formula_5">min { f j } c j=1 c ∑ j=1 1 n l n l ∑ i=1 ( f j (x i ) − r ji ) 2 + γ f j 2 H + β 2 n ∑ i=n l +1 f j (x i ) − ˆ r ji 2 ,<label>(3)</label></formula><p>where r ji = 2y i = j − 1 is the ±1 binary encod- ing for the i labeled sample belonging to relation j.  <ref type="bibr" target="#b30">and Scholkopf, 1998)</ref>, the solution for Eq. 3 is linear in K(x i , ·):</p><formula xml:id="formula_6">f j (x) = ∑ n i=1 α ji K(x i , x)</formula><p>. Putting this into Eq. 3, parameter vectors α j are ( <ref type="bibr" target="#b2">Belkin et al., 2006</ref>):</p><formula xml:id="formula_7">α * j = (JK + γ(n l + βn u )I) −1 JR j .<label>(4)</label></formula><p>Here, R j is an (n l + n u )-vector, where R ji = r ji if sample i belongs to the labeled set, and R ji = ˆ r i j if it belongs to the unlabeled set; and J is an (n l + n u )-by-(n l + n u ) diagonal matrix where the first n l diagonal entries are ones and the rest are βs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We evaluate our algorithm on two corpora: Au- tomatic Content Extraction (ACE) <ref type="bibr">2004</ref>    <ref type="bibr" target="#b5">Bollegala et al. (2011)</ref>. It consists of twenty relation types such as ceo company, bornIn and isMarriedTo, and each of them is con- sidered as a domain in this work. YAGO is dif- ferent from ACE 2004 in two aspects: there is less overlapping of topics, entity types and rela- tion types between domains; and it has more rela- tion mentions with 11 mentions per pair of entities on the average.</p><p>We used Collins parser <ref type="bibr" target="#b7">(Collins, 1999</ref>) to parse the sentences. The constituent parse trees were then transformed into dependency parse trees, us- ing the head of each constituent <ref type="bibr" target="#b15">(Jiang and Zhai, 2007b</ref>). The candidate relation instances were generated by considering all pairs of entities that occur in the same sentence. For the similarity ma- trix W in section 4.1 and the kernel K(·, ·) in sec- tion 4.2, we used the composite kernel function ( <ref type="bibr" target="#b35">Zhang et al., 2006</ref>), which is based on structured features and entity-related features.</p><p>F 1 is used to measure the performance of the al- gorithms. This is the harmonic mean of precision TP/(TP + FP) and recall TP/ <ref type="figure">(TP + FN)</ref>, where TP, FP and FN are the numbers of correct, missing and wrongly recognized relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>For ACE 2004, we used each of the six domains as the target domain and the remaining domains as source domains. For YAGO, each relation type in YAGO was considered as a domain. For each domain in YAGO, we have a binary classifica- tion task: whether the instance has the relation corresponding to the domain. Five-fold cross- validation was used to evaluate the performance.</p><p>For every target domain, we divided all data into 5 subsets, and we used each subset for testing and the other four subsets for training. In the training set, we randomly removed most of the positive in- stances of the target domain from the training set except for 10% of the labeled data. This gave us the weakly-supervised setting. This was repeated five times with different training and test sets. We report the average performance over the five runs.</p><p>In our experiments, we set µ = 0.8 in Eq. 1; θ = 0.18 in Eq. 2; and γ = 0.1 and β = 0.3 in Eq. 3. For each target domain, we used k ∈ {1, 3, 5} dif- ferent source domains chosen randomly from the remaining domains. Thus, the relevance of the source domains to the target domain varies from experiment to experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare our framework with several other methods, including state-of-the-art machine learn- ing, relation extraction and common domain adap- tation methods. These are described below.</p><p>In-domain multiclass classifier This is Support- vector-machine <ref type="bibr" target="#b13">(Fan et al., 2008</ref>, SVM) using the one-versus-rest decoding without removing positive labeled data <ref type="bibr" target="#b15">(Jiang and Zhai, 2007b</ref>) from the target domain. Its performance can be regarded as an upper bound on the performance of the cross-domain methods.</p><p>No-transfer classifier (NT) We only use the few labeled instances of the target relation type to- gether with the negative relation instances to train a binary classifier.</p><p>Alternate no-transfer classifier (NT-U) We use the union of the k source-domain labeled data sets D s s and the small set of target-domain la- beled data D l to train a binary classifier. It is then applied directly to predict on the unlabeled target-domain data D u without any adaptation.</p><p>Laplacian SVM (L-SVM) This is a semi- supervised learning method based on label propagation (Melacci and Belkin, 2011).</p><p>Multi-task transfer (MTL) This is a learning method for weakly-supervised relation extrac- tion <ref type="bibr" target="#b16">(Jiang, 2009)</ref>.</p><p>Adaptive domain bootstrapping (DAB) This is an instance-based domain adaptation method for relation extraction ( <ref type="bibr" target="#b33">Xu et al., 2010</ref>).</p><p>Structural correspondence learning (SCL) We use the feature-based domain adaptation ap- proach by <ref type="bibr" target="#b4">Blitzer et al. (2007)</ref>. We apply SCL on the D s s and D l to train a model. The learned model then makes predictions on D u .</p><p>Domain Adaptation Machine (DAM) We use the framework of <ref type="bibr" target="#b11">Duan et al. (2009)</ref>, which is a multiple-sources domain adaptation method.</p><p>For the kernel-based methods above, we use the same composite kernel used in our method. The source codes of L-SVM, MTL, SCL and DAM were obtained from the authors. The others were re-implemented. <ref type="table" target="#tab_3">Tables 2, 3</ref>  From <ref type="table" target="#tab_4">Table 3</ref> and <ref type="table" target="#tab_6">Table 5</ref>, we see that the proposed method has the best F 1 among all the other methods, except for the supervised upper bound (In-domain). We first notice that NT-U generally does not perform well, and sometimes it performs worse than NT. The reason is that NT-U aims to obtain a consensus among the do- mains, and this will give a worse label than NT when there are enough irrelevant sources to influ- ence the classification decision wrongly. In fact, one can roughly deduce that a target domain has few relevant source domains by simply comparing columns NT with columns NT-U in the tables: a decrease in F 1 from NT to NT-U suggests that the source domains are mainly irrelevant. For exam- ple, for domain BC in ACE 2004, we find that its F 1 decreases from NT to NT-U consistently in Ta- bles 2, 3 and 4, which suggests that BN, NW, CTS, UN and WL are generally irrelevant to it; and sim- ilarly for domain CTS. We investigate this further by examining the relevance scores w s, j s, and we find that the decreases in F 1 from NT to NT-U hap- pen when there are more regions in the target do- main to which source-domains are irrelevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Results</head><p>We find that MTL, DAB and SCL are better than NT-U when the majority of source domains are relevant. This shows that MTL, DAB and SCL are able to make more effective use of relevant sources than NT-U. Howevever, we find that their perfo- mances are not stable: for example, MTL for tar- get UN in <ref type="table" target="#tab_3">Table 2</ref>. In contrast, we find the per- formance of L-SVM and DAM to be more sta- ble. The reason is their reduced vulnerability to   We analyzed histogram of the relation types to order the domains according to the imbalance of the class distributions. Using this, we observe that MTL, DAB and SCL perform relatively badly when the target-domain distribution is more im- balanced. In constrast, L-SVM, DAM and RDA are more robust.</p><p>Comparing with the baselines, RDA achieves the best performance on almost all the experi- ments. Using the two-phase framework, RDA can successfully transfer useful knowledge even in the pressence of irrelevant sources and imbalanced distributions. For ACE 2004, the improvement in F 1 over the best baseline can be up to 4.0% and is on average 3.6%. Similarly for YAGO, the im- provement in F 1 over the best baseline can be up to 5.5% and is on average 4.3%. <ref type="table" target="#tab_3">Tables  2, 3</ref>, 4 and 6 also demonstrate that RDA improves monotonically as the number of source domains increases for both ACE 2004 and YAGO.  <ref type="table" target="#tab_3">Tables 2 to 4</ref>, we ob- serve that the smallest performance gap between RDA and the in-domain settings is still high (about 12% with k = 5) on ACE 2004. This is because we have used a lot less labeled instances in the target domains: only 10% are used. However, the gaps reduces when the number of source domains in- creases. Comparing with the in-domain results in <ref type="table" target="#tab_6">Table 5</ref> (which is constant with k), <ref type="table" target="#tab_7">Table 6</ref> also shows a similar trend on YAGO. By exploiting the labeled data in ten source domains in YAGO, our RDA algorithm can reduce the gap between the cross-domain and in-domain settings to 9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact of Number of Source Domains</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have proposed a robust domain adaptation (RDA) approach for the relation extrac- tion problem where labeled data is scarce. Ex- isting domain adaptation approaches suffer from negative transfer and under imbalanced distribu- tions. To overcome these, we have proposed a two-phase approach to transfer only relevant in- formation from multiple source domains, and thus derive accurate and robust predictions on the un- labeled target-domain data. Experimental results on ACE 2004 and YAGO have shown that the our domain adaptation method achieves the best per- formance on F 1 measure compared with the other baselines when only few labeled target instances are used. Because of the practical importance of domain adaptation for relation extraction due to lack of labeled data in new domains, we hope our study and findings will lead to further investiga- tions into this problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 illustrates this.</head><label>1</label><figDesc>There, both enclosing cir- cles in the left and right figures denote the same input space of the target domain. There are four disjoint regions within the input space, located at the left, right, top and bottom of the space. There are four classes of labels: plus (+), cross (×), cir- cle (•) and asterisk ( * ). The labels in the left fig- ure are given by a preliminary predictor in the tar- get domain data, while the labels in the right fig- ure are given by a predictor trained on the source domain data. Comparing the figures, we see the preliminary predictor and source domain predic- tor are consistent for the bottom and right regions, Target domain input space with transduc- tive learning using la- beled and unlabeled target domain data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Clustering consistency is used to determine the relevance of a source domain to a region in the target domain data. The bottom and right regions are more relevant than the top and left regions. See text for explanation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and 4 present the results on ACE 2004 (corresponding to k = 1, 3, 5), and Tables 5 present those on YAGO (corresponding to k = 5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 : Statistics on ACE 2004 and YAGO Properties ACE 2004 YAGO</head><label>1</label><figDesc></figDesc><table># relation types 

7 
20 

# candidate relations 

48,625 
68,822 

# gold relations 

4,296 
2,000 

# mentions per entity pair 

6 
11 

% mentions with +ve relations 

8.8% 
21% 

Physical (Phy), Personal/Social (Per), Employ-
ment/Membership/Subsidiary (Emp), Agent-
Artifact (Agt), PER/ORG Affiliation (Aff), GPE 
Affiliation (GPE) and Discourse (Dis). 
YAGO is an open information extraction data 
set. The relation types of YAGO are built from 
Wikipedia and WordNet, while the labeled text for 
YAGO is from </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 : The F 1 of different methods on ACE 2004 with k = 1 source domain. The best performance for each target domain is in bold.</head><label>2</label><figDesc></figDesc><table>Target 
In-domain 
NT 
NT-U L-SVM MTL DAB SCL DAM RDA 

BC 
55.74 
30.00 20.31 
32.42 
32.74 32.12 30.41 33.07 35.43 
BN 
67.24 
33.43 38.31 
35.40 
44.81 27.32 45.27 43.26 47.28 
NW 
68.32 
41.48 39.35 
41.50 
42.28 43.27 44.16 41.69 45.41 
CTS 
72.92 
36.60 29.90 
36.15 
45.06 37.50 44.68 39.40 44.27 
UN 
45.16 
21.67 17.55 
25.10 
18.69 18.78 28.77 26.57 31.07 
WL 
46.46 
28.53 23.84 
29.90 
26.13 24.78 23.71 27.01 30.80 

Average 
57.58 
31.95 28.21 
33.41 
35.02 30.46 29.57 33.50 39.00 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>The F 1 of different methods on ACE 2004 with k = 3 source domains. 
Target 
In-domain 
NT 
NT-U L-SVM MTL DAB SCL DAM RDA 

BC 
55.74 
30.00 24.55 
32.42 
35.26 34.12 37.83 36.08 39.43 
BN 
67.24 
33.43 38.31 
35.40 
49.76 32.15 49.25 45.89 51.28 
NW 
68.32 
41.48 43.35 
42.50 
43.28 43.71 44.16 44.01 46.41 
CTS 
72.92 
36.60 30.25 
36.15 
45.06 37.50 44.68 42.51 49.27 
UN 
45.16 
21.67 27.55 
25.10 
19.72 35.78 31.77 33.29 35.07 
WL 
46.46 
28.53 30.72 
30.90 
33.21 32.81 26.37 32.46 35.11 

Average 
57.58 
31.95 32.46 
34.20 
37.72 36.01 39.01 39.10 42.76 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>The F 1 of different methods on ACE 2004 with k = 5 source domains. 
Target 
In-domain 
NT 
NT-U L-SVM MTL DAB 
SCL DAM RDA 

BC 
55.74 
30.00 27.32 
33.07 
37.76 35.08 40.38 38.70 42.90 
BN 
67.24 
33.43 40.83 
36.42 
52.69 42.76. 50.47 48.23 53.40 
NW 
68.32 
41.48 44.35 
43.69 
47.80 44.09 45.50 46.06 49.13 
CTS 
72.92 
36.60 34.60 
38.90 
45.06 38.71 47.35 45.69 52.63 
UN 
45.16 
21.67 29.34 
26.34 
35.47 35.44 33.21 34.13 36.02 
WL 
46.46 
28.53 32.41 
31.56 
34.72 32.81 36.89 32.29 37.90 

Average 
57.58 
31.95 34.80 
35.0 
42.25 38.15 42.30 40.84 45.33 

negative transfer from irrelevant sources by rely-
ing on similarity of feature vectors between source 
and target domains based on labeled and unlabeled 
data. Further improvements can still be made, as 
shown by the better performance of RDA over L-
SVM and DAM. This is achieved by further ad-
justing the relevances between source and target 
domains according to regions in the target-domain 
input space. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 5 : The F 1 of different methods on YAGO with k = 5 source domains.</head><label>5</label><figDesc></figDesc><table>Target 
In-domain 
NT 
NT-U L-SVM MTL DAB SCL DAM RDA 

acquirer acquiree 

58.74 
32.12 33.19 
43.16 
45.28 39.08 44.19 45.07 51.15 

actedIn 

77.36 
40.73 44.32 
50.45 
57.18 49.61 58.23 56.37 63.40 

bornIn 

68.32 
42.39 40.35 
44.38 
49.80 48.36 50.67 48.12 56.93 

ceo company 

82.92 
47.60 51.27 
55.27 
61.06 58.33 57.41 59.08 66.71 

company headquarters 

75.16 
48.92 52.15 
50.13 
59.47 61.23 58.36 56.65 64.36 

created 

74.26 
46.37 43.58 
60.45 
60.74 55.08 59.42 57.34 65.28 

diedIn 

81.45 
42.78 47.37 
57.37 
62.69 57.16 65.28 60.44 71.15 

directed 

70.11 
44.42 48.29 
50.57 
54.29 49.09 52.31 50.30 57.71 

discovered 

68.13 
37.34 42.51 
48.77 
53.04 49.82 53.73 51.21 59.12 

graduatedFrom 

69.37 
39.28 45.74 
51.56 
58.22 54.38 56.32 51.17 60.37 

hasChild 

74.56 
49.14 50.98 
56.07 
64.82 53.41 62.38 61.12 66.83 

hasWonPrize 

69.41 
38.75 45.72 
53.47 
57.38 52.76 58.29 54.03 63.13 

isLeaderOf 

79.18 
46.31 52.66 
58.88 
63.49 60.27 63.75 61.51 70.27 

isMarriedTo 

73.33 
47.85 48.16 
52.31 
56.39 50.73 55.35 52.10 62.58 

livesIn 

66.93 
36.16 35.15 
40.28 
50.27 41.72 43.59 48.11 56.91 

participatedIn 

85.38 
46.22 48.33 
62.48 
67.51 61.08 65.38 61.12 71.72 

person birthplace 

77.62 
43.43 45.27 
49.66 
58.47 59.32 57.55 52.14 65.80 

person field 

68.32 
36.25 37.93 
47.69 
54.22 50.46 50.47 48.89 59.47 

politicianOf 

79.10 
39.17 42.25 
53.38 
64.56 62.11 60.74 58.82 68.12 

worksAt 

84.29 
45.78 49.78 
59.34 
65.33 65.44 66.53 63.24 73.31 

Average 
74.20 
42.55 45.25 
52.28 
58.21 53.97 56.80 54.84 63.72 

Performance Gap From </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Average F 1 of RDA on YAGO 

# source domains 
F 1 

k = 1 
53.81 
k = 3 
59.43 
k = 5 
63.72 
k = 10 
65.55 

</table></figure>

			<note place="foot" n="1"> The source code for extracting entity features is provided by the authors (Jiang and Zhai, 2007b).</note>

			<note place="foot" n="2"> For two-classes, though, only one function is needed. 3 http://www.mpi-inf.mpg.de/yago-naga/yago/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by DSO grant DSOCL10021.</p><p>We thank Jiang for provid-ing the source code for feature extraction and Bollegala for sharing his YAGO dataset.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Snowball: Extracting relations from large plain-text collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM conference on Digital libraries</title>
		<meeting>the fifth ACM conference on Digital libraries</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The tradeoffs between open and traditional relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Turing</forename><surname>Center</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
		<meeting>ACL-08: HLT</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Relation adaptation: learning to extract novel relations with minimum supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three</title>
		<meeting>the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2205" to="2210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Subsequence kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="171" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Head-Driven Statistical Models for Natural Language Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dependency tree kernels for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aron</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="423" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual meeting-association for computational linguistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to match the schemas of data sources: A multistrategy approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anhai</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="279" to="301" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain adaptation from multiple sources via auxiliary classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ivor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual ICML</title>
		<meeting>the 26th Annual ICML</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="68" to="74" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Instance weighting for domain adaptation in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting-Association For Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A systematic exploration of the feature space for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-task transfer learning for weakly-supervised relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the ACL</title>
		<meeting>the 47th Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1012" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Not all seeds are equal: Measuring the quality of text mining seeds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT: The 2010 Annual Conference of the North American Chapter of the ACL</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Laplacian support vector machines trained in the primal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Melacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1149" to="1184" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Effectiveness and efficiency of open relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><surname>Mesquita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Schmidek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-13</title>
		<meeting>EMNLP-13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="447" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonan</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="777" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via spectral feature alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochuan</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Organizing and searching the world wide web of facts-step one: The one-million fact extraction challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Bigham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Lifchits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alpa</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st National Conference on Artificial Intelligence</title>
		<meeting>the 21st National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1400" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Embedding semantic similarity in tree kernels for domain adaptation of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Exploiting constituent dependencies for tree kernel-based semantic relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longhua</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peide</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Linguistics</title>
		<meeting>the 22nd Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="697" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning dictionaries for information extraction by multi-level bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosie</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on AI</title>
		<meeting>the National Conference on AI</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="474" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">To transfer or not to transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvika</forename><surname>Michael T Rosenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas G</forename><surname>Pack Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2005 Workshop on Transfer Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">898</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Introduction to Modern Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>McGrawHill, Inc</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Preemptive information extraction using unrestricted relation discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Shinyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT Conference of the North American Chapter of the ACL</title>
		<meeting>the HLT Conference of the North American Chapter of the ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="304" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scholkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge unifying wordnet and wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Reducing wrong labels in distant supervision for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shingo</forename><surname>Takamatsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="721" to="729" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Boosting relation extraction with limited closed-world knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Linguistics</title>
		<meeting>the 23rd Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1354" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Filling knowledge base gaps for distant supervision of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael Hoffmann Le</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-13</title>
		<meeting>EMNLP-13</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="665" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A composite kernel to extract relations between entities with both flat and structured features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="825" to="832" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">Navin</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Statsnowball: a statistical approach to extracting entity relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiqing</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th international conference on World wide web</title>
		<meeting>the 18th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
