<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Word Embedding for Response-To-Text Assessment of Evidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
						</author>
						<title level="a" type="main">Word Embedding for Response-To-Text Assessment of Evidence</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="75" to="81"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3013</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Manually grading the Response to Text Assessment (RTA) is labor intensive. Therefore, an automatic method is being developed for scoring analytical writing when the RTA is administered in large numbers of classrooms. Our long-term goal is to also use this scoring method to provide formative feedback to students and teachers about students&apos; writing quality. As a first step towards this goal, in-terpretable features for automatically scoring the evidence rubric of the RTA have been developed. In this paper, we present a simple but promising method for improving evidence scoring by employing the word embedding model. We evaluate our method on corpora of responses written by upper elementary students.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In <ref type="bibr" target="#b4">Correnti et al. (2013)</ref>, it was noted that the 2010 Common Core State Standards emphasize the ability of young students from grades 4-8 to interpret and evaluate texts, construct logi- cal arguments based on substantive claims, and marshal relevant evidence in support of these claims. <ref type="bibr" target="#b4">Correnti et al. (2013)</ref> relatedly developed the Response to Text Assessment (RTA) for as- sessing students' analytic response-to-text writing skills. The RTA was designed to evaluate writing skills in Analysis, Evidence, Organization, Style, and MUGS (Mechanics, Usage, Grammar, and Spelling) dimensions. To both score the RTA and provide formative feedback to students and teach- ers at scale, an automated RTA scoring tool is now being developed ( <ref type="bibr" target="#b11">Rahimi et al., 2017)</ref>. This paper focuses on the Evidence dimension of the RTA, which evaluates students' ability to find and use evidence from an article to support their position. <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref> previously de- veloped a set of interpretable features for scoring the Evidence rubric of RTA. Although these fea- tures significantly improve over competitive base- lines, the feature extraction approach is largely based on lexical matching and can be enhanced.</p><p>The contributions of this paper are as follows. First, we employ a new way of using the word em- bedding model to enhance the system of <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>. Second, we use word embeddings to deal with noisy data given the disparate writing skills of students at the upper elementary level.</p><p>In the following sections, we first present re- search on related topics, describe our corpora, and review the interpretable features developed by <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>. Next, we explain how we use the word embedding model for feature extraction to improve performance by addressing the limita- tions of prior work. Finally, we discuss the results of our experiments and present future plans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Most research studies in automated essay scor- ing have focused on holistic rubrics <ref type="bibr" target="#b14">(Shermis and Burstein, 2003;</ref><ref type="bibr" target="#b0">Attali and Burstein, 2006</ref>). In contrast, our work focuses on evaluating a sin- gle dimension to obtain a rubric score for stu- dents' use of evidence from a source text to sup- port their stated position. To evaluate the content of students' essays, <ref type="bibr" target="#b7">Louis and Higgins (2010)</ref> pre- sented a method to detect if an essay is off-topic. <ref type="bibr" target="#b16">Xie et al. (2012)</ref> presented a method to evaluate content features by measuring the similarity be- tween essays. <ref type="bibr" target="#b2">Burstein et al. (2001)</ref> and <ref type="bibr" target="#b10">Ong et al. (2014)</ref> both presented methods to use argumen- tation mining techniques to evaluate the students' use of evidence to support claims in persuasive es- says. However, those studies are different from this work in that they did not measure how the es- say uses material from the source article. Further- more, young students find it difficult to use sophis- ticated argumentation structure in their essays. <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref> presented a set of inter- pretable rubric features that measure the related- ness between students' essays and a source article by extracting evidence from the students' essays. However, evidence from students' essays could not always be extracted by their word matching method. There are some potential solutions us- ing the word embedding model. <ref type="bibr" target="#b13">Rei and Cummins (2016)</ref> presented a method to evaluate topical relevance by estimating sentence similarity using weighted-embedding. Kenter and de Rijke (2015) evaluated short text similarity with word embed- ding. <ref type="bibr" target="#b6">Kiela et al. (2015)</ref> developed specialized word embedding by employing external resources. However, none of these methods address highly noisy essays written by young students.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>Our response-to-text essay corpora were all col- lected from classrooms using the following pro- cedure. The teacher first read aloud a text while students followed along with their copy. After the teacher explained some predefined vocabu- lary and discussed standardized questions at des- ignated points, there is a prompt at the end of the text which asks students to write an essay in re- sponse to the prompt. <ref type="figure" target="#fig_1">Figure 1</ref> shows the prompt of RT A M V P Two forms of the RTA have been developed, based on different articles that students read be- fore writing essays in response to a prompt. The first form is RT A M V P and is based on an arti- cle from Time for Kids about the Millennium Vil- lages Project, an effort by the United Nations to end poverty in a rural village in Sauri, Kenya. The other form is RT A Space , based on a developed ar- ticle about the importance of space exploration. Below is a small excerpt from the RT A M V P ar- ticle. Evidence from the text that expert human graders want to see in students' essays are in bold.</p><p>"Today, Yala Sub-District Hospital has medicine, free of charge, for all of the most common diseases. Water is con- nected to the hospital, which also has a generator for electricity. Bed nets are used in every sleeping site in Sauri." Two corpora of RT A M V P from lower and higher age groups were introduced in <ref type="bibr" target="#b4">Correnti et al. (2013)</ref>. One group included grades 4-6 (de- noted by M V P L ), and the other group included grades 6-8 (denoted by M V P H ). The students in each age group represent different levels of writing proficiency. We also combined these two corpora to form a larger corpus, denoted by M V P ALL . The corpus of the RT A Space is collected only from students of grades 6-8 (denoted by Space).</p><formula xml:id="formula_0">Space M V P L M V P H Score 1 538 535 317 (26%) (30%) (27%)<label>Score</label></formula><p>Based on the rubric criterion shown in <ref type="table" target="#tab_1">Table 2</ref>, the essays in each corpus were annotated by two raters on a scale of 1 to 4, from low to high. Raters are experts and trained undergraduates. Ta- ble 1 shows the distribution of Evidence scores from the first rater and the agreement (Kappa, and Quadratic Weighted Kappa) between two raters of the double-rated portion. All experiment perfor- mances will be measured by Quadratic Weighted Kappa between the score from prediction and the first rater. The reason to only use the score of the first rater is that the first rater graded more essays. <ref type="figure" target="#fig_1">Figure 1</ref> shows an essay with a score of 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Rubric Features</head><p>Based on the rubric criterion for the evidence di- mension, <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref> developed a set of interpretable features. By using this set of fea- tures, a predicting model can be trained for auto- mated essay scoring in the evidence dimension.</p><p>Number of Pieces of Evidence (NPE): A good essay should mention evidence from the article as much as possible. To extract the NPE feature, they manually craft a topic word list based on the arti- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">4 Number of Pieces of ev- idence</head><p>Features one or no pieces of evi- dence (NPE)</p><p>Features at least 2 pieces of evi- dence (NPE)</p><p>Features at least 3 pieces of evi- dence (NPE)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features at least 3 pieces of evi- dence (NPE) Relevance of evidence</head><p>Selects inappropriate or irrele- vant details from the text to sup- port key idea (SPC); references to text feature serious factual er- rors or omissions</p><p>Selects some appropriate and relevant evidence to support key idea, or evidence is provided for some ideas, but not actually the key idea (SPC); evidence may contain a factual error or omis- sion</p><p>Selects pieces of evidence from the text that are appropriate and relevant to key idea (SPC)</p><p>Selects evidence from the text that clearly and effectively sup- ports key idea Specificity of evidence Provides general or cursory evi- dence from the text (SPC)</p><p>Provides general or cursory evi- dence from the text (SPC)</p><p>Provides specific evidence from the text (SPC)</p><p>Provides pieces of evidence that are detailed and specific (SPC) Elaboration of Evidence Evidence may be listed in a sen- tence (CON)</p><p>Evidence provided may be listed in a sentence, not expanded upon (CON)</p><p>Attempts to elaborate upon evi- dence (CON)</p><p>Evidence must be used to sup- port key idea / inference(s)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Plagiarism</head><p>Summarize entire text or copies heavily from text (in these cases, the response automatically re- ceives a 1) cle. Then, they use a simple window-based algo- rithm with a fixed size window to extract this fea- ture. If a window contains at least two words from the topic list, they consider this window to contain evidence related to a topic. To avoid redundancy, each topic is only counted once. Words from the window and crafted list will only be considered a match if they are exactly the same. This feature is an integer to represent the number of topics that are mentioned by the essay. Concentration (CON): Rather than list all the topics in the essay, a good essay should explain each topic with details. The same topic word list and simple window-based algorithm are used for extracting the CON feature. An essay is concen- trated if the essay has fewer than 3 sentences that mention at least one of the topic words. Therefore, this feature is a binary feature. The value is 1 if the essay is concentrated, otherwise it is 0.</p><p>Specificity (SPC): A good essay should use rel- evant examples as much as possible. For matching SPC feature, experts manually craft an example list based on the article. Each example belongs to one topic, and is an aspect of a specific detail about the topic. For each example, the same window- based algorithm is used for matching. If the win- dow contains at least two words from an example, they consider the window to mention this exam- ple. Therefore, the SPC feature is an integer vec- tor. Each value in the vector represents how many examples in this topic were mentioned by the es- say. To avoid redundancy, each example is only to be counted at most one time. The length of the vector is the same as the number of categories of examples in the crafted list.</p><p>Word Count (WOC): The SPC feature can capture how many evidences were mentioned in the essay, but it cannot represent if these pieces of evidence support key ideas effectively. From pre- vious work, we know longer essays tend to have higher scores. Thus, they use word count as a po- tentially helpful fallback feature. This feature is an integer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Word Embedding Feature Extraction</head><p>Based on the results of <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>, the in- terpretable rubric-based features outperform com- petitive baselines. However, there are limitations in their feature extraction method. It cannot ex- tract all examples mentioned by the essay due to the use of simple exact matching.</p><p>First, students use their own vocabularies other than words in the crafted list. For instance, some students use the word "power" instead of "electric- ity" from the crafted list.</p><p>Second, according to our corpora, students at the upper elementary level make spelling mis- takes, and sometimes they make mistakes in the same way. For example, around 1 out of 10 stu- dents misspell "poverty" as "proverty" instead. Therefore, evidence with student spelling mistakes cannot be extracted. However, the evidence di- mension of RTA does not penalize students for misspelling words. <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref> showed that manual spelling corrections indeed improves performance, but not significantly.</p><p>Finally, tenses used by students can sometimes be different from that of the article. Although a stemming algorithm can solve this problem, some- times there are words that slip through the process.</p><p>Prompt: The author provided one spe- cific example of how the quality of life can be improved by the Millennium Vil- lages Project in Sauri, Kenya. Based on the article, did the author provide a con- vincing argument that winning the fight against poverty is achievable in our life- time? Explain why or why not with 3-4 examples from the text to support your answer.</p><p>Essay: In my opinion I think that they will achieve it in lifetime. During the years threw 2004 and 2008 they made progress. People didnt have the money to buy the stuff in 2004. The hospital was packed with patients and they didnt have alot of treatment in 2004. In 2008 it changed the hospital had medicine, free of charge, and for all the common dieases. Water was connected to the hospital and has a generator for electric- ity. Everybody has net in their site. The hunger crisis has been addressed with fertilizer and seeds, as well as the tools needed to maintain the food. The school has no fees and they serve lunch. To me thats sounds like it is going achieve it in the lifetime. For example, "went" is the past tense of "go", but stemming would miss this conjugation. Therefore, "go" and "went" would not be considered a match.</p><p>To address the limitations above, we introduced the Word2vec (the skip-gram (SG) and the con- tinuous bag-of-words (CBOW)) word embedding model presented by <ref type="bibr" target="#b8">Mikolov et al. (2013a)</ref> into the feature extraction process. By mapping words from the vocabulary to vectors of real numbers, the similarity between two words can be calcu- lated. Words with high similarity can be consid- ered a match. Because words in the same context tend to have similar meaning, they would therefore have higher similarity.</p><p>We use the word embedding model as a sup- plement to the original feature extraction process, and use the same searching window algorithm pre- sented by <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>. If a word in a stu- dent's essay is not exactly the same as the word in the crafted list, the cosine similarity between these two words is calculated by the word embed- ding model. We consider them matching, if the similarity is higher than a threshold.</p><p>In <ref type="figure" target="#fig_1">Figure 1</ref>, the phrases in italics are exam- ples extracted by the existing feature extraction method. For instance, "water was connected to the hospital" can be found because "water" and "hos- pital" are exactly the same as words in the crafted list. However, "for all the common dieases" can- not be found due to misspelling of "disease". Ad- ditional examples that can be extracted by the word embedding model are in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Setup</head><p>We configure experiments to test several hypothe- ses: H1) the model with the word embedding trained on our own corpus will outperform or at least perform equally well as the baseline (denoted by Rubric) presented by <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>. H2) the model with the word embedding trained on our corpus will outperform or at least perform equally well as the model with off-the-shelf word embed- ding models. H3) the model with word embedding trained on our own corpus will generalize better across students of different ages. Note that while all models with word embeddings use the same features as the Rubric baseline, the feature ex- traction process was changed to allow non-exact matching via the word embeddings.</p><p>We stratify each corpus into 3 parts: 40% of the data are used for training the word embedding models; 20% of the data are used to select the best word embedding model and best threshold (this is the development set of our model); and another 40% of data are used for final testing.</p><p>For word embedding model training, we also add essays not graded by the first rater (Space has 229, M V P L has 222, M V P H has 296, and M V P ALL has 518) to 40% of the data from the corpus in order to enlarge the training corpus to get better word embedding models. We train multi- ple word embedding models with different param- eters, and select the best word embedding model by using the development set.</p><p>Two off-the-shelf word embeddings are used for comparison. <ref type="bibr" target="#b9">Mikolov et al. (2013b)</ref> presented vec- tors that have 300 dimensions and were trained on a newspaper corpus of about 100 billion words. The other is presented by <ref type="bibr" target="#b1">Baroni et al. (2014)</ref> and includes 400 dimensions, with the context window size of 5, 10 negative samples and subsampling.</p><p>We use 10 runs of 10-fold cross validation in the final testing, with Random Forest (max-depth = 5) implemented in Weka ( <ref type="bibr" target="#b15">Witten et al., 2016</ref>) as the classifier. This is the setting used by <ref type="bibr" target="#b12">Rahimi et al. (2014)</ref>. Since our corpora are imbalanced with re- spect to the four evidence scores being predicted <ref type="table">(Table 1)</ref>, we use SMOTE oversampling method ( <ref type="bibr" target="#b3">Chawla et al., 2002</ref>). This involves creating "syn- thetic" examples for minority classes. We only oversample the training data. All experiment per- formances are measured by Quadratic Weighted Kappa (QWKappa).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results and Discussion</head><p>We first examine H1. The results shown in <ref type="table">Table 3</ref> partially support this hypothesis. The skip-gram embedding yields a higher performance or per- forms equally well as the rubric baseline on most corpora, except for M V P H . The skip-gram em- bedding significantly improves performance for the lower grade corpus. Meanwhile, the skip-gram embedding is always significantly better than the continuous bag-of-words embedding.</p><p>Second, we examine H2. Again, the results shown in <ref type="table">Table 3</ref> partially support this hypoth- esis. The skip-gram embedding trained on our corpus outperform Baroni's embedding on Space and M V P L . While Baroni's embedding is sig- nificantly better than the skip-gram embedding on M V P H and M V P ALL .</p><p>Third, we examine H3, by training models from one corpus and testing it on 10 disjointed sets of the other test corpus. We do it 10 times and av- erage the results in order to perform significance testing. The results shown in <ref type="table">Table 4</ref> support this hypothesis. The skip-gram word embedding model outperform all other models.</p><p>As we can see, the skip-gram embedding out- performs the continuous bag-of-words embedding in all experiments. One possible reason for this is that the skip-gram is better than the continu- ous bag-of-words for infrequent words <ref type="bibr" target="#b9">(Mikolov et al., 2013b</ref>). In the continuous bag-of-words, vectors from the context will be averaged before predicting the current word, while the skip-gram does not. Therefore, it remains a better represen- tation for rare words. Most students tend to use words that appear directly from the article, and only a small portion of students introduce their own vocabularies into their essays. Therefore, the word embedding is good with infrequent words and tends to work well for our purposes.</p><p>In examining the performances of the two off- the-shelf word embeddings, Mikolov's embed- ding cannot help with our task, because it has less preprocessing of its training corpus. There- fore, the embedding is case sensitive and contains symbols and numbers. For example, it matches "2015" with "000". Furthermore, its training cor- pus comes from newspapers, which may contain more high-level English that students may not use, and professional writing has few to no spelling mistakes. Although Baroni's embedding also has no spelling mistakes, it was trained on a corpus containing more genres of writing and has more preprocessing. Thus, it is a better fit to our work compared to Mikolov's embedding.</p><p>In comparing the performance of the skip-gram embedding and Baroni's embedding, there are many differences. First, even though the skip- gram embedding partially solves the tense prob- lem, Baroni's embedding solves it better because it has a larger training corpus. Second, the larger training corpus contains no or significantly fewer spelling mistakes, and therefore it cannot solve the spelling problem at all. On the other hand, the skip-gram embedding solves the spelling prob- lem better, because it was trained on our own corpus. For instance, it can match "proverty" with "poverty", while Baroni's embedding can- not. Third, the skip-gram embedding cannot ad- dress a vocabulary problem as well as the Ba- roni's embedding because of the small training corpus. Baroni's embedding matches "power" with "electricity", while the skip-gram embedding does not. Nevertheless, the skip-gram embedding still partially addresses this problem, for example, it matches "mosquitoes" with "malaria" due to re- latedness. Last, Baroni's embedding was trained on a corpus that is thousands of times larger than our corpus. However, it does not address our prob- lems significantly better than the skip-gram em- bedding due to generalization. In contrast, our task-dependent word embedding is only trained on a small corpus while outperforming or at least per- forming equally well as Baroni's embedding.</p><p>Overall, the skip-gram embedding tends to find examples by implicit relations. For instance, "win- ning against poverty possible achievable lifetime" is an example from the article and in the meantime Off-the-Shelf</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On Our Corpus</head><formula xml:id="formula_1">Corpus Rubric(1) Baroni(2) Mikolov(3) SG(4) CBOW(5) Space 0.606(2) 0.594 0.606(2) 0.611(2,5) 0.600(2) M V P L 0.628 0.666(1,3,5)</formula><p>0.623 0.682(1,2,3,5) 0.641(1,3) M V P H 0.599(3,4,5) 0.593(3,4,5) 0.582(5) 0.583(5) 0.556 M V P ALL 0.624(5) 0.645(1,3,4,5) 0.634(1,5) 0.634(1,5) 0.614 <ref type="table">Table 3</ref>: The performance (QWKappa) of the off-the-shelf embeddings and embeddings trained on our corpus compared to the rubric baseline on all corpora. The numbers in parenthesis show the model numbers over which the current model performs significantly better. The best results in each row are in bold.</p><p>Off-the-Shelf On Our Corpus <ref type="table">Table 4</ref>: The performance (QWKappa) of the off-the-shelf embeddings and embeddings trained on our corpus compared to the rubric baseline. The numbers in parenthesis show the model numbers over which the current model performs significantly better. The best results in each row are in bold.</p><formula xml:id="formula_2">Train Test Rubric(1) Baroni(2) Mikolov(3) SG(4) CBOW(5) M V P L M V P H 0.582(3) 0.609 (1,3,5) 0.555 0.615(1,2,3,5) 0.596(1,3) M V P H M V P L 0.604 0.629(1,3,5) 0.620(1,5) 0.644(1,2,3,5) 0.605</formula><p>the prompt asks students "Did the author provide a convincing argument that winning the fight against poverty is achievable in our lifetime?". Conse- quently, students may mention this example by only answering "Yes, the author convinced me.". However, the skip-gram embedding can extract this implicit example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>We have presented several simple but promising uses of the word embedding method that improve evidence scoring in corpora of responses to texts written by upper elementary students. In our re- sults, a task-dependent word embedding model trained on our small corpus was the most helpful in improving the baseline model. However, the word embedding model still measures additional information that is not necessary in our work. Im- proving the word embedding model or the feature extraction process is thus our most likely future endeavor.</p><p>One potential improvement is re-defining the loss function of the word embedding model, since the word embedding measures not only the simi- larity between two words, but also the relatedness between them. However, our work is not helped by matching related words too much. For exam- ple, we want to match "poverty" with "proverty", while we do not want to match "water" with "elec- tricity", even though students mention them to- gether frequently. Therefore, we could limit this measurement by modifying the loss function of the word embedding. <ref type="bibr" target="#b6">Kiela et al. (2015)</ref> presented a specialized word embedding by employing an ex- ternal thesaurus list. However, it does not fit to our task, because the list contains high-level English words that will not be used by young students.</p><p>Another area for future investigation is improv- ing the word embedding models trained on our corpus. Although they improved performance, they were trained on a corpus from one form of the RTA and tested on the same RTA. Thus, another possible improvement is generalizing the model- from one RTA to another RTA.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The prompt of RT A M V P and an example essay with score of 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Rubric for the Evidence dimension of RTA. The abbreviations in the parentheses identify the 
corresponding feature group discussed in the Rubric Features section of this paper that is aligned with 
that specific criteria (Rahimi et al., 2017). 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to show our appreciation to every member of the RTA group for sharing their pearls of wisdom with us. We are also immensely grate-ful to Dr. Richard Correnti, Deanna Prine, and Zahra Rahimi for their comments on an earlier ver-sion of the paper.</p><p>The research reported here was supported, in whole or in part, by the Institute of Education Sciences, U.S. Department of Education, through Grant R305A160245 to the University of Pitts-burgh. The opinions expressed are those of the authors and do not represent the views of the Insti-tute or the U.S. Department of Education.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automated essay scoring with e-rater R v. 2. The Journal of Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yigal</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning and Assessment</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germ√°n</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enriching automated essay scoring using discourse marking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Kukich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smote: synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">W</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">O</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Philip</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Assessing students&apos; skills at writing analytically in response to texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Correnti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsay</forename><forename type="middle">Clare</forename><surname>Matsumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaine</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Elementary School Journal</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="142" to="177" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Short text similarity with word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maarten De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1411" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Specializing word embeddings for similarity or relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2044" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Off-topic essay detection using short prompt texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</title>
		<meeting>the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="92" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ontology-based argument mining and automatic essay scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Brusilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="24" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Assessing students use of evidence and organization in response-to-text writing: Using natural language processing for rubric-based automated scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Correnti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaine</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsay</forename><forename type="middle">Clare</forename><surname>Matsumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic scoring of an analytical responseto-text assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Correnti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsay</forename><forename type="middle">Clare</forename><surname>Matsumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaine</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahid</forename><surname>Kisa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Tutoring Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Sentence similarity measures for fine-grained estimation of topical relevance in learner essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Cummins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Automated essay scoring: A cross-disciplinary perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><forename type="middle">C</forename><surname>Shermis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Data Mining: Practical machine learning tools and techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Ian H Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploring content features for automated speech scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keelan</forename><surname>Evanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Zechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="103" to="111" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
