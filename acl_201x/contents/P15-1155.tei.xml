<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Salient Updates for Disaster Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Kedzie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
							<email>fdiaz@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Columbia University</orgName>
								<orgName type="institution" key="instit2">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Salient Updates for Disaster Summarization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1608" to="1617"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>During crises such as natural disasters or other human tragedies, information needs of both civilians and responders often require urgent, specialized treatment. Monitoring and summarizing a text stream during such an event remains a difficult problem. We present a system for update sum-marization which predicts the salience of sentences with respect to an event and then uses these predictions to directly bias a clustering algorithm for sentence selection , increasing the quality of the updates. We use novel, disaster-specific features for salience prediction, including geo-locations and language models representing the language of disaster. Our evaluation on a standard set of retrospective events using ROUGE shows that salience prediction provides a significant improvement over other approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During crises, information is critical for first re- sponders, crisis management organizations, and those caught in the event. When the event is sig- nificant, as in the case of Hurricane Sandy, the amount of content produced by traditional news outlets, government agencies, relief organizations, and social media can vastly overwhelm those try- ing to monitor the situation. Crisis informatics ( <ref type="bibr" target="#b21">Palen et al., 2010</ref>) is dedicated to finding methods for sharing the right information in a timely fash- ion during such an event. Research in this field has focused on human-in-the-loop approaches rang- ing from on the ground information gathering to crowdsourced reporting and disaster management <ref type="bibr" target="#b25">(Starbird and Palen, 2013)</ref>.</p><p>Multi-document summarization has the poten- tial to assist the crisis informatics community. Au- tomatic summarization could deliver relevant and salient information at regular intervals, even when human volunteers are unable to. Perhaps more im- portantly it could help filter out unnecessary and irrelevant detail when the volume of incoming in- formation is large. While methods for identifying, tracking, and summarizing events from text based input have been explored extensively ( <ref type="bibr" target="#b0">Allan et al., 1998;</ref><ref type="bibr" target="#b5">Filatova and Hatzivassiloglou, 2004;</ref><ref type="bibr" target="#b28">Wang et al., 2011)</ref>, these experiments were not devel- oped to handle streaming data from a heteroge- neous environment at web scale. These methods also rely heavily on redundancy which is subop- timal for time sensitive domains where there is a high cost in delaying information.</p><p>In this paper, we present an update summariza- tion system to track events across time. Our sys- tem predicts sentence salience in the context of a large-scale event, such as a disaster, and integrates these predictions into a clustering based multi- document summarization system. We demonstrate that combining salience with clustering produces more relevant summaries compared to baselines using clustering or relevance alone. Our experi- ments suggest that this is because our system is better able to adapt to dynamic changes in input volume that adversely affect methods that use re- dundancy as a proxy for salience.</p><p>In addition to the tight integration between clus- tering and salience prediction, our approach also exploits knowledge about the event to determine salience. Thus, salience represents both how typi- cal a sentence is of the event type (e.g., industrial accident, hurricane, riot) and whether it specifies information about this particular event. Our fea- ture representation includes a set of language mod- els, one for each event type, to measure the typi- cality of the sentence with regard to the current event, the distance of mentioned locations from the center of the event, and the change in word frequencies over the time of the event. While we evaluate these features in the domain of disasters, this approach is generally applicable to many up- date summarization tasks.</p><p>Our approach achieves a statistically significant improvement in ROUGE scores compared to mul- tiple baselines. Additionally, we introduce novel methods for estimating the average information gain each update provides and how completely the update summary covers the event it is tracking; our system's updates contain more relevant informa- tion on average than the competing baselines.</p><p>The remainder of the paper is organized as fol- lows. We begin with a review of related work in the information retrieval and multi-document summarization literature. Section 3 outlines the details of our salience and summarization models. Next we describe our data (Section 4) and experi- ments (Section 5). Finally, we discuss our results (Section 6) and conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A principal concern in extractive multi-document summarization is the selection of salient sentences for inclusion in summary output <ref type="bibr" target="#b19">(Nenkova and McKeown, 2012)</ref>. Existing approaches generally fall into one of three categories, each with specific trade-offs with respect to update summarization.</p><p>First, centrality-focused approaches (including graph ( <ref type="bibr" target="#b3">Erkan and Radev, 2004</ref>), cluster <ref type="bibr" target="#b12">(Hatzivassiloglou et al., 2001</ref>), and centroid ( ) methods) are very natural for retrospective analysis in the sense that they let the data "speak for itself." These methods equate salience with centrality, either to the input or some other ag- gregate object (i.e. a cluster center or input cen- troid). However, they rely chiefly on redundancy. When applied to an unfolding event, there may not exist enough redundant content at the event onset for these methods to exploit. Once the event onset has passed, however, the redundancy reduction of these methods is quite beneficial.</p><p>The second category, predictive approaches, in- cludes ranking and classification based methods. Sentences have been ranked by the average word probability, average TF*IDF score, and the num- ber of topically related words (topic-signatures in the summarization literature) <ref type="bibr" target="#b20">(Nenkova and Vanderwende, 2005;</ref><ref type="bibr" target="#b13">Hovy and Lin, 1998;</ref><ref type="bibr" target="#b16">Lin and Hovy, 2000</ref>). The first two statistics are easily computable from the input sentences, while the third only requires an additional, generic back- ground corpus. In classification based methods, model features are usually derived from human generated summaries, and are non-lexical in na- ture (e.g., sentence starting position, number of topic-signatures, number of unique words). Sem- inal work in this area has employed na¨ıvena¨ıve Bayes and logistic regression classifiers to identify sen- tences for summary inclusion ( <ref type="bibr" target="#b14">Kupiec et al., 1995;</ref><ref type="bibr" target="#b2">Conroy et al., 2001</ref>). While these methods are less dependent on redundancy, the expressiveness of their features is limited. Our model expands on these basic features to account for geographic, temporal, and language model features.</p><p>The last category includes probabilistic ( <ref type="bibr" target="#b11">Haghighi and Vanderwende, 2009)</ref>, information theoretic, and set cover (Lin and Bilmes, 2011) approaches. While these methods are focused on producing diverse summaries, they are difficult to adapt to the streaming setting, where we do not necessarily have a fixed summary length and the corpus to be summarized contains many irrelevant sentences, i.e. there are large portions of the corpora that we specifically want to avoid.</p><p>Several researchers have recognized the impor- tance of summarization during natural disasters. ( <ref type="bibr" target="#b10">Guo et al., 2013</ref>) developed a system for detect- ing novel, relevant, and comprehensive sentences immediately after a natural disaster. ( <ref type="bibr" target="#b27">Wang and Li, 2010</ref>) present a clustering-based approach to efficiently detect important updates during natural disasters. The algorithm works by hierarchically clustering sentences online, allowing the system to output a more expressive narrative structure than ( <ref type="bibr" target="#b10">Guo et al., 2013)</ref>. Our system attempts to unify these system's approaches (predictive ranking and clustering respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Our update summarization system takes as input a) a short query defining the event to be tracked (e.g. 'Hurricane Sandy'), b) an event category defining the type of event to be tracked (e.g. 'hur- ricane'), c) a stream of time-stamped documents presented in temporal order, and d) an evaluation time period of interest. While processing docu- ments throughout the time period of interest, the system outputs sentences from these documents likely to be useful to the query issuer. We refer to these selected sentences as updates.</p><p>In order to measure the usefulness of a sys- tem's updates, we consider the degree to which the system output reflects the different aspects of -hurricane force wind warnings are in effect from Rhode Island Sound to Chincoteague Bay -over 5000 commercial airline flights sched- uled for October 28 and October 29 were cancelled an event. Events are often composed of a vari- ety of sub-events. For example, the Hurricane Sandy event includes sub-events related to the storm making landfall, the ensuing flooding, the many transportation issues, among many others. An ideal system would update the user about each of these sub-events as they occur. We refer to these sub-events as the nuggets associated with an event. A nugget is defined as a fine-grained atomic sub-event associated with an event. We present 2 example nuggets associated with the Hurricane Sandy event in <ref type="figure" target="#fig_0">Figure 1</ref>. Each event has anywhere from 50 to several hundred nuggets in total in our gold dataset. We describe how these nuggets are found in Section 4.</p><p>Throughout our treatment of our algorithm, the salience of an update captures the degree to which it reflects an event's unobserved nuggets. Assum- ing that we have a text representation for each of our nuggets, the salience of an update u with re- spect to a set of nuggets N is defined as,</p><formula xml:id="formula_0">salience(u) = max n∈N sim(u, n) (1)</formula><p>where sim(·) is the semantic similarity such as the cosine similarity of latent vectors associated with the update and nugget text (Guo and Diab, 2012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Update Summarization</head><p>Our system architecture follows a simple pipeline design where each stage provides an additional level of processing or filtering of the input sen- tences. We begin with an empty update summary U . At each hour we receive a new batch of sen- tences b t from the stream of event relevant docu- ments and perform the following actions:</p><p>1. predict the salience of sentences in b t (Sec- tion 3.2),</p><p>2. select a set of exemplar sentences in b t by combining clustering with salience predic- tions (Section 3.3),</p><p>3. add the most novel and salient exemplars to U (Section 3.4).</p><p>The resultant list of updates U is our summary of the event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Salience Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Features</head><p>We want our model to be predictive of sen- tence salience across different event instances so we avoid event-specific lexical features. In- stead, we extract features such as language model scores, geographic relevance, and temporal rele- vance from each sentence. Basic Features We employ several basic fea- tures that have been used previously in supervised models to rank sentence salience ( <ref type="bibr" target="#b14">Kupiec et al., 1995;</ref><ref type="bibr" target="#b2">Conroy et al., 2001</ref>). These include sen- tence length, the number of capitalized words nor- malized by sentence length, document position, and number of named entities. The data stream comprises text extracted from raw html docu- ments; these features help to downweight sen- tences that are not content (e.g. web page titles, links to other content) or more heavily weight im- portant sentences (e.g., that appear in prominent positions such as paragraph initial or article ini- tial).</p><p>Query Features Query features measure the relationship between the sentence and the event query and type. These include the number of query words present in the sentence in addition to the number of event type synonyms, hypernyms, and hyponyms using WordNet <ref type="bibr" target="#b18">(Miller, 1995)</ref>. For example, for event type earthquake, we match sen- tence terms "quake", "temblor", "seism", and "af- tershock".</p><p>Language Model Features Language models allow us to measure the likelihood of producing a sentence from a particular source. We consider two types of language model features. The first model is estimated from a corpus of generic news articles (we used the 1995-2010 Associated Press section of the Gigaword corpus ( <ref type="bibr" target="#b8">Graff and Cieri, 2003)</ref>). This model is intended to assess the gen- eral writing quality (grammaticality, word usage) of an input sentence and helps our model to select sentences written in the newswire style.</p><p>The second model is estimated from text spe- cific to our event types. For each event type we create a corpus of related documents using pages and subcategories listed under a related Wikipedia category. For example, the language model for event type 'earthquake' is estimated from Wikipedia pages under the category Cate- gory:Earthquakes. <ref type="figure" target="#fig_1">Fig. 2</ref> lists the event types found in our dataset. These models are intended to detect sentences similar to those appearing in summaries of other events in the same category (e.g. most earthquake summaries are likely to in- clude higher probability for ngrams including the token 'magnitude'). While we focus our system on the language of news and disaster, we emphasize that the use of language modeling can be an effec- tive feature for multi-document summarization for other domains that have related text corpora. We use the SRILM toolkit ( <ref type="bibr">Stolcke and others, 2002</ref>) to implement a 5-gram Kneser-Ney model for both the background language model and the event specific language models. For each sentence we use the average token log probability under each model as a feature.</p><p>Geographic Relevance Features The disasters in our corpus are all phenomena that affect some part of the world. Where possible, we would like to capture a sentence's proximity to the event, i.e. when a sentence references a location, it should be close to the area of the disaster.</p><p>There are two challenges to using geographic features. First, we do not know where the event is, and second, most sentences do not contain refer- ences to a location. We address the first issue by extracting all locations from documents relevant to the event at the current hour and looking up their latitude and longitude using a publicly available geo-location service. Since the documents that are at least somewhat relevant to the event, we assume in aggregate the locations should give us a rough area of interest. The locations are clustered and we treat the resulting cluster centers as the event locations for the current time.</p><p>The second issue arises from the fact that the majority of sentences in our data do not contain explicit references to locations, i.e. a sequence of tokens tagged as location named entities. Our in- tuition is that geographic relevance is important in the disaster domain, and we would like to take ad- vantage of the sentences that do have location in- formation present. To make up for this imbalance, we instead compute an overall location for the document and derive geographic features based on the document's proximity to the event in question. These features are assigned to all sentences in the document.</p><p>Our method of computing document-level ge- ographic relevance features is as follows. Using the locations in each document, we compute the median distance to the nearest event location. Be- cause document position is a good indicator of im- portance we also compute the distance of the first mentioned location to the nearest event location. All sentences in the document take as features these two distance calculations. Because some events can move, we also compute these distances to event locations from the previous hour.</p><p>Temporal Relevance Features As we track events over time, it is likely that the coverage of the event may die down, only to spike back up when there is a breaking development. Identify- ing terms that are "bursty," i.e. suddenly peaking in usage, can help to locate novel sentences that are part of the most recent reportage and have yet to fall into the background.</p><p>We compute the IDF for each hour in our data stream. For each sentence, the average TF*IDF for the current hour t is taken as a feature. Addi- tionally, we use the difference in average TF*IDF from time t to t − i for i = {1, . . . , 24} to mea- sure how the TF*IDF scores for the sentence have changed over the last 24 hours, i.e. we keep the sentence term frequencies fixed and compute the difference in IDF. Large changes in IDF value in- dicate the sentence contains bursty terms. We also use the time (in hours) since the event started as a feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Model</head><p>Given our feature representation of the input sen- tences, we need only target salience values for model learning. For each event in our training data, we sample a set of sentences and each sen- tence's salience is computed according to Equa- tion 1. This results in a training set of sen- tences, their feature representations, and their tar- get salience values to predict.</p><p>We opt to use a Gaussian process (GP) re- gression model <ref type="bibr" target="#b23">(Rasmussen and Williams, 2006</ref>) with a Radial Basis Function (RBF) kernel for the salience prediction task. Our features fall naturally into five groups and we use a separate RBF kernel for each, using the sum of each feature group RBF kernel as the final input to the GP model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Exemplar Selection</head><p>Once we have predicted the salience for a batch of sentences, we must now select a set of update candidates, i.e. sentences that are both salient and representative of the current batch. To accomplish this, we combine the output of our salience pre- diction model with the affinity propagation algo- rithm. Affinity propagation (AP) is a clustering algorithm that identifies a subset of data points as exemplars and forms clusters by assigning the re- maining points to one of the exemplars <ref type="bibr" target="#b7">(Frey and Dueck, 2007)</ref>. AP attempts to maximize the net similarity objective</p><formula xml:id="formula_1">S = n i:i =e i sim(i, e i ) + n i:i=e i salience(e i )</formula><p>where e i is the exemplar of the i-th data point, and functions sim and salience express the pairwise similarity of data points and our predicted apri- ori preference of a data point to be an exemplar respectively. AP differs from other k-centers algo- rithms in that it simultaneously considers all data points as exemplars, making it less prone to find- ing local optima as a result of poor initialization. Furthermore, the second term in S incorporates the individual importance of data points as candi- date exemplars; most other clustering algorithms only make use of the first term, i.e. the pairwise similarities between data points. AP has several useful properties and interpre- tations. Chiefly, the number of clusters k is not a model hyper-parameter. Given that our task re- quires clustering many batches of streaming data, searching for an optimal k would be computation- ally prohibitive. With AP, k is determined by the similarities and preferences of the data. Generally lower preferences will result in fewer clusters.</p><p>Recall that salience(s) is a prediction of the semantic similarity of s to information about the event be summarized, i.e. the set of event nuggets. Intuitively, when maximizing objective function S, AP must balance between best representing the input data and representing the most salient in- put. Additionally, when the level of input is high but the salience predictions are low, the preference term will guide AP toward a solution with fewer clusters; vice-versa when input is very salient on average but the volume of input is low. The adap- tive nature of our model differentiates our method from most other update summarization systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Update Selection</head><p>The exemplar sentences from the exemplar selec- tion stage are the most salient and representative of the input for the current hour. However, we need to reconcile these sentences with updates from the previous hour to ensure that the most salient and least redundant updates are selected. To ensure that only the most salient updates are selected we apply a minimum salience threshold; after exem- plar sentences have been identified, any exemplars whose salience is less than λ sal are removed from consideration.</p><p>Next, to prevent adding updates that are redun- dant with previous output updates, we filter out ex- emplars that are too similar to previous updates. The exemplars are examined sequentially in order of decreasing salience and a similarity threshold is applied, where the exemplar is ignored if its max- imum semantic similarity to any previous updates in the summary is greater than λ sim .</p><p>Exemplars that pass these thresholds are se- lected as updates and added to the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>For the document stream, we use the news portion of the 2014 TREC KBA Stream Corpus ( <ref type="bibr" target="#b6">Frank et al., 2012</ref>). The documents from this corpus come from hourly crawls of the web covering October 2011 through February 2013.</p><p>Our experiments also make use of the TREC Temporal Summarization (TS) Track data from <ref type="bibr">and 2014</ref><ref type="bibr" target="#b1">(Aslam et al., 2013</ref>. This data in- cludes 25 events and event metadata (e.g., a user search query for the event, the event type, and event evaluation time frame). All events occurred during the time span of the TREC KBA Stream Corpus. For each event we create a stream of rel- evant documents by selecting only documents that contain the complete set of query words.</p><p>Along with the metadata, NIST assessors con- structed a set of ground truth nuggets for each event. Nuggets are brief and important text snip- pets that represent sub-events that should be con- veyed by an ideal update summary. In order to ac- complish this, for each event, assessors were pro- vided with the revision history of the Wikipedia page associated with the event. For example, the revision history for the Wikipedia page for 'Hurri- cane Sandy' will contain text additions including those related to individual nuggets. The assess- ment task involves reviewing the Wikipedia revi- sions in the evaluation time frame and marking the text additions capturing a new, unique nugget. More detail on this process can be found in the track description <ref type="bibr" target="#b1">(Aslam et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We evaluate our system on two metrics: ROUGE <ref type="bibr" target="#b17">(Lin, 2004</ref>), an automatic summarization method and an evaluation of system expected gain and comprehensiveness-metrics adapted from the TREC TS track <ref type="bibr" target="#b1">(Aslam et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training and Testing</head><p>Of the 25 events in the TREC TS data, 24 are covered by the news portion of the TREC KBA Stream Corpus. From these 24, we set aside three events to use as a development set. All system salience and similarity threshold parame- ters are tuned on the development set to maximize ROUGE-2 F1 scores.</p><p>We train a salience model for each event us- ing 1000 sentences randomly sampled from the event's document stream.</p><p>We perform a leave-one-out evaluation of each event. At test time, we predict a sentence's salience using the average predictions of the 23 other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ROUGE Evaluation</head><p>ROUGE measures the ngram overlap between a model summary and an automatically gener- ated system summary. Model summaries for each event were constructed by concatenating the event's nuggets. Generally, ROUGE evaluation assumes both model and system summaries are of a bounded length. Since our systems are summa- rizing events over a span of two weeks time, the total length of our system output is much longer than the model. To address this, for each sys- tem/event pair, we sample with replacement 1000 random summaries of length less than or equal to the model summary (truncating the last sentence when neccessary). The final ROUGE scores for the system are the average scores from these 1000 samples.</p><p>Because we are interested in system perfor- mance over time, we also evaluate systems at 12 hour intervals using the same regime as above. The model summaries in this case are retrospec- tive, and this evaluation reveals how quickly sys- tems can cover information in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Expected Gain and Comprehensiveness</head><p>NIST developed metrics for evaluating update summarization systems as part of the TREC TS track. We present results on two of these metrics, the expected gain and comprehensiveness.</p><p>Expected Gain We treat the event's nuggets as unique units of information. When a system adds an update to its summary, it is potentially adding some of this nugget information. It would be in- structive to know how much unique and novel in- formation each update is adding on average to the summary. To that end, we define</p><formula xml:id="formula_2">E[Gain] = |S n | |S|</formula><p>where S is the set of system updates, S n is the set of nuggets contained in S, and | · | is the number of elements in the set. To compute the set S n we match each system update to 0 or more nuggets, where an update matches a nugget if their seman- tic similarity is above a threshold. S n results from the unique set of nuggets matched. Because an update can map to more than one nugget, it is pos- sible to receive an expected gain greater than 1. An expected gain of 1 would indicate that every sentence was both relevant and contained a unique piece of information.</p><p>Comprehensiveness Additionally, we can use the nuggets to measure the completeness of an up- date summary. We define</p><formula xml:id="formula_3">Comprehensiveness = |S n | |N |</formula><p>where N is the set of event nuggets. A compre- hensiveness of 1 indicates that the summary has covered all nugget information for the event; the maximum attainable comprehensiveness is 1. Update-nugget matches are computed automat- ically; a match exists if the semantic similarity of the update/nugget pair is above a threshold. De- termining an optimal threshold to count matches is difficult so we evaluate at threshold values rang- ing from .5 to 1, where values closer to 1 are more conservative estimates of performance. A manual inspection of matches suggests that se- mantic similarity values around .7 produce reason- able matches. The average semantic similarity of manual matches performed by NIST assessors was much lower at approximately .25, increasing our confidence in the automatic matches in the .5-1 range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Model Comparisons</head><p>We refer to our complete model as AP+SALIENCE.</p><p>We compare this model against several variants and baselines intended to measure the contribution of different components. All thresholds for all runs are tuned on the development set.</p><p>Affinity Propagation only (AP) The purpose of this model is to directly measure the effect of integrating salience and clustering by providing a baseline that uses the identical clustering compo- nent, but without the salience information. In this model, input sentences are apriori equally likely to be exemplars; the salience values are uniformly set as the median value of the input similarity scores, as is commonly used in the AP literature <ref type="bibr" target="#b7">(Frey and Dueck, 2007)</ref>. After clustering a sen- tence batch, the exemplars are examined in order of increasing time since event start and selected as updates if their maximum similarity to the pre- vious updates is less than λ sim , as in the novelty filtering stage of AP+SALIENCE.</p><p>Hierarchichal Agglomerative Clustering (HAC) We provide another clustering baseline, single-linkage hierarchichal agglomerative clus- tering. We include this baseline to show that AP+SALIENCE is not just an improvement over AP but centrality driven methods in general. HAC was chosen over other clustering ap- proaches because the number of clusters is not an explicit hyper-parameter. To produce flat clusters from the hierarchical clustering, we flatten the HAC dendrogram using the cophenetic distance criteria, i.e. observations in each flat cluster have no greater a cophenetic distance than a threshold. Cluster centers are determined to be the sentence with highest cosine similariy to the flat cluster mean. Cluster centers are examined in time order and are added to the summary if their similarity to previous updates is below a similarity threshold λ sim as is done in the AP model.</p><p>Rank by Salience (RS) We also isolate the im- pact of our salience model in order to demonstrate that the fusion of clustering and salience predic- tion improves over predicting salience alone. In this model we predict the salience of sentences as in step 1 for AP+SALIENCE. We omit the cluster- ing phase (step 2). Updates are selected identically to step 3 of AP+SALIENCE, proceeding in order of decreasing salience, selecting updates that are above a salience threshold λ sal and below a simi- larity threshold λ sim with respect to the previously selected updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">ROUGE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROUGE-1 System</head><p>Recall Prec.  <ref type="table">Table 1</ref>: System ROUGE performance. <ref type="table">Table 1</ref> shows our results for system output samples against the full summary of nuggets us- ing ROUGE. This improvement is statistically sig- nificant for all ngram precision, recall, and F- measures at the α = .01 level using the Wilcoxon signed-rank test.</p><p>AP+SALIENCE maintains its performance above the baselines over time as well. <ref type="figure">Fig- ure 3</ref> shows the ROUGE-1 scores over time. We show the difference in unigram precision (bigram precision is not shown but it follows similar curve). Within the initial days of the event, AP+SALIENCE is able to take the lead over the over systems in ngram precision. The AP+SALIENCE model is better able to find salient updates earlier on; for the disaster domain, this is an especially important quality of the model. Moreover, the AP+SALIENCE's recall is not di- minished by the high precision and remains com- petitive with AP. Over time AP+SALIENCE's re- call also begins to pull away, while the other mod- els start to suffer from topic drift. Predicting salience in general is helpful for keep- ing a summary on topic as the RS approach out performs the clustering only approaches on ex- pected gain. When looking at the comprehensiveness of the summaries AP outperforms AP+SALIENCE. The compromise encoded in the AP+SALIENCE ob- jective function, between being representative and being salient, is seen clearly here where the per- formance of the AP+SALIENCE methods is lower bounded by the salience focused RS system and upper bounded by the clustering only AP system. Overall, AP+SALIENCE achieves the best balance of these two metrics. <ref type="table" target="#tab_1">Table 2</ref> shows the results of our feature ablation tests. Removing the language models yields a statistically significant drop in both ngram recall and F-measure. Interestingly, removing the ba- sic features leads to an increase in both unigram and bigram precision; in the bigram case this is enough to cause a statistically significant increase in F-measure over the full model. In other words, the generic features actually lead to an inferior model when we can incorporate more appropri- ate domain specific features. The result mirrors Sparck Jones' claim that generic approaches to summarization cannot produce a useful summary <ref type="bibr" target="#b24">(Sparck-Jones, 1998)</ref>. Removing the language model and geographic relevance features leads to a statistically signifi- cant drop in ROUGE-1 F1 scores. Unfortunately, this is not the case for the temporal relevance features. We surmise that these features are too strongly correlated with each other, i.e. the differ- ences in TF*IDF between hours are definitely not i.i.d. variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Expected Gain and Comprehensiveness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Feature Ablation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we have presented an update sum- marization system for the disaster domain, and demonstrated improved system performance by integrating sentence salience with clustering.</p><p>We also have shown that features specifically targeted to the domain of disaster yield better sum- maries. We developed novel features that capture the language typical of different event types and that identify sentences specific to the particular disaster based on location.</p><p>In the future we would like to explore the appli- The fire broke out when people in the building were trying to start their generator after the electricity went out.</p><p>• Pakistani television showed pictures of what appeared to be a three-story building with flames leaping from the top-floor windows and smoke billowing into the night sky.</p><p>• The people went to the back side of the building but there was no access, so we had to made forceful entries and rescue the people, said Numan Noor, a firefighter on the scene.</p><p>• "We have recovered 63 bodies, including three found when we reached the basement of the building," Karachi fire chief Ehtesham Salim told AFP on Wednesday.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2012">Romanian Protests</head><p>• Clashes between riot police and demonstrators have also erupted in the Romanian capital Bucharest for a third day in a row.</p><p>• BOC urged Romanians to understand that tough austerity measures are needed to avoid a default.</p><p>• More than 1,000 protesters rallied in Bucharest's main university square, blocking traffic.</p><p>• Bucharest : a Romanian medical official says 59 people suffered injuries as days of protests against the government and austerity measures turned violent.</p><p>Figure 5: AP+SALIENCE summary excerpts.  † indicates statistically significant difference from full model at the α = .05 level. † † indicates sta- tistically significant difference from full model at the α = .01 level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROUGE-1</head><p>cation of the AP+SALIENCE model and features to a wider class of events.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example nuggets from Hurricane Sandy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: TREC TS event types.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 shows the expected gain across a range of similarity thresholds,Figure 3 :</head><label>43</label><figDesc>Figure 4 shows the expected gain across a range of similarity thresholds, where thresholds closer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Expected Gain and Comprehensiveness performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>•</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Feature ablation ROUGE performance.</head><label>2</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>The research described here was supported in part by the National Science Foundation (NSF) under IIS-1422863. Any opinions, findings and conclu-sions or recommendations expressed in this paper are those of the authors and do not necessarily re-flect the views of the NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Topic detection and tracking pilot study final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Yamron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Trec 2013 temporal summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javed</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Ekstrand-Abueg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virgil</forename><surname>Pavlu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernado</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Sakai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Text Retrieval Conference (TREC), November</title>
		<meeting>the 22nd Text Retrieval Conference (TREC), November</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Using hmm and logistic regression to generate extract summaries for duc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">D</forename><surname>James M Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">E</forename><surname>Po Dianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Okurowski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir R Radev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lexrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res.(JAIR)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="457" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Event-based extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Filatova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Workshop on Summarization</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Building an entity-centric stream filtering test collection for trec 2012</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>John R Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Daniel A Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soboroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>DTIC Document</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Clustering by passing messages between data points. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delbert</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dueck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">English gigaword corpus. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple unsupervised latent semantics based approach for sentence similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Semantic Evaluation</title>
		<meeting>the Sixth International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="586" to="590" />
		</imprint>
	</monogr>
	<note>Proceedings of the main conference and the shared task, and</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Updating users about time critical events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Yom-Tov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<editor>Pavel Serdyukov, Pavel Braslavski, SergeiO. Kuznetsov, Jaap Kamps, Stefan Rüger, Eugene Agichtein, Ilya Segalovich, and Emine Yilmaz</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">7814</biblScope>
			<biblScope unit="page" from="483" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Exploring content models for multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="362" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simfinder: A flexible clustering tool for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><forename type="middle">L</forename><surname>Holcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Workshop on Automatic Summarizatio</title>
		<meeting>the NAACL Workshop on Automatic Summarizatio</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated text summarization and the summarist system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of a workshop on</title>
		<meeting>a workshop on<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1998-10-13" />
			<biblScope unit="page" from="197" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A trainable document summarizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francine</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 18th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A class of submodular functions for document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="510" to="520" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The automated acquisition of topic signatures for text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th conference on Computational linguistics</title>
		<meeting>the 18th conference on Computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="495" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A survey of text summarization techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mining Text Data</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="43" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The impact of frequency on summarization. Microsoft Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<idno>MSR-TR- 2005-101</idno>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Redmond, Washington</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A vision for technologymediated support for public participation &amp; assistance in mass emergencies &amp; disasters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leysia</forename><surname>Palen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gloria</forename><surname>Kenneth M Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Sicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grunwald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM-BCS visions of computer science conference</title>
		<meeting>the 2010 ACM-BCS visions of computer science conference</meeting>
		<imprint>
			<publisher>British Computer Society</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Centroid-based summarization of multiple documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Dragomir R Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Małgorzata</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sty´ssty´s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="919" to="938" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Gaussian Processes for Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">Edward</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic summarizing: factors and directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Sparck-Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in automatic text summarization</title>
		<editor>Mani and Maybury</editor>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Working and sustaining the virtual disaster desk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Starbird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leysia</forename><surname>Palen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on Computer supported cooperative work</title>
		<meeting>the 2013 conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="491" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Document update summarization using incremental hierarchical clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingding</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM &apos;10</title>
		<meeting>the 19th ACM international conference on Information and knowledge management, CIKM &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="279" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Identifying event descriptions using co-training with online news summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of IJCNLP</title>
		<meeting>IJCNLP<address><addrLine>Chiang-Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
