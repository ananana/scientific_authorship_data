<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:23+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Compositional Semantic Parsing on Semi-Structured Tables</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
							<email>ppasupat@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Compositional Semantic Parsing on Semi-Structured Tables</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1470" to="1480"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations , and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation , we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In semantic parsing for question answering, nat- ural language questions are converted into logi- cal forms, which can be executed on a knowl- edge source to obtain answer denotations. Early semantic parsing systems were trained to answer highly compositional questions, but the knowl- edge sources were limited to small closed-domain databases ( <ref type="bibr" target="#b30">Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b27">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b31">Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b12">Kwiatkowski et al., 2011</ref>). More recent work sacrifices compositionality in favor of using more open-ended knowledge bases such as Freebase <ref type="bibr" target="#b4">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b2">Berant et al., 2013;</ref><ref type="bibr" target="#b7">Fader et al., 2014;</ref><ref type="bibr" target="#b21">Reddy et al., 2014</ref>). However, even these broader knowledge sources still define a x1: "Greece held its last Summer Olympics in which year?" y1: {2004}</p><p>x2: "In which city's the first time with at least 20 nations?" y2: {Paris} x3: "Which years have the most participating countries?" y3: {2008, 2012}</p><p>x4: "How many events were in Athens, Greece?" y4: {2}</p><p>x5: "How many more participants were there in 1900 than in the first year?" y5: {10} <ref type="figure">Figure 1</ref>: Our task is to answer a highly composi- tional question from an HTML table. We learn a semantic parser from question-table-answer triples {(x i , t i , y i )}.</p><p>rigid schema over entities and relation types, thus restricting the scope of answerable questions.</p><p>To simultaneously increase both the breadth of the knowledge source and the depth of logical compositionality, we propose a new task (with an associated dataset): answering a question using an HTML table as the knowledge source. <ref type="figure">Figure 1</ref> shows several question-answer pairs and an ac- companying table, which are typical of those in our dataset. Note that the questions are logically quite complex, involving a variety of operations such as comparison (x 2 ), superlatives (x 3 ), aggre- gation (x 4 ), and arithmetic (x 5 ).</p><p>The HTML tables are semi-structured and not normalized. For example, a cell might contain multiple parts (e.g., "Beijing, China" or "200 km"). Additionally, we mandate that the train- ing and test tables are disjoint, so at test time, we will see relations (column headers; e.g., "Na- tions") and entities (table cells; e.g., "St. Louis") that were not observed during training. This is in contrast to knowledge bases like Freebase, which have a global fixed relation schema with normal- ized entities and relations.</p><p>Our task setting produces two main challenges. Firstly, the increased breadth in the knowledge source requires us to generate logical forms from novel tables with previously unseen relations and entities. We therefore cannot follow the typical semantic parsing strategy of constructing or learn- ing a lexicon that maps phrases to relations ahead of time. Secondly, the increased depth in com- positionality and additional logical operations ex- acerbate the exponential growth of the number of possible logical forms.</p><p>We trained a semantic parser for this task from question-answer pairs based on the framework il- lustrated in <ref type="figure">Figure 2</ref>. First, relations and entities from the semi-structured HTML table are encoded in a graph. Then, the system parses the question into candidate logical forms with a high-coverage grammar, reranks the candidates with a log-linear model, and then executes the highest-scoring logi- cal form to produce the answer denotation. We use beam search with pruning strategies based on type and denotation constraints to control the combina- torial explosion.</p><p>To evaluate the system, we created a new dataset, WIKITABLEQUESTIONS, consisting of 2,108 HTML tables from Wikipedia and 22,033 question-answer pairs. When tested on unseen ta- bles, the system achieves an accuracy of 37.1%, which is significantly higher than the information retrieval baseline of 12.7% and a simple semantic parsing baseline of 24.3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task</head><p>Our task is as follows: given a </p><formula xml:id="formula_0">D = {(x i , t i , y i )} N i=1</formula><p>of questions, tables, and an- swers, but the tables in test data do not appear dur- ing training.</p><p>The only restriction on the question x is that a person must be able to answer it using just the ta- ble t. Other than that, the question can be of any type, ranging from a simple table lookup question to a more complicated one that involves various logical operations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>{2004}</head><p>Figure 2: The prediction framework: (1) the table t is deterministically converted into a knowledge graph w as shown in <ref type="figure" target="#fig_2">Figure 3</ref>; (2) with informa- tion from w, the question x is parsed into candi- date logical forms in Z x ; (3) the highest-scoring candidate z ∈ Z x is chosen; and (4) z is executed on w, yielding the answer y.</p><p>Dataset. We created a new dataset, WIK- ITABLEQUESTIONS, of question-answer pairs on HTML tables as follows. We randomly selected data tables from Wikipedia with at least 8 rows and 5 columns. We then created two Amazon Mechan- ical Turk tasks. The first task asks workers to write trivia questions about the table. For each question, we put one of the 36 generic prompts such as "The question should require calculation" or "contains the word 'first' or its synonym" to encourage more complex utterances. Next, we submit the result- ing questions to the second task where the work- ers answer each question based on the given table.</p><p>We only keep the answers that are agreed upon by at least two workers. After this filtering, approxi- mately 69% of the questions remains. The final dataset contains 22,033 examples on 2,108 tables. We set aside 20% of the tables and their associated questions as the test set and de- velop on the remaining examples. Simple pre- processing was done on the tables: We omit all non-textual contents of the tables, and if there is a merged cell spanning many rows or columns, we unmerge it and duplicate its content into each un- merged cell. Section 7.2 analyzes various aspects of the dataset and compares it to other datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>We now describe our semantic parsing framework for answering a given question and for training the model with question-answer pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction. Given a table t and a question x,</head><p>we predict an answer y using the framework il- lustrated in <ref type="figure">Figure 2</ref>. We first convert the table t into a knowledge graph w ("world") which en- codes different relations in the table (Section 4). Next, we generate a set of candidate logical forms Z x by parsing the question x using the informa- tion from w (Section 6.1). Each generated logical form z ∈ Z x is a graph query that can be exe- cuted on the knowledge graph w to get a denota- tion z w . We extract a feature vector φ(x, w, z) for each z ∈ Z x (Section 6.2) and define a log- linear distribution over the candidates:</p><formula xml:id="formula_1">p θ (z | x, w) ∝ exp{θ φ(x, w, z)},<label>(1)</label></formula><p>where θ is the parameter vector. Finally, we choose the logical form z with the highest model probability and execute it on w to get the answer denotation y = z w .</p><formula xml:id="formula_2">Training. Given training examples D = {(x i , t i , y i )} N i=1</formula><p>, we seek a parameter vector θ that maximizes the regularized log-likelihood of the correct denotation y i marginalized over logi- cal forms z. Formally, we maximize the objective function</p><formula xml:id="formula_3">J(θ) = 1 N N i=1 log p θ (y i | x i , w i ) − λ θ 1 , (2)</formula><p>where w i is deterministically generated from t i , and</p><formula xml:id="formula_4">p θ (y | x, w) = z∈Zx;y=zw p θ (z | x, w). (3)</formula><p>We optimize θ using AdaGrad ( <ref type="bibr" target="#b5">Duchi et al., 2010)</ref>, running 3 passes over the data. We use L 1 regularization with λ = 3 × 10 −5 obtained from cross-validation.</p><p>The following sections explain individual sys- tem components in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Knowledge graph</head><p>Inspired by the graph representation of knowledge bases, we preprocess the table t by deterministi- cally converting it into a knowledge graph w as illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. In the most basic form, ta- ble rows become row nodes, strings in table cells become entity nodes, 1 and table columns become directed edges from the row nodes to the entity 1 Two occurrences of the same string constitute one node.  nodes of that column. The column headers are used as edge labels for these row-entity relations.</p><p>The knowledge graph representation is conve- nient for three reasons. First, we can encode dif- ferent forms of entity normalization in the graph. Some entity strings (e.g., "1900") can be inter- preted as a number, a date, or a proper name de- pending on the context, while some other strings (e.g., "200 km") have multiple parts. Instead of committing to one normalization scheme, we in- troduce edges corresponding to different normal- ization methods from the entity nodes. For exam- ple, the node 1900 will have an edge called Date to another node 1900-XX-XX of type date. Apart from type checking, these normalization nodes also aid learning by providing signals on the ap- propriate answer type. For instance, we can define a feature that associates the phrase "how many" with a logical form that says "traverse a row-entity edge, then a Number edge" instead of just "traverse a row-entity edge."</p><p>The second benefit of the graph representation is its ability to handle various logical phenomena via graph augmentation. For example, to answer questions of the form "What is the next . . . ?" or "Who came before . . . ?", we augment each row node with an edge labeled Next pointing to the next row node, after which the questions can be answered by traversing the Next edge. In this work, we choose to add two special edges on each row node: the Next edge mentioned above and an Index edge pointing to the row index number (0, 1, 2, . . . ).</p><p>Finally, with a graph representation, we can query it directly using a logical formalism for knowledge graphs, which we turn to next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Join</head><p>City.Athens (row nodes with a City edge to Athens) Union City.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(Athens Beijing) Intersection</head><p>City.Athens Year.Number.&lt;.1990 Reverse R <ref type="bibr">[Year]</ref>.City.Athens (entities where a row in City.Athens has a Year edge to) Aggregation count(City.Athens) (the number of rows with city Athens) Superlative argmax(City.Athens, Index) (the last row with city Athens) Arithmetic sub <ref type="bibr">(204,</ref><ref type="bibr">201)</ref> </p><formula xml:id="formula_5">(= 204 − 201) Lambda λx[Year.Date.x]</formula><p>(a binary: composition of two relations) <ref type="table" target="#tab_1">Table 1</ref>: The lambda DCS operations we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Logical forms</head><p>As our language for logical forms, we use lambda dependency-based compositional seman- tics (Liang, 2013), or lambda DCS, which we briefly describe here. Each lambda DCS logical form is either a unary (denoting a list of values) or a binary (denoting a list of pairs). The most basic unaries are singletons (e.g., China represents an entity node, and 30 represents a single number), while the most basic binaries are relations (e.g., City maps rows to city entities, Next maps rows to rows, and &gt;= maps numbers to numbers). Log- ical forms can be combined into larger ones via various operations listed in <ref type="table" target="#tab_1">Table 1</ref>. Each opera- tion produces a unary except lambda abstraction:</p><formula xml:id="formula_6">λx[f (x)</formula><p>] is a binary mapping x to f (x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Parsing and ranking</head><p>Given the knowledge graph w, we now describe how to parse the utterance x into a set of candidate logical forms Z x</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Parsing algorithm</head><p>We propose a new floating parser which is more flexible than a standard chart parser. Both parsers recursively build up derivations and corresponding logical forms by repeatedly applying deduction rules, but the floating parser allows logical form predicates to be generated independently from the utterance.</p><p>Chart parser. We briefly review the CKY al- gorithm for chart parsing to introduce notation. Given an utterance with tokens x 1 , . . . , x n , the CKY algorithm applies deduction rules of the fol-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule</head><p>Semantics Example Anchored to the utterance TokenSpan → Entity match(z1) Greece (match(s) = entity with name s) anchored to "Greece" TokenSpan → Atomic val(z1) 2012-07-XX (val(s) = interpreted value) anchored to "July 2012" </p><formula xml:id="formula_7">Unanchored (floating) ∅ → Relation r Country (r = row-entity relation) ∅ → Relation λx[r.p.x] λx[Year.Date.x] (p = normalization relation) ∅ → Records Type.Row (list of all rows) ∅ → RecordFn Index (row ← row index)</formula><formula xml:id="formula_8">(TokenSpan, i, j)[s] → (c, i, j)[f (s)],<label>(4)</label></formula><formula xml:id="formula_9">(c 1 , i, k)[z 1 ] + (c 2 , k + 1, j)[z 2 ] (5) → (c, i, j)[f (z 1 , z 2 )].</formula><p>The first rule is a lexical rule that matches an utter- ance token span x i · · · x j (e.g., s = "New York") and produces a logical form (e.g., f (s) = NewYorkCity) with category c (e.g., Entity).</p><p>The second rule takes two adjacent spans giv- ing rise to logical forms z 1 and z 2 and builds a new logical form f (z 1 , z 2 ). Algorithmically, CKY stores derivations of category c covering the span x i · · · x j in a cell (c, i, j). CKY fills in the cells of increasing span lengths, and the logical forms in the top cell (ROOT, 1, n) are returned. Floating parser. Chart parsing uses lexical rules (4) to generate relevant logical predicates, but in our setting of semantic parsing on tables, we do not have the luxury of starting with or inducing a full-fledged lexicon. Moreover, there is a mismatch between words in the utterance and predicates in the logical form. For in- stance, consider the question "Greece held its last Summer Olympics in which year?" on the table in <ref type="figure">Figure 1</ref> and the correct logical form <ref type="bibr">Date.x]</ref>].argmax(Country.Greece, Index).</p><formula xml:id="formula_10">R[λx[Year.</formula><p>While the entity Greece can be anchored to the token "Greece", some logical predicates (e.g., Country) cannot be clearly anchored to a token span. We could potentially learn to anchor the logical form Country.Greece to "Greece", but if the relation Country is not seen during training, such a mapping is impossible to learn from the training data. Similarly, some prominent tokens</p><note type="other">Rule Semantics Example Join + Aggregate Entity or Atomic → Values z1 China Atomic → Values c.z1</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt;=.30 (at least 30) (c ∈ {&lt;, &gt;, &lt;=, &gt;=})</head><p>Relation + Values → Records z1.z2</p><p>Country.China (events (rows) where the country is China)</p><formula xml:id="formula_11">Relation + Records → Values R[z1].z2 R[Year]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.Country.China (years of events in China) Records → Records</head><p>Next.z1 Next.Country.China (. .</p><note type="other">. before China) Records → Records R[Next].z1 R[Next].Country.China (. . . after China) Values → Atomic a(z1) count(Country.China) (How often did China . . . ) (a ∈ {count, max, min, sum, avg}) Values → ROOT z1 Superlative Relation → RecordFn z1 λx[Nations.Number.x] (row ← value in Nations column) Records + RecordFn → Records s(z1, z2) argmax(Type.Row, λx[Nations.Number.x]) (s ∈ {argmax, argmin}) (events with the most participating nations) argmin(City.Athens, Index) (first event in Athens) Relation → ValueFn R[λx[a(z1.x)]] R[λx[count(City.x)]] (city ← num. of rows with that city) Relation + Relation → ValueFn λx[R[z1].z2.x] λx[R[City].Nations.Number.x] (city ← value in Nations column) Values + ValueFn → Values s(z1, z2) argmax(. . . , R[λx[count(City.x)]]) (most frequent city) Other operations ValueFn + Values + Values → Values</note><formula xml:id="formula_12">o(R[z1].z2, R[z1].z3) sub(R[Number].R[Nations].City.London, . . . ) (o ∈ {add, sub, mul, div})</formula><p>(How many more participants were in London than . . .  <ref type="table" target="#tab_1">Table 3</ref>: Compositional deduction rules. Each rule c 1 , . . . , c k → c takes logical forms z 1 , . . . , z k con- structed over categories c 1 , . . . , c k , respectively, and produces a logical form based on the semantics.</p><note type="other">) Entity + Entity → Values z1 z2 China France (China or France) Records + Records → Records z1 z2 City.</note><p>(e.g., "Olympics") are irrelevant and have no predicates anchored to them. Therefore, instead of anchoring each predicate in the logical form to tokens in the utterance via lexical rules, we propose parsing more freely. We replace the anchored cells (c, i, j) with floating cells (c, s) of category c and logical form size s. Then we apply rules of the following three kinds:</p><formula xml:id="formula_13">(TokenSpan, i, j)[s] → (c, 1)[f (s)],<label>(6)</label></formula><formula xml:id="formula_14">∅ → (c, 1)[f ()],<label>(7)</label></formula><formula xml:id="formula_15">(c 1 , s 1 )[z 1 ] + (c 2 , s 2 )[z 2 ]<label>(8)</label></formula><formula xml:id="formula_16">→ (c, s 1 + s 2 + 1)[f (z 1 , z 2 )].</formula><p>Note that rules (6) are similar to (4) in chart parsing except that the floating cell (c, 1) only keeps track of the category and its size 1, not the span (i, j). Rules (7) allow us to construct predicates out of thin air. For example, we can construct a logical form representing a table rela- tion Country in cell (Relation, 1) using the rule ∅ → Relation [Country] independent of the ut- terance. Rules (8) perform composition, where the induction is on the size s of the logical form rather than the span length. The algorithm stops when the specified maximum size is reached, after which the logical forms in cells (ROOT, s) for any s are included in Z x . <ref type="figure" target="#fig_3">Figure 4</ref> shows an example derivation generated by our floating parser. The floating parser is very flexible: it can skip tokens and combine logical forms in any order. This flexibility might seem too unconstrained, but we can use strong typing constraints to prevent nonsensical derivations from being constructed. <ref type="table" target="#tab_1">Tables 2 and 3</ref> show the full set of deduction rules we use. We assume that all named entities will explicitly appear in the question x, so we an-"Greece held its last Summer Olympics in which year?" z = R[λx[Year. <ref type="bibr">Number.x]</ref>].argmax(Type.Row, Index) y = {2012} (type: NUM, column: YEAR)</p><p>Feature Name Note ("last", predicate = argmax) lex phrase = predicate unlex ( "year" = Year) missing entity unlex ( missing Greece) denotation type = NUM denotation column = YEAR ("which year", type = NUM) lex phrase = column unlex ( "year" = YEAR) (Q = "which", type = NUM) lex (H = "year", type = NUM) lex H = column unlex ( "year" = YEAR) chor all entity predicates (e.g., Greece) to token spans (e.g., "Greece"). We also anchor all numer- ical values (numbers, dates, percentages, etc.) de- tected by an NER system. In contrast, relations (e.g., Country) and operations (e.g., argmax) are kept floating since we want to learn how they are expressed in language. Connections between phrases in x and the generated relations and op- erations in z are established in the ranking model through features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Features</head><p>We define features φ(x, w, z) for our log-linear model to capture the relationship between the question x and the candidate z. <ref type="table" target="#tab_1">Table 4</ref> shows some example features from each feature type. Most features are of the form (f (x), g(z)) or (f (x), h(y)) where y = z w is the denotation, and f , g, and h extract some information (e.g., identity, POS tags) from x, z, or y, respectively. phrase-predicate: Conjunctions between n- grams f (x) from x and predicates g(z) from z. We use both lexicalized features, where all possi- ble pairs (f (x), g(z)) form distinct features, and binary unlexicalized features indicating whether f (x) and g(z) have a string match.</p><p>missing-predicate: Indicators on whether there are entities or relations mentioned in x but not in z. These features are unlexicalized.</p><p>denotation: Size and type of the denotation y = x w . The type can be either a primitive type (e.g., NUM, DATE, ENTITY) or the name of the column containing the entity in y (e.g., CITY).</p><p>phrase-denotation: Conjunctions between n- grams from x and the types of y. Similar to the phrase-predicate features, we use both lexicalized and unlexicalized features.</p><p>headword-denotation: Conjunctions between the question word Q (e.g., what, who, how many) or the headword H (the first noun after the ques- tion word) with the types of y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Generation and pruning</head><p>Due to their recursive nature, the rules allow us to generate highly compositional logical forms. However, the compositionality comes at the cost of generating exponentially many logical forms, most of which are redundant (e.g., logical forms with an argmax operation on a set of size 1). We employ several methods to deal with this combi- natorial explosion:</p><p>Beam search. We compute the model proba- bility of each partial logical form based on avail- able features (i.e., features that do not depend on the final denotation) and keep only the K = 200 highest-scoring logical forms in each cell.</p><p>Pruning. We prune partial logical forms that lead to invalid or redundant final logical forms. For example, we eliminate any logical form that does not type check (e.g., Beijing Greece), executes to an empty list (e.g., Year.Number.24), includes an aggregate or superlative on a singleton set (e.g., argmax(Year.Number.2012, Index)), or joins two relations that are the reverses of each other (e.g., R <ref type="bibr">[City]</ref>.City.Beijing).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Main evaluation</head><p>We evaluate the system on the development sets (three random 80:20 splits of the training data) and the test data. In both settings, the tables we test on do not appear during training.</p><p>Evaluation metrics. Our main metric is accu- racy, which is the number of examples (x, t, y) on which the system outputs the correct answer y. We also report the oracle score, which counts the number of examples where at least one generated candidate z ∈ Z x executes to y.</p><p>Baselines. We compare the system to two base- lines. The first baseline (IR), which simulates in- formation retrieval, selects an answer y among the entities in the table using a log-linear model over entities (table cells) rather than logical forms. The features are conjunctions between phrases in x and properties of the answers y, which cover all fea- tures in our main system that do not involve the logical form. As an upper bound of this baseline, dev test acc ora acc ora IR baseline 13.4 69.1 12.7 70.6 WQ baseline 23.6 34.4 24.3 35.6 Our system 37.0 76.7 37.1 76.6  <ref type="table" target="#tab_1">Table 6</ref>: Average accuracy and oracle scores on development data in various system settings.</p><p>69.1% of the development examples have the an- swer appearing as an entity in the table.</p><p>In the second baseline (WQ), we only allow de- duction rules that produce join and count logical forms. This rule subset has the same logical cov- erage as <ref type="bibr" target="#b1">Berant and Liang (2014)</ref>, which is de- signed to handle the WEBQUESTIONS ( <ref type="bibr" target="#b2">Berant et al., 2013</ref>) and FREE917 <ref type="bibr" target="#b4">(Cai and Yates, 2013)</ref> datasets.</p><p>Results. <ref type="table" target="#tab_1">Table 5</ref> shows the results compared to the baselines. Our system gets an accuracy of 37.1% on the test data, which is significantly higher than both baselines, while the oracle is 76.6%. The next subsections analyze the system components in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Dataset statistics</head><p>In this section, we analyze the breadth and depth of the WIKITABLEQUESTIONS dataset, and how the system handles them.</p><p>Number of relations. With 3,929 unique col- umn headers (relations) among 13,396 columns, the tables in the WIKITABLEQUESTIONS dataset contain many more relations than closed-domain datasets such as Geoquery (Zelle and Mooney,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operation</head><p>Amount join <ref type="table" target="#tab_1">(table lookup)</ref> 13.5% + join with Next + 5.5% + aggregate (count, sum, max, . . . ) + 15.0% + superlative (argmax, argmin) + 24.5% + arithmetic, , + 20.5% + other phenomena + 21.0% <ref type="table" target="#tab_1">Table 7</ref>: The logical operations required to answer the questions in 200 random examples.</p><p>1996) and ATIS <ref type="bibr" target="#b20">(Price, 1990)</ref>. Additionally, the logical forms that execute to the correct denota- tions refer to a total of 2,056 unique column head- ers, which is greater than the number of relations in the FREE917 dataset (635 Freebase relations). Knowledge coverage. We sampled 50 exam- ples from the dataset and tried to answer them manually using Freebase. Even though Free- base contains some information extracted from Wikipedia, we can answer only 20% of the ques- tions, indicating that WIKITABLEQUESTIONS contains a broad set of facts beyond Freebase.</p><p>Logical operation coverage. The dataset cov- ers a wide range of question types and logical operations. <ref type="table" target="#tab_1">Table 6</ref>(a) shows the drop in oracle scores when different subsets of rules are used to generate candidates logical forms. The join only subset corresponds to simple table lookup, while join + count is the WQ baseline for Freebase ques- tion answering on the WEBQUESTIONS dataset. Finally, join + count + superlative roughly corre- sponds to the coverage of the Geoquery dataset.</p><p>To better understand the distribution of log- ical operations in the WIKITABLEQUESTIONS dataset, we manually classified 200 examples based on the types of operations required to an- swer the question. The statistics in <ref type="table" target="#tab_1">Table 7</ref> shows that while a few questions only require simple operations such as table lookup, the majority of the questions demands more advanced operations. Additionally, 21% of the examples cannot be an- swered using any logical form generated from the current deduction rules; these examples are dis- cussed in Section 7.4.</p><p>Compositionality. From each example, we compute the logical form size (number of rules applied) of the highest-scoring candidate that exe- cutes to the correct denotation. The histogram in <ref type="figure">Figure 5</ref> shows that a significant number of logical forms are non-trivial.</p><p>Beam size and pruning. <ref type="figure">Figure 6</ref> shows the results with and without pruning on various beam sizes. Apart from saving time, pruning also pre- vents bad logical forms from clogging up the beam which hurts both oracle and accuracy metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Features</head><p>Effect of features. <ref type="table" target="#tab_1">Table 6</ref>(b) shows the accu- racy when some feature types are ablated. The most influential features are lexicalized phrase- predicate features, which capture the relationship between phrases and logical operations (e.g., relat- ing "last" to argmax) as well as between phrases and relations (e.g., relating "before" to &lt; or Next, and relating "who" to the relation Name).</p><p>Anchoring with trigger words. In our parsing algorithm, relations and logical operations are not anchored to the utterance. We consider an alter- native approach where logical operations are an- chored to "trigger" phrases, which are hand-coded based on co-occurrence statistics (e.g., we trigger a count logical form with how, many, and total). <ref type="table" target="#tab_1">Table 6</ref>(c) shows that the trigger words do not significantly impact the accuracy, suggesting that the original system is already able to learn the re- lationship between phrases and operations even without a manual lexicon. As an aside, the huge drop in oracle is because fewer "semantically in- correct" logical forms are generated; we discuss this phenomenon in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Semantically correct logical forms</head><p>In our setting, we face a new challenge that arises from learning with denotations: with deeper com- positionality, a larger number of nonsensical log- ical forms can execute to the correct denotation.</p><p>For example, if the target answer is a small num- ber (say, 2), it is possible to count the number of rows with some random properties and arrive at the correct answer. However, as the system en- counters more examples, it can potentially learn to disfavor them by recognizing the characteristics of semantically correct logical forms.</p><p>Generating semantically correct logical forms. The system can learn the features of semantically correct logical forms only if it can generate them in the first place. To see how well the system can generate correct logical forms, looking at the oracle score is insufficient since bad logical forms can execute to the correct denotations. Instead, we randomly chose 200 ex- amples and manually annotated them with logical forms to see if a trained system can produce the annotated logical form as a candidate.</p><p>Out of 200 examples, we find that 79% can be manually annotated. The remaining ones in- clude artifacts such as unhandled question types (e.g., yes-no questions, or questions with phrases "same" or "consecutive"), table cells that require advanced normalization methods (e.g., cells with comma-separated lists), and incorrect annotations.</p><p>The system generates the annotated logical form among the candidates in 53.5% of the ex- amples. The missing examples are mostly caused by anchoring errors due to lexical mismatch (e.g., "Italian" → Italy, or "no zip code" → an empty cell in the zip code column) or the need to generate complex logical forms from a single phrase (e.g., "May 2010" → &gt;=.2010-05-01&lt;=.2010-05-31).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Error analysis</head><p>The errors on the development data can be divided into four groups. The first two groups are unhan- dled question types (21%) and the failure to an- chor entities (25%) as described in Section 7.4. The third group is normalization and type errors (29%): although we handle some forms of en- tity normalization, we observe many unhandled string formats such as times (e.g., 3:45.79) and city-country pairs (e.g., Beijing, China), as well as complex calculation such as computing time peri- ods (e.g., 12pm-1am → 1 hour). Finally, we have ranking errors (25%) which mostly occur when the utterance phrase and the relation are obliquely re- lated (e.g., "airplane" and Model).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>Our work simultaneously increases the breadth of knowledge source and the depth of compositional- ity in semantic parsing. This section explores the connections in both aspects to related work.</p><p>Logical coverage. Different semantic parsing systems are designed to handle different sets of logical operations and degrees of compositional- ity. For example, form-filling systems ( <ref type="bibr" target="#b26">Wang et al., 2011</ref>) usually cover a smaller scope of opera- tions and compositionality, while early statistical semantic parsers for question answering <ref type="bibr" target="#b27">(Wong and Mooney, 2007;</ref><ref type="bibr" target="#b31">Zettlemoyer and Collins, 2007)</ref> and high-accuracy natural language inter- faces for databases <ref type="bibr" target="#b0">(Androutsopoulos et al., 1995;</ref><ref type="bibr" target="#b19">Popescu et al., 2003</ref>) target more compositional utterances with a wide range of logical opera- tions. This work aims to increase the logical coverage even further. For example, compared to the Geoquery dataset, the WIKITABLEQUES- TIONS dataset includes a move diverse set of log- ical operations, and while it does not have ex- tremely compositional questions like in Geoquery (e.g., "What states border states that border states that border Florida?"), our dataset contains fairly compositional questions on average.</p><p>To parse a compositional utterance, many works rely on a lexicon that translates phrases to enti- ties, relations, and logical operations. A lexicon can be automatically generated <ref type="bibr" target="#b23">(Unger and Cimiano, 2011;</ref><ref type="bibr" target="#b24">Unger et al., 2012)</ref>, learned from data ( <ref type="bibr" target="#b31">Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b12">Kwiatkowski et al., 2011</ref>), or extracted from external sources <ref type="bibr" target="#b4">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b2">Berant et al., 2013</ref>), but requires some techniques to generalize to unseen data. Our work takes a different approach similar to the log- ical form growing algorithm in <ref type="bibr" target="#b1">Berant and Liang (2014)</ref> by not anchoring relations and operations to the utterance.</p><p>Knowledge domain. Recent works on seman- tic parsing for question answering operate on more open and diverse data domains. In particular, large-scale knowledge bases have gained popular- ity in the semantic parsing community <ref type="bibr" target="#b4">(Cai and Yates, 2013;</ref><ref type="bibr" target="#b2">Berant et al., 2013;</ref><ref type="bibr" target="#b7">Fader et al., 2014</ref>). The increasing number of relations and en- tities motivates new resources and techniques for improving the accuracy, including the use of ontol- ogy matching models ( <ref type="bibr" target="#b13">Kwiatkowski et al., 2013</ref>), paraphrase models <ref type="bibr" target="#b6">(Fader et al., 2013;</ref><ref type="bibr" target="#b1">Berant and Liang, 2014)</ref>, and unlabeled sentences <ref type="bibr" target="#b11">(Krishnamurthy and Kollar, 2013;</ref><ref type="bibr" target="#b21">Reddy et al., 2014)</ref>.</p><p>Our work leverages open-ended data from the Web through semi-structured tables. There have been several studies on analyzing or inferring the table schemas <ref type="bibr" target="#b3">(Cafarella et al., 2008;</ref><ref type="bibr" target="#b25">Venetis et al., 2011;</ref><ref type="bibr" target="#b22">Syed et al., 2010;</ref><ref type="bibr" target="#b15">Limaye et al., 2010</ref>) and answering search queries by joining tables on sim- ilar columns <ref type="bibr" target="#b3">(Cafarella et al., 2008;</ref><ref type="bibr" target="#b8">Gonzalez et al., 2010;</ref><ref type="bibr" target="#b18">Pimplikar and Sarawagi, 2012)</ref>. While the latter is similar to question answering, the queries tend to be keyword lists instead of natural language sentences. In parallel, open information extraction ( <ref type="bibr" target="#b29">Wu and Weld, 2010;</ref><ref type="bibr" target="#b16">Masaum et al., 2012)</ref> and knowledge base population <ref type="bibr" target="#b10">(Ji and Grishman, 2011</ref>) extract information from web pages and compile them into structured data. The result- ing knowledge base is systematically organized, but as a trade-off, some knowledge is inevitably lost during extraction and the information is forced to conform to a specific schema. To avoid these is- sues, we choose to work on HTML tables directly.</p><p>In future work, we wish to draw informa- tion from other semi-structured formats such as colon-delimited pairs ( <ref type="bibr" target="#b28">Wong et al., 2009)</ref>, bulleted lists ( <ref type="bibr" target="#b9">Gupta and Sarawagi, 2009)</ref>, and top-k lists ( <ref type="bibr" target="#b32">Zhang et al., 2013)</ref>. <ref type="bibr" target="#b17">Pasupat and Liang (2014)</ref> used a framework similar to ours to extract entities from web pages, where the "logical forms" were XPath expressions. A natural direction is to com- bine the logical compositionality of this work with the even broader knowledge source of general web pages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Part of the knowledge graph corresponding to the table in Figure 1. Circular nodes are row nodes. We augment the graph with different entity normalization nodes such as Number and Date (red) and additional row node relations Next and Index (blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A derivation for the utterance "Greece held its last Summer Olympics in which year?" Only Greece is anchored to a phrase "Greece"; Year and other predicates are floating.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Sizes of the highest-scoring correct candidate logical forms in development examples. with pruning without pruning</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>table t and</head><label>t</label><figDesc>a ques- tion x about the table, output a list of values y that answers the question according to the table. Example inputs and outputs are shown in Fig- ure 1. The system has access to a training set</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Base deduction rules. Entities and atomic 
values (e.g., numbers, dates) are anchored to to-
ken spans, while other predicates are kept floating. 
(a ← b represents a binary mapping b to a.) 

lowing two kinds: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Example features that fire for the (incor-
rect) logical form z. All features are binary. (lex = 
lexicalized) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Accuracy (acc) and oracle scores (ora) 
on the development sets (3 random splits of the 
training data) and the test data. 

acc 
ora 
Our system 
37.0 76.7 
(a) Rule Ablation 
join only 
10.6 15.7 
join + count (= WQ baseline) 
23.6 34.4 
join + count + superlative 
30.7 68.6 
all − {{, } 
34.8 75.1 
(b) Feature Ablation 
all − features involving predicate 
11.8 74.5 
all − phrase-predicate 
16.9 74.5 
all − lex phrase-predicate 
17.6 75.9 
all − unlex phrase-predicate 
34.3 76.7 
all − missing-predicate 
35.9 76.7 
all − features involving denotation 
33.5 76.8 
all − denotation 
34.3 76.6 
all − phrase-denotation 
35.7 76.8 
all − headword-denotation 
36.0 76.7 
(c) Anchor operations to trigger words 37.1 59.4 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Natural language interfaces to databasesan introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thanisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="81" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">WebTables: exploring the power of tables on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Very Large Data Bases (VLDB)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="538" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing via schema matching and lexicon extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Learning Theory (COLT)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1156" to="1165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Google fusion tables: web-centered data management and collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Langen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shapley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldbergkidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGMOD International Conference on Management of data</title>
		<meeting>the 2010 ACM SIGMOD International Conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1061" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Answering table augmentation queries from unstructured lists on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Very Large Data Bases (VLDB)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="289" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Knowledge base population: Successful approaches and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1148" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Jointly learning to parse and perceive: Connecting natural language to the physical world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1512" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<title level="m">Lambda dependency-based compositional semantics. arXiv</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Annotating and searching web tables using entities, types and relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Limaye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Very Large Data Bases (VLDB)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1338" to="1347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Masaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Zero-shot entity extraction from web pages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Answering table queries on the web using column keywords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pimplikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Very Large Data Bases (VLDB)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="908" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Towards a theory of natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent User Interfaces (IUI)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of spoken language systems: The ATIS domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third DARPA Speech and Natural Language Workshop</title>
		<meeting>the Third DARPA Speech and Natural Language Workshop</meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Largescale semantic parsing without question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting a web of semantic data for interpreting tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mulwad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Web Science Conference</title>
		<meeting>the Second Web Science Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pythia: compositional meaning construction for ontology-based question answering on the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on Natural language processing and information systems</title>
		<meeting>the 16th international conference on Natural language processing and information systems</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Template-based question answering over RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ngonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recovering semantics of tables on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Venetis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pas¸capas¸ca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Very Large Data Bases (VLDB)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="528" to="538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Semantic frame-based spoken language understanding. Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="41" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="960" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scalable attribute-value extraction from semistructured text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Widdows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lokovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Data Mining Workshops</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="302" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Open information extraction using Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automatic extraction of top-k lists from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
