<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ultra-Fine Entity Typing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">G</forename><surname>Allen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington Allen Institute for Artificial Intelligence</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ultra-Fine Entity Typing</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="87" to="96"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>87</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce a new entity typing task: given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, songwriter, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale: head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing benchmarks. We present a model that can predict open types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from entity linking. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets. 1</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entities can often be described by very fine grained types. Consider the sentences "Bill robbed John. He was arrested." The noun phrases "John," "Bill," and "he" have very specific types that can be inferred from the text. This includes the facts that "Bill" and "he" are both likely "crimi- nal" due to the "robbing" and "arresting," while "John" is more likely a "victim" because he was "robbed." Such fine-grained types (victim, crimi- nal) are important for context-sensitive tasks such <ref type="bibr">1</ref> Our data and model can be downloaded from: http://nlp.cs.washington.edu/entity_type</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence with Target Entity Entity Types</head><p>During the Inca Empire, {the Inti Raymi} was the most important of four ceremonies celebrated in Cusco.</p><p>event, festival, rit- ual, custom, cere- mony, party, cele- bration {They} have been asked to appear in court to face the charge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>person,</head><p>accused, suspect, defendant Ban praised Rwanda's commit- ment to the UN and its role in {peacemaking operations}.</p><p>event, plan, mis- sion, action <ref type="table">Table 1</ref>: Examples of entity mentions and their an- notated types, as annotated in our dataset. The en- tity mentions are bold faced and in the curly brack- ets. The bold blue types do not appear in existing fine-grained type ontologies.</p><p>as coreference resolution and question answering (e.g. "Who was the victim?"). Inferring such types for each mention (John, he) is not possible given current typing models that only predict relatively coarse types and only consider named entities.</p><p>To address this challenge, we present a new task: given a sentence with a target entity men- tion, predict free-form noun phrases that describe appropriate types for the role the target entity plays in the sentence. <ref type="table">Table 1</ref> shows three examples that exhibit a rich variety of types at different granular- ities. Our task effectively subsumes existing fine- grained named entity typing formulations due to the use of a very large type vocabulary and the fact that we predict types for all noun phrases, includ- ing named entities, nominals, and pronouns.</p><p>Incorporating fine-grained entity types has im- proved entity-focused downstream tasks, such as relation extraction <ref type="bibr" target="#b29">(Yaghoobzadeh et al., 2017a</ref>), question answering ( <ref type="bibr" target="#b33">Yavuz et al., 2016)</ref>, query analysis ( <ref type="bibr" target="#b1">Balog and Neumayer, 2012)</ref>, and coref- erence resolution <ref type="bibr" target="#b5">(Durrett and Klein, 2014</ref>). These systems used a relatively coarse type ontology. However, manually designing the ontology is a challenging task, and it is difficult to cover all pos-    <ref type="table">force   anima   meetin   ateme   ecord   dividu   risone   squad   nalys   victim  licem   uratio   battle   essag   avele   plan   singe   aract   title   dar_m   name   reem   voca   ndida   club   child   semb   nditio   bstan   movie   land   docto   ry_se   ceho   tuden   istric   ateri   raine   maste   evic   fenda   ogra   urnal   vesto   atien   policy   writin   ontra   rrito   ystem   llplay   sast   choo   rtain   match   erati   act   oble   attac   opos   food   war   amily   ache   rule   mpaig   agen   astro   hang   aim   plom   eekd   ruler   film   ndma   oubl   part   mmu   us_l   olitic   wspa   gisla   ubjec   ctres   album   data   oces   vers   mou   hoic   rrori   elativ   plan   demi   fund   ppor   dy_p   umb   own   nam  marke   awye   ecut   ecisio   ress  belie   e_e   visio   lam   achi   rren   uca   upa   tesm   olleg   home   cuss   esu   aren   inist   book   work   vern   slat   uipm   tatu   islat   nanc   eath   g_th   agu   etwo   fere   easu   onte   orma   car   eatio   body   cce   inne   mmo   pos   gme   band   er_p   lica   two   job   rive   pous   play   rugg   nes   gotia   dea   ufac   owe   spe   new   case   ligio   easo   emb   peec  head   uni   ecta   r_ve   hing   stitu   udg   of_e   elin   nom   ucat  rticl   figh   gine   ehic   _of_   ome   matte   cash   wife   crip   tem   ounc   oduc   urre   ove   toc   llag   res   sea   ders   cide   oss   king   mpa   lop   girl   ilwa   ctio   ect  vote  quid   fes   pinio   ssu  spu   mic_   nio   ncti opic   row   site   dus   sour  emi   pita   stig   rum   bill   risi   mba   war   ian   apit   eat   kpl   ecti   oth   s_p   ady   anc   gua   ace   ocie   tem   sto   star   ketp   serv   roo   liat   ugh   our   oad   oun   ontr   ow   ion   ouri   tru   tne   dic   nce   onv  adc   _tra   dm   cus   gat   soci</ref>    <ref type="figure">Figure 1</ref>: A visualization of all the labels that cover 90% of the data, where a bubble's size is proportional to the label's frequency. Our dataset is much more diverse and fine grained when compared to existing datasets (OntoNotes and FIGER), in which the top 5 types cover 70-80% of the data.</p><p>sible concepts even within a limited domain. This can be seen empirically in existing datasets, where the label distribution of fine-grained entity typing datasets is heavily skewed toward coarse-grained types. For instance, annotators of the OntoNotes dataset ( <ref type="bibr" target="#b6">Gillick et al., 2014</ref>) marked about half of the mentions as "other," because they could not find a suitable type in their ontology (see <ref type="figure">Figure 1</ref> for a visualization and Section 2.2 for details).</p><p>Our more open, ultra-fine vocabulary, where types are free-form noun phrases, alleviates the need for hand-crafted ontologies, thereby greatly increasing overall type coverage. To better un- derstand entity types in an unrestricted setting, we crowdsource a new dataset of 6,000 examples. Compared to previous fine-grained entity typing datasets, the label distribution in our data is sub- stantially more diverse and fine-grained. Annota- tors easily generate a wide range of types and can determine with 85% agreement if a type generated by another annotator is appropriate. Our evalu- ation data has over 2,500 unique types, posing a challenging learning problem.</p><p>While our types are harder to predict, they also allow for a new form of contextual distant super- vision. We observe that text often contains cues that explicitly match a mention to its type, in the form of the mention's head word. For example, "the incumbent chairman of the African Union" is a type of "chairman." This signal comple- ments the supervision derived from linking entities to knowledge bases, which is context-oblivious. For example, "Clint Eastwood" can be described with dozens of types, but context-sensitive typing would prefer "director" instead of "mayor" for the sentence "Clint Eastwood won 'Best Director' for Million Dollar Baby."</p><p>We combine head-word supervision, which pro- vides ultra-fine type labels, with traditional sig- nals from entity linking. Although the problem is more challenging at finer granularity, we find that mixing fine and coarse-grained supervision helps significantly, and that our proposed model with a multitask objective exceeds the performance of existing entity typing models. Lastly, we show that head-word supervision can be used for previ- ous formulations of entity typing, setting the new state-of-the-art performance on an existing fine- grained NER benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task and Data</head><p>Given a sentence and an entity mention e within it, the task is to predict a set of natural-language phrases T that describe the type of e. The selec- tion of T is context sensitive; for example, in "Bill Gates has donated billions to eradicate malaria," Bill Gates should be typed as "philanthropist" and not "inventor." This distinction is important for context-sensitive tasks such as coreference resolu- tion and question answering (e.g. "Which philan- thropist is trying to prevent malaria?").</p><p>We annotate a dataset of about 6,000 mentions via crowdsourcing (Section 2.1), and demonstrate that using an large type vocabulary substantially increases annotation coverage and diversity over existing approaches (Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Crowdsourcing Entity Types</head><p>To capture multiple domains, we sample sentences from <ref type="bibr">Gigaword (Parker et al., 2011</ref>), OntoNotes ( <ref type="bibr" target="#b8">Hovy et al., 2006</ref>), and web articles ( <ref type="bibr" target="#b26">Singh et al., 2012)</ref>. We select entity mentions by taking max- imal noun phrases from a constituency parser <ref type="bibr" target="#b11">(Manning et al., 2014</ref>) and mentions from a coref- erence resolution system ( <ref type="bibr" target="#b9">Lee et al., 2017)</ref>.</p><p>We provide the sentence and the target entity mention to five crowd workers on Mechanical Turk, and ask them to annotate the entity's type. To encourage annotators to generate fine-grained types, we require at least one general type (e.g. person, organization, location) and two specific types (e.g. doctor, fish, religious institute), from a type vocabulary of about 10K frequent noun phrases. We use WordNet <ref type="bibr" target="#b12">(Miller, 1995)</ref> to ex- pand these types automatically by generating all their synonyms and hypernyms based on the most common sense, and ask five different annotators to validate the generated types. Each pair of annota- tors agreed on 85% of the binary validation deci- sions (i.e. whether a type is suitable or not) and 0.47 in Fleiss's κ. To further improve consistency, the final type set contained only types selected by at least 3/5 annotators. Further crowdsourcing de- tails are available in the supplementary material.</p><p>Our collection process focuses on precision. Thus, the final set is diverse but not comprehen- sive, making evaluation non-trivial (see Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data Analysis</head><p>We collected about 6,000 examples. For analysis, we classified each type into three disjoint bins:</p><p>• 9 general types: person, location, object, orga- nization, place, entity, object, time, event • 121 fine-grained types, mapped to fine-grained entity labels from prior work ( <ref type="bibr" target="#b10">Ling and Weld, 2012;</ref><ref type="bibr" target="#b6">Gillick et al., 2014</ref>) (e.g. film, athlete) • 10,201 ultra-fine types, encompassing every other label in the type space (e.g. detective, law- suit, temple, weapon, composer) On average, each example has 5 labels: 0.9 gen- eral, 0.6 fine-grained, and 3.9 ultra-fine types. Among the 10,000 ultra-fine types, 2,300 unique types were actually found in the 6,000 crowd- sourced examples. Nevertheless, our distant su- pervision data (Section 3) provides positive train- ing examples for every type in the entire vocabu- lary, and our model (Section 4) can and does pre- dict from a 10K type vocabulary. For example, <ref type="figure">Figure 2</ref>: The label distribution across different evaluation datasets. In existing datasets, the top 4 or 7 labels cover over 80% of the labels. In ours, the top 50 labels cover less than 50% of the data. the model correctly predicts "television network" and "archipelago" for some mentions, even though that type never appears in the 6,000 crowdsourced examples.</p><p>Improving Type Coverage We observe that prior fine-grained entity typing datasets are heav- ily focused on coarse-grained types. To quan- tify our observation, we calculate the distribu- tion of types in FIGER ( <ref type="bibr" target="#b10">Ling and Weld, 2012</ref>), OntoNotes ( <ref type="bibr" target="#b6">Gillick et al., 2014</ref>), and our data. For examples with multiple types (|T | &gt; 1), we counted each type 1/|T | times. <ref type="figure">Figure 2</ref> shows the percentage of labels covered by the top N labels in each dataset. In previous enitity typing datasets, the distribution of labels is highly skewed towards the top few labels. To cover 80% of the examples, FIGER requires only the top 7 types, while OntoNotes needs only 4; our dataset requires 429 different types. <ref type="figure">Figure 1</ref> takes a deeper look by visualizing the types that cover 90% of the data, demonstrating the diversity of our dataset. It is also striking that more than half of the examples in OntoNotes are classified as "other," perhaps because of the limi- tation of its predefined ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improving</head><p>Mention Coverage Existing datasets focus mostly on named entity mentions, with the exception of OntoNotes, which contained nominal expressions. This has implications on the transferability of FIGER/OntoNotes-based models to tasks such as coreference resolution, which need to analyze all types of entity mentions (pronouns, nominal expressions, and named entity</p><note type="other">Source Example Sentence Labels Size Prec.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Head Words</head><p>Western powers that brokered the proposed deal in Vi- enna are likely to balk, said Valerie Lincy, a researcher with the Wisconsin Project.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Distant Supervision</head><p>Training data for fine-grained NER systems is typically obtained by linking entity mentions and drawing their types from knowledge bases (KBs). This approach has two limitations: recall can suf- fer due to KB incompleteness ( <ref type="bibr" target="#b28">West et al., 2014</ref>), and precision can suffer when the selected types do not fit the context (Ritter et al., 2011). We al- leviate the recall problem by mining entity men- tions that were linked to Wikipedia in HTML, and extract relevant types from their encyclope- dic definitions (Section 3.1). To address the pre- cision issue (context-insensitive labeling), we pro- pose a new source of distant supervision: auto- matically extracted nominal head words from raw text (Section 3.2). Using head words as a form of distant supervision provides fine-grained infor- mation about named entities and nominal men- tions. While a KB may link "the 44th president of the United States" to many types such as author, lawyer, and professor, head words provide only the type "president", which is relevant in the context.</p><p>We experiment with the new distant supervi- sion sources as well as the traditional KB super- vision. <ref type="table" target="#tab_3">Table 2</ref> shows examples and statistics for each source of supervision. We annotate 100 ex- amples from each source to estimate the noise and usefulness in each signal (precision in <ref type="table" target="#tab_3">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Entity Linking</head><p>For KB supervision, we leveraged training data from prior work ( <ref type="bibr" target="#b10">Ling and Weld, 2012;</ref><ref type="bibr" target="#b6">Gillick et al., 2014</ref>) by manually mapping their ontology to our 10,000 noun type vocabulary, which cov- ers 130 of our labels (general and fine-grained). <ref type="bibr">2</ref> Section 6 defines this mapping in more detail.</p><p>To improve both entity and type coverage of KB supervision, we use definitions from Wikipedia. We follow Shnarch et al. () who observed that the first sentence of a Wikipedia article often states the entity's type via an "is a" relation; for exam- ple, "Roger Federer is a Swiss professional tennis player." Since we are using a large type vocabu- lary, we can now mine this typing information. <ref type="bibr">3</ref> We extracted descriptions for 3.1M entities which contain 4,600 unique type labels such as "compe- tition," "movement," and "village."</p><p>We bypass the challenge of automatically link- ing entities to Wikipedia by exploiting existing hy- perlinks in web pages ( <ref type="bibr" target="#b26">Singh et al., 2012</ref>), fol- lowing prior work ( <ref type="bibr" target="#b10">Ling and Weld, 2012;</ref><ref type="bibr" target="#b35">Yosef et al., 2012</ref>). Since our heuristic extraction of types from the definition sentence is somewhat noisy, we use a more conservative entity linking policy 4 that yields a signal with similar overall ac- curacy to KB-linked data. <ref type="bibr">2</ref> Data from: https://github.com/ shimaokasonse/NFGEC 3 We extract types by applying a dependency parser <ref type="bibr" target="#b11">(Manning et al., 2014</ref>) to the definition sentence, and taking nouns that are dependents of a copular edge or connected to nouns linked to copulars via appositive or conjunctive edges. <ref type="bibr">4</ref> Only link if the mention contains the Wikipedia entity's name and the entity's name contains the mention's head.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contextualized Supervision</head><p>Many nominal entity mentions include detailed type information within the mention itself. For example, when describing Titan V as "the newly- released graphics card", the head words and phrases of this mention ("graphics card" and "card") provide a somewhat noisy, but very easy to gather, context-sensitive type signal.</p><p>We extract nominal head words with a depen- dency parser <ref type="bibr" target="#b11">(Manning et al., 2014</ref>) from the Gi- gaword corpus as well as the Wikilink dataset.</p><p>To support multiword expressions, we included nouns that appear next to the head if they form a phrase in our type vocabulary. Finally, we lower- case all words and convert plural to singular.</p><p>Our analysis reveals that this signal has a com- parable accuracy to the types extracted from en- tity linking (around 80%). Many errors are from the parser, and some errors stem from idioms and transparent heads (e.g. "parts of capital" labeled as "part"). While the headword is given as an input to the model, with heavy regularization and multi- tasking with other supervision sources, this super- vision helps encode the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>We design a model for predicting sets of types given a mention in context.</p><p>The architec- ture resembles the recent neural AttentiveNER model ( <ref type="bibr" target="#b24">Shimaoka et al., 2017)</ref>, while improving the sentence and mention representations, and in- troducing a new multitask objective to handle mul- tiple sources of supervision. The hyperparameter settings are listed in the supplementary material.</p><p>Context Representation Given a sentence x 1 , . . . , x n , we represent each token x i using a pre-trained word embedding w i . We concate- nate an additional location embedding l i which indicates whether x i is before, inside, or after the mention. We then use [x i ; l i ] as an input to a bidirectional LSTM, producing a contextualized representation h i for each token; this is different from the architecture of <ref type="bibr" target="#b24">Shimaoka et al. 2017</ref>, who used two separate bidirectional LSTMs on each side of the mention. Finally, we represent the context c as a weighted sum of the contextualized token representations using MLP-based attention:</p><formula xml:id="formula_0">a i = SoftMax i (v a · relu(W a h i ))</formula><p>Where W a and v a are the parameters of the atten- tion mechanism's MLP, which allows interaction between the forward and backward directions of the LSTM before computing the weight factors. Label Prediction We learn a type label embed- ding matrix W t ∈ R n×d where n is the number of labels in the prediction space and d is the dimen- sion of r. This matrix can be seen as a combination of three sub matrices, W general , W f ine , W ultra , each of which contains the representations of the general, fine, and ultra-fine types respectively. We predict each type's probability via the sigmoid of its inner product with r: y = σ(W t r). We predict every type t for which y t &gt; 0.5, or arg max y t if there is no such type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mention Representation</head><p>Multitask Objective The distant supervision sources provide partial supervision for ultra-fine types; KBs often provide more general types, while head words usually provide only ultra-fine types, without their generalizations. In other words, the absence of a type at a different level of abstraction does not imply a negative signal; e.g. when the head word is "inventor", the model should not be discouraged to predict "person".</p><p>Prior work used a customized hinge loss <ref type="bibr" target="#b0">(Abhishek et al., 2017)</ref> or max margin loss <ref type="bibr" target="#b18">(Ren et al., 2016a</ref>) to improve robustness to noisy or incom- plete supervision. We propose a multitask objec- tive that reflects the characteristic of our training dataset. Instead of updating all labels for each ex- ample, we divide labels into three bins (general, fine, and ultra-fine), and update labels only in bin containing at least one positive label. Specifically, the training objective is to minimize J where t is the target vector at each granularity:</p><formula xml:id="formula_1">J all = J general · 1 general (t) + J fine · 1 fine (t) + J ultra · 1 ultra (t)</formula><p>Where 1 category (t) is an indicator function that checks if t contains a type in the category, and   <ref type="table">Table 4</ref>: Results on the development set for different type granularity and for different supervision data with our model. In each row, we remove a single source of supervision. Entity linking (EL) includes supervision from both KB and Wikipedia definitions. The numbers in the first row are example counts for each type granularity.</p><p>J category is the category-specific logistic regression objective:</p><formula xml:id="formula_2">J = − i t i · log(y i ) + (1 − t i ) · log(1 − y i )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>Experiment Setup The crowdsourced dataset (Section 2.1) was randomly split into train, devel- opment, and test sets, each with about 2,000 ex- amples. We use this relatively small manually- annotated training set (Crowd in <ref type="table">Table 4</ref>) along- side the two distant supervision sources: entity linking (KB and Wikipedia definitions) and head words. To combine supervision sources of differ- ent magnitudes (2K crowdsourced data, 4.7M en- tity linking data, and 20M head words), we sample a batch of equal size from each source at each it- eration. We reimplement the recent AttentiveNER model (Shimaoka et al., 2017) for reference. <ref type="bibr">5</ref> We report macro-averaged precision, recall, and F1, and the average mean reciprocal rank (MRR).</p><p>Results <ref type="table" target="#tab_5">Table 3</ref> shows the performance of our model and our reimplementation of Atten- tiveNER. Our model, which uses a multitask ob- jective to learn finer types without punishing more general types, shows recall gains at the cost of drop in precision. The MRR score shows that our <ref type="bibr">5</ref> We use the AttentiveNER model with no engineered fea- tures or hierarchical label encoding (as a hierarchy is not clear in our label setting) and let it predict from the same label space, training with the same supervision data. model is slightly better than the baseline at ranking correct types above incorrect ones. <ref type="table">Table 4</ref> shows the performance breakdown for different type granularity and different supervi- sion. Overall, as seen in previous work on fine- grained NER literature ( <ref type="bibr" target="#b6">Gillick et al., 2014;</ref><ref type="bibr" target="#b18">Ren et al., 2016a</ref>), finer labels were more challenging to predict than coarse grained labels, and this is- sue is exacerbated when dealing with ultra-fine types. All sources of supervision appear to be useful, with crowdsourced examples making the biggest impact. Head word supervision is par- ticularly helpful for predicting ultra-fine labels, while entity linking improves fine label prediction. The low general type performance is partially be- cause of nominal/pronoun mentions (e.g. "it"), and because of the large type inventory (some- times "location" and "place" are annotated inter- changeably).</p><p>Analysis We manually analyzed 50 examples from the development set, four of which we present in <ref type="table">Table 5</ref>. Overall, the model was able to generate accurate general types and a diverse set of type labels. Despite our efforts to annotate a com- prehensive type set, the gold labels still miss many potentially correct labels (example (a): "man" is reasonable but counted as incorrect). This makes the precision estimates lower than the actual per- formance level, with about half the precision er- rors belonging to this category. Real precision errors include predicting co-hyponyms (example (b): "accident" instead of "attack"), and types that Example Bruguera said {he} had problems with his left leg and had grown tired early during the match . (a) Annotation person, athlete, player, adult, male, contestant Prediction person, athlete, player, adult, male, contestant, defendant, man Example {The explosions} occurred on the night of October 7 , against the Hilton Taba and campsites used by Israelis in Ras al-Shitan. (b) Annotation event calamity, attack, disaster Prediction event, accident Example Similarly , Enterprise was considered for refit to replace Challenger after {the latter} was destroyed , but Endeavour was built from structural spares instead .  <ref type="table">Table 5</ref>: Example and predictions from our best model on the development set. Entity mentions are marked with curly brackets, the correct predictions are boldfaced, and the missing labels are italicized and written in red.</p><p>may be true, but are not supported by the context. We found that the model often abstained from predicting any fine-grained types. Especially in challenging cases as in example (c), the model predicts only general types, explaining the low re- call numbers (28% of examples belong to this cat- egory). Even when the model generated correct fine-grained types as in example (d), the recall was often fairly low since it did not generate a com- plete set of related fine-grained labels.</p><p>Estimating the performance of a model in an in- complete label setting and expanding label cover- age are interesting areas for future work. Our task also poses a potential modeling challenge; some- times, the model predicts two incongruous types (e.g. "location" and "person"), which points to- wards modeling the task as a joint set prediction task, rather than predicting labels individually. We provide sample outputs on the project website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Improving Existing Fine-Grained NER with Better Distant Supervision</head><p>We show that our model and distant supervision can improve performance on an existing fine- grained NER task. We chose the widely-used OntoNotes ( <ref type="bibr" target="#b6">Gillick et al., 2014</ref>) dataset which in- cludes nominal and named entity mentions. 6</p><p>6 While we were inspired by FIGER ( <ref type="bibr" target="#b10">Ling and Weld, 2012)</ref>, the dataset presents technical difficulties. The test set has only 600 examples, and the development set was labeled with distant supervision, not manual annotation. We there- fore focus our evaluation on OntoNotes.</p><p>Augmenting the Training Data The original OntoNotes training set (ONTO in <ref type="table" target="#tab_7">Tables 6 and 7)</ref> is extracted by linking entities to a KB. We supple- ment this dataset with our two new sources of dis- tant supervision: Wikipedia definition sentences (WIKI) and head word supervision (HEAD) (see Section 3). To convert the label space, we manu- ally map a single noun from our natural-language vocabulary to each formal-language type in the OntoNotes ontology. 77% of OntoNote's types directly correspond to suitable noun labels (e.g. "doctor" to "/person/doctor"), whereas the other cases were mapped with minimal manual effort (e.g. "musician" to "person/artist/music", "politi- cian" to "/person/political figure"). We then ex- pand these labels according to the ontology to in- clude their hypernyms ("/person/political figure" will also generate "/person"). Lastly, we create negative examples by assigning the "/other" label to examples that are not mapped to the ontology. The augmented dataset contains 2.5M/0.6M new positive/negative examples, of which 0.9M/0.1M are from Wikipedia definition sentences and 1.6M/0.5M from head words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Setup</head><p>We compare performance to other published results and to our reimplemen- tation of AttentiveNER ( <ref type="bibr" target="#b24">Shimaoka et al., 2017</ref>). We also compare models trained with different sources of supervision. For this dataset, we did not use our multitask objective (Section 4), since ex- panding types to include their ontological hyper- nyms largely eliminates the partial supervision as-   <ref type="table">Table 7</ref>: Ablation study on the OntoNotes fine- grained entity typing development. The second row isolates dataset improvements, while the third row isolates the model. sumption. Following prior work, we report macro- and micro-averaged F1 score, as well as accuracy (exact set match).</p><formula xml:id="formula_3">Acc. Ma-F1 Mi-F1</formula><p>Results <ref type="table" target="#tab_7">Table 6</ref> shows the overall performance on the test set. Our combination of model and training data shows a clear improvement from prior work, setting a new state-of-the art result. <ref type="bibr">7</ref> In <ref type="table">Table 7</ref>, we show an ablation study. Our new supervision sources improve the performance of both the AttentiveNER model and our own. We observe that every supervision source improves performance in its own right. Particularly, the naturally-occurring head-word supervision seems to be the prime source of improvement, increasing performance by about 10% across all metrics.</p><p>Predicting Miscellaneous Types While analyz- ing the data, we observed that over half of the men- tions in OntoNotes' development set were anno- tated only with the miscellaneous type ("/other"). For both models in our evaluation, detecting the miscellaneous category is substantially easier than</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Fine-grained NER has received growing atten- tion, and is used in many applications ( <ref type="bibr" target="#b7">Gupta et al., 2017;</ref><ref type="bibr" target="#b20">Ren et al., 2017;</ref><ref type="bibr" target="#b30">Yaghoobzadeh et al., 2017b;</ref><ref type="bibr" target="#b17">Raiman and Raiman, 2018)</ref>. Researchers studied typing in varied contexts, including men- tions in specific sentences (as we consider) ( <ref type="bibr" target="#b10">Ling and Weld, 2012;</ref><ref type="bibr" target="#b6">Gillick et al., 2014;</ref><ref type="bibr" target="#b34">Yogatama et al., 2015;</ref><ref type="bibr" target="#b4">Dong et al., 2015;</ref><ref type="bibr" target="#b23">Schutze et al., 2017)</ref>, corpus-level prediction <ref type="bibr" target="#b31">(Yaghoobzadeh and Schütze, 2016)</ref>, and lexicon level (given only a noun phrase with no context) ( <ref type="bibr" target="#b32">Yao et al., 2013)</ref>.</p><p>Recent work introduced fine-grained type on- tologies ( <ref type="bibr" target="#b16">Rabinovich and Klein, 2017;</ref><ref type="bibr" target="#b13">Murty et al., 2017;</ref><ref type="bibr" target="#b2">Corro et al., 2015)</ref>, defined using Wikipedia categories (100), Freebase types (1K) and WordNet senses (16K). However, they focus on named entities, and data has been challeng- ing to gather, often approximating gold annota- tions with distant supervision. In contrast, (1) our ontology contains any frequent noun phrases that depicts a type, (2) our task goes beyond named entities, covering every noun phrase (even pro- nouns), and (3) we provide crowdsourced annota- tions which provide context-sensitive, fine grained type labels.</p><p>Contextualized fine-grained entity typing is re- lated to selectional preference <ref type="bibr" target="#b21">(Resnik, 1996;</ref><ref type="bibr" target="#b14">Pantel et al., 2007;</ref><ref type="bibr" target="#b36">Zapirain et al., 2013;</ref><ref type="bibr" target="#b3">de Cruys, 2014)</ref>, where the goal is to induce semantic gen- eralizations on the type of arguments a predicate prefers. Rather than focusing on predicates, we condition on the entire sentence to deduce the ar- guments' types, which allows us to capture more nuanced types. For example, not every type that fits "He played the violin in his room" is also suitable for "He played the violin in the Carnegie Hall". Entity typing here can be connected to ar- gument finding in semantic role labeling.</p><p>To deal with noisy distant supervision for KB population and entity typing, researchers used multi-instance multi-label learning <ref type="bibr" target="#b27">(Surdeanu et al., 2012;</ref><ref type="bibr" target="#b30">Yaghoobzadeh et al., 2017b</ref>) or custom losses ( <ref type="bibr" target="#b0">Abhishek et al., 2017;</ref><ref type="bibr" target="#b18">Ren et al., 2016a</ref>). Our multitask objective handles noisy su- pervision by pooling different distant supervision sources across different levels of granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Using virtually unrestricted types allows us to ex- pand the standard KB-based training methodol- ogy with typing information from Wikipedia defi- nitions and naturally-occurring head-word super- vision. These new forms of distant supervision boost performance on our new dataset as well as on an existing fine-grained entity typing bench- mark. These results set the first performance lev- els for our evaluation dataset, and suggest that the data will support significant future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>We represent the mention m as the concatenation of two items: (a) a character-based representation produced by a CNN on the entire mention span, and (b) a weighted sum of the pre-trained word embeddings in the mention span computed by attention, similar to the mention representation in a recent coreference resolution model (Lee et al., 2017). The final representation is the concatenation of the context and mention representations: r = [c; m].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(c) Annotation object, spacecraft, rocket, thing, vehicle, shuttle Prediction event Context " There is a wealth of good news in this report , and I 'm particularly encouraged by the progress {we} are making against AIDS , " HHS Secretary Donna Shalala said in a statement. (d) Annotation government, group, organization,hospital,administration,socialist Prediction government, group, person</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>power 20M 80.4% Alexis Kaniaris, CEO of the organizing company Eu- ropartners, explained, speaking in a radio program in na- tional radio station NET.</head><label></label><figDesc></figDesc><table>radio, station, ra-
dio station 

Entity Linking 
+ Definitions 

Toyota recalled more than 8 million vehicles globally over 
sticky pedals that can become entrapped in floor mats. 

manufacturer 
2.7M 77.7% 

Entity Linking 
+ KB 

Iced Earth's musical style is influenced by many traditional 
heavy metal groups such as Black Sabbath. 

person, artist, actor, 
author, musician 

2.5M 77.6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Distant supervision examples and statistics. We extracted the headword and Wikipedia def-
inition supervision from Gigaword and Wikilink corpora. KB-based supervision is mapped from prior 
work, which used Wikipedia and news corpora. 

mentions). Our new dataset provides a well-
rounded benchmark with roughly 40% pronouns, 
38% nominal expressions, and 22% named entity 
mentions. The case of pronouns is particularly 
interesting, since the mention itself provides little 
information. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : Performance of our model and AttentiveNER (Shimaoka et al., 2017) on the new entity</head><label>3</label><figDesc></figDesc><table>typing 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Results on the OntoNotes fine-grained 
entity typing test set. The first two models (At-
tentiveNER++ and AFET) use only KB-based su-
pervision. LNR uses a filtered version of the KB-
based training set. Our model uses all our distant 
supervision sources. 

Model 
Training Data 
Performance 

ONTO 
WIKI 
HEAD 

Acc. MaF1 MiF1 

Attn. 

46.5 
63.3 
58.3 
NER 


53.7 
72.8 
68.0 


41.7 
64.2 
59.5 


48.5 
67.6 
63.6 
Ours 

57.9 
73.0 
66.9 

60.1 
75.0 
68.7 


61.6 
77.3 
71.8 

</table></figure>

			<note place="foot" n="7"> We did not compare to a system from (Yogatama et al., 2015), which reports slightly higher test number (72.98 micro F1) as they used a different, unreleased test set. producing real types (94% F1 vs. 58% F1 with our best model). We provide further details of this analysis in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The research was supported in part the ARO (W911NF-16-1-0121) the NSF (IIS-1252835, IIS-1562364), and an Allen Distinguished Investigator Award. We would like to thank the reviewers for constructive feedback. Also thanks to Yotam Es-hel and Noam Cohen for providing the Wikilink dataset. Special thanks to the members of UW NLP for helpful discussions and feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fine-grained entity type classification by jointly learning representations and label embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Abhishek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Awekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Chapter</title>
		<meeting>European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hierarchical target type identification for entity-oriented queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Neumayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Information and Knowledge Management</title>
		<meeting>the Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finet: Context-aware fine-grained named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A neural network approach to selectional preference acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A hybrid neural model for type classification of entity mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence</title>
		<meeting>International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Contextdependent fine-grained entity type tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Huynh</surname></persName>
		</author>
		<idno>abs/1412.1820</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Entity linking via joint encoding of types, descriptions, and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2671" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ontonotes: the 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the human language technology conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers</title>
		<meeting>the human language technology conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for the Advancement of Artificial Intelligence</title>
		<meeting>Association for the Advancement of Artificial Intelligence</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finer grained entity typing with typenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Isp: Learning inferential selectional preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhagat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonaventura</forename><surname>Coppola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of North American Chapter of the Association for Computational Linguistics</title>
		<meeting>North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">English gigaword fifth edition (ldc2011t07)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fine-grained entity typing with high-multiplicity assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics (ACL)</title>
		<meeting>Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deeptype: Multilingual entity linking by neural type system evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Raiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Raiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Afet: Automatic finegrained entity typing by hierarchical partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Label noise reduction in entity typing by heterogeneous partial-label embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Knowledge Discovery and Data Mining</title>
		<meeting>Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cotype: Joint extraction of typed entities and relations with knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqiu</forename><surname>Xiang Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><forename type="middle">R</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tarek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of World Wide Web Conference</title>
		<meeting>World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Selectional constraints: an information-theoretic model and its computational realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Named entity recognition in tweets: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1524" to="1534" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end trainable attentive decoder for hierarchical entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schutze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulli</forename><surname>Waltinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Karn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Chapter</title>
		<meeting>European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An attentive neural architecture for fine-grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonse</forename><surname>Shimaoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Chapter</title>
		<meeting>the European Chapter</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Extracting lexical reference rules from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyal</forename><surname>Shnarch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libby</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Wikilinks: A large-scale cross-document coreference corpus labeled via links to Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno>UM-CS-2012-015</idno>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Amherst</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Massachusetts</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multiinstance multi-label learning for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of World Wide Web Conference</title>
		<meeting>World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Noise mitigation for neural entity typing and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno>abs/1612.07495</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Noise mitigation for neural entity typing and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Chapter</title>
		<meeting>European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Corpus-level fine-grained entity typing using contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadollah</forename><surname>Yaghoobzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Universal schema for entity type prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic KnowledgeBase Construction Workshop at the Conference on Information and Knowledge Management</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improving semantic parsing via answer type inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izzeddin</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mudhakar</forename><surname>Srivatsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Embedding methods for fine grained entity type classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nevena</forename><surname>Lazic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics (ACL)</title>
		<meeting>Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hyena: Hierarchical type classification for entity names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amir Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Selectional preferences for semantic role classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Beñat Zapirain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>` Arquez I Villodre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Surdeanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="631" to="663" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
