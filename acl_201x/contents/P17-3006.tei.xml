<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Are You Asking the Right Questions? Teaching Machines to Ask Clarification Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudha</forename><surname>Rao</surname></persName>
							<email>raosudha@cs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University Of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Are You Asking the Right Questions? Teaching Machines to Ask Clarification Questions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL 2017, Student Research Workshop</title>
						<meeting>ACL 2017, Student Research Workshop <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="30" to="35"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-3006</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Inquiry is fundamental to communication, and machines cannot effectively collaborate with humans unless they can ask questions. In this thesis work, we explore how can we teach machines to ask clarification questions when faced with uncertainty , a goal of increasing importance in today&apos;s automated society. We do a preliminary study using data from StackEx-change, a plentiful online resource where people routinely ask clarifying questions to posts so that they can better offer assistance to the original poster. We build neu-ral network models inspired by the idea of the expected value of perfect information: a good question is one whose expected answer is going to be most useful. To build generalizable systems, we propose two future research directions: a template-based model and a sequence-to-sequence based neural generative model.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A main goal of asking questions is to fill in- formation gaps, typically through clarification questions, which naturally occur in conversations <ref type="bibr" target="#b13">(Purver, 2004;</ref><ref type="bibr" target="#b2">Ginzburg, 2012)</ref>. A good ques- tion is one whose likely answer is going to be the most useful. Consider the exchange in <ref type="figure" target="#fig_1">Figure 1</ref>, in which an initial poster (who we'll call "Terry") asks for help configuring environment variables. This question is underspecified and a responder ("Parker") asks a clarifying question "(a) What ver- sion of Ubuntu do you have?" Parker could alterna- tively have asked one of:  Parker should not ask (b) because it's not useful; they should not ask (c) because it's too specific and an answer of "No" gives little help. Parker's ques- tion (a) is optimal: it is both likely to be useful, and is plausibly answerable by Terry. Our goal in this work is to automate Parker. Specifically, after Terry writes their initial post, we aim to generate a clarification question so that Terry can immedi- ately amend their post in hopes of getting faster and better replies.</p><p>Our work has two main contributions: 1. A novel neural-network model for addressing this task that integrates the notion of expected value of perfect information ( §2). 2. A novel dataset, derived from StackEx- change, that enables us to learn a model to ask clarifying questions by looking at the types of questions people ask ( §4.1). 1 To develop our model we take inspiration from the decision theoretic framework of the Expected Value of Perfect Information (EVPI) <ref type="bibr" target="#b1">(Avriel and Williams, 1970)</ref>, a measure of the value of gath- ering additional information. In our setting, we use EVPI to calculate which question is most likely to elicit an answer that would make the post more informative. Formally, for an input post p, we want to choose a question q that maximizes E a∼p,q [U(p+a)], where a is a hypothetical answer and U is a utility function measuring the complete- ness of post p if a were to be added to it. To achieve this, we construct two models: <ref type="bibr">(1)</ref> an an- swer model, which estimates P[a | p, q], the like- lihood of receiving answer a if one were to ask question q on post p; (2) a completeness model, U(p), which measures how complete a post is. Given these two models, at prediction time we search over a shortlist of possible questions for that which maximizes the EVPI.</p><p>We are able to train these models jointly based on (p, q, a) triples that we extract automatically from StackExchange. <ref type="figure" target="#fig_1">Figure 1</ref> depicts how we do this using StackExchange's edit history. In the fig- ure, the initial post fails to state what version of Ubuntu is being run. In response to Parker's ques- tion in the comments section, Terry, the author of the post, edits the post to answer Parker's clarifi- cation question. We extract the initial post as p, question posted in the comments section as q, and edit to the original post as answer a to form our (p, q, a) triples.</p><p>Our results show significant improvements from using the EVPI formalism over both standard feedforward network architectures and bag-of- ngrams baselines, even when our system builds on strong information retrieval scaffolding. In comparison, without this scaffolding, the bag-of- ngrams model outperforms the feedforward net- work. We additionally analyze the difficulty of this task for non-expert humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The problem of question generation has received sparse attention from the natural language pro- cessing community. Most prior work focuses on generating reading comprehension questions: given text, write questions that one might find on a standardized test <ref type="bibr" target="#b17">(Vanderwende, 2008;</ref><ref type="bibr" target="#b3">Heilman, 2011;</ref><ref type="bibr" target="#b14">Rus et al., 2011</ref>). Comprehension questions, by definition, are answerable from the provided text. Clarification questions are not. Outside reading comprehension questions, <ref type="bibr" target="#b6">Labutov et al. (2015)</ref> studied the problem of gener- ating question templates via crowdsourcing, <ref type="bibr" target="#b8">Liu et al. (2010)</ref> use template-based question genera- tion to help authors write better related work sec- tions, <ref type="bibr" target="#b10">Mostafazadeh et al. (2016)</ref> consider ques- tion generation from images, and Artzi and Zettle- moyer (2011) use human-generated clarification questions to drive a semantic parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Description</head><p>In order to choose what question to ask, we build a neural network model inspired by the theory of ex- pected value of perfect information (EVPI). EVPI is a measurement of: if I were to acquire informa- tion X, how useful would that be to me? How- ever, because we haven't acquired X yet, we have to take this quantity in expectation over all pos- sible X, weighted by each X's likelihood. In the question generation setting, for any given ques- tion q that we can ask, there is set A of possible answers that could be given. For each possible an- swer a ∈ A, there is some probability of getting that answer, and some utility if that were the an- swer we got. The value of this question q is the expected utility, over all possible answers. The theory of EVPI then states that we want to choose the question q that maximizes:</p><formula xml:id="formula_0">arg max q∈Q a∈A P[a|p, q]U(p + a)<label>(1)</label></formula><p>In Eq 1, p is the post, q is a potential question from a set of candidate questions Q ( §3.1) and a is a potential answer from a set of candidate answers A ( §3.1). P[a|p, q] ( §3.2) measures the probability of getting an answer a given an initial post p and a clarifying question q. U(p + a) ( §3.3) measures how useful it would be if p were augmented with answer a. Finally, using these pieces, we build a joint neural network that we can optimize end-to- end over our data ( §3.4). <ref type="figure">Figure 2</ref> describes the behavior of our model during test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Question &amp; Answer Candidate Generator</head><p>Given a post, our first step is to generate a set of candidate questions and answers. Our model learns to ask questions by looking at questions asked in previous similar situations. We first iden- tify 10 posts similar to the given post in our dataset using Lucene 2 (a software extensively used in in- formation retrieval) and then consider the ques- <ref type="figure">Figure 2:</ref> The behavior of our model during test time. Given a post p, we retrieve 10 posts similar to p using Lucene and consider the questions asked to those as question candidates and the edits made to the posts in response to the questions as answer candidates. Our answer model generates an answer representation Fans(p, qj) for each question candidate qj and calculates how close is an answer candidate a k to Fans(p, qj). Our utility calculator calculates the utility of the post if it were updated with the answer a k . We select the question qj that maximizes the expected utility of the post p (Equation 1).</p><p>tions asked to these posts as our set of question candidates and the edits made to the posts in re- sponse to the questions as our set of answer candi- dates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Answer Modeling</head><p>Given a post p and a question candidate q i , our second step is to calculate how likely is this ques- tion to be answered using one of our answer can- didates a k . To calculate this probability, we first generate an answer representation F ans (p, q i ) and then measure how close is the answer candidate a k to our answer representation using the equation:</p><formula xml:id="formula_1">P[a k |p, q i ] = 1 Z exp −λ||a k − F ans (p, q i )|| 2<label>(2)</label></formula><p>where λ is a tunable parameter that controls the variance of the distribution.</p><p>We train our answer generator using the follow- ing intuition: a question can be asked in several different ways. For e.g. in <ref type="figure" target="#fig_1">Figure 1</ref>, the ques- tion "What version of Ubuntu do you have?" can be asked in other ways like "What version of operating system are you using?", "Version of OS?", etc. Addi- tionally, a question can generate several different answers. For instance, "Ubuntu 14.04 LTS", "Ubuntu 12.0", "Ubuntu 9.0", are all valid answers. To cap- ture these generalizations, we define the following loss function:</p><formula xml:id="formula_2">loss ans (¯ p, ¯ q, ¯ a, Q) = ||F ans (¯ p, ¯ q) − ¯ a|| 2<label>(3)</label></formula><formula xml:id="formula_3">+ j∈Q ||F ans (¯ p, ¯ q) − ¯ a j || 2 (1 − tanh (||¯ q − ¯ q j || 2 ))</formula><p>In equation 3, the first term forces the answer rep- resentation F ans (¯ p i , ¯ q i ) to be as close as possible to the correct answer a i and the second term forces it to be close to the answer a j corresponding to a question q j very similar to q i (i.e. || ¯ q i − ¯ q j || is near zero).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Utility Calculator</head><p>Given a post p and an answer candidate a k , our third step is to calculate the utility of the updated post i.e. U(p + a k ) which measures how use- ful it would be if a given post p were augmented with an answer a k . We use the intuition that a post p i , when updated with the answer a i that it is paired with in our dataset, would be more com- plete than if it is updated with some other an- swer a j . Therefore we label all the (p i , a i ) pairs from our dataset as positive (y = 1) and label p i paired with other nine answer candidates gen- erated using Lucene ( §3.1) as negative (y = 0). The utility of the updated post is then defined as</p><formula xml:id="formula_4">U(p + a) = σ(F utility (¯ p, ¯ a))</formula><p>where F utility is a feedforward neural network. We want this utility to be close to one for all the positively labelled (p, a) pairs and close to zero for all the negatively labelled (p, a) pairs. We therefore define our loss using the binary cross-entropy formulation below: loss util (y, ¯ p, ¯ a) = y log(σ(F utility (¯ p, ¯ a))) (4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Our joint neural network model</head><p>Our fundamental representation is based on re- current neural network, specifically long short- term memory architecture (LSTM) <ref type="bibr" target="#b4">(Hochreiter and Schmidhuber, 1997</ref> obtained using a GloVe ( <ref type="bibr" target="#b12">Pennington et al., 2014</ref>) model trained on the entire datadump of StackEx- change. We define three LSTMs corresponding to p, q and a and two feedforward neural networks corresponding to our answer model F ans (¯ p, ¯ q) and our utility calculator F utility (¯ p, ¯ a). We jointly train the parameters of all our neural network mod- els to minimize the sum of the loss of our answer model (Eq 3) and our utility calculator (Eq 4):</p><formula xml:id="formula_5">i loss ans (¯ p i , ¯ q i , ¯ a i , Q i ) + loss util (y i , ¯ p i , ¯ a i ) (5)</formula><p>Given such an estimate P <ref type="bibr">[a|p, q]</ref> of an answer and a utility U(p + a) of the updated post, predictions can be done by choosing that "q" that maximizes Eq 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>StackExchange is a network of online question answering websites containing timestamped infor- mation about the posts, comments on the post and the history of the revisions made to the post. Us- ing this, we create our dataset of {post, question, answer} triples: where post is the initial unedited post, question is the comment containing a ques- tion and answer is the edit made to the post that matches the question comment <ref type="bibr">3</ref> . We extract a to- tal of 37K triples from the following three domains of StackExchange: askubuntu, unix and superuser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setups</head><p>We define our task as given a post and 10 question candidates, select the correct question candidate. For every post p in our dataset of (p, q, a) triples, the question q paired with p is our positive ques- tion candidate. We define two approaches to gen- erate negative question candidates: Lucene Negative Candidates: We retrieve nine question candidates using Lucene ( §3.1) and Random Negative Candidates: We randomly sample nine other questions from our dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Primary Research Questions</head><p>Our primary research questions that we evaluate experimentally are: a. Does a neural architecture improve upon a sim- ple bag-of-ngrams baseline? b. Does the EVPI formalism provide leverage over a similarly expressive feed-forward network? c. How much harder is the task when the negative candidate questions come from Lucene rather than selected randomly?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Baseline Methods</head><p>Random: Randomly permute the set of 10 candi- date questions uniformly. Bag-of-ngrams: Construct a bag-of-ngrams rep- resentation for the post, the question and the an- swer and train a classifier to minimize hinge loss on misclassification loss. Feed-forward neural: Concatenate the post LSTM representation, the question LSTM rep- resentation and the answer LSTM representation and feed it through a feed forward neural network of two fully-connected hidden layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results</head><p>We describe results on a test split of askubuntu when our models are trained on the union of all data, summarized in <ref type="table">Table 1</ref>. The left half of this table shows results when the candidate sets is from Lucene-the "hard" setting and the right half of this table shows the same results when the candi- date set is chosen randomly-the "easy" setting. Here, we see that for all the evaluation metrics, EVPI outperforms all the baselines by at least a few percentage points. A final performance of 51% recall at 3 in the "hard" setting is encourag- ing, though clearly there is a long way to go for a perfect system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>33</head><p>5 How good are humans at this task?</p><p>In this section we address two natural questions: (a) How does the performance of our system com- pare to a human solving the same task? (b) Just be- cause the system selects a question that is not the exact gold standard question, is it certainly wrong?</p><p>To answer these questions, we had 14 computer science graduate students perform the task on 50 examples. Most of these graduate students are not experts in unix or ubuntu, but are knowledgable. Given a post and a randomized list of ten possi- ble questions, they were instructed to select what they thought was the single best question to ask, and additionally mark as "valid" any additional questions that they thought would also be okay to ask. We also asked them to rate their confidence in {0, 1, 2, 3}. Most found this task quite challeng- ing because many of the questions are about subtle nuances of operating system behavior. These annotator's accuracy on the "hard" task of Lucene-selected questions, was only 36%, sig- nificantly better than our best system (23%), but still far from perfect. If we limited to those ex- amples on which they were more confident (con- fidence of 2 or 3), their accuracy raised to 42%, but never surpassed that. A major problem for the human annotators is the amount of background knowledge required to solve this problem. On an easier domain, or with annotators who are truly ex- perts, we might expect these numbers to be higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Proposed Research Directions</head><p>In our preliminary work, we focus on the question selection problem i.e. select the right clarification question from a set of prior questions. To enable our system to generalize well to new context, we propose two future research directions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Template Based Question Generation</head><p>Consider a template like "What version of are you running?". This template can generate thousands of specific variants found in the data like "What version of Ubuntu are you running?", "What version of apt-get are you running?", etc. We propose the following four step approach to our template-based question generation method:</p><p>1. Cluster questions based on their lexical and semantic similarity. 2. Generate a template for each cluster by re- moving topic specific words from questions.</p><p>3. Given a post, select a question template from a set of candidate question templates using a model similar to our preliminary work. 4. Finally, fill in the blanks in the template using topic specific words retrieved from the post.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Neural Network Generative Model</head><p>Sequence-to-sequence neural network models have proven to be effective for several lan- guage generation tasks like machine translation <ref type="bibr" target="#b16">(Sutskever et al., 2014</ref>), dialog generation (Ser- ban et al., 2016), etc. These models are based on an encoder-decoder framework where the encoder takes in a sequence of words and generates a vec- tor representation which is then taken in by a de- coder to generate the output sequence of words. On similar lines, we propose a model for gener- ating the clarification question one word at a time, given the words of a post. A recent neural gener- ative question answering model ( <ref type="bibr" target="#b18">Yin et al., 2016</ref>) built an answer language model which decides, at each time step, whether to generate a common vo- cabulary word or an answer word retrieved from a knowledge base. Inspired from this work, we pro- pose to build a question generation model which will decide, at each time step, whether to gener- ate a common vocabulary word or a topic specific word retrieved from the current post, thus incor- porating the template-based method into a more general neural network framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>b) Is the moon waxing or waning? (c) Are you running Ubuntu 14.10 kernel 4.4.0-59- generic on an x86 64 architecture?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A post on an online Q &amp; A forum "askubuntu.com" is updated to fill the missing information pointed out by the question comment</figDesc><graphic url="image-1.png" coords="1,309.83,224.03,213.17,159.83" type="bitmap" /></figure>

			<note place="foot" n="1"> We use data from StackExchange; per license cc-by-sa 3.0, the data is &quot;intended to be shared and remixed&quot; (with attribution). We will release all of the data we extract.</note>

			<note place="foot" n="2"> https://lucene.apache.org/</note>

			<note place="foot" n="3"> We measure the cosine similarity between the averaged word embeddings of the question and the edit.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In our work, we introduce a novel dataset for clar-ification question generation, and build a model that integrates neural network structure with the classic notion of expected value of perfect infor-mation. Our preliminary model learns to select the right question from a set of candidate ques-tions. We propose two future directions for auto-matically generating clarification questions.</p><p>One main avenue for improvement of this work is in evaluation: given that this task is so diffi-cult for humans, but also given that there is no single right question to ask, how can we better measure performance at this task? This is exactly the same question faced in dialog and generation <ref type="bibr" target="#b11">(Paek, 2001;</ref><ref type="bibr" target="#b9">Lowe et al., 2015;</ref><ref type="bibr" target="#b7">Liu et al., 2016;</ref><ref type="bibr" target="#b5">Kannan and Vinyals, 2017)</ref>. Finally, asking ques-tion is a natural component of dialog, and build-ing a collaborative dialog system that can naturally converse with a user is a broad long term goal.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The value of information and stochastic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mordecai</forename><surname>Avriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="954" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The interactive stance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ginzburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic factual question generation from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Adversarial evaluation of dialogue models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08198</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep questions without deep understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="889" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic question generation for literature review writing support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rafael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasile</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Tutoring Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Margaret Mitchell, Xiaodong He, and Lucy Vanderwende</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1802" to="1813" />
		</imprint>
	</monogr>
	<note>Generating natural questions about an image</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Empirical methods for evaluating dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Evaluation for Language and Dialogue Systems</title>
		<meeting>the workshop on Evaluation for Language and Dialogue Systems</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics, page 2</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The theory and use of clarification requests in dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew Richard John</forename><surname>Purver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Question generation shared task and evaluation challenge: Status report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vasile Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Piwek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Stoyanchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Wyse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Lintean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th European Workshop on Natural Language Generation. Association for Computational Linguistics</title>
		<meeting>the 13th European Workshop on Natural Language Generation. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="318" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The importance of being important: Question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on the Question Generation Shared Task Evaluation Challenge</title>
		<meeting>the 1st Workshop on the Question Generation Shared Task Evaluation Challenge<address><addrLine>Arlington, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Neural generative question answering. International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
