<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Persona-Based Neural Conversation Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
							<email>jiweil@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><forename type="middle">P</forename><surname>Spithourakis</surname></persName>
							<email>g.spithourakis@cs.ucl.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Persona-Based Neural Conversation Model</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="994" to="1003"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed em-beddings that capture individual characteristics such as background information and speaking style. A dyadic speaker-addressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gains in speaker consistency as measured by human judges.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As conversational agents gain traction as user in- terfaces, there has been growing research inter- est in training naturalistic conversation systems from large volumes of human-to-human interac- tions ( <ref type="bibr" target="#b19">Ritter et al., 2011;</ref><ref type="bibr" target="#b10">Li et al., 2016)</ref>. One major is- sue for these data-driven systems is their propensity to select the response with greatest likelihood-in effect a consensus response of the humans repre- sented in the training data. Outputs are frequently vague or non-committal ( <ref type="bibr" target="#b10">Li et al., 2016)</ref>, and when not, they can be wildly inconsistent, as illustrated in <ref type="table">Table 1</ref>.</p><p>In this paper, we address the challenge of consis- tency and how to endow data-driven systems with the coherent "persona" needed to model human- like behavior, whether as personal assistants, per- * The entirety of this work was conducted at Microsoft. sonalized avatar-like agents, or game characters. <ref type="bibr">1</ref> For present purposes, we will define PERSONA as the character that an artificial agent, as actor, plays or performs during conversational interac- tions. A persona can be viewed as a composite of elements of identity (background facts or user profile), language behavior, and interaction style. A persona is also adaptive, since an agent may need to present different facets to different human interlocutors depending on the interaction.</p><p>Fortunately, neural models of conversation gen- eration ( <ref type="bibr" target="#b22">Shang et al., 2015;</ref><ref type="bibr" target="#b10">Li et al., 2016</ref>) provide a straightforward mechanism for incorporating per- sonas as embeddings. We therefore explore two per-sona models, a single-speaker SPEAKER MODEL and a dyadic SPEAKER-ADDRESSEE MODEL, within a sequence-to-sequence (SEQ2SEQ) frame- work ( <ref type="bibr" target="#b24">Sutskever et al., 2014</ref>). The Speaker Model integrates a speaker-level vector representation into the target part of the SEQ2SEQ model. Analo- gously, the Speaker-Addressee model encodes the interaction patterns of two interlocutors by con- structing an interaction representation from their individual embeddings and incorporating it into the SEQ2SEQ model. These persona vectors are trained on human-human conversation data and used at test time to generate personalized responses. Our experiments on an open-domain corpus of Twitter conversations and dialog datasets compris- ing TV series scripts show that leveraging persona vectors can improve relative performance up to 20% in BLEU score and 12% in perplexity, with a commensurate gain in consistency as judged by human annotators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work follows the line of investigation initiated by <ref type="bibr" target="#b19">Ritter et al. (2011)</ref> who treat generation of con- versational dialog as a statistical machine transla- tion (SMT) problem. <ref type="bibr" target="#b19">Ritter et al. (2011)</ref> represents a break with previous and contemporaneous dialog work that relies extensively on hand-coded rules, typically either building statistical models on top of heuristic rules or templates ( <ref type="bibr" target="#b9">Levin et al., 2000;</ref><ref type="bibr" target="#b34">Young et al., 2010;</ref><ref type="bibr" target="#b28">Walker et al., 2003;</ref><ref type="bibr" target="#b17">Pieraccini et al., 2009;</ref><ref type="bibr" target="#b31">Wang et al., 2011</ref>) or learning genera- tion rules from a minimal set of authored rules or labels <ref type="bibr" target="#b15">(Oh and Rudnicky, 2000;</ref><ref type="bibr" target="#b18">Ratnaparkhi, 2002;</ref><ref type="bibr" target="#b2">Banchs and Li, 2012;</ref><ref type="bibr" target="#b0">Ameixa et al., 2014;</ref><ref type="bibr" target="#b13">Nio et al., 2014;</ref><ref type="bibr" target="#b3">Chen et al., 2013</ref>). More recently <ref type="bibr" target="#b32">(Wen et al., 2015)</ref> have used a Long Short-Term Memory (LSTM) <ref type="bibr" target="#b7">(Hochreiter and Schmidhuber, 1997</ref>) to learn from unaligned data in order to reduce the heuristic space of sentence planning and surface realization.</p><p>The SMT model proposed by Ritter et al., on the other hand, is end-to-end, purely data-driven, and contains no explicit model of dialog structure; the model learns to converse from human-to-human conversational corpora. Progress in SMT stemming from the use of neural language models ( <ref type="bibr" target="#b24">Sutskever et al., 2014;</ref><ref type="bibr" target="#b6">Gao et al., 2014;</ref><ref type="bibr" target="#b1">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b12">Luong et al., 2015)</ref> has inspired efforts to extend these neural techniques to SMT-based conversa- tional response generation.  augments <ref type="bibr" target="#b19">Ritter et al. (2011)</ref> by rescoring out- puts using a SEQ2SEQ model conditioned on con- versation history. Other researchers have recently used SEQ2SEQ to directly generate responses in an end-to-end fashion without relying on SMT phrase tables ( <ref type="bibr" target="#b21">Serban et al., 2015;</ref><ref type="bibr" target="#b22">Shang et al., 2015;</ref>. <ref type="bibr" target="#b21">Serban et al. (2015)</ref> propose a hierarchical neural model aimed at capturing de- pendencies over an extended conversation history. Recent work by <ref type="bibr" target="#b10">Li et al. (2016)</ref> measures mutual information between message and response in or- der to reduce the proportion of generic responses typical of SEQ2SEQ systems. <ref type="bibr" target="#b33">Yao et al. (2015)</ref> em- ploy an intention network to maintain the relevance of responses.</p><p>Modeling of users and speakers has been exten- sively studied within the standard dialog model- ing framework (e.g., <ref type="bibr" target="#b27">(Wahlster and Kobsa, 1989;</ref><ref type="bibr" target="#b8">Kobsa, 1990;</ref><ref type="bibr" target="#b20">Schatztnann et al., 2005;</ref>). Since generating meaningful re- sponses in an open-domain scenario is intrinsi- cally difficult in conventional dialog systems, ex- isting models often focus on generalizing character style on the basis of qualitative statistical analysis ( <ref type="bibr" target="#b30">Walker et al., 2012;</ref>). The present work, by contrast, is in the vein of the SEQ2SEQ models of  and <ref type="bibr" target="#b10">Li et al. (2016)</ref>, enriching these models by training persona vectors directly from conversational data and relevant side-information, and incorporating these directly into the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sequence-to-Sequence Models</head><p>Given a sequence of inputs X = {x 1 , x 2 , ..., x n X }, an LSTM associates each time step with an input gate, a memory gate and an output gate, respec- tively denoted as i t , f t and o t . We distinguish e and h where e t denotes the vector for an individual text unit (for example, a word or sentence) at time step t while h t denotes the vector computed by the LSTM model at time t by combining e t and h t−1 . c t is the cell state vector at time t, and σ denotes the sigmoid function. Then, the vector representation h t for each time step t is given by:</p><formula xml:id="formula_0">    i t f t o t l t     =     σ σ σ tanh     W · h t−1 e s t<label>(1)</label></formula><formula xml:id="formula_1">c t = f t · c t−1 + i t · l t<label>(2)</label></formula><formula xml:id="formula_2">h s t = o t · tanh(c t )<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">W i , W f , W o , W l ∈ R K×2K .</formula><p>In SEQ2SEQ generation tasks, each input X is paired with a sequence of outputs to predict: Y = {y 1 , y 2 , ..., y n Y }. The LSTM defines a distribu- tion over outputs and sequentially predicts tokens using a softmax function:</p><formula xml:id="formula_4">p(Y |X) = ny t=1 p(y t |x 1 , x 2 , ..., x t , y 1 , y 2 , ..., y t−1 ) = ny t=1 exp(f (h t−1 , e yt )) y exp(f (h t−1 , e y ))</formula><p>where f (h t−1 , e yt ) denotes the activation function between h t−1 and e yt . Each sentence terminates with a special end-of-sentence symbol EOS. In keeping with common practices, inputs and out- puts use different LSTMs with separate parameters to capture different compositional patterns.</p><p>During decoding, the algorithm terminates when an EOS token is predicted. At each time step, either a greedy approach or beam search can be adopted for word prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Personalized Response Generation</head><p>Our work introduces two persona-based models: the Speaker Model, which models the personal- ity of the respondent, and the Speaker-Addressee Model which models the way the respondent adapts their speech to a given addressee -a linguistic phe- nomenon known as lexical entrainment <ref type="bibr" target="#b4">(Deutsch and Pechmann, 1982)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Notation</head><p>For the response generation task, let M de- note the input word sequence (message) M = {m 1 , m 2 , ..., m I }. R denotes the word sequence in response to M , where R = {r 1 , r 2 , ..., r J , EOS} and J is the length of the response (terminated by an EOS token). r t denotes a word token that is associated with a K dimensional distinct word embedding e t . V is the vocabulary size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Speaker Model</head><p>Our first model is the Speaker Model, which mod- els the respondent alone. This model represents each individual speaker as a vector or embedding, which encodes speaker-specific information (e.g., dialect, register, age, gender, personal informa- tion) that influences the content and style of her responses. Note that these attributes are not ex- plicitly annotated, which would be tremendously expensive for our datasets. Instead, our model man- ages to cluster users along some of these traits (e.g., age, country of residence) based on the responses alone. <ref type="figure" target="#fig_0">Figure 1</ref> gives a brief illustration of the Speaker Model. Each speaker i ∈ <ref type="bibr">[1, N ]</ref> is associated with a user-level representation v i ∈ R K×1 . As in stan- dard SEQ2SEQ models, we first encode message S into a vector representation h S using the source LSTM. Then for each step in the target side, hidden units are obtained by combining the representation produced by the target LSTM at the previous time step, the word representations at the current time step, and the speaker embedding</p><formula xml:id="formula_5">v i :     i t f t o t l t     =     σ σ σ tanh     W ·   h t−1 e s t v i   (4) c t = f t · c t−1 + i t · l t (5) h s t = o t · tanh(c t )<label>(6)</label></formula><p>where W ∈ R 4K×3K . In this way, speaker informa- tion is encoded and injected into the hidden layer at each time step and thus helps predict personalized responses throughout the generation process. The Speaker embedding {v i } is shared across all con- versations that involve speaker i. {v i } are learned by back propagating word prediction errors to each neural component during training.</p><p>Another useful property of this model is that it helps infer answers to questions even if the evi- dence is not readily present in the training set. This is important as the training data does not contain ex- plicit information about every attribute of each user (e.g., gender, age, country of residence). The model learns speaker representations based on conversa- tional content produced by different speakers, and speakers producing similar responses tend to have similar embeddings, occupying nearby positions in the vector space. This way, the training data of speakers nearby in vector space help increase the generalization capability of the speaker model. For example, consider two speakers i and j who sound distinctly British, and who are therefore close in speaker embedding space. Now, suppose that, in the training data, speaker i was asked Where do you live? and responded in the UK. Even if speaker j was never asked the same question, this answer can help influence a good response from speaker j, and this without explicitly labeled geo-location information.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EOS Rob</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Speaker-Addressee Model</head><p>A natural extension of the Speaker Model is a model that is sensitive to speaker-addressee inter- action patterns within the conversation. Indeed, speaking style, register, and content does not vary only with the identity of the speaker, but also with that of the addressee. For example, in scripts for the TV series Friends used in some of our exper- iments, the character Ross often talks differently to his sister Monica than to Rachel, with whom he is engaged in an on-again off-again relationship throughout the series. The proposed Speaker-Addressee Model oper- ates as follows: We wish to predict how speaker i would respond to a message produced by speaker j. Similarly to the Speaker model, we associate each speaker with a K dimensional speaker-level repre- sentation, namely v i for user i and v j for user j. We obtain an interactive representation V i,j ∈ R K×1 by linearly combining user vectors v i and v j in an attempt to model the interactive style of user i towards user j,</p><formula xml:id="formula_6">V i,j = tanh(W 1 · v i + W 2 · v 2 )<label>(7)</label></formula><p>where W 1 , W 2 ∈ R K×K . V i,j is then linearly in- corporated into LSTM models at each step in the target:</p><formula xml:id="formula_7">    i t f t o t l t     =     σ σ σ tanh     W ·   h t−1 e s t V i,j  <label>(8)</label></formula><formula xml:id="formula_8">c t = f t · c t−1 + i t · l t<label>(9)</label></formula><formula xml:id="formula_9">h s t = o t · tanh(c t )<label>(10)</label></formula><p>V i,j depends on both speaker and addressee and the same speaker will thus respond differently to a message from different interlocutors. One po- tential issue with Speaker-Addressee modelling is the difficulty involved in collecting a large-scale training dataset in which each speaker is involved in conversation with a wide variety of people. Like the Speaker Model, however, the Speaker- Addressee Model derives generalization capabil- ities from speaker embeddings. Even if the two speakers at test time (i and j) were never involved in the same conversation in the training data, two speakers i and j who are respectively close in embeddings may have been, and this can help mod- elling how i should respond to j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Decoding and Reranking</head><p>For decoding, the N-best lists are generated us- ing the decoder with beam size B = 200. We set a maximum length of 20 for the generated candidates. Decoding operates as follows: At each time step, we first examine all B × B possible next-word can- didates, and add all hypothesis ending with an EOS token to the N-best list. We then preserve the top-B unfinished hypotheses and move to the next word position.</p><p>To deal with the issue that SEQ2SEQ models tend to generate generic and commonplace re- sponses such as I don't know, we follow <ref type="bibr" target="#b10">Li et al. (2016)</ref> by reranking the generated N-best list using a scoring function that linearly combines a length penalty and the log likelihood of the source given the target: log p(R|M, v) + λ log p(M |R) + γ|R| <ref type="formula" target="#formula_0">(11)</ref> where p(R|M, v) denotes the probability of the generated response given the message M and the respondent's speaker ID. |R| denotes the length of the target and γ denotes the associated penalty weight. We optimize γ and λ on N-best lists of response candidates generated from the develop- ment set using MERT <ref type="bibr" target="#b14">(Och, 2003)</ref> by optimizing BLEU. To compute p(M |R), we train an inverse SEQ2SEQ model by swapping messages and re- sponses. We trained standard SEQ2SEQ models for p(M |R) with no speaker information considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Twitter Persona Dataset</head><p>Data Collection Training data for the Speaker Model was extracted from the Twitter FireHose for the six-month period beginning January 1, 2012. We limited the sequences to those where the respon- ders had engaged in at least 60 (and at most 300) 3-turn conversational interactions during the period, in other words, users who reasonably frequently en- gaged in conversation. This yielded a set of 74,003 users who took part in a minimum of 60 and a max- imum of 164 conversational turns (average: 92.24, median: 90). The dataset extracted using responses by these "conversationalists" contained 24,725,711 3-turn sliding-window (context-message-response) conversational sequences.</p><p>In addition, we sampled 12000 3-turn conversa- tions from the same user set from the Twitter Fire- Hose for the three-month period beginning July 1, 2012, and set these aside as development, valida- tion, and test sets (4000 conversational sequences each). Note that development, validation, and test sets for this data are single-reference, which is by design. Multiple reference responses would typ- ically require acquiring responses from different people, which would confound different personas.</p><p>Training Protocols We trained four-layer SEQ2SEQ models on the Twitter corpus following the approach of ( <ref type="bibr" target="#b24">Sutskever et al., 2014</ref>). Details are as follows:</p><p>• 4 layer LSTM models with 1,000 hidden cells for each layer.</p><p>• Batch size is set to 128.</p><p>• Learning rate is set to 1.0.</p><p>• Parameters are initialized by sampling from the uniform distribution [−0.1, 0.1].</p><p>• Gradients are clipped to avoid gradient explo- sion with a threshold of 5.</p><p>• Vocabulary size is limited to 50,000.</p><p>• Dropout rate is set to 0.2. Source and target LSTMs use different sets of pa- rameters. We ran 14 epochs, and training took roughly a month to finish on a Tesla K40 GPU machine.</p><p>As only speaker IDs of responses were specified when compiling the Twitter dataset, experiments on this dataset were limited to the Speaker Model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Twitter Sordoni Dataset</head><p>The Twitter Persona Dataset was collected for this paper for experiments with speaker ID informa- tion. To obtain a point of comparison with prior state-of-the-art work ( <ref type="bibr" target="#b10">Li et al., 2016)</ref>, we measure our baseline (non-persona) LSTM model against prior work on the dataset of ( , which we call the Twit- ter Sordoni Dataset. We only use its test-set por- tion, which contains responses for 2114 context and messages. It is important to note that the Sor- doni dataset offers up to 10 references per message, while the Twitter Persona dataset has only 1 refer- ence per message. Thus BLEU scores cannot be compared across the two Twitter datasets (BLEU scores on 10 references are generally much higher than with 1 reference). Details of this dataset are in ( ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Television Series Transcripts</head><p>Data Collection For the dyadic Speaker- Addressee Model we used scripts from the American television comedies Friends 2 and The Big Bang Theory, 3 available from Internet Movie Script Database (IMSDb). <ref type="bibr">4</ref> We collected 13 main characters from the two series in a corpus of 69,565 turns. We split the corpus into train- ing/development/testing sets, with development and testing sets each of about 2,000 turns.</p><p>Training Since the relatively small size of the dataset does not allow for training an open domain dialog model, we adopted a domain adaption strat- egy where we first trained a standard SEQ2SEQ System BLEU MT baseline <ref type="bibr" target="#b19">(Ritter et al., 2011)</ref> 3.60% Standard LSTM MMI ( <ref type="bibr" target="#b10">Li et al., 2016)</ref> 5.26% Standard LSTM MMI (our system) 5.82% Human 6.08% <ref type="table">Table 2</ref>: BLEU on the Twitter Sordoni dataset (10 references). We contrast our baseline against an SMT baseline ( <ref type="bibr" target="#b19">Ritter et al., 2011)</ref>, and the best result ( <ref type="bibr" target="#b10">Li et al., 2016</ref>) on the established dataset of ( . The last result is for a human oracle, but it is not directly comparable as the oracle BLEU is computed in a leave-one-out fashion, having one less reference available. We nevertheless provide this result to give a sense that these BLEU scores of 5-6% are not unreasonable. models using a much larger OpenSubtitles (OSDb) dataset <ref type="bibr" target="#b25">(Tiedemann, 2009)</ref>, and then adapting the pre-trained model to the TV series dataset.</p><p>The OSDb dataset is a large, noisy, open-domain dataset containing roughly 60M-70M scripted lines spoken by movie characters. This dataset does not specify which character speaks each subtitle line, which prevents us from inferring speaker turns. Fol- lowing , we make the simplify- ing assumption that each line of subtitle constitutes a full speaker turn. <ref type="bibr">5</ref> We trained standard SEQ2SEQ models on OSDb dataset, following the protocols already described in Section 5.1. We run 10 itera- tions over the training set.</p><p>We initialize word embeddings and LSTM pa- rameters in the Speaker Model and the Speaker- Addressee model using parameters learned from OpenSubtitles datasets. User embeddings are ran- domly initialized from [−0.1, 0.1]. We then ran 5 additional epochs until the perplexity on the devel- opment set stabilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation</head><p>Following ( <ref type="bibr" target="#b10">Li et al., 2016)</ref> we used BLEU ( <ref type="bibr" target="#b16">Papineni et al., 2002</ref>) for parame- ter tuning and evaluation. BLEU has been shown to correlate well with human judgment on the re- sponse generation task, as demonstrated in ( . Besides BLEU scores, we also report perplexity as an indicator of model capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Baseline</head><p>Since our main experiments are with a new dataset (the Twitter Persona Dataset), we first show that our LSTM baseline is competitive with the state-of-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Standard LSTM Speaker Model Perplexity 47.2 42.2 (−10.6%)  the-art ( <ref type="bibr" target="#b10">Li et al., 2016</ref>) on an established dataset, the Twitter Sordoni Dataset ( . Our baseline is simply our implementation of the LSTM-MMI of ( <ref type="bibr" target="#b10">Li et al., 2016)</ref>, so results should be relatively close to their reported results. <ref type="table">Table 2</ref> summarizes our results against prior work. We see that our system actually does better than ( <ref type="bibr" target="#b10">Li et al., 2016)</ref>, and we attribute the improvement to a larger training corpus, the use of dropout during training, and possibly to the "conversationalist" nature of our corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>We first report performance on the Twitter Persona dataset. Perplexity is reported in <ref type="table" target="#tab_2">Table 3</ref>. We ob- serve about a 10% decrease in perplexity for the Speaker model over the standard SEQ2SEQ model. In terms of BLEU scores <ref type="table" target="#tab_3">(Table 4)</ref>, a significant per- formance boost is observed for the Speaker model over the standard SEQ2SEQ model, yielding an in- crease of 21% in the maximum likelihood (MLE) setting and 11.7% for mutual information setting (MMI). In line with findings in ( <ref type="bibr" target="#b10">Li et al., 2016</ref>), we observe a consistent performance boost introduced by the MMI objective function over a standard SEQ2SEQ model based on the MLE objective func- tion. It is worth noting that our persona models are more beneficial to the MLE models than to the MMI models. This result is intuitive as the persona models help make Standard LSTM MLE outputs more informative and less bland, and thus make the use of MMI less critical. For the TV Series dataset, perplexity and BLEU scores are respectively reported in <ref type="table">Table 5</ref> and Ta- ble 6. As can be seen, the Speaker and Speaker- Addressee models respectively achieve perplexity values of 25.4 and 25.0 on the TV-series dataset,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Standard LSTM Speaker Model Speaker-Addressee Model Perplexity 27.3 25.4 (−7.0%) 25.0 (−8.4%) <ref type="table">Table 5</ref>: Perplexity for standard SEQ2SEQ and persona models on the TV series dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Standard LSTM Speaker Model</head><p>Speaker-Addressee Model MLE 1.60% 1.82% (+13.7%) 1.83% (+14.3%) MMI</p><p>1.70% 1.90% (+10.6%) 1.88% (+10.9%) <ref type="table">Table 6</ref>: BLEU on the TV series dataset (1 reference), for the standard SEQ2SEQ and persona models.</p><p>7.0% and 8.4% percent lower than the correspon- dent standard SEQ2SEQ models. In terms of BLEU score, we observe a similar performance boost as on the Twitter dataset, in which the Speaker model and the Speaker-Addressee model outper- form the standard SEQ2SEQ model by 13.7% and 10.6%. By comparing the Speaker-Addressee model against the Speaker model on the TV Se- ries dataset, we do not observe a significant dif- ference. We suspect that this is primarily due to the relatively small size of the dataset where the interactive patterns might not be fully captured.</p><p>Smaller values of perplexity are observed for the Television Series dataset than the Twitter dataset, the perplexity of which is over 40, presumably due to the noisier nature of Twitter dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Qualitative Analysis</head><p>Diverse Responses by Different Speakers Ta- ble 7 represents responses generated by persona models in response to three different input ques- tions. We randomly selected 10 speakers (without cherry-picking) from the original Twitter dataset. We collected their user level representations from a speaker look-up table and integrated them into the decoding models. The model tends to generate specific responses for different people in response to the factual questions. 6 <ref type="table" target="#tab_5">Table 8</ref> shows responses generated from the Speaker-Addressee Model using the TV-series dataset. Interestingly, we regularly observe that this model is sensitive to the identity of the ad- dressee, generating words specifically targeted at that addressee (e.g., her name). For example, the model produces Of course, I love you, Emily in response to an input from Emily. Also, the model generates Of course I love you. ( kisses him), where the pronoun "him" accurately identifies the gender of the addressee. user9 I work at a gas station. user10 I don't know # message What did you have for dinner? baseline I had fish and chips.</p><p>user1 I had spag bol. user2 Chicken and chips. user3 Chicken and rice. user4 Fish and chips. user5 I had spag bol. user6 I had Mexican food. user7 Salad... user8 I had chicken and chips. user9 I had spag bol. user10 Pizza. <ref type="table">Table 7</ref>: Responses generated by the baseline (LSTM-MMI) and the Speaker Model for ten randomly selected users, with- out cherry picking. # indicates poor-quality responses pro- duced by the system.</p><p>Human Evaluation We conducted a human eval- uation of outputs from the Speaker Model, using a crowdsourcing service. Since we cannot expect crowdsourced human judges to know or attempt to learn the ground truth of Twitter users who are not well-known public figures, we designed our experi- ment to evaluate the consistency of outputs associ- ated with the speaker IDs. To this end, we collected 24 pairs of questions for which we would expect message Do you love me? baseline Of course, I love you.</p><p>addressee: Emily, speaker: Sheldon response Of course, I love you, Emily.</p><p>addressee: Emily, speaker: Penny response Of course, I love you, Emily.</p><p>addressee: Leonard, speaker: Penny response Of course, I love you, Leonard.</p><p>addressee: Monica, speaker: Chandler response Of course I love you. I want to marry you.</p><p>addressee: Rachel, speaker: Chandler response Of course I love you.</p><p>addressee: Ross, speaker: Chandler response Of course I love you.</p><p>addressee: Ross, speaker: Rachel response Of course I love you. (kisses him) addressee: Emily, speaker: Rachel response Of course I love you. responses to be consistent if the persona model is coherent. For example, responses to the questions What country do you live in? and What city do you live in? would be considered consistent if the an- swers were England and London respectively, but not if they were UK and Chicago. Similarly, the responses to Are you vegan or vegetarian? and Do you eat beef? are consistent if the answers gener- ated are vegan and absolutely not, but not if they are vegan and I love beef. We collected 20 pairs of outputs for randomly-selected personas provided by the Speaker Model for each question pair (480 response pairs total). We also obtained the corre- sponding outputs from the baseline MMI-enhanced SEQ2SEQ system.</p><p>Since our purpose is to measure the gain in con- sistency over the baseline system, we presented the pairs of answers system-pairwise, i.e., 4 responses, 2 from each system, displayed on the screen, and asked judges to decide which of the two systems was more consistent. The position in which the system pairs were presented on the screen was ran- domized. The two systems were judged on 5-point zero-sum scale, assigning a score of 2 (-2) if one system was judged more (less) consistent than the other, and 1 (-1) if one was rated "somewhat" more (less) consistent. Ties were assigned a score of zero. Five judges rated each pair and their scores were averaged and remapped into 5 equal-width bins. After discarding ties, we found the persona model was judged either "more consistent" or "somewhat more consistent" in 56.7% of cases. If we ignore the "somewhat more consistent" judgments, the persona model wins in 6.1% of cases, compared User1 message Where is your hometown? response I'm from England. message Where are you from? response I'm from England. message In which city do you live now? response I live in London. message In which country do you live now? response I live in England. message What is your major? response Business. You? message What did you study in college? response I did business studies. message How old are you? response I'm 18. message What is your age? response I'm 18. User2 message Where is your hometown? response I live in Indonesia. message Where are you from? response England, you? message In which city do you live now? response I live in Jakarta. message In which country do you live now? response I live in Indonesia. message What is your major? response Business, you? message What did you study in college? response Psychology, you? message How old are you? response I'm 18. message What is your age? response I'm 16. <ref type="table">Table 9</ref>: Examples of speaker consistency and inconsistency generated by the Speaker Model with only 1.6% for the baseline model. It should be emphasized that the baseline model is a strong baseline, since it represents the consensus of all 70K Twitter users in the dataset 7 . <ref type="table">Table 9</ref> illustrates how consistency is an emer- gent property of two arbitrarily selected users. The model is capable of discovering the relations be- tween different categories of location such as Lon- don and the UK, Jakarta and Indonesia. However, the model also makes inconsistent response de- cisions, generating different answers in the sec- ond example in response to questions asking about age or major. Our proposed persona models inte- grate user embeddings into the LSTM, and thus can be viewed as encapsulating a trade-off between a persona-specific generation model and a general conversational model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have presented two persona-based response generation models for open-domain conversation generation. There are many other dimensions of speaker behavior, such as mood and emotion, that are beyond the scope of the current paper and must be left to future work.</p><p>Although the gains presented by our new mod- els are not spectacular, the systems outperform our baseline SEQ2SEQ systems in terms of BLEU, per- plexity, and human judgments of speaker consis- tency. We have demonstrated that by encoding personas in distributed representations, we are able to capture personal characteristics such as speaking style and background information. In the Speaker- Addressee model, moreover, the evidence suggests that there is benefit in capturing dyadic interactions.</p><p>Our ultimate goal is to be able to take the pro- file of an arbitrary individual whose identity is not known in advance, and generate conversations that accurately emulate that individual's persona in terms of linguistic response behavior and other salient characteristics. Such a capability will dra- matically change the ways in which we interact with dialog agents of all kinds, opening up rich new possibilities for user interfaces. Given a suffi- ciently large training corpus in which a sufficiently rich variety of speakers is represented, this objec- tive does not seem too far-fetched.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustrative example of the Speaker Model introduced in this work. Speaker IDs close in embedding space tend to respond in the same manner. These speaker embeddings are learned jointly with word embeddings and all other parameters of the neural model via backpropagation. In this example, say Rob is a speaker clustered with people who often mention England in the training data, then the generation of the token 'england' at time t = 2 would be much more likely than that of 'u.s.'. A non-persona model would prefer generating in the u.s. if 'u.s.' is more represented in the training data across all speakers.</figDesc><graphic url="image-1.png" coords="4,321.69,136.98,146.62,103.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : Perplexity for standard SEQ2SEQ and the Speaker model on the Twitter Persona development set.</head><label>3</label><figDesc></figDesc><table>Model 
Objective BLEU 
Standard LSTM MLE 
0.92% 
Speaker Model MLE 
1.12% (+21.7%) 
Standard LSTM MMI 
1.41% 
Speaker Model MMI 
1.66% (+11.7%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>BLEU on the Twitter Persona dataset (1 reference), 
for the standard SEQ2SEQ model and the Speaker model using 
as objective either maximum likelihood (MLE) or maximum 
mutual information (MMI). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 8 :</head><label>8</label><figDesc>Responses to Do you love me? from the Speaker- Addressee model on the TV-series dataset using different ad- dressees and speakers.</figDesc><table></table></figure>

			<note place="foot" n="1"> (Vinyals and Le, 2015) suggest that the lack of a coherent personality makes it impossible for current systems to pass the Turing test.</note>

			<note place="foot" n="2"> https://en.wikipedia.org/wiki/Friends 3 https://en.wikipedia.org/wiki/The_ Big_Bang_Theory 4 http://www.imsdb.com</note>

			<note place="foot" n="5"> This introduces a degree of noise as consecutive lines are not necessarily from the same scene or two different speakers.</note>

			<note place="foot" n="6"> There appears to be a population bias in the training set that favors British users.</note>

			<note place="foot" n="7"> I&apos;m not pregnant is an excellent consensus answer to the question Are you pregnant?, while I&apos;m pregnant is consistent as a response only in the case of someone who also answers the question Are you a guy or a girl? with something in the vein of I&apos;m a girl.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We with to thank Stephanie Lukin, Pushmeet Kohli, Chris Quirk, Alan Ritter, and Dan Jurafsky for helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Luke, I am your father: dealing with out-of-domain requests by using movies subtitles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ameixa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Coheur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Fialho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Virtual Agents</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Learning Representations (ICLR)</title>
		<meeting>of the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">IRIS: a chatoriented dialogue system based on the vector space model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rafael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL 2012 System Demonstrations</title>
		<meeting>of the ACL 2012 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="37" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An empirical investigation of sparse log-linear models for improved dialogue act classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><forename type="middle">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8317" to="8321" />
		</imprint>
	</monogr>
	<note>2013 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Social interaction and the development of definite descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Deutsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pechmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="159" to="184" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">∆BLEU: A discriminative metric for generation tasks with intrinsically diverse targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-IJCNLP</title>
		<meeting>of ACL-IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="445" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning continuous phrase representations for translation modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="699" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">User modeling in dialog systems: Potentials and hazards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Kobsa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI &amp; society</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="214" to="231" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A stochastic model of human-machine interaction for learning dialog strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="23" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">All the world&apos;s a stage: Learning character models from film</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn A</forename><surname>Grace I Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE)</title>
		<meeting>the Seventh AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Addressing the rare word problem in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Developing non-goal dialog system based on examples of drama television</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasguido</forename><surname>Nio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirna</forename><surname>Adriani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Interaction with Robots, Knowbots and Smartphones</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="355" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stochastic language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander I</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 ANLP/NAACL Workshop on Conversational systems</title>
		<meeting>the 2000 ANLP/NAACL Workshop on Conversational systems</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Are we there yet? research in commercial spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Suendermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Dayanidhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackson</forename><surname>Liscombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text, Speech and Dialogue</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Trainable approaches to surface natural language generation and their application to conversational dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="435" to="455" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effects of the user model on simulation-based learning of dialogue strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatztnann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stuttle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Weilhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="220" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AAAI</title>
		<meeting>of AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meg</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">News from OPUS-a collection of multilingual parallel corpora with tools and interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent advances in natural language processing</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A neural conversational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML Deep Learning Workshop</title>
		<meeting>of ICML Deep Learning Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">User models in dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Wahlster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Kobsa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A trainable generator for recommendations in multimodal dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Perceived or not perceived: Film character models for expressive nlg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sawyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Grace I Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wardrip-Fruin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Buell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interactive Storytelling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="109" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An annotated corpus of film dialogue for learning and characterizing character style</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Grace I Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sawyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1373" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improving spoken dialogue understanding using phonetic mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Leuski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS Conference</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semantically conditioned LSTM-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1711" to="1721" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Attention with intention for a neural network conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<idno>abs/1510.08565</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for pomdp-based spoken dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="150" to="174" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
