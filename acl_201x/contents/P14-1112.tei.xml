<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Syntactic and Semantic Parsing with Combinatory Categorial Grammar</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
							<email>jayantk@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue Pittsburgh</addrLine>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
							<email>tom.mitchell@cmu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue Pittsburgh</addrLine>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Syntactic and Semantic Parsing with Combinatory Categorial Grammar</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1188" to="1198"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an approach to training a joint syntactic and semantic parser that combines syntactic training information from CCGbank with semantic training information from a knowledge base via distant supervision. The trained parser produces a full syntactic parse of any sentence, while simultaneously producing logical forms for portions of the sentence that have a semantic representation within the parser&apos;s predicate vocabulary. We demonstrate our approach by training a parser whose semantic representation contains 130 predicates from the NELL ontology. A semantic evaluation demonstrates that this parser produces logical forms better than both comparable prior work and a pipelined syntax-then-semantics approach. A syntactic evaluation on CCGbank demonstrates that the parser&apos;s dependency F-score is within 2.5% of state-of-the-art.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Integrating syntactic parsing with semantics has long been a goal of natural language processing and is expected to improve both syntactic and se- mantic processing. For example, semantics could help predict the differing prepositional phrase at- tachments in "I caught the butterfly with the net" and "I caught the butterfly with the spots." A joint analysis could also avoid propagating syntactic parsing errors into semantic processing, thereby improving performance.</p><p>We suggest that a large populated knowledge base should play a key role in syntactic and se- mantic parsing: in training the parser, in resolv- ing syntactic ambiguities when the trained parser is applied to new text, and in its output semantic representation. Using semantic information from the knowledge base at training and test time will ideally improve the parser's ability to solve diffi- cult syntactic parsing problems, as in the exam- ples above. A semantic representation tied to a knowledge base allows for powerful inference op- erations -such as identifying the possible entity referents of a noun phrase -that cannot be per- formed with shallower representations (e.g., frame semantics ( <ref type="bibr" target="#b2">Baker et al., 1998</ref>) or a direct conver- sion of syntax to logic <ref type="bibr" target="#b5">(Bos, 2005)</ref>).</p><p>This paper presents an approach to training a joint syntactic and semantic parser using a large background knowledge base. Our parser produces a full syntactic parse of every sentence, and fur- thermore produces logical forms for portions of the sentence that have a semantic representation within the parser's predicate vocabulary. For ex- ample, given a phrase like "my favorite town in California," our parser will assign a logical form like λx.CITY(x) ∧ LOCATEDIN(x, CALIFORNIA) to the "town in California" portion. Additionally, the parser uses predicate and entity type informa- tion during parsing to select a syntactic parse.</p><p>Our parser is trained by combining a syntactic parsing task with a distantly-supervised relation extraction task. Syntactic information is provided by CCGbank, a conversion of the Penn Treebank into the CCG formalism <ref type="bibr">(Hockenmaier and Steedman, 2002a</ref>). Semantics are learned by training the parser to extract knowledge base relation in- stances from a corpus of unlabeled sentences, in a distantly-supervised training regime. This ap- proach uses the knowledge base to avoid expen- sive manual labeling of individual sentence se- mantics. By optimizing the parser to perform both tasks simultaneously, we train a parser that pro- duces accurate syntactic and semantic analyses.</p><p>We demonstrate our approach by training a joint syntactic and semantic parser, which we call ASP. ASP produces a full syntactic analysis of every sentence while simultaneously producing logical forms containing any of 61 category and 69 re-lation predicates from NELL. Experiments with ASP demonstrate that jointly analyzing syntax and semantics improves semantic parsing perfor- mance over comparable prior work and a pipelined syntax-then-semantics approach. ASP's syntactic parsing performance is within 2.5% of state-of- the-art; however, we also find that incorporating semantic information reduces syntactic parsing ac- curacy by ∼ 0.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Prior Work</head><p>This paper combines two lines of prior work: broad coverage syntactic parsing with CCG and semantic parsing.</p><p>Broad coverage syntactic parsing with CCG has produced both resources and successful parsers. These parsers are trained and evaluated using CCGbank <ref type="bibr">(Hockenmaier and Steedman, 2002a)</ref>, an automatic conversion of the Penn Treebank into the CCG formalism. Several broad cover- age parsers have been trained using this resource <ref type="bibr" target="#b16">(Hockenmaier and Steedman, 2002b;</ref><ref type="bibr" target="#b19">Hockenmaier, 2003b</ref>). The parsing model in this paper is loosely based on C&amp;C <ref type="bibr" target="#b12">(Clark and Curran, 2007b;</ref><ref type="bibr" target="#b11">Clark and Curran, 2007a</ref>), a discriminative log- linear model for statistical parsing. Some work has also attempted to automatically derive logi- cal meaning representations directly from syntac- tic CCG parses <ref type="bibr" target="#b5">(Bos, 2005;</ref><ref type="bibr" target="#b25">Lewis and Steedman, 2013)</ref>. However, these approaches to semantics do not ground the text to beliefs in a knowledge base.</p><p>Meanwhile, work on semantic parsing has fo- cused on producing semantic parsers for answer- ing simple natural language questions <ref type="bibr" target="#b33">(Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b14">Ge and Mooney, 2005;</ref><ref type="bibr" target="#b30">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b31">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b27">Lu et al., 2008;</ref><ref type="bibr" target="#b21">Kate and Mooney, 2006;</ref><ref type="bibr" target="#b34">Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b23">Kwiatkowski et al., 2011</ref>). This line of work has typically used a corpus of sen- tences with annotated logical forms to train the parser. Recent work has relaxed the requisite su- pervision conditions <ref type="bibr" target="#b13">(Clarke et al., 2010;</ref><ref type="bibr" target="#b26">Liang et al., 2011</ref>), but has still focused on simple ques- tions. Finally, some work has looked at applying semantic parsing to answer queries against large knowledge bases, such as YAGO ( <ref type="bibr" target="#b32">Yahya et al., 2012)</ref> and <ref type="bibr">Freebase (Cai and Yates, 2013b;</ref><ref type="bibr" target="#b6">Cai and Yates, 2013a;</ref><ref type="bibr" target="#b24">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b4">Berant et al., 2013)</ref>. Although this work considers a larger number (thousands) of predicates than we do, none of these systems are capable of parsing open-domain text. Our approach is most closely related to the distantly-supervised approach of <ref type="bibr" target="#b22">Krishnamurthy and Mitchell (2012)</ref>.</p><p>The parser presented in this paper can be viewed as a combination of both a broad coverage syn- tactic parser and a semantic parser trained using distant supervision. Combining these two lines of work has synergistic effects -for example, our parser is capable of semantically analyzing con- junctions and relative clauses based on the syn- tactic annotation of these categories in CCGbank. This synergy gives our parser a richer semantic representation than previous work, while simulta- neously enabling broad coverage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parser Design</head><p>This section describes the Combinatory Categorial Grammar (CCG) parsing model used by ASP. The input to the parser is a part-of-speech tagged sen- tence, and the output is a syntactic CCG parse tree, along with zero or more logical forms representing the semantics of subspans of the sentence. These logical forms are constructed using category and relation predicates from a broad coverage knowl- edge base. The parser also outputs a collection of dependency structures summarizing the sentence's predicate-argument structure. <ref type="figure">Figure 1</ref> illustrates ASP's input/output specification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knowledge Base</head><p>The parser uses category and relation predicates from a broad coverage knowledge base both to construct logical forms and to parametrize the parsing model. The knowledge base is assumed to have two kinds of ontological structure: a gen- eralization/subsumption hierarchy and argument type constraints. This paper uses NELL's ontology <ref type="bibr">(Carlson et al., 2010)</ref>, which, for example, speci- fies that the category ORGANIZATION is a general- ization of SPORTSTEAM, and that both arguments to the LOCATEDIN relation must have type LOCA- TION. These type constraints are enforced during parsing. Throughout this paper, predicate names are shown in SMALLCAPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Syntax</head><p>ASP uses a lexicalized and semantically- typed Combinatory Categorial Grammar (CCG) <ref type="bibr" target="#b29">(Steedman, 1996)</ref>.</p><p>Most gram- matical information in CCG is encoded in a lexicon Λ, containing entries such as:</p><formula xml:id="formula_0">area / NN N λx.LOCATION(x) that / WDT (N1\N1)/(S[dcl]\N P1)2 λf.λg.λz.g(z) ∧ f (λy.y = z) includes / VBZ (S[dcl]\N P1)/N P2 λf.λg.∃x, y.g(x) ∧ f (y) ∧ LOCATEDIN(y, x) beautiful / JJ N1/N1 λf.f London / NNP N λx.M(x, "london", CITY) N : λx.M(x, "london", CITY) (S[dcl]\N P1) : λg.∃x, y.g(x) ∧ M(y, "london", CITY) ∧ LOCATEDIN(y, x) N1\N1 : λg.λz.∃x, y.g(z) ∧ x = z ∧ M(y, "london", CITY) ∧ LOCATEDIN(y, x) N : λz.∃x, y.LOCATION(z) ∧ x = z ∧ M(y, "london", CITY) ∧ LOCATEDIN(y, x)</formula><p>Head Argument word POS semantic type index syntactic category arg. num. word POS semantic type index that WDT -</p><formula xml:id="formula_1">1 (N1\N1)/(S\N P1)2 1 area NN LOCATION 0 that WDT - 1 (N1\N1)/(S\N P1)2 2 includes VBZ LOCATEDIN −1 2 includes VBZ LOCATEDIN −1 2 (S[dcl]\N P1)/N P2 1 area NN LOCATION 0 includes VBZ LOCATEDIN −1 2 (S[dcl]\N P1)/N P2 2 ENTITY:CITY NNP CITY 4 beautiful JJ - 3 N1/N1 1 ENTITY:CITY NNP CITY 4</formula><p>Figure 1: Example input and output for ASP. Given a POS-tagged sentence, the parser produces a CCG syntactic tree and logical form (top), and a collection of dependency structures (bottom). </p><formula xml:id="formula_2">bought := (S[dcl]\N P1)/N P2 : ACQUIRED : λf.λg.∃x, y.f (y) ∧ g(x) ∧ ACQUIRED(x, y)</formula><p>Each lexicon entry maps a word to a syntactic category, semantic type, and logical form. CCG has two kinds of syntactic categories: atomic and functional. Atomic categories include N for noun and S for sentence. Functional categories are functions constructed recursively from atomic cat- egories; these categories are denoted using slashes to separate the category's argument type from its return type. The argument type appears on the right side of the slash, and the return type on the left. The direction of slash determines where the argument must appear -/ means an argument on the right, and \ means an argument on the left.</p><p>Syntactic categories in ASP are annotated with two additional kinds of information. First, atomic categories may have associated syntactic features given in square brackets. These features are used in CCGbank to distinguish variants of atomic syn- tactic categories, e.g., S[dcl] denotes a declara- tive sentence. Second, each category is anno- tated with head and dependency information us- ing subscripts. These subscripts are used to pop- ulate predicate-argument dependencies (described below), and to pass head information using unifi- cation. For example, the head of the parse in <ref type="figure">Fig- ure 1</ref> is "area," due to the coindexing of the argu- ment and return categories in the category N 1 \N 1 .</p><p>In addition to the syntactic category, each lexi- con entry has a semantic type and a logical form. The semantic type is a category or relation pred- icate that concisely represents the word's seman- tics. The semantic type is used to enforce type constraints during parsing and to include seman- tics in the parser's parametrization. The logi- cal form gives the full semantics of the word in lambda calculus. The parser also allows lexicon entries with the semantic type "-", representing words whose semantics cannot be expressed using predicates from the ontology.</p><p>Parsing in CCG combines adjacent categories using a small number of combinators, such as function application:</p><formula xml:id="formula_3">X/Y : f Y : g =⇒ X : f (g) Y : g X\Y : f =⇒ X : f (g)</formula><p>The first rule states that the category X/Y can be applied to the category Y , returning category X, and that the logical form f is applied to g to produce the logical form for the returned category. Head words and semantic types are also propa- gated to the returned category based on the anno- tated head-passing markup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dependency Structures</head><p>Parsing a sentence produces a collection of depen- dency structures which summarize the predicate- argument structure of the sentence. Dependency structures are 10-tuples, of the form:</p><p>&lt; head word, head POS, head semantic type, head word index, head word syntactic category, argument number, ar- gument word, argument POS, argument semantic type, argu- ment word index &gt; A dependency structure captures a relationship between a head word and its argument. During parsing, whenever a subscripted argument of a syntactic category is filled, a dependency structure is created between the head of the applied func- tion and its argument. For example, in <ref type="figure">Figure 1</ref>, the first application fills argument 1 of "beautiful" with "London," creating a dependency structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Logical Forms</head><p>ASP performs a best-effort semantic analysis of every parsed sentence, producing logical forms for subspans of the sentence when possible. Logical forms are designed so that the meaning of a sen- tence is a universally-and existentially-quantified conjunction of predicates with partially shared ar- guments. This representation allows the parser to produce semantic analyses for a reasonable subset of language, including prepositions, verbs, nouns, relative clauses, and conjunctions. <ref type="figure">Figure 1</ref> shows a representative sample of a log- ical form produced by ASP. Generally, the parser produces a lambda calculus statement with sev- eral existentially-quantified variables ranging over entities in the knowledge base. The only excep- tion to this rule is conjunctions, which are rep- resented using a scoped universal quantifier over the conjoined predicates. Entity mentions appear in logical forms via a special mention predicate, M, instead of as database constants. For exam- ple, "London" appears as M(x, "london", CITY), instead of as a constant like LONDON. The mean- ing of this mention predicate is that x is an en- tity which can be called "london" and belongs to the CITY category. This representation propagates uncertainty about entity references into the logical form where background knowledge can be used for disambiguation. For example, "London, Eng- land" is assigned a logical form that disambiguates "London" to a "London" located in "England." <ref type="bibr">1</ref> Lexicon entries without a semantic type are au- tomatically assigned logical forms based on their head passing markup. For example, in <ref type="figure">Figure 1</ref>, the adjective "beautiful" is assigned λf.f . This approach allows a logical form to be derived for most sentences, but (somewhat counterintuitively) can lose interesting logical forms from constituent subspans. For example, the preposition "in" has syntactic category (N 1 \N 1 )/N 2 , which results in the logical form λf.λg.g. This logical form dis- cards any information present in the argument f . We avoid this problem by extracting a logical form from every subtree of the CCG parse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Parametrization</head><p>The parser Γ is trained as a discriminative linear model of the following form:</p><formula xml:id="formula_4">Γ(, d, t|s; θ) = θ T φ(d, t, s)</formula><p>Given a parameter vector θ and a sentence s, the parser produces a score for a syntactic parse tree t, a collection of dependency structures d and a logical form . The score depends on features of the parse produced by the feature function φ.</p><p>φ contains four classes of features: lexicon features, combinator features, dependency fea- tures and dependency distance features <ref type="table">(Table 1)</ref>. These features are based on those of C&amp;C <ref type="bibr" target="#b12">(Clark and Curran, 2007b</ref>), modified to include seman- tic types. The features are designed to share syn- tactic information about a word across its distinct semantic realizations in order to transfer syntactic information from CCGbank to semantic parsing.</p><p>The parser also includes a hard type-checking constraint to ensure that logical forms are well- typed. This constraint states that dependency structures with a head semantic type only accept arguments that (1) have a semantic type, and <ref type="formula">(2)</ref> are within the domain/range of the head type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parameter Estimation</head><p>This section describes the training procedure for ASP. Training is performed by minimizing a joint objective function combining a syntactic parsing task and a distantly-supervised relation extraction task. The input training data includes:</p><p>1. A collection L of sentences s i with annotated syntactic trees t i (e.g., CCGbank).</p><p>2. A corpus of sentences S (e.g., Wikipedia).</p><p>3. A knowledge base K (e.g., NELL), contain- ing relation instances r(e 1 , e 2 ) ∈ K.</p><p>4. A CCG lexicon Λ (see Section 5.2).</p><p>Given these resources, the algorithm described in this section produces parameters θ for a se- mantic parser. Our parameter estimation proce- dure constructs a joint objective function O(θ) that decomposes into syntactic and semantic compo- nents: O(θ) = O syn (θ) + O sem (θ). The syntac- tic component O syn is a standard syntactic pars- ing objective constructed using the syntactic re- source L. The semantic component O sem is a distantly-supervised relation extraction task based on the semantic constraint from <ref type="bibr" target="#b22">Krishnamurthy and Mitchell (2012)</ref>. These components are de- scribed in more detail in the following sections. </p><note type="other">: word, POS := X : t : Word/syntactic category word, X POS/syntactic category POS, X Word semantics word, X, t Combinator features: X Y → Z or X → Z Binary combinator indicator X Y → Z Unary combinator indicator X → Z Root syntactic category Z Dependency Features: &lt; hw, hp, ht, hi, s, n, aw, ap, at, ai &gt;</note><p>Predicate-Argument Indicator &lt; hw, -, ht, -, s, n, aw, -, at, -&gt; Word-Word Indicator &lt; hw, -, -, -, s, n, aw, -, -, -&gt; Predicate-POS Indicator &lt; hw, -, ht, -, s, n, -, ap, -, -&gt; Word-POS Indicator &lt; hw, -, -, -, s, n, -, ap, -, -&gt; POS-Argument Indicator &lt; -, hp, -, -, s, n, aw, -, at, -&gt; POS-Word Indicator &lt; -, hp, -, -, s, n, aw, -, -, -&gt; POS-POS Indicator &lt; -, hp, -, -, s, n, -, ap, -, -&gt; (The above distance features are repeated using the number of intervening verbs and punctuation marks.) <ref type="table">Table 1</ref>: Listing of parser feature templates used in the feature function φ. Each feature template repre- sents a class of indicator features that fire during parsing when lexicon entries are used, combinators are applied, or dependency structures are instantiated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Syntactic Objective</head><p>The syntactic objective is the structured percep- tron objective instantiated for a syntactic parsing task. This objective encourages the parser to accu- rately reproduce the syntactic parses in the anno-</p><formula xml:id="formula_5">tated corpus L = {(s i , t i )} n i=1</formula><p>:</p><formula xml:id="formula_6">O syn (θ) = n i=1 | maxˆ,ˆd maxˆ maxˆ,maxˆ,ˆ maxˆ,ˆd, ˆ t Γ( ˆ , ˆ d, ˆ t|s i ; θ) − max * ,d * Γ( * , d * , t i |s i ; θ)| +</formula><p>The first term in the above expression represents the best CCG parse of the sentence s i according to the current model. The second term is the best parse of s i whose syntactic tree equals the true syntactic tree t i . In the above equation | · | + de- notes the positive part of the expression. Minimiz- ing this objective therefore finds parameters θ that reproduce the annotated syntactic trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Semantic Objective</head><p>The semantic objective corresponds to a distantly- supervised relation extraction task that constrains the logical forms produced by the semantic parser. Distant supervision is provided by the following constraint: every relation instance r(e 1 , e 2 ) ∈ K must be expressed by at least one sentence in S (e 1 ,e 2 ) , the set of sentences that mention both e 1 and e 2 (Hoffmann et al., 2011). If this constraint is empirically true and sufficiently constrains the parser's logical forms, then optimizing the seman- tic objective produces an accurate semantic parser.</p><p>A training example in the semantic objective consists of the set of sentences mentioning a pair of entities, S (e 1 ,e 2 ) = {s 1 , s 2 , ...}, paired with a binary vector representing the set of relations that the two entities participate in, y (e 1 ,e 2 ) . The distant supervision constraint Ψ forces the logical forms predicted for the sentences to entail the relations in y (e 1 ,e 2 ) . Ψ is a deterministic OR constraint that checks whether each logical form entails the re- lation instance r(e 1 , e 2 ), deterministically setting y r = 1 if any logical form entails the instance and y r = 0 otherwise. Let (, d, t) represent a collection of seman- tic parses for the sentences S = S (e 1 ,e 2 ) . Let</p><formula xml:id="formula_7">Γ(, d, t|S; θ) = |S| i=1 Γ( i , d i , t i |s i ; θ)</formula><p>represent the total weight assigned by the parser to a collec- tion of parses for the sentences S. For the pair of entities (e 1 , e 2 ), the semantic objective is:</p><formula xml:id="formula_8">O sem (θ) = | maxˆ,ˆd maxˆmaxˆ,maxˆ,ˆ maxˆ,ˆd, ˆ t Γ( ˆ , ˆ d, ˆ t|S; θ) − max * ,d * ,t * Ψ(y (e 1 ,e 2 ) , * , d * , t * ) + Γ( * , d * , t * |S; θ) | +</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Optimization</head><p>Training minimizes the joint objective using the structured perceptron algorithm, which can be viewed as the stochastic subgradient method ( <ref type="bibr" target="#b28">Ratliff et al., 2006</ref>) applied to the objective O(θ). We initialize the parameters to zero, i.e., θ 0 = 0. On each iteration, we sample either a syntactic example (s i , t i ) or a semantic example (S (e 1 ,e 2 ) , y (e 1 ,e 2 ) ). If a syntactic example is sam- pled, we apply the following parameter update:  <ref type="table">Table 2</ref>: Syntactic parsing results for Section 23 of CCGbank. Parser performance is measured using precision (P), recall (R) and F-measure (F) of labeled and unlabeled dependencies.</p><formula xml:id="formula_9">ˆ , ˆ d, ˆ t ← arg max ,d,t Γ(, d, t|s i ; θ t ) * , d * ← arg max ,d Γ(, d, t i |s i ; θ t ) θ t+1 ← θ t + φ(d * , t i , s i ) − φ( ˆ d, ˆ t</formula><p>sampled, we instead apply the following update:</p><formula xml:id="formula_10">ˆ , ˆ d, ˆ t ← arg max ,d,t Γ(, d, t|S (e 1 ,e 2 ) ; θ t ) * , d * , t * ← arg max ,d,t Γ(, d, t|S (e 1 ,e 2 ) ; θ t ) + Ψ(y (e 1 ,e 2 ) , , d, t) θ t+1 ← θ t + φ(d * , t * , S (e 1 ,e 2 ) ) − φ( ˆ d, ˆ t, S (e 1 ,e 2 ) )</formula><p>This update moves the parameters toward the fea- tures of the best set of parses that satisfy the distant supervision constraint. Training outputs the aver- age of each iteration's parameters, ¯ θ = 1 n n t=1 θ t . In practice, we train the parser by performing a single pass over the examples in the data set.</p><p>All of the maximizations above can be per- formed exactly using a CKY-style chart parsing algorithm, except for the last one. This maxi- mization is intractable due to the coupling between logical forms in caused by enforcing the dis- tant supervision constraint. We approximate this maximization in two steps. First, we perform a beam search to produce a list of candidate parses for each sentence s ∈ S (e 1 ,e 2 ) . We then extract relation instances from each parse and apply the greedy inference algorithm from <ref type="bibr" target="#b20">Hoffmann et al., (2011)</ref> to identify the best set of parses that satisfy the distant supervision constraint. The procedure skips any examples with sentences that cannot be parsed (due to beam search failures) or where the distant supervision constraint cannot be satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The experiments below evaluate ASP's syntactic and semantic parsing ability. The parser is trained on CCGbank and a corpus of Wikipedia sentences, using NELL's predicate vocabulary. The syntactic analyses of the trained parser are evaluated against CCGbank, and its logical forms are evaluated on an information extraction task and against an an- notated test set of Wikipedia sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data Sets</head><p>The data sets for the evaluation consist of CCG- bank, a corpus of dependency-parsed Wikipedia sentences, and a logical knowledge base derived from NELL and Freebase. Sections 02-21 of CCGbank were used for training, Section 00 for validation, and Section 23 for the final results. The knowledge base's predicate vocabulary is taken from NELL, and its instances are taken from Free- base using a manually-constructed mapping be- tween Freebase and NELL. Using Freebase rela- tion instances produces cleaner training data than NELL's automatically-extracted instances.</p><p>Using the relation instances and Wikipedia sen- tences, we constructed a data set for distantly- supervised relation extraction. We identified men- tions of entities in each sentence using simple string matching, then aggregated these sentences by entity pair. 20% of the entity pairs were set aside for validation. In the remaining training data, we downsampled entity pairs that did not participate in at least one relation. We further eliminated sentences containing more than 30 to- kens. The resulting training corpus contains 25k entity pairs (half of which participate in a relation), 41k sentences, and 71 distinct relation predicates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Grammar Construction</head><p>The grammar for ASP contains the annotated lex- icon entries and grammar rules in Sections 02-21 of CCGbank, and additional semantic entries pro- duced using a set of dependency parse heuristics.</p><p>The lexicon Λ contains all words that occur at least 20 times in CCGbank. Rare words are re- placed by their part of speech. The head pass- ing and dependency markup was generated using the rules of the C&amp;C parser <ref type="bibr" target="#b12">(Clark and Curran, 2007b</ref>). These lexicon entries are also annotated with logical forms capturing their head passing re- lationship. For example, the adjective category N 1 /N 1 is annotated with the logical form λf.f . These entries are all assigned semantic type -.</p><p>We augment this lexicon with additional entries Sentence Extracted Logical Form St. John, a Mexican-American born in San Francisco, Califor- nia, her family comes from Zacatecas, Mexico.</p><p>λx.∃y, z.M(x, "st. john") ∧ M(y, "san francisco") ∧ PERSONBORNINLOCATION(x, y) ∧ CITYLOCATEDINSTATE(y, z) ∧ M(z, "california") The capital and largest city of Laos is Vientiane and other major cities include Luang Prabang, Savannakhet and Pakse.</p><p>∃x, y.M(x, "vientiane") ∧ CITY(x) ∧ CITYCAPITALOFCOUNTRY(x, y) ∧ M(y, "laos") Gellar next played a lead role in James Toback 's critically unsuccessful independent "Harvard Man" <ref type="bibr">(2001)</ref>, where she played the daughter of a mobster. mapping words to logical forms with NELL pred- icates. These entries are instantiated using a set of dependency parse patterns, listed in an online appendix. <ref type="bibr">2</ref> These patterns are applied to the train- ing corpus, heuristically identifying verbs, prepo- sitions, and possessives that express relations, and nouns that express categories. The patterns also include special cases for forms of "to be." This process generates ∼4000 entries (not counting en- tity names), representing 69 relations and 61 cate- gories from NELL. Section 3.2 shows several lex- icon entries generated by this process.</p><p>The parser's combinators include function ap- plication, composition, and crossed composition, as well as several binary and unary type-changing rules that occur in CCGbank. All combinators were restricted to only apply to categories that combine in Sections 02-21. Finally, the grammar includes a number of heuristically-instantiated bi- nary rules of the form , N → N \N that instanti- ate a relation between adjacent nouns. These rules capture appositives and some other constructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Supertagging</head><p>Parsing in practice can be slow because the parser's lexicalized grammar permits a large num- ber of parses for a sentence. We improve parser performance by performing supertagging <ref type="bibr">(Banga-lore and Joshi, 1999;</ref><ref type="bibr" target="#b10">Clark and Curran, 2004</ref>). We trained a logistic regression classifier to pre- dict the syntactic category of each token in a sen- tence from features of the surrounding tokens and POS tags. Subsequent parsing is restricted to only consider categories whose probability is within a factor of α of the highest-scoring category. The parser uses a backoff strategy, first attempting to parse with the supertags from α = 0.01, backing off to α = 0.001 if the initial parsing attempt fails.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Syntactic Evaluation</head><p>The syntactic evaluation measures ASP's ability to reproduce the predicate-argument dependencies in CCGbank. As in previous work, our evalu- ation uses labeled and unlabeled dependencies. Labeled dependencies are dependency structures with both words and semantic types removed, leaving two word indexes, a syntactic category, and an argument number. Unlabeled dependen- cies further eliminate the syntactic category and argument number, leaving a pair of word indexes. Performance is measured using precision, recall, and F-measure against the annotated dependency structures in CCGbank. Precision is the fraction of predicted dependencies which are in CCGbank, recall is the fraction of CCGbank dependencies produced by the parser, and F-measure is the har- monic mean of precision and recall.</p><p>For comparison, we also trained a syntactic ver- sion of our parser, ASP-SYN, using only the CCG- bank lexicon and grammar. Comparing against this parser lets us measure the effect of the rela- tion extraction task on syntactic parsing. <ref type="table">Table 2</ref> shows the results of our evaluation. For comparison, we include results for two ex- isting syntactic CCG parsers: C&amp;C, the current state-of-the-art CCG parser <ref type="bibr" target="#b12">(Clark and Curran, 2007b)</ref>, and the next best system <ref type="bibr" target="#b18">(Hockenmaier, 2003a)</ref>. Both ASP and ASP-SYN perform rea- sonably well, within 2.5% of the performance of C&amp;C at the same coverage level. However, ASP-  <ref type="table">Table 3</ref>: Logical form accuracy and extraction pre- cision/recall on the annotated test set. The high extraction recall for ASP shows that it produces more complete logical forms than either baseline.</p><p>SYN outperforms ASP by around 0.5%, suggesting that ASP's additional semantic knowledge slightly hurts syntactic parsing performance. This perfor- mance loss appears to be largely due to poor en- tity mention detection, as we found that not us- ing entity mention lexicon entries at test time im- proves ASP's labeled and unlabeled F-scores by 0.3% on Section 00. The knowledge base contains many infrequently-mentioned entities with com- mon names; these entities contribute incorrect se- mantic type information that confuses the parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Semantic Evaluation</head><p>We performed two semantic evaluations to bet- ter understand ASP's ability to construct logical forms. The first evaluation emphasizes precision over recall, and the second evaluation accurately measures recall using a manually labeled test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Baselines</head><p>For comparison, we also trained two base- line models. The first baseline, PIPELINE, is a pipelined syntax-then-semantics approach de- signed to mimic Boxer ( <ref type="bibr" target="#b5">Bos, 2005)</ref>. This base- line first syntactically parses each sentence using ASP-SYN, then produces a semantic analysis by assigning a logical form to each word. We train this baseline using the semantic objective (Section 4.2) while holding fixed the syntactic parse of each sentence. Note that, unlike Boxer, this baseline learns which logical form to assign each word, and its logical forms contain NELL predicates. The second baseline, K&amp;M-2012, is the ap- proach of <ref type="bibr" target="#b22">Krishnamurthy and Mitchell (2012)</ref>, representing the state-of-the-art in distantly- supervised semantic parsing. This approach trains a semantic parser by combining distant seman- tic supervision with syntactic supervision from dependency parses. The best performing vari- ant of this system also uses dependency parses at test time to constrain the interpretation of test sentences -hence, this system also uses a pipelined syntax-then-semantics approach. To im- prove comparability, we reimplemented this ap- proach using our parsing model, which has richer features than were used in their paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Information Extraction Evaluation</head><p>The information extraction evaluation uses each system to extract logical forms from a large cor- pus of sentences, then measures the fraction of extracted logical forms that are correct. The test set consists of 8.5k sentences sampled from the held-out Wikipedia sentences. Each system was run on this data set, extracting all logical forms from each sentence that entailed at least one cat- egory or relation instance. We ranked these ex- tractions using the parser's inside chart score, then manually annotated a sample of 250 logical forms from each system for correctness. Logical forms were marked correct if all category and relation instances entailed by the logical form were ex- pressed by the sentence. Note that a correct logical form need not entail all of the relations expressed by the sentence, reflecting an emphasis on preci- sion over recall. <ref type="figure">Figure 2</ref> shows some example logical forms produced by ASP in the evaluation.</p><p>The annotated sample of logical forms allows us to estimate precision for each system as a func- tion of the number of correct extractions ( <ref type="figure">Figure  3</ref>). The number of correct extractions is directly proportional to recall, and was estimated from the total number of extractions and precision at each rank in the sample. All three systems initially have high precision, implying that their extracted logical forms express facts found in the sentence. However, ASP produces 3 times more correct log- ical forms than either baseline because it jointly analyzes syntax and semantics. The baselines suf- fer from reduced recall because they depend on re- ceiving an accurate syntactic parse as input; syn- tactic parsing errors cause these systems to fail.</p><p>Examining the incorrect logical forms produced by ASP reveals that incorrect mention detection is by far the most common source of mistakes. Ap- proximately 50% of errors are caused by marking common nouns as entity mentions (e.g., marking "coin" as a COMPANY). These errors occur be- cause the knowledge base contains many infre- quently mentioned entities with relatively com- mon names. Another 30% of errors are caused by assigning an incorrect type to a common proper noun (e.g, marking "Bolivia" as a CITY). This analysis suggests that performing entity linking before parsing could significantly reduce errors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.3">Annotated Sentence Evaluation</head><p>A limitation of the previous evaluation is that it does not measure the completeness of predicted logical forms, nor estimate what portion of sen- tences are left unanalyzed. We conducted a second evaluation to measure these quantities.</p><p>The data for this evaluation consists of sen- tences annotated with logical forms for subspans. We manually annotated Wikipedia sentences from the held-out set with logical forms for the largest subspans for which a logical form existed. To avoid trivial cases, we only annotated logical forms containing at least one category or relation predicate and at least one mention. We also chose not to annotate mentions of entities that are not in the knowledge base, as no system would be able to correctly identify them. The corpus contains 97 sentences with 100 annotated logical forms.</p><p>We measured performance using two met- rics: logical form accuracy, and extraction preci- sion/recall. Logical form accuracy examines the predicted logical form for the smallest subspan of the sentence containing the annotated span, and marks this prediction correct if it exactly matches the annotation. A limitation of this metric is that it does not assign partial credit to logical forms that are close to, but do not exactly match, the anno- tation. The extraction metric assigns partial credit by computing the precision and recall of the cat- egory and relation instances entailed by the pre- dicted logical form, using those entailed by the an- notated logical form as the gold standard. <ref type="figure" target="#fig_4">Figure  4</ref> shows the computation of both error metrics on two examples from the test corpus. <ref type="table">Table 3</ref> shows the results of the annotated sen- tence evaluation. ASP outperforms both baselines in logical form accuracy and extraction recall, sug- gesting that it produces more complete analyses than either baseline. The extraction precision of 90% suggests that ASP rarely extracts incorrect in- formation. Precision is higher in this evaluation because every sentence in the data set has at least one correct extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We present an approach to training a joint syntac- tic and semantic parser. Our parser ASP produces a full syntactic parse of any sentence, while simul- taneously producing logical forms for sentence spans that have a semantic representation within its predicate vocabulary. The parser is trained by jointly optimizing performance on a syntac- tic parsing task and a distantly-supervised rela- tion extraction task. Experimental results demon- strate that jointly analyzing syntax and semantics triples the number of extracted logical forms over approaches that first analyze syntax, then seman- tics. However, we also find that incorporating se- mantics slightly reduces syntactic parsing perfor- mance. Poor entity mention detection is a major source of error in both cases, suggesting that fu- ture work should consider integrating entity link- ing with joint syntactic and semantic parsing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>person :=</head><label></label><figDesc>N : PERSON : λx.PERSON(x) London := N : CITY : λx.M(x, "london", CITY) great := N1/N1 : -: λf.λx.f (x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lexicon features</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Distance Features:</head><label></label><figDesc>Token distance hw, ht, -, s, n, d d = Number of tokens between hi and ai: 0, 1, 2 or more. Token distance word backoff hw, -, s, n, d d = Number of tokens between hi and ai: 0, 1, 2 or more. Token distance POS backoff -, -, hp, s, n, d d = Number of tokens between hi and ai: 0, 1, 2 or more.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Logical forms produced by ASP for sentences in the information extraction corpus. Each logical form is extracted from the underlined sentence portion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Two test examples with ASP's predictions and error calculations. The annotated logical forms are for the italicized sentence spans, while the extracted logical forms are for the underlined spans.</figDesc></figure>

			<note place="foot" n="1"> Specifically, λx.∃y.CITYLOCATEDINCOUNTRY(x, y) ∧ M(x, &quot;london&quot;, CITY) ∧ M(y, &quot;england&quot;, COUNTRY)</note>

			<note place="foot" n="2"> http://rtw.ml.cmu.edu/acl2014_asp/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by DARPA under award FA8750-13-2-0005. We additionally thank Jamie Callan and Chris Ré's Hazy group for col-lecting and processing the Wikipedia corpus.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Sentence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Niro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pesci</surname></persName>
		</author>
		<title level="m">Goodfellas&quot; offered a virtuoso display of the director&apos;s bravura cinematic technique and reestablished, enhanced, and consolidated his reputation. Annotation: LF: λx.∀p ∈ {λd.M(d, &quot;de niro&quot;), λj.M(j, &quot;joe pesci&quot;)}∃y.p(x) ∧ STARREDINMOVIE(x, y) ∧ M(y, &quot;goodfellas&quot;) Instances: STARREDINMOVIE(de niro, goodfellas), STARREDINMOVIE(joe pesci, goodfellas) Prediction: LF: λx.∀p ∈ {λd.M(d</title>
		<imprint/>
	</monogr>
	<note>de niro&quot;), λj.M(j, &quot;joe pesci&quot;)}∃y.p(x) ∧ STARREDINMOVIE(x, y) ∧ M(y, &quot;goodfellas&quot;) Instances: STARREDINMOVIE(de niro, goodfellas), STARREDINMOVIE(joe pesci, goodfellas) Logical form accuracy: 1 / 1 Extraction Precision: 2 / 2 Extraction Recall: 2 / 2</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">UNIVERSITYINCITY(parkland college, champaign) Prediction: LF 1: λx.∃yM(y</title>
	</analytic>
	<monogr>
		<title level="m">Sentence: In addition to the University of Illinois, Champaign is also home to Parkland College. Annotation: LF: ∃c, p.M(c, &quot;champaign&quot;) ∧ CITY(c) ∧ M(p</title>
		<meeting><address><addrLine>UNIVERSITYINCITY(parkland college, champaign), CITYLOCATEDINSTATE(university, illinois</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>∧ UNIVERSITYINCITY(p, c) Instances: CITY(champaign). Logical form accuracy: 1 / 1 Extraction Precision: 2 / 3 Extraction Recall: 2 / 2</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The berkeley framenet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>References Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Computational Linguistics</title>
		<meeting>the 17th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supertagging: an approach to almost parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="237" to="265" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards wide-coverage semantic interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Sixth International Workshop on Computational Semantics IWCS-6</title>
		<meeting>Sixth International Workshop on Computational Semantics IWCS-6</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Largescale Semantic Parsing via Schema Matching and Lexicon Extension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semantic Parsing Freebase: Towards Open-domain Semantic Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the Second Joint Conference on Lexical and Computational Semantics (*SEM)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Betteridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Kisiel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estevam</forename><forename type="middle">R</forename><surname>Hruschka</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward an architecture for neverending language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fourth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The importance of supertagging for wide-coverage CCG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Computational Linguistics</title>
		<meeting>the 20th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Perceptron training for a wide-coverage lexicalizedgrammar parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Deep Linguistic Processing</title>
		<meeting>the Workshop on Deep Linguistic Processing</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Widecoverage efficient statistical parsing with CCG and log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="552" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A statistical semantic parser that integrates syntax and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative models for statistical parsing with combinatory categorial grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th</title>
		<meeting>the 40th</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annual Meeting on Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Data and Models for Statistical Parsing with Combinatory Categorial Grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parsing with generative models of predicate-argument structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congle</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using string-kernels for learning semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Kate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Combined distributional and logical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">(online) subgradient methods for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><forename type="middle">D</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Andrew</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Surface Structure and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Natural language questions for the web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth national conference on Artificial Intelligence</title>
		<meeting>the thirteenth national conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI &apos;05, Proceedings of the 21st Conference in Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
