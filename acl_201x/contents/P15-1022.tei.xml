<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Multitask Learning for Machine Translation Quality Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><forename type="middle">G C</forename><surname>De Souza</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Fbk -Fondazione</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Kessler</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>Via Sommarive 18</addrLine>
									<postCode>38123</postCode>
									<settlement>Trento</settlement>
									<country>Italy (</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online Multitask Learning for Machine Translation Quality Estimation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="219" to="228"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a method for predicting machine translation output quality geared to the needs of computer-assisted translation. These include the capability to: i) continuously learn and self-adapt to a stream of data coming from multiple translation jobs, ii) react to data diversity by exploiting human feedback, and iii) leverage data similarity by learning and transferring knowledge across domains. To achieve these goals, we combine two supervised machine learning paradigms, online and multitask learning, adapting and unifying them in a single framework. We show the effectiveness of our approach in a regression task (HTER prediction), in which online multitask learning outperforms the competitive online single-task and pooling methods used for comparison. This indicates the feasibility of integrating in a CAT tool a single QE component capable to simultaneously serve (and continuously learn from) multiple translation jobs involving different domains and users.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Even if not perfect, machine translation (MT) is now getting reliable enough to support and speed- up human translation. Thanks to this progress, the work of professional translators is gradually shifting from full translation from scratch to MT post-editing. Advanced computer-assisted trans- lation (CAT) tools 1 provide a natural framework for this activity by proposing, for each segment in a source document, one or more suggestions ob- tained either from a translation memory (TM) or from an MT engine. In both cases, accurate mech- anisms to indicate the reliability of a suggestion are extremely useful to let the user decide whether to post-edit a given suggestion or ignore it and translate the source segment from scratch. How- ever, while scoring TM matches relies on standard methods based on fuzzy matching, predicting the quality of MT suggestions at run-time and without references is still an open issue. This is the goal of MT quality estimation (QE), which aims to predict the quality of an automatic translation as a function of the estimated number of editing operations or the time required for man- ual correction ( <ref type="bibr" target="#b26">Specia et al., 2009;</ref><ref type="bibr" target="#b25">Soricut and Echihabi, 2010;</ref><ref type="bibr" target="#b1">Bach et al., 2011;</ref><ref type="bibr" target="#b18">Mehdad et al., 2012)</ref>. So far, QE has been mainly approached in controlled settings where homogeneous train- ing and test data is used to learn and evaluate static predictors. Cast in this way, however, it does not fully reflect (nor exploit) the working conditions posed by the CAT framework, in which:</p><p>1. The QE module is exposed to a continuous stream of data. The amount of such data and the tight schedule of multiple, simultaneous translation jobs prevents from (theoretically feasible but impractical) complete re-training procedures in a batch fashion and advocate for continuous learning methods.</p><p>2. The input data can be diverse in nature. Con- tinuous learning should be sensitive to such differences, in a way that each translation job and user is supported by a reactive model that is robust to variable working conditions.</p><p>3. The input data can show similarities with previous observations. Continuous learning should leverage such similarities, so that QE can capitalize from all the previously pro- cessed segments even if they come from dif- ferent domains, genres or users.</p><p>While previous QE research disregarded these challenges or addressed them in isolation, our work tackles them in a single unifying framework based on the combination of two paradigms: on- line and multitask learning. The former provides continuous learning capabilities that allow the QE model to be robust and self-adapt to a stream of potentially diverse data. The latter provides the model with the capability to exploit the similari- ties between data coming from different sources. Along this direction our contributions are:</p><p>• The first application of online multitask learning to QE, geared to the challenges posed by CAT technology. In this framework, our models are trained to predict MT quality in terms of HTER ( <ref type="bibr" target="#b24">Snover et al., 2006</ref>). 2</p><p>• The extension of current online multitask learning methods to regression. Prior works in the machine learning field applied this paradigm to classification problems, but its use for HTER estimation requires real-valued predictions. To this aim, we propose a new regression algorithm that, at the same time, handles positive and negative transfer and performs online weight updates.</p><p>• A comparison between online multitask and alternative, state-of-the-art online learning strategies. Our experiments, carried out in a realistic scenario involving a stream of data from four domains, lead to consistent results that prove the effectiveness of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In recent years, sentence-level QE has been mainly investigated in controlled evaluation sce- narios such as those proposed by the shared tasks organized within the WMT workshop on SMT <ref type="bibr" target="#b5">(Callison-Burch et al., 2012;</ref><ref type="bibr" target="#b2">Bojar et al., 2013;</ref><ref type="bibr" target="#b3">Bojar et al., 2014</ref>). In this framework, systems trained from a collection of (source, target, label) instances are evaluated based on their capability to predict the correct label 3 for new, unseen test items. Compared to our application scenario, the shared tasks setting differs in two main aspects. <ref type="bibr">2</ref> The HTER is the minimum edit distance between a trans- lation suggestion and its manually post-edited version in the <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> interval. Edit distance is calculated as the number of edits (word insertions, deletions, substitutions, and shifts) di- vided by the number of words in the reference. <ref type="bibr">3</ref> Possible label types include post-editing effort scores (e.g. 1-5 Likert scores indicating the estimated percentage of MT output that has to be corrected), HTER values, and post-editing time (e.g. seconds per word). First, the data used are substantially homogeneous (usually they come from the same domain, and tar- get translations are produced by the same MT sys- tem). Second, training and test are carried out as distinct, sequential phases. Instead, in the CAT en- vironment, a QE component should ideally serve, adapt to and continuously learn from simultaneous translation jobs involving different MT engines, domains, genres and users ( <ref type="bibr" target="#b28">Turchi et al., 2013</ref>).</p><p>These challenges have been separately ad- dressed from different perspectives in few recent works. <ref type="bibr" target="#b15">Huang et al. (2014)</ref> proposed a method to adaptively train a QE model for document- specific MT post-editing. Adaptability, however, is achieved in a batch fashion, by re-training an ad hoc QE component for each document to be trans- lated. The adaptive approach proposed by  overcomes the limitations of batch methods by applying an online learning protocol to continuously learn from a stream of (potentially heterogeneous) data. Experimental results suggest the effectiveness of online learning as a way to ex- ploit user feedback to tailor QE predictions to their quality standards and to cope with the heterogene- ity of data coming from different domains. How- ever, though robust to user and domain changes, the method is solely driven by the distance com- puted between predicted and true labels, and it does not exploit any notion of similarity between tasks (e.g. domains, users, MT engines).</p><p>On the other way round, task relatedness is suc- cessfully exploited by <ref type="bibr" target="#b8">Cohn and Specia (2013)</ref>, who apply multitask learning to jointly learn from data obtained from several annotators with differ- ent levels of expertise and reliability. A similar ap- proach is adopted by de <ref type="bibr" target="#b10">Souza et al. (2014a)</ref>, who apply multitask learning to cope with situations in which a QE model has to be trained with scarce data from multiple domains/genres, different from the actual test domain. The two methods signifi- cantly outperform both individual single-task (in- domain) models and single pooled models. How- ever, operating in batch learning mode, none of them provides the continuous learning capabilities desirable in the CAT framework.</p><p>The idea that online and multitask learning can complement each other if combined is suggested by <ref type="bibr" target="#b11">(de Souza et al., 2014b)</ref>, who compared the two learning paradigms in the same experimental set- ting. So far, however, empirical evidence of this complementarity is still lacking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Online Multitask Learning for QE</head><p>Online learning takes place in a stepwise fash- ion. At each step, the learner processes an instance (in our case a feature vector extracted from source and target sentences) and predicts a label for it (in our case an HTER value). After the prediction, the learner receives the "true" label (in our case the ac- tual HTER computed from a human post-edition) and computes a loss that indicates the distance be- tween the predicted and the true label. Before go- ing to the next step, the weights are updated ac- cording to the suffered loss.</p><p>Multitask learning (MTL) aims to simultane- ously learn models for a set of possibly related tasks by exploiting their relationships. By do- ing this, improved generalization capabilities are obtained over models trained on the different tasks in isolation (single-task learning -STL). The relationships among tasks are provided by a shared structure, which can encode three types of relationships based on their correlation <ref type="bibr" target="#b32">(Zhang and Yeung, 2010)</ref>. Positive correlation indicates that the tasks are related and knowledge transfer should lead to similar model parameters. Negative correlation indicates that the tasks are likely to be unrelated and knowledge transfer should force an increase in the distance between model parame- ters. No correlation indicates that the tasks are in- dependent and no knowledge transfer should take place. In our case, a task is a set of (instance, la- bel) pairs obtained from source sentences coming from different translation jobs, together with their translations produced by several MT systems and the relative post-editions from various translators. In this paper the terms task and domain are used interchangeably.</p><p>Early MTL methods model only positive cor- relation <ref type="bibr" target="#b6">(Caruana, 1997;</ref><ref type="bibr" target="#b0">Argyriou et al., 2008)</ref>, which results in a positive knowledge transfer be- tween all the tasks, with the risk of impairing each other's performance when they are unrelated or negatively correlated. Other methods ( <ref type="bibr" target="#b16">Jacob et al., 2009;</ref><ref type="bibr" target="#b33">Zhong and Kwok, 2012;</ref><ref type="bibr" target="#b31">Yan et al., 2014</ref>) cluster tasks into different groups and share knowledge only among those in the same cluster, thus implicitly identifying outlier tasks. A third class of algorithms considers all the three types of relationships by learning task interaction via the covariance of task-specific weights ( <ref type="bibr" target="#b4">Bonilla et al., 2008;</ref><ref type="bibr" target="#b32">Zhang and Yeung, 2010)</ref>. All these meth- ods, however, learn the task relationships in batch mode. To overcome this limitation, recent works propose the "lifelong learning" paradigm ( <ref type="bibr" target="#b12">Eaton and Ruvolo, 2013;</ref><ref type="bibr" target="#b21">Ruvolo and Eaton, 2014)</ref>, in which all the instances of a task are given to the learner sequentially and the previously learned tasks are leveraged to improve generalization for future tasks. This approach, however, is not ap- plicable to our scenario as it assumes that all the instances of each task are processed as separate blocks.</p><p>In this paper we propose a novel MTL algorithm for QE that learns the structure shared by differ- ent tasks in an online fashion and from an input stream of instances from all the tasks. To this aim, we extend the online passive aggressive (PA) al- gorithm <ref type="bibr" target="#b9">(Crammer et al., 2006</ref>) to the multitask scenario, learning a set of task-specific regression models. The multitask component of our method is given by an "interaction matrix" that defines to which extent each encoded task can "borrow" and "lend" knowledge from and to the other tasks. Op- posite to previous methods <ref type="bibr" target="#b7">(Cavallanti et al., 2010</ref>) that assume fixed dependencies among tasks, we propose to learn the interaction matrix instance- by-instance from the data. To this aim we follow the recent work of <ref type="bibr" target="#b22">Saha et al. (2011)</ref>, extending it to a regression setting. The choice of PA is mo- tivated by practical reasons. Indeed, by provid- ing the best trade-off between accuracy and com- putational time <ref type="bibr">(He and Wang, 2012</ref>) compared to other algorithms such as OnlineSVR <ref type="bibr" target="#b19">(Parrella, 2007)</ref>, it represents a good solution to meet the de- mand of efficiency posed by the CAT framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Passive Aggressive Algorithm</head><p>PA follows the typical online learning proto- col. At each round t the learner receives an in- stance, x t ∈ R d (d is the number of features), and predicts the labeî y t according to a function parametrized by a set weights w t ∈ R d . Next, the learner receives the true label y t , computes the -insensitive loss, , measuring the deviation be- tween the predictionˆypredictionˆ predictionˆy t and the true label y t and updates the weights. The weights are updated by solving the optimization problem:</p><formula xml:id="formula_0">wt = arg min w CP A(w) + Cξ (1) s.t. (w, (xt, yt)) ≤ ξ and ξ ≥ 0</formula><p>where C P A (w) = 1 2 ||w − w t−1 || 2 and is the -insensitive hinge loss defined as:</p><formula xml:id="formula_1">(w, (x, y)) = 0, if |y − w · x| ≤ |y − w · x| − , otherwise<label>(2)</label></formula><p>The loss is zero when the absolute difference be- tween the prediction and the true label is smaller or equal to , and grows linearly with this differ- ence otherwise. The parameter is given as input and regulates the sensitivity to mistakes. The slack variable ξ acts as an upper-bound to the loss, while the C parameter is introduced to control the ag- gressiveness of the weights update. High C values lead to more aggressive weight updates. However, when the labels present some degree of noise (a common situation in MT QE), they might cause the learner to drastically change the weight vector in a wrong direction. In these situations, setting C to small values is desirable. As shown in <ref type="bibr" target="#b9">(Crammer et al., 2006</ref>), a closed form solution for the weights update in Eq.1 can be derived as:</p><formula xml:id="formula_2">w t = w t−1 + sgn(y t − ˆ y t )τ t x t<label>(3)</label></formula><p>with τ t = min(C, t ||xt|| 2 ) and t = (w, (x t , y t )).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Passive Aggressive MTL Algorithm</head><p>Our Passive Aggressive Multitask Learning (PAMTL) algorithm extends the traditional PA for regression to multitask learning. Our approach is inspired by the Online Task Relationship Learning algorithm proposed by <ref type="bibr" target="#b22">Saha et al. (2011)</ref> which, however, is only defined for classification.</p><p>The learning process considers one instance at each round t. The random sequence of instances belongs to a fixed set of K tasks and the goal of the algorithm is to learn K linear models, one for each task, parametrized by weight vectors w t,k , k ∈ {1, . . . , K}. Moreover, the algorithm also learns a positive semidefinite matrix Ω ∈ R K×K , mod- eling the relationship among tasks. Algorithm 1 summarizes our approach. At each round t, the learner receives a pair (x t , i t ) where x t ∈ R d is an instance and i t ∈ {1, . . . , K} is the task identifier. Each incoming instance is transformed to a com- pound vector φ t = [0, . . . , 0, x t , 0, . . . , 0] ∈ R Kd . Then, the algorithm predicts the HTER score cor- responding to the labeî y by using the weight vec- tor w t . The weight vector is a compound vector</p><formula xml:id="formula_3">w t = [ w t,1 , . . . , w t,K ] ∈ R Kd , where w t,k ∈ R d , k ∈ {1, . . . , K}.</formula><p>Next, the learner receives the true HTER label y and computes the loss (Eq. 2) for round t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 PA Multitask Learning (PAMTL)</head><p>Input: instances from K tasks, number of rounds R &gt; 0, &gt; 0, C &gt; 0 Output: w and Ω, learned after T rounds</p><formula xml:id="formula_4">Initialization: Ω = 1 K × I k , w = 0 for t = 1 to T do receive instance (xt, it)</formula><note type="other">compute φ t from xt predict HTERˆytHTERˆ HTERˆyt = ( w T t · φ t ) receive true HTER label yt compute t (Eq. 2) compute τt = min(C, t ||φ t || 2 ) / * update weights * / wt = wt−1 + sgn(yt − ˆ yt)τt(Ωt−1 ⊗ I d ) −1 φ t / * update task matrix * / if t &gt; R then update Ωt with Eq. 6 or Eq. 7 end if end for</note><p>We propose to update the weights by solving:</p><formula xml:id="formula_5">wt, Ωt = argmin w,Ω0 CMT L(w, Ω) + Cξ + D(Ω, Ωt−1) s.t. (w, (xt, yt)) ≤ ξ, ξ ≥ 0<label>(4)</label></formula><p>The first term models the joint dependencies between the task weights and the interaction matrix and it is defined as</p><formula xml:id="formula_6">C M T L (w, Ω) = 1 2 (w − w t ) T Ω ⊗ (w − w t ), where Ω ⊗ = Ω ⊗ I d .</formula><p>The function D(·) represents the diver- gence between a pair of positive definite matri- ces. Similar to <ref type="bibr" target="#b22">(Saha et al., 2011</ref>), to define D(·) we also consider the family of Bregman di- vergences and specifically the LogDet and the Von Neumann divergences. Given two matri- ces X, Y ∈ R n×n , the LogDet divergence is</p><formula xml:id="formula_7">D LD (X, Y) = tr(XY −1 ) − log |XY −1 | − n, while the Von Neumann divergence is computed as D V N (X, Y) = tr(X log X−Y log Y−X+Y).</formula><p>The optimization process to solve Eq.4 is per- formed with an alternate scheme: first, with a fixed Ω, we compute w; then, given w we opti- mize for Ω. The closed-form solution for updating w, which we derived similarly to the PA update ( <ref type="bibr" target="#b9">Crammer et al., 2006</ref>), becomes:</p><formula xml:id="formula_8">wt = wt−1 + sgn(yt − ˆ yt)τt(Ωt−1 ⊗ I d ) −1 φ t (5)</formula><p>In practice, the interaction matrix works as a learn- ing rate when updating the weights of each task. Similarly, following previous works ( <ref type="bibr" target="#b27">Tsuda et al., 2005</ref>), the update steps for the interaction matrix Ω can be easily derived. For the Log-Det diver- gence we have:</p><formula xml:id="formula_9">Ωt = (Ωt−1 + η sym( W T t−1 Wt−1)) −1<label>(6)</label></formula><p>222 while for the Von Neumann we obtain:</p><formula xml:id="formula_10">Ωt = exp(log Ωt−1 − η sym( W T t−1 Wt−1))<label>(7)</label></formula><p>where W t ∈ R d×K is a matrix obtained by column-wise reshaping the weight vector w t , sym(X) = (X + X T )/2 and η is the learning rate parameter. The sequence of steps to compute Ω t and w t is summarized in Algorithm 1. Impor- tantly, the weight vector is updated at each round t, while Ω t is initialized to a diagonal matrix and it is only computed after R iterations. In this way, at the beginning, the tasks are assumed to be in- dependent and the task-specific regression mod- els are learned in isolation. Then, after R rounds, the interaction matrix is updated and the weights are refined considering tasks dependencies. This leads to a progressive increase in the correlation of weight vectors of related tasks. In the follow- ing, PAMTL vn refers to PAMTL with the Von Neumann updates and PAMTL ld to PAMTL with LogDet updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setting</head><p>In this section, we describe the data used in our ex- periments, the features extracted from the source and target sentences, the evaluation metric and the baselines used for comparison.</p><p>Data. We experiment with English-French datasets coming from Technology Entertainment Design talks (TED), Information Technology manuals (IT) and Education Material (EM). All datasets provide a set of tuples composed by (source, translation and post-edited translation).</p><p>The TED dataset is distributed in the Trace cor- pus <ref type="bibr">4</ref> and includes, as source sentences, the sub- titles of several talks spanning a range of topics presented in the TED conferences. Translations were generated by two different MT systems: a phrase-based statistical MT system and a commer- cial rule-based system. Post-editions were col- lected from four different translators, as described by <ref type="bibr" target="#b30">Wisniewski et al. (2013)</ref>.</p><p>The IT manuals data come from two language service providers, henceforth LSP 1 and LSP 2. The IT LSP 1 tuples belong to a software manual translated by an SMT system trained using the Moses toolkit ( <ref type="bibr" target="#b17">Koehn et al., 2007)</ref>. The post- editions were produced by one professional trans- In total, we end up with four domains (TED, IT LSP 1 , EM and IT LSP 2 ), which allows us to eval- uate the PAMTL algorithm in realistic conditions where the QE component is exposed to a contin- uous stream of heterogeneous data. Each domain is composed by 1,000 tuples formed by: i) the En- glish source sentence, ii) its automatic translation in French, and iii) a real-valued quality label ob- tained by computing the HTER between the trans- lation and the post-edition with the TERCpp open source tool. <ref type="bibr">6</ref> Table 1 reports some macro-indicators (num- ber of tokens, vocabulary size, average sentence length) that give an idea about the similarities and differences between domains. Although they con- tain data from different software manuals, similar vocabulary size and sentence lengths for the two IT domains seem to reflect some commonalities in their technical style and jargon. Larger values for TED and EM evidence a higher lexical variability in the topics that compose these domains and the expected stylistic differences featured by speech transcriptions and non-technical writing. Over- all, these numbers suggest a possible dissimilar- ity between IT LSP 1 and IT LSP 2 and the other two domains, which might make knowledge transfer across them more difficult and QE model reactiv- ity to domain changes particularly important.</p><p>Features. Our models are trained using the 17 baseline features proposed in ( <ref type="bibr" target="#b26">Specia et al., 2009)</ref>, extracted with the online version of the QuEst fea- ture extractor <ref type="bibr" target="#b23">(Shah et al., 2014</ref>). These features take into account the complexity of the source sen- tence (e.g. number of tokens, number of transla- tions per source word) and the fluency of the trans- lation (e.g. language model probabilities). Their description is available in <ref type="bibr" target="#b5">(Callison-Burch et al., 2012)</ref>. The results of previous WMT QE shared tasks have shown that these features are particu- larly competitive in the HTER prediction task.</p><p>Baselines. We compare the performance of PAMTL against three baselines: i) pooling mean, ii) pooling online single task learning (STL pool ) and iii) in-domain online single task learning (STL in ). The pooling mean is obtained by assign- ing a fixed prediction value to each test point. This value is the average HTER computed on the entire pool of training data. Although assigning the same prediction to each test instance would be useless in real applications, we compare against the mean baseline since it is often hard to beat in regression tasks, especially when dealing with heterogeneous data distributions ( <ref type="bibr" target="#b20">Rubino et al., 2013)</ref>. The two online single task baselines implement the PA algorithm described in Section 3.1. The choice of PA is to make them comparable to our method, so that we can isolate more precisely the contribution of multitask learning. STL pool results are obtained by a single model trained on the entire pool of available training data presented in random order. STL in results are obtained by separately training one model for each domain. These repre- sent two alternative strategies for the integration of QE in the CAT framework. The former would al- low a single model to simultaneously support mul- tiple translation jobs in different domains, without any notion about their relations. The latter would lead to a more complex architecture, organized as a pool of independent, specialized QE modules.</p><p>Evaluation metric. The performance of our re- gression models is evaluated in terms of mean ab- solute error (MAE), a standard error measure for regression problems commonly used also for QE <ref type="bibr" target="#b5">(Callison-Burch et al., 2012</ref>). The MAE is the av- erage of the absolute errors e i = | ˆ y i − y i |, wherêwherê y i is the prediction of the model and y i is the true value for the i th instance. As it is an error mea- sure, lower values indicate better performance (↓).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>In this Section we evaluate the proposed PAMTL algorithm. First, by analyzing how the number of rounds R impacts on the performance of our ap- proach, we empirically find the value that will be used to train the model. Then, the learned model is run on test data and compared against the base- lines. Performance is analyzed both by averag- ing the MAE results computed on all the domains, and by separately discussing in-domain behavior. Finally, the capability of the algorithm to learn task correlations and, in turn, transfer knowledge across them, is analysed by presenting the correla- For the evaluation, we uniformly sample 700 in- stances from each domain for training, leaving the remaining 300 instances for test. The training sets of all the domains are concatenated and shuffled to create a random sequence of points. To inves- tigate the impact of different amounts of data on the learning process, we create ten subsets of 10 to 100% of the training data. We optimize the pa- rameters of all the models with a grid search pro- cedure using 5-fold cross-validation. This process is repeated for 30 different train/test splits over the whole data. Results are presented with 95% confi- dence bands. 7</p><p>Analysis of the R parameter. We empirically study the influence of the number of instances re- quired to start updating the interaction matrix (the R parameter in Algorithm 1). For that, we per- form a set of experiments where R is initialized with nine different values (expressed as percent- age of training data). <ref type="figure" target="#fig_0">Figure 1</ref> shows the val- idation curves obtained in cross-validation over the training data using the LogDet and Von Neu- mann updates. The curves report the performance (MAE) difference between STL in and PAMTL ld (black curve) and STL in and PAMTL vn (grey curve). The higher the difference, the better. The PAMTL vn curve differs from PAMTL ld one only for small values of R <ref type="bibr">(&lt; 20)</ref>, showing that the two divergences are substantially equivalent. It is in- teresting to note that with only 20% of the training data (R = 20), PAMTL is able to find a stable set of weights and to effectively update the inter- action matrix. Larger values of R harm the perfor- mance, indicating that the interaction matrix up- dates require a reasonable amount of points to reli- ably transfer knowledge across tasks. We use this observation to set R for our final experiment, in which we evaluate the methods over the test data.</p><p>Evaluation on test data. Global evaluation re- sults are summarized in <ref type="figure" target="#fig_1">Figure 2</ref>, which shows five curves: one for each baseline (Mean, STL in , STL pool ) and two for the proposed online mul- titask method (PAMTL vn and PAMTL ld ). The curves are computed by calculating the average MAE achieved with different amounts of data on each domain's test set.</p><p>The results show that PAMTL ld and PAMTL vn have similar trends (confirming the substantial equivalence previously observed), and that both outperform all the baselines in a statistically sig- nificant manner. This holds for all the training set sizes we experimented with. The maximum im- provement over the baselines (+1.3 MAE) is ob- served with 60% of the training data when com- paring PAMTL vn with STL in . Even if this is the best baseline, also with 100% of the data its results are not competitive and of limited interest with re- spect to our application scenario (the integration of effective QE models in the CAT framework). In- deed, despite the STL in downward error trend, it's worth remarking that an increased competitive- ness would come at the cost of: i) collecting large amounts of annotated data and ii) integrating the model in a complex CAT architecture organized as a pool of independent QE components. Under the tested conditions, it is also evident that the al- ternative strategy of using a single QE component to simultaneously serve multiple translation jobs is not viable. Indeed, STL pool is the worst perform- ing baseline, with a constant distance of around 2 MAE points from the best PAMTL model for al- most all the training set sizes. The fact that, with increasing amounts of data, the STL pool predic- tions get close to those of the simple mean base- line indicates its limitations to cope with the noise introduced by a continuous stream of diverse data. The capability to handle such stream by exploit- ing task relationships makes PAMTL a much bet- ter solution for our purposes.</p><p>Per-domain analysis. <ref type="figure" target="#fig_2">Figure 3</ref> shows the MAE results achieved on each target domain by the most competitive baseline (STL in ) and the proposed on- line multitask method (PAMTL vn , PAMTL ld ).</p><p>For all the domains, the behavior of PAMTL ld and PAMTL vn is consistent and almost identi- cal. With both divergences, the improvement of PAMTL over online single task learning becomes statistically significant when using more than 30% of the training data (210 instances). Interestingly, in all the plots, with 20% of the training data (140 instances for each domain, i.e. a total of 560 instances adding data from all the domains), PATML results are comparable to those achieved by STL in with 80% of the training data (i.e. 560 in-domain instances). This confirms that PATML can effectively leverage data heterogeneity, and that a limited amount of in-domain data is suf- ficient to make it competitive. Nevertheless, for all domains except EM, the PATML and STL in curves converge to comparable performance when trained with 100% of the data. This is not surpris- ing if we consider that EM has a varied vocabulary (see <ref type="table">Table 1</ref>), which may be evidence of the pres- ence of different topics, increasing its similarity with other domains. The same assumption should also hold for TED, given that its source sentences belong to talks about different topics. The results for the TED domain, however, do not present the same degree of improvement as for EM.</p><p>To better understand the relationships learned by the PAMTL models, we compute the corre- lation between the weights inferred for each do- main (as performed by <ref type="bibr" target="#b22">Saha et al. (2011)</ref>). <ref type="figure" target="#fig_3">Fig- ure 4</ref> shows the correlations computed on the task weights learned by PATML vn with all the train- ing data. In the matrix, EM is the domain that presents the highest correlation with all the others. Instead, TED and IT LSP 2 are the less correlated with the other domains (even though, being close to the other IT domain, IT LSP 2 can share knowl- edge with it). This explains why the improvement measured on TED is smaller compared to EM. Al- though there is no canonical way to measure cor- relation among domains, the weights correlation matrix and the improvements achieved by PAMTL show the capability of the method to identify task relationships and exploit them to improve the gen- eralization properties of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We addressed the problem of developing qual- ity estimation models suitable for integration in computer-assisted translation technology. In this framework, on-the-fly MT quality prediction for a stream of heterogeneous data coming from differ- ent domains/users/MT systems represents a major challenge. On one side, processing such stream calls for supervised solutions that avoid the bot-tleneck of periodically retraining the QE models in a batch fashion. On the other side, handling data heterogeneity requires the capability to lever- age data similarities and dissimilarities. While previous works addressed these two problems in isolation, by proposing approaches respectively based on online and multitask learning, our so- lution unifies the two paradigms in a single on- line multitask approach. To this aim, we devel- oped a novel regression algorithm, filling a gap left by current online multitask learning methods that only operate in classification mode. Our ap- proach, which is based on the passive aggressive algorithm, has been successfully evaluated against strong online single-task competitors in a scenario involving four domains. Our future objective is to extend our evaluation to streams of data com- ing from a larger number of domains. Finding reasonably-sized datasets for this purpose is cur- rently difficult. However, we are confident that the gradual shift of the translation industry towards human MT post-editing will not only push for fur- ther research on these problems, but also provide data for larger scale evaluations in a short time.</p><p>To allow for replicability of our results and promote further research on QE, the features ex- tracted from our data, the computed labels and the source code of the method are available at https://github.com/jsouza/pamtl.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Validation curves for the R parameter.</figDesc><graphic url="image-1.png" coords="6,73.69,62.80,214.91,158.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Learning curves for all the domains, computed by calculating the mean MAE (↓) of the four domains.</figDesc><graphic url="image-2.png" coords="6,311.33,62.81,210.17,167.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning curves showing MAE (↓) variations for each domain.</figDesc><graphic url="image-3.png" coords="7,83.94,62.81,429.66,276.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Correlation among the weights predicted by PATML vn using all the training data.</figDesc><graphic url="image-4.png" coords="8,307.28,62.81,228.75,151.13" type="bitmap" /></figure>

			<note place="foot" n="1"> See for instance the open source MateCat tool (Federico et al., 2014).</note>

			<note place="foot" n="4"> http://anrtrace.limsi.fr/trace_ postedit.tar.bz2</note>

			<note place="foot" n="5"> https://autodesk.app.box.com/ Autodesk-PostEditing 6 http://sourceforge.net/projects/ tercpp/</note>

			<note place="foot" n="7"> Confidence bands are used to show whether performance differences between the models are statistically significant.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work has been partially supported by the EC-funded H2020 project QT21 (grant agreement no. 645452). The authors would like to thank Dr. Ventsislav Zhechev for his support with the Au-todesk Post-Editing Data corpus.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Convex multi-task feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano Massimo</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2008-01" />
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="243" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Goodness: A method for measuring machine translation confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nguyen Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al-Onaizan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">49th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<title level="m">Findings of the 2013 Workshop on Statistical Machine Translation</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Eighth Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Findings of the 2014 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saint-Amand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-task Gaussian Process Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Bonilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Kian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20: NIPS&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Findings of the 2012 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Statistical Machine Translation</title>
		<meeting>the 7th Workshop on Statistical Machine Translation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linear algorithms for online multitask classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Cavallanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gentile</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2901" to="2934" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modelling Annotator Bias with Multi-task Gaussian Processes: An application to Machine Translation Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Shai Shalev-Shwartz, and Yoram Singer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofer</forename><surname>Dekel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="551" to="585" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Online Passive-Aggressive Algorithms</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine Translation Quality Estimation Across Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="409" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards a Combination of Online and Multitask Learning for MT Quality Estimation: a Preliminary Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Interactive and Adaptive Machine Translation</title>
		<meeting>Workshop on Interactive and Adaptive Machine Translation<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
	<note>IAMT 2014</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ELLA: An efficient lifelong learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Eaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on Machine Learning<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="507" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Trombetti</surname></persName>
		</author>
		<imprint>
			<pubPlace>Alessandro Cattelan, Antonio Farina, Domenico</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">THE MATECAT TOOL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Lupinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Martines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Massidda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Blain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Germann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="129" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adaptive HTER Estimation for Document-Specific MT Post-Editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Ming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Clustered Multi-Task Learning: A Convex Formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D Koller, D Schuurmans, Y Bengio, and L Bottou</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="745" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2007 Demo and Poster Sessions</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Match without a Referee: Evaluating MT Adequacy without Reference Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Machine Translation Workshop (WMT2012)</title>
		<meeting>the Machine Translation Workshop (WMT2012)<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Online support vector regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Parrella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Genoa, Italy</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Information Science, University of</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Topic Models for Translation Quality Estimation for Gisting Purposes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation Summit XIV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online Multi-Task Learning via Sparse Dictionary Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ruvolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Eaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI-14)</title>
		<meeting>the 28th AAAI Conference on Artificial Intelligence (AAAI-14)<address><addrLine>Québec City, Québec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online Learning of Multiple Tasks and their Relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Venkatasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)<address><addrLine>Fort Lauderdale, FL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Efficient and User-friendly Tool for Machine Translation Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Study of Translation Edit Rate with Targeted Human Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Machine Translation in the Americas</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Trustrank: Inducing trust in automatic translations via ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Echihabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, number July</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics, number July</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="612" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Estimating the Sentence-Level Quality of Machine Translation Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Annual Conference of the EAMT</title>
		<meeting>the 13th Annual Conference of the EAMT<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-05" />
			<biblScope unit="page" from="28" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Matrix exponentiated gradient updates for online learning and bregman projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koji</forename><surname>Tsuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="995" to="1018" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Coping with the Subjectivity of Human Judgements in MT Quality Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation (WMT)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="240" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive Quality Estimation for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="710" to="720" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Design and Analysis of a Large Corpus of Post-Edited Translations: Quality Estimation, Failure Analysis and the Variability of Post-Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation Summit XIV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multitask linear discriminant analysis for view invariant action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramanathan</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaowen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5599" to="5611" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Convex Formulation for Learning Task Relationships in Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-10)</title>
		<meeting>the Twenty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-10)<address><addrLine>Catalina Island, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="733" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Convex multitask learning with flexible task clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon Wenliang</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29 th International Conference on Machine Learning</title>
		<meeting>the 29 th International Conference on Machine Learning<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
