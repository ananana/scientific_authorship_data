<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Matrix Factorization with Knowledge Graph Propagation for Unsupervised Spoken Language Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Aveue</addrLine>
									<postCode>15213-3891</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Aveue</addrLine>
									<postCode>15213-3891</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatole</forename><surname>Gershman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Aveue</addrLine>
									<postCode>15213-3891</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Aveue</addrLine>
									<postCode>15213-3891</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Matrix Factorization with Knowledge Graph Propagation for Unsupervised Spoken Language Understanding</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="483" to="494"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Spoken dialogue systems (SDS) typically require a predefined semantic ontology to train a spoken language understanding (SLU) module. In addition to the annotation cost, a key challenge for designing such an ontology is to define a coherent slot set while considering their complex relations. This paper introduces a novel matrix factorization (MF) approach to learn latent feature vectors for utterances and semantic elements without the need of corpus annotations. Specifically, our model learns the semantic slots for a domain-specific SDS in an unsupervised fashion, and carries out semantic parsing using latent MF techniques. To further consider the global semantic structure , such as inter-word and inter-slot relations , we augment the latent MF-based model with a knowledge graph propagation model based on a slot-based semantic graph and a word-based lexical graph. Our experiments show that the proposed MF approaches produce better SLU models that are able to predict semantic slots and word patterns taking into account their relations and domain-specificity in a joint manner.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A key component of a spoken dialogue sys- tem (SDS) is the spoken language understand- ing (SLU) module-it parses the users' utterances into semantic representations; for example, the ut- terance "find a cheap restaurant" can be parsed into (price=cheap, target=restaurant) ( <ref type="bibr" target="#b32">Pieraccini et al., 1992)</ref>. To design the SLU module of a SDS, most previous studies relied on predefined slots 1 for training the decoder <ref type="bibr" target="#b35">(Seneff, 1992;</ref><ref type="bibr" target="#b17">Dowding et al., 1993;</ref><ref type="bibr" target="#b20">Gupta et al., 2006;</ref><ref type="bibr" target="#b1">Bohus and Rudnicky, 2009</ref>). However, these predefined semantic slots may bias the subsequent data collection pro- cess, and the cost of manually labeling utterances for updating the ontology is expensive ( .</p><p>In recent years, this problem led to the devel- opment of unsupervised SLU techniques <ref type="bibr" target="#b11">Chen et al., 2014b</ref>). In particular,  proposed a frame-semantics based framework for automatically inducing se- mantic slots given raw audios. However, these ap- proaches generally do not explicitly learn the la- tent factor representations to model the measure- ment errors <ref type="bibr" target="#b36">(Skrondal and Rabe-Hesketh, 2004</ref>), nor do they jointly consider the complex lexical, syntactic, and semantic relations among words, slots, and utterances.</p><p>Another challenge of SLU is the inference of the hidden semantics. Considering the user utter- ance "can i have a cheap restaurant", from its sur- face patterns, we can see that it includes explicit semantic information about "price (cheap)" and "target (restaurant)"; however, it also includes hidden semantic information, such as "food" and "seeking", since the SDS needs to infer that the user wants to "find" some cheap "food", even though they are not directly observed in the sur- face patterns. Nonetheless, these implicit seman- tics are important semantic concepts for domain- specific SDSs. Traditional SLU models use dis- criminative classifiers <ref type="bibr" target="#b24">(Henderson et al., 2012</ref>) to predict whether the predefined slots occur in the utterances or not, ignoring the unobserved con- cepts and the hidden semantic information.</p><p>In this paper, we take a rather radical approach: we propose a novel matrix factorization (MF) model for learning latent features for SLU, tak- ing account of additional information such as the word relations, the induced slots, and the slot re- lations. To further consider the global coherence of induced slots, we combine the MF model with a knowledge graph propagation based model, fus- ing both a word-based lexical knowledge graph and a slot-based semantic graph. In fact, as it is shown in the Netflix challenge, MF is cred- ited as the most useful technique for recommen- dation systems ( <ref type="bibr" target="#b26">Koren et al., 2009)</ref>. Also, the MF model considers the unobserved patterns and esti- mates their probabilities instead of viewing them as negative examples. However, to the best of our knowledge, the MF technique is not yet well un- derstood in the SLU and SDS communities, and it is not very straight-forward to use MF methods to learn latent feature representations for semantic parsing in SLU. To evaluate the performance of our model, we compare it to standard discrimina- tive SLU baselines, and show that our MF-based model is able to produce strong results in seman- tic decoding, and the knowledge graph propaga- tion model further improves the performance. Our contributions are three-fold:</p><p>• We are among the first to study matrix fac- torization techniques for unsupervised SLU, taking account of additional information; • We augment the MF model with a knowl- edge graph propagation model, increasing the global coherence of semantic decoding using induced slots; • Our experimental results show that the MF- based unsupervised SLU outperforms strong discriminative baselines, obtaining promis- ing results. In the next section, we outline the related work in unsupervised SLU and latent variable model- ing for spoken language processing. Section 3 introduces our framework. The detailed MF ap- proach is explained in Section 4. We then intro- duce the global knowledge graphs for MF in Sec- tion 5. Section 6 shows the experimental results, and Section 7 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Unsupervised SLU <ref type="bibr" target="#b38">Tur et al. (2011;</ref> were among the first to consider unsupervised ap- proaches for SLU, where they exploited query logs for slot-filling. In a subsequent study, Heck and Hakkani-Tür (2012) studied the Semantic Web for an unsupervised intent detection problem in SLU, showing that results obtained from the unsuper- vised training process align well with the perfor- mance of traditional supervised learning. Fol- lowing their success of unsupervised SLU, recent studies have also obtained interesting results on the tasks of relation detection <ref type="bibr" target="#b10">Chen et al., 2014a</ref>), entity extraction ( <ref type="bibr" target="#b42">Wang et al., 2014)</ref>, and extending domain coverage <ref type="bibr">(ElKahky et al., 2014;</ref><ref type="bibr" target="#b7">Chen and Rudnicky, 2014</ref>). However, most of the studies above do not ex- plicitly learn latent factor representations from the data-while we hypothesize that the better robust- ness in noisy data can be achieved by explicitly modeling the measurement errors (usually pro- duced by automatic speech recognizers (ASR)) us- ing latent variable models and taking additional lo- cal and global semantic constraints into account. Latent Variable Modeling in SLU Early stud- ies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition <ref type="bibr" target="#b25">(Jelinek, 1997)</ref>. Recently,  were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model. In the field of dialogue modeling, the partially observ- able Markov decision process (POMDP) ( <ref type="bibr" target="#b44">Young et al., 2013</ref>) model is a popular technique for di- alogue management, reducing the cost of hand- crafted dialogue managers while producing ro- bustness against speech recognition errors. More recently,  used a semi-supervised LDA model to show improvement on the slot fill- ing task. Also, <ref type="bibr" target="#b45">Zhai and Williams (2014)</ref> proposed an unsupervised model for connecting words with latent states in HMMs using topic models, obtain- ing interesting qualitative and quantitative results. However, for unsupervised learning for SLU, it is not obvious how to incorporate additional infor- mation in the HMMs. To the best of our knowl- edge, this paper is the first to consider MF tech- niques for learning latent feature representations in unsupervised SLU, taking various local and global lexical, syntactic, and semantic information into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Framework</head><p>This paper introduces a matrix factorization tech- nique for unsupervised SLU,. The proposed framework is shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>. Given the utterances, the task of the SLU model is to de- code their surface patterns into semantic forms and differentiate the target semantic concepts from the generic semantic space for task-oriented SDSs simultaneously. Note that our model does not require any human-defined slots and domain- specific semantic representations for utterances.</p><p>In the proposed model, we first build a feature matrix to represent the training utterances, where each row represents an utterance, and each column refers to an observed surface pattern or a induced slot candidate. <ref type="figure" target="#fig_0">Figure 1(</ref>  of the matrix. Given a testing utterance, we con- vert it into a vector based on the observed surface patterns, and then fill in the missing values of the slots. In the first utterance in the figure, although the semantic slot food is not observed, the utter- ance implies the meaning facet food. The MF ap- proach is able to learn the latent feature vectors for utterances and semantic elements, inferring im- plicit semantic concepts to improve the decoding process-namely, by filling the matrix with prob- abilities (lower part of the matrix).</p><p>The feature model is built on the observed word patterns and slot candidates, where the slot candi- dates are obtained from the slot induction compo- nent through frame-semantic parsing (the yellow block in <ref type="figure" target="#fig_0">Figure 1</ref>(a)) ). Sec- tion 4.1 explains the detail of the feature model.</p><p>In order to consider the additional inter-word and inter-slot relations, we propose a knowledge graph propagation model based on two knowl- edge graphs, which includes a word relation model (blue block) and a slot relation model (pink block), described in Section 4.2. The method of auto- matic knowledge graph construction is introduced in Section 5, where we leverage distributed word embeddings associated with typed syntactic de- pendencies to model the relations ( <ref type="bibr" target="#b29">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b30">Mikolov et al., 2013c;</ref><ref type="bibr" target="#b27">Levy and Goldberg, 2014;</ref><ref type="bibr" target="#b12">Chen et al., 2015)</ref>.</p><p>Finally, we train the SLU model by learning latent feature vectors for utterances and slot can- didates through MF techniques. Combining with a knowledge graph propagation model based on word/slot relations, the trained SLU model esti- mates the probability that each semantic slot oc- curs in the testing utterance, and how likely each slot is domain-specific simultaneously. In other words, the SLU model is able to transform the test- ing utterances into domain-specific semantic rep- resentations without human involvement.  long-range dependencies between observations, in this work we apply an MF approach to SLU mod- eling for SDSs. In our model, we use U to de- note the set of input utterances, W as the set of word patterns, and S as the set of semantic slots that we would like to predict. The pair of an ut- terance u ∈ U and a word pattern/semantic slot x ∈ {W + S}, u, x, is a fact. The input to our model is a set of observed facts O, and the observed facts for a given utterance is denoted by {{u, x ∈ O}. The goal of our model is to esti- mate, for a given utterance u and a given word pat- tern/semantic slot x, the probability, p(M u,x = 1), where M u,x is a binary random variable that is true if and only if x is the word pattern/domain-specific semantic slot in the utterance u. We introduce a series of exponential family models that estimate the probability using a natural parameter θ u,x and the logistic sigmoid function:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Matrix Factorization Approach</head><formula xml:id="formula_0">p(M u,x = 1 | θ u,x ) = σ(θ u,x ) = 1 1 + exp (−θ u,x )</formula><p>(1) We construct a matrix M |U |×(|W |+|S|) as observed facts for MF by integrating a feature model and a knowledge graph propagation model below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Model</head><p>First, we build a word pattern matrix F w with binary values based on observations, where each row represents an utterance and each column refers to an observed unigram. In other words, F w carries the basic word vectors for the utterances, which is illustrated as the left part of the matrix in <ref type="figure" target="#fig_0">Figure 1(b)</ref>.</p><p>To induce the semantic elements, we parse all ASR-decoded utterances in our corpus using SE- MAFOR 2 , a state-of-the-art semantic parser for frame-semantic parsing ( <ref type="bibr" target="#b14">Das et al., 2010;</ref><ref type="bibr" target="#b15">Das et al., 2013)</ref>, and extract all frames from seman- tic parsing results as slot candidates <ref type="bibr" target="#b16">Dinarelli et al., 2009</ref>). <ref type="figure" target="#fig_1">Figure 2</ref> shows an example of an ASR-decoded output parsed by SEMAFOR. Three FrameNet-defined frames (capability, expensiveness, and locale by use) are generated for the utterance, which we consider as slot candidates for a domain-specific dialogue system ( <ref type="bibr" target="#b0">Baker et al., 1998</ref>). Then we build a slot matrix F s with binary values based on the induced slots, which also denotes the slot features for the utterances (right part of the matrix in <ref type="figure" target="#fig_0">Figure 1(b)</ref>).</p><p>To build the feature model M F , we concatenate two matrices:</p><formula xml:id="formula_1">M F = [ F w F s ],<label>(2)</label></formula><p>which is the upper part of the matrix in <ref type="figure" target="#fig_0">Fig- ure 1(b)</ref> for training utterances. Note that we do not use any annotations, so all slot candidates are included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge Graph Propagation Model</head><p>Since SEMAFOR was trained on FrameNet anno- tation, which has a more generic frame-semantic context, not all the frames from the parsing re- sults can be used as the actual slots in the domain- specific dialogue systems. For instance, in <ref type="figure" target="#fig_1">Fig- ure 2</ref>, we see that the frames "expensiveness" and "locale by use" are essentially the key slots for the purpose of understanding in the restaurant query domain, whereas the "capability" frame does not convey particularly valuable information for SLU.</p><p>Assuming that domain-specific concepts are usually related to each other, considering global relations between semantic slots induces a more coherent slot set. It is shown that the relations on knowledge graphs help make decisions on domain-specific slots <ref type="bibr" target="#b12">(Chen et al., 2015)</ref>. Con- sidering two directed graphs, semantic and lexi- cal knowledge graphs, each node in the semantic knowledge graph is a slot candidate s i generated by the frame-semantic parser, and each node in the lexical knowledge graph is a word w j .</p><p>• Slot-based semantic knowledge graph is built as</p><formula xml:id="formula_2">G s = V s , E ss , where V s = {s i ∈ S} and E ss = {e ij | s i , s j ∈ V s }. • Word-based lexical knowledge graph is built as G w = V w , E ww , where V w = {w i ∈ W } and E ww = {e ij | w i , w j ∈ V w }.</formula><p>The edges connect two nodes in the graphs if there is a typed dependency between them. <ref type="figure" target="#fig_2">Figure 3</ref> is a simplified example of a slot-based semantic knowledge graph. The structured graph helps de- fine a coherent slot set. To model the relations be- tween words/slots based on the knowledge graphs, we define two relation models below. • Semantic Relation For modeling word semantic rela- tions, we compute a matrix R S w = [Sim(w i , w j )] |W |×|W | , where Sim(w i , w j ) is the cosine similarity between the de- pendency embeddings of the word pat- terns w i and w j after normalization. For slot semantic relations, we compute R S s = [Sim(s i , s j )] |S|×|S| similarly 3 . The matrices R S w and R S s model not only the semantic but functional similarity since we use dependency-based embeddings ( <ref type="bibr" target="#b27">Levy and Goldberg, 2014</ref>).</p><p>• Dependency Relation</p><p>Assuming that important semantic slots are usually mutually related to each other, that is, connected by syntactic dependencies, our automatically derived knowledge graphs are able to help model the dependency relations.</p><p>For word dependency relations, we compute a matrix R D w = [ˆ r(w i , w j )] |W |×|W | , wherêwherê r(w i , w j ) measures the dependency between two word patterns w i and w j based on the word-based lexical knowledge graph, and the detail is described in Section 5. For slot dependency relations, we similarly compute</p><formula xml:id="formula_3">R D s = [ˆ r(s i , s j )] |S|×|S| based on the slot- based semantic knowledge graph.</formula><p>With the built word relation models (R S w and R D w ) and slot relation models (R S s and R D s ), we com- bine them as a knowledge graph propagation ma- trix M R 4 .</p><formula xml:id="formula_4">M R = R SD w 0 0 R SD s ,<label>(3)</label></formula><p>3 For each column in R S w and R S s , we only keep top 10 highest values, which correspond the top 10 semantically similar nodes. <ref type="bibr">4</ref> The values in the diagonal of MR are 0 to model the propagation from other entries.</p><note type="other">where R SD w = R S w + R D w and R SD s = R S s + R D s to integrate semantic and</note><p>dependency relations. The goal of this matrix is to propagate scores between nodes according to different types of relations in the knowledge graphs (Chen and Metze, 2012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Integrated Model</head><p>With a feature model M F and a knowledge graph propagation model M R , we integrate them into a single matrix.</p><formula xml:id="formula_5">M = M F · (αI + βM R )<label>(4)</label></formula><formula xml:id="formula_6">= αF w + βF w R w 0 0 αF s + βF s R s ,</formula><p>where M is the final matrix and I is the iden- tity matrix. α and β are the weights for balanc- ing original values and propagated values, where α + β = 1. The matrix M is similar to M F , but some weights are enhanced through the knowl- edge graph propagation model, M R . The word relations are built by F w R w , which is the ma- trix with internal weight propagation on the lexical knowledge graph (the blue arrow in <ref type="figure" target="#fig_0">Figure 1(b)</ref>). Similarly, F s R s models the slot correlations, and can be treated as the matrix with internal weight propagation on the semantic knowledge graph (the pink arrow in <ref type="figure" target="#fig_0">Figure 1(b)</ref>). The propagation mod- els can be treated as running a random walk algo- rithm on the graphs. F s contains all slot candidates generated by SEMAFOR, which may include some generic slots (such as capability), so the original feature model cannot differentiate the domain-specific and generic concepts. By integrating with R s , the semantic and dependency relations can be propa- gated via the knowledge graph, and the domain- specific concepts may have higher weights based on the assumption that the slots for dialogue sys- tems are often mutually related ( <ref type="bibr" target="#b12">Chen et al., 2015)</ref>. Hence, the structure information can be automati- cally involved in the matrix. Also, the word rela- tion model brings the same function, but now on the word level. In conclusion, for each utterance, the integrated model not only predicts the proba- bility that semantic slots occur but also considers whether the slots are domain-specific. The follow- ing sections describe the learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Parameter Estimation</head><p>The proposed model is parameterized through weights and latent component vectors, where the parameters are estimated by maximizing the log likelihood of observed data <ref type="bibr" target="#b13">(Collins et al., 2001</ref>).</p><formula xml:id="formula_7">θ * = arg max θ u∈U p(θ | M u )<label>(5)</label></formula><p>= arg max</p><formula xml:id="formula_8">θ u∈U p(M u | θ)p(θ) = arg max θ u∈U ln p(M u | θ) − λ θ ,</formula><p>where M u is the vector corresponding to the utter- ance u from M u,x in (1), because we assume that each utterance is independent of others.</p><p>To avoid treating unobserved facts as designed negative facts, we consider our positive-only data as implicit feedback. Bayesian Personalized Rank- ing (BPR) is an optimization criterion that learns from implicit feedback for MF, which uses a vari- ant of the ranking: giving observed true facts higher scores than unobserved (true or false) facts ( <ref type="bibr" target="#b33">Rendle et al., 2009</ref>). <ref type="bibr" target="#b34">Riedel et al. (2013)</ref> also showed that BPR learns the implicit relations for improving the relation extraction task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Objective Function</head><p>To estimate the parameters in (5), we create a dataset of ranked pairs from M in (4): for each utterance u and each observed fact f + = u, x + , where M u,x ≥ δ, we choose each word pat- tern/slot x − such that f − = u, x − , where M u,x &lt; δ, which refers to the word pattern/slot we have not observed to be in utterance u. That is, we construct the observed data O from M . Then for each pair of facts f + and f − , we want to model p(f + ) &gt; p(f − ) and hence θ f + &gt; θ f − accord- ing to (1). BPR maximizes the summation of each ranked pair, where the objective is</p><formula xml:id="formula_9">u∈U ln p(M u | θ) = f + ∈O f − ∈O ln σ(θ f + − θ f − ). (6)</formula><p>The BPR objective is an approximation to the per utterance AUC (area under the ROC curve), which directly correlates to what we want to achieve -well-ranked semantic slots per utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Optimization</head><p>To maximize the objective in (6), we employ a stochastic gradient descent (SGD) algorithm <ref type="bibr" target="#b33">(Rendle et al., 2009</ref>). For each randomly sampled ob- served fact u, x + , we sample an unobserved fact u, x − , which results in |O| fact pairs f − , f + . For each pair, we perform an SGD update using the gradient of the corresponding objective func- tion for matrix factorization <ref type="bibr" target="#b19">(Gantner et al., 2011</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Knowledge Graph Construction</head><p>This section introduces the procedure of con- structing knowledge graphs in order to estimatêestimatê r(w i , w j ) for building R D w andˆrandˆ andˆr(s i , s j ) for R D s in Section 4.2. Considering the relations in the knowledge graphs, the edge weights for E ww and E ss are measured asˆrasˆ asˆr(w i , w j ) andˆrandˆ andˆr(s i , s j ) based on the dependency parsing results respectively.</p><p>The example utterance "can i have a cheap restaurant" and its dependency parsing result are illustrated in <ref type="figure" target="#fig_3">Figure 4</ref>. The arrows denote the dependency relations from headwords to their dependents, and words on arcs denote types of the dependencies. All typed dependencies between two words are encoded in triples and form a word-based dependency set T w = {{w i , t, w j }, where t is the typed dependency between the headword w i and the dependent w j . For example, <ref type="figure" target="#fig_3">Figure 4</ref> generates restaurant, AMOD, cheap, restaurant, DOBJ, have, etc.</p><p>for T w , Sim- ilarly, we build a slot-based dependency set T s = {{s i , t, s j } by transforming dependen- cies between slot-fillers into ones between slots. For example, restaurant, AMOD, cheap from T w is transformed into locale by use, AMOD, expensiveness for building T s , because both sides of the non-dotted line are parsed as slot-fillers by SEMAFOR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Relation Weight Estimation</head><p>For the edges in the knowledge graphs, we model the relations between two connected nodes x i and x j asˆrasˆ asˆr(x i , x j ), where x is either a slot s or a word pattern w. Since the weights are measured based on the relations between nodes regardless of the directions, we combine the scores of two direc- tional dependencies:</p><formula xml:id="formula_10">ˆ r(x i , x j ) = r(x i → x j ) + r(x j → x i ),<label>(7)</label></formula><p>where r(x i → x j ) is the score estimating the de- pendency including x i as a head and x j as a de- pendent. We propose a scoring function for r(·) using dependency-based embeddings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Dependency-Based Embeddings</head><p>Most neural embeddings use linear bag-of-words contexts, where a window size is defined to pro- duce contexts of the target words ( <ref type="bibr" target="#b30">Mikolov et al., 2013c;</ref><ref type="bibr" target="#b29">Mikolov et al., 2013b;</ref><ref type="bibr" target="#b28">Mikolov et al., 2013a</ref>). However, some important contexts may be missing due to smaller windows, while larger windows capture broad topical content. A dependency-based embedding approach was pro- posed to derive contexts based on the syntactic re- lations the word participates in for training embed- dings, where the embeddings are less topical but offer more functional similarity compared to orig- inal embeddings ( <ref type="bibr" target="#b27">Levy and Goldberg, 2014)</ref>. <ref type="table" target="#tab_2">Table 1</ref> shows the extracted dependency-based contexts for each target word from the example in <ref type="figure" target="#fig_3">Figure 4</ref>, where headwords and their dependents can form the contexts by following the arc on a word in the dependency tree, and −1 denotes the directionality of the dependency. After replacing original bag-of-words contexts with dependency- based contexts, we can train dependency-based embeddings for all target words ( <ref type="bibr" target="#b43">Yih et al., 2014;</ref><ref type="bibr" target="#b2">Bordes et al., 2011;</ref><ref type="bibr" target="#b3">Bordes et al., 2013</ref>).</p><p>For training dependency-based word embed- dings, each target x is associated with a vector v x ∈ R d and each context c is represented as a context vector v c ∈ R d , where d is the embed- ding dimensionality. We learn vector representa- tions for both targets and contexts such that the dot product v x · v c associated with "good" target- context pairs belonging to the training data D is maximized, leading to the objective function:</p><formula xml:id="formula_11">arg max vx,vc (w,c)∈D log 1 1 + exp(−v c · v x ) ,<label>(8)</label></formula><p>which can be trained using stochastic-gradient up- dates ( <ref type="bibr" target="#b27">Levy and Goldberg, 2014</ref>). Then we can obtain the dependency-based slot and word em- beddings using T s and T w respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Embedding-Based Scoring Function</head><p>With trained dependency-based embeddings, we estimate the probability that x i is the headword and x j is its dependent via the typed dependency t as</p><formula xml:id="formula_12">P (x i − → t x j ) = Sim(x i , x j /t) + Sim(x j , x i /t −1 ) 2 , (9)</formula><p>where Sim(x i , x j /t) is the cosine similarity be- tween word/slot embeddings v x i and context em- beddings v x j /t after normalizing to <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>.</p><p>Based on the dependency set T x , we use t * x i →x j to denote the most possible typed dependency with x i as a head and x j as a dependent.</p><formula xml:id="formula_13">t * x i →x j = arg max t C(x i − → t x j ),<label>(10)</label></formula><p>where C(x i − → t x j ) counts how many times the dependency x i , t, x j occurs in the dependency set T x . Then the scoring function r(·) in <ref type="formula" target="#formula_10">(7)</ref> that estimates the dependency x i → x j is measured as</p><formula xml:id="formula_14">r(x i → x j ) = C(x i − −−− → t * x i →x j x j )·P (x i − −−− → t * x i →x j x j ),<label>(11)</label></formula><p>which is equal to the highest observed frequency of the dependency x i → x j among all types from T x and additionally weighted by the estimated probability. The estimated probability smoothes the observed frequency to avoid overfitting due to the smaller dataset. <ref type="figure" target="#fig_2">Figure 3</ref> is a simplified exam- ple of an automatically derived semantic knowl- edge graph with the most possible typed depen- dencies as edges based on the estimated weights. Then the relation weightsˆrweightsˆ weightsˆr(x i , x j ) can be ob- tained by <ref type="bibr">(7)</ref> in order to build R D w and R D s ma- trices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>In this experiment, we used the Cambridge Uni- versity SLU corpus, previously used on several other SLU tasks ( <ref type="bibr" target="#b24">Henderson et al., 2012;</ref>). The domain of the corpus is about restaurant recommendation in Cambridge; sub- jects were asked to interact with multiple SDSs in an in-car setting. The corpus contains a to- tal number of 2,166 dialogues, including 15,453 utterances (10,571 for self-training and 4,882 for <ref type="table">Table 2</ref>: The MAP of predicted slots (%); † indicates that the result is significantly better than the Logistic Regression (row (b)) with p &lt; 0.05 in t-test.  testing). The data is gender-balanced, with slightly more native than non-native speakers. The vocab- ulary size is 1868. An ASR system was used to transcribe the speech; the word error rate was re- ported as 37%. There are 10 slots created by do- main experts: addr, area, food, name, phone, postcode, price range, signature, task, and type. For parameter setting, the weights for balanc- ing feature models and propagation models, α and β, are set as 0.5 to give the same influence, and the threshold for defining the unobserved facts δ is set as 0.5 for all experiments. We use the Stan- ford Parser <ref type="bibr">5</ref> to obtain the collapsed typed syntac- tic dependencies <ref type="bibr" target="#b37">(Socher et al., 2013)</ref> and set the dimensionality of embeddings d = 300 in all ex- periments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation Metrics</head><p>To evaluate the accuracy of the automatically decoded slots, we measure their quality as the proximity between predicted slots and reference slots. <ref type="figure" target="#fig_4">Figure 5</ref> shows the mappings that indicate semantically related induced slots and reference slots .</p><p>To eliminate the influence of threshold selection when predicting semantic slots, in the following <ref type="bibr">5</ref> http://nlp.stanford.edu/software/lex-parser. shtml metrics, we take the whole ranking list into ac- count and evaluate the performance by the met- rics that are independent of the selected threshold. For each utterance, with the predicted probabilities of all slot candidates, we can compute an average precision (AP) to evaluate the performance of SLU by treating the slots with mappings as positive. AP scores the ranking result higher if the correct slots are ranked higher, which also approximates to the area under the precision-recall curve <ref type="bibr" target="#b4">(Boyd et al., 2012)</ref>. Mean average precision (MAP) is the met- ric for evaluating all utterances. For all experi- ments, we perform a paired t-test on the AP scores of the results to test the significance. <ref type="table">Table 2</ref> shows the MAP performance of predicted slots for all experiments on ASR and manual tran- scripts. For the first baseline using explicit seman- tics, we use the observed data to self-train mod- els for predicting the probability of each seman- tic slot by support vector machine (SVM) with a linear kernel and multinomial logistic regression (MLR) (row (a)-(b)) <ref type="bibr" target="#b31">(Pedregosa et al., 2011;</ref><ref type="bibr" target="#b24">Henderson et al., 2012)</ref>. It is shown that SVM and MLR perform similarly, and MLR is slightly bet- ter than SVM because it has better capability of estimating probabilities. For modeling implicit semantics, two baselines are performed as refer- ences, Random (row (c)) and Majority (row (d)), where the former assigns random probabilities for all slots, and the later assigns probabilities for the slots based on their frequency distribution. To im- prove probability estimation, we further integrate the results from implicit semantics with the better result from explicit approaches, MLR (row (b)), by averaging the probability distribution from two results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation Results</head><p>Two baselines, Random and Majority, cannot model the implicit semantics, producing poor re- sults. The results of Random integrated with MLR significantly degrades the performance of <ref type="table">Table 3</ref>: The MAP of predicted slots using different types of relation models in M R (%); † indicates that the result is significantly better than the feature model (column (a)) with p &lt; 0.05 in t-test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Feature for ASR and manual results respectively, which are worse than two baselines using explicit se- mantics. However, with the combination of ex- plicit semantics, using only the feature model sig- nificantly outperforms the baselines, where the performance comes from about 34.0% to 37.6% and from 38.8% to 45.3% for ASR and manual results respectively. Additionally integrating a knowledge graph propagation (KGP) model (row (e)) outperforms the baselines for both ASR and manual transcripts, and the performance is fur- ther improved by combining with explicit seman- tics (achieving MAP of 43.5% and 53.4%). The experiments show that the proposed MF models successfully learn the implicit semantics and con- sider the relations and domain-specificity simulta- neously.</p><formula xml:id="formula_15">Knowledge Graph Propagation Model Rel. (a) None (b) Semantic (c) Dependency (d) Word (e) Slot (f) All M R - R S w 0 0 R S s R D w 0 0 R D s R SD w 0 0 0 0 0 0 R SD s R SD w 0 0 R SD</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Discussion and Analysis</head><p>With promising results obtained by the proposed models, we analyze the detailed difference be- tween different relation models in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Effectiveness of Semantic and Dependency Relation Models</head><p>To evaluate the effectiveness of semantic and de- pendency relations, we consider each of them in- dividually in M R of (3) (columns (b) and (c) in <ref type="table">Ta- ble 3</ref>). Comparing to the original model (column (a)), both modeling semantic relations and mod- eling dependency relations significantly improve the performance for ASR and manual results. It is shown that semantic relations help the SLU model infer the implicit meaning, and then the predic- tion becomes more accurate. Also, dependency re- lations successfully differentiate the generic con- cepts from the domain-specific concepts, so that the SLU model is able to predict more coherent set of semantic slots <ref type="bibr" target="#b12">(Chen et al., 2015)</ref>. Integrat- ing two types of relations (column (f)) further im- proves the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">Comparing Word/ Slot Relation Models</head><p>To analyze the performance results from inter- word and inter-slot relations, the columns (d) and (e) show the results considering only word rela- tions and only slot relations respectively. It can be seen that the inter-slot relation model signif- icantly improves the performance for both ASR and manual results. However, the inter-word re- lation model only performs slightly better results for ASR output (from 37.6% to 39.2%), and there is no difference after applying the inter-word rela- tion model on manual transcripts. The reason may be that inter-slot relations carry high-level seman- tics that align well with the structure of SDSs, but inter-word relations do not. Nevertheless, combin- ing two relations (column (f)) outperforms both re- sults for ASR and manual transcripts, showing that different types of relations can compensate each other and then benefit the SLU performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper presents an MF approach to self-train the SLU model for semantic decoding in an unsu- pervised way. The purpose of the proposed model is not only to predict the probability of each se- mantic slot but also to distinguish between generic semantic concepts and domain-specific concepts that are related to an SDS. The experiments show that the MF-based model obtains promising re- sults, outperforming strong discriminative base- lines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a): The proposed framework. (b): Our matrix factorization method completes a partiallymissing matrix for implicit semantic parsing. Dark circles are observed facts, shaded circles are inferred facts. The slot induction maps (yellow arrow) observed surface patterns to semantic slot candidates. The word relation model (blue arrow) constructs correlations between surface patterns. The slot relation model (pink arrow) learns the slot-level correlations based on propagating the automatically derived semantic knowledge graphs. Reasoning with matrix factorization (gray arrow) incorporates these models jointly, and produces a coherent, domain-specific SLU model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of probabilistic framesemantic parsing on ASR output. FT: frame target. FE: frame element. LU: lexical unit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A simplified example of the automatically derived knowledge graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The dependency parsing result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The mappings from induced slots (within blocks) to reference slots (right sides of arrows).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 : The example contexts extracted for training dependency-based word/slot embeddings.</head><label>1</label><figDesc></figDesc><table>Typed Dependency Relation 
Target Word 
Contexts 

Word 
restaurant, AMOD, cheap 
restaurant 
cheap/AMOD 
cheap 
restaurant/AMOD −1 

Slot locale by use, AMOD, expensiveness 
locale by use 
expensiveness/AMOD 
expansiveness locale by use/AMOD −1 

</table></figure>

			<note place="foot" n="1"> A slot is defined as a basic semantic unit in SLU, such as &quot;price&quot; and &quot;target&quot; in the example.</note>

			<note place="foot" n="2"> http://www.ark.cs.cmu.edu/SEMAFOR/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank anonymous reviewers for their useful comments and Prof. Manfred Stede for his men-toring. We are also grateful to MetLife's support. Any opinions, findings, and conclusions expressed in this publication are those of the authors and do not necessarily reflect the views of funding agen-cies.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Berkeley FrameNet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The RavenClaw dialog management framework: Architecture and systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="332" to="361" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garciaduran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unachievable region in precision-recall space and its effect on empirical evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kendrick</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santos</forename><surname>Vitor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C David</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning: proceedings of the International Conference. International Conference on Machine Learning</title>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page">349</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Leveraging web query logs to learn user intent via bayesian discrete latent variable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Twolayer mutually reinforced random walk for improved multi-party meeting summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 4th IEEE Workshop on Spoken Language Tachnology</title>
		<meeting>The 4th IEEE Workshop on Spoken Language Tachnology</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="461" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamically supporting unexplored domains in conversational interactions by enriching semantics with neural word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT)</title>
		<meeting>2014 IEEE Spoken Language Technology Workshop (SLT)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="590" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical investigation of sparse log-linear models for improved dialogue act classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8317" to="8321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised induction and filling of semantic slots for spoken dialogue systems using frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2013 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</title>
		<meeting>2013 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="120" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deriving local relational surface forms from dependency-based entity embeddings for unsupervised spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokan</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT)</title>
		<meeting>2014 IEEE Spoken Language Technology Workshop (SLT)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="242" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Leveraging frame semantics and distributional semantics for unsupervised semantic slot induction in spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2014 IEEE Spoken Language Technology Workshop (SLT)</title>
		<meeting>2014 IEEE Spoken Language Technology Workshop (SLT)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="584" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Jointly modeling inter-slot relations by random walk on knowledge graphs for unsupervised spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">I</forename><surname>Rudnicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies. ACL</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies. ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A generalization of principal components analysis to the exponential family</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjoy</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="617" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>The Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="948" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Frame-semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Annotating spoken dialogs: from speech segments to dialog acts and frame semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Dinarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Quarteroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Semantic Representation of Spoken Language</title>
		<meeting>the 2nd Workshop on Semantic Representation of Spoken Language</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="34" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Gemini: A natural language system for spoken-language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dowding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">Mark</forename><surname>Gawron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Cherny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="54" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extending domain coverage of language understanding systems via intent transfer between domains using knowledge graphs and search query click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>El-Kahky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mymedialite: A free recommender system library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM conference on Recommender systems</title>
		<meeting>the fifth ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="305" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The AT&amp;T spoken language understanding system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gökhan</forename><surname>Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mazin</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="213" to="222" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using a knowledge graph and query click logs for unsupervised learning of relation detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8327" to="8331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploiting the semantic web for unsupervised spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Leveraging knowledge graphs for web-scale unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Larry P Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1594" to="1598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discriminative spoken language understanding using word confusion networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pirros</forename><surname>Tsiakoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Statistical methods for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop at ICLR</title>
		<meeting>Workshop at ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems</title>
		<meeting>Advances in Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A speech understanding system based on statistical representation of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelyne</forename><surname>Tzoukermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zakhar</forename><surname>Gorelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Hui</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilpon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</title>
		<meeting>1992 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">BPR: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Steffen Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin M</forename><surname>Marlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="74" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TINA: A natural language system for spoken language applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Seneff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational linguistics</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="61" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Generalized latent variable modeling: Multilevel, longitudinal, and structural equation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Skrondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia Rabe-Hesketh</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Crc Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL conference</title>
		<meeting>the ACL conference</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Towards unsupervised spoken language understanding: Exploiting query click logs for slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dilek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Hillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Celikyilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1293" to="1296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploiting the semantic web for unsupervised natural language semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye-Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry P</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Latent semantic modeling for slot filling in conversational understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkanitur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8307" to="8311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Crowdsourcing the acquisition of natural language corpora: Methods and observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bohus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ece</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="73" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Leveraging semantic web search and browse sessions for multi-turn spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4082" to="4086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">POMDP-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Discovering latent structure in task-oriented dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
