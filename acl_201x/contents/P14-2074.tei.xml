<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing Automatic Evaluation Measures for Image Description</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
							<email>d.elliott@ed.ac.uk, keller@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language</orgName>
								<orgName type="department" key="dep2">Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<settlement>Cognition</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Language</orgName>
								<orgName type="department" key="dep2">Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<settlement>Cognition</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing Automatic Evaluation Measures for Image Description</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="452" to="457"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Image description is a new natural language generation task, where the aim is to generate a human-like description of an image. The evaluation of computer-generated text is a notoriously difficult problem, however , the quality of image descriptions has typically been measured using unigram BLEU and human judgements. The focus of this paper is to determine the correlation of automatic measures with human judgements for this task. We estimate the correlation of unigram and Smoothed BLEU, TER, ROUGE-SU4, and Meteor against human judgements on two data sets. The main finding is that unigram BLEU has a weak correlation, and Meteor has the strongest correlation with human judgements.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in computer vision and natural language processing have led to an upsurge of re- search on tasks involving both vision and language. State of the art visual detectors have made it possi- ble to hypothesise what is in an image ( <ref type="bibr" target="#b5">Guillaumin et al., 2009;</ref><ref type="bibr" target="#b4">Felzenszwalb et al., 2010)</ref>, paving the way for automatic image description systems. The aim of such systems is to extract and reason about visual aspects of images to generate a human- like description. An example of the type of image and gold-standard descriptions available can be seen in <ref type="figure">Figure 1</ref>. Recent approaches to this task have been based on slot-filling <ref type="bibr" target="#b16">(Yang et al., 2011;</ref><ref type="bibr" target="#b2">Elliott and Keller, 2013)</ref>, combining web-scale n- grams ( ), syntactic tree substitution ( <ref type="bibr" target="#b11">Mitchell et al., 2012</ref>), and description-by-retrieval <ref type="bibr" target="#b3">(Farhadi et al., 2010;</ref><ref type="bibr" target="#b13">Ordonez et al., 2011;</ref><ref type="bibr" target="#b6">Hodosh et al., 2013)</ref>. Image description has been compared to translating an image into text ( ) or summarising an image</p><p>1. An older woman with a small dog in the snow.</p><p>2. A woman and a cat are outside in the snow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A woman in a brown vest is walking on the</head><p>snow with an animal.</p><p>4. A woman with a red scarf covering her head walks with her cat on snow-covered ground.</p><p>5. Heavy set woman in snow with a cat.</p><p>Figure 1: An image from the Flickr8K data set and five human-written descriptions. These descrip- tions vary in the adjectives or prepositional phrases that describe the woman (1, 3, 4, 5), incorrect or un- certain identification of the cat (1, 3), and include a sentence without a verb (5).</p><p>( <ref type="bibr" target="#b16">Yang et al., 2011</ref>), resulting in the adoption of the evaluation measures from those communities. In this paper we estimate the correlation of hu- man judgements with five automatic evaluation measures on two image description data sets. Our work extends previous studies of evaluation mea- sures for image description <ref type="bibr" target="#b6">(Hodosh et al., 2013)</ref>, which focused on unigram-based measures and re- ported agreement scores such as Cohen's κ rather than correlations. The main finding of our analysis is that TER and unigram BLEU are weakly corre-lated against human judgements, ROUGE-SU4 and Smoothed BLEU are moderately correlated, and the strongest correlation is found with Meteor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>We estimate Spearman's ρ for five different auto- matic evaluation measures against human judge- ments for the automatic image description task. Spearman's ρ is a non-parametric correlation co- efficient that restricts the ability of outlier data points to skew the co-efficient value. The automatic measures are calculated on the sentence level and correlated against human judgements of semantic correctness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>We perform the correlation analysis on the Flickr8K data set of <ref type="bibr" target="#b6">Hodosh et al. (2013)</ref>, and the data set of <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref>.</p><p>The test data of the Flickr8K data set contains 1,000 images paired with five reference descrip- tions. The images were retrieved from Flickr, the reference descriptions were collected from Me- chanical Turk, and the human judgements were collected from expert annotators as follows: each image in the test data was paired with the highest scoring sentence(s) retrieved from all possible test sentences by the TRI5SEM model in <ref type="bibr" target="#b6">Hodosh et al. (2013)</ref>. Each image-description pairing in the test data was judged for semantic correctness by three expert human judges on a scale of 1-4. We calcu- late automatic measures for each image-retrieved sentence pair against the five reference descriptions for the original image.</p><p>The test data of <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref> con- tains 101 images paired with three reference de- scriptions. The images were taken from the PAS- CAL VOC Action Recognition Task, the reference descriptions were collected from Mechanical Turk, and the judgements were also collected from Me- chanical Turk. <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref> gener- ated two-sentence descriptions for each of the test images using four variants of a slot-filling model, and collected five human judgements of the se- mantic correctness and grammatical correctness of the description on a scale of 1-5 for each image- description pair, resulting in a total of 2,042 human judgement-description pairings. In this analysis, we use only the first sentence of the description, which describes the event depicted in the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Automatic Evaluation Measures</head><p>BLEU measures the effective overlap between a reference sentence X and a candidate sentence Y . It is defined as the geometric mean of the effective n-gram precision scores, multiplied by the brevity penalty factor BP to penalise short translations. p n measures the effective overlap by calculating the proportion of the maximum number of n-grams co-occurring between a candidate and a reference and the total number of n-grams in the candidate text. More formally,  <ref type="formula">(2012)</ref>; to the best of our knowledge, the only image de- scription work to use higher-order n-grams with BLEU is <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref>. In this paper we use the smoothed BLEU implementation of Clark et al. (2011) to perform a sentence-level analysis, set- ting n = 1 and no brevity penalty to get the unigram BLEU measure, or n = 4 with the brevity penalty to get the Smoothed BLEU measure. We note that a higher BLEU score is better. ROUGE measures the longest common subse- quence of tokens between a candidate Y and refer- ence X. There is also a variant that measures the co- occurrence of pairs of tokens in both the candidate and reference (a skip-bigram): ROUGE-SU*. The skip-bigram calculation is parameterised with d skip , the maximum number of tokens between the words in the skip-bigram. Setting d skip to 0 is equivalent to bigram overlap and setting d skip to ∞ means tokens can be any distance apart. If α = |SKIP2(X,Y )| is the number of matching skip-bigrams between the reference and the candidate, then skip-bigram ROUGE is formally defined as:</p><formula xml:id="formula_0">BLEU = BP · exp N ∑ n=1 w n log p n p n = ∑ c∈cand ∑ ngram∈c count clip (ngram) ∑ c∈cand ∑ ngram∈c count(ngram) BP = 1 if c &gt; r e (1−r/c) if c ≤ r</formula><formula xml:id="formula_1">R SKIP2 = α / α 2</formula><p>ROUGE has been used by only <ref type="bibr" target="#b16">Yang et al. (2011)</ref> to measure the quality of generated descriptions, using a variant they describe as ROUGE-1. We set d skip = 4 and award partial credit for unigram only matches, otherwise known as ROUGE-SU4. We use ROUGE v.1.5.5 for the analysis, and configure the evaluation script to return the result for the average score for matching between the candidate and the references. A higher ROUGE score is better. TER measures the number of modifications a hu- man would need to make to transform a candidate Y into a reference X. The modifications available are insertion, deletion, substitute a single word, and shift a word an arbitrary distance. TER is expressed as the percentage of the sentence that needs to be changed, and can be greater than 100 if the candi- date is longer than the reference. More formally, TER = |edits| |reference tokens| <ref type="bibr">TER</ref> has not yet been used to evaluate image de- scription models. We use v.0.8.0 of the TER evalu- ation tool, and a lower TER is better.</p><p>Meteor is the harmonic mean of unigram preci- sion and recall that allows for exact, synonym, and paraphrase matchings between candidates and ref- erences. It is calculated by generating an alignment between the tokens in the candidate and reference sentences, with the aim of a 1:1 alignment between tokens and minimising the number of chunks ch of contiguous and identically ordered tokens in the sentence pair. The alignment is based on exact to- ken matching, followed by Wordnet synonyms, and then stemmed tokens. We can calculate precision, recall, and F-measure, where m is the number of aligned unigrams between candidate and reference. Meteor is defined as:  the performance of different models on the image description task; a higher Meteor score is better.</p><formula xml:id="formula_2">M = (1 − Pen) · F mean Pen = γ ch m θ F mean = PR αP + (1 − α)R P = |m| |unigrams in candidate|</formula><note type="other">reported to evaluate Flickr 8K co-efficient n = 17, 466 E&amp;K (2013) co-efficient n = 2,</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Protocol</head><p>We performed the correlation analysis as follows.</p><p>The sentence-level evaluation measures were cal- culated for each image-description-reference tu- ple. We collected the BLEU, TER, and Meteor scores using MultEval <ref type="bibr" target="#b0">(Clark et al., 2011)</ref>, and the ROUGE-SU4 scores using the RELEASE-1.5.5.pl script. The evaluation measure scores were then compared with the human judgements using Spear- man's correlation estimated at the sentence-level. <ref type="table">Table 1</ref> shows the correlation co-efficients between automatic measures and human judgements and On the Flickr8k data set, all evaluation measures can be classified as either weakly correlated or mod- erately correlated with human judgements and all results are significant. TER is only weakly cor- related with human judgements but could prove useful in comparing the types of differences be- tween models. An analysis of the distribution of TER scores in <ref type="figure" target="#fig_2">Figure 2</ref>(a) shows that differences in candidate and reference length are prevalent in the image description task. Unigram BLEU is also only weakly correlated against human judgements, even though it has been reported extensively for this task. METEOR ρ= 0.524    Qualitative Analysis <ref type="figure">Figure 3</ref> shows two images from the test collec- tion of the Flickr8K data set with a low Meteor score and a maximum human judgement of seman- tic correctness. The main difference between the candidates and references are in deciding what to describe (content selection), and how to describe it (realisation). We can hypothesise that in both trans- lation and summarisation, the source text acts as a lexical and semantic framework within which the translation or summarisation process takes place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In <ref type="figure">Figure 3(a)</ref>, the authors of the descriptions made different decisions on what to describe. A decision has been made to describe the role of the officials in the candidate text, and not in the reference text. The underlying cause of this is an active area of research in the human vision literature and can be attributed to bottom-up effects, such as saliency ( <ref type="bibr" target="#b7">Itti et al., 1998</ref>), top-down contextual effects ( <ref type="bibr" target="#b15">Torralba et al., 2006</ref>), or rapidly-obtained scene properties <ref type="bibr" target="#b12">(Oliva and Torralba, 2001</ref>). In (b), we can see the problem of deciding how to describe the selected content. The reference uses a more specific noun to describe the person on the bicycle than the candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>There are several differences between our analysis and that of <ref type="bibr" target="#b6">Hodosh et al. (2013)</ref>. First, we report Spearman's ρ correlation coefficient of automatic measures against human judgements, whereas they report agreement between judgements and auto- matic measures in terms of Cohen's κ. In contrast to the results presented here, <ref type="bibr" target="#b14">Reiter and Belz (2009)</ref> found no significant correlations of automatic evaluation measures against human judgements of the accuracy of machine-generated weather forecasts. They did, however, find signif- icant correlations of automatic measures against fluency judgements. There are no fluency judge- ments available for Flickr8K, but <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref> report grammaticality judgements for their data, which are comparable to fluency ratings. We failed to find significant correlations between gram- matlicality judgements and any of the automatic measures on the <ref type="bibr" target="#b2">Elliott and Keller (2013)</ref> data. This discrepancy could be explained in terms of the dif- ferences between the weather forecast generation and image description tasks, or because the image description data sets contain thousands of texts and a few human judgements per text, whereas the data sets of <ref type="bibr" target="#b14">Reiter and Belz (2009)</ref> included hundreds of texts with 30 human judges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we performed a sentence-level corre- lation analysis of automatic evaluation measures against expert human judgements for the automatic image description task. We found that sentence- level unigram BLEU is only weakly correlated with human judgements, even though it has extensively reported in the literature for this task. Meteor was found to have the highest correlation with human judgements, but it requires Wordnet and paraphrase resources that are not available for all languages. Our findings held when judgements were made on human-written or computer-generated descriptions.</p><p>The variability in what and how people describe images will cause problems for all of the measures compared in this paper. Nevertheless, we propose that unigram BLEU should no longer be used as an objective function for automatic image descrip- tion because it has a weak correlation with human accuracy judgements. We recommend adopting either Meteor, Smoothed BLEU, or ROUGE-SU4 be- cause they show stronger correlations with human judgements. We believe these suggestions are also applicable to the ranking tasks proposed in <ref type="bibr" target="#b6">Hodosh et al. (2013)</ref>, where automatic evaluation scores could act as features to a ranking function.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Unigram BLEU without a brevity penalty has been reported by Kulkarni et al. (2011), Li et al. (2011), Ordonez et al. (2011), and Kuznetsova et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>R</head><label></label><figDesc>= |m| |unigrams in reference| We calculated the Meteor scores using release 1.4.0 with the package-provided free parameter settings of 0.85, 0.2, 0.6, and 0.75 for the matching compo- nents. Meteor has not yet been</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figures 2 (</head><label>2</label><figDesc>a) and (b) show the distribution of scores for each measure against human judgements. To classify the strength of the correlations, we fol- lowed the guidance of Dancey and Reidy (2011), who posit that a co-efficient of 0.0-0.1 is uncor- related, 0.11-0.4 is weak, 0.41-0.7 is moderate, 0.71-0.90 is strong, and 0.91-1.0 is perfect.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Sentence-level automated measure score Human Judgement (a) Flick8K data set, n=17,466.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Distribution of automatic evaluation measures against human judgements. ρ is the correlation between human judgements and the automatic measure. The intensity of each point indicates the number of occurrences that fall into that range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 2 (</head><label>2</label><figDesc>Figure 2(a) shows an almost uniform distribution of unigram BLEU scores, regardless of the human judgement. Smoothed BLEU and ROUGE-SU4 are moderately correlated with human judgements, and the correlation is stronger than with unigram BLEU. Finally, Meteor is most strongly correlated measure against human judgements. A similar pattern is observed in the Elliott and Keller (2013) data set, though the correlations are lower across all measures. This could be caused by the smaller sample size or because the descriptions were generated by a computer, and not retrieved from a collection of human-written descriptions containing the goldstandard text, as in the Flickr8K data set.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Alexandra Birch and R. Calen Walshe, and the anonymous reviewers provided valuable feedback on this paper. The research is funded by ERC Starting Grant SYNPROC <ref type="bibr">No. 203427.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Better hypothesis testing for statistical machine translation: Controlling for optimizer instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Dancey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Reidy</surname></persName>
		</author>
		<title level="m">Statistics Without Maths for Psychology</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page">175</biblScope>
		</imprint>
	</monogr>
	<note>5th edition</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image Description using Visual Dependency Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, U.S.A</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1292" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Every picture tells a story: generating sentences from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Hejrati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Amin</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Rashtchian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th European Conference on Computer Vision</title>
		<meeting>the 11th European Conference on Computer Vision<address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="15" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Object Detection with Discriminatively Trained Part-Based Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tagprop: Discriminative metric learning in nearest neighbor models for image auto-annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="309" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Framing Image Description as a Ranking Task : Data , Models and Evaluation Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="853" to="899" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernst</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Baby talk: Understanding and generating simple image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Visruth</forename><surname>Premraj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagnik</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 24th IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Colorado Springs, Colorado, U.S.A</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Collective Generation of Natural Image Descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polina</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, South Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Composing simple image descriptions using web-scale n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting><address><addrLine>Portland, Oregon, U.S.A</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="220" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Midge : Generating Image Descriptions From Computer Vision Detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kota</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyssa</forename><surname>Mensch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="747" to="756" />
		</imprint>
	</monogr>
	<note>Avignon</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Im2Text: Describing Images Using 1 Million Captioned Photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An investigation into the validity of some metrics for automatically evaluating natural language generation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="529" to="558" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><forename type="middle">S</forename><surname>Castelhano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychologial Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="766" to="786" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Corpus-Guided Sentence Generation of Natural Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yezhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching</forename><forename type="middle">Lik</forename><surname>Teo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiannis</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="444" to="454" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
