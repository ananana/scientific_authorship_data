<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EviNets: Neural Networks for Combining Evidence Signals for Factoid Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Savenkov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
						</author>
						<title level="a" type="main">EviNets: Neural Networks for Combining Evidence Signals for Factoid Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="299" to="304"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2047</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A critical task for question answering is the final answer selection stage, which has to combine multiple signals available about each answer candidate. This paper proposes EviNets: a novel neural network architecture for factoid question answering. EviNets scores candidate answer entities by combining the available supporting evidence, e.g., structured knowledge bases and unstructured text documents. EviNets represents each piece of evidence with a dense embeddings vector, scores their relevance to the question, and aggregates the support for each candidate to predict their final scores. Each of the components is generic and allows plugging in a variety of models for semantic similarity scoring and information aggregation. We demonstrate the effectiveness of EviNets in experiments on the existing TREC QA and WikiMovies benchmarks, and on the new Yahoo! Answers dataset introduced in this paper. EviNets can be extended to other information types and could facilitate future work on combining evidence signals for joint reasoning in question answering.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most of the recent works in Question Answering (QA) have focused on the problem of semantic matching between a question and candidate an- swer sentences <ref type="bibr" target="#b13">Rao et al., 2016;</ref><ref type="bibr" target="#b21">Yang et al., 2016)</ref>. The datasets used in these works, such as Answer Sentence Selection Dataset ( <ref type="bibr" target="#b18">Wang et al., 2007</ref>) and WikiQA ( <ref type="bibr" target="#b22">Yang et al., 2015)</ref>, typically contain a relatively small set of sentences, and the task is to select those that state the answer to the question. However, for many questions, a single sentence does not pro- vide sufficient information, and it may not be reli- able in isolation. At the same time, the redundancy of information in large corpora, such as the Web, has been shown useful to improve information re- trieval approaches to QA <ref type="bibr" target="#b3">(Clarke et al., 2001</ref>).</p><p>This work focuses on factoid questions, which can be answered with an entity, i.e., an object in a Knowledge Base (KB) such as Freebase. Knowl- edge Base Question Answering (KBQA) tech- niques, such as <ref type="bibr" target="#b1">Berant et al. (2013)</ref>; ; <ref type="bibr" target="#b0">Bast and Haussmann (2015)</ref>, can be used to answer some of the user questions directly from a KB. However, KBs are inherently incom- plete ( <ref type="bibr" target="#b4">Dong et al., 2014</ref>), and do not have suf- ficient information to answer many other ques- tions <ref type="bibr" target="#b5">(Fader et al., 2014</ref>).</p><p>Previous, feature-engineering, approaches for combining different data sources to improve an- swer retrieval were shown to be quite effective for QA ( <ref type="bibr" target="#b16">Sun et al., 2015;</ref><ref type="bibr" target="#b20">Xu et al., 2016;</ref><ref type="bibr" target="#b14">Savenkov and Agichtein, 2016)</ref>. Alternatively, Memory Net- works ( <ref type="bibr" target="#b15">Sukhbaatar et al., 2015)</ref> and their exten- sions ( <ref type="bibr">Miller et al., 2016</ref>) use embeddings to rep- resent relevant data as memories, and summarize them into a single vector, therefore losing infor- mation about answers provenances.</p><p>In this paper, we introduce EviNets, a novel neu- ral network architecture for factoid question an- swering, which provides a unified framework for aggregating evidence, supporting answer candi- dates. Given a question, EviNets retrieves a set of relevant pieces of information, e.g., sentences from a corpora or knowledge base triples, and ex- tracts mentioned entities as candidate answers. All the evidence signals are then embedded into the same vector space, scored and aggregated using multiple strategies for each answer candidate. Ex- periments on the TREC QA, WikiMovies and new Yahoo! Answers datasets demonstrate the effec- tiveness of EviNets, and its ability to handle both unstructured text and structured KB triples. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">EviNets Question Answering Model</head><p>The high level architecture of EviNets is illus- trated in <ref type="figure" target="#fig_0">Figure 1</ref>. For a given question, we ex- tract potentially relevant information, e.g., sen- tences from documents retrieved from text corpora using a search system. Next, we can use an en- tity linking system, such as TagMe <ref type="bibr" target="#b6">(Ferragina and Scaiella, 2010)</ref>, to identify entities mentioned in the extracted information, which become candi- date answers. EviNets can further incorporate ad- ditional supporting evidence, e.g., textual descrip- tion of candidate answer entities, and potentially useful KB triples, such as types ( <ref type="bibr" target="#b16">Sun et al., 2015)</ref>. Finally, question, answer candidates and support- ing evidence are given as input to the EviNets neu- ral network.</p><p>Let us denote a question by q, and {q t ∈ R |V | }, as a one-hot encoding of its tokens from a fixed vocabulary V . a i is a candidate answer from the set A, and we will assume, that each answer is rep- resented as a single entity. For each question, we have a fixed set E = E text ∪ E KB of evidence statements e (i) , i = 1..M , and their tokens e  </p><formula xml:id="formula_0">emb,t = W e (i)</formula><p>t . In our ex- periments, we use the same matrix for questions, evidence, and answers. KB entities are considered to be individual tokens, while predicates and type names are tokenized into constituent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Memory Matching Module</head><p>Evidence matching is responsible for estimating the relevance of each of the pieces of evidence to the question, i.e., w e = sof tmax(match(q, e)). The function match(q, e) can be implemented us- ing any of the recently proposed semantic simi- larity estimation architectures <ref type="bibr">1</ref> . One of the sim- plest approaches is to average question and each evidence token embeddings and score the similar- ity using the dot product: q emb = 1 Lq t q emb,t and e</p><formula xml:id="formula_1">(i) emb = 1 Le t e (i) emb,t and match(q, e (i) ) = q T emb · e (i) emb .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evidence Aggregation Module</head><p>After all the evidence signals have been scored, EviNets aggregates the support for each answer candidate. <ref type="table">Table 1</ref> summarizes the evidence sig- nals used. With these features, EviNets captures different aspects, i.e., how well individual sen- tences match the question, how frequently the can- didate is mentioned and how well a set of answer Evidence Feature Description Maximum evidence score mentioning the answer maxe{we|mention(a, e)}, e ∈ E, Etext or EKB Average evidence score mentioning the answer avge{we|mention(a, e)}, e ∈ E, Etext or EKB Sum of evidence scores mentioning the answer e {we|mention(a, e)}, e ∈ E, Etext or EKB Number of mentions e {1|mention(a, e)}, e ∈ Etext Weighted memory similarity to the question</p><formula xml:id="formula_2">( 1 M i wee (i)</formula><p>emb ) · q emb Weighted memory similarity to the answer ( <ref type="bibr" target="#b15">Sukhbaatar et al., 2015)</ref> (  evidences covers the information requested in the question.</p><formula xml:id="formula_3">1 M i wee (i) emb ) · a emb or R T ( 1 M i wee (i) emb + q emb ) · a emb ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Answer Scoring Module</head><p>Finally, EviNets uses the aggregated signals to pre- dict the answer scores, to rank them, and to return the best candidate as the final answer to the ques- tion. For this purpose, we use two fully-connected neural network layers with the ReLU activation function, with 32 and 8 hidden units respectively. The model was trained end-to-end by optimizing the cross entropy loss function using the Adam al- gorithm <ref type="bibr" target="#b9">(Kingma and Ba, 2014</ref>).  <ref type="table" target="#tab_1">(Table 2)</ref>. In all experiments, embed- dings were initialized with 300-dimensional vec- tors pre-trained with Glove ( <ref type="bibr" target="#b12">Pennington et al., 2014</ref>). Embeddings for multi-word entity names were obtained by averaging the word vectors of constituent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baselines</head><p>As baselines for different experiments depending on availability and specifics of a dataset we con- sidered the following methods:</p><p>• IR-based QA systems: AskMSR ( <ref type="bibr" target="#b2">Brill et al., 2002</ref>) and AskMSR+ ( , which select the best answer based on the frequency of entity mentions in retrieved text snippets.</p><p>• KBQA systems: SemPre ( <ref type="bibr" target="#b1">Berant et al., 2013)</ref> and Aqqu (Bast and Haussmann, 2015), which identify possible topic entities of the question, and select the answer from the can- didates in the neighborhood of these entities in a KB.</p><p>• Hybrid system QuASE (Sun et al., 2015) de- tects mentions of knowledge base entities in text passages, and uses the types and descrip- tion information from the KB to support an- swer selection. 0.517 0.500 0.508 EviNets (text) 0.580 0.560 0.569 EviNets (text+kb) 0.585 0.564 0.574 <ref type="table">Table 3</ref>: Precision, Recall and F1 of different methods on TREC QA dataset. Improvements over KV MemN2N are statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TREC QA dataset</head><p>The TREC QA dataset is composed of factoid questions, which can be answered with an en- tity, and were used in TREC 8-12 question an- swering tracks. Similarly to <ref type="bibr" target="#b16">Sun et al. (2015)</ref> we used web search (using the Microsoft Bing Web Search API) to retrieve top 50 documents, parsed them, extracted sentences and ranked them using tf-idf similarity to the question. To compare our results with the existing state-of-the-art, we used the same set of candidate entities as used by the QuASE model. We note that the extracted evi- dence differs between the models, and we were unable to match some of the candidates to our sen- tences. For text+kb experiment, just as QuASE, we used entity descriptions and types from Free- base knowledge base. <ref type="table">Table 3</ref> summarizes the results. EviNets achieves competitive results on the dataset, beating KV MemN2N by 13% in F1 score, and, unlike QuASE, does not rely on ex- pensive feature engineering and does not require any external resources to train.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">WikiMovies dataset</head><p>The WikiMovies dataset contains questions in the movies domain along with relevant Wikipedia passages and OMDb knowledge base. Since KVMemN2N already achieves an almost perfect result answering the questions using the KB, we focus on using the provided movie articles from Wikipedia. We followed the preprocessing pro- cedures described in <ref type="bibr">Miller et al. (2016)</ref>. Unlike TREC QA, where there are often multiple rel- evant supporting pieces of evidence, answers in the WikiMovies dataset usually have a single rel- evant sentence, which, however, mentions multi-   <ref type="table" target="#tab_5">Table 4</ref>. As we can see, with the same setup using individual sentences as evidence/memories EviNets significantly outper- forms the KV MemN2N model by 27%. It is im- portant to emphasize that the best-reported results of memory networks were obtained using entity- centered windows as memories, which requires special pre-processing and increases the number of memories. Additionally, these models used all of the KB entities as candidate answers, whereas EviNets relies only on the mentioned ones, which is a more scalable scenario for open-domain ques- tion answering, where it is not realistic to score millions of candidate answers in real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Yahoo! Answers dataset</head><p>Yahoo! recently released a dataset with search queries, which lead to clicks on factoid Ya- hoo! Answers questions, identified as questions with the best answer containing less than 3 words and a Wikipedia page as the specified source of information <ref type="bibr">3</ref> . This dataset contains 15K queries, which correspond to 4725 unique Yahoo! An- swers questions <ref type="table" target="#tab_1">(Table 2)</ref>. We took these ques- tions, and mapped answers to KB entities using the TagMe entity linking library <ref type="bibr" target="#b6">(Ferragina and Scaiella, 2010</ref>  which no answer entities with a good confidence 4 were identified, e.g., date answers, and randomly split the rest into training, development and test sets, with 2711 questions in total. Similarly to the TREC QA experiments, we extracted textual evidence using Bing Web Search API, by retriev- ing top 50 relevant documents, extracting the main content blocks, and splitting them into sentences. We applied the TagMe entity linker to the ex- tracted sentences, and considered all entities of mentions with the confidence score above the 0.2 threshold as candidate answers. For candidate en- tities we also retrieved relevant KB triples, such as entity types and descriptions, which extended the original pool of evidences. <ref type="table" target="#tab_7">Table 5</ref> summarizes the results of EviNets and some baseline methods on the created Yahoo! An- swers dataset. As we can see, knowledge base data is not enough to answer most of these questions, and a state-of-the-art KBQA system Aqqu gets only 0.116 precision. Adding textual data helps significantly, and Text2KB improves the precision to 0.17, which roughly matches the results of the AskMSR system, that ranks candidate entities by their popularity in the retrieved documents. Using text along with KB evidence gave higher perfor- mance metrics, boosting F1 from 0.271 to 0.291. EviNets significantly improves over the baseline approaches, beating AskMSR by 28% and KV MemN2N by almost 80% in F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>The success of deep neural network architectures in computer vision and NLP applications mo-tivated researchers to investigate applying these techniques for answer sentence selection, eval- uated on TREC QA ( <ref type="bibr" target="#b18">Wang et al., 2007)</ref>, Wik- iQA ( <ref type="bibr" target="#b22">Yang et al., 2015</ref>) and other datasets. A num- ber of models proposed in recent years explore dif- ferent ways of matching questions and answer sen- tences <ref type="bibr" target="#b21">Yang et al., 2016;</ref><ref type="bibr" target="#b13">Rao et al., 2016)</ref>. Our EviNets architecture allows to easily plug these sentence matching networks into the evidence matching module, and provides the aggregation layer, which helps to make a decision based on all available information.</p><p>Our evidence representation module is based on the ideas of memory networks <ref type="bibr" target="#b15">(Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b10">Kumar et al., 2015;</ref><ref type="bibr">Miller et al., 2016)</ref>, which also embed relevant information into a vec- tor space. However, they use soft attention mecha- nism to retrieve the memories, and do not use links from memories to the corresponding answer can- didates, which means that all relevant information is squeezed into a fixed dimensional vector. This limitation has been partially addressed in <ref type="bibr" target="#b19">Wang et al. (2016)</ref> and <ref type="bibr" target="#b8">Henaff et al. (2016)</ref>, which accu- mulate evidence for each answer separately using a recurrent neural network. In contrast, the evi- dence aggregation in our EviNets model uses mul- tiple different features, which is more flexible and can be extended with other signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We presented EviNets, a neural network for ques- tion answering, which encodes and aggregates multiple evidence signals to select answers. Ex- periments on TREC QA, WikiMovies and Ya- hoo! Answers datasets demonstrate that EviNets can be trained end-to-end to use both the available textual and knowledge base information. EviNets improves over the baselines, both in cases when there are many or just a few relevant pieces of evidence, by helping build an aggregate picture and distinguish between candidates, mentioned to- gether in a relevant memory, as is the case for WikiMovies dataset. The results of our experi- ments also demonstrate that EviNets can incor- porate signals from different data sources, e.g., adding KB triples helps to improve the perfor- mance over text-only setup. As a limitation of this work and a direction for future research, EviNets could be extended to support dynamic evidence retrieval, which would allow retrieving additional answer candidates and evidence as needed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The EviNets neural network architecture for combining evidence in factoid question answering.</figDesc><graphic url="image-1.png" coords="2,72.00,62.81,453.55,238.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>t</head><label></label><figDesc>. A boolean function mention : A×E → {0, 1} pro- vides the information about which answer candi- dates are mentioned in which evidences. Individ- ual tokens q t , a i , e (i) t are translated into the embed- ding space using a matrix W D× |V | , where D is the dimension of the embeddings, i.e., q emb,t = W q t , a emb,i = W a t and e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Description of TREC QA, WikiMovies 
and Yahoo! Answers factoid QA datasets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Accuracy of EviNets and baseline mod-
els on the WikiMovies dataset. The results marked 
* are obtained using a different setup, i.e., they 
use pre-processed entity window memories, and 
the whole set of entities as candidates. 

ple entities. To help the model distinguish the 
correct answer, and explore its abilities to en-
code structured and unstructured data, we gener-
ated additional entity type triples. For example, 
if an entity E appears as an object of the predi-
cate directed by in OMDb, we added the [E, 
type, director] triple. As baselines, we 
used MemN2N and KV MemN2N models, and the 
results are presented in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Precision, Recall and F1 of different 
methods on Yahoo! Answers factoid QA dataset. 
The Oracle assumes candidate answers are ranked 
perfectly and its performance is limited by the ini-
tial retrieval step. 

</table></figure>

			<note place="foot" n="1"> https://goo.gl/6gWrgA</note>

			<note place="foot" n="3"> L27 dataset https://webscope.sandbox.yahoo.com</note>

			<note place="foot" n="4"> A minimum ρ score of 0.2 from TagMe was required.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">More accurate question answering on freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An analysis of the askmsr question-answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting redundancy in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas R</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual international ACM SIGIR conference</title>
		<meeting>the 24th annual international ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geremy</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilko</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD</title>
		<meeting>the 20th ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tagme: on-the-fly annotation of short text fragments (by wikipedia entities)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><surname>Scaiella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM ICKM</title>
		<meeting>the 19th ACM ICKM</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pairwise word interaction modeling with deep neural networks for semantic similarity measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03969</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>CoRR abs/1412.6980</idno>
		<ptr target="http://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>English</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>abs/1506.07285</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Karimi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03126</idno>
		<title level="m">Antoine Bordes, and Jason Weston. 2016. Key-value memory networks for directly reading documents</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Noisecontrastive estimation for answer selection with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">When a knowledge base is not enough: Question answering over knowledge bases with external text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Savenkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th ACM SIGIR conference</title>
		<meeting>the 39th ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Open domain question answering via semantic enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Web-based question answering: Revisiting askmsr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2015-20</idno>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Microsoft Research</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasisynchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Reading comprehension using entity-based memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomohide</forename><surname>Shibata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kawahara</forename><surname>Daisuke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurohashi</forename><surname>Sadao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03551</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Question answering on freebase via relation extraction and textual evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.00957</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">anmm: Ranking short answer texts with attention-based neural matching model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic parsing via staged query graph generation: Question answering with knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the ACL</title>
		<meeting>the 53rd Annual Meeting of the ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
