<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">What Action Causes This? Towards Naive Physical Action-Effect Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University ‡ Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>Washington</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University ‡ Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>Washington</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University ‡ Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>Washington</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University ‡ Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>Washington</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">What Action Causes This? Towards Naive Physical Action-Effect Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="934" to="945"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>934</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Despite recent advances in knowledge representation , automated reasoning, and machine learning, artificial agents still lack the ability to understand basic action-effect relations regarding the physical world, for example, the action of cutting a cucumber most likely leads to the state where the cucumber is broken apart into smaller pieces. If artificial agents (e.g., robots) ever become our partners in joint tasks, it is critical to empower them with such action-effect understanding so that they can reason about the state of the world and plan for actions. Towards this goal, this paper introduces a new task on naive physical action-effect prediction, which addresses the relations between concrete actions (expressed in the form of verb-noun pairs) and their effects on the state of the physical world as depicted by images. We collected a dataset for this task and developed an approach that harnesses web image data through distant supervision to facilitate learning for action-effect prediction. Our empirical results have shown that web data can be used to complement a small number of seed examples (e.g., three examples for each action) for model learning. This opens up possibilities for agents to learn physical action-effect relations for tasks at hand through communication with humans with a few examples.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Causation in the physical world has long been a central discussion to philosophers who study ca- sual reasoning and explanation <ref type="bibr" target="#b10">(Ducasse, 1926;</ref><ref type="bibr" target="#b18">Gopnik et al., 2007)</ref>, to mathematicians or com- puter scientists who apply computational ap- proaches to model cause-effect prediction ( <ref type="bibr" target="#b28">Pearl et al., 2009)</ref>, and to domain experts (e.g., medical doctors) who attempt to understand the underly- ing cause-effect relations (e.g., disease and symp- toms) for their particular inquires. Apart from this wide range of topics, this paper investigates a spe- cific kind of causation, the very basic causal rela- tions between a concrete action (expressed in the form of a verb-noun pair such as "cut-cucumber") and the change of the physical state caused by this action. We call such relations naive physical action-effect relations.</p><p>For example, given an image as shown in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, we would have no problem predicting what actions can cause the state of the world depicted in the image, e.g., slicing an apple will likely lead to the state. On the other hand, given a statement "slice an apple", it would not be hard for us to imagine what state change may happen to the ap- ple. We can make such action-effect prediction because we have developed an understanding of this kind of basic action-effect relations at a very young age <ref type="bibr" target="#b1">(Baillargeon, 2004)</ref>. What happens to machines? Will artificial agents be able to make the same kind of predictions? The answer is not yet.</p><p>Despite tremendous progress in knowledge rep- resentation, automated reasoning, and machine learning, artificial agents still lack the understand- ing of naive causal relations regarding the physical world. This is one of the bottlenecks in machine intelligence. If artificial agents ever become capa- ble of working with humans as partners, they will need to have this kind of physical action-effect un- derstanding to help them reason, learn, and per- form actions.</p><p>To address this problem, this paper introduces a new task on naive physical action-effect pre- diction. This task supports both cause predic- tion: given an image which describes a state of the world, identify the most likely action (in the form of a verb-noun pair, from a set of candidates) that can result in that state; and effect prediction: given an action in the form of a verb-noun pair, identify images (from a set of candidates) that depicts the most likely effects on the state of the world caused by that action. Note that there could be different ways to formulate this problem, for example, both causes and effects are in the form of language or in the form of images/videos. Here we intention- ally frame the action as a language expression (i.e., a verb-noun pair) and the effect as depicted in an image in order to make a connection between lan- guage and perception. This connection is impor- tant for physical agents that not only can perceive and act, but also can communicate with humans in language.</p><p>As a first step, we collected a dataset of 140 verb-noun pairs. Each verb-noun pair is annotated with possible effects described in language and de- picted in images (where language descriptions and image descriptions are collected separately). We have developed an approach that applies distant supervision to harness web data for bootstrapping action-effect prediction models. Our empirical re- sults have shown that, using a simple bootstrap- ping strategy, our approach can combine the noisy web data with a small number of seed examples to improve action-effect prediction. In addition, for a new verb-noun pair, our approach can infer its ef- fect descriptions and predict action-effect relations only based on 3 image examples.</p><p>The contributions of this paper are three folds. First, it introduces a new task on physical action- effect prediction, a first step towards an under- standing of causal relations between physical ac- tions and the state of the physical world. Such ability is central to robots which not only perceive from the environment, but also act to the environ- ment through planning. To our knowledge, there is no prior work that attempts to connect actions (in language) and effects (in images) in this na- ture. Second, our approach harnesses the large amount of image data available on the web with minimum supervision. It has shown that physi- cal action-effect models can be learned through a combination of a few annotated examples and a large amount of un-annotated web data. This opens up the possibility for humans to teach robots new tasks through language communication with a small number of examples. Third, we have cre- ated a dataset for this task, which is available to the community 1 . Our bootstrapping approach can serve as a baseline for future work on this topic.</p><p>In the following sections, we first describe our data collection effort, then introduce the bootstrap- ping approach for action-effect prediction, and fi- nally present results from our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In the NLP community, there has been exten- sive work that models cause-effect relations from text ( <ref type="bibr" target="#b5">Cole et al., 2005;</ref><ref type="bibr" target="#b8">Do et al., 2011;</ref><ref type="bibr" target="#b52">Yang and Mao, 2014</ref>). Most of these previous studies ad- dress high-level causal relations between events, for example, "the collapse of the housing bubble" causes the effect of "stock prices to fall" ( <ref type="bibr" target="#b34">Sharp et al., 2016</ref>). They do not concern the kind of naive physical action-effect relations in this pa- per. There is also an increasing amount of effort on capturing commonsense knowledge, for exam- ple, through knowledge base population. Except for few <ref type="bibr" target="#b54">(Yatskar et al., 2016</ref>) that acquires knowl- edge from images, most of the previous effort ap- ply information extraction techniques to extract facts from a large amount of web data <ref type="bibr" target="#b9">(Dredze et al., 2010;</ref><ref type="bibr" target="#b30">Rajani and Mooney, 2016)</ref>. DBPe- dia ( <ref type="bibr" target="#b21">Lehmann et al., 2015</ref>), <ref type="bibr">Freebase (Bollacker et al., 2008)</ref>, and YAGO ( <ref type="bibr" target="#b39">Suchanek et al., 2007)</ref> knowledge bases contain millions of facts about the world such as people and places. However, they do not contain basic cause-effect knowledge related to concrete actions and their effects to the world. Recent work started looking into phys-ical causality of action verbs (  and other physical properties of verbs <ref type="bibr" target="#b14">(Forbes and Choi, 2017;</ref><ref type="bibr" target="#b55">Zellers and Choi, 2017;</ref><ref type="bibr" target="#b4">Chao et al., 2015</ref>). But they do not address action-effect pre- diction.</p><p>The idea of modeling object physical state change has also been studied in the computer vi- sion community <ref type="bibr" target="#b13">(Fire and Zhu, 2016)</ref>. Compu- tational models have been developed to infer ob- ject states from observations and to further pre- dict future state changes ( <ref type="bibr" target="#b56">Zhou and Berg, 2016;</ref><ref type="bibr" target="#b45">Wu et al., 2016</ref><ref type="bibr" target="#b46">Wu et al., , 2017</ref>). The action recognition task can be treated as detecting the transforma- tion on object states <ref type="bibr" target="#b11">(Fathi and Rehg, 2013;</ref><ref type="bibr" target="#b53">Yang et al., 2013;</ref><ref type="bibr" target="#b43">Wang et al., 2016)</ref>. However these previous works only focus on the visual presenta- tion of motion effects. Recent years have seen an increasing amount of work integrating language and vision, for example, visual question answer- ing ( <ref type="bibr" target="#b0">Antol et al., 2015;</ref><ref type="bibr" target="#b15">Fukui et al., 2016;</ref><ref type="bibr" target="#b23">Lu et al., 2016)</ref>, image description generation ( <ref type="bibr" target="#b47">Xu et al., 2015;</ref><ref type="bibr" target="#b42">Vinyals et al., 2015)</ref>, and grounding lan- guage to perception <ref type="bibr" target="#b33">Roy, 2005;</ref><ref type="bibr" target="#b40">Tellex et al., 2011;</ref><ref type="bibr" target="#b24">Misra et al., 2017)</ref>. While many approaches require a large amount of train- ing data, recent works have developed zero/few shot learning for language and vision <ref type="bibr" target="#b26">(Mukherjee and Hospedales, 2016;</ref><ref type="bibr" target="#b49">Xu et al., 2016</ref><ref type="bibr" target="#b48">Xu et al., , 2017a</ref><ref type="bibr" target="#b41">Tsai and Salakhutdinov, 2017)</ref>. Different from these previous works, this paper introduces a new task that connects language with vision for physi- cal action-effect prediction.</p><p>In the robotics community, an important task is to enable robots to follow human natural lan- guage instructions. Previous works <ref type="bibr" target="#b37">(She et al., 2014;</ref><ref type="bibr" target="#b25">Misra et al., 2015;</ref><ref type="bibr">Chai, 2016, 2017</ref>) explicitly model verb semantics as desired goal states and thus linking natural language com- mands with underlying planning systems for ac- tion planning and execution. However, these stud- ies were carried out either in a simulated world or in a carefully curated simple environment within the limitation of the robot's manipulation system. And they only focus on a very limited set of do- main specific actions which often only involve the change of locations. In this work, we study a set of open-domain physical actions and a variety of effects perceived from the environment (i.e., from images).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Action-Effect Data Collection</head><p>We collected a dataset to support the investigation on physical action-effect prediction. This dataset consists of actions expressed in the form of verb- noun pairs, effects of actions described in lan- guage, and effects of actions depicted in images. Note that, as we would like to have a wide range of possible effects, language data and image data are collected separately.</p><p>Actions (verb-noun pairs). We selected 40 nouns that represent everyday life objects, most of them are from the COCO dataset ( <ref type="bibr" target="#b22">Lin et al., 2014</ref>), with a combination of food, kitchen ware, furniture, in- door objects, and outdoor objects. We also iden- tified top 3000 most frequently used verbs from Google Syntactic N-gram dataset <ref type="bibr" target="#b17">(Goldberg and Orwant, 2013</ref>) (Verbargs set). And we extracted top frequent verb-noun pairs containing a verb from the top 3000 verbs and a noun in the 40 nouns which hold a dobj (i.e., direct object) dependency relation. This resulted in 6573 candidate verb- noun pairs. As changes to an object can occur at various dimensions (e.g., size, color, location, attachment, etc.), we manually selected a subset of verb-noun pairs based on the following criteria: (1) changes to the objects are visible (as opposed to other types such as temperature change, etc.); and (2) changes reflect one particular dimension as opposed to multiple dimensions (as entailed by high-level actions such as "cook a meal", which correspond to multiple dimensions of change and can be further decomposed into basic actions). As a result, we created a subset of 140 verb-noun pairs (containing 62 unique verbs and 39 unique nouns) for our investigation.</p><p>Effects Described in Language. The basic knowledge about physical action-effect is so fun- damental and shared among humans. It is of- ten presupposed in our communication and not explicitly stated. Thus, it is difficult to extract naive action-effect relations from the existing tex- tual data (e.g., web). This kind of knowledge is also not readily available in commonsense knowl- edge bases such as ConceptNet ( <ref type="bibr" target="#b38">Speer and Havasi, 2012)</ref>. To overcome this problem, we applied crowd-sourcing (Amazon Mechanical Turk) and collected a dataset of language descriptions de- scribing effects for each of the 140 verb-noun pairs. The workers were shown a verb-noun pair, and were asked to use their own words and imag-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action</head><p>Effect Text ignite paper The paper is on fire. soak shirt</p><p>The shirt is thoroughly wet. fry potato</p><p>The potatoes become crisp and golden. stain shirt</p><p>There is a visible mark on the shirt. <ref type="table">Table 1</ref>: Example action and effect text from our collected data.</p><p>inations to describe what changes might occur to the corresponding object as a result of the action. Each verb-noun pair was annotated by 10 differ- ent annotators, which has led to a total of 1400 effect descriptions. <ref type="table">Table 1</ref> shows some examples of collected effect descriptions. These effect lan- guage descriptions allow us to derive seed effect knowledge in a symbolic form.</p><p>Effects Depicted in Images. For each action, three students searched the web and collected a set of images depicting potential effects. Specif- ically, given a verb-noun pair, each of the three students was asked to collect at least 5 positive images and 5 negative images. Positive images are those deemed to capture the resulting world state of the action. And negative images are those deemed to capture some state of the related ob- ject (i.e., the nouns in the verb-noun pairs), but are not the resulting state of the corresponding action. Then, each student was also asked to provide pos- itive or negative labels for the images collected by the other two students. As a result each image has three positive/negative labels. We only keep the images whose labels are agreed by all three stu- dents. In total, the dataset contains 4163 images. On average, each action has 15 positive images, and 15 negative images. <ref type="figure" target="#fig_1">Figure 2</ref> shows several examples of positive images and negative images of the action peel-orange. The positive images show an orange in a peeled state, while the neg- ative images show oranges in different states (or- ange as a whole, orange slices, orange juice, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Action-Effect Prediction</head><p>Action-effect prediction is to connect actions (as causes) to the effects of actions. Specifically, given an image which depicts a state of the world, our task is to predict what concrete actions could cause the state of the world. This task is different from traditional action recognition as the underly- ing actions (e.g., human body posture/movement) are not captured by the images. In this regard, it is also different from image description generation. We frame the problem as a few-shot learning task, by only providing a few human-labelled im- ages for each action at the training stage. Given the very limited training data, we attempt to make use of web-search images. Web search has been adopted by previous computer vision studies to ac- quire training data <ref type="bibr" target="#b12">(Fergus et al., 2005;</ref><ref type="bibr" target="#b20">Kennedy et al., 2006;</ref><ref type="bibr" target="#b2">Berg et al., 2010;</ref><ref type="bibr" target="#b27">Otani et al., 2016</ref>). Compared with human annotations, web-search comes at a much lower cost, but with a trade-off of poor data quality. To address this issue, we ap- ply a bootstrapping approach that aims to handle data with noisy labels.</p><p>The first question is what search terms should be used for image search. There are two options. The first option is to directly use the action terms (i.e., verb-noun pairs) to search images and the downloaded web images are referred to as action web images. As desired images should be depict- ing effects of an action, terms describing effects become a natural choice. The second option is to use the key phrases extracted from language effect descriptions to search the web. The downloaded web images are referred to as effect web images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extracting Effect Phrases from Language Data</head><p>We first apply chunking (shallow parsing) using the SENNA software <ref type="bibr" target="#b6">(Collobert et al., 2011</ref>) to break an effect description into phrases such as noun phrases (NP), verb phrases (VP), preposi- tional phrases (PP), adjectives (ADJP), adverbs (ADVP), etc. After some examination, we found that most of the effect descriptions follow simple syntactic patterns. For a verb-noun pair, around 80% of its effect descriptions start with the same noun as the subject. In an effect description, the Example patterns Example Effect Phrases (bold) extracted from effect descriptions VP with a verb ∈ {be, become, turn, get} The ship is destroyed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VP + PRT</head><p>The wall is knocked off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VP + ADVP</head><p>The door swings forward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ADJP</head><p>The window would begin to get clean.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PP + NP</head><p>The eggs are divided into whites and yolks. <ref type="table">Table 2</ref>: Example patterns that are used to extract effect phrases (bold) from sample sentences.</p><p>change of state associated with the noun is mainly captured by some key phrases. For example, an adjective phrase usually describes a physical state; verbs like be, become, turn, get often indicate a description of change of the state. Based on these observations, we defined a set of patterns to iden- tify phrases that describe physical states of an ob- ject. In total 1997 effect phrases were extracted from the language data. <ref type="table">Table 2</ref> shows some ex- ample patterns and example effect phrases that are extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Downloading Web Images</head><p>The purpose of querying search engine is to re- trieve images of objects in certain effect states. To form image searching keywords, the effect phrases are concatenated with the corresponding noun phrases, for example, "apple + into thin pieces". The image search results are downloaded and used as supplementary training data for the action-effect prediction models. However, web images can be noisy. First of all, not all of the au- tomatically extracted effect phrases describe vis- ible state of objects. Even if a phrase represents visible object states, the retrieved results may not be relevant. <ref type="figure" target="#fig_2">Figure 3</ref> shows some example image search results using queries describing the object name "book", and describing the object state such as "book is on fire", "book is set aflame". These state phrases were used by human annotators to describe the effect of the action "burn a book". We can see that the images returned from the query "book is set aflame" are not depicting the physi- cal effect state of "burn a book". Therefore, it's important to identify images with relevant effect states to train the model. To do that, we applied a bootstrapping method to handle the noisy web images as described in Section 4.3. For an action (i.e., a verb-noun pair), it has multiple correspond- ing effect phrases, and all of their image search re- sults are treated as training images for this action.</p><p>Since both the human annotated image data (Section 3) and the web-search image data were obtained from Internet search engines, they may book book is on fire book is set aflame have duplicates. As part of the annotated images are used as test data to evaluate the models, it is important to remove duplicates. We designed a simple method to remove any images from the web-search image set that has a duplicate in the human annotated set. We first embed all images into feature vectors using pre-trained CNNs. For each web-search image, we calculate its cosine similarity score with each of the annotated images. And we simply remove the web images that have a score larger than 0.95.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Models</head><p>We formulate the action-effect prediction task as a multi-class classification problem. Given an im- age, the model will output a probability distribu- tion q over the candidate actions (i.e., verb-noun pairs) that can potentially cause the effect depicted in the image. Specifically for model training, we are given a set of human annotated seeding image data {x, t} and a set of web-search image data {x , t }. Here x and x are the images (depicting effect states), and t and t are their classification targets (i.e., ac- tions that cause the effects). Each target vector is the observed image label, t ∈ {0, 1} C , i t i = 1, and C is the number of classes (i.e., actions). The human annotated targets t can be trusted. But the targets of web-search images t are usually very noisy. Bootstrapping method has been shown to be an effective method to handle noisy labelled data ( <ref type="bibr" target="#b32">Rosenberg et al., 2005;</ref><ref type="bibr" target="#b44">Whitney and Sarkar, 2012;</ref><ref type="bibr" target="#b31">Reed et al., 2014</ref>). The objective of the cross-entropy loss is defined as follows:</p><formula xml:id="formula_0">L(t, q) = C i=1 t i log (q i ),<label>(1)</label></formula><p>where q are the predicted class probabilities, and C is the number of classes. To handle the noisy labels in the web-search data {x , t }, we adopt a bootstrapping objective following Reed's work ( <ref type="bibr" target="#b31">Reed et al., 2014</ref>):</p><formula xml:id="formula_1">L(t , q) = C i=1 [βt i + (1 − β)z i ] log (q i ),<label>(2)</label></formula><p>where β ∈ [0, 1] is a model parameter to be as- signed, z is the one-hot vector of the prediction q,</p><formula xml:id="formula_2">z i = 1, if i = argmax q k , k = 1 . . . C.</formula><p>The model architecture is shown in <ref type="figure" target="#fig_3">Figure 4</ref>. After each training batch, the current model will be used to make predictions q on images in the next batch. And the target probabilities is calcu- lated as a linear combination of the current predic- tions q and the observed noisy labels t . The idea behind this bootstrapping strategy is to ensure the consistency of the model's predictions. By first initializing the model on the seeding image data, the bootstrapping approach allows the model to trust more on the web images that are consistent with the seeding data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>We evaluate the models on the action-effect pre- diction task. Given an image that illustrates a state of the world, the goal is to predict what action could cause that state. Given an action in the form of a verb-noun pair, the goal is to identify images that depict the most likely effects on the state of the world caused by that action.</p><p>For each of the 140 verb-noun pairs, we use 10% of the human annotated images as the seed- ing image data for training, and use 30% for de- velopment and the rest 60% for test. The seeding image data set contains 408 images. On average, each verb-noun pair has less than 3 seeding images (including positive images and negative images). The development set contains 1252 images. The test set contains 2503 images. The model param- eters were selected based on the performance on the development set.</p><p>As a given image may not be relevant to any ef- fect, we add a background class to refer to images where effects are not caused by any action in the space of actions. So the total of classes for our evaluation model is 141. For each verb-noun pair and each of the effect phrases, around 40 images were downloaded from the Bing image search en- gine and used as candidate training examples. In total we have 6653 action web images and 59575 effect web images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods for Comparison</head><p>All the methods compared are based on one neu- ral network structure. We use ResNet ( <ref type="bibr" target="#b19">He et al., 2016)</ref> pre-trained on ImageNet ( <ref type="bibr" target="#b7">Deng et al., 2009)</ref> to extract image features. The extracted image fea- tures are fed to a fully connected layer with rec- tified linear units and then to a softmax layer to make predictions. More specifically, we compare the following configurations: (1) BS+Seed+Act+Eff. The bootstrapping ap- proach trained on the seeding images, the action web images, and the effect web images. During the training stage, the model was first trained on the seeding image data using vanilla cross-entropy objective (Equation 1). Then it was further trained on a combination of the seeding image data and web-search data using the bootstrapping objective (Equation 2). In the experiments we set β = 0.3. (2) BS+Seed+Act. The bootstrapping approach trained in the same fashion as (1). The only dif- ference is that this method does not use the effect web images. (3) Seed+Act+Eff. A baseline method trained on a combination of the seeding images, the web ac- tion images, and the web effect images, using the vanilla cross-entropy objective. (4) Seed+Act. A baseline method trained on a combination of the seeding images and the action web images, using the vanilla cross-entropy objec- tive. <ref type="table">Predictions  Top Effect Descriptions  Top Action  Predictions  Top Effect Descriptions   bake potato  peel potato  boil potato  fry potato   potato crispy  potato is crushed  eggs get beaten  potato browned   wrap book  tear book  fold paper  shave hair   book is ripped  paper become creased  book into smaller pieces  meat is being</ref>    <ref type="table">Table 3</ref>: Results for the action-effect prediction task (given an action, rank all the candidate im- ages).  <ref type="table">Table 4</ref>: Results for the action-effect prediction task (given an image, rank all the actions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Top Action</head><p>(5) Seed. A baseline method that was only trained on the seeding image data, using the vanilla cross- entropy objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Results</head><p>We apply the trained classification model to all of the test images. Based on the matrix of predic- tion scores, we can evaluate action-effect predic- tion from two angles: (1) given an action class, rank all the candidate images; (2) given an image, rank all the candidate action classes. <ref type="table">Table 3 and 4</ref> show the results for these two angels respectively. We report both mean average precision (MAP) and top prediction accuracy. Overall, BS+Seed+Act+Eff gives the best per- formance. By comparing the bootstrap approach with baseline approaches (i.e., BS+Seed+Act+Eff</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>vs.</head><p>Seed+Act+Eff, and BS+Seed+Act vs. Seed+Act), the bootstrapping approaches clearly outperforms their counterparts, demonstrating its ability in handling noisy web data. Comparing BS+Seed+Act+Eff with BS+Seed+Act, we can see that BS+Seed+Act+Eff performs better. This indicates the use of effect descriptions can bring more relevant images to train better models for action-effect prediction.</p><p>In <ref type="table">Table 4</ref>, the poor performance of Seed+Act+Eff and Seed+Act shows that it is risky to fully rely on the noisy web search results. These two methods had trouble in distinguishing the background class from the rest.</p><p>We further trained another multi-class classifier with web effect images, using their corresponding effect phrases as class labels. Given a test image, we apply this new classifier to predict the effect descriptions of this image. <ref type="figure" target="#fig_4">Figure 5</ref> shows some example images, their predicted actions based on our bootstrapping approach and their predicted ef- fect phrases based on the new classifier. These ex- amples also demonstrate another advantage of in- corporating seed effect knowledge from language data: it provides state descriptions that can be used to better explain the perceived state. Such explana- tion can be crucial in human-agent communication for action planning and reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Generalizing Effect Knowledge to New</head><p>Verb-Noun Pairs</p><p>In real applications, it is very likely that we do not have the effect knowledge (i.e., language effect de- scriptions) for every verb-noun pair. And annotat-  <ref type="figure">Figure 6</ref>: Architecture of the action-effect embed- ding model. ing effect knowledge using language (as shown in Section 3) can be very expensive. In this section, we describe how to potentially generalize seed ef- fect knowledge to new verb-noun pairs through an embedding model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Action-Effect Embedding Model</head><p>The structure of our model is shown in <ref type="figure">Figure 6</ref>. It is composed of two sub-networks: one for verb- noun pairs (i.e., action) and the other one for effect phrases (i.e, effect). The action or effect is fed into an LSTM encoder and then to two fully-connected layers. The output is an action embedding v c and effect embedding v e . The networks are trained by minimizing the following cosine embedding loss function:</p><formula xml:id="formula_3">L(v c , v e ) = 1 − s(v c , v e ), if (c, e) ∈ T max(0, s(v c , v e )), if (c, e) / ∈ T s(·, ·)</formula><p>is the cosine similarity between vectors. T is a collection of action-effect pairs. Suppose c is an input for action and e is an input for effect, this loss function will learn an action and effect seman- tic space that maximizes the similarities between c and e if they have an action-effect relation (i.e., (c, e) ∈ T ). During training, the negative action- effect pairs (i.e., (c, e) / ∈ T ) are randomly sam- pled from data. In the experiments, the negative sampling ratio is set to 25. That is, for each posi- tive action-effect pair, 25 negative pairs are created through random sampling.</p><p>At the inference step, given an unseen verb- noun pair, we embed it into the action and ef- fect semantic space. Its embedding vector will be used to calculate similarities with all the embed- ding vectors of the candidate effect phrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP Top 1 Top 5 BS+Seed+Act+Eff</head><p>0.529 0.643 0.928 BS+Seed+Act+pEff 0.507 0.642 0.893 BS+Seed+Act 0.435 0.643 0.964 Seed 0.369 0.678 0.786 <ref type="table">Table 5</ref>: Results for the action-effect prediction task (given an action, rank all the candidate im- ages).  <ref type="table">Table 6</ref>: Results for the action-effect prediction task (given an image, rank all the actions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>We divided the 140 verb-noun pairs into 70% training set (98 verb-noun pairs), 10% develop- ment set (14) and 20% test set (28). For the action- effect embedding model, we use pre-trained GloVe word embeddings ( <ref type="bibr" target="#b29">Pennington et al., 2014</ref>) as input to the LSTM. The embedding model was trained using the language effect data correspond- ing to the training verb-noun pairs, and then it was applied to predict effect phrases for the unseen verb-noun pairs in the test set. For each unseen verb-noun pair, we collected its top five predicted effect phrases. Each predicted effect phrase was then used as query keywords to download web ef- fect images. This set of web images are referred to as pEff and will be used in training the action- effect prediction model. For each of the 28 test (i.e., new) verb-noun pairs, we use the same ratio 10% (about 3 ex- amples) of the human annotated images as the seeding images, which were combined with down- loaded web images to train the prediction model. The remaining 30% and 60% are used as the de- velopment set, and the test set. We compare the following different configurations: (1) BS+Seed+Act+pEff. The bootstrapping ap- proach trained on the seeding images, the action web images, and the web images downloaded us- ing the predicted effect phrases. (2) BS+Seed+Act+Eff. The bootstrapping ap- proach trained on the seeding images, the action web images, and the effect web images (down- loaded using ground-truth effect phrases). (3) BS+Seed+Act. The bootstrapping approach trained on the seeding images and the action web   <ref type="table">Table 5 and 6</ref> show the results for the action-effect prediction task for unseen verb- noun pairs. From the results we can see that BS+Seed+Act+pEff achieves close performance compared with BS+Seed+Act+Eff, which uses hu- man annotated effect phrases. Although in most cases, BS+Seed+Act+pEff outperforms the base- line, which seems to point to the possibility that semantic embedding space can be employed to extend effect knowledge to new verb-noun pairs. However, the current results are not conclusive partly due to the small testing set. More in-depth evaluation is needed in the future. <ref type="table" target="#tab_3">Table 7</ref> shows top predicted effect phrases for several new verb-noun pairs. After analyzing the action-effect prediction results we notice that gen- eralizing the effect knowledge to a verb-noun pair that contains an unseen verb tends to be more dif- ficult than generalizing to a verb-noun pair that contains an unseen noun. Among the 28 test verb- noun pairs, 12 of them contain unseen verbs and known nouns, 7 of them contain unseen nouns and known verbs. For the task of ranking images given an action, the mean average precision is 0.447 for the unseen verb cases and 0.584 for the unseen noun cases. Although not conclusive, this might indicate that, verbs tend to capture more informa- tion about the effect states of the world than nouns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Conclusion</head><p>When robots operate in the physical world, they not only need to perceive the world, but also need to act to the world. They need to understand the current state, to map their goals to the world state, and to plan for actions that can lead to the goals. All of these point to the importance of the ability to understand causal relations between actions and the state of the world. To address this issue, this paper introduces a new task on action-effect pre- diction.</p><p>Particularly, we focus on modeling the connec- tion between an action (a verb-noun pair) and its effect as illustrated in an image and treat natural language effect descriptions as side knowledge to help acquiring web image data and bootstrap train- ing. Our current model is very simple and perfor- mance is yet to be improved. We plan to apply more advanced approaches in the future, for exam- ple, attention models that jointly capture actions, image states, and effect descriptions. We also plan to incorporate action-effect prediction to human- robot collaboration, for example, to bridge the gap of commonsense knowledge about the physical world between humans and robots. This paper presents an initial investigation on action-effect prediction. There are many chal- lenges and unknowns, from problem formulation to knowledge representation; from learning and inference algorithms to methods and metrics for evaluations. Nevertheless, we hope this work can motivate more research in this area, enabling phys- ical action-effect reasoning, towards agents which can perceive, act, and communicate with humans in the physical world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Images showing the effects of "slice an apple".</figDesc><graphic url="image-2.png" coords="2,181.93,139.54,92.88,72.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Positive images (top row) and negative images (bottom row) of the action peel-orange.</figDesc><graphic url="image-9.png" coords="4,382.87,131.22,66.85,66.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Examples of image search results.</figDesc><graphic url="image-11.png" coords="5,307.38,175.49,67.90,79.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Architecture for the action-effect prediction model with bootstrapping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Several example test images and their predicted actions and predicted effect descriptions. The actions in bold are ground-truth labels.</figDesc><graphic url="image-26.png" coords="7,91.39,187.61,63.65,50.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>small pieces LSTM LSTM</head><label></label><figDesc></figDesc><table>Action 
Effect 

slice  apple 
into  many  Cosine 
Embedding Loss 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Example predicted effect phrases for 
new verb-noun pairs. Unseen verbs and nouns are 
shown in bold. 

images. 

(4) Seed. A baseline only trained on the seeding 
images. 

</table></figure>

			<note place="foot" n="1"> This dataset is available at http://lair.cse.msu. edu/lair/projects/actioneffect.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Sci-ence Foundation (IIS-1617682) and the DARPA XAI program under a subcontract from UCLA (N66001-17-2-4029). The authors would like to thank the anonymous reviewers for their valuable comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Infants&apos; physical world. Current directions in psychological science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renée</forename><surname>Baillargeon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="89" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Automatic attribute discovery and characterization from noisy web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="663" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mining semantic affordances of visual object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wei</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4259" to="4267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A lightweight tool for automatically extracting causal relationships from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">D</forename><surname>Stephen V Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Royal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valtorta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Huhns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SoutheastCon, 2006. Proceedings of the IEEE</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="125" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Minimally supervised event causality identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Quang Xuan Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Entity disambiguation for knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="277" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the nature and the observability of the causal relation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Curt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ducasse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="57" to="68" />
			<date type="published" when="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modeling actions through state changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James M Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2579" to="2586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning object categories from google&apos;s image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1816" to="1823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning perceptual causality from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Fire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2016" />
			<publisher>TIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Verb physics: Relative physical knowledge of actions and objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="266" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Fukui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Huk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daylen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01847</idno>
		<title level="m">Multimodal compact bilinear pooling for visual question answering and visual grounding</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Physical causality of action verbs in grounded language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Doering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1814" to="1824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dataset of syntactic-ngrams over time from a very large corpus of english books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Orwant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity</title>
		<meeting>the Main Conference and the Shared Task: Semantic Textual Similarity</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="241" to="247" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (* SEM)</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Causal learning: Psychology, philosophy, and computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Gopnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><forename type="middle">Elizabeth</forename><surname>Schulz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">To search or to label?: predicting the performance of search-based automatic image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Lyndon S Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><forename type="middle">V</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kozintsev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th ACM international workshop on Multimedia information retrieval</title>
		<meeting>the 8th ACM international workshop on Multimedia information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="249" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical question-image coattention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mapping instructions and visual observations to actions with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1015" to="1026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Environment-driven lexicon induction for high-level instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejia</forename><surname>Dipendra Kumar Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="992" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gaussian visual-linguistic embedding for zero-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmoy</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="912" to="918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning joint representations of videos and sentences with web image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayu</forename><surname>Otani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esa</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janne</forename><surname>Heikkilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naokazu</forename><surname>Yokoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="651" to="667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Causal inference in statistics: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics surveys</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="96" to="146" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Combining supervised and unsupervised ensembles for knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatema</forename><surname>Nazneen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semi-supervised self-training of object detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuck</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Schneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Application of Computer Vision, 2005. WACV/MOTIONS&apos;05 Volume</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Grounding words in perception and action: computational insights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="389" to="396" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Creating causal embeddings for question answering with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hammond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="138" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Incremental acquisition of verb hypothesis space towards physical world interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Interactive learning of grounded verb semantics towards human-robot communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1634" to="1644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Back to the blocks world: Learning new actions through situated human-robot dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Representing general relational knowledge in conceptnet 5</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3679" to="3686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Yago: a core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Fabian M Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th international conference on World Wide Web</title>
		<meeting>the 16th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Understanding natural language commands for robotic navigation and mobile manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashis</forename><forename type="middle">Gopal</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><forename type="middle">J</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Improving one-shot learning through fusing side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao-Hung Hubert</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08347</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Actions˜transformationsActions˜transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2658" to="2667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bootstrapping via graph propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="620" to="628" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning physical object properties from unlabeled videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning to see physics via visual de-animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erika</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="152" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Transductive zero-shot action recognition by word-vector embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="333" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-task zero-shot action recognition with prioritised data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Few-shot object recognition from machine-labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Grounded semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="149" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Multi level causal relation identification using extended features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kezhi</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="7171" to="7181" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Detection of manipulation action consequences (mac)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yezhou</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornelia</forename><surname>Fermüller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiannis</forename><surname>Aloimonos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2563" to="2570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Stating the obvious: Extracting visual common sense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="193" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Zero-shot activity recognition with verb attribute induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning temporal transformations from time-lapse videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yipin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="262" to="277" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
