<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Web-scale system for scientific knowledge exploration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Redmond</orgName>
								<address>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Web-scale system for scientific knowledge exploration</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="87" to="92"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>87</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>To enable efficient exploration of Web-scale scientific knowledge, it is necessary to organize scientific publications into a hierarchical concept structure. In this work, we present a large-scale system to (1) identify hundreds of thousands of scientific concepts, (2) tag these identified concepts to hundreds of millions of scientific publications by leverag-ing both text and graph structure, and (3) build a six-level concept hierarchy with a subsumption-based model. The system builds the most comprehensive cross-domain scientific concept ontology published to date, with more than 200 thousand concepts and over one million relationships .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Scientific literature has grown exponentially over the past centuries, with a two-fold increase ev- ery 12 years ( <ref type="bibr" target="#b0">Dong et al., 2017)</ref>, and millions of new publications are added every month. Effi- ciently identifying relevant research has become an ever increasing challenge due to the unprece- dented growth of scientific knowledge. In order to assist researchers to navigate the entirety of sci- entific information, we present a deployed system that organizes scientific knowledge in a hierarchi- cal manner.</p><p>To enable a streamlined and satisfactory seman- tic exploration experience of scientific knowledge, three criteria must be met:</p><p>• a comprehensive coverage on the broad spec- trum of academic disciplines and concepts (we call them concepts or fields-of-study, ab- breviated as FoS, in this paper);</p><p>Figure 1: Three modules of the system: concept discovery, concept-document tagging, and con- cept hierarchy generation.</p><p>• an accurate mapping between these concepts and all forms of academic publications, in- cluding books, journal articles, conference papers, pre-prints, etc.</p><p>To build such a system on Web-scale, the fol- lowing challenges need to be tackled:</p><p>• Scalability: Traditionally, academic disci- pline and concept taxonomies have been cu- rated manually on a scale of hundreds or thousands, which is insufficient in modeling the richness of academic concepts across all domains. Consequently, the low concept cov- erage also limits the exploration experience of hundreds of millions of scientific publica- tions.</p><p>• Trustworthy representation: Traditional concept hierarchy construction approaches extract concepts from unstructured docu- ments, select representative terms to denote a concept, and build the hierarchy on top of them ( <ref type="bibr" target="#b5">Sanderson and Croft, 1999;</ref><ref type="bibr" target="#b1">Liu et al., 2012</ref>). The concepts extracted this way not only lack authoritative definition, but also graph link analysis text + graph structure subsumption Data scale 10 5 -10 6 10 9 -10 10 10 6 -10 7 Data update frequency monthly weekly monthly <ref type="table">Table 1</ref>: System key features at a glance.</p><p>contain erroneous topics with subpar quality which is not suitable for a production system.</p><p>• Temporal dynamics: Academic publica- tions are growing at an unprecedented pace (about 70K more papers per day according to our system) and new concepts are emerging faster than ever. This requires frequent inclu- sion on latest publications and re-evaluation in tagging and hierarchy-building results.</p><p>In this work, we present a Web-scale sys- tem with three modules-concept discovery, concept-document tagging, and concept-hierarchy generation-to facilitate scientific knowledge ex- ploration (see <ref type="figure">Figure 1</ref>). This is one of the core components in constructing the Microsoft Aca- demic Graph (MAG), which enables a semantic search experience in the academic domain <ref type="bibr">1</ref> . MAG is a scientific knowledge base and a heterogeneous graph with six types of academic entities: publica- tion, author, institution, journal, conference, and field-of-study (i.e., concept or FoS). As of March 2018, it contains more than 170 million publica- tions with over one billion paper citation relation- ships, and is the largest publicly available aca- demic dataset to date 2 .</p><p>To generate high-quality concepts with com- prehensive coverage, we leverage Wikipedia ar- ticles as the source of concept discovery. Each Wikipedia article is an entity in a general knowl- edge base (KB). A KB entity associated with a Wikipedia article is referred to as a Wikipedia en- tity. We formulate concept discovery as a knowl- edge base type prediction problem <ref type="bibr" target="#b4">(Neelakantan and Chang, 2015)</ref> and use graph link analysis to guide the process. In total, 228K academic con- cepts are identified from over five million English Wikipedia entities.</p><p>During the tagging stage, both textual informa- tion and graph structure are considered. The text from Wikipedia articles and papers' meta informa- tion (e.g., titles, keywords, and abstracts) are used as the concept's and publication's textual repre- sentations respectively. Graph structural informa- tion is leveraged by using text from a publication's neighboring nodes in MAG (its citations, refer- ences, and publishing venue) as part of the pub- lication's representation with a discounting factor. We limit the search space for each publication to a constant range, reduce the complexity to O(N ) for scalability, where N is the number of publications. Close to one billion concept-publication pairs are established with associated confidence scores.</p><p>Together with the notion of subsump- tion ( <ref type="bibr" target="#b5">Sanderson and Croft, 1999</ref>), this confidence score is then used to construct a six-level directed acyclic graph (DAG) hierarchy with over 200K nodes and more than one million edges.</p><p>Our system is a deployed product with regular data refreshment and algorithm improvement. Key features of the system are summarized in <ref type="table">Table 1</ref>. The system is updated weekly or monthly to in- clude fresh content on the Web. Various docu- ment and language understanding techniques are experimented with and incorporated to incremen- tally improve the performance over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Concept Discovery</head><p>As top level disciplines are extremely important and highly visible to system end users, we man-ually define 19 top level ("L0") disciplines (such as physics, medicine) and 294 second level ("L1") sub-domains (examples are machine learning, al- gebra) by referencing existing classification <ref type="bibr">3</ref> and get their correspondent Wikipedia entities in a general in-house knowledge base (KB).</p><p>It is well understood that entity types in a gen- eral KB are limited and far from complete. Enti- ties labeled with FoS type in KB are in the lower thousands and noisy for both in-house KB and latest Freebase dump 4 . The goal is to identify more FoS type entities from over 5 million English Wikipedia entities in an in-house KB. We formu- late this task as a knowledge base type prediction problem, and focus on predicting only one specific type-FoS.</p><p>In addition to the above-mentioned "L0" and "L1" FoS, we manually review and identify over 2000 high-quality ones as initial seed FoS. We it- erate a few rounds between a graph link analysis step for candidate exploration and an entity type based filtering and enrichment step for candidate fine-tuning based on KB types.</p><p>Graph link analysis: To drive the process of exploring new FoS candidates, we apply the in- tuition that if the majority of an entity's nearest neighbours are FoS, then it is highly likely an FoS as well. To calculate nearest neighbours, a dis- tance measure between two Wikipedia entities is required. We use an effective and low-cost ap- proach based on Wikipedia link analysis to com- pute the semantic closeness <ref type="bibr" target="#b3">(Milne and Witten, 2008)</ref>. We label a Wikipedia entity as an FoS can- didate if there are more than K neighbours in its top N nearest ones are in a current FoS set. Em- pirically, N is set to 100 and K is in <ref type="bibr">[35,</ref><ref type="bibr">45]</ref> range for best results.</p><p>Entity type based filtering and enrichment: The candidate set generated in the above step con- tains various types of entities, such as person, event, protein, book topic, etc. 5 Entities with obvious invalid types are eliminated (e.g. per- son) and entities with good types are further in- cluded (e.g. protein, such that all Wikipedia enti- ties which have labeled type as protein are added).</p><p>The results of this step are used as the input for graph link analysis in the next iteration.</p><p>More than 228K FoS have been identified with this iterative approach, based on over 2000 initial seed FoS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tagging Concepts to Publications</head><p>We formulate the concept tagging as a multi-label classification problem; i.e. each publication could be tagged with multiple FoS as appropriate. In a naive approach, the complexity could reach M · N to exhaust all possible pairs, where M is 200K+ for FoS and N is close to 200M for publications. Such a naive solution is computationally expen- sive and wasteful, since most scientific publica- tions cover no more than 20 FoS based on empiri- cal observation.</p><p>We apply heuristics to cut candidate pairs ag- gressively to address the scalability challenge, to a level of 300-400 FoS per publication <ref type="bibr">6</ref> . Graph structural information is incorporated in addition to textual information to improve the accuracy and coverage when limited or inadequate text of a con- cept or publication is accessible.</p><p>We first define simple representing text (or SRT) and extended representing text (or ERT). SRT is the text used to describe the academic entity it- self. ERT is the extension of SRT and leverages the graph structural information to include textual information from its neighbouring nodes in MAG.</p><p>A publishing venue's full name (i.e. the jour- nal name or the conference name) is its SRT. The first paragraph of a concept's Wikipedia article is used as its SRT. Textual meta data, such as title, keywords, and abstract is a publication's SRT.</p><p>We sample a subset of publications from a given venue and concatenate their SRT. This is used as this venue's ERT. For broad disciplines or do- mains (e.g. L0 and L1 FoS), Wikipedia text be- comes too vague and general to best represent its academic meanings. We manually curate such concept-venue pairs and aggregate ERT of venues associated with a given concept to obtain the ERT for the concept. For example, SRT of a subset of papers from ACL are used to construct ERT for ACL, and subsequently be part of the ERT for nat- ural language processing concept. A publication's ERT includes SRT from its citations, references and ERT of its linked publishing venue.</p><p>We use h p s and h p e to denote the representation of a publication (p)'s SRT and ERT, h v s and h v e for a venue (v)'s SRT and ERT. Weight w is used to discount different neighbours' impact as appropri- ate. Equation 1 and 2 formally define publication ERT and venue ERT calculation.</p><formula xml:id="formula_0">h p e = h p s + i∈Cit w i h p s (i) + j∈Ref w j h p s (j) + w v h v e<label>(1)</label></formula><formula xml:id="formula_1">h v e = i∈V h p s (i) + h v s<label>(2)</label></formula><p>Four types of features are extracted from the text: bag-of-words (BoW), bag-of-entities (BoE), embedding-of-words (EoW), and embedding-of- entities (EoE). These features are concatenated for the vector representation h used in Equation 1 and 2. The confidence score of a concept-publication pair is the cosine similarity between these vector representations.</p><p>We pre-train the word embeddings by us- ing the skip-gram ( <ref type="bibr" target="#b2">Mikolov et al., 2013</ref>) on the academic corpus, with 13B words based on 130M titles and 80M abstracts from English sci- entific publications. The resulting model con- tains 250-dimensional vectors for 2 million words and phrases. We compare our model with pre- trained embeddings based on general text (such as Google News <ref type="bibr">7</ref> and Wikipedia 8 ) and observe that the model trained from academic corpus performs better with higher accuracy on the concept-tagging task with more than 10% margin.</p><p>Conceptually, the calculation of publication and venue's ERT is to leverage neighbours' informa- tion to represent itself. The MAG contains hun- dreds of millions of nodes with billions of edges, hence it is computationally prohibitive by optimiz- ing the node latent vector and weights simultane- ously. Therefore, in Equation 1 and 2, we initial- ize h p s and h v s based on textual feature vectors de- fined above and adopt empirical weight values to directly compute h p e and h v e to make it scalable. After calculating the similarity for about 50 bil- lion pairs, close to 1 billion are finally picked based on the threshold set by the confidence score. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Concept Hierarchy Building</head><p>In this subsection, we describe how to build a con- cept hierarchy based on concept-document tag- ging results. We extend Sanderson and Croft's early work (1999) which uses the notion of subsumption-a form of co-occurrence-to asso- ciate related terms. We say term x subsumes y if y occurs only in a subset of the documents that x occurs in. In the hierarchy, x is the parent of y. In reality, it is hard for y to be a strict subset of x. Sanderson and Croft's work relaxed the subsump- tion to 80% (e.g. P (x|y) ≥ 0.8, P (y|x) &lt; 1).</p><p>In our work, we extend the concept co- occurrence calculation weighted with the concept- document pair's confidence score from previous step. More formally, we define a weighted rela- tive coverage score between two concepts i and j as below and illustrate in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><formula xml:id="formula_2">RC(i, j) = k∈(I∩J) w i,k k∈I w i,k − k∈(I∩J) w j,k k∈J w j,k<label>(3)</label></formula><p>Set I and J are documents tagged with concepts i and j respectively. I ∩ J is the overlapping set of documents that are tagged with both i and j. w i,k denotes the confidence score (or weights) between concept i and document k, which is the final con- fidence score in the previous concept-publication tagging stage. When RC(i, j) is greater than a given positive threshold 9 , i is the child of j. Since With the proposed model, we construct a six level FoS hierarchy (from L0 and L5) on over 200K concepts with more than 1M parent-child pairs. Due to the high visibility, high impact and small size, the hierarchical relationships between L0 and L1 are manually inspected and adjusted if necessary. The remaining L2 to L5 hierarchical structures are produced completely automatically by the extended subsumption model.</p><p>One limitation of subsumption-based models is the intransitiveness of parent-child relationships. This model also lacks a type-consistency check between parents and children. More discussions on such limitations with examples will be in eval- uation section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deployment and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Deployment</head><p>The work described in this paper has been de- ployed in the production system of Microsoft Aca- demic Service <ref type="bibr">10</ref> . <ref type="figure" target="#fig_1">Figure 3</ref> shows the website homepage with entity statistics. The contents of MAG, including the full list of FoS, FoS hierarchy structure, and FoS tagging to papers, are accessi- ble via API, website, and full graph dump from Open Academic Society <ref type="bibr">11</ref> . <ref type="figure" target="#fig_2">Figure 4</ref> shows the example for word2vec con- cept. Concept definition with linked Wikipedia page, its immediate parents (machine learning, artificial intelligence, natural language process- ing) in the hierarchical structure and its related 10 https://academic.microsoft.com/ 11 https://www.openacademic.ai/oag/</p><p>Step Accuracy 1. Concept discovery 94.75% 2. Concept tagging 81.20% 3. Build hierarchy 78.00% <ref type="table">Table 2</ref>: Accuracy results for each step.</p><p>concepts 12 (word embedding, artificial neural net- work, deep learning, etc.) are shown on the right rail pane. Top tagged publications (without word2vec explicitly stated in their text) are recog- nized via graph structure information based on ci- tation relationship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>For this deployed system, we evaluate the accu- racy on three steps (concept discovery, concept tagging, and hierarchy building) separately.</p><p>For each step, 500 data points are randomly sampled and divided into five groups with 100 data points each. On concept discovery, a data point is an FoS; on concept tagging, a data point is a concept-publication pair; and on hierarchy build- ing, a data point is a parent-child pair between two concepts. For the first two steps, each 100-data- points group is assigned to one human judge. The concept hierarchy results are by nature more con- troversial and prone to individual subjective bias, hence we assign each group of data to three judges and use majority voting to decide final results. The accuracy is calculated by counting positive labels in each 100-data-points group and averag- ing over 5 groups for each step. The overall accu- racy is shown in <ref type="table">Table 2</ref> and some sampled hierar- chical results are listed in <ref type="table" target="#tab_2">Table 3</ref>.</p><p>Most hierarchy dissatisfaction is due to the in- transitiveness and type-inconsistent limitations of the subsumption model. For example, most pub- lications that discuss the polycystic kidney disease also mention kidney; however, for all publications that mentioned kidney, only a small subset would mention polycystic kidney disease. According to the subsumption model, polycystic kidney disease is the child of kidney. It is not legitimate for a dis- ease as the child of an organ. Leveraging the en- tity type information to fine-tune hierarchy results is in our plan to improve the quality.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we demonstrated a Web-scale pro- duction system that enables an easy exploration of scientific knowledge. We designed a system with three modules: concept discovery, concept tagging to publications, and concept hierarchy construc- tion. The system is able to cover latest scientific knowledge from the Web and allows fast iterations on new algorithms for document and language un- derstanding.</p><p>The system shown in this paper builds the largest cross-domain scientific concept ontology published to date, and it is one of the core components in the construction of the Microsoft Academic Graph, which is a publicly available academic knowledge graph-a data asset with tremendous value that can be used for many tasks in domains like data mining, natural language un- derstanding, science of science, and network sci- ence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Extended subsumption for hierarchy generation.</figDesc><graphic url="image-2.png" coords="4,317.20,62.63,198.36,234.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Deployed system homepage at March 2018, with all six types of entities statistics: over 228K fields-of-study.</figDesc><graphic url="image-3.png" coords="5,67.75,62.81,226.74,117.12" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Word2vec example, with its parent FoS, related FoS and top tagged publications.</figDesc><graphic url="image-4.png" coords="6,142.87,62.79,311.75,178.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Sample results for FoS hierarchy.</figDesc><table></table></figure>

			<note place="foot" n="1"> The details about where and how we obtain, aggregate, and ingest academic publication information into the system is out-of-scope for this paper and for more information please refer to (Sinha et al., 2015). 2 https://www.openacademic.ai/oag/</note>

			<note place="foot" n="3"> http://science-metrix.com/en/ classification 4 https://developers.google.com/ freebase/ 5 Entity types are obtained from the in-house KB, which has higher type coverage compared with Freebase, details on how the in-house KB produces entity types is out-of-scope and not discussed in this paper.</note>

			<note place="foot" n="6"> We include all L0s and L1s and FoS entities spotted in a publication&apos;s extended representing text, which is defined later in this section</note>

			<note place="foot" n="7"> https://code.google.com/archive/p/ word2vec/ 8 https://fasttext.cc/docs/en/ pretrained-vectors.html</note>

			<note place="foot" n="9"> It is usually in [0.2, 0.5] based on empirical observation.</note>

			<note place="foot" n="12"> Details about how to generate related entities are out-ofscope and not included in this paper.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A century of science: Globalization of scientific collaborations, citations, and innovations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1437" to="1446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic taxonomy construction from keywords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1433" to="1441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An effective, low-cost measure of semantic relatedness obtained from wikipedia links. WIKIAI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<title level="m">ferring missing entity type instances for knowledge base completion: New dataset and methods</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="515" to="525" />
		</imprint>
	</monogr>
	<note>NAACL</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deriving concept hierarchies from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="206" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An overview of microsoft academic service (mas) and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrin</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="243" to="246" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
