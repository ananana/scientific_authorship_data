<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Easy Questions First? A Case Study on Curriculum Learning for Question Answering</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="453" to="463"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cognitive science researchers have emphasized the importance of ordering a complex task into a sequence of easy to hard problems. Such an ordering provides an easier path to learning and increases the speed of acquisition of the task compared to conventional learning. Recent works in machine learning have explored a curriculum learning approach called self-paced learning which orders data samples on the easiness scale so that easy samples can be introduced to the learning algorithm first and harder samples can be introduced successively. We introduce a number of heuristics that improve upon self-paced learning. Then, we argue that incorporating easy, yet, a diverse set of samples can further improve learning. We compare these curriculum learning proposals in the context of four non-convex models for QA and show that they lead to real improvements in each of them.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A key challenge in building an intelligent agent is in modeling the incrementality and the cumulative nature of human learning <ref type="bibr" target="#b30">(Skinner, 1958;</ref><ref type="bibr" target="#b23">Peterson, 2004;</ref><ref type="bibr" target="#b16">Krueger and Dayan, 2009)</ref>. Children typically learn grade by grade, progressing from simple concepts to more complex ones. Given a complex set of concepts, it is often the case that some concepts are easier than others. Some con- cepts can even be prerequisite to learning other concepts. Hence, evolving a useful curriculum where easy concepts are presented first and more complex concepts are gradually introduced can be beneficial for learning.</p><p>We explore methods for learning a curriculum in the context of non-convex models for question answering. Curriculum learning (CL) ( <ref type="bibr" target="#b1">Bengio et al., 2009</ref>) and self-paced learning (SPL) ( <ref type="bibr" target="#b17">Kumar et al., 2010</ref>) have been recently introduced in ma- chine learning literature. However, their useful- ness in the context of NLP tasks such as QA has not been studied so far. The main challenge in learning a curriculum is that it requires the identifi- cation of easy and hard concepts in the given train- ing dataset. However, in real-world applications, such a ranking of training samples is difficult to obtain. Furthermore, a human judgement of 'eas- iness' of a task might not correlate with what is easy for the algorithm in the feature and hypothe- sis space employed for the given application. SPL combines the selection of the curriculum and the learning task in a single objective. The easiness of a question in self-paced learning is defined by its local loss. We propose and study other heuristics that define a measure of easiness and learn the cur- riculum by selecting samples using this measure. These heuristics are similar to those used in active learning, but with one key difference. In curricu- lum learning, all the training examples and labels are already known, which is not the case in active learning. Our experiments show that these heuris- tics work well in practice. While the strategy of learning from easy ques- tions first and then gradually handling harder ques- tions is supported by many cognitive scientists, others <ref type="bibr" target="#b4">(Cantor, 1946)</ref> argue that it is also important to expose the learning to diverse (even if some- times harder) examples. We argue that the right curriculum should not only be arranged in the in- creasing order of difficulty but also introduce the learner to sufficient number of diverse examples that are sufficiently dissimilar from what has al- ready been introduced to the learning process. We showed that the above heuristics when coupled with diversity lead to significant improvements.</p><p>We provide empirical evaluation on four QA models: (a) an alignment-based approach <ref type="bibr" target="#b25">(Sachan et al., 2015)</ref> for machine comprehension -a reading comprehension task ( <ref type="bibr" target="#b24">Richardson et al., 2013</ref>) with a set of questions and associated texts, (b) an alignment-based approach <ref type="bibr" target="#b26">(Sachan et al., 2016</ref>) for a multiple-choice elementary science test <ref type="bibr" target="#b5">(Clark and Etzioni, 2016)</ref>, (c) QANTA <ref type="bibr" target="#b10">(Iyyer et al., 2014</ref>) -a recursive neural network for an- swering quiz bowl questions, and (d) memory net- works ( <ref type="bibr" target="#b34">Weston et al., 2014</ref>) -a recurrent neural network with a long-term memory component for answering 20 pre-defined tasks for machine com- prehension. We show value in our approaches for curriculum learning on all these settings. Our paper has the following contributions:</p><p>1. In our knowledge, this is the first application of curriculum learning to the task of QA and one of the first in NLP. We hope to make the NLP and ML communities aware of the ben- efits of CL for non-convex optimization. 2. We perform an in-depth analysis of SPL, and propose heuristics which offer significant im- provements over SPL; the state-of-the-art in curriculum learning. 3. We stress on diversity of questions in the curriculum during learning and propose a method that learns a curriculum while cap- turing diversity to gain more improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Setting for QA</head><p>For each question q i ∈ Q, let A i = {a i1 , . . . , a im } be the set of candidate answers to the question. Let a * i be the correct answer. The candidate answers may be pre-defined, as in multiple-choice QA, or may be undefined but easy to extract with a high degree of confidence (e.g., by using a pre-existing system). We want to learn a function f : (q, K) → a that, given a question q i and background knowl- edge K (texts/resources required to answer the question), outputs an answerâanswerˆanswerâ i ∈ A i . We con- sider a scoring function S w (q, a; K) (with model parameters w) and a prediction rule f w (q i ) = ˆ a i = arg max</p><formula xml:id="formula_0">a ij ∈A i S w (q i , a ij ; K). Let ∆(ˆ a i , a * i</formula><p>) be the cost of giving a wrong answer. We consider the empirical risk minimization (ERM) framework given a loss function L and a regularizer Ω:</p><formula xml:id="formula_1">min w q i ∈Q L w (a * i , f w (q i ); K) + Ω(w)<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">QA Models</head><p>The field of QA is quite rich. Solutions proposed have ranged from various IR based approaches that treat this as a problem of retrieval from ex- isting knowledge bases or perform inference using a large corpus of unstructured texts by learning a similarity between the question and a set of can- didate answers <ref type="bibr">(Yih et al., 2013)</ref>. A comprehen- sive review of QA is out of scope of this paper. So we point the interested readers to <ref type="bibr" target="#b14">Jurafsky and Martin (2000)</ref>, chapter 28 for a more comprehen- sive review. In this paper, we will explore curricu- lum learning in the context of non-convex models for QA. The models will be (1) latent structural SVM ( <ref type="bibr" target="#b36">Yu and Joachims, 2009)</ref> based solutions for standardized question-answering tests and (2) deep learning models <ref type="bibr" target="#b10">(Iyyer et al., 2014;</ref><ref type="bibr" target="#b34">Weston et al., 2014</ref>) for QA.</p><p>Recently, researchers have proposed standard- ized tests as 'drivers for progress in AI' <ref type="bibr" target="#b5">(Clark and Etzioni, 2016)</ref>. Some example standardized tests are reading comprehensions ( <ref type="bibr" target="#b24">Richardson et al., 2013)</ref>, algebra word problems ( <ref type="bibr" target="#b19">Kushman et al., 2014</ref>), geometry problems ( <ref type="bibr" target="#b28">Seo et al., 2014</ref>), entrance exams ( <ref type="bibr" target="#b8">Fujita et al., 2014;</ref><ref type="bibr" target="#b0">Arai and Matsuzaki, 2014</ref>), etc. These tests are usually in the form of question-answers and focus on elemen- tary learning. The idea of learning the curriculum could be especially useful in the context of stan- dardized tests. Standardized tests <ref type="bibr" target="#b5">(Clark and Etzioni, 2016</ref>) are implicitly incremental in nature, covering various levels of difficulty. Thus they are rich sources of data for building systems that learn incrementally. These datasets can also help us understand the shaping hypothesis as we can use them to verify if easier questions are indeed getting picked by our incremental learning algo- rithm before harder questions.</p><p>On the other hand, deep learning models ( <ref type="bibr" target="#b20">LeCun et al., 2015)</ref> have recently shown good per- formance in many standard NLP and vision tasks, including QA. These models usually learn repre- sentations of data and the QA model jointly. The models use a cascade of many layers of nonlinear processing units, leading to a highly non-convex model and a large parameter space. This renders these models susceptible to local-minima. Hence, the idea of learning the curricula is also very use- ful in the context of deep-learning models, as the technique of processing questions in the increas- ing order of difficulty often leads to better minima Text: … Natural greenhouse gases include carbon dioxide, methane, water vapor, and ozone ... CFCs and ! some other man-made compounds are also greenhouse gases … Hypothesis: The important greenhouse gases are Carbon dioxide , Methane, Ozone and CFC Q: What are the important greenhouse gases? ! A: Carbon dioxide, Methane, Ozone and CFC for the question-answer candidate pair (q i , a i,j ). A natural solution is to treat QA as a problem of ranking the hypothesis set h i such that the correct hypothesis is at the top of this ranking. Hence, a scoring function S w (h, z) is learnt such that the score given to the correct hypothesis h * i and the corresponding latent structure z * i is higher than the score given to any other hypothesis and its corre- sponding latent structure. In fact, in a max-margin fashion, the model learns the scoring function such that</p><formula xml:id="formula_2">S w (h * i , z * i ) &gt; S w (h ij , z ij ) + ∆(h * i , h ij ) − ξ i for all h j ∈ h \ h * for some slack ξ i .</formula><p>This can be formulated as the following optimization problem:</p><formula xml:id="formula_3">min ||w|| 1 2 ||w|| 2 2 + C i ξi s.t. Sw(h * i , z * i ) ≥ max z ij Sw(hij, zij) + ∆(h * i , hij) − ξi It is intuitive to use 0-1 cost, i.e. ∆(h * i , h ij ) = 1(h * i = h ij )</formula><p>If the scoring function is convex then this objective is in concave-convex form and can be minimized by the concave-convex program- ming procedure (CCCP) <ref type="bibr" target="#b37">(Yuille and Rangarajan, 2003)</ref>. The scoring function is assumed to be lin- ear:</p><formula xml:id="formula_4">S w (h, z) = w T ψ(h, z). Here, ψ(h, z)</formula><p>is a task-dependent feature map (see <ref type="bibr" target="#b25">Sachan et al. (2015)</ref> and <ref type="bibr" target="#b26">Sachan et al. (2016)</ref> for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Deep Learning Models</head><p>We briefly review two neural network models for QA - <ref type="bibr" target="#b10">Iyyer et al. (2014)</ref> and <ref type="bibr" target="#b34">Weston et al. (2014)</ref>. QANTA: QANTA ( <ref type="bibr" target="#b10">Iyyer et al., 2014</ref>) answers quiz bowl questions using a dependency tree struc- tured recursive neural network. It combines pre- dictions across sentences to produce a question an- swering neural network with trans-sentential av- eraging. The model is optimized using AdaGrad <ref type="bibr" target="#b6">(Duchi et al., 2011</ref>). In quiz bowl, questions typ- ically consist of four to six sentences and are as- sociated with factoid answers. Every sentence in the question is guaranteed to contain clues that uniquely identify its answer, even without the con- text of previous sentences <ref type="bibr">1</ref> . Recently, QANTA had beaten the well-known Jeopardy! star Ken Jennings at an exhibition quiz bowl contest. Memory Networks: Memory networks ( <ref type="bibr" target="#b34">Weston et al., 2014</ref>) are essentially recurrent neural net- works with a long-term memory component. The memory can be read and written to, and can be used for prediction. The memory can be seen as acting like a dynamic knowledge base. The model is trained using a margin ranking loss and stochas- tic gradient descent. It was evaluated on a set of synthetic QA tasks. For each task, a set of state- ments were generated by a simulation of 4 char- acters, 3 objects and 5 rooms using an automated grammar with characters moving around, picking up and dropping objects are given, followed by a question whose answer is typically a single word 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Curriculum Learning</head><p>Studies in cognitive science <ref type="bibr" target="#b30">(Skinner, 1958;</ref><ref type="bibr" target="#b23">Peterson, 2004;</ref><ref type="bibr" target="#b16">Krueger and Dayan, 2009)</ref> have shown that humans learn much better when the training examples are not randomly presented but organized in increasing order of difficulty. The idea of shaping, which consists of training a ma- chine learning algorithm with a curriculum was first introduced by <ref type="bibr" target="#b7">(Elman, 1993)</ref> in the context of grammatical structure learning using a recur- rent connectionist network. This idea also lent support for the much debated Newport's "less is more" hypothesis ( <ref type="bibr" target="#b9">Goldowsky and Newport, 1993;</ref><ref type="bibr" target="#b22">Newport, 1990</ref>) that child language acqui- sition is aided, rather than hindered, by limited cognitive resources. Curriculum learning <ref type="bibr" target="#b1">(Bengio et al., 2009</ref>) is a recent idea in machine learn- ing, where a curriculum is designed by ranking samples based on manually curated difficulty mea- sures. These measurements are usually not known in real-world scenarios, and are hard to elicit from humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Self-paced Learning</head><p>Self-paced learning (SPL) ( <ref type="bibr" target="#b17">Kumar et al., 2010;</ref><ref type="bibr" target="#b11">Jiang et al., 2014a;</ref>) reformu- lates curriculum learning as an optimization prob- lem by jointly modeling the curriculum and the task at hand. Let v ∈ [0, 1] |Q| be the weight vector that models the weight of the sample ques- tions in the curriculum. The SPL model includes a weighted loss term on all samples and an ad- ditional self-paced regularizer imposed on sample weights v. SPL formulation for the ERM frame- work described in eq 1 can be rewritten as: The problem usually has closed-form solution with respect to v (described later; lets call the solution v * (λ; L) for now). g(v, λ) is usually called the self-paced regularizer with the "age" or "pace" parameter λ. g is convex with re- spect to v ∈ [0, 1] |Q| . Furthermore, v(λ; L) is monotonically decreasing with respect to L, and</p><formula xml:id="formula_5">min w,v∈[0,1] |Q| q i ∈Q v i L w (a * i , f w (q i ); K) + g(v i , λ</formula><formula xml:id="formula_6">lim L→0 v * (λ; L) = 1 and lim L→∞ v * (λ; L) = 0.</formula><p>This means that the model inclines to select easy samples (with smaller losses) in favor of complex samples (with larger losses). Finally, v * (λ; L) is monotonically increasing with respect to λ, and</p><formula xml:id="formula_7">lim λ→0 v * (λ; L) = 0 and lim λ→∞ v * (λ; L) ≤ 1.</formula><p>This means that when the model "ages" (i.e. the age parameter λ gets larger), it tends to incorpo- rate more, probably complex samples to train a 'mature' model.</p><p>Four popular self-paced regularizers in the lit- erature ( <ref type="bibr" target="#b17">Kumar et al., 2010;</ref><ref type="bibr" target="#b11">Jiang et al., 2014a;</ref>) are hard, soft logarithmic, soft linear and mixture. These SP-regularizers, sum- marized with corresponding closed form solutions for v are shown in <ref type="table" target="#tab_1">Table 1</ref>. Hard weighting is usu- ally less appropriate as it cannot discriminate the importance of samples. However, soft weighting assigns real-valued weights and reflects the latent importance of samples in training. The soft linear regularizer linearly weighs samples with respect to their losses and the soft logarithmic penalizes the weight logarithmically. Mixture weighting com- bines both hard and soft weighting schemes. We can solve the model in the SPL regime by itera- tively updating v (closed form solution for v is shown in <ref type="table" target="#tab_1">Table 1</ref>) and w (by CCCP, AdaGrad or SGD), and gradually increasing the age parameter λ to let harder and harder problems in.</p><p>Since its inception, variations of SPL such as self-paced re-ranking ( <ref type="bibr" target="#b11">Jiang et al., 2014a</ref>), self- paced learning with diversity (Jiang et al., 2014b), self-paced multiple-instance learning ( <ref type="bibr" target="#b38">Zhang et al., 2015</ref>) and self-paced curriculum learning ( ) have been proposed. The tech- niques have been shown to be useful in some com- puter vision tasks ( <ref type="bibr" target="#b21">Lee and Grauman, 2011;</ref><ref type="bibr" target="#b18">Kumar et al., 2011;</ref><ref type="bibr" target="#b32">Tang et al., 2012;</ref><ref type="bibr" target="#b31">Supancic and Ramanan, 2013;</ref><ref type="bibr" target="#b11">Jiang et al., 2014a</ref>). SPL is dif- ferent from active learning <ref type="bibr" target="#b29">(Settles, 1995</ref>) in the sense that the training examples (and labels) are already provided and the solution only orders the examples to achieve a better solution. On the other hand, active learning tries to interactively query the user (or another information source) to achieve a better model with few queries. Curriculum learn- ing is also related to teaching dimension ( <ref type="bibr" target="#b15">Khan et al., 2011</ref>) which studies the strategies that humans follow as they teach a target concept to a robot by assuming a teaching goal of minimizing the learner's expected generalization error at each it- eration. One can also think of curriculum learning as an approach for achieving a better local opti- mum in non-convex problems.</p><formula xml:id="formula_8">Regularizer g(v; λ) v * (λ; L) Hard −λv 1, if L ≤ λ 0, o/w Soft Linear λ( 1 2 v 2 − v) − L λ + 1, if L ≤ λ 0, otherwise Soft Logarithmic q i ∈Q (1 − λ)vi − (1−λ) v i log(1−λ) log(L+1−λ) log(1−λ) , if L ≤ λ 0, o/w Mixed γ 2 v+ γ λ        1, if L ≤ λγ λ+γ 2 0, if L ≥ λ 2 γ 1 √ L − 1 λ , o/w</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Improved Curriculum Learning Heuristics</head><p>SPL selects questions based on the local loss term of the question. This is not the only way to define 'easiness' of the question. Hence, we suggest some other heuristics for selecting the order of questions to be presented to our learning algorithm. The heuristics select the next question q i ∈ Q \ Q 0 given the current model (M) and the set of questions already presented for learning (Q 0 ). We assume access to a minimization oracle (CCCP/AdaGrad/SGD) for the QA models. We explore the following heuristics: 1) Greedy Optimal (GO): The simplest and greedy optimal heuristic <ref type="bibr" target="#b27">(Schohn and Cohn, 2000</ref>) would be to pick a question q i ∈ Q \ Q 0 which has the minimum expected effect on the model. The expected effect on adding q i can be written as:</p><formula xml:id="formula_9">a ij ∈A i p(a * i = a ij ) q j ∈Q 0 ∪q i E L w (a * j , f w (q j ); K) .</formula><p>p(a * i = a ij ) can be estimated by normalizing S w (q, a; K). 3) Mini-max (M 2 ): Chooses question q i ∈ Q\Q 0 that minimizes the regularized expected risk when including the question with the answer candidate a ij that yields the maximum error.</p><formula xml:id="formula_10">q j ∈Q 0 ∪q i E L w (a * j , f w (q j ); K) can</formula><formula xml:id="formula_11">ˆ q i = arg min q i ∈Q\Q 0 max a ij ∈A i L w (a ij , f w (q i ); K)</formula><p>4) Expected Change in Objective (ECiO): In this greedy heuristic, we pick a question q i ∈ Q \ Q 0 which has the minimum expected effect on the model. The expected effect can be writ- ten as</p><formula xml:id="formula_12">a ij ∈A i p(a * i = a ij ) × E [L w (a * i , f w (q i ); K)].</formula><p>Here, p(a * i = a ij ) can be achieved by normalizing</p><formula xml:id="formula_13">S w (q, a; K) and E [L w (a * i , f w (q i ); K)]</formula><p>can be es- timated by running inference for q i . 4) Change in Objective-Expected Change in Objective (CiO -ECiO): We pick a question q i ∈ Q \ Q 0 which has the minimum value of the difference between the change in objective and the expected change in objective. Intuitively, the difference represents how much the model is sur- prised to see this new question. 5) Correctly Answered (CA): Pick a question q i ∈ Q \ Q 0 which is answered by the model M with the minimum cost ∆(ˆ a i , a * i ). If there are multiple questions with minimum cost, pick one of them randomly. 6) Farthest from Decision Boundary (FfDB): This heuristic applies for latent structural SVMs only. Here, we choose the question q i ∈ Q \ Q 0 whose predicted answerâanswerˆanswerâ i is farthest from the decision boundary: max</p><formula xml:id="formula_14">z * w T φ(q i , a * , z * , K) = maxˆz maxˆ maxˆz w T φ(q, ˆ a, ˆ z, K) + ∆(ˆ a, a * ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Timing Considerations:</head><p>A key consideration in applying the above heuris- tics is efficiency as the QA models considered (la- tent structural SVM and deep learning) are compu-tationally expensive. Among our selection strate- gies, GO and CiO require updating the model, M 2 , ECiO, CA and FfDB require performing inference on the candiate questions, while CiO -ECiO re- quires both retraining as well as inference. Con- sequently, M 2 , ECiO, CA and FfDB are most effi- cient. We can also gain considerable speed-up by picking questions in batches. This results in sig- nificant speed-up with small loss in accuracy. We will discuss the batch question selection setup in more detail in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Smarter Selection Strategies:</head><p>We further describe some improvements to the above selection strategies: 1) Ensemble Strategy: In this strategy, we com- bine all of the above heuristics into an ensemble. The ensemble computes the ratio of the score of the suggested question pick and the average score over remaining Q \ Q 0 questions for all the heuris- tics and picks the question with the highest ratio.</p><p>As we will see in our results, this ensemble works well in practice.</p><p>2) Importance-Weighting (IW): Importance weighting is a common technique in active learn- ing literature ( <ref type="bibr" target="#b33">Tong and Koller, 2002;</ref><ref type="bibr" target="#b2">Beygelzimer et al., 2009;</ref><ref type="bibr" target="#b3">Beygelzimer et al., 2010)</ref>, which mitigates the problem that if we query questions actively instead of selecting them uniformly at random, the training (and test) question sets are no longer independent and identically distributed (i.i.d.). In other words, the training set will have a sample selection bias that can impair prediction performance. To mitigate this, we propose to sam- ple questions from a biased sample distribution D. To achieve D, we introduce the weighted loss </p><formula xml:id="formula_15">L w (a, f w (q); K) = w(q, a) × L w (a, f w (q); K)</formula><formula xml:id="formula_16">E (q,a)∼ D L w (a, f w (q); K) = (q,a) p D (q, a) p D (q, a) p D (q, a) L w (a, f w (q); K)d(q, a) = (q,a) p D (q, a)L w (a, f w (q); K)d(q, a) = E (q,a)∼D [L w (a, f w (q); K)]</formula><p>Thus, given appropriate weights w(q, a), we mod- ify our loss-function in order to compute an un- biased estimator of the generalization error. Each question-answer is assigned with a non-negative weight. For latent structural SVMs, one can mini- mize the weighted loss by simply multiplying the corresponding regularization parameter C i with a corresponding term. In neural networks, this is simply achieved by multiplying the gradients with the corresponding weights. The weights can be set by an appropriate heuristic, e.g. proportional to distance from the decision boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Incorporating Diversity with Explore</head><p>and Exploit (E&amp;E):</p><p>The strategy of learning from easy questions first and then gradually handling harder questions is in- tuitive as it helps the learning process. Yet, it has one key deficiency. Under curriculum learning, by focusing on easy questions first, our learning al- gorithm is usually not exposed to a diverse set of questions. This is particularly a problem for deep- learning approaches that learn representations dur- ing the process of learning. Hence, when a harder question arrives, it is usually hard for the learner to adjust to this new question as the current repre- sentation may not be appropriate for the new level of difficulty. This motivates our E&amp;E strategy. The explore and exploit strategy ensures that while we still select easy questions first, we also want to make our selection as diverse as possible.</p><p>We define a measure for di- versity as the angle between the hyperplanes that the question samples induce in feature space:</p><formula xml:id="formula_17">∠(φ(q i , a * i , z * i , K), φ(q i , a * i , z * i , K)) = Cosine −1 |φ(q i ,a * i ,z * i ,K)φ(q i ,a * i ,z * i ,K)| ||φ(q i ,a * i ,z * i ,K)||||φ(q i ,a * i ,z * i ,K)|| .</formula><p>The E&amp;E solution picks the question which optimizes a convex combination of the curriculum learning objective and the sum of angles between the can- didate question pick and questions in Q 0 . The con- vex combination is tuned on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>As described, we study curriculum learning on four different tasks. The first task is question answering for reading comprehensions. We use MCTest-500 dataset ( <ref type="bibr" target="#b24">Richardson et al., 2013</ref>), a freely available set of 500 stories (300 train, 50 dev and 150 test) and associated questions to eval- uate our model. Each story in MCTest has four  <ref type="table">Table 2</ref>: Accuracy on the test set obtained on the four experiments, comparing results when no curriculum (NC) was learnt, when we use self-paced learning (SPL) with four variations of SP-regularizers, the six heuristics and four improvements pro- posed by us. Each cell reports the mean±se (standard error) accuracy over 10 repetitions of each experimental configuration.</p><p>multiple-choice questions, each with four answer choices. Each question has exactly one correct an- swer. The second task is science question answer- ing. We use a mix of 855 third, fourth and fifth grade science questions derived from a variety of regional and state science exams 3 for training and evaluating our model. We used publicly available science textbooks available through ck12.org and Simple English Wikipedia 4 as texts required to an- swer the questions. The model retrieves a section from the textbook or a Wikipedia page (using a lucene index on the sections and Wikipedia pages) by querying for the hypothesis h ij and then align- ing the hypothesis to snippets in the document. For QANTA <ref type="bibr" target="#b10">(Iyyer et al., 2014</ref>), we use ques- tions from quiz bowl tournaments for training as in <ref type="bibr" target="#b10">Iyyer et al. (2014</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>We implemented and compared the six selection heuristics ( §5) with the suggested improvements ( §5.2) and self-paced learning ( §4) with the ex- plore and exploit extension for both alignment based models ( §3.1) and two deep learning models ( §3.2). We use accuracy (proportion of test ques- tions correctly answered) as our evaluation metric. In all our experiments, we begin with zero training data (random initialization). For alignment based models, we select 1 percent of training set ques- tions after every epoch (an epoch is defined as a single pass through the current training set by the optimization oracle) and add them to the training set based on the selection strategy. For deep learn- ing models, we discovered that the learning was a lot slower so we added 0.1 percent of new training set questions after every epoch. Hyper parameters of the alignment based models and the deep learn- ing models were fixed to the corresponding values proposed in their corresponding papers (pre-tuned for the optimization oracle on a held-out develop- ment set). All the results reported in this paper are averaged over 10 runs of each experiment. <ref type="table">Table 5</ref>.3 reports test accuracies obtained on all the QA tasks, comparing the aforementioned pro- posals against corresponding models when cur- riculum learning is not used. We can observe from these results that variants of SPL (and E&amp;E) as well as the heuristics (and improvements) lead to improvements in the final test accuracy for both alignment-based models and QANTA.</p><p>The surprising ineffectiveness of the heuris- tics and SPL for memory networks essentially boils down to the abrupt restructure of mem- ory the model has to do for curriculum learn- ing. We provide support for this argument in <ref type="figure" target="#fig_2">Figure 2</ref> which plots the net relative change in all the parameters W until convergence for each of the four tasks on the model Ensemble+E&amp;E against the linear interpolant used to tune the ex- plore and exploit combination. As the interpolant grows from 0 to 1, more and more diverse ques- tions get selected. We can observe that the change in parameters decreases as more diverse questions are selected for all the four tasks. Furthermore, once we bring in diversity (change the interpolant from 0 to 0.1), the relative change in parameters drops sharply for both neural network approaches. The drop is sharpest for memory networks. Easier examples usually require less memory than hard examples. Memory networks have no incentive to utilize only a fraction of its state for easy exam- ples. They simply use the entire memory capacity. This implies that harder examples appearing later require a restructuring of all memory patterns. The network needs to change its memory representa- tion every time in order to free space and accom- modate the harder example. This process of mem- ory pattern restructuring is difficult to achieve, so it could be the reason for the relatively poor per- formance of naive curriculum learning and SPL strategies. However, as we can see from the pre- vious results, the explore and exploit strategy of mixing in some harder examples avoids the prob- lem of having to abruptly restructure memory pat- terns. The extra samples of all difficulties prevent the network from utilizing all the memory on the easy examples, thus eliminating the need to re- structure memory patterns. From <ref type="table">Table 5</ref>.3 , we can observe that the choice of the SP-regularizer is important. The soft regu- larizers perform better than the hard regularizer. The mixed regularizer (with mixture weighting) performs even better. We can also observe that all the heuristics work as well as SPL, despite being a lot simpler. The heuristics arranged in increas- ing order of performance are: CA, M 2 , ECiO, GO, CiO, FfDB and CiO-ECiO,. The differences be- tween the heuristics are larger for alignment-based models and smaller for deep learning models. The ECiO heuristic has very similar performance to SPL with hard SP-regularizer. This is understand- able as SPL also selects 'easy' questions based on their expected objective value. The Ensemble is a significant improvement over the individual heuristics. Importance weighting (IW) and the ex- plore and exploit strategies (E&amp;E) provide further improvements. E&amp;E is crucial to making curricu- lum learning work for deep learning approaches as described before. Motivated by the success of E&amp;E, we also extended it to SPL 5 by tuning a convex combination as before. E&amp;E provides im- provements across all the experiments for all the SPL experiments. While, the strategy is more im- portant for memory networks, it leads to improve- ments on all the tasks.</p><p>In order to understand the curriculum learning process and to test the hypothesis that the proce- dure indeed selects easy questions first, succes- sively moving on to harder questions, we plot the number of questions of grade 3, 4 and 5 picked by SPL, Ensemble and Ensemble+E&amp;E against the epoch number in <ref type="figure" target="#fig_4">Figure 3</ref>. We can observe that all the three methods pick more questions from grade 3 initially, successively moving on to more and more grade 4 questions and finally more grade 5 questions. Both Ensemble and Ensemble+E&amp;E are more aggressive at learning this curriculum than SPL. Ensemble becomes too aggressive so  E&amp;E, initially increases the number of grade 4 and grade 5 questions received by the learner, thereby incorporating diversity in learning. In order to further the claim that curriculum learning follows the principal of learning sim- pler concepts first and then learning successively harder and harder concepts, we plot the test accu- racy on grade 3, 4 and 5 questions with curriculum learning (CL) -i.e. Ensemble+E&amp;E and without curriculum learning (NC) against the epoch num- ber in <ref type="figure" target="#fig_5">Figure 4</ref>. Here, we can see that the test ac- curacy increases for questions in all three grade levels. With curriculum learning, the accuracy on grade 3 questions rises sharply in the beginning. This rise is sharper than the case when curricu- lum learning is not used. Grade 3 test accuracy for curriculum learning then saturates (saturates ear- lier compared to the case when curriculum learn- ing is not used). The improvements due to cur- riculum learning for grade 4 questions mainly oc- cur in epochs 30-140. The final epochs of cur- riculum learning see greater gain in test accuracy for grade 5 questions over the case when curricu- lum learning is not used. All these experiments together support the intuition of curriculum learn- ing. The models indeed pick and learn from easier questions first and successively learn from harder and harder questions. We also tried variants of our models where we used curriculum learning on grade 3 questions, followed by grade 4 and grade 5 questions. However, this did not lead to significant improvements. Perhaps, this is because questions that are easy for humans may not always corre- spond to what is easy for our algorithms. Char- acterizing what is easy for algorithms and how it relates to what is easy for humans is an interesting question for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Curriculum learning is inspired by the way hu- mans acquire knowledge and skills: by mastering simple concepts first, and progressing through in- formation with increasing difficulty to grasp more complex topics. We studied self-paced learning, an approach for curriculum learning that expresses the difficulty of a data sample in terms of the value of the objective function and builds the curriculum via a joint optimization framework. We proposed a number of heuristics, an ensemble, and several improvements for selecting the curriculum that improves upon self-paced learning. We stressed on another important aspect of human learning - diversity, that requires that the right curriculum should not only arrange the data samples in in- creasing order of difficulty but should also intro- duce the learner to a small number of samples that are sufficiently dissimilar to the samples that have already been introduced to the learning pro- cess. We showed that our heuristics when coupled with diversity lead to significant improvements in a number of question answering tasks. The ap- proach is quite general and we hope that this paper will encourage more NLP researchers to explore curriculum learning in their own works.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Alignment structure for an example question from the science QA dataset. The question and answer candidate are combined to generate a hypothesis sentence. Then alignments (shown by red lines) are found between the hypothesis and the appropriate snippet in the texts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>be estimated by retraining the model on Q 0 ∪ q i . 2) Change in Objective (CiO): Choose the question q i ∈ Q \ Q 0 that causes the smallest increase in the objective. If there are multiple questions with the smallest increase in objective, pick one of them randomly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relative change in parameters*10 −x where x = 2 for machine comprehension and science QA, 4 for QANTA and memory networks when CL is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Number of grade 3, 4 and 5 questions picked vs Epoch for various CL approaches for Science QA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Test split accuracy on grade 3, 4 and 5 questions picked vs Epoch for Science QA when CL is used/not used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Various SP-regularizers for SPL. 

</table></figure>

			<note place="foot" n="1"> Refer to Figure 1 in (Iyyer et al., 2014) for an example</note>

			<note place="foot" n="5"> This is different from Jiang et al. (2014c) which encourages diversity in samples across groups. On the other hand, we encourage diversity in feature space.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, along with Emmanouil A. Platanios and Snigdha Chaturvedi for their valuable comments and suggestions that helped improve the quality of this paper. This work was supported by the following research grants: NSF IIS1218282, NSF IIS1447676 and AFOSR FA95501010247.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The impact of ai on educationcan a robot get into the university of tokyo?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noriko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Arai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matsuzaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCE</title>
		<meeting>ICCE</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1034" to="1042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Importance weighted active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beygelzimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting>the 26th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Agnostic active learning without constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beygelzimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="199" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Dynamics of learning. Foster and Stewart publishing corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cantor</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1946" />
			<pubPlace>Buffalo, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">My computer is an honor student-but how intelligent is it? standardized tests as a measure of ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clark</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etzioni2016] Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AI Magazine</title>
		<meeting>AI Magazine</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization. The Journal of</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Duchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning and development in neural networks: The importance of starting small</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="99" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of todai robot project and evaluation framework of its nlp-based problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World History</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Modeling the effects of processing limitations on the acquisition of morphology: The less is more hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Goldowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">]</forename><forename type="middle">B N</forename><surname>Newport1993</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Goldowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th West Coast Conference on Formal Linguistics</title>
		<meeting>the 11th West Coast Conference on Formal Linguistics</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural network for factoid question answering over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iyyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Easy samples first: Self-paced reranking for zero-example multimedia search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Multimedia</title>
		<meeting>the ACM International Conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="547" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-paced learning with diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2078" to="2086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Self-paced learning with diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2078" to="2086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TwentyNinth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Self-paced curriculum learning</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How do humans teach: On curriculum learning and teaching dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Flexible shaping: How learning in small steps helps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="380" to="394" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning specific-class segmentation from diverse data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1800" to="1807" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV)</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to automatically solve algebra word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Yann LeCun, Yoshua Bengio, and Geoffrey Hinton</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning the easy things first: Self-paced visual category discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><surname>Grauman2011] Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1721" to="1728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maturational constraints on language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Elissa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="28" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A day of great illumination: Bf skinner&apos;s discovery of shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gail B Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Experimental Analysis of Behavior</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing</title>
		<meeting>Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning answer-entailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sachan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sachan</surname></persName>
		</author>
		<idno>abs/1602.04375</idno>
		<title level="m">Mrinmaya Sachan, Avinava Dubey, and Eric P. Xing. 2016. Science question answering using instructional materials. CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Less is more: Active learning with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Cohn2000</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International Conference on Machine Learning</title>
		<meeting>the 17th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Diagram understanding in geometry questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">11</biblScope>
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reinforcement today</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Burrhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Skinner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Self-paced learning for long-term tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Supancic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2379" to="2386" />
		</imprint>
	</monogr>
	<note>Supancic and Ramanan2013</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Shifting weights: Adapting object detectors from image to video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="638" to="646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koller2002] Simon</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Jason Weston, Sumit Chopra, and Antoine Bordes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno>abs/1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Yih et al.2013] Wentau Yih, Ming-Wei Chang, Christopher Meek, and Andrzej Pastusiak</editor>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Question answering using enhanced lexical semantic models</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning structural svms with latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachims2009] Chun-Nam</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">]</forename><forename type="middle">A L</forename><surname>Rangarajan2003</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">A self-paced multiple-instance learning framework for co-saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Self-paced learning for matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
