<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TMop: a Tool for Unsupervised Translation Memory Cleaning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masoud</forename><forename type="middle">Jalili</forename><surname>Sabet</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country>Iran, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country>Iran, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country>Iran, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><forename type="middle">G C</forename><surname>De Souza</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country>Iran, Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country>Iran, Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TMop: a Tool for Unsupervised Translation Memory Cleaning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="49" to="54"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present TMop, the first open-source tool for automatic Translation Memory (TM) cleaning. The tool implements a fully unsupervised approach to the task, which allows spotting unreliable translation units (sentence pairs in different languages , which are supposed to be translations of each other) without requiring labeled training data. TMop includes a highly configurable and extensible set of filters capturing different aspects of translation quality. It has been evaluated on a test set composed of 1,000 translation units (TUs) randomly extracted from the English-Italian version of MyMemory, a large-scale public TM. Results indicate its effectiveness in automatic removing &quot;bad&quot; TUs, with comparable performance to a state-of-the-art supervised method (76.3 vs. 77.7 balanced accuracy).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computer-assisted translation (CAT) refers to a framework in which the work of human translators is supported by machines. Its advantages, espe- cially in terms of productivity and translation con- sistency, have motivated huge investments both economic (by the translation industry) and intel- lectual (by the research community). Indeed, the high market potential of solutions geared to speed up the translation process and reduce its costs has attracted increasing interest from both sides.</p><p>Advanced CAT tools currently integrate the strengths of two complementary technologies: translation memories (TM -a high-precision mechanism for storing and retrieving previously translated segments) and machine translation (MT -a high-recall technology for translating unseen segments). The success of the integration has de- termined the quick growth of market shares that are held by CAT, as opposed to fully manual trans- lation that became a niche of the global transla- tion market. However, differently from MT that is constantly improving and reducing the distance from human translation, core TM technology has slightly changed over the years. This is in contrast with the fact that TMs are still more widely used than MT, especially in domains featuring high text repetitiveness (e.g. software manuals).</p><p>Translation memories have a long tradition in CAT, with a first proposal dating back to <ref type="bibr" target="#b0">(Arthern, 1979)</ref>. They consist of databases that store previously translated segments, together with the corresponding source text. Such (source, target) pairs, whose granularity can range from the phrase level to the sentence or even the paragraph level, are called translation units (TUs). When working with a CAT tool, each time a segment of a docu- ment to be translated matches with the source side of a TU, the corresponding target is proposed as a suggestion to the user. The user can also store each translated (source, target) pair in the TM for future use, thus increasing the size and the cover- age of the TM. Due to such constant growth, in which they evolve over time incorporating users style and terminology, the so-called private TMs represent an invaluable asset for individual trans- lators and translation companies. Collaboratively- created public TMs grow in a less controlled way but still remain a practical resource for the transla- tors' community at large.</p><p>The usefulness of TM suggestions mainly de- pends on two factors: the matching process and the quality of the TU. To increase recall, the re- trieval is based on computing a "fuzzy match" score. Depending on how the matching is per- formed, its output can be a mix of perfect and par- tial matches requiring variable amounts of correc-tions by the user. For this reason, most prior works on TM technology focused on improving this as- pect ( <ref type="bibr" target="#b9">Gupta et al., 2014;</ref><ref type="bibr" target="#b2">Bloodgood and Strauss, 2014;</ref><ref type="bibr" target="#b15">Vanallemeersch and Vandeghinste, 2015;</ref><ref type="bibr" target="#b7">Chatzitheodoroou, 2015;</ref><ref type="bibr" target="#b10">Gupta et al., 2015)</ref>.</p><p>The other relevant factor, TU quality, relates to the reliability of the target translations. Indeed, a perfectly matching source text associated to a wrong translation would make the corresponding suggestion useless or, even worse, an obstacle to productivity. On this aspect, prior research is lim- ited to the work proposed in ( <ref type="bibr" target="#b1">Barbu, 2015)</ref>, which so far represents the only attempt to automatically spot false translations in the bi-segments of a TM. However, casting the problem as a supervised bi- nary classification task, this approach highly de- pends on the availability of labelled training data.</p><p>Our work goes beyond the initial effort of Barbu (2015) in two ways. First, we propose a config- urable and extensible open source framework for TM cleaning. In this way, we address the de- mand of easy-to-use TM management tools whose development is out of the reach of individual trans- lators and translation companies. Such demand is not only justified by productivity reasons (remove bad suggestions as a cause of slow production), but also for usability reasons. Loading, searching and editing a TM are indeed time-consuming and resource-demanding operations. In case of very large databases (up to millions of TUs) the accu- rate removal of useless units can significantly in- crease usability. Though paid, the few existing tools that incorporate some data cleaning meth- ods (e.g. Apsic X-Bench 1 ) only implement very simple syntactic checks (e.g. repetitions, open- ing/closing tags consistency). These are insuffi- cient to capture the variety of errors that can be en- countered in a TM (especially in the public ones).</p><p>Second, our approach to TM cleaning is fully unsupervised. This is to cope with the lack of la- belled training data which, due to the high acqui- sition costs, represents a bottleneck rendering su- pervised solutions unpractical. It is worth remark- ing that also current approaches to tasks closely re- lated to TM cleaning (e.g. MT quality estimation ( <ref type="bibr" target="#b13">Mehdad et al., 2012;</ref><ref type="bibr" target="#b6">C. de Souza et al., 2014)</ref>) suffer from the same problem. Besides not being customised for the specificities of the TM clean- ing scenario (their usefulness for the task should be demonstrated), their dependence on labelled training data is a strong requirement from the TM cleaning application perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The TM cleaning task</head><p>The identification of "bad" TUs is a multifaceted problem. First, it deals with the recognition of a variety of errors. These include:</p><p>• Surface errors, such as opening/closing tags inconsistencies and empty or suspiciously long/short translations;</p><p>• Language inconsistencies, for instance due to the inversion between the source and target languages;</p><p>• Translation fluency issues, such as typos and grammatical errors (e.g. morpho-syntactic disagreements, wrong word ordering);</p><p>• Translation adequacy issues, such as the pres- ence of untranslated terms, wrong lexical choices or more complex phenomena (e.g. negation and quantification errors) for which a syntactically correct target can be a seman- tically poor translation of the source segment.</p><p>The severity of the errors is another aspect to take into account. Deciding if a given error makes a TU useless is often difficult even for humans. For instance, judging about the usefulness of a TU whose target side has missing/extra words would be a highly subjective task. <ref type="bibr">2</ref> For this reason, iden- tifying "bad" TUs with an automatic approach opens a number of problems related to: i) defining when a given issue becomes a real error (e.g. the ratio of acceptable missing words), ii) combining potentially contradictory evidence (e.g. syntactic and semantic issues), and iii) making these actions easily customisable by different users having dif- ferent needs, experience and quality standards.</p><p>What action to take when one or more errors are identified in a TU is also important. Ideally, a TM cleaning tool should allow users either to simply flag problematic TUs (leaving the final de- cision to a human judgment), or to automatically remove them without further human intervention.</p><p>Finally, two critical aspects are the external knowledge and resources required by the TM- cleaning process. On one side, collecting evidence for each TU can involve processing steps that ac- cess external data and tools. On the other side, decision making can require variable amounts of labelled training data (i.e. positive/negative exam- ples of "good"/"bad" TUs). For both tasks, the recourse to external support can be an advantage in terms of performance due to the possibility to get informed judgments taken from models trained in a supervised fashion. At the same time, it can be a limitation in terms of usability and portabil- ity across languages. When available, external re- sources and tools (e.g. syntactic/semantic parsers) can indeed be too slow to process huge amounts of data. Most importantly, labelled training data are usually difficult to acquire. In case of need, a TM cleaning tool should hence minimise the de- pendence of its performance from the availability of external resources.</p><p>All these aspects were considered in the design of TMop, whose capability to cope with a vari- ety of errors, customise its actions based on their severity and avoid the recourse to external knowl- edge/resources are described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The TMop framework</head><p>TMop <ref type="table">(Translation Memory open-source purifier)</ref> is an open-source TM cleaning software written in Python. It consists of three parts: core, filters and policy managers. The core, the main part of the software, manages the workflow between fil- ters, policy managers and input/output files. The filters ( §3.2) are responsible for detecting "bad" TUs. Each of them can detect a specific type of problems (e.g. formatting, fluency, adequacy) and will emit an accept or reject judgment for each TU. Policy managers ( §3.3) collect the individual results from each filter and take a final decision for each TM entry based on different possible strate- gies. Filters, policies and basic parameters can be set by means of a configuration file, which was structured by keeping ease of use and flexibility as the main design criteria.</p><p>TMop implements a fully unsupervised ap- proach to TM cleaning. The accept/reject criteria are learned from the TM itself and no training data are required to inform the process. 3 Nevertheless, the filters' output could be also used to instantiate feature vectors in any supervised learning scenario supported by training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Workflow</head><p>The input file of TMop is a TM represented as a text file containing one TU per line in the form (ID, source, target). The output consists of sev- eral files, the most important of which are the ac- cept and reject files containing the TUs identified as "good"/"bad", in the same format of the input. As depicted in <ref type="figure" target="#fig_0">Figure 1</ref>, TMop filters operate in two steps. In the first one, the learning step, each filter i iterates over the TM or a subset of it to gather the basic statistics needed to define its accept/reject criteria. For instance, by computing mean and standard deviation values for a given in- dicator (e.g. sentence length ratio, proportion of aligned words), quantiles or std counts in case of normal value distributions will be used as deci- sion boundaries. Then, in the decision step, each filter uses the gathered information to decide about each TU. At the end of this process, for each TU the policy manager collects all the decisions taken by the filters and applies the policy set by the user in the configuration file to assign an accept or reject judgment. The final labels, the TUs and the filters outputs are saved in different files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Filters</head><p>Our filters capture different aspects of the similar- ity between the source and the target of a TU. The full set consists of 23 filters, which are organized in four groups.</p><p>Basic filters (8 in total). This group (B) ex- tends the filters proposed by <ref type="bibr" target="#b1">Barbu (2015)</ref> and substantially covers those offered by commercial TM cleaning tools. They capture translation qual- ity by looking at surface aspects, such as the pos- sible mismatches in the number of dates, numbers, URLs, XML tags, ref and image tags present in the source and target segments. Other filters model the similarity between source and target by computing the direct and inverse ratio between the number of characters and words, as well as the average word length in the two segments. Finally, two filters look for uncommon character or word repetitions.</p><p>Language identification filter (1). This filter (LI) exploits the Langid tool ( <ref type="bibr">Lui and Baldwin, 2012)</ref> to verify the consistency between the source and target languages of a TU and those indicated in the TM. Though simple, it is quite effective since often the two languages are inverted or even completely different from the expected ones.</p><p>QE-derived filters (9). This group (QE) con- tains filters borrowed from the closely-related task of MT quality estimation, in which the complex- ity of the source, the fluency of the target and the adequacy between source and target are modeled as quality indicators. Focusing on the adequacy aspect, we exploit a subset of the features pro- posed by C. de <ref type="bibr" target="#b5">Souza et al. (2013)</ref>. They use word alignment information to link source and target words and capture the quantity of meaning pre- served by the translation. For each segment of a TU, word alignment information is used to calcu- late: i) the proportion of aligned and unaligned word n-grams (n=1,2), ii) the ratio between the longest aligned/unaligned word sequence and the length of the segment, iii) the average length of the aligned/unaligned word sequences, and iv) the position of the first/last unaligned word, normal- ized by the length of the segment. Word alignment models can be trained on the whole TM with one of the many existing word aligners. For instance, the results of WE filters reported in §4 were ob- tained using MGIZA++ ( <ref type="bibr" target="#b8">Gao and Vogel, 2008)</ref>.</p><p>Word embedding filters (5). Cross-lingual word embeddings provide a common vector rep- resentation for words in different languages and allow looking at the source and target segments at the same time. In TMop, they are computed us- ing the method proposed in ( <ref type="bibr">Søgaard et al., 2015)</ref> but, instead of considering bilingual documents as atomic concepts to bridge the two languages, they exploit the TUs contained in the TM itself. Given a TU and a 100-dimensional vector repre- sentation of each word in the source and target segments, this group of filters (WE) includes: i) the cosine similarity between the source and tar- get segment vectors obtained by averaging (or us- ing the median) the source and target word vec- tors; ii) the average embedding alignment score obtained by computing the cosine similarity be- tween each source word and all the target words and averaging over the largest cosine score of each source word; iii) the average cosine similarity be- tween source/target word alignments; iv) a score that merges features (ii) and (iii) by complement- ing word alignments (also in this case obtained us- ing MGIZA++) with the alignments obtained from word embedding and averaging all the alignment weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Policies</head><p>Decision policies allow TMop combining the out- put of the active filters into a final decision for each TU. Simple decision-making strategies can con- sider the number of accept and reject judgments, but more complex methods can be easily imple- mented by the user (both filters and policy man- agers can be easily modified and extended by ex- ploiting well-documented abstract base classes). TMop currently implements three policies: OneNo, 20%No and MajorityVoting. The first one copies a TU in the reject file if at least one filter rejects it. The second and the third policy take this decision only if at least twenty or fifty percent of the filters reject the TU respectively.</p><p>These three policies reflect different TM clean- ing strategies. The first one is a very aggressive (recall-oriented) solution that tends to flag more TUs as "bad". The third one is a more conser- vative (precision-oriented) solution, as it requires at least half of the judgments to be negative for pushing a TU in the reject file. Depending on the user needs and the overall quality of the TM, the choice of the policy will allow keeping under con- trol the number of false positives ("bad" TUs ac- cepted) and false negatives ("good" TUs rejected).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Benchmarking</head><p>We test TMop on the English-Italian version of MyMemory, 4 one of the world's largest collabo- rative public TMs. This dump contains about 11M TUs coming from heterogeneous sources: aggre- gated private TMs, either provided by translators or automatically extracted from the web/corpora, as well as anonymous contributions of (source, target) bi-segments. Its uncontrolled sources call for accurate cleaning methods (e.g. to make it more accurate, smaller and manageable).</p><p>From the TM we randomly extracted a subset of 1M TUs to compute the statistics of each filter and a collection of 2,500 TUs manually annotated with binary labels. Data annotation was done by two Italian native speakers properly trained with the same guidelines prepared by the TM owner for periodic manual revisions. After agreement com- putation (Cohen's kappa is 0.78), a reconciliation ended up with about 65% positive and 35% nega- tive examples. This pool is randomly split in two parts. One (1,000 instances) is used as test set for our evaluation. The other (1,500 instances) is used to replicate the supervised approach of <ref type="bibr" target="#b1">Barbu (2015)</ref>, which leverages human-labelled data to train an SVM binary classifier. We use it as a term of comparison to assess the performance of the different groups of filters.</p><p>To handle the imbalanced (65%-35%) data dis- tribution, and equally reward the correct classifi- cation on both classes, we evaluate performance in terms of balanced accuracy (BA), computed as the average of the accuracies on the two classes ( <ref type="bibr" target="#b3">Brodersen et al., 2010</ref>).</p><p>In <ref type="table">Table 1</ref>, different combinations of the four groups of filters are shown with results aggregated with the 20%No policy, which, on this data, re- sults to be the best performing policy among the ones implemented in TMop. Based on the statis- tics collected in the learning phase of each filter, the accept/reject criterion applied in these experiments considers as "good" all the TUs for 4 http://mymemory.translated.net  which the filter value is below one standard devia- tion from the mean and "bad" otherwise.</p><p>Looking at the results, it is worth noting that the LI, QE and WE groups, both alone and in combi- nation, outperform the basic filters (B), which sub- stantially represent those implemented by com- mercial tools. Although relying on an external component (the word aligner), QE filters produce the best performance in isolation, showing that word alignment information is a good indicator of translation quality. The results obtained by com- bining the different groups confirm their comple- mentarity. In particular, when using all the groups, the performance is close to the results achieved by the supervised method by <ref type="bibr" target="#b1">Barbu (2015)</ref>, which re- lies on human-labelled data <ref type="bibr">(76.3 vs. 77.7)</ref>.</p><p>The choice of which filter combination to use strongly depends on the application scenario and it is often a trade-off. A first important aspect concerns the type of user. When the expertise to train a word aligner is not available, combining B, WE and LI is the best solution, though it comes at the cost of lower accuracy. Another aspect is the processing time that the user can afford. TM cleaning is an operation conceived to be performed once in a while (possibly overnight), once the TM has grown enough to justify a new sanity check. However, although it does not require real-time processing, the size of the TM can motivate the selection of faster filter combinations. An analy- sis of the efficiency of the four groups, made by counting the number of processed TUs per sec- ond, <ref type="bibr">5</ref> indicates that B and QE are the fastest filters (processing on average ∼2,000 TUs/sec.). The LI filter is slower, processing ∼300 TUs per second, while the large number of times the cosine similar- ity score is computed does not allow the WE filter to process more than 50 TUs per second.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: TMop workflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Filters</head><label></label><figDesc></figDesc></figure>

			<note place="foot" n="1"> http://www.xbench.net/</note>

			<note place="foot" n="2"> Likely, the perceived severity of a missing word out of n perfectly translated terms will be inversely proportional to n.</note>

			<note place="foot" n="3"> The tool has been recently used also in the unsupervised approach by Jalili Sabet et al. (2016).</note>

			<note place="foot" n="5"> Conclusion We presented TMop, the first open-source tool for automatic Translation Memory (TM) cleaning. We summarised its design criteria, workflow and main components, also reporting some efficiency and performance indicators. TMop is implemented in Python and can be downloaded, together with complete documentation, from https://github.com/hlt-mt/TMOP. Its license is FreeBSD, a very open permissive noncopyleft license, compatible with the GNU GPL and with any use, including commercial.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been partially supported by the EC-funded project ModernMT (H2020 grant agree-ment no. 645487). The work carried out at FBK by Masoud Jalili Sabet was sponsored by the EAMT summer internships 2015 program and supported by Prof. Heshaam Faili (University of Tehran). The authors would also like to thank Translated for providing a dump of MyMemory.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Machine Translation and Computerized Terminology Systems: a Translator&apos;s Viewpoint. In Translating and the computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter Arthern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of a seminar</title>
		<meeting>of a seminar<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1979" />
			<biblScope unit="page" from="77" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spotting False Translation Segments in Translation Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Barbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop Natural Language Processing for Translation Memories</title>
		<meeting>of the Workshop Natural Language essing for Translation Memories<address><addrLine>Hissar, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translation Memory Retrieval Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bloodgood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Strauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th Conference of the EACL</title>
		<meeting>of the 14th Conference of the EACL<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="202" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Balanced Accuracy and Its Posterior Distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kay</forename><surname>Henning Brodersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><forename type="middle">Soon</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaas</forename><forename type="middle">Enno</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 2010 20th International Conference on Pattern Recognition, ICPR &apos;10</title>
		<meeting>of the 2010 20th International Conference on Pattern Recognition, ICPR &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3121" to="3124" />
		</imprint>
	</monogr>
	<note>5 Experiments were run with a PC with an Intel Core i5</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">M540 @ 2.53GHz and 6 GB RAM</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">FBK-UEdin Participation to the WMT13 Quality Estimation Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>of the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="352" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">FBK-UPV-UEdin Participation in the WMT14 Quality Estimation Shared-task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>González-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Negri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>of the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="322" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving Translation Memory Fuzzy Matching by Paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Chatzitheodoroou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop Natural Language Processing for Translation Memories</title>
		<meeting>of the Workshop Natural Language essing for Translation Memories<address><addrLine>Hissar, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="24" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Parallel Implementations of Word Alignment Tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL 2008 Software Engineering, Testing, and Quality Assurance Workshop</title>
		<meeting>of the ACL 2008 Software Engineering, Testing, and Quality Assurance Workshop</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Intelligent Translation Memory Matching and Retrieval Metric Exploiting Linguistic Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><surname>Bechara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Translating and the Computer</title>
		<meeting>of Translating and the Computer</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="86" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Can Translation Memories afford not to use paraphrasing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Vela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 18th Annual Conference of the European Association for Machine Translation</title>
		<meeting>of the 18th Annual Conference of the European Association for Machine Translation<address><addrLine>Antalya, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="35" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An Unsupervised Method for Automatic Translation Memory Cleaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masoud Jalili</forename><surname>Sabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Barbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">2012. langid.py: An Off-the-shelf Language Identification Tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL 2012 system demonstrations</title>
		<meeting>of the ACL 2012 system demonstrations</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Match without a Referee: Evaluating MT Adequacy without Reference Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Machine Translation Workshop (WMT2012)</title>
		<meeting>of the Machine Translation Workshop (WMT2012)<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inverted indexing for cross-lingual NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Héctor Martínez</forename><surname>Zeljko Agi´cagi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johannsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 53rd Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Assessing Linguistically Aware Fuzzy Matching in Translation Memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Vanallemeersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vandeghinste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 18th Annual Conference of the European Association for Machine Translation</title>
		<meeting>of the 18th Annual Conference of the European Association for Machine Translation<address><addrLine>Antalya, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
