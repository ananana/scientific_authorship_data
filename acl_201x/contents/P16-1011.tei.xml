<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University East Lansing</orgName>
								<address>
									<postCode>48824</postCode>
									<region>Michigan</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University East Lansing</orgName>
								<address>
									<postCode>48824</postCode>
									<region>Michigan</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incremental Acquisition of Verb Hypothesis Space towards Physical World Interaction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="108" to="117"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands and to learn new actions from human language instructions. To address this issue, this paper presents an approach that explicitly represents verb semantics through hypothesis spaces of fluents and automatically acquires these hypothesis spaces by interacting with humans. The learned hypothesis spaces can be used to automatically plan for lower-level primitive actions towards physical world interaction. Our empirical results have shown that the representation of a hypothesis space of flu-ents, combined with the learned hypothesis selection algorithm, outperforms a previous baseline. In addition, our approach applies incremental learning, which can contribute to lifelong learning from humans in the future.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a new generation of cognitive robots start to enter our lives, it is important to enable robots to follow human commands <ref type="bibr" target="#b25">(Tellex et al., 2014;</ref><ref type="bibr" target="#b26">Thomason et al., 2015)</ref> and to learn new actions from human language instructions <ref type="bibr" target="#b1">(Cantrell et al., 2012;</ref><ref type="bibr" target="#b16">Mohan et al., 2013)</ref>. To achieve such a capability, one of the fundamental challenges is to link higher-level concepts expressed by human language to lower-level primitive actions the robot is familiar with. While grounding language to perception <ref type="bibr" target="#b6">(Gorniak and Roy, 2007;</ref><ref type="bibr" target="#b2">Chen and Mooney, 2011;</ref><ref type="bibr" target="#b10">Kim and Mooney, 2012;</ref><ref type="bibr" target="#b0">Artzi and Zettlemoyer, 2013;</ref><ref type="bibr" target="#b25">Tellex et al., 2014;</ref><ref type="bibr" target="#b13">Liu et al., 2014</ref>; <ref type="bibr" target="#b12">Liu and Chai, 2015)</ref> has received much at- tention in recent years, less work has addressed grounding language to robotic action. Actions are often expressed by verbs or verb phrases. Most semantic representations for verbs are based on ar- gument frames (e.g., thematic roles which capture participants of an action). For example, suppose a human directs a robot to "fill the cup with milk". The robot will need to first create a semantic rep- resentation for the verb "fill" where "the cup" and "milk" are grounded to the respective objects in the environment ( . Suppose the robot is successful in this first step, it still may not be able to execute the action "fill" as it does not know how this higher-level action corresponds to its lower-level primitive actions.</p><p>In robotic systems, operations usually consist of multiple segments of lower-level primitive actions (e.g., move to, open gripper, and close gripper) which are executed both sequentially and con- currently. Task scheduling provides the order or schedule for executions of different segments of actions and action planning provides the plan for executing each individual segment. Primitive ac- tions are often predefined in terms of how they change the state of the physical world. Given a goal, task scheduling and action planning will derive a sequence of primitive actions that can change the initial environment to the goal state. The goal state of the physical world becomes a driving force for robot actions. Thus, beyond se- mantic frames, modeling verb semantics through their effects on the state of the world may provide a link to connect higher-level language and lower- level primitive actions.</p><p>Motivated by this perspective, we have devel- oped an approach where each verb is explicitly represented by a hypothesis space of fluents (i.e., desired goal states) of the physical world, which is incrementally acquired and updated through inter- acting with humans. More specifically, given a hu- man command, if there is no knowledge about the corresponding verb (i.e., no existing hypothesis space for that verb), the robot will initiate a learn- ing process by asking human partners to demon- strate the sequence of actions that is necessary to accomplish this command. Based on this demon- stration, a hypothesis space of fluents for that verb frame will be automatically acquired. If there is an existing hypothesis space for the verb, the robot will select the best hypothesis that is most rele- vant to the current situation and plan for the se- quence of lower-level actions. Based on the out- come of the actions (e.g., whether it has success- fully executed the command), the corresponding hypothesis space will be updated. Through this fashion, a hypothesis space for each encountered verb frame is incrementally acquired and updated through continuous interactions with human part- ners. In this paper, to focus our effort on repre- sentations and learning algorithms, we adopted an existing benchmark dataset ( <ref type="bibr" target="#b15">Misra et al., 2015)</ref> to simulate the incremental learning process and in- teraction with humans.</p><p>Compared to previous works <ref type="bibr" target="#b22">(She et al., 2014b;</ref><ref type="bibr" target="#b15">Misra et al., 2015)</ref>, our approach has three unique characteristics. First, rather than a single goal state associated with a verb, our approach captures a space of hypotheses which can potentially account for a wider range of novel situations when the verb is applied. Second, given a new situation, our approach can automatically identify the best hy- pothesis that fits the current situation and plan for lower-level actions accordingly. Third, through in- cremental learning and acquisition, our approach has a potential to contribute to life-long learning from humans. This paper provides details on the hypothesis space representation, the induction and inference algorithms, as well as experiments and evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work here is motivated by previous linguistic studies on verbs, action modeling in AI, and recent advances in grounding language to actions.</p><p>Previous linguistic studies <ref type="bibr" target="#b7">(Hovav and Levin, 2008;</ref><ref type="bibr" target="#b8">Hovav and Levin, 2010)</ref> propose action verbs can be divided into two types: manner verbs that "specify as part of their meaning a man- ner of carrying out an action" (e.g., nibble, rub, laugh, run, swim), and result verbs that "specify the coming about of a result state" (e.g., clean, cover, empty, fill, chop, cut, open, enter). Re- cent work has shown that explicitly modeling re- sulting change of state for action verbs can im- prove grounded language understanding ( . Motivated by these studies, this paper focuses on result verbs and uses hypothesis spaces to explicitly represent the result states associated with these verbs.</p><p>In AI literature on action modeling, action schemas are defined with preconditions and ef- fects. Thus, representing verb semantics for ac- tion verbs using resulting states can be connected to the agent's underlying planning modules. Dif- ferent from earlier works in the planning com- munity that learn action models from example plans <ref type="bibr" target="#b27">(Wang, 1995;</ref><ref type="bibr" target="#b28">Yang et al., 2007</ref>) and from interactions <ref type="bibr" target="#b5">(Gil, 1994)</ref>, our goal here is to explore the representation of verb semantics and its acqui- sition through language and action.</p><p>There has been some work in the robotics com- munity to translate natural language to robotic operations ( <ref type="bibr" target="#b11">Kress-Gazit et al., 2007;</ref><ref type="bibr" target="#b9">Jia et al., 2014;</ref><ref type="bibr" target="#b23">Spangenberg and Henrich, 2015</ref>), but not for the purpose of learning new actions. To support action learning, previ- ously we have developed a system where the robot can acquire the meaning of a new verb (e.g., stack) by following human's step-by-step language in- structions ( <ref type="bibr" target="#b21">She et al., 2014a;</ref><ref type="bibr" target="#b22">She et al., 2014b)</ref>. By performing the actions at each step, the robot is able to acquire the desired goal state associ- ated with the new verb. Our empirical results have shown that representing acquired verbs by resulting states allow the robot to plan for prim- itive actions in novel situations. Moreover, recent work ( <ref type="bibr" target="#b14">Misra et al., 2014;</ref><ref type="bibr" target="#b15">Misra et al., 2015)</ref> has presented an algorithm for grounding higher-level commands such as "microwave the cup" to lower- level robot operations, where each verb lexicon is represented as the desired resulting states. Their empirical evaluations once again have shown the advantage of representing verbs as desired states in robotic systems. Different from these previous works, we represent verb semantics through a hy- pothesis space of fluents (rather than a single hy- pothesis). In addition, we present an incremen- tal learning approach for inducing the hypothesis space and selecting the best hypothesis. command L i (e.g. "fill the cup with water.") and an environment E i (e.g. a simulated environment shown in <ref type="figure" target="#fig_0">Figure 1</ref>), the goal is to identify a se- quence of lower-level robotic actions to perform the command. Similar to previous works ( <ref type="bibr" target="#b18">Pasula et al., 2007;</ref><ref type="bibr" target="#b17">Mouro et al., 2012)</ref>, the environment E i is represented by a conjunction of grounded state fluents, where each fluent describes either the property of an object or relations (e.g. spa- tial) between objects. The language command L i is first translated to an intermediate representation of grounded verb frame v i through semantic pars- ing and referential grounding (e.g. for "fill the cup", the argument the cup is grounded to Cup1 in the scene). The system knowledge of each verb frame (e.g., fill(x)) is represented by a Hy- pothesis Space H, where each hypothesis (i.e. a node) is a description of possible fluents -or, in other words, resulting states -that are attributed to executing the verb command. Given a verb frame v i and an environment E i , a Hypothesis Selector will choose an optimal hypothesis from space H to describe the expected resulting state of execut- ing v i in E i . Given this goal state and the cur- rent environment, a symbolic planner such as the STRIPS planner <ref type="bibr" target="#b3">(Fikes and Nilsson, 1971</ref>) is used to generate an action sequence for the agent to ex- ecute. If the action sequence correctly performs the command (e.g. as evaluated by a human part- ner), the hypothesis selector will be updated with the success of its prediction. On the other hand, if the action has never been encountered (i.e., the system has no knowledge about this verb and thus the corresponding space is empty) or the predicted action sequence is incorrect, the human partner will provide an action sequence A i that can cor- rectly perform command v i in the current environ- ment. Using A i as the ground truth information, the system will not only update the hypothesis se- lector, but will also update the existing space of v i . The updated hypothesis space is treated as sys- tem knowledge of v i , which will be used in future interaction. Through this procedure, a hypothe- sis space for each verb frame v i is continually and incrementally updated through human-robot inter- action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">State Hypothesis Space</head><p>To bridge human language and robotic actions, previous works have studied representing the se- mantics of a verb with a single resulting state <ref type="bibr" target="#b22">(She et al., 2014b;</ref><ref type="bibr" target="#b15">Misra et al., 2015)</ref>. One problem of this representation is that when the verb is ap- plied in a new situation, if any part of the result- ing state cannot be satisfied, the symbolic planner will not be able to generate a plan for lower-level actions to execute this verb command. The plan- ner is also not able to determine whether the failed part of state representation is even necessary. In fact, this effect is similar to the over-fitting prob- lem. For example, given a sequence of actions of performing fill(x), the induced hypothe- sis could be "Has(x, W ater) be applicable. Nevertheless, the first two terms Has(x, W ater) ∧ Grasping(x) may already be sufficient to generate a plan for completing the verb command.</p><formula xml:id="formula_0">∧ Grasping(x) ∧ In(x, o 1 ) ∧ ¬(On(x, o 2 ))",</formula><p>To handle this over-fitting problem, we propose a hierarchical hypothesis space to represent verb semantics, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. The space is or- ganized based on a specific-to-general hierarchi- cal structure. Formally, a hypothesis space H for a verb frame is defined as: N, E, where each n i ∈ N is a hypothesis node and each e ij ∈ E is a directed edge pointing from parent n i to child n j , meaning node n j is more general than n i and has one less constraint.</p><p>In <ref type="figure" target="#fig_1">Figure 2</ref>, the bottom hypothesis (n 1 ) is Has(x, W ater) ∧ Grasping(x) ∧ In(x, o1) ∧ ¬(On(x, o2)). A hypothesis n i represents a con- junction of parameterized state fluents l k :</p><formula xml:id="formula_1">n i := ∧ l k , and l k := [¬] pred k (x k 1 [, x k 2 ])</formula><p>A fluent l k is composed of a predicate (e.g. object status: Has, or spatial relation: On) and a set of argument variables. It can be positive or negative. Take the bottom node in <ref type="figure" target="#fig_1">Figure 2</ref> as an example, it contains four fluents including one negative term (i.e. ¬(On(x, o 2 ))) and three positive terms. Dur- ing inference, the parameters will be grounded to the environment to check whether this hypothesis is applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Hypothesis Space Induction</head><p>Given an initial environment E i , a language com- mand which contains the verb frame v i , and a cor- responding action sequence A i , {E i , v i , A i } forms a training instance for hypothesis space induction. First, based on different heuristics, a base hypoth- esis is generated by comparing the state difference between the final and the initial environment. Sec- ond, a hypothesis space H is induced on top of this Base Hypothesis in a bottom-up fashion. And dur- ing induction some nodes are pruned. Third, if the system has existing knowledge for the same verb frame (i.e. an existing hypothesis space H t for the same verb frame), this newly induced space will be merged with previous knowledge. Next we ex- plain each step in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Base Hypothesis Induction</head><p>One key concept in the space induction is the Base Hypothesis (e.g. the bottom node in <ref type="figure" target="#fig_1">Figure 2</ref>), which provides a foundation for building a space. As shown in <ref type="figure">Figure 3</ref>, given a verb frame v i and a working environment E i , the action sequence A i given by a human will change the initial en- vironment E i to a final environment E i . The state changes are highlighted in <ref type="figure">Figure 3</ref>. Suppose a state change can be described by n fluents. Then the first question is which of these n fluents should be included in the base hypothesis. To gain some understanding on what would be a good represen- tation, we applied different heuristics of choosing fluents to form a base hypothesis as shown in <ref type="figure">Fig- ure</ref> 3:</p><p>• H1 argonly : only includes the changed states associated with the argument objects speci- fied in the frame (e.g., in <ref type="figure">Figure 3</ref>, Kettle1 is the only argument).</p><p>• H2 manip : includes the changed states of all the objects that have been manipulated in the action sequence taught by the human.</p><p>• H3 argrelated : includes the changed states of all the objects related to the argument ob- jects in the final environment. An object o is considered as "related to" an argument ob- ject if there is a state fluent that includes both o and an argument object in one predicate.</p><p>(e.g. Stove is related to the argument object Kettle1 through On(Kettle1, Stove)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input: A Base Hypothesis h Initialization: Set initial space H : N, E with N:[h] and E:[ ], Set a set of temporary hypotheses T :[h] while T is not empty do</head><p>Pop an element t from T Generate children [t (0) ,...,t (k) ] from t by removing each single fluent</p><formula xml:id="formula_2">foreach i = 0 ... k do if t (i)</formula><note type="other">is consistent with t then Append t (i) to T ; Add t (i) to N if not already in; Add link t → t (i) to E if not already in; else Prune t (i) and any node that can be generalized from t (i) end end end Output: Hypothesis space H Algorithm 1: A single hypothesis space induc- tion algorithm. H is a space initialized with a base hypothesis and an empty set of links. T is a temporary container of candidate hypotheses.</note><p>• H4 all : includes all the fluents whose values are changed from E i to E i (e.g. all the four highlighted state fluents in E i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Single Space Induction</head><p>First we define the consistency between two hy- potheses:</p><p>Definition. Hypotheses h 1 and h 2 are consistent, if and only if the action sequence A 1 generated from a symbolic planner based on goal state h 1 is exactly the same as the action sequence A 2 gener- ated based on goal state h 2 .</p><p>Given a base hypothesis, the space induction process is a while-loop generalizing hypotheses in a bottom-up fashion, which stops when no hy- potheses can be further generalized. As shown in Algorithm 1, a hypothesis node t can firstly be generalized to a set of immediate children [t (0) ,...,t (k) ] by removing a single fluent from t. For example, the base hypothesis n 1 in <ref type="figure" target="#fig_1">Figure 2</ref> is composed of 4 fluents, such that 4 immediate children nodes can potentially be generated. If a child node t (i) is consistent with its parent t (i.e. determined based on the consistency defined pre- viously), node t (i) and a link t → t (i) are added to the space H. The node t (i) is also added to a temporary hypothesis container waiting to be fur- ther generalized. On the other hand, some children hypotheses can be inconsistent with their parents. For example, the gray node (n 2 ) in <ref type="figure" target="#fig_1">Figure 2</ref> is a child node that is inconsistent with its parent (n 1 ). As n 2 does not explicitly specify Has(x, W ater) as part of its goal state, the symbolic planner gen- erates less steps to achieve goal state n 2 than goal state n 1 . This implies that the semantics of achiev- ing n 2 may be different than those for achieving n 1 . Such hypotheses that are inconsistent with their parents are pruned. In addition, if t (i) is in- consistent with its parent t, any children of t (i) are also inconsistent with t (e.g. children of n 2 in <ref type="figure" target="#fig_1">Fig- ure 2</ref> are also gray nodes, meaning they are incon- sistent with the base hypothesis). Through prun- ing, the size of entire space can be greatly reduced.</p><p>In the resulting hypothesis space, every single hypothesis is consistent with the base hypothesis. By only keeping consistent hypotheses via prun- ing, we can remove fluents that are not representa- tive of the main goal associated with the verb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Space Merging</head><p>If the robot has existing knowledge (i.e. hypoth- esis space H t ) for a verb frame, the induced hy- pothesis space H from a new instance of the same verb will be merged with the existing space H t . Currently, a new space H t+1 is generated where the nodes of H t+1 are the union of H and H t , and links in H t+1 are generated by checking the parent-child relationship between nodes. In future work, more space merging operations will be ex- plored, and human feedback will be incorporated into the induction process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Hypothesis Selection</head><p>Hypothesis selection is applied when the agent in- tends to execute a command. Given a verb frame extracted from the language command, the agent will first select the best hypothesis (describing the goal state) from the existing knowledge base, and then apply a symbolic planner to generate an ac- tion sequence to achieve the goal. In our frame- work, the model of selecting the best hypothesis is incrementally learned throughout continuous in- teraction with humans. More specifically, given a correct action sequence (whether performed by the robot or provided by the human), a regression model is trained to capture the fitness of a hypoth- esis given a particular situation.</p><p>Inference: Given a verb frame v i and a working environment E i , the goal of inference is to esti- mate how well each hypothesis h k from a space H t describes the expected result of performing v i in E i . The best fit hypothesis will be used as the goal state to generate the action sequence. Specif- ically, the "goodness" of describing command v i with hypothesis h k in environment E i is formu- lated as follows:</p><formula xml:id="formula_3">f (h k | v i ; E i ; H t ) = W T · Φ(h k , v i , E i , H t ) (1)</formula><p>where Φ(h k , v i , E i , H t ) is a feature vector captur- ing multiple aspects of relations between h k , v i , E i and H t as shown in <ref type="table">Table 1</ref>; and W captures the weight associated with each feature. Exam- ple global features include whether the candidate goal h k is in the top level of entire space H t and whether h k has the highest frequency. Example local features include if most of the fluents in h k are already satisfied in current scene E i (as this h k is unlikely to be a desired goal state). The features also include whether the same verb frame v i has been performed in a similar scene during previous interactions, as the corresponding hypotheses in- duced during that experience are more likely to be relevant and are thus preferred.</p><p>Parameter Estimation: Given an action se- quence A i that illustrates how to correctly perform command v i in environment E i during interaction, the model weights will be incrementally updated with 1 :</p><formula xml:id="formula_4">W t+1 = W t − η(α ∂R(W t ) ∂W t + ∂L(J ki , f ki ) ∂W t )</formula><p>where f ki := f (h k |v i ; E i ; H t ) is defined in Equa- tion 1. J ki is the dependent variable the model should approximate, where J ki := J(s i , h k ) is the Jaccard Index (details in Section 7) between hy- pothesis h k and a set of changed states s i (i.e. the changed states of executing the illustration action sequence</p><formula xml:id="formula_5">A i in current environment). L(J ki , f ki )</formula><p>is a squared loss function. αR(W t ) is the penalty term, and η is the constant learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiment Setup</head><p>Dataset Description. To evaluate our approach, we applied the dataset made available by <ref type="bibr" target="#b15">(Misra et al., 2015)</ref>. To support incremental learning, each utterance from every original paragraph is ex- tracted so that each command/utterance only con- tains one verb and its arguments. The correspond- ing initial environment and an action sequence on candidate hypothesis h k and the space Ht 1. If h k belongs to the top level of Ht. 2. If h k has the highest frequency in Ht.</p><p>Features on h k and current situation Ei 3. Portion of fluents in h k that are already satisfied by Ei. 4. Portion of non-argument objects in h k . Examples of non-argument objects are o1 and o2 in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>Features on relations between a testing verb frame vi and previous interaction experience 5. Whether the same verb frame vi has been executed previously with the same argument objects. 6. Similarities between noun phrase descriptions used in current command and commands from interaction history. <ref type="table">Table 1</ref>: Current features used for incremental learning of the regression model. The first two are binary features and the rest are real-valued fea- tures.</p><p>taught by a human for each command are also ex- tracted. An example is shown in <ref type="figure">Figure 3</ref>, where L i is a language command, E i is the initial work- ing environment, and A i is a sequence of primitive actions to complete the command given by the hu- man. In the original data, some sentences are not aligned with any actions, and thus cannot be used for either the learning or the evaluation. Remov- ing these unaligned sentences resulted in a total of 991 data instances, including 165 different verb frames.</p><p>Among the 991 data instances, 793 were used for incremental learning (i.e., space induction and hypothesis selector learning). Specifically, given a command, if the robot correctly predicts an action sequence 2 , this correct prediction is used to update the hypothesis selector. Otherwise, the agent will require a correct action sequence from the human, which is used for hypothesis space induction as well as updating the hypothesis selector.</p><p>The hypothesis spaces and regression based se- lectors acquired at each run were evaluated on the other 20% (198) testing instances. Specifically, for each testing instance, the induced space and the hypothesis selector were applied to identify a de- sired goal state. Then a symbolic planner 3 was ap- plied to predict an action sequence A (p) based on this predicted goal state. We then compared A (p) with the ground truth action sequence A (g) using the following two metrics.</p><p>• IED (Instruction Edit Distance) measures similarity between the ground truth action se- quence A (g) and the predicted sequence A (p) . Specifically, the edit distance d between two action sequences A (g) and</p><formula xml:id="formula_6">A (p) is first cal- culated. Then d is rescaled as IED = 1 − d/max( A (g) , A (p)</formula><p>), such that IED ranges from 0 to 1 and a larger IED means the two sequences are more similar.</p><p>• SJI (State Jaccard Index). Because different action sequences could lead to a same goal state, we also use Jaccard Index to check the overlap between the changed states. Specif- ically, executing the ground truth action se- quence A (g) in the initial scene E i results in a final environment E i . Suppose the changed states between E i and E i is c (g) . For the pre- dicted action sequence, we can calculate an- other set of changed states c (p) . The Jac- card Index between c (g) and c (p) is evaluated, which also ranges from 0 to 1 and a larger SJI means the predicted state changes are more similar to the ground truth.</p><p>Configurations. We also compared the results of using the regression based selector to select a hypothesis (i.e., RegressionBased) with the fol- lowing different strategies for selecting the hy- pothesis:</p><p>• Misra2015: The state of the art system re- ported in ( <ref type="bibr" target="#b15">Misra et al., 2015</ref>) on the com- mand/utterance level evaluation 4 .</p><p>• MemoryBased: Given the induced space, only the base hypotheses h k s from each learning instances are used. Because these h k s don't have any relaxation, they represent purely learning from memorization.</p><p>• MostGeneral: In this case, only those hy- potheses from the top level of the hypothesis space are used, which contain the least num- ber of fluents. These nodes are the most re- laxed hypotheses in the space.</p><p>• MostFrequent: In this setting, the hypothe- ses that are most frequently observed in the learning instances are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Overall performance</head><p>The results of the overall performance across different configurations are shown in <ref type="figure" target="#fig_3">Figure 4</ref>. For both of the IED and SJI (i.e. <ref type="figure" target="#fig_3">Figure 4</ref>(a) and <ref type="figure" target="#fig_3">Figure 4</ref>(b)), the hypothesis spaces with the regression model based hypothesis selector al- ways achieve the best performance across different configurations, and outperforms the previous ap- proach ( <ref type="bibr" target="#b15">Misra et al., 2015)</ref>. For different base hy- pothesis induction strategies, the H4 all consider- ing all the changed states achieves the best perfor- mance across all configurations. This is because H4 all keeps all of the state change information compared with other heuristics. The performance of H2 manip is similar to H4 all . The reason is that, when all the manipulated objects are considered, the resulted set of changed states will cover most of the fluents in H4 all . On the other dimension,  the regression based hypothesis selector achieves the best performance and the MemoryBased strat- egy has the lowest performance. Results for Most- General and MostFrequent are between the regres- sion based selector and MemoryBased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Incremental Learning Results</head><p>Figure 5 presents the incremental learning results on the testing set. To better present the results, we show the performance based on each learning cy- cle of 40 instances. The averaged Jaccard Index (SJI) is reported. Specifically, <ref type="figure" target="#fig_5">Figure 5</ref>(a) shows the results of configurations comparing different base hypothesis induction heuristics using regres- sion model based hypothesis selection. After us- ing 200 out of 840 (23.8%) learning instances, all the four curves achieve more than 80% of the over- all performance. For example, for the heuristic H4 all , the final average Jaccard Index is 0.418. When 200 instances are used, the score is 0.340 (0.340/0.418≈81%). The same number holds for the other heuristics. After 200 instances, H4 all and H2 manip consistently achieve better perfor- mance than H1 argonly and H3 argrelated . This re- sult indicates that while change of states mostly af- fect the arguments of the verbs, other state changes in the environment cannot be ignored. Modeling them actually leads to better performance. Using H4 all for base hypothesis induction, <ref type="figure" target="#fig_5">Figure 5</ref>(b) shows the results of comparing different hypoth- esis selection strategies. The regression model based selector always outperforms other selection strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Results on Frequently Used Verb Frames</head><p>Beside overall evaluation, we have also taken a closer look at individual verb frames. Most of the verb frames in the data have a very low frequency, which cannot produce statistically significant re- sults. So we only selected verb frames with fre- quency larger than 40 in this evaluation. For each verb frame, 60% data are used for incremental learning and 40% are for testing. For each frame, a regression based selector is trained separately. The resulting SJI curves are shown in <ref type="figure" target="#fig_6">Figure 6</ref>.</p><p>As shown in <ref type="figure" target="#fig_6">Figure 6</ref>, all the four curves be- come steady after 8 learning instances are used. However, while some verb frames have final SJIs of more than 0.55 (i.e. take(x) and turn(x)), oth- ers have relatively lower results (e.g. results for put(x, y) are lower than 0.4). After examining the learning instances for put(x, y), we found these data are more noisy than the training data for other frames. One source of errors is the incorrect ob- ject grounding results. For example, a problematic training instance is "put the pillow on the couch", where the object grounding module cannot cor- rectly ground the "couch" to the target object. As a result, the changed states of the second argument (i.e. the "couch") are incorrectly identified, which leads to incorrect prediction of desired states dur- ing inference. Another common error source is from automated parsing of utterances. The action frames generated from the parsing results could be incorrect in the first place, which would contribute to a hypothesis space for a wrong frame. These different types of errors are difficult to be recog- nized by the system itself. This points to the fu- ture direction of involving humans in a dialogue to learn a more reliable hypothesis space for verb semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>This paper presents an incremental learning ap- proach that represents and acquires semantics of action verbs based on state changes of the envi- ronment. Specifically, we propose a hierarchical hypothesis space, where each node in the space describes a possible effect on the world from the verb. Given a language command, the induced hy- pothesis space, together with a learned hypothe- sis selector, can be applied by the agent to plan for lower-level actions. Our empirical results have demonstrated a significant improvement in perfor- mance compared to a previous leading approach. More importantly, as our approach is based on in- cremental learning, it can be potentially integrated in a dialogue system to support life-long learning from humans. Our future work will extend the current approach with dialogue modeling to learn more reliable hypothesis spaces of resulting states for verb semantics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An incremental process of verb acquisition (i.e. learning) and application (i.e. inference).</figDesc><graphic url="image-1.png" coords="3,72.00,62.81,226.77,116.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example hypothesis space for the verb frame fill(x). The bottom node captures the state changes after executing the fill command in the environment. Anchored by the bottom node, the hypothesis space is generated in a bottom-up fashion. Each node represents a potential goal state. The highlighted nodes are pruned during induction, as they are not consistent with the bottom node.</figDesc><graphic url="image-2.png" coords="3,307.28,62.81,222.24,141.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Features</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The overall performance on the testing set with different configurations in generating the base hypothesis and in hypothesis selection. Each configuration runs five times by randomly shuffling the order of learning instances, and the averaged performance is reported. The result from Misra2015 is shown as a line. Results that are statistically significant better than Misra2015 are marked with * (paired t-test, p&lt; 0.05).</figDesc><graphic url="image-5.png" coords="7,303.34,62.81,217.70,110.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>a) Use regression based selector to select hypothesis, and compare each base hypothesis induction heuristics. (b) Induce the base hypothesis with H4 all , and compare different hypothesis selection strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Incremental learning results. The spaces and regression models acquired at different incremental learning cycles are evaluated on testing set. The averaged Jaccard Index is reported.</figDesc><graphic url="image-8.png" coords="8,314.36,263.22,204.09,121.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Incremental evaluation for individual verb frames. Four frequently used verb frames are examined: place(x, y), put(x, y), take(x), and turn(x). X-axis is the number of incremental learning instances, and Y-axis is the averaged SJI computed with H4 all base hypothesis induction and regression based hypothesis selector.</figDesc></figure>

			<note place="foot" n="3"> An Incremental Learning Framework An overview of our incremental learning framework is shown in Figure 1. Given a language</note>

			<note place="foot" n="1"> The SGD regressor in the scikit-learn (Pedregosa et al., 2011) is used to perform the linear regression with L2 regularization.</note>

			<note place="foot" n="2"> Currently, a prediction is considered correct if the predicted result (c (p) ) is similar to a human labeled action sequence (c (g) ) (i.e., SJI(c (g) , c (p) ) &gt; 0.5). 3 The symbolic planner implemented by (Rintanen, 2012) was utilized to generate action sequences.</note>

			<note place="foot" n="4"> We applied the same system described in (Misra et al., 2015) to predict action sequences. The only difference is here we report the performance at the command level, not at the paragraph level.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by IIS-1208390 and IIS-1617682 from the National Science Founda-tion. The authors would like to thank Dipendra K. Misra and colleagues for providing the evalua-tion data, and the anonymous reviewers for valu-able comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tell me when and why to do it! run-time planner model updates via natural language instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cantrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schermerhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Benton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kambhampati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scheutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;12)</title>
		<meeting>the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI&apos;12)<address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-03" />
			<biblScope unit="page" from="471" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI2011)</title>
		<meeting>the 25th AAAI Conference on Artificial Intelligence (AAAI2011)<address><addrLine>San Francisco, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Strips: A new approach to the application of theorem proving to problem solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">J</forename><surname>Nilsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Joint Conference on Artificial Intelligence (IJCAI&apos;71)</title>
		<meeting>the 2nd International Joint Conference on Artificial Intelligence (IJCAI&apos;71)<address><addrLine>London, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="page" from="608" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Physical causality of action verbs in grounded language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Doering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning by experimentation: incremental refinement of incomplete planning domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yolanda</forename><surname>Gil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prococeedings of the Eleventh International Conference on Machine Learning (ICML&apos;94)</title>
		<meeting>oceedings of the Eleventh International Conference on Machine Learning (ICML&apos;94)<address><addrLine>New Brunswick, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="87" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Situated language understanding as filtering perceived affordances. Cognitive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gorniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="231" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Reflections on manner/result complementarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malka</forename><forename type="middle">Rappaport</forename><surname>Hovav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture notes</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malka</forename><forename type="middle">Rappaport</forename><surname>Hovav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
		<title level="m">Reflections on Manner / Result Complementarity. Lexical Semantics, Syntax, and Event Structure</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="21" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perceptive feedback for natural language control of robotic operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Robotics and Automation, ICRA 2014</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-05-31" />
			<biblScope unit="page" from="6673" to="6678" />
		</imprint>
	</monogr>
	<note>Rui Fang, and Lanbo She</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised pcfg induction for grounded language learning with highly ambiguous supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joohyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL &apos;12)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL &apos;12)<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="433" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">From structured english to robot motion. In Intelligent Robots and Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadas</forename><surname>Kress-Gazit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Georgios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George J</forename><surname>Fainekos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pappas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2717" to="2722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to mediate perceptual differences in situated humanrobot dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI&apos;15)</title>
		<meeting>the 29th AAAI Conference on Artificial Intelligence (AAAI&apos;15)<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2288" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic labeling for efficient referential grounding based on collaborative discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics ACL&apos;14</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics ACL&apos;14<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Tell me dave: Contextsensitive grounding of natural language to mobile manipulation instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Robotics: Science and Systems (RSS&apos;14)</title>
		<meeting>Robotics: Science and Systems (RSS&apos;14)<address><addrLine>Berkeley, US</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Environment-driven lexicon induction for high-level instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kejia</forename><surname>Dipendra Kumar Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing ACL-IJCNLP&apos;15</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing ACL-IJCNLP&apos;15<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="992" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A computational model for situated task learning with interactive instruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwali</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International conference on cognitive modeling (ICCM&apos;13)</title>
		<meeting>the International conference on cognitive modeling (ICCM&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning strips operators from noisy and incomplete observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Mouro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Petrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence (UAI&apos;12)</title>
		<meeting>the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence (UAI&apos;12)<address><addrLine>Catalina Island, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="614" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning symbolic models of stochastic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Hanna M Pasula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">Pack</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaelbling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="309" to="352" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Planning as satisfiability: Heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jussi</forename><surname>Rintanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="45" to="86" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Teaching robots new actions through natural language instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 23rd IEEE International Symposium on Robot and Human Interactive Communication</title>
		<meeting><address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="868" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Back to the blocks world: Learning new actions through situated human-robot dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lanbo</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)<address><addrLine>Philadelphia, PA, U.S.A.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Grounding of actions based on verbalized physical effects and manipulation primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spangenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on</title>
		<meeting><address><addrLine>Hamburg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="844" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Synthesizing manipulation sequences for under-specified tasks using unrolled markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS&apos;14)</title>
		<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2970" to="2977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning perceptually grounded word meanings from unaligned parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratiksha</forename><surname>Thaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="151" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language commands through human-robot dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 2015 International Joint Conference on Artificial Intelligence (IJCAI)<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1923" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning by observation and practice: An incremental approach for planning operator acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuemei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Machine Learning (ICML&apos;95)</title>
		<meeting>the Twelfth International Conference on Machine Learning (ICML&apos;95)<address><addrLine>Tahoe City, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="549" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning action models from plan examples using weighted max-sat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfei</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="107" to="143" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Grounded semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joyce</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;16)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;16)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
