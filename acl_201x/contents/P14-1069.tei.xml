<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
							<email>zgwang@brandeis.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Brandeis University Waltham</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
							<email>xuen@brandeis.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Brandeis University Waltham</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="733" to="742"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose three improvements to address the drawbacks of state-of-the-art transition-based constituent parsers. First, to resolve the error propagation problem of the traditional pipeline approach, we incorporate POS tagging into the syntactic parsing process. Second, to alleviate the negative influence of size differences among competing action sequences, we align parser states during beam-search decoding. Third, to enhance the power of parsing models, we enlarge the feature set with non-local features and semi-supervised word cluster features. Experimental results show that these modifications improve parsing performance significantly. Evaluated on the Chinese Tree-Bank (CTB), our final performance reaches 86.3% (F1) when trained on CTB 5.1, and 87.1% when trained on CTB 6.0, and these results outperform all state-of-the-art parsers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Constituent parsing is one of the most fundamen- tal tasks in Natural Language Processing (NLP). It seeks to uncover the underlying recursive phrase structure of sentences. Most of the state-of-the- art parsers are based on the PCFG paradigm and chart-based decoding algorithms <ref type="bibr" target="#b4">(Collins, 1999;</ref><ref type="bibr" target="#b1">Charniak, 2000;</ref><ref type="bibr" target="#b15">Petrov et al., 2006</ref>). Chart-based parsers perform exhaustive search with dynam- ic programming, which contributes to their high accuracy, but they also suffer from higher run- time complexity and can only exploit simple local structural information.</p><p>Transition-based constituent parsing <ref type="bibr" target="#b16">(Sagae and Lavie, 2005;</ref><ref type="bibr" target="#b18">Wang et al., 2006</ref>; <ref type="bibr" target="#b20">Zhang and Clark, 2009</ref>) is an attractive alternative. It utilizes a se- ries of deterministic shift-reduce decisions to con- struct syntactic trees. Therefore, it runs in linear time and can take advantage of arbitrarily complex structural features from already constructed sub- trees. The downside is that they only search a tiny fraction of the whole space and are therefore com- monly considered to be less accurate than chart- based parsers. Recent studies ( <ref type="bibr" target="#b22">Zhu et al., 2013;</ref> show, however, that this ap- proach can also achieve the state-of-the-art perfor- mance with improved training procedures and the use of additional source of information as features.</p><p>However, there is still room for improvemen- t for these state-of-the-art transition-based con- stituent parsers. First, POS tagging is typically performed separately as a preliminary step, and POS tagging errors will propagate to the parsing process. This problem is especially severe for lan- guages where the POS tagging accuracy is rela- tively low, and this is the case for Chinese where there are fewer contextual clues that can be used to inform the tagging process and some of the tagging decisions are actually influenced by the syntactic structure of the sentence. This creates a chicken and egg problem that needs to be ad- dressed when designing a parsing model. Second, due to the existence of unary rules in constituen- t trees, competing candidate parses often have d- ifferent number of actions, and this increases the disambiguation difficulty for the parsing model. Third, transition-based parsers have the freedom to define arbitrarily complex structural features, but this freedom has not fully been taken advan- tage of and most of the present approaches only use simple structural features.</p><p>In this paper, we address these drawbacks to improve the transition-based constituent parsing for Chinese. First, we integrate POS tagging in- to the parsing process and jointly optimize these two processes simultaneously. Because non-local syntactic information is now available to POS tag determination, the accuracy of POS tagging im- proves, and this will in turn improve parsing ac- curacy. Second, we propose a novel state align- ment strategy to align candidate parses with dif- ferent action sizes during beam-search decoding. With this strategy, parser states and their unary extensions are put into the same beam, therefore the parsing model could decide whether or not to use unary actions within local decision beam- s. Third, we take into account two groups of complex structural features that have not been previously used in transition-based parsing: non- local features <ref type="bibr" target="#b0">(Charniak and Johnson, 2005</ref>) and semi-supervised word cluster features ( <ref type="bibr" target="#b10">Koo et al., 2008)</ref>. With the help of the non-local features, our transition-based parsing system outperform- s all previous single systems in Chinese. After integrating semi-supervised word cluster features, the parsing accuracy is further improved to 86.3% when trained on CTB 5.1 and 87.1% when trained on CTB 6.0, and this is the best reported perfor- mance for Chinese.</p><p>The remainder of this paper is organized as fol- lows: Section 2 introduces the standard transition- based constituent parsing approach. Section 3 describes our three improvements to standard transition-based constituent parsing. We discuss and analyze the experimental results in Section 4. Section 5 discusses related work. Finally, we con- clude this paper in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Transition-based Constituent Parsing</head><p>This section describes the transition-based con- stituent parsing model, which is the basis of Sec- tion 3 and the baseline model in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transition-based Constituent Parsing Model</head><p>A transition-based constituent parsing model is a quadruple C = (S, T, s 0 , S t ), where S is a set of parser states (sometimes called configurations), T is a finite set of actions, s 0 is an initialization func- tion to map each input sentence into a unique ini- tial state, and S t ∈ S is a set of terminal states. Each action t ∈ T is a transition function to tran- sit a state into a new state. A parser state s ∈ S is defined as a tuple s = (σ, β), where σ is a stack which is maintained to hold partial subtrees that are already constructed, and β is a queue which is used for storing word-POS pairs that remain un- processed. In particular, the initial state has an  <ref type="table" target="#tab_2">(a)   B0,3   F2,3   c2,3   w2   E0,2   A0,2   D1,2   b1,2   w1   C0,1   a0,1   w0</ref> sh,ru-C,sh,ru-D,rr-A, ru-E,sh,ru-F,rl-B (b) <ref type="figure">Figure 1</ref>: Two constituent trees for an example sentence w 0 w 1 w 2 with POS tags abc. The cor- responding action sequences are given below, the spans of each nodes are annotated and the head n- odes are written with Bold font type.</p><p>empty stack σ and a queue β containing the entire input sentence (word-POS pairs), and the terminal states have an empty queue β and a stack σ con- taining only one complete parse tree. The task of transition-based constituent parsing is to scan the input POS-tagged sentence from left to right and perform a sequence of actions to transform the ini- tial state into a terminal state. In order to construct lexicalized constituen- t parse trees, we define the following actions for the action set T according to <ref type="bibr" target="#b16">(Sagae and Lavie, 2005;</ref><ref type="bibr" target="#b18">Wang et al., 2006;</ref><ref type="bibr" target="#b20">Zhang and Clark, 2009</ref>):</p><p>• SHIFT (sh): remove the first word-POS pair from β, and push it onto the top of σ;</p><p>• REDUCE-UNARY-X (ru-x): pop the top subtree from σ, construct a new unary node labeled with X for the subtree, then push the new subtree back onto σ. The head of the new subtree is inherited from its child;</p><p>• REDUCE-BINARY-{L/R}-X (rl/rr-x): pop the top two subtrees from σ, combine them into a new tree with a node labeled with X, then push the new subtree back onto σ. The left (L) and right (R) versions of the action indicate whether the head of the new subtree is inherited from its left or right child.</p><p>With these actions, our parser can process trees with unary and binary branches easily. For exam- ple, in <ref type="figure">Figure 1</ref>, for the input sentence w 0 w 1 w 2 and its POS tags abc, our parser can construct t- wo parse trees using action sequences given below these trees. However, parse trees in Treebanks of- ten contain an arbitrary number of branches. To Type Feature Templates unigrams p 0 tc, p 0 wc, p 1 tc, p 1 wc, p 2 tc p 2 wc, p 3 tc, p 3 wc, q 0 wt, q 1 wt q 2 wt, q 3 wt, p 0l wc, p 0r wc p 0u wc, p 1l wc, p 1r wc, p 1u wc bigrams p 0 wp 1 w, p 0 wp 1 c, p 0 cp 1 w, p 0 cp 1 c p 0 wq 0 w, p 0 wq 0 t, p 0 cq 0 w, p 0 cq 0 t q 0 wq 1 w, q 0 wq 1 t, q 0 tq 1 w, q 0 tq 1 t p 1 wq 0 w, p 1 wq 0 t, p 1 cq 0 w, p 1 cq 0 t trigrams p 0 cp 1 cp 2 c, p 0 wp 1 cp 2 c, p 0 cp 1 wq 0 t p 0 cp 1 cp 2 w, p 0 cp 1 cq 0 t, p 0 wp 1 cq 0 t p 0 cp 1 wq 0 t, p 0 cp 1 cq 0 w <ref type="table">Table 1</ref>: Baseline features, where p i represents the i th subtree in the stack σ and q i denotes the i th item in the queue β. w refers to the head lexicon, t refers to the head POS, and c refers to the con- stituent label. p il and p ir refer to the left and right child for a binary subtree p i , and p iu refers to the child of a unary subtree p i .</p><p>process such trees, we employ binarization and debinarization processes described in <ref type="bibr" target="#b20">Zhang and Clark (2009)</ref> to transform multi-branch trees into binary-branch trees and restore the generated bi- nary trees back to their original forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modeling, Training and Decoding</head><p>To determine which action t ∈ T should the parser perform at a state s ∈ S, we use a linear model to score each possible s, t combination:</p><formula xml:id="formula_0">score(s, t) = w · φ(s, t) = i w i f i (s, t) (1)</formula><p>where φ(s, t) is the feature function used for map- ping a state-action pair into a feature vector, and w is the weight vector. The score of a parser state s is the sum of the scores for all state-action pairs in the transition path from the initial state to the current state. <ref type="table">Table 1</ref> lists the feature templates used in our baseline parser, which is adopted from <ref type="bibr" target="#b20">Zhang and Clark (2009)</ref>. To train the weight vec- tor w, we employ the averaged perceptron algo- rithm with early update ( <ref type="bibr" target="#b3">Collins and Roark, 2004</ref>).</p><p>We employ the beam search decoding algorith- m ( <ref type="bibr" target="#b20">Zhang and Clark, 2009</ref>) to balance the trade- off between accuracy and efficiency. Algorithm 1 gives details of the process. In the algorithm, we maintain a beam (sometimes called agenda) to keep k best states at each step. The first beam 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Beam-search Constituent Parsing</head><p>Input: A POS-tagged sentence, beam size k. Output: A constituent parse tree.</p><p>1: beam 0 ← {s 0 } initialization 2: i ← 0 step index <ref type="bibr">3</ref> </p><formula xml:id="formula_1">i ← i + 1</formula><p>is initialized with the initial state s 0 (line 1). At step i, each of the k states in beam i is extended by applying all possible actions (line 5-10). For all newly generated states, only the k best states are preserved for beam i+1 (line 11). The decod- ing process repeats until the highest scored state in beam i+1 reaches a terminal state (line 12-14).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Joint POS Tagging and Parsing with Non-local Features</head><p>To address the drawbacks of the standard transition-based constituent parsing model (de- scribed in Section 1), we propose a model to joint- ly solve POS tagging and constituent parsing with non-local features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Joint POS Tagging and Parsing</head><p>POS tagging is often taken as a preliminary step for transition-based constituent parsing, therefore the accuracy of POS tagging would greatly affec- t parsing performance. In our experiment (de- scribed in Section 4.2), parsing accuracy would decrease by 8.5% in F 1 in Chinese parsing when using automatically generated POS tags instead of gold-standard ones. To tackle this issue, we inte- grate POS tagging into the transition-based con- stituent parsing process and jointly optimize these two processes simultaneously. Inspired from Ha- tori et al. <ref type="formula">(2011)</ref>, we modify the sh action by as- signing a POS tag for the word when it is shifted:</p><p>• SHIFT-X (sh-x): remove the first word from β, assign POS tag X to the word and push it onto the top of σ.</p><p>With such an action, POS tagging becomes a nat- ural part of transition-based parsing. However, some feature templates in <ref type="table">Table 1</ref> become unavail- able, because POS tags for the look-ahead words are not specified yet under the joint framework. For example, for the template q 0 wt , the POS tag of the first word q 0 in the queue β is required, but it is not specified yet at the present state.</p><p>To overcome the lack of look-ahead POS tags, we borrow the concept of delayed features origi- nally developed for dependency parsing <ref type="bibr" target="#b6">(Hatori et al., 2011)</ref>. Features that require look-ahead POS tags are defined as delayed features. In these fea- tures, look-ahead POS tags are taken as variables. During parsing, delayed features are extracted and passed from one state to the next state. When a sh-x action is performed, the look-ahead POS tag of some delayed features is specified, there- fore these delayed features can be transformed in- to normal features (by replacing variable with the newly specified POS tag). The remaining delayed features will be transformed similarly when their look-ahead POS tags are specified during the fol- lowing parsing steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">State Alignment</head><p>Assuming an input sentence contains n words, in order to reach a terminal state, the initial state re- quires n sh-x actions to consume all words in β, and n − 1 rl/rr-x actions to construct a com- plete parse tree by consuming all the subtrees in σ. However, ru-x is a very special action. It on- ly constructs a new unary node for the subtree on top of σ, but does not consume any items in σ or β. As a result, the number of ru-x actions varies among terminal states for the same sentence. For example, the parse tree in <ref type="figure">Figure 1a</ref> contains no ru-x action, while the parse tree for the same in- put sentence in <ref type="figure">Figure 1b</ref> contains four ru-x ac- tions. This makes the lengths of complete action sequences very different, and the parsing model has to disambiguate among terminal states with varying action sizes. <ref type="bibr" target="#b22">Zhu et al. (2013)</ref> proposed a padding method to align terminal states containing different number of actions. The idea is to append some IDLE actions to terminal states with shorter action sequence, and make sure all terminal states contain the same number of actions (including I- DLE actions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Beam-search with State Alignment</head><p>Input: A word-segmented sentence, beam size k. Output: A constituent parse tree.</p><p>1: beam 0 ← {s 0 } initialization 2: for i ← 0 to 2n − 1 do n is sentence length 3: P 0 ← {}, P 1 ← {} two priority queues</p><note type="other">4: while beam i is not empty do 5: s ← POP(beam i ) 6: for t ∈ {sh-x, rl-x, rr-x} do 7: s new ← apply t to s 8: score s new with E.q (1) 9: insert s new into P 0 10: for all state s in P 0 do 11: for all possible t ∈ {ru-x} do 12: s new ← apply t to s 13: score s new with E.q (1) 14: insert s new into P 1 15: insert all states of P 1 into P 0 16: beam i+1 ← k best states of P 0 17: return the best state in beam 2n−1</note><p>We propose a novel method to align states dur- ing the parsing process instead of just aligning ter- minal states like <ref type="bibr" target="#b22">Zhu et al. (2013)</ref>. We classify all the actions into two groups according to whether they consume items in σ or β. sh-x, rl-x, and rr-x belong to consuming actions, and ru-x be- longs to non-consuming action. Algorithm 2 gives the details of our method. It is based on the beam search decoding algorithm described in Algorith- m 1. Different from Algorithm 1, Algorithm 2 is guaranteed to perform 2n − 1 parsing steps for an input sentence containing n words (line 2), and divides each parsing step into two parsing phas- es. In the first phase (line 4-9), each of the k s- tates in beam i is extended by consuming action- s. In the second phase (line 10-14), each of the newly generated states is further extended by non- consuming actions. Then, all these states extend- ed by both consuming and non-consuming action- s are considered together (line 15), and only the k highest-scored states are preserved for beam i+1 (line 16). After these 2n − 1 parsing steps, the highest scored state in beam 2n−1 is returned as the final result (line 17). <ref type="figure" target="#fig_1">Figure 2</ref> shows the states aligning process for the two trees in <ref type="figure">Figure 1</ref>. We find that our new method aligns states with their ru-x extensions in the same beam, therefore the parsing model could make decisions on whether using ru-x actions or not within local decision  <ref type="figure">Figure 1</ref>. For clarity, we represent each state as a rectangle with the label of top subtree in the stack σ. We also denote sh-x with →, ru-x with ↑ or ↓, rl-x with , and rr-x with .</p><formula xml:id="formula_2">s 0 a 0,1 b 1,2 A 0,2 c 2,3 B 0,3 T 0 C 0,1 b 1,2 D 1,2 A 0,2 E 0,2 c 2,3 F 2,3</formula><p>beams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Feature Extension</head><p>One advantage of transition-based constituen- t parsing is that it is capable of incorporating ar- bitrarily complex structural features from the al- ready constructed subtrees in σ and unprocessed words in β. However, all the feature templates given in <ref type="table">Table 1</ref> are just some simple structural features. To further improve the performance of our transition-based constituent parser, we con- sider two group of complex structural features: non-local features <ref type="bibr" target="#b0">(Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b2">Collins and Koo, 2005</ref>) and semi-supervised word cluster features ( <ref type="bibr" target="#b10">Koo et al., 2008)</ref>. <ref type="table" target="#tab_2">Table 2</ref> lists all the non-local features we want to use. These features have been proved very help- ful for constituent parsing <ref type="bibr" target="#b0">(Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b2">Collins and Koo, 2005</ref>). But almost all pre- vious work considered non-local features only in parse reranking frameworks. Instead, we attempt to extract non-local features from newly construct- ed subtrees during the decoding process as they become incrementally available and score newly generated parser states with them. One difficul- ty is that the subtrees built by our baseline pars- er are binary trees (only the complete parse tree is debinarized into its original multi-branch form), but most of the non-local features need to be ex- tracted from their original multi-branch forms. To resolve this conflict, we integrate the debinariza- tion process into the parsing process, i.e., when a <ref type="bibr" target="#b2">(Collins and Koo, 2005</ref>) <ref type="bibr" target="#b0">(Charniak and Johnson, 2005</ref>  new subtree is constructed during parsing, we de- binarize it immediately if it is not rooted with an intermediate node <ref type="bibr">1</ref> . The other subtrees for sub- sequent parsing steps will be built based on these debinarized subtrees. After the modification, our parser can extract non-local features incrementally during the parsing process. Semi-supervised word cluster features have been successfully applied to many NLP tasks <ref type="bibr" target="#b13">(Miller et al., 2004;</ref><ref type="bibr" target="#b10">Koo et al., 2008;</ref><ref type="bibr" target="#b22">Zhu et al., 2013</ref>). Here, we adopt such features for our transition-based constituent parser. Given a large- scale unlabeled corpus (word segmentation should be performed), we employ the Brown cluster al- gorithm <ref type="bibr" target="#b12">(Liang, 2005</ref>) to cluster all words into a binary tree. Within this binary tree, words ap- pear as leaves, left branches are labeled with 0 and right branches are labeled with 1. Each word can be uniquely identified by its path from the root, and represented as a bit-string. By using various length of prefixes of the bit-string, we can produce word clusters of different granularities <ref type="bibr" target="#b13">(Miller et al., 2004</ref>). Inspired from <ref type="bibr" target="#b10">Koo et al. (2008)</ref>, we employ two types of word clusters: (1) taking 4 bit-string prefixes of word clusters as replacements of POS tags, and (2) taking 8 bit-string prefixes as replacements of words. Using these two types of clusters, we construct semi-supervised word clus- ter features by mimicking the template structure of the original baseline features in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setting</head><p>We conducted experiments on the Penn Chinese Treebank (CTB) version 5.1 ( <ref type="bibr" target="#b19">Xue et al., 2005</ref>): Articles 001-270 and 400-1151 were used as the training set, Articles 301-325 were used as the development set, and Articles 271-300 were used as the test set. Standard corpus preparation step- s were performed before our experiments: emp- ty nodes and functional tags were removed, and the unary chains were collapsed to single unary rules as <ref type="bibr" target="#b5">Harper and Huang (2011)</ref>. To build word clusters, we used the unlabeled Chinese Gigaword (LDC2003T09) and conducted Chinese word seg- mentation using a CRF-based segmenter.</p><p>We used EVALB 2 tool to evaluate parsing per- formance. The metrics include labeled precision (LP ), labeled recall (LR), bracketing F 1 and POS tagging accuracy. We set the beam size k to 16, which brings a good balance between efficiency and accuracy. We tuned the optimal number of iterations of perceptron training algorithm on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pipeline Approach vs Joint POS Tagging and Parsing</head><p>In this subsection, we conducted some experi- ments to illustrate the drawbacks of the pipeline approach and the advantages of our joint approach. We built three parsing systems: Pipeline-Gold system is our baseline parser (described in Sec- tion 2) taking gold-standard POS tags as input;</p><p>Pipeline system is our baseline parser taking as input POS tags automatically assigned by Stan- ford POS Tagger 3 ; and JointParsing system is our joint POS tagging and transition-based pars- ing system described in subsection 3.1. We trained these three systems on the training set and evalu- ated them on the development set. The second, third and forth rows in <ref type="table">Table 3</ref> show the parsing performances. We can see that the parsing F 1 de- creased by about 8.5 percentage points in F 1 score when using automatically assigned POS tags in- stead of gold-standard ones, and this shows that the pipeline approach is greatly affected by the quality of its preliminary POS tagging step. Af- ter integrating the POS tagging step into the pars- ing process, our JointParsing system improved the POS tagging accuracy to 94.8% and parsing F 1 to 85.8%, which are significantly better than the Pipeline system. Therefore, the joint parsing ap- proach is much more effective for transition-based constituent parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">State Alignment Evaluation</head><p>We built two new systems to verify the effective- ness of our state alignment strategy proposed in  <ref type="table">Table 3</ref>: Parsing performance on Chinese devel- opment set. Subsection 3.2. The first system Padding extend- s our JointParsing system by aligning terminal s- tates with the padding strategy proposed in <ref type="bibr" target="#b22">Zhu et al. (2013)</ref>, and the second system StateAlign ex- tends the JointParsing system with our state align- ment strategy. The fifth and sixth rows of <ref type="table">Table 3</ref> give the performances of these two systems. Com- pared with the JointParsing system which does not employ any alignment strategy, the Padding sys- tem only achieved a slight improvement on pars- ing F 1 score, but no improvement on POS tag- ging accuracy. In contrast, our StateAlign system achieved an improvement of 0.6% on parsing F 1 s- core and 0.4% on POS tagging accuracy. All these results show us that our state alignment strategy is more helpful for beam-search decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Feature Extension Evaluation</head><p>In this subsection, we examined the usefulness of the new non-local features and the semi- supervised word cluster features described in Sub- section 3.3. We built three new parsing system- s based on the StateAlign system: Nonlocal sys- tem extends the feature set of StateAlign system with non-local features, Cluster system extends the feature set with semi-supervised word cluster features, and Nonlocal&amp;Cluster system extend the feature set with both groups of features. Parsing performances of the three systems are shown in the last three rows of <ref type="table">Table 3</ref>. Compared with the StateAlign system which takes only the baseline features, the non-local features improved parsing F 1 by 0.8%, while the semi-supervised word clus- ter features result in an improvement of 2.3% in parsing F 1 and an 1.1% improvement on POS tag- ging accuracy. When integrating both groups of features, the final parsing F 1 reaches 89.1%. Al-  l these results show that both the non-local fea- tures and the semi-supervised features are helpful for our transition-based constituent parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Final Results on Test Set</head><p>In this subsection, we present the performances of our systems on the CTB test set. The correspond- ing results are listed in the top rows of <ref type="table" target="#tab_5">Table 4</ref>.</p><p>We can see that all these systems maintain a simi- lar relative relationship as they do on the develop- ment set, which shows the stability of our systems.</p><p>To further illustrate the effectiveness of our systems, we compare them with some state-of- the-art systems. We group parsing systems into three categories: single systems, reranking sys- tems and semi-supervised systems. Our Pipeline, JointParsing, Padding, StateAlign and Nonlocal systems belong to the category of single system- s, because they don't utilize any extra process- ing steps or resources. Our Cluster and Nonlo- cal&amp;Cluster systems belong to semi-supervised systems, because both of them have employed semi-supervised word cluster features. The pars- ing performances of state-of-the-art systems are shown in the bottom rows of <ref type="table" target="#tab_5">Table 4</ref>. We can see that the final F 1 of our Nonlocal system reached 84.9%, and it outperforms state-of-the-art single systems by more than 1.6%. As far as we know, this is the best result on the CTB test set acquired by single systems. Our Nonlocal&amp;Cluster sys- tem further improved the parsing F 1 to 86.3%, and it outperforms all reranking systems and semi- supervised systems. To our knowledge, this is the  best reported performance in Chinese parsing.</p><p>All previous experiments were conducted on CTB 5. To check whether more labeled data can further improve our parsing system, we evaluat- ed our Nonlocal&amp;Cluster system on the Chinese TreeBank version 6.0 (CTB6), which is a super set of CTB5 and contains more annotated data. We used the same development set and test set as CTB5, and took all the remaining data as the new training set. <ref type="table" target="#tab_7">Table 5</ref> shows the parsing per- formances on CTB6. Our Nonlocal&amp;Cluster sys- tem improved the final F 1 to 87.1%, which is 1.9% better than the state-of-the-art performance on CT- B6 ( <ref type="bibr" target="#b7">Huang and Harper, 2009</ref>). Compared with it- s performance on CTB5 (in <ref type="table" target="#tab_5">Table 4</ref>), our Nonlo- cal&amp;Cluster system also got 0.8% improvemen- t. All these results show that our approach can become more powerful when given more labeled training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Error Analysis</head><p>To better understand the linguistic behavior of our systems, we employed the berkeley-parser- analyser tool <ref type="bibr">4 (Kummerfeld et al., 2013</ref>) to cat- egorize the errors.   <ref type="table">Table 7</ref>: POS tagging error patterns on Chinese test set. For each error pattern, the left hand side tag is the gold-standard tag, and the right hand side is the wrongly assigned tag.</p><p>number of errors for each error type by our pars- ing systems. We can see that almost all the Worst numbers are produced by the Pipeline system. The JointParsing system reduced errors of all types produced by the Pipeline system except for the coordination error type (Coord). The StateAlign system corrected a lot of the NP-internal errors (NP Int.). The Nonlocal system and the Cluster system produced similar numbers of errors for al- l error types. The Nonlocal&amp;Cluster system pro- duced the Best numbers for all the error types. NP- internal errors are still the most frequent error type in our parsing systems. <ref type="table">Table 7</ref> presents the statistics of frequent POS tagging error patterns. We can see that JointPars- ing system disambiguates {VV, NN} and {DEC, DEG} better than Pipeline system, but cannot deal with the NN→JJ pattern very well. StateAlign system got better results in most of the patterns, but cannot disambiguate {NR, NN} well. Non- local&amp;Cluster system got the best results in dis- ambiguating the most ambiguous POS tag pairs of {VV, NN}, {DEC, DEG}, {JJ, NN} and {NN, N- R}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Joint POS tagging with parsing is not a new idea. In PCFG-based parsing <ref type="bibr" target="#b4">(Collins, 1999;</ref><ref type="bibr" target="#b1">Charniak, 2000;</ref><ref type="bibr" target="#b15">Petrov et al., 2006</ref>), POS tagging is consid- ered as a natural step of parsing by employing lex- ical rules. For transition-based parsing, <ref type="bibr" target="#b6">Hatori et al. (2011)</ref> proposed to integrate POS tagging with dependency parsing. Our joint approach can be seen as an adaption of <ref type="bibr" target="#b6">Hatori et al. (2011)</ref>'s ap- proach for constituent parsing.  proposed a transition-based constituent parser to process an input sentence from the character level. However, manual annotation of the word-internal structures need to be added to the original Tree- bank in order to train such a parser.</p><p>Non-local features have been successfully used for constituent parsing <ref type="bibr" target="#b0">(Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b2">Collins and Koo, 2005;</ref><ref type="bibr" target="#b8">Huang, 2008)</ref>. However, almost all of the previous work use non- local features at the parse reranking stage. The reason is that the single-stage chart-based parser cannot use non-local structural features. In con- trast, the transition-based parser can use arbitrari- ly complex structural features. Therefore, we can concisely utilize non-local features in a single-stage parsing system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed three improvements to transition-based constituent parsing for Chinese. First, we incorporated POS tagging into transition- based constituent parsing to resolve the error prop- agation problem of the pipeline approach. Second, we proposed a state alignment strategy to align competing decision sequences that have different number of actions. Finally, we enhanced our pars- ing model by enlarging the feature set with non- local features and semi-supervised word cluster features. Experimental results show that all these methods improved the parsing performance sub- stantially, and the final performance of our parsing system outperformed all state-of-the-art systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>BFigure 2 :</head><label>2</label><figDesc>Figure 2: State alignment for the two trees in Figure 1, where s 0 is the initial state, T 0 and T 1 are terminal states corresponding to the two trees in Figure 1. For clarity, we represent each state as a rectangle with the label of top subtree in the stack σ. We also denote sh-x with →, ru-x with ↑ or ↓, rl-x with , and rr-x with .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Non-local features for constituent pars-
ing. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Parsing performance on Chinese test set.  *  Huang (2009) adapted the parse reranker to CTB5. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Parsing performance based on CTB 6. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 presents the average</head><label>6</label><figDesc></figDesc><table>System 

NP 
Int. 
Unary 
1-Word 
Span 
Coord 
Mod. 
Attach 
Verb 
Args 
Diff 
Label 
Clause 
Attach 
Noun 
Edge 

Worst 
1.75 
0.74 
0.44 
0.49 
0.39 
0.37 
0.29 
0.15 
0.14 
Pipeline 
JointParsing 
Padding 
StateAlign 
Nonlocal 
Cluster 
Nonlocal&amp;Cluster 
Best 
1.33 
0.42 
0.28 
0.29 
0.19 
0.21 
0.17 
0.07 
0.09 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Parse errors on Chinese test set. The shaded area of each bar indicates average number of that 
error type per sentence, and the completely full bar indicates the number in the Worst row. 

System 
VV→NN NN→VV DEC→DEG JJ→NN NR→NN DEG→DEC NN→NR NN→JJ 

Worst 
0.26 
0.18 
0.15 
0.09 
0.08 
0.07 
0.06 
0.05 
Pipeline 
JointParsing 
Padding 
StateAlign 
Nonlocal 
Cluster 
Nonlocal&amp;Cluster 
Best 
0.14 
0.10 
0.03 
0.07 
0.05 
0.03 
0.03 
0.02 

</table></figure>

			<note place="foot" n="1"> Intermediate nodes are produced by binarization process.</note>

			<note place="foot" n="4"> http://code.google.com/p/berkeley-parser-analyser/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank three anonymous reviewers for their cogent comments. This work is funded by the DAPRA via contract HR0011-11-C-0145 entitled /Linguistic Resources for Multilingual Process-ing0. All opinions expressed here are those of the authors and do not necessarily reflect the views of DARPA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Coarseto-fine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A maximum-entropyinspired parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference</title>
		<meeting>the 1st North American chapter of the Association for Computational Linguistics conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="132" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminative reranking for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="70" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume</title>
		<meeting>the 42nd Meeting of the Association for Computational Linguistics (ACL&apos;04), Main Volume<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">HEAD-DRIVEN STATISTICAL MODELS FOR NATURAL LANGUAGE PARSING</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Chinese statistical parsing. Handbook of Natural Language Processing and Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental joint pos tagging and dependency parsing in chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hatori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Matsuzaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
		<meeting>5th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1216" to="1224" />
		</imprint>
	</monogr>
	<note>Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Selftraining pcfg grammars with latent annotations across languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="832" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Forest reranking: Discriminative parsing with non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="586" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improve chinese parsing with max-ent reranking parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling-Ya</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Brown University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master Project Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Simple semi-supervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="595" to="603" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-08: HLT</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An empirical examination of challenges in chinese parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="98" to="103" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Semi-supervised learning for natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Name tagging with word clusters and discriminative training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jethran</forename><surname>Guinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zamanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="337" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved inference for unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning accurate, compact, and interpretable tree annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Thibaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A classifier-based parser with linear run-time complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Workshop on Parsing Technology</title>
		<meeting>the Ninth International Workshop on Parsing Technology</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parse reranking based on higher-order lexical dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1251" to="1259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A fast, accurate deterministic parser for chinese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The penn chinese treebank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transition-based parsing of the chinese treebank using a global discriminative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Parsing Technologies</title>
		<meeting>the 11th International Conference on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="162" to="171" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Chinese parsing exploiting characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and accurate shiftreduce constituent parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="434" to="443" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
