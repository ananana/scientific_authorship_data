<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LEXenstein: A Framework for Lexical Simplification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 26-31, 2015. c 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Henrique</forename><surname>Paetzold</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LEXenstein: A Framework for Lexical Simplification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of ACL-IJCNLP 2015 System Demonstrations</title>
						<meeting>ACL-IJCNLP 2015 System Demonstrations <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="85" to="90"/>
							<date type="published">July 26-31, 2015. c 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Lexical Simplification consists in replacing complex words in a text with simpler alternatives. We introduce LEXen-stein, the first open source framework for Lexical Simplification. It covers all major stages of the process and allows for easy benchmarking of various approaches. We test the tool&apos;s performance and report comparisons on different datasets against the state of the art approaches. The results show that combining the novel Substitution Selection and Substitution Ranking approaches introduced in LEXenstein is the most effective approach to Lexical Simplification.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of a Lexical Simplification (LS) ap- proach is to replace complex words and expres- sions in a given text, often a sentence, with sim- pler alternatives of equivalent meaning in context. Although very intuitive, this is a challenging task since the substitutions must preserve both the orig- inal meaning and the grammaticality of the sen- tence being simplified.</p><p>The LS task has been gaining significant atten- tion since the late 1990's, thanks to the positive influence of the early work presented by  and <ref type="bibr" target="#b3">(Carroll et al., 1999</ref>). More re- cently, the LS task at SemEval-2012 ( ) has given LS wider visibility. Participants had the opportunity to compare their approaches in the task of ranking candidate substitutions, all of which were already known to fit the context, according to their "simplicity".</p><p>Despite its growth in popularity, the inexistence of tools to support the process and help researchers to build upon has been hampering progress in the area. We were only able to find one tool for LS: a set of scripts designed for the training and testing of ranking models provided by (Jauhar and Spe- cia, 2012) <ref type="bibr">1</ref> . However, they cover only one step of the process. In an effort to tackle this issue, we present LEXenstein: a framework for Lexical Simplification development and benchmarking.</p><p>LEXenstein is an easy-to-use framework that provides simplified access to many approaches for several sub-tasks of the LS pipeline, which is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. Its current version in- cludes methods for the three main sub-tasks in the pipeline: Substitution Generation, Substitution Selection and Substitution Ranking. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Overview</head><p>LEXenstein is a Python library that provides sev- eral approaches for sub-tasks in LS. To increase its flexibility, the library is structured in six mod- ules: Substitution Generation, Substitution Selec- tion, Substitution Ranking, Feature Estimation, Evaluation and Text Adorning. In the following Sections, we describe them in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Substitution Generation</head><p>We define Substitution Generation (SG) as the task of producing candidate substitutions for complex words, which is normally done regardless of the context of the complex word. Previous work com- monly addresses this task by querying general do- main thesauri such as WordNet <ref type="bibr" target="#b5">(Fellbaum, 1998)</ref>, or domain specific ones such as UMLS <ref type="bibr" target="#b1">(Bodenreider, 2004</ref>). Examples of work resorting to this strategy are <ref type="bibr" target="#b3">(Carroll et al., 1999</ref>). Recent work focuses on learning substitutions from sentence-aligned parallel cor- pora of complex-simple texts <ref type="bibr" target="#b15">(Paetzold and Specia, 2013;</ref><ref type="bibr" target="#b6">Horn et al., 2014</ref>).</p><p>LEXenstein's SG module offers support for five approaches. All approaches use LEXenstein's Text Adorning module to create substitutions for all possible inflections of verbs and nouns. Each approach is represented by one of the following Python classes:</p><p>KauchakGenerator ( <ref type="bibr" target="#b6">Horn et al., 2014</ref>) Auto- matically extracts substitutions from parallel cor- pora. It requires a set of tagged parallel sentences and the word alignments between them in Pharaoh format <ref type="bibr" target="#b14">(Och and Ney, 2000</ref>). It produces a dictio- nary of complex-to-simple substitutions filtered by the criteria described in <ref type="bibr" target="#b6">(Horn et al., 2014</ref>).</p><p>BiranGenerator (Biran et al., 2011) Filters substitutions based on the Cartesian product be- tween vocabularies of complex and simple words. It requires vocabularies of complex and simple words, as well as two language models trained over complex and simple corpora. It produces a dictionary linking words to a set of synonyms and hypernyms filtered by the criteria described in <ref type="bibr" target="#b0">(Biran et al., 2011</ref>).</p><p>YamamotoGenerator ( <ref type="bibr" target="#b9">Kajiwara et al., 2013</ref>) Extracts substitutions from dictionary definitions of complex words. It requires an API key for the Merriam Dictionary 2 , which can be obtained for free. It produces a dictionary linking words in the Merriam Dictionary and WordNet to words with the same Part-of-Speech (POS) tag in its entries' definitions and examples of usage.</p><p>MerriamGenerator Extracts a dictionary link- ing words to their synonyms, as listed in the Mer- riam Thesaurus. It requires an API key.</p><p>WordnetGenerator Extracts a dictionary link- ing words to their synonyms, as listed in WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Substitution Selection</head><p>Substitution Selection (SS) is the task of selecting which substitutions -from a given list -can re- place a complex word in a given sentence with- out altering its meaning. Most work addresses this task referring to the context of the complex word by employing Word Sense Disambiguation (WSD) approaches ( <ref type="bibr" target="#b17">Sedding and Kazakov, 2004;</ref><ref type="bibr" target="#b13">Nunes et al., 2013</ref>), or by discarding substitutions which do not share the same POS tag of the target complex word ( <ref type="bibr" target="#b9">Kajiwara et al., 2013;</ref><ref type="bibr" target="#b15">Paetzold and Specia, 2013</ref>).</p><p>LEXenstein's SS module provides access to three approaches. All approaches require as input a dictionary of substitutions generated by a given approach and a dataset in the VICTOR format (as in Victor Frankenstein <ref type="bibr" target="#b18">(Shelley, 2007)</ref>). As out- put, they produce a set of selected substitutions for each entry in the VICTOR dataset. The VICTOR format is structured as illustrated in Example 1, where S i is the ith sentence in the dataset, w i a target complex word in the h i th position of S i , c j i a substitution candidate and r j i its simplicity rank- ing. Each bracketed component is separated by a tabulation marker.   </p><formula xml:id="formula_0">S 1 w 1 h 1 r 1 1 :c 1 1 · · ··r n 1 :c n 1 . . . S m w m h m r 1 m :c 1 m · · ··r n m :c n m    (1)</formula><p>LEXenstein includes two resources for train- ing/testing in the VICTOR format: the LexMTurk ( <ref type="bibr" target="#b6">Horn et al., 2014</ref>) and the SemEval corpus . Each approach in the SS mod- ule is represented by one of the following Python classes:</p><p>WSDSelector Allows for the user to use one among various classic WSD approaches in SS. It requires the PyWSD <ref type="bibr" target="#b20">(Tan, 2014</ref>) module to be in- stalled, which includes the approaches presented by <ref type="bibr" target="#b12">(Lesk, 1986)</ref> and ( <ref type="bibr" target="#b21">Wu and Palmer, 1994)</ref>, as well as baselines such as random and first senses.</p><p>BiranSelector (Biran et al., 2011) Employs a strategy in which a word co-occurrence model is used to determine which substitutions have mean- ing similar to that of a target complex word. It requires a plain text file with each line in the for- mat specified in Example 2, where w i is a word, c j i a co-occurring word and f j i its frequency of occurrence.</p><formula xml:id="formula_1">w i c 0 i : f 0 i · · · c n i : f n i<label>(2)</label></formula><p>Each component in the format in 2 must be separated by a tabulation marker. Given such a model, the approach filters all substitutions which are estimated to be more complex than the tar- get word, and also those for which the distance between their co-occurrence vector and the target sentence's vector is higher than a threshold set by the user.</p><p>WordVectorSelector Employs a novel strategy, in which a word vector model is used to deter- mine which substitutions have the closest mean- ing to that of the sentence being simplified. It requires a binary word vector model produced by <ref type="bibr">Word2Vec 3</ref> , and can be configured in many ways. It retrieves a user-defined percentage of the substi- tutions, which are ranked with respect to the co- sine distance between their word vector and the sum of some or all of the sentences' words, de- pending on the settings defined by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Substitution Ranking</head><p>Substitution Ranking (SR) is the task of ranking a set of selected substitutions for a target complex word with respect to their simplicity. Approaches vary from simple word length and frequency- based measures <ref type="bibr" target="#b2">Carroll et al., 1998;</ref><ref type="bibr" target="#b3">Carroll et al., 1999;</ref><ref type="bibr" target="#b0">Biran et al., 2011</ref>) to more sophisticated linear combinations of scor- ing functions (Jauhar and Specia, 2012), as well as machine learning-based approaches <ref type="bibr" target="#b6">(Horn et al., 2014</ref>).</p><p>LEXenstein's SR module provides access to three approaches. All approaches receive as in- put datasets in the VICTOR format, which can be either training/testing datasets already containing only valid substitutions in context, or datasets gen- erated with (potentially noisy) substitutions by a given SS approach. They also require as input a FeatureEstimator object to calculate feature values describing the candidate substitutes. More details on the FeatureEstimator class are provided in Sec- tion 2.4. Each approach in the SR module is rep- resented by one of the following Python classes:</p><p>MetricRanker Employs a simple ranking strat- egy based on the values of a single feature pro- vided by the user. By configuring the input Fea- tureEstimator object, the user can calculate values of several features for the candidates in a given dataset and easily rank the candidates according to each of these features.</p><p>SVMRanker <ref type="bibr" target="#b8">(Joachims, 2002</ref></p><note type="other">) Use Support Vector Machines in a setup that minimises a loss function with respect to a ranking model. This strategy is the one employed in the LS experiments of (Horn et al., 2014), yielding promising results. The user needs to provide a path to their SVM- Rank installation, as well as SVM-related configu- rations, such as the kernel type and parameter val- ues for C, epsilon, etc.</note><p>BoundaryRanker Employs a novel strategy, in which ranking is framed as a binary classification task. During training, this approach assigns the la- bel 1 to all candidates of rank 1 ≥ r ≥ p, where p is a range set by the user, and 0 to the remain- ing candidates. It then trains a stochastic descent linear classifier based on the features specified in the FeatureEstimator object. During testing, can- didate substitutions are ranked based on how far from 0 they are. This ranker allows the user to provide several parameters during training, such as loss function and penalty type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Feature Estimation</head><p>LEXenstein's Feature Estimation module allows the calculation of several features for LS-related tasks. Its class FeatureEstimator allows the user to select and configure many features commonly used by LS approaches.</p><p>The FeatureEstimator object can be used either for the creation of LEXenstein's rankers, or in stand-alone setups. For the latter, the class pro- vides a function called calculateFeatures, which produces a matrix M xN containing M feature values for each of the N substitution candidates listed in the dataset. Each of the 11 features sup- ported must be configured individually. They can be grouped in four categories:</p><p>Lexicon-oriented: Binary features which re- ceive value 1 if a candidate appears in a given vo- cabulary, and 0 otherwise.</p><p>Morphological: Features that exploit morpho- logical characteristics of substitutions, such as word length and number of syllables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collocational: N-gram probabilities of the form</head><formula xml:id="formula_2">P S h−l h−1 c S h+r h+1</formula><p>, where c is a candidate substi- tution in the hth position in sentence S, and S h−l h−1 and S h+r h+1 are n-grams of size l and r, respectively.</p><p>Sense-oriented: Several features which are re- lated to the meaning of a candidate substitution such as number of senses, lemmas, synonyms, hy- pernyms, hyponyms and maximum and minimum distances among all of its senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation</head><p>Since one of the goals of LEXenstein is to facili- tate the benchmarking LS approaches, it is crucial that it provides evaluation methods. This module includes functions for the evaluation of all sub- tasks, both individually and in combination. It contains four Python classes:</p><p>GeneratorEvaluator: Provides evaluation met- rics for SG methods. It requires a gold-standard in the VICTOR format and a set of generated sub- stitutions. It returns the Potential, Precision and F-measure, where Potential is the proportion of in- stances for which at least one of the substitutions generated is present in the gold-standard, Preci- sion the proportion of generated instances which are present in the gold-standard, and F-measure their harmonic mean.</p><p>SelectorEvaluator: Provides evaluation metrics for SS methods. It requires a gold-standard in the VICTOR format and a set of selected substi- tutions. It returns the Potential, Precision and F- measure of the SS approach, as defined above.</p><p>RankerEvaluator: Provides evaluation metrics for SR methods. It requires a gold-standard in the VICTOR format and a set of ranked substitutions. It returns the TRank-at-1:3 and Recall-at-1:3 met- rics ( , where Trank-at-i is the proportion of instances for which a candidate of gold-rank r ≤ i was ranked first, and Recall-at-i the proportion of candidates of gold-rank r ≤ i that are ranked in positions p ≤ i.</p><p>PipelineEvaluator: Provides evaluation metrics for the entire LS pipeline. It requires as input a gold-standard in the VICTOR format and a set of ranked substitutions which have been gener- ated and selected by a given set of approaches. It returns the approaches' Precision, Accuracy and Change Proportion, where Precision is the pro- portion of instances for which the highest ranking substitution is not the target complex word itself and is in the gold-standard, Accuracy is the pro- portion of instances for which the highest ranking substitution is in the gold-standard, and Change Proportion is the proportion of instances for which the highest ranking substitution is not the target complex word itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Text Adorning</head><p>This approach provides a Python interface to the Morph Adorner Toolkit <ref type="bibr" target="#b16">(Paetzold, 2015)</ref>, a set of Java tools that facilitates the access to Morph Adorner's functionalities. The class provides easy access to word lemmatisation, word stemming, syllable splitting, noun inflection, verb tensing and verb conjugation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Resources</head><p>LEXenstein also provides a wide array of re- sources for the user to explore in benchmarking tasks. Among them are the aforementioned LexM- turk and SemEval corpora in the VICTOR format, lists of stop and basic words, as well as language models and lexica built over Wikipedia and Sim- ple Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this Section, we discuss the results obtained in four benchmarking experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Substitution Generation</head><p>In this experiment we evaluate all SG approaches in LEXenstein. For the KauchakGenerator, we use the corpus provided by <ref type="bibr" target="#b10">(Kauchak, 2013)</ref>, com- posed of 150, 569 complex-to-simple parallel sen- tences, parsed by the Stanford Parser ( <ref type="bibr" target="#b11">Klein and Manning, 1965)</ref>. From the the same corpus, we build the required vocabularies and language mod- els for the BiranGenerator. We used the LexMturk dataset as the gold-standard ( <ref type="bibr" target="#b6">Horn et al., 2014</ref>), which is composed by 500 sentences, each with a single target complex word and 50 substitutions suggested by turkers. The results are presented in <ref type="table">Table 1</ref>.</p><p>The results in <ref type="table">Table 1</ref> show that the method of ( <ref type="bibr" target="#b6">Horn et al., 2014</ref>) yields the best F-Measure re- sults, although combining the output of all gener- ation methods yields the highest Potential. This shows that using parallel corpora to generate sub- stitution candidates for complex words can be a Approach Pot.</p><p>Prec. F Kauchak 0.830 0.155 0.262 Wordnet 0.608 0.109 0.184 Biran 0.630 0.102 0.175 Merriam 0.540 0.067 0.120 Yamamoto 0.504 0.054 0.098 All 0.976 0.066 0.124 <ref type="table">Table 1</ref>: SG benchmarking results more efficient strategy than querying dictionaries and databases. We must, however, keep in mind that the sentences that compose the LexMturk cor- pus were extracted from Wikipedia, which is the same corpus from which the KauchakGenerator learns substitutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Substitution Selection</head><p>Here we evaluate of all SS approaches in LEX- enstein. For the BiranSelector, we trained a co- occurrence model over a corpus of 6+ billion words extracted from the various sources sug- gested in the Word2Vec documentation 4 , the same sources over which the word vector model re- quired by the WordVectorSelector was trained. In order to summarise the results, we present the scores obtained only with the best performing con- figurations of each approach. The LexMturk cor- pus is used as the gold-standard, and the initial set of substitutions is the one produced by all SG ap- proaches combined. The results are presented in   <ref type="table" target="#tab_0">Table 2</ref> represents the total number of substitutions selected for all test instances. The results in <ref type="table" target="#tab_0">Table 2</ref> show that our novel word vector approach outperforms all others in F-Measure by a considerable margin, including the method of not performing selection at all. Note that not perform- ing selection allows for Potential to be higher, but yields very poor Precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Substitution Ranking</head><p>In <ref type="table" target="#tab_2">Table 3</ref> we present the results of the evaluation of several SR approaches. We trained the SVM- Ranker with features similar to the ones used in <ref type="bibr" target="#b6">(Horn et al., 2014)</ref>, and the BoundaryRanker with a set of 10 features selected through univariate feature selection. We compare these approaches to three baseline Metric Rankers, which use the word's frequency in Simple Wikipedia, its length or its number of senses. The SemEval corpus is used as the gold-standard so that we can compare our results with the best one obtained at <ref type="bibr">SemEval2012 (Jauhar and</ref>) (SemEval, in <ref type="table">Ta</ref>  The novel Boundary ranking approach outper- forms all other approaches in both TRank-at-1 and Recall-at-1 by a considerable margin, but it is worse than the best SemEval-2012 approach in terms of Recall-at-2 and 3. This however reveals not a limitation but a strength of our approach: since the Boundary ranker focuses on placing the best substitution in the highest rank, it becomes more effective at doing so as opposed to at pro- ducing a full ranking for all candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Round-Trip Evaluation</head><p>In this experiment we evaluate the performance of different combinations of SS and SR approaches in selecting suitable substitutions for complex words from the ones produced by all generators combined. Rankers and selectors are configured in the same way as they were in the experiments in Sections 3.3 and 3.2. The gold-standard used is LexMturk, and the performance metric used is the combination's Precision: the proportion of times in which the candidate ranked highest is not the target complex word itself and belongs to the gold- standard list. Results are shown in  <ref type="table" target="#tab_3">Table 4</ref>: Round-trip benchmarking results the highest performance in the pipeline evalua- tion. Interestingly, the SVMRanker, which per- formed very well in the individual evaluation of Section 3.3, was outperformed by all three base- lines in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Final Remarks</head><p>We have presented LEXenstein, a framework for Lexical Simplification distributed under the per- missive BSD license. It provides a wide arrange of useful resources and tools for the task, such as feature estimators, text adorners, and various approaches for Substitution Generation, Selection and Ranking. These include methods from pre- vious work, as well as novel approaches. LEX- enstein's modular structure also allows for one to easily add new approaches to it. We have conducted evaluation experiments in- cluding various LS approaches in the literature. Our results show that the novel approaches intro- duced in this paper outperform those from previ- ous work. In the future, we intend to incorporate in LEXenstein approaches for Complex Word Iden- tification, as well as more approaches for the re- maining tasks of the usual LS pipeline.</p><p>The tool can be downloaded from: http:// ghpaetzold.github.io/LEXenstein/.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Lexical Simplification Pipeline LEXenstein was devised to facilitate performance comparisons among various LS approaches, as well as the creation of new strategies for LS. In the following Sections we present LEXenstein's components (Section 2) and discuss the results of several experiments conducted with the tool (Section 3).</figDesc><graphic url="image-1.png" coords="1,320.41,391.75,192.00,98.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>Approach 
Pot. 
Prec. 
F 
Size 
Word Vec. 0.768 0.219 0.341 3, 042 
Biran 
0.508 0.078 0.136 9, 680 
First 
0.176 0.045 0.072 2, 471 
Lesk 
0.246 0.041 0.070 4, 716 
Random 
0.082 0.023 0.035 2, 046 
Wu-Pa 
0.038 0.013 0.020 1, 749 
No Sel. 
0.976 0.066 0.124 26, 516 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>SS benchmarking results 

"Size" in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : SR benchmarking results</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>The results show that combining the Word-
VectorSelector with the BoundaryRanker yields </table></figure>

			<note place="foot" n="1"> https://github.com/sjauhar/simplex</note>

			<note place="foot" n="2"> http://www.dictionaryapi.com/</note>

			<note place="foot" n="3"> https://code.google.com/p/word2vec/</note>

			<note place="foot" n="4"> https://code.google.com/p/word2vec/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Putting it Simply: a Context-Aware Approach to Lexical Simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Biran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 49th Annual Meeting of the ACL</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The unified medical language system (umls): integrating biomedical terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Practical simplification of english newspaper text to assist aphasic readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Canning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 15th AAAI</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Simplifying Text for Language Impaired Readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Canning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>The 9th EACL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The use of a psycholinguistic database in the simplification of text for aphasic readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Linguistic Databases</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Bradford Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manduca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
		<title level="m">Learning a Lexical Simplifier Using Wikipedia. The 52nd Annual Meeting of the ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">UOW-SHEF: SimpLex-lexical simplicity ranking based on contextual and psycholinguistic features. The 1st *SEM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 8th ACM</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Selecting Proper Lexical Paraphrase for Children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kajiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving Text Simplification Language Modeling Using Unsimplified Text Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 51st Annual Meeting of the ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate Unlexicalized Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st Annual Meeting of ACL</title>
		<imprint>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 5th SIGDOC</title>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">As Simple as It Gets-A Sentence Simplifier for Different Learning Levels and Contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kawase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Siehndel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dietze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>IEEE 13th ICALT</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 38th Annual Meeting of the ACL</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Text simplification as tree transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 9th STIL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Morph adorner toolkit: Morph adorner made simple</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Paetzold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wordnet-based text document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sedding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kazakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 3rd ROMAND</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shelley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 1: English lexical simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 1st *SEM</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Pywsd: Python implementations of word sense disambiguation technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<ptr target="https://github.com/alvations/pywsd" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Verbs semantics and lexical selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 32nd Annual Meeting of ACL</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
