<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Painless Labeling with Application to Text Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sajib</forename><surname>Dasgupta</surname></persName>
							<email>sdgnew@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Chittagong Indepedent University Chittagong</orgName>
								<address>
									<country key="BD">Bangladesh</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Painless Labeling with Application to Text Mining</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="402" to="407"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Labeled data is not readily available for many natural language domains, and it typically requires expensive human effort with considerable domain knowledge to produce a set of labeled data. In this paper, we propose a simple unsupervised system that helps us create a labeled resource for categorical data (e.g., a document set) using only fifteen minutes of human input. We utilize the labeled resources to discover important insights about the data. The entire process is domain independent, and demands no prior annotation samples, or rules specific to an annotation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Consider the following two scenarios:</p><p>Scenario 1: We start processing a new language and we want to get an initial idea of the language before embarking on the expensive process of cre- ating hand annotated resources. For instance, we may want to know how people express opinion in a language of interest, what characterizes the sub- jective content of the language and how expres- sions of opinion differ along opinion types. The question is how to acquire such first-hand insights of an unknown language in quick time and with minimal human effort?</p><p>Scenario 2: We have a set of blog articles and we are interested in learning how blogging differs across gender. In particular, we seek to learn the writing styles or other indicative patterns -topics of interest, word choices etc. -that can potentially distinguish writings across gender. A traditional NLP approach would be to collect a set of articles that are tagged with gender information, which we can then input to a learning system to learn pat- terns that can differentiate gender. What if no such annotation is available, as the bloggers don't re- veal their gender information? Could we arrange a human annotation task to annotate the articles along gender? Often the articles contain explicit patterns (e.g., "my boyfriend", "as a woman" etc.) which help the annotators to annotate the articles. Often there are no indicative patterns in the writ- ten text, and it becomes impossible to annotate the articles reliably.</p><p>The above scenarios depict the cases when we are resource constrained and creating a new re- source is nontrivial and time consuming. Given such difficulties, it would be helpful if we could design a system that requires less human input to create a labeled resource. In this paper, we present a simple unsupervised system that helps us cre- ate a labeled resource with minimal human effort.</p><p>The key to our method is that instead of label- ing the entire set of unlabeled instances the sys- tem labels a subset of data instances for which it is confident to achieve high level of accuracy. We experiment with several document labeling tasks and show that a high-quality labeled resource can be produced by a clustering-based labeling system that requires a mere fifteen minutes of human in- put. It achieves 85% and 78% accuracy for the task of sentiment and gender classification, showing its effectiveness on two nontrivial labeling tasks with distinct characteristics (see Section 3).</p><p>We also utilize the labeled resources created by our system to learn discriminative patterns that help us gain insights into a dataset. For instance, we learn how users generally express opinion in a language of interest, and how writing varies across gender. The next section describes the details of our main algorithm. We present experimental re- sults in Section 3 and 4. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>We consider a general classification framework. Let X = {x 1 , . . . , x n } represents a categorical dataset with n data points where x i ∈ ℜ d . Let c x ∈ {1,-1} is the true label of x 1 . Our goal is label a subset of the data, X ′ = {C 1 , C 2 } ⊆ X, where C 1 and C 2 comprise data points of positive and negative class respectively. Note that, X ′ rep- resents the subset of datapoints that are confidently labeled by the system.</p><p>To illustrate, we show a snippet of a CD player review taken from Amazon in <ref type="table" target="#tab_0">Table 1</ref>. As you can see this review is highly ambiguous, as it describes both the positive and negative aspects of the prod- uct: while the phrases a little better, not skipping, and not as bad conveys a positive sentiment, the phrases didn't fix and skipping noticeably are neg- ative sentiment-bearing. Any automated system would find it hard to correctly label this review, as the review is highly ambiguous. Our goal is to remove such ambiguous data points from the data space and label the remaining unambiguous data points. The fact that unambiguous data instances are easier to label allows us to use an automated system to label them quickly with minimal human effort (see the next section). Now how could we set apart unambiguous data points from the ambiguous ones from a set of unla- beled data points? Note that we desire the system to be unsupervised. We also desire the system to be generic i.e., applicable to any application do- main. Next we show how we extend spectral clus- tering to achieve this goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Ambiguity Resolution with Iterative Spectral Clustering</head><p>In spectral clustering, a set of n data points is rep- resented as an undirected graph, where each node corresponds to a data point and the edge weight between two nodes is their similarity as defined by S. The goal is to induce a clustering, or equiv- alently, a partitioning function f , which is typi- cally represented as a vector of length n such that f (i) ∈ {1, −1} indicates which of the two clusters data point i should be assigned to. In spectral clustering, the normalized cut parti- tion of a similarity graph, S is derived from the solution of the following constrained optimization problem: argmin f ∈ℜ n i,j S i,j ( f (i)  <ref type="formula">(2000)</ref>). Clustering using the second eigenvec- tor, is trivial: since we have a linearization of the points, all we need to do is to determine a thresh- old for partitioning the data points.</p><formula xml:id="formula_0">√ d i − f (j) √ d j ) 2 subject to f T Df = 1 and Df ⊥ 1,</formula><p>Second eigenvector reveals useful information regarding the ambiguity of the individual data points. In the computation of eigenvectors each data point factors out orthogonal projections of each of the neighboring data points. Ambigu- ous data points factor out orthogonal projections from both the positive and negative data instances, and hence they have near zero values in the pivot eigenvectors. We exploit this important informa- tion. The basic idea is that the data points with near zero values in the second eigenvector are more ambiguous than those with large absolute values. Hence, to cluster only the unambiguous datapoints, we can therefore sort the data points according to second eigenvector, and keep only the top and bottom m(m &lt; n) datapoints. Finally, in- stead of removing (n − m) datapoints at once, we remove them in iteration.</p><p>Here is our final algorithm:</p><formula xml:id="formula_1">1. Let s : X × X → ℜ be a similarity function defined over data X. Construct a similarity matrix S such that S ij = s(x i , x j ). 2. Construct the Laplacian matrix L = D −1/2 (D − S)D −1/2 , where D is a diago- nal matrix with D i,i = j S i,j .</formula><p>3. Find eigenvector e 2 corresponding to second smallest eigenvalue of L.</p><p>4. Sort X according to e 2 and remove α points indexed from (|X|/2 − α/2 + 1) to (|X|/2 + α/2).</p><p>5. If |X| = m, goto Step 6; else goto Step 1.  <ref type="table">Table 2</ref>: Accuracy of automatically labeled data for each dataset. We also report 5-fold supervised classification result for each dataset.</p><formula xml:id="formula_2">Dataset System m = 1 5 n m = 2 5 n m = 3 5 n m = 4 5 n m = n Fully Supervised</formula><p>6. Sort X according to e 2 and put top m 2 data points in cluster C 1 and bottom m 2 data points in cluster C 2 .</p><p>In the algorithm stated above, we start with an initial clustering of all of the data points, and then iteratively remove the α most ambiguous points from the data space. We iterate the process of re- moving ambiguous data points and re-clustering until we have m data points remaining. It should not be difficult to see the advantage of removing the data points in an iterative fashion (as opposed to removing them in a single iteration): the clus- ters produced in a given iteration are supposed to be better than those in the previous iterations, as subsequent clusterings are generated from less ambiguous points. In all our experiments, we set α to 100. Finally, we label the clusters by inspect- ing 10 randomly sampled points from each cluster. We use the cluster labels to assign labels to the m unambiguous data points. Note that labeling the clusters is the only form of human input we re- quire in our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We use three text classification tasks for evalua- tion:</p><p>Gender Classification: Here we classify blog articles according to whether an article is written by a male or female. We employ the blog dataset as introduced by <ref type="bibr" target="#b19">Schler et al. (2006)</ref> for this task. The dataset contains 19320 blog articles, out of which we randomly selected 5000 blog articles as our dataset.</p><p>Spam Classification: Here the goal is to deter- mine whether an email is Spam or Ham (i.e., not spam). We use the Enron spam dataset as intro- duced by <ref type="bibr">Metris</ref>  To preprocess a document, we first tokenize and downcase it, remove stop words, and represent it as a vector of unigrams, using frequency as pres- ence. For spectral clustering, we use dot product as a measure of similarity between two documents vectors.  <ref type="table">Table 3</ref>: Description of the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Accuracy of Automatically Labeled Data</head><p>For each dataset, given n unlabeled data points, we apply our system to label m(m &lt;= n) least ambiguous data points. We check the quality of labeled data by comparing the assigned (cluster) labels of m datapoints against their true labels, and show the accuracy. <ref type="table">Table 2</ref> shows the accu- racy of automatically labeled data for five different values of m for each dataset. For example, when m = n/5, our system labels 1000 out of available 5000 data points with 78.5% accuracy for the gen- der dataset. These 1000 data points are the most unambiguous out of the 5000 data points, as se- lected by the algorithm. For m = n the system labels the entire dataset. As you can see, for all three datasets, the ac- curacy of labeling unambiguous data instances is much higher than the accuracy of labeling the en- tire dataset. For instance, the accuracy of top n/5 unambiguous labeled instances of the sentiment dataset is 90.3%, whereas the accuracy of labeling the entire dataset is 71.2%. The more unambigu-ous the data instances are the higher is the qual- ity of labeled data (as shown by the fact that the accuracy of labeled instances increases as we in- crease m). Notice that our system labels 60% of the data points of the spam dataset with 80.4% ac- curacy; 40% of the data points of the sentiment dataset with 85.4% accuracy; and 20% of the data points of the gender dataset with 78.5% accuracy.</p><p>We also report 5-fold supervised classification result for each dataset. We used linear SVM for classification with all parameters set to their de- fault values. As you can see, when m = n/5 our system achieves near supervised labeling perfor- mance for the gender and sentiment dataset. One of the reviewers asked how SVM performed when trained with unambiguous data instances alone. We refer to <ref type="bibr" target="#b3">Dasgupta and Ng (2009)</ref> where the au- thors report that training SVM with unambiguous data alone produces rather inferior result. They, however, work on a small data sample. It would be interesting to know whether large number of unambiguous (or, semi-ambiguous) data instances could offset the need for ambiguous data in a gen- eral classification setting. Given that unlabeled data are abundantly available in many NLP tasks, one can employ our method to create decent size labeled data quickly from unlabeled data, and uti- lize them later in the process to build an indepen- dent classifier or augment the performance of an existing classifier ( <ref type="bibr" target="#b7">Fuxman et al. (2009)</ref>).</p><p>We employed two baseline algorithms, i.e., kmeans++ and a semi-supervised learning system, Transductive SVM. For kmeans++ we used the following as a measure of ambiguity for each data point:</p><formula xml:id="formula_3">1 − (x−µ i ) 2 k i (x−µ i ) 2</formula><p>, where x is a data vector and µ i , i = 1 : k are k mean vectors. It ranges from 0 to 1. Ambiguity score near 0.5 suggests that the data point is ambiguous. Following common practice in document clustering, we reduced the dimensions of the data to 100 using SVD before we apply kmeans++. For transductive SVM, we randomly selected 20 labeled data points as seeds. <ref type="table">Table 2</ref> shows the result for each baseline.</p><p>Notice that our system beat the baselines (one of them is a semisupervised system) by a big mar- gin for the Gender and Sentiment dataset, whereas Transductive SVM performs the best for the Spam dataset. Interesting to point that our method of re- moving ambiguous data instances to get a qualita- tively stronger clustering contrasts with the max- margin methods which use the ambiguous data instances to acquire the margin. Also impor- tant to mention that spectral clustering is a graph- based clustering algorithm, where similarity mea- sure employed to construct the graph plays a cru- cial role in performance ( <ref type="bibr" target="#b12">Maier et al. (2013)</ref>). In fact, "right" construction of the feature space and a right similarity measure can considerably change the performance of a graph-based clustering algo- rithm. We have not tried different similarity mea- sures in this initial study, but it provides us room for improvement for a dataset like Spam.</p><p>Implementation Details: On a machine with 3GHz of Intel Quad Core Processor and 4GB of RAM, the iterative spectral clustering algorithm takes less than 2 minutes in Matlab for a dataset comprising 5000 data points and 75188 features. This along with the fact that human labelers take on average 12 minutes to label the clusters sug- gests that the entire labeling process requires less than 15 minutes to complete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Mining Patterns and Insights</head><p>In this section, we show that we can utilize the labeled resources created by our system to learn discriminative patterns that help us gain insights into a dataset ( <ref type="bibr" target="#b4">Don et al. (2007)</ref>, Larsen and Aone (1999), <ref type="bibr" target="#b0">Cheng et al. (2007)</ref>, <ref type="bibr" target="#b13">Maiya et al. (2013)</ref>). We utilize the top n/5 unambiguous labeled in- stances for this task, where n is size of the dataset.</p><p>Note that the quality of unambiguous labeled in- stances is much higher than the entire set of la- beled instances (see Section 3.1), so the statis- tics we collect from the unambiguous labeled in- stances to identify discriminative patterns are sup- posedly more reliable.</p><p>We learn our first category of discriminative patterns the following way: for each cluster, we rank all unigrams in the vocabulary by their weighted log-likelihood ratio:</p><formula xml:id="formula_4">P (w t | c j ) · log P (w t | c j ) P (w t | ¬c j )</formula><p>where w t and c j denote the t-th word in the vocab- ulary and the j-th cluster, respectively, and each conditional probability is add one smoothed. In- formally, a unigram w will have a high rank with respect to a cluster c if it appears frequently in c and infrequently in ¬c. The higher the score the more discriminative the pattern is. We also learn the discriminative bigrams similarly: for each cluster, we rank all bigrams by their weighted <ref type="bibr">Female haha, wanna, sooo, lol, ppl, omg, hahaha, ur, yay, soo, cuz, bye, soooo, hehe, ate, hurts, sucks. Male provide, reported, policies, administration, companies, development, policy, services, nations. Spam Spam vicodin, goodbye, utf, rolex, watches, loading, promotion, reproductions, nepel, fw, fwd, click. Ham risk, securities, statements, exchange, terms, third, events, act, investing, objectives, assumptions. Sentiment Positive relationship, husband, effective, mother, strong, perfect, tale, novel, fascinating, outstanding. Negative stupid, worst, jokes, bunch, sequel, lame, guess, dumb, boring, maybe, guys, video, flick, oh.</ref>   log-likelihood ratio score and select the top scor- ing bigrams as the most discriminative bigrams. <ref type="table" target="#tab_3">Table 4</ref> and 5 show the most discriminative un- igrams and bigrams learned by our system. No- tice that the learned patterns are quite informa- tive. For instance, in the case of blog dataset we learn that certain word usages (e.g., sooo, cuz etc.) are more common in women's writings, whereas men's writings often contain discussion of poli- tics, news and technology. For sentiment data, the patterns correspond well to the generic sentiment lexicon manually created by the sentiment experts. The ability of our system to learn top sentiment features could be handy for a resource-scarce lan- guage, which may not have a general purpose sen- timent lexicon. Note that the system is not lim- ited to unigram and bigram patterns only. The la- beled instances can be utilized similarly to gather statistics for other form of usage patterns includ- ing syntactic and semantic patterns for document collections.</p><note type="other">Dataset Class Top Discriminative Unigrams Gender</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Automatic extraction of labeled data has gained momentum in recent years ( <ref type="bibr" target="#b5">Durme and Pasca (2008)</ref>, <ref type="bibr" target="#b15">Nakov and Hearst (2005)</ref>, <ref type="bibr" target="#b7">Fuxman et al. (2009)</ref>). Traditionally, researchers use task- specific heuristics to generate labeled data, e.g., searching for a specific pattern in the web to col- lect data instances of a particular category (Hearst (1992), <ref type="bibr" target="#b8">Go et al. (2009)</ref>, <ref type="bibr" target="#b10">Hu et al. (2013)</ref>). An- other line of research follows semi-supervised in- formation extraction task, where given a list of seed instances of a particular category, a bootstrap- ping algorithm is applied to mine new instances from large corpora ( <ref type="bibr" target="#b17">Riloff and Jones (1999)</ref>, <ref type="bibr" target="#b6">Etzioni et al. (2005)</ref>, <ref type="bibr" target="#b5">Durme and Pasca (2008)</ref>).</p><p>There has also been a surge of interests in unsu- pervised approaches which primarily rely on clus- tering to induce psuedo labels from large amount of text <ref type="bibr" target="#b2">(Clark (2000)</ref>, <ref type="bibr" target="#b21">Slonim and Tishby (2000)</ref>, <ref type="bibr" target="#b18">Sahoo et al. (2006)</ref>, <ref type="bibr" target="#b1">Christodoulopoulos et al. (2010)</ref>). We differ from existing unsupervised clustering algorithms in a way that we uncompli- cate spectral clustering by forcing it to cluster un- ambiguous data points only, which ensures that the system makes less mistakes during clustering and the clustered data are qualitatively strong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented a system that helps us create a labeled resource for a given dataset with mini- mal human effort.</p><p>We also utilize the labeled resources to discover important insights about the data. The ability of our system to learn and vi- sualize top discriminative patterns facilitates ex- ploratory data analysis for a dataset that might be unknown to us. Even if we have some knowledge of the data, the system may unveil additional char- acterisitcs that are unknown to us. The top fea- tures induced for each classification task can also be interpreted as our system's ability to discover new feature spaces, which can be utilized inde- pendently or along with a simpler feature space (e.g., bag of words) to learn a better classification model. Additional research is needed to further explore this idea.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>where D is a diagonal matrix with D i,i = j S i,j and d i = D i,i . The closed form solution to this opti- mization problem is the eigenvector corresponding to the second smallest eigenvalue of the Laplacian matrix, L = D −1/2 (D − S)D −1/2 (Shi and Ma- lik</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>et al.</head><label></label><figDesc>(Metsis et al. (2006)). We join together the BG section of Spam emails and kaminski section of Ham emails, and randomly se- lected 5000 emails as our dataset. Sentiment Classification: Here the goal is to determine whether the sentiment expressed in a product review is positive or negative. We use Pang et al.'s movie review dataset for this task (Pang et al. (2002)). The dataset contains 2000 reviews annotated with the positive and negative sentiment label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Snippet of an ambiguous CD Player re- view.</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 : Top discriminative unigram patterns identified by our system.</head><label>4</label><figDesc></figDesc><table>Dataset 
Class 
Top Discriminative Bigrams 
Gender 
Female 
wanna go, im so, im gonna, at like, don't wanna, was sooo, was gonna, soo much, so yeah. 
Male 
to provide, york times, the issue, understanding of, the political, bush admin, the democratic. 
Spam 
Spam 
promotional material, adobe photoshop, name it, choose from, you name, stop getting, office xp. 
Ham 
investment advice, this report, respect to, current price, risks and, information provided. 
Sentiment 
Positive 
story of, her husband, relationship with, begins to, love and, life of, the central, the perfect. 
Negative the worst, bad movie, bunch of, got to, too bad, action sequences, waste of, than this, the bad. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Top discriminative bigram patterns identified by our system.</figDesc><table></table></figure>

			<note place="foot" n="1"> We present our system for binary classification task. It can be extended fairly easily to multi-way classification tasks.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We acknowledge three anonymous reviewers and Vincent Ng for their valuable feedback on an ear-lier draft of the paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Discriminative frequent pattern analysis for effective classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Two decades of unsupervised pos induction: How far have we come?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Christodoulopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inducing syntactic categories by context distributional clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mine the easy, classify the hard: A semi-supervised approach to automatic sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP 2009: Proceedings of the Main Conference</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discovering interesting usage patterns in text collections: integrating text mining with visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Don</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zheleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tarkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Auvil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shneiderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plaisant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the ACM International Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding cars, goddesses and enzymes: Parametrizable acquisition of labeled instances for open-domain information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised named-entity extraction from the web: an experimental study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improving classification accuracy using automatically extracted training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fuxman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tsaparas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shafer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">15th ACM Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Twitter sentiment classification using distant supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bhayani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Project Report</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the International Conference on Computational Linguistics (COLING)</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised sentiment analysis with emotional signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Proceedings of the International World Wide Web Conference</title>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast and effective text mining using linear-time document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How the result of graph clustering methods depends on the construction of the graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESAIM: Probability and Statistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploratory analysis of highly heterogeneous document collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Maiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Loaiza-Lemos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Rolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Knowledge Discovery and Data Mining (SIGKDD)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Metsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<title level="m">Spam filtering with naive bayes-which naive bayes? In 3rd Conference on Email and Anti-Spam (CEAS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using the web as an implicit training set: Application to structural ambiguity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Thumbs up? Sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning dictionaries for information extraction by multi-level bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>the ACM International Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Incremental hierarchical clustering of text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Padman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the International Conference on Information and Knowledge Management (CIKM)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Effects of age and gender in blogging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Symposium on Computational Approaches for Analyzing Weblogs</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Document clustering using word clusters via the information bottleneck method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
