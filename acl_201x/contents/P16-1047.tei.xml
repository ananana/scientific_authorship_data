<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Networks For Negation Scope Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Fancellu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>11 Crichton Street</addrLine>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>11 Crichton Street</addrLine>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>11 Crichton Street</addrLine>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Networks For Negation Scope Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="495" to="504"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatic negation scope detection is a task that has been tackled using different classifiers and heuristics. Most systems are however 1) highly-engineered, 2) English-specific, and 3) only tested on the same genre they were trained on. We start by addressing 1) and 2) using a neural network architecture. Results obtained on data from the *SEM2012 shared task on negation scope detection show that even a simple feed-forward neural network using word-embedding features alone, performs on par with earlier classifiers, with a bi-directional LSTM outperforming all of them. We then address 3) by means of a specially-designed synthetic test set; in doing so, we explore the problem of detecting the negation scope more in depth and show that performance suffers from genre effects and differs with the type of negation considered.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Amongst different extra-propositional aspects of meaning, negation is one that has received a lot of attention in the NLP community. Previous work have focused in particular on automatically detect- ing the scope of negation, that is, given a nega- tive instance, to identify which tokens are affected by negation ( §2). As shown in (1), only the first clause is negated and therefore we mark he and the car, along with the predicate was driving as inside the scope, while leaving the other tokens outside.</p><p>(1) He was not driving the car and she left to go home.</p><p>In the BioMedical domain there is a long line of research around the topic (e.g.  and <ref type="bibr" target="#b17">Prabhakaran and Boguraev (2015)</ref>),</p><p>given the importance of recognizing negation for information extraction from medical records. In more general domains, efforts have been more limited and most of the work centered around the *SEM2012 shared task on automatically detecting negation ( §3), despite the recent interest (e.g. machine translation <ref type="bibr" target="#b21">(Wetzel and Bond, 2012;</ref><ref type="bibr" target="#b7">Fancellu and Webber, 2014;</ref><ref type="bibr" target="#b8">Fancellu and Webber, 2015)</ref>).</p><p>The systems submitted for this shared task, although reaching good overall performance are highly feature-engineered, with some relying on heuristics based on English ( ) or on tools that are available for a limited number of languages (e.g. <ref type="bibr" target="#b3">Basile et al. (2012)</ref>, <ref type="bibr" target="#b16">Packard et al. (2014)</ref>), which do not make them easily portable across languages. Moreover, the performance of these systems was only assessed on data of the same genre (stories from Conan Doyle's Sherlock Holmes) but there was no attempt to test the approach on data of different genre.</p><p>Given these shortcomings, we investigate whether neural network based sequence-to- sequence models ( § 4) are a valid alternative. The first advantage of neural networks-based methods for NLP is that we could perform classification by means of unsupervised word-embeddings features only, under the assumption that they also encode structural information previous system had to explicitly represent as features. If this assumption holds, another advantage of contin- uous representations is that, by using a bilingual word-embedding space, we would be able to transfer the model cross-lingually, obviating the problem of the lack of annotated data in other languages.</p><p>The paper makes the following contributions:</p><p>1. Comparable or better performance: We show that neural networks perform on par with previously developed classifiers, with a bi-directional LSTM outperforming them when tested on data from the same genre.</p><p>2. Better understanding of the problem: We an- alyze in more detail the difficulty of detecting negation scope by testing on data of different genre and find that the performance of word- embedding features is comparable to that of more fine-grained syntactic features.</p><p>3. Creation of additional resources: We cre- ate a synthetic test set of negative sentences extracted from Simple English Wikipedia ( § 5) and annotated according to the guidelines released during the *SEM2012 shared task <ref type="bibr" target="#b15">(Morante et al., 2011</ref>), that we hope will guide future work in the field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The task</head><p>Before formalizing the task, we begin by giving some definitions. A negative sentence n is defined as a vector of words w 1 , w 2 ...w n containing one or more negation cues, where the latter can be a word (e.g. not), a morpheme (e.g. im-patient) or a multi-word expression (e.g. by no means, no longer) inherently expressing negation. A word is a scope token if included in the scope of a negation cue. Following <ref type="bibr" target="#b4">Blanco and Moldovan (2011)</ref>, in the *SEM2012 shared task the negation scope is understood as part of a knowledge representation focused around a negated event along with its related semantic roles and adjuncts (or its head in the case of a nominal event). This is exemplified in (2) (from <ref type="bibr" target="#b4">Blanco and Moldovan (2011)</ref>) where the scope includes both the negated event eat along the subject the cow, the object grass and the PP with a fork.</p><p>(2) The cow did n't eat grass with a fork. 1</p><p>Each cue defines its own negation instance, here defined as a tuple I(n,c) where c ∈ {1,0} |n| is a vector of length n s.t. c i = 1 if w i is part of the cue and 0 otherwise. Given I the goal of automatic scope detection is to predict a vector s ∈ {O,I} |n| s.t. s i = I (inside of the scope) if w i is in the scope of the cue or O (outside) otherwise.</p><p>In (3) for instance, there are two cues, not and no longer, each one defining a separate negation instance, I1(n,c1) and I2(n,c2), and each with its own scope, s1 and s2. In both (3a) and (3b), n = <ref type="bibr">[I, do, not, love, you, and, you, are, no, longer, invited]</ref>; in (3a), the vector c1 is 1 only at index 3 (w 2 ='not'), while in (3b) c2 is 1 at position 9, 10 (where w 9 w 10 = 'no longer'); finally the vectors s1 and s2 are I only at the indices of the words underlined and O anywhere else.</p><p>(3) a. I do not love you and you are no longer invited b. I do not love you and you are no longer invited</p><p>There are the two main challenges involved in de- tecting the scope of negation: 1) a sentence can contain multiple instances of negation, sometimes nested and 2) scope can be discontinuous. As for 1), the classifier must correctly classify each word as being inside or outside the scope and as- sign each word to the correct scope; in (4) for in- stance, there are two negation cues and therefore two scopes, one spanning the entire sentence (3a.) and the other the subordinate only (3b.), with the latter being nested in the former (given that, ac- cording to the guidelines, if we negate the event in the main, we also negate its cause).</p><p>(4) a. I did not drive to school because my wife was not feeling well . 2 b. I did not drive to school because my wife was not feeling well .</p><p>In (5), the classifier should instead be able to cap- ture the long range dependency between the sub- ject and its negated predicate, while excluding the positive VP in the middle.</p><p>(5) Naomi went to visit her parents to give them a special gift for their anniversary but never came back .</p><p>In the original task, the performance of the classi- fier is assessed in terms of precision, recall and F 1 measure over the number of words correctly classified as part of the scope (scope tokens) and over the number of scopes predicted that exactly <ref type="bibr">2</ref> One might object that the scope only spans over the sub- ordinate given that it is the part of the scope most likely to be interpreted as false (It is not the case that I drove to school because my wife was not at home, but for other reasons). In the *SEM2012 shared task however this is defined separately as the focus of negation and considered as part of the scope. One reason to distinguish the two is the high ambiguity of the focus: one can imagine for instance that if the speaker stresses the words to school this will be most likely consid- ered the focus and the statement interpreted as It is not the case that I drive to school because my wife was not feeling well (but I drove to the hospital instead). match the gold scopes (exact scope match). As for latter, recall is a measure of accuracy since we score how many scopes we fully predict (true posi- tives) over the total number of scopes in our test set (true positives and false negatives); precision takes instead into consideration false positives, that is those negation instances that are predicted as hav- ing a scope but in reality don't have any. This is the case of the interjection No (e.g. 'No, leave her alone') that never take scope. <ref type="table" target="#tab_1">Table 1</ref> summarizes the performance of systems previously developed to resolve the scope of nega- tion in non-Biomedical texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Previous work</head><p>In general, supervised classifiers perform better than rule-based systems, although it is a combina- tion of hand-crafted heuristics and SVM rankers to achieve the best performance. Regardless of the approach used, the syntactic structure (either con- stituent or dependency-based) of the sentence is often used to detect the scope of negation. This is because the position of the cue in the tree along with the projection of its parent/governor are strong indicators of scope boundaries. Moreover, given that during training we basically learn which syntactic patterns the scope are likely to span, it is also possible to hypothesize that this system should scale well to other genre/domain, as long as we can have a parse for the sentence; this how- ever was never confirmed empirically. Although informative, these systems suffers form three main shortcomings: 1) they are highly-engineered (as in the case of ) and syntactic fea- tures add up to other PoS, word and lemma n-gram features, 2) they rely on the parser producing a cor- rect parse and 3) they are English specific.</p><p>Other systems ( <ref type="bibr" target="#b3">Basile et al., 2012;</ref><ref type="bibr" target="#b16">Packard et al., 2014</ref>) tried to traverse a semantic representa- tion instead. <ref type="bibr" target="#b16">Packard et al. (2014)</ref> achieves the best results so far, using hand-crafted heuristics to traverse the MRS (Minimal Recursion Semantics) structures of negative sentences. If the semantic parser cannot create a reliable representation for a sentence, the system 'backs-off' to the hybrid model of , which uses syntactic information instead. This system suffers however from the same shortcomings mentioned above, in particular, given that MRS representation can only be built for a small set of languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Scope detection using Neural Networks</head><p>In this paper, we experiment with two differ- ent neural networks architecture: a one hidden layer feed-forward neural network and a bi- directional LSTM (Long Short Term Memory, BiLSTM below) model. We chose to 'start sim- ple' from a feed-forward network to investigate whether even a simple model can reach good per- formance using word-embedding features only. We then turned to a BiLSTM because a better fit for the task. BiLSTM are sequential models that operate both in forward and backwards fash- ion; the backward pass is especially important in the case of negation scope detection, given that a scope token can appear in a string before the cue and it is therefore important that we see the latter first to classify the former. We opted in this case for LSTM over RNN cells given that their inner composition is able to better retain use- ful information when backpropagating the error. <ref type="bibr">4</ref> Both networks take as input a single negative instance I(n,c). We represent each word w i ∈ n as a d-dimensional word-embedding vector x ∈ R d (d=50). In order to encode information about the cue, each word is also represented by a cue- embedding vector c ∈ R d of the same dimension- ality of x. c can only take two representations, cue, if c i =1, or notcue otherwise. We also define E vxd w as the word-embedding matrix, where v is the vo- cabulary size, and E 2xd c as the cue-embedding ma- trix.</p><p>In the case of a feed-forward neural network, the input for each word w i ∈ n is the concate- nation of its representation with the ones of its neighboring words in a context window of length l. This is because feed-forward networks treat the input units as separate and information about how words are arranged as sequences must be explic- itly encoded in the input. We define these con- catenations x conc and c conc as</p><formula xml:id="formula_0">x w i−l ...x w i−1 ; x w i ; x w i+1 ...x w i +l and c w i−l ...c w i−1 ; c w i ; c w i+1 ...c w i+l respectively.</formula><p>We chose the value of l after analyz- ing the negation scopes in the dev set. We found that although the furthest scope tokens are 23 and 31 positions away from the cue on the left and the right respectively, 95% of the scope tokens fall in a window of 9 tokens to the left and 15 to the right, these two values being the window sizes we con-  sider for our input. The probability of a given in- put is then computed as follows:</p><note type="other">Scope tokens 3 Exact scope match Method Prec. Rec</note><formula xml:id="formula_1">h = σ(W x x conc + W c c conc + b) y = g(W y h + b y )<label>(1)</label></formula><p>where W and b the weight and biases matrices, h the hidden layer representation, σ the sigmoid activation function and g the softmax operation (g(z m )= e zm / k e z k ) to assign a probability to the input of belonging to either the inside (I) or outside (O) of the scope classes.</p><p>In the biLSTM, no concatenation is performed, given that the structure of the network is already sequential. The input to the network for each word w i are the word-embedding vector x w i and the cue-embedding vector c w i , where w i constitutes a time step. The computation of the hidden layer at time t and the output can be represented as fol- lows:</p><formula xml:id="formula_2">i t = σ(W (i) x x + W (i) c c + W (i) h h t−1 + b (i) ) f t = σ(W (f ) x x + W (f ) c c + W (f ) h h t−1 + b (f ) ) o t = σ(W (o) x x + W (o) c c + W (o) h h t−1 + b (o) ) ˜ c t = tanh(W (c) x x + W (c) c c + W (c) h h t−1 + b (c) ) c t = f t · ˜ c t−1 + i t · ˜ c t h back/f orw = o t · tanh(c t ) y t = g(W y (h back ; h f orw ) + b y )<label>(2)</label></formula><p>where the Ws are the weight matrices, h t−1 the hidden layer state a time t-1, i t , f t , o t the input, forget and the output gate at the time t and h back ; h f orw the concatenation of the backward and for- ward hidden layers.</p><p>Finally, in both networks our training objective is to minimise, for each negative instance, the neg- ative log likelihood J(W,b) of the correct predic- tions over gold labels:</p><formula xml:id="formula_3">J(W, b) = − 1 l l i=1 y (w i ) log h θ (x (w i ) ) + (1 − y (w i ) ) log(1 − h θ (x (w i ) ))<label>(3)</label></formula><p>where l is the length of the sentence n ∈ I, x (w i ) the probability for the word w i to belong to either the I or O class and y (w i ) its gold label. An overview of both architectures is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments</head><p>Training, development and test set are a col- lection of stories from Conan Doyle's Sherlock Holmes annotated for cue and scope of negation and released in concomitance with the *SEM2012 shared task. <ref type="bibr">5</ref> For each word, the correspondent lemma, POS tag and the constituent subtree it be- longs to are also annotated. If a sentence contains multiple instances of negation, each is annotated separately.</p><p>Both training and testing is done on negative sentences only, i.e. those sentences with at least one cue annotated. Training and test size are of 848 and 235 sentences respectively. If a sentence contains multiple negation instances, we create as many copies as the number of instances. If the sentence contains a morphological cue (e.g. im- patient) we split it into affix (im-) and root (pa- tient), and consider the former as cue and the latter as part of the scope.</p><p>Both neural network architectures are imple- mented using TensorFlow ( <ref type="bibr" target="#b0">Abadi et al., 2015</ref>) with a 200-units hidden layer (400 in total for two concatenated hidden layers in the BiLSTM), the Adam optimizer ( <ref type="bibr" target="#b11">Kingma and Ba, 2014</ref>) with a starting learning rate of 0.0001, learning rate de- cay after 10 iterations without improvement and early stopping. In both cases we experimented with different settings:</p><p>1. Simple baseline: In order to understand how hard the task of negation scope detection is, we created a simple baseline by tagging as part of the scope all the tokens 4 words to the left and 6 to the right of the cue; these values were found to be the average span of the scope in either direction in the training data.</p><p>2. Cue info (C): The word-embedding matrix is randomly initialised and updated relying on the training data only. Information about the cue is fed through another set of embedding vectors, as shown in 4. This resembles the 'Closed track' of the *SEM2012 shared task since no external resource is used.</p><p>3. Cue info + external embeddings (E): This is the same as setting <ref type="formula" target="#formula_2">(2)</ref> except that the embed- dings are pre-trained using external data. We experimented with both keeping the word- embedding matrix fixed and updating it dur- ing training but we found small or no dif- ference between the two settings. To do this, we train a word-embedding matrix us- ing Word2Vec ( <ref type="bibr" target="#b13">Mikolov et al., 2013</ref>) on 770 million tokens (for a total of 30 million sen- tences and 791028 types) from the 'One Bil- lion Words Language Modelling' dataset 6 and the Sherlock Holmes data (5520 sen- tences) combined. The dataset was tokenized and morphological cues split into negation affix and root to match the Conan Doyle's data. In order to perform this split, we matched each word against an hand-crafted list of words containing affixal negation <ref type="bibr">7</ref> ; this method have an accuracy of 0.93 on the Co- nan Doyle test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Adding PoS / Universal PoS information (PoS/uni PoS):</head><p>This was mainly to assess whether we could get further improvement by adding additional information. For all the set- ting above, we also add an extra embedding input vector for the POS or Universal POS of each word w i . As for the word and the cue embeddings, PoS-embedding information are fed to the hidden layer through a separate weight matrix. When pre-trained, the train- ing data for the external PoS-embedding ma- trix is the same used for building the word embedding representation, except that in this case we feed the PoS / Universal PoS tag for each word. As in (3), we experimented with both updating the tag-embedding matrix and keeping it fixed but found again small or no difference between the two settings. In or- der to maintain consistency with the original data, we perform PoS tagging using the GE- NIA tagger ( <ref type="bibr" target="#b19">Tsuruoka et al., 2005</ref>) <ref type="bibr">8</ref> and then map the resulting tags to universal POS tags. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The results for the scope detection task are shown in <ref type="table">Table 2</ref>.</p><p>Results for both architecture when word- embedding features only are used (C and C + E) show that neural networks are a valid alternative for scope detection, with bi-directional LSTM be- ing able to outperform all previously developed classifiers on both scope token recognition and ex- act scope matching. Moreover, a bi-directional LSTM shows similar performance to the hybrid system of <ref type="bibr" target="#b16">Packard et al. (2014)</ref> (rule-based + SVM as a back-off) in absence of any hand-crafted heuristics.</p><p>It is also worth noticing that although pre- training the word-embedding and PoS-embedding matrices on external data leads to a slight improve- ment in performance, the performance of the sys- tems using internal data only is already competi- tive; this is a particularly positive result consider- ing that the training data is relatively small.</p><p>Finally, adding universal POS related infor- mation leads to a better performance in most cases. The fact that the best system is built using language-independent features only is an impor- tant result when considering the portability of the model across different languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Error analysis</head><p>In order to understand the kind of errors our best classifier makes, we performed an error analysis on the held-out set.</p><p>First, we investigate whether the per-instance prediction accuracy correlates with scope-related (length of the scope to the left, to the right and combined; maximum length of the gap in a discon- tinuous scope) and cue-related (type of cue -one- word, prefixal, suffixal, multiword-) variables. We also checked whether the neural network is biased towards the words it has seen in the training(for instance, if it has seen the same token always la- beled as O it will then classify it as O). For our best biLSTM system, we found only weak to moderate negative correlations with the following variables:</p><p>• length of the gap, if the scope is discontinu- ous (r=-0.1783, p = 0.004);</p><p>• overall scope length (r=-0.3529, p &lt; 0.001);</p><p>• scope length to the left and to the right (r=- 0.3251 and -0.2659 respectively with p &lt; 0.001)</p><p>• presence of a prefixal cue (r=-0.1781, p = 0.004)</p><p>• presence of a multiword cue (r=-0.1868, p = 0.0023) meaning that the variables considered are not strong enough to be considered as error patterns. For this reason we also manually analyzed the 96 negation scopes that the best biLSTM system predicted incorrectly and noticed several error pat- terns:</p><p>• in 5 cases, the scope should only span on the subordinate but end up including elements from the main. In (6) for instance, where the system prediction is reported in curly brack- ets, the BiLSTM ends up including the main predicate with its subject in the scope.</p><p>(6) You felt so strongly about it that {I knew you could} not {think of Beecher without thinking of that also} .</p><p>• in 5 cases, the system makes an incorrect pre- diction in presence of the syntactic inversion, where a subordinate appears before the main clause; in (7) for instance, the system ex- tends the prediction to the main clause when the scope should instead span the subordinate only.</p><p>(7) But {if she does} not {wish to shield him she would give his name}</p><p>• in 8 cases, where two VPs, one positive and one negative, are coordinated, the system ends up including in the scope the positive VP as well, as shown in <ref type="formula">(8)</ref>. We hypothe- sized this is due to the lack of such examples in the training set.</p><p>(8) Ah, {you do} n't {know Sarah 's temper or you would wonder no more} .</p><p>As in <ref type="bibr" target="#b16">Packard et al. (2014)</ref>, we also noticed that in 15 cases, the gold annotations do not follow the guidelines; in the case of a negated adverb in par- ticular, as shown in (9a) and (9b) the annotations do not seem to agree on whether consider as scope only the adverb or the entire clause around it.</p><p>adding a negation cue (do support or minor mor- phological changes were added when required). If more than a lexical negation cue fit in the context, we used them all by creating more than one nega- tive counterpart, as shown in (10). The sentences were picked to contain different kind of predicates (verbal, existential, nominal, adjectival).</p><p>(10) a. Many people disagree on the topic b. Many people do not disagree on the topic c. Many people never disagree on the topic Lexical: we randomly picked 10 sentences 11 for each lexical (i.e. one-word) cue in training data (these are not, no, none, nobody, never, without) Prefixal: we randomly picked 10 sentences for each prefixal cue in the training data (un-, im-, in-, dis-, ir-)</p><p>Suffixal: we randomly picked 10 sentences for the suffixal cue -less.</p><p>Multi-word: we randomly picked 10 sen- tences for each multi-word cue (neither...nor,no longer,by no means).</p><p>Unseen: we include 10 sentences for each of the negative prefixes a-(e.g. a-cyclic), ab-(e.g. ab-normal) non-(e.g. non-Communist) that are not annotated as cue in the Conan Doyle corpus,  <ref type="table">Table 3</ref>: Results for the scope detection task on the synthetic test set.</p><p>to test whether the system can generalise the clas- sification to unseen cues. <ref type="bibr">12</ref>  <ref type="table">Table 3</ref>. shows the results for the comparison on the synthetic test set. The first thing worth noticing is that by using word-embedding features only it is possible to reach comparable performance with a classifier using syntactic features, with univer- sal PoS generally contributing to a better perfor- mance; this is particularly evident in the multi- word and lexical sub-sets. In general, genre ef- fects hinder both systems; however, considering that the training data is less than 1000 sentences, results are relatively good. Performance gets worse when dealing with morphological cues and in particular in the case of our classifier, with suffixal cues; at a closer inspec- tion however, the cause of such poor performance is attributable to a discrepancy between the an- notation guidelines and the training data, already noted in §4.4. The guidelines state in fact that 'If the negated affix is attached to an adverb that is a complement of a verb, the negation scopes over the entire clause <ref type="bibr" target="#b15">'(Morante et al., 2011</ref>, p. 21) and we annotated suffixal negation in this way. How- ever, 3 out of 4 examples of suffixal negation in adverbs in the training data (e.g. 9a.) mark the scope on the adverbial root only and that's what our classifiers learn to do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Finally, it can be noticed that our system does worse at exact scope matching than the CRF clas- sifier. This is because White (2012)'s CRF model is build on constituency-based features that will then predict scope tokens based on constituent boundaries (which, as we said, are good indica- tor of scope boundaries), while neural networks, basing the prediction only on word-embedding in- formation, might extend the prediction over these boundaries or leave 'gaps' within.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this work, we investigated and confirmed that neural networks sequence-to-sequence models are a valid alternative for the task of detecting the scope of negation. In doing so we offer a detailed analysis of its performance on data of different genre and containing different types of negation, also in comparison with previous classifiers, and found that non-English specific continuous repre- sentation can perform batter than or on par with more fine-grained structural features.</p><p>Future work can be directed towards answering two main questions:</p><p>Can we improve the performance of our classi- fier? To do this, we are going to explore whether adding language-independent structural informa-tion (e.g. universal dependency information) can help the performance on exact scope matching.</p><p>Can we transfer our model to other languages? Most importantly, we are going to test the model using word-embedding features extracted from a bilingual embedding space.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of scope detection using feed-forward and BiLSTM for the tokens 'you are no longer invited' in the instance in ex. (3b).</figDesc><graphic url="image-1.png" coords="5,72.00,62.80,223.20,324.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Summary of previous work on automatic detection of negation scope. 

</table></figure>

			<note place="foot" n="1"> In the *SEM2012 shared task, negation is not considered as a downward monotone function and definite expressions are included in its scope.</note>

			<note place="foot" n="4"> For more details on LSTM and related mathematical formulations, we refer to reader to Hochreiter and Schmidhuber (1997)</note>

			<note place="foot" n="5"> For the statistics regarding the data, we refer the reader to Morante and Blanco (2012).</note>

			<note place="foot" n="6"> Available at https://code.google.com/ archive/p/word2vec/ 7 The list was courtesy of Ulf Hermjakob and Nathan Schneider. 8 https://github.com/saffsd/geniatagger 9 Mapping available at https://github.com/ slavpetrov/universal-pos-tags</note>

			<note place="foot" n="10"> In order for the results to be comparable, we feed White&apos;s system with the cues from the gold-standard instead of automatically detecting them.</note>

			<note place="foot" n="11"> In some cases, we ended up with more than 10 examples for some cues given that some of the sentences we picked contained more than a negation instance.</note>

			<note place="foot" n="12"> The data, along with the code, is freely available at https://github.com/ffancellu/NegNN</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This project was also founded by the European Unions Horizon 2020 research and innovation programme under grant agreement No 644402 (HimL).</p><p>The authors would like to thank Naomi Saphra, Nathan Schneider and Claria Vania for the valu-able suggestions and the three anonymous review-ers for their comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation on synthetic data set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Methodology</head><p>One question left unanswered by previous work is whether the performance of scope detection classi- fiers is robust against data of a different genre and whether different types of negation lead to differ- ence in performance. To answer this, we compare two of our systems with the only original submis- sion to the *SEM2012 we found available (White, 2012) <ref type="bibr">10</ref> . We decided to use both our best sys- tem, BiLSTM+C+UniPoS+E and a sub-optimal systems, BiLSTM+C+E to also assess the robust- ness of non-English specific features. The synthetic test set here used is built on sen- tences extracted from Simple Wikipedia and man- ually annotated for cue and scope according to the annotation guidelines released in concomitance with the *SEM2012 shared task <ref type="bibr" target="#b15">(Morante et al., 2011)</ref>. We created 7 different subsets to test dif- ferent types of negative sentences:</p><p>Simple: we randomly picked 50 positive sen- tences, containing only one predicate, no dates and no named entities, and we made them negative by</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gs Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Devin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>White paper, Google Research</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Umichigan: A conditional random field model for resolving the scope of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Abu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Jbara</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="334" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ucm-2: a rule-based approach to infer the scope of negation via dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Gervás</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="288" to="293" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ugroningen: Negation detection with discourse representation structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Evang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noortje</forename><surname>Venhuizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="301" to="309" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Some issues on detecting negation from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">I</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS Conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="228" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fbk: Exploiting phrasal and contextual clues for negation scope detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Mahbub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="340" to="346" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ucm-i: A rule-based syntactic approach for resolving the scope of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Díaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="282" to="287" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Applying the semantics of negation to smt through nbest list re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Fancellu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="598" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Translating negation: A manual error analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Fancellu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ExProM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Uabcoral: a preliminary study for resolving the scope of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Gyawali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thamar</forename><surname>Solorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Semantic Evaluation</title>
		<meeting>the Sixth International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
	<note>Proceedings of the main conference and the shared task, and</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Uio 2: sequence-labeling negation using dependency features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Lapponi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Velldal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Read</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="319" to="327" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">* sem 2012 shared task: Resolving the scope and focus of negation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Blanco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Annotation of negation cues and their scope: Guidelines v1. Computational linguistics and psycholinguistics technical report series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Schrauwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<idno>CTRS- 003</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simple negation scope resolution through deep parsing: A semantic solution to a semantic problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woodley</forename><surname>Packard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Dridan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning structures of negations from flat annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinodkumar</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lexical and Computational Semantics (* SEM 2015)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Uio 1: Constituent-based discriminative ranking for negation resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Velldal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Developing a robust partof-speech tagger for biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcnaught</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in informatics</title>
		<imprint>
			<biblScope unit="page" from="382" to="392" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Speculation and negation: Rules, rankers, and the role of syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Velldal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational linguistics</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="369" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Enriching parallel corpora for statistical machine translation with semantic negation rephrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominikus</forename><surname>Wetzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="20" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Uwashington: Negation resolution using machine learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Paul White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="335" to="339" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
