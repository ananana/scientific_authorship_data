<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Mind/Brain Sciences</orgName>
								<orgName type="institution">University of Trento</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1403" to="1414"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Following up on recent work on establishing a mapping between vector-based semantic embeddings of words and the visual representations of the corresponding objects from natural images, we first present a simple approach to cross-modal vector-based semantics for the task of zero-shot learning, in which an image of a previously unseen object is mapped to a linguistic representation denoting its word. We then introduce fast mapping, a challenging and more cognitively plausible variant of the zero-shot task, in which the learner is exposed to new objects and the corresponding words in very limited linguistic contexts. By combining prior linguistic and visual knowledge acquired about words and their objects, as well as exploiting the limited new evidence available , the learner must learn to associate new objects with words. Our results on this task pave the way to realistic simulations of how children or robots could use existing knowledge to bootstrap grounded semantic knowledge about new concepts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computational models of meaning that rely on corpus-extracted context vectors, such as LSA <ref type="bibr" target="#b30">(Landauer and Dumais, 1997</ref>), HAL <ref type="bibr" target="#b35">(Lund and Burgess, 1996)</ref>, Topic Models ( <ref type="bibr" target="#b19">Griffiths et al., 2007</ref>) and more recent neural-network approaches <ref type="bibr" target="#b10">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b37">Mikolov et al., 2013b</ref>) have successfully tackled a number of lex- ical semantics tasks, where context vector sim- ilarity highly correlates with various indices of semantic relatedness <ref type="bibr" target="#b52">(Turney and Pantel, 2010)</ref>. Given that these models are learned from natu- rally occurring data using simple associative tech- niques, various authors have advanced the claim that they might be also capturing some crucial as- pects of how humans acquire and use language <ref type="bibr" target="#b30">(Landauer and Dumais, 1997;</ref><ref type="bibr" target="#b32">Lenci, 2008)</ref>.</p><p>However, the models induce the meaning of words entirely from their co-occurrence with other words, without links to the external world. This constitutes a serious blow to claims of cogni- tive plausibility in at least two respects. One is the grounding problem <ref type="bibr" target="#b23">(Harnad, 1990;</ref><ref type="bibr" target="#b42">Searle, 1984)</ref>. Irrespective of their relatively high per- formance on various semantic tasks, it is debat- able whether models that have no access to visual and perceptual information can capture the holis- tic, grounded knowledge that humans have about concepts. However, a possibly even more serious pitfall of vector models is lack of reference: natu- ral language is, fundamentally, a means to commu- nicate, and thus our words must be able to refer to objects, properties and events in the outside world <ref type="bibr" target="#b0">(Abbott, 2010)</ref>. Current vector models are purely language-internal, solipsistic models of meaning. Consider the very simple scenario in which visual information is being provided to an agent about the current state of the world, and the agent's task is to determine the truth of a statement similar to There is a dog in the room. Although the agent is equipped with a powerful context vector model, this will not suffice to successfully complete the task. The model might suggest that the concepts of dog and cat are semantically related, but it has no means to determine the visual appearance of dogs, and consequently no way to verify the truth of such a simple statement.</p><p>Mapping words to the objects they denote is such a core function of language that humans are highly optimized for it, as shown by the so-called fast mapping phenomenon, whereby children can learn to associate a word to an object or prop- erty by a single exposure to it <ref type="bibr" target="#b1">(Bloom, 2000;</ref><ref type="bibr" target="#b7">Carey, 1978;</ref><ref type="bibr" target="#b6">Carey and Bartlett, 1978;</ref><ref type="bibr" target="#b24">Heibeck and Markman, 1987)</ref>. But lack of reference is not only a theoretical weakness: Without the ability to refer to the outside world, context vectors are ar- guably useless for practical goals such as learning to execute natural language instructions <ref type="bibr" target="#b2">(Branavan et al., 2009;</ref><ref type="bibr" target="#b9">Chen and Mooney, 2011)</ref>, that could greatly benefit from the rich network of lex- ical meaning such vectors encode, in order to scale up to real-life challenges.</p><p>Very recently, a number of papers have ex- ploited advances in automated feature extraction form images and videos to enrich context vectors with visual information ( <ref type="bibr" target="#b4">Bruni et al., 2014;</ref><ref type="bibr" target="#b15">Feng and Lapata, 2010;</ref><ref type="bibr" target="#b33">Leong and Mihalcea, 2011;</ref><ref type="bibr" target="#b41">Regneri et al., 2013;</ref><ref type="bibr" target="#b44">Silberer et al., 2013)</ref>. This line of research tackles the grounding problem: Word representations are no longer limited to their linguistic contexts but also encode visual informa- tion present in images associated with the corre- sponding objects. In this paper, we rely on the same image analysis techniques but instead focus on the reference problem: We do not aim at en- riching word representations with visual informa- tion, although this might be a side effect of our approach, but we address the issue of automati- cally mapping objects, as depicted in images, to the context vectors representing the correspond- ing words. This is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hid- den layer that can be interpreted as a cross-modal semantic space.</p><p>We first test the effectiveness of our cross- modal semantic space on the so-called zero-shot learning task ( <ref type="bibr" target="#b39">Palatucci et al., 2009)</ref>, which has re- cently been explored in the machine learning com- munity ( <ref type="bibr" target="#b17">Frome et al., 2013;</ref><ref type="bibr" target="#b48">Socher et al., 2013)</ref>. In this setting, we assume that our system possesses linguistic and visual information for a set of con- cepts in the form of text-based representations of words and image-based vectors of the correspond- ing objects, used for vision-to-language-mapping training. The system is then provided with visual information for a previously unseen object, and the task is to associate it with a word by cross-modal mapping. Our approach is competitive with re- spect to the recently proposed alternatives, while being overall simpler.</p><p>The aforementioned task is very demanding and interesting from an engineering point of view. However, from a cognitive angle, it relies on strong, unrealistic assumptions: The learner is asked to establish a link between a new object and a word for which they possess a full-fledged text- based vector extracted from a billion-word cor- pus. On the contrary, the first time a learner is exposed to a new object, the linguistic informa- tion available is likely also very limited. Thus, in order to consider vision-to-language mapping un- der more plausible conditions, similar to the ones that children or robots in a new environment are faced with, we next simulate a scenario akin to fast mapping. We show that the induced cross-modal semantic space is powerful enough that sensible guesses about the correct word denoting an object can be made, even when the linguistic context vec- tor representing the word has been created from as little as 1 sentence containing it.</p><p>The contributions of this work are three-fold. First, we conduct experiments with simple image- and text-based vector representations and compare alternative methods to perform cross-modal map- ping. Then, we complement recent work <ref type="bibr" target="#b17">(Frome et al., 2013)</ref> and show that zero-shot learning scales to a large and noisy dataset. Finally, we pro- vide preliminary evidence that cross-modal pro- jections can be used effectively to simulate a fast mapping scenario, thus strengthening the claims of this approach as a full-fledged, fully inductive theory of meaning acquisition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The problem of establishing word reference has been extensively explored in computational sim- ulations of cross-situational learning (see <ref type="bibr" target="#b14">Fazly et al. (2010)</ref> for a recent proposal and extended re- view of previous work). This line of research has traditionally assumed artificial models of the ex- ternal world, typically a set of linguistic or logi- cal labels for objects, actions and possibly other aspects of a scene <ref type="bibr" target="#b45">(Siskind, 1996)</ref>. Recently, Yu and Siskind (2013) presented a system that induces word-object mappings from features ex- tracted from short videos paired with sentences. Our work complements theirs in two ways. First, unlike <ref type="bibr" target="#b56">Yu and Siskind (2013)</ref> who considered a limited lexicon of 15 items with only 4 nouns, we conduct experiments in a large search space con- taining a highly ambiguous set of potential target words for every object (see Section 4.1). Most im- portantly, by projecting visual representations of objects into a shared semantic space, we do not limit ourselves to establishing a link between ob-jects and words. We induce a rich semantic rep- resentation of the multimodal concept, that can lead, among other things, to the discovery of im- portant properties of an object even when we lack its linguistic label. Nevertheless, Yu and Siskind's system could in principle be used to initialize the vision-language mapping that we rely upon.</p><p>Closer to the spirit of our work are two very recent studies coming from the machine learning community. <ref type="bibr" target="#b48">Socher et al. (2013)</ref> and <ref type="bibr" target="#b17">Frome et al. (2013)</ref> focus on zero-shot learning in the vision- language domain by exploiting a shared visual- linguistic semantic space. <ref type="bibr" target="#b48">Socher et al. (2013)</ref> learn to project unsupervised vector-based image representations onto a word-based semantic space using a neural network architecture. Unlike us, Socher and colleagues train an outlier detector to decide whether a test image should receive a known-word label by means of a standard super- vised object classifier, or be assigned an unseen label by vision-to-language mapping. In our zero- shot experiments, we assume no access to an out- lier detector, and thus, the search for the correct label is performed in the full concept space. Fur- thermore, Socher and colleagues present a much more constrained evaluation setup, where only 10 concepts are considered, compared to our experi- ments with hundreds or thousands of concepts.  <ref type="formula" target="#formula_0">(2013)</ref> rely on a supervised state-of- the-art method: They feed low-level features to a deep neural network trained on a supervised object recognition task ( <ref type="bibr" target="#b28">Krizhevsky et al., 2012</ref>). Fur- thermore, their text-based vectors encode very rich information, such as king − man + woman = queen ( <ref type="bibr" target="#b38">Mikolov et al., 2013c)</ref>. A natural ques- tion we aim to answer is whether the success of cross-modal mapping is due to the high-quality embeddings or to the general algorithmic design. If the latter is the case, then these results could be extended to traditional distributional vectors bear- ing other desirable properties, such as high inter- pretability of dimensions. 3 Zero-shot learning and fast mapping "We found a cute, hairy wampimuk sleeping be- hind the tree." Even though the previous state- ment is certainly the first time one hears about wampimuks, the linguistic context already creates some visual expectations: Wampimuks probably resemble small animals ( <ref type="figure" target="#fig_1">Figure 1a</ref>). This is the scenario of zero-shot learning. Moreover, if this is also the first linguistic encounter of that concept, then we refer to the task as fast mapping.</p><p>Concretely, we assume that concepts, denoted for convenience by word labels, are represented in linguistic terms by vectors in a text-based distri- butional semantic space (see Section 4.3). Objects corresponding to concepts are represented in vi- sual terms by vectors in an image-based semantic space (Section 4.2). For a subset of concepts (e.g., a set of animals, a set of vehicles), we possess in- formation related to both their linguistic and visual representations. During training, this cross-modal vocabulary is used to induce a projection func- tion (Section 4.4), which -intuitively -represents a mapping between visual and linguistic dimen- sions. Thus, this function, given a visual vector, returns its corresponding linguistic representation. At test time, the system is presented with a previ- ously unseen object (e.g., wampimuk). This object is projected onto the linguistic space and associ- ated with the word label of the nearest neighbor in that space (degus in <ref type="figure" target="#fig_1">Figure 1b)</ref>.</p><p>The fast mapping setting can be seen as a spe- cial case of the zero-shot task. Whereas for the lat- ter our system assumes that all concepts have rich linguistic representations (i.e., representations es- timated from a large corpus), in the case of the for- mer, new concepts are assumed to be encounted in a limited linguistic context and therefore lacking rich linguistic representations. This is operational- ized by constructing the text-based vector for these concepts from a context of just a few occurrences. In this way, we simulate the first encounter of a learner with a concept that is new in both visual and linguistic terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Visual Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100</head><p>The CIFAR-100 dataset <ref type="bibr" target="#b29">(Krizhevsky, 2009)</ref> consists of 60,000 32x32 colour images (note the extremely small size) representing 100 distinct concepts, with 600 images per concept. The dataset covers a wide range of concrete domains and is organized into 20 broader categories. <ref type="table">Table 1</ref> lists the concepts used in our experiments organized by category.</p><p>ESP Our second dataset consists of 100K im- ages from the ESP-Game data set, labeled through a "game with a purpose" <ref type="bibr" target="#b54">(Von Ahn, 2006</ref>). <ref type="bibr">1</ref> The ESP image tags form a vocabulary of 20,515 unique words. Unlike other datasets used for zero- shot learning, it covers adjectives and verbs in ad- dition to nouns. On average, an image has 14 tags and a word appears as a tag for 70 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Visual Semantic Spaces</head><p>Image-based vectors are extracted using the unsu- pervised bag-of-visual-words (BoVW) represen- tational architecture <ref type="bibr" target="#b46">(Sivic and Zisserman, 2003;</ref><ref type="bibr" target="#b11">Csurka et al., 2004)</ref>, that has been widely and suc- cessfully applied to computer vision tasks such as object recognition and image retrieval ( <ref type="bibr" target="#b55">Yang et al., 2007</ref>). First, low-level visual features <ref type="bibr" target="#b51">(Szeliski, 2010)</ref> are extracted from a large collection of im- ages and clustered into a set of "visual words". The low-level features of a specific image are then mapped to the corresponding visual words, and the image is represented by a count vector recording the number of occurrences of each visual word in it. We do not attempt any parameter tuning of the pipeline.</p><p>As low-level features, we use Scale Invariant Feature Transform (SIFT) features <ref type="bibr" target="#b34">(Lowe, 2004)</ref>. SIFT features are tailored to capture object parts and to be invariant to several image transfor- mations such as rotation, illumination and scale change. These features are clustered into vocab- ularies of 5,000 (ESP) and 4,096 (CIFAR-100) vi- sual words. <ref type="bibr">2</ref> To preserve spatial information in the BoVW representation, we use the spatial pyramid technique ( <ref type="bibr" target="#b31">Lazebnik et al., 2006</ref>), which consists in dividing the image into several regions, comput- ing BoVW vectors for each region and concatenat- ing them. In particular, we divide ESP images into 16 regions and the smaller CIFAR-100 images into 4. The vectors resulting from region concatenation have dimensionality 5000 × 16 = 80, 000 (ESP) and 4, 096 × 4 = 16, 384 (CIFAR-100), respec- tively. We apply Local Mutual Information <ref type="bibr">(LMI, (Evert, 2005)</ref>) as weighting scheme and reduce the full co-occurrence space to 300 dimensions using the Singular Value Decomposition.</p><p>For CIFAR-100, we extract distinct visual vec- tors for single images. For ESP, given the size and amount of noise in this dataset, we build vec- tors for visual concepts, by normalizing and sum- ming the BoVW vectors of all the images that have the relevant concept as a tag. Note that relevant literature ( <ref type="bibr" target="#b40">Pereira et al., 2010</ref>) has emphasized the importance of learners self-generating multi- ple views when faced with new objects. Thus, our multiple-image assumption should not be consid- ered as problematic in the current setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Category</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seen Concepts</head><p>Unseen <ref type="table">(Test) Concepts  aquatic mammals  beaver, otter, seal, whale  dolphin  fish  ray, trout  shark  flowers  orchid, poppy, sunflower, tulip  rose  food containers  bottle, bowl, can ,plate  cup  fruit vegetable  apple, mushroom, pear  orange  household electrical devices  keyboard, lamp, telephone, television clock  household furniture  chair, couch, table, wardrobe  bed</ref>  <ref type="table">Table 1</ref>: Concepts in our version of the CIFAR-100 data set</p><note type="other">insects bee, beetle, caterpillar, cockroach butterfly large carnivores bear, leopard, lion, wolf tiger large man-made outdoor things bridge, castle, house, road skyscraper large natural outdoor scenes cloud, mountain, plain, sea forest large omnivores and herbivores camel, cattle, chimpanzee, kangaroo elephant medium-sized mammals fox, porcupine, possum, skunk raccoon non-insect invertebrates crab, snail, spider, worm lobster people baby, girl, man, woman boy reptiles crocodile, dinosaur, snake, turtle lizard small mammals hamster, mouse, rabbit, shrew squirrel vehicles 1 bicycle, motorcycle, train bus vehicles 2 rocket, tank, tractor streetcar</note><p>We implement the entire visual pipeline with VSEM, an open library for visual seman- tics ( <ref type="bibr" target="#b3">Bruni et al., 2013</ref>). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Linguistic Semantic Spaces</head><p>For constructing the text-based vectors, we fol- low a standard pipeline in distributional semantics (Turney and Pantel, 2010) without tuning its pa- rameters and collect co-occurrence statistics from the concatenation of ukWaC 4 and the Wikipedia, amounting to 2.7 billion tokens in total. Seman- tic vectors are constructed for a set of 30K target words (lemmas), namely the top 20K most fre- quent nouns, 5K most frequent adjectives and 5K most frequent verbs, and the same 30K lemmas are also employed as contextual elements. We collect co-occurrences in a symmetric context window of 20 elements around a target word. Finally, simi- larly to the visual semantic space, raw counts are transformed by applying LMI and then reduced to 300 dimensions with SVD. <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Cross-modal Mapping</head><p>The process of learning to map objects to the their word label is implemented by training a projec- tion function f projv→w from the visual onto the lin- guistic semantic space. For the learning, we use a set of N s seen concepts for which we have both image-based visual representations V s ∈ R Ns×dv and text-based linguistic representations W s ∈ R Ns×dw . The projection function is subject to an objective that aims at minimizing some cost function between the induced text-based represen- tationsˆWtationsˆ tationsˆW s ∈ R Ns×dw and the gold ones W s . The induced f projv→w is then applied to the image- based representations V u ∈ R Nu×dv of N u un- seen objects to transform them into text-based rep- resentationsˆWresentationsˆ resentationsˆW u ∈ R Nu×dw . We implement 4 alternative learning algorithms for inducing the cross-modal projection function f projv→w .</p><p>Linear Regression (lin) Our first model is a very simple linear mapping between the two modali- ties estimated by solving a least-squares problem. This method is similar to the one introduced by <ref type="bibr" target="#b36">Mikolov et al. (2013a)</ref> for estimating a translation matrix, only solved analytically. In our setup, we can see the two different modalities as if they were different languages. By using least-squares regres- sion, the projection function f projv→w can be de- rived as</p><formula xml:id="formula_0">f projv→w = (V T s V s ) −1 V T s W s<label>(1)</label></formula><p>Canonical Correlation Analysis (CCA) CCA ( <ref type="bibr" target="#b20">Hardoon et al., 2004;</ref><ref type="bibr" target="#b26">Hotelling, 1936)</ref> and variations thereof have been successfully used in the past for annotation of regions <ref type="bibr" target="#b47">(Socher and Fei-Fei, 2010</ref>) and complete images ( <ref type="bibr" target="#b21">Hardoon et al., 2006;</ref><ref type="bibr" target="#b25">Hodosh et al., 2013</ref>). Given two paired observation matrices, in our case V s and W s , CCA aims at capturing the linear relationship that exists between these variables. This is achieved by finding a pair of matrices, in our case C V ∈ R dv×d and C W ∈ R dw×d , such that the correlation between the projections of the two multidimensional variables into a common, lower-rank space is maximized. The resulting multimodal space has been shown to provide a good approximation to human concept similarity judgments <ref type="bibr" target="#b43">(Silberer and Lapata, 2012</ref>). In our setup, after applying CCA on the two spaces V s and W s , we obtain the two projection mappings onto the common space and thus our projection function can be derived as:</p><formula xml:id="formula_1">f projv→w = C V C W −1 (2)</formula><p>Singular Value Decomposition (SVD) SVD is the most widely used dimensionality reduction technique in distributional semantics <ref type="bibr" target="#b52">(Turney and Pantel, 2010)</ref>, and it has recently been exploited to combine visual and linguistic dimensions in the multimodal distributional semantic model of <ref type="bibr" target="#b4">Bruni et al. (2014)</ref>. SVD smoothing is also a way to infer values of unseen dimensions in partially incomplete matrices, a technique that has been ap- plied to the task of inferring word tags of unanno- tated images <ref type="bibr" target="#b22">(Hare et al., 2008)</ref>. Assuming that the concept-representing rows of V s and W s are or- dered in the same way, we apply the (k-truncated)</p><formula xml:id="formula_2">SVD to the concatenated matrix [V s W s ], such that [ ˆ V s ˆ W s ] = U k Σ k Z T k</formula><p>is a k-rank approxima- tion of the original matrix. <ref type="bibr">6</ref> The projection func- tion is then:</p><formula xml:id="formula_3">f projv→w = Z k Z T k (3)</formula><p>where the input is appropriately padded with 0s ([V u 0 N u×W ]) and we discard the visual block of the output matrix</p><formula xml:id="formula_4">[ ˆ V u ˆ W u ].</formula><p>Neural Network (NNet) The last model that we introduce is a neural network with one hidden layer. The projection function in this model can be described as:</p><formula xml:id="formula_5">f projv→w = Θ v→w (4)</formula><p>where Θ v→w consists of the model weights θ (1) ∈ R dv×h and θ (2) ∈ R h×dw that map the in- put image-based vectors V s first to the hid- den layer and then to the output layer in or- der to obtain text-based vectors, i.e., <ref type="bibr">(2)</ref> ), where σ (1) and σ (2) are the non-linear activation functions. We experi- mented with sigmoid, hyperbolic tangent and lin- ear; hyperbolic tangent yielded the highest perfor- mance. The weights are estimated by minimizing the objective function</p><formula xml:id="formula_6">ˆ W s = σ (2) (σ (1) (V s θ (1) )θ</formula><formula xml:id="formula_7">J(Θ v→w ) = 1 2 (1 − sim(W s , ˆ W s )) (5)</formula><p>where sim is some similarity function. In our ex- periments we used cosine as similarity function, so that sim(A, B) = AB AB , thus penalizing pa- rameter settings leading to a low cosine between the target linguistic representations W s and those produced by the projection functionˆWfunctionˆ functionˆW s . The co- sine has been widely used in the distributional se- mantic literature, and it has been shown to out- perform Euclidean distance <ref type="bibr" target="#b5">(Bullinaria and Levy, 2007)</ref>. <ref type="bibr">7</ref> Parameters were estimated with standard backpropagation and L-BFGS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Our experiments focus on the tasks of zero-shot learning (Sections 5.1 and 5.2) and fast mapping (Section 5.3). In both tasks, the projected vector of the unseen concept is labeled with the word asso- ciated to its cosine-based nearest neighbor vector in the corresponding semantic space.</p><p>For the zero-shot task we report the accuracy of retrieving the correct label among the top k neighbors from a semantic space populated with the union of seen and unseen concepts. For fast mapping, we report the mean rank of the correct concept among fast mapping candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Zero-shot Learning in CIFAR-100</head><p>For this experiment, we use the intersection of our linguistic space with the concepts present in CIFAR-100, containing a total of 90 concepts. For each concept category, we treat all concepts but one as seen concepts <ref type="table">(Table 1)</ref>. The 71 seen con- cepts correspond to 42,600 distinct visual vectors and are used to induce the projection function. Ta- ble 2 reports results obtained by averaging the per- formance on the 11,400 distinct vectors of the 19 unseen concepts.</p><p>Our 4 models introduced in Section 4.4 are compared to a theoretically derived baseline Chance simulating selecting a label at random. For the neural network NN, we use prior knowledge P P P P P P  about the number of concept categories to set the number of hidden units to 20 in order to avoid tuning of this parameter. For the SVD model, we set the number of dimensions to 300, a common choice in distributional semantics, coherent with the settings we used for the visual and linguistic spaces. First and foremost, all 4 models outperform Chance by a large margin. Surprisingly, the very simple lin method outperforms both CCA and SVD. However, NN, an architecture that can capture more complex, non-linear relations in features across modalities, emerges as the best performing model, confirming on a larger scale the recent find- ings of <ref type="bibr" target="#b48">Socher et al. (2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Concept Categorization</head><p>In order to gain qualitative insights into the perfor- mance of the projection process of NN, we attempt to investigate the role and interpretability of the hidden layer. We achieve this by looking at which visual concepts result in the highest hidden unit activation. 8 This is inspired by analogous quali- tative analysis conducted in Topic Models ( <ref type="bibr" target="#b19">Griffiths et al., 2007)</ref>, where "topics" are interpreted in terms of the words with the highest probability under each of them. <ref type="table">Table 3</ref> presents both seen and unseen con- cepts corresponding to visual vectors that trigger the highest activation for a subset of hidden units. The table further reports, for each hidden unit, the "correct" unseen concept for the category of the top seen concepts, together with its rank in terms of activation of the unit. The analysis demon- strates that, although prior knowledge about cat- egories was not explicitly used to train the net- work, the latter induced an organization of con- cepts into superordinate categories in which the Unseen Concept Nearest Neighbors tiger cat, microchip, kitten, vet, pet bike spoke, wheel, brake, tyre, motorcycle blossom bud, leaf, jasmine, petal, dandelion bakery quiche, bread, pie, bagel, curry <ref type="table">Table 4</ref>: Top 5 neighbors in linguistic space after visual vector projection of 4 unseen concepts.</p><p>hidden layer acts as a cross-modal concept cate- gorization/organization system. When the induced projection function maps an object onto the lin- guistic space, the derived text vector will inherit a mixture of textual features from the concepts that activated the same hidden unit as the object. This suggests a bias towards seen concepts. Fur- thermore, in many cases of miscategorization, the concepts are still semantically coherent with the induced category, confirming that the projection function is indeed capturing a latent, cross-modal semantic space. A squirrel, although not a "large omnivore", is still an animal, while butterflies are not flowers but often feed on their nectar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Zero-shot Learning in ESP</head><p>For this experiment, we focus on NN, the best per- forming model in the previous experiment. We use a set of approximately 9,500 concepts, the in- tersection of the ESP-based visual semantic space with the linguistic space. For tuning the number of hidden units of NN, we use the MEN-concrete dataset of <ref type="bibr" target="#b4">Bruni et al. (2014)</ref>. Finally, we ran- domly pick 70% of the concepts to induce the pro- jection function f projv→w and report results on the remaining 30%. Note that the search space for the correct label in this experiment is approximately 95 times larger than the one used for the experi- ment presented in Section 5.1.</p><p>Although our experimental setup differs from the one of <ref type="bibr" target="#b17">Frome et al. (2013)</ref>, thus preventing a direct comparison, the results reported in <ref type="table" target="#tab_3">Table 5</ref> are on a comparable scale to theirs. We note that previous work on zero-shot learning has used stan- dard object recognition benchmarks. To the best of our knowledge, this is the first time this task has been performed on a dataset as noisy as ESP. Over- all, the results suggest that cross-modal mapping could be applied in tasks where images exhibit a more complex structure, e.g., caption generation and event recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seen Concepts</head><p>Unseen Concept Rank of Correct CIFAR-100 Category Unseen Concept Unit 1 sunflower, tulip, pear butterfly 2 (rose) flowers Unit 2 cattle, camel, bear squirrel 2 (elephant) large omnivores and herbivores Unit 3 castle, bridge, house bus 4 (skyscraper) large man-made outdoor things Unit 4 man, girl, baby boy 1 people Unit 5 motorcycle, bicycle, tractor streetcar 2 (bus) vehicles 1 Unit 6 sea, plain, cloud forest 1 large natural outdoor scenes Unit 7 chair, couch, table bed 1 household furniture Unit 8 plate, bowl, can clock 3 (cup) food containers Unit 9 apple, pear, mushroom orange 1 fruit and vegetables <ref type="table">Table 3</ref>: Categorization induced by the hidden layer of the NN; concepts belonging in the same CIFAR- 100 categories, reported in the last column, are marked in bold. Example: Unit 1 receives the highest activation during training by the category flowers and at test time by butterfly, belonging to insects. The same unit receives the second highest activation by the "correct" test concept, the flower rose.</p><p>P P P P P P  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Fast Mapping in ESP</head><p>In this section, we aim at simulating a fast map- ping scenario in which the learner has been just exposed to a new concept, and thus has limited lin- guistic evidence for that concept. We operational- ize this by considering the 34 concrete concepts introduced by <ref type="bibr" target="#b16">Frassinelli and Keller (2012)</ref>, and deriving their text-based representations from just a few sentences randomly picked from the corpus. Concretely, we implement 5 models: context 1, con- text 5, context 10, context 20 and context full, where the name of the model denotes the number of sen- tences used to construct the text-based representa- tions. The derived vectors were reduced with the same SVD projection induced from the complete corpus. Cross-modal mapping is done via NN.</p><p>The zero-shot framework leads us to frame fast mapping as the task of projecting visual represen- tations of new objects onto language space for re- trieving their word labels (v → w). This mapping from visual to textual representations is arguably a more plausible task than vice versa. If we think about how linguistic reference is acquired, a sce- nario in which a learner first encounters a new ob- ject and then seeks its reference in the language of the surrounding environment (e.g., adults having a conversation, the text of a book with an illustration of an unknown object) is very natural. Further- more, since not all new concepts in the linguistic environment refer to new objects (they might de- note abstract concepts or out-of-scene objects), it seems more reasonable for the learner to be more alerted to linguistic cues about a recently-spotted new object than vice versa. Moreover, once the learner observes a new object, she can easily con- struct a full visual representation for it (and the acquisition literature has shown that humans are wired for good object segmentation and recogni- tion <ref type="bibr" target="#b49">(Spelke, 1994)</ref>) -the more challenging task is to scan the ongoing and very ambiguous linguistic communication for contexts that might be relevant and informative about the new object. However, fast mapping is often described in the psycholog- ical literature as the opposite task: The learner is exposed to a new word in context and has to search for the right object referring to it. We im- plement this second setup (w → v) by training the projection function f projw→v which maps linguis- tic vectors to visual ones. The adaptation of NN is straightforward; the new objective function is de- rived as <ref type="table" target="#tab_5">Table 7</ref> presents the results. Not surprisingly, performance increases with the number of sen- tences that are used to construct the textual repre- sentations. Furthermore, all models perform bet- ter than Chance, including those that are based on just 1 or 5 sentences. This suggests that the system can make reasonable inferences about object-word connections even when linguistic evidence is very scarce.</p><formula xml:id="formula_8">J(Θ w→v ) = 1 2 (1 − sim(V s , ˆ V s ))<label>(6)</label></formula><formula xml:id="formula_9">wherê V s = σ (2) (σ (1) (W s θ (1) )θ (2) ), θ (1) ∈ R dw×h and θ (2) ∈ R h×dv .</formula><p>Regarding the sources of error, a qualitative analysis of predicted word labels and objects as v→w w→v cooker→potato dishwasher→ corkscrew clarinet→ drum potato→ corn gorilla→ elephant guitar→ violin scooter→ car scarf→ trouser  presented in <ref type="table" target="#tab_4">Table 6</ref> suggests that both textual and visual representations, although capturing rel- evant "topical" or "domain" information, are not enough to single out the properties of the target concept. As an example, the textual vector of dish- washer contains kitchen-related dimensions such as fridge, oven, gas, hob, ..., sink. After projecting onto the visual space, its nearest visual neighbours are the visual ones of the same-domain concepts corkscrew and kettle. The latter is shown in <ref type="figure" target="#fig_3">Figure  3a</ref>, with a gas hob well in evidence. As a further example, the visual vector for cooker is extracted from pictures such as the one in <ref type="figure" target="#fig_3">Figure 3b</ref>. Not surprisingly, when projecting it onto the linguis- tic space, the nearest neighbours are other kitchen- related terms, i.e., potato and dishwasher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>At the outset of this work, we considered the problem of linking purely language-based distri- butional semantic spaces with objects in the vi- sual world by means of cross-modal mapping. We compared recent models for this task both on a benchmark object recognition dataset and on a more realistic and noisier dataset covering a wide range of concepts. The neural network architec- ture emerged as the best performing approach, and our qualitative analysis revealed that it induced a categorical organization of concepts. Most impor- tantly, our results suggest the viability of cross- modal mapping for grounded word-meaning ac- quisition in a simulation of fast mapping. Given the success of NN, we plan to experi- ment in the future with more sophisticated neural network architectures inspired by recent work in machine translation ( <ref type="bibr" target="#b18">Gao et al., 2013</ref>) and mul- timodal deep learning <ref type="bibr" target="#b50">(Srivastava and Salakhutdinov, 2012</ref>). Furthermore, we intend to adopt visual attributes <ref type="bibr" target="#b13">(Farhadi et al., 2009;</ref><ref type="bibr" target="#b44">Silberer et al., 2013)</ref> as visual representations, since they should allow a better understanding of how cross- modal mapping works, thanks to their linguistic interpretability. The error analysis in Section 5.3 suggests that automated localization techniques (van <ref type="bibr" target="#b53">de Sande et al., 2011)</ref>, distinguishing an ob- ject from its surroundings, might drastically im- prove mapping accuracy. Similarly, in the textual domain, models that extract collocates of a word that are more likely to denote conceptual proper- ties ( <ref type="bibr" target="#b27">Kelly et al., 2012</ref>) might lead to more infor- mative and discriminative linguistic vectors. Fi- nally, the lack of large child-directed speech cor- pora constrained the experimental design of fast mapping simulations; we plan to run more realis- tic experiments with true nonce words and using source corpora (e.g., the Simple Wikipedia, child stories, portions of CHILDES) that contain sen- tences more akin to those a child might effectively hear or read in her word-learning years.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Frome</head><label></label><figDesc>et al. (2013) use linear regression to transform vector-based image representations onto vectors representing the same concepts in linguis- tic semantic space. Unlike Socher et al. (2013) and the current study that adopt simple unsupervised techniques for constructing image representations, Frome et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A potential wampimuk (a) together with its projection onto the linguistic space (b).</figDesc><graphic url="image-1.png" coords="3,307.28,67.91,102.05,76.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Images of chair as extracted from CIFAR-100 (left) and ESP (right).</figDesc><graphic url="image-3.png" coords="4,88.76,62.81,76.80,76.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Two images from ESP.</figDesc><graphic url="image-6.png" coords="9,194.08,659.51,96.00,64.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Percentage accuracy among top k nearest 
neighbors on CIFAR-100. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Percentage accuracy among top k nearest 
neighbors on ESP. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 6 : Top-ranked concepts in cases where the gold concepts received numerically high ranks.</head><label>6</label><figDesc></figDesc><table>X X X X X X X X 

Context 
Mapping v → w w → v 

Chance 
17 
17 
context 1 
12.6 
14.5 
context 5 
8.08 
13.29 
context 10 
7.29 
13.44 
context 20 
6.02 
12.17 
context full 
5.52 
5.88 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Mean rank results averaged across 34 
concepts when mapping an image-based vector 
and retrieving its linguistic neighbors (v → w) as 
well as when mapping a text-based vector and 
retrieving its visual neighbors (w → v). Lower 
numbers cue better performance. 

</table></figure>

			<note place="foot">Unlike the CIFAR-100 images, which were chosen specifically for image object recognition tasks (i.e., each image is clearly depicting a single object in the foreground), ESP contains a random selection of images from the Web. Consequently, objects do not appear in most images in their prototypical display, but rather as elements of complex scenes (see Figure 2). Thus, ESP constitutes a more realistic, and at the same time more challenging, simulation of how things are encountered in real life, testing the potentials of cross-modal mapping in dealing with the complex scenes that one would encounter in event recognition and caption generation tasks. 1 http://www.cs.cmu.edu/ ˜ biglou/ resources/</note>

			<note place="foot" n="2"> For selecting the size of the vocabulary size, we relied on standard settings found in the relevant literature (Bruni et al., 2014; Chatfield et al., 2011).</note>

			<note place="foot" n="3"> http://clic.cimec.unitn.it/vsem/ 4 http://wacky.sslmit.unibo.it 5 We also experimented with the image-and text-based vectors of Socher et al. (2013), but achieved better performance with the reported setup.</note>

			<note place="foot" n="6"> We denote the right singular vectors matrix by Z instead of the customary V to avoid confusion with the visual matrix.</note>

			<note place="foot" n="7"> We also experimented with the same objective function as Socher et al. (2013), however, our objective function yielded consistently better results in all experimental settings.</note>

			<note place="foot" n="8"> For this post-hoc analysis, we include a sparsity parameter in the objective function of Equation 5 in order to get more interpretable results; hidden units are therefore maximally activated by a only few concepts.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Adam Liška for helpful discussions and the 3 anonymous reviewers for useful comments. This work was supported by ERC 2011 Starting Independent Research Grant n. 283554 (COM-POSES).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Abbott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How Children Learn the Meanings of Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bloom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Vsem: An open library for visual semantics representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulisse</forename><surname>Bordignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Liska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Sergienya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Extracting semantic representations from word co-occurrence statistics: A computational study. Behavior Research Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bullinaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Levy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="510" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Acquiring a single new word</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Carey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elsa</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Papers and Reports on Child Language Development</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="17" to="29" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The child as a word learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Carey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistics Theory and Psychological Reality</title>
		<editor>M. Halle, J. Bresnan, and G. Miller</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BMVC</title>
		<meeting>BMVC<address><addrLine>Dundee, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML<address><addrLine>Helsinki, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jutta</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cédric</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Statistical Learning in Computer Vision, ECCV</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Statistics of Word Cooccurrences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">Evert</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Stuttgart University</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Ph.D dissertation</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Describing objects by their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1778" to="1785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A probabilistic computational model of cross-situational word learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afsaneh</forename><surname>Fazly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afra</forename><surname>Alishahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1017" to="1063" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual information in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL<address><addrLine>Los Angeles, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The plausibility of semantic properties generated by a distributional model: Evidence from a visual world experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Frassinelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CogSci</title>
		<meeting>CogSci</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1560" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DeViSE: A deep visual-semantic embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2121" to="2129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning semantic representations for the phrase translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.0482</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Topics in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="211" to="244" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis: An overview with application to learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>David R Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shawetaylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2639" to="2664" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A correlation approach for automatic image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>David R Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandor</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Data Mining and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="681" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantic spaces revisited: Investigating the performance of auto-annotation and semantic retrieval using semantic spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Samangooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIVR</title>
		<meeting>CIVR<address><addrLine>Niagara Falls, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The symbol grounding problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stevan</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Word learning in children: an examination of fast mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><surname>Heibeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Markman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Child Development</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1021" to="1024" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Framing image description as a ranking task: Data, models and evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="853" to="899" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for automatic conceptual property extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Devereux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the 3rd Workshop on Cognitive Modeling and Computational Linguistics<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="240" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
	<note>Washington, DC</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Distributional approaches in linguistic and cognitive research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Italian Journal of Linguistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Going beyond text: A hybrid image-text approach for measuring word relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Chee Wee Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1403" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Producing high-dimensional semantic spaces from lexical cooccurrence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curt</forename><surname>Burgess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="203" to="208" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Zero-shot learning with semantic output codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Early biases and developmental changes in self-generated object views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfredo</forename><forename type="middle">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><forename type="middle">H</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda B</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dominikus Wetzel, Stefan Thater, Bernt Schiele, and Manfred Pinkal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Grounding action descriptions in videos</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Minds, Brains and Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Searle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Grounded models of semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1423" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Models of semantic representation with visual attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="572" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">A computational study of crosssituational techniques for learning word-to-meaning mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="39" to="91" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV<address><addrLine>Nice, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="966" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Lake Tahoe, Nevada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="935" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Initial knowledge: Six suggestions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Spelke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="431" to="445" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multimodal learning with deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2231" to="2239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Computer Vision : Algorithms and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Szeliski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">From frequency to meaning: Vector space models of semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Segmentation as selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Koen Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1879" to="1886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Games with a purpose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luis Von Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="92" to="94" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Evaluating bag-of-visualwords representations in scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multimedia Information Retrieval</title>
		<editor>James Ze Wang, Nozha Boujemaa, Alberto Del Bimbo, and Jia Li</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Grounded language learning from video described with sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haonan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
