<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raksha</forename><surname>Sharma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandipan</forename><surname>Dandapat</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft AI and Research</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><forename type="middle">Sharad</forename><surname>Bhatt</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">American Express Big Data Labs</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Himanshu.S.Bhatt@Aexp.Com</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="968" to="978"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>968</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Getting manually labeled data in each domain is always an expensive and a time consuming task. Cross-domain sentiment analysis has emerged as a demanding concept where a labeled source domain facilitates a sentiment classifier for an unlabeled target domain. However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another domain. Owing to these differences, cross-domain sentiment classification is still a challenging task. In this paper, we propose that words that do not change their polarity and significance represent the transfer-able (usable) information across domains for cross-domain sentiment classification. We present a novel approach based on χ 2 test and cosine-similarity between context vector of words to identify polarity preserving significant words across domains. Furthermore, we show that a weighted ensemble of the classifiers enhances the cross-domain classification performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The choice of the words to express an opinion de- pends on the domain as users often use domain- specific words ( <ref type="bibr" target="#b25">Qiu et al., 2009;</ref>). For example, entertaining and boring are frequently used in the movie domain to express an opinion; however, finding these words in the electronics domain is rare. Moreover, there are words which are likely to be used across do- mains in the same proportion, but may change their polarity orientation from one domain to an- other ( <ref type="bibr" target="#b8">Choi et al., 2009)</ref>. For example, a word like unpredictable is positive in the movie domain (un- predictable plot), but negative in the automobile domain (unpredictable steering). Such a polarity changing word should be assigned positive orien- tation in the movie domain and negative orienta- tion in the automobile domain. <ref type="bibr">1</ref> Due to these dif- ferences across domains, a supervised algorithm trained on a labeled source domain, does not gen- eralize well on an unlabeled target domain and the cross-domain performance degrades.</p><p>Generally, supervised learning algorithms have to be re-trained from scratch on every new domain using the manually annotated review corpus ( <ref type="bibr" target="#b22">Pang et al., 2002;</ref><ref type="bibr" target="#b16">Kanayama and Nasukawa, 2006;</ref><ref type="bibr" target="#b21">Pang and Lee, 2008;</ref><ref type="bibr" target="#b9">Esuli and Sebastiani, 2005;</ref><ref type="bibr" target="#b5">Breck et al., 2007;</ref><ref type="bibr" target="#b17">Li et al., 2009;</ref><ref type="bibr" target="#b24">Prabowo and Thelwall, 2009;</ref><ref type="bibr" target="#b33">Taboada et al., 2011;</ref><ref type="bibr" target="#b28">Rosenthal et al., 2014</ref>). This is not practical as there are numerous domains and getting manu- ally annotated data for every new domain is an ex- pensive and time consuming task <ref type="bibr" target="#b3">(Bhattacharyya, 2015)</ref>. On the other hand, domain adaptation tech- niques work in contrast to traditional supervised techniques on the principle of transferring learned knowledge across domains <ref type="bibr" target="#b4">(Blitzer et al., 2007;</ref><ref type="bibr" target="#b20">Pan et al., 2010;</ref><ref type="bibr" target="#b2">Bhatt et al., 2015</ref>). The exist- ing transfer learning based domain adaptation al- gorithms for cross-domain classification have gen- erally been proven useful in reducing the labeled data requirement, but they do not consider words like unpredictable that change polarity orienta- tion across domains. Transfer (reuse) of chang- ing polarity words affects the cross-domain per- formance negatively. Therefore, one cannot use transfer learning as the proverbial hammer, rather one needs to gauge what to transfer from the source domain to the target domain.</p><p>In this paper, we propose that the words which are equally significant with a consistent polar- ity across domains represent the usable informa- tion for cross-domain sentiment analysis. χ 2 is a popularly used and reliable statistical test to identify significance and polarity of a word in an annotated corpus ( <ref type="bibr" target="#b19">Oakes et al., 2001;</ref><ref type="bibr" target="#b0">Al-Harbi et al., 2008;</ref><ref type="bibr" target="#b7">Cheng and Zhulyn, 2012;</ref><ref type="bibr" target="#b30">Sharma and Bhattacharyya, 2013)</ref>. However, for an un- labeled corpus no such statistical technique is ap- plicable. Therefore, identification of words which are significant with a consistent polarity across domains is a non-trivial task. In this paper, we present a novel technique based on χ 2 test and cosine-similarity between context vector of words to identify Significant Consistent Polarity (SCP) words across domains. <ref type="bibr">2</ref> The major contribution of this research is as follows.</p><p>1. Extracting significant consistent polarity words across domains: A technique which exploits cosine-similarity between context vector of words and χ 2 test is used to iden- tify SCP words across labeled source and un- labeled target domains.</p><p>2. An ensemble-based adaptation algorithm: A classifier (C s ) trained on SCP words in the labeled source domain acts as a seed to initi- ate a classifier (C t ) on the target specific fea- tures. These classifiers are then combined in a weighted ensemble to further enhance the cross-domain classification performance.</p><p>Our results show that our approach gives a sta- tistically significant improvement over Structured Correspondence Learning (SCL) <ref type="bibr" target="#b2">(Bhatt et al., 2015)</ref> and common unigrams in identification of transferable words, which eventually facilitates a more accurate sentiment classifier in the target do- main. The road-map for rest of the paper is as fol- lows. Section 2 describes the related work. Sec- tion 3 describes the extraction of the SCP and the ensemble-based adaptation algorithm. Section 4 elaborates the dataset and the experimental proto- col. Section 5 presents the results and section 6 reports the error analysis. Section 7 concludes the paper. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The most significant efforts in the learning of transferable knowledge for cross-domain text clas- sification are Structured Correspondence Learning (SCL) <ref type="bibr" target="#b4">(Blitzer et al., 2007)</ref> and Structured Fea- ture Alignment (SFA) ( <ref type="bibr" target="#b20">Pan et al., 2010)</ref>. SCL aims to learn the co-occurrence between features from the two domains. It starts with learning pivot features that occur frequently in both the do- mains. It models correlation between pivots and all other features by training linear predictors to predict presence of pivot features in the unlabeled target domain data. SCL has shown significant im- provement over a baseline (shift-unaware) model. SFA uses some domain-independent words as a bridge to construct a bipartite graph to model the co-occurrence relationship between domain- specific words and domain-independent words. Our approach also exploits the concept of co- occurrence ( <ref type="bibr" target="#b20">Pan et al., 2010</ref>), but we measure the co-occurrence in terms of similarity between con- text vector of words, unlike SCL and SFA, which literally look for the co-occurrence of words in the corpus. The use of context vector of words in place of words helps to overcome the data sparsity problem ( .</p><p>Domain adaptation for sentiment classification has been explored by many researchers <ref type="bibr" target="#b15">(Jiang and Zhai, 2007;</ref><ref type="bibr" target="#b14">Ji et al., 2011;</ref><ref type="bibr" target="#b29">Saha et al., 2011;</ref><ref type="bibr" target="#b12">Glorot et al., 2011;</ref><ref type="bibr" target="#b38">Zhou et al., 2014;</ref><ref type="bibr" target="#b2">Bhatt et al., 2015</ref>). Most of the works have fo- cused on learning a shared low dimensional repre- sentation of features that can be generalized across different domains. However, none of the ap- proaches explicitly analyses significance and po- larity of words across domains. On the other hand, <ref type="bibr" target="#b12">Glorot et al., (2011)</ref> proposed a deep learn- ing approach which learns to extract a meaning- ful representation for each review in an unsuper- vised fashion. <ref type="bibr" target="#b38">Zhou et al., (2014)</ref> also proposed a deep learning approach to learn a feature mapping between cross-domain heterogeneous features as well as a better feature representation for mapped data to reduce the bias issue caused by the cross- domain correspondences. Though deep learning based approaches perform reasonably good, they don't perform explicit identification and visualiza- tion of transferable features across domains un- like SFA and SCL, which output a set of words as transferable (reusable) features. Our approach explicitly determines the words which are equally significant with a consistent polarity across source and target domains. Our results show that the use of SCP words as features identified by our ap- proach leads to a more accurate cross-domain sen- timent classifier in the unlabeled target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach: Cross-domain Sentiment Classification</head><p>The proposed approach identifies words which are equally significant for sentiment classification with a consistent polarity across source and tar- get domains. These Significant Consistent Polar- ity (SCP) words make a set of transferable knowl- edge from the labeled source domain to the un- labeled target domain for cross-domain sentiment analysis. The algorithm further adapts to the un- labeled target domain by learning target domain specific features. The following sections elaborate SCP features extraction (3.1) and the ensemble- based cross-domain adaptation algorithm (3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extracting SCP Features</head><p>The words which are not significant for classifi- cation in the labeled source domain, do not trans- fer useful knowledge to the target domain through a supervised classifier trained in the source do- main. Moreover, words that are significant in both the domains, but have different polarity orienta- tion transfer the wrong information to the target domain through a supervised classifier trained in the labeled source domain, which also downgrade the cross-domain performance. Our algorithm identifies the significance and the polarity of all the words individually in their re- spective domains. Then the words which are sig- nificant in both the domains with the consistent polarity orientation are used to initiate the cross- domain adaptation algorithm. The following sec- tions elaborate how the significance and the polar- ity of the words are obtained in the labeled source and the unlabeled target domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Extracting Significant Words with the</head><p>Polarity Orientation from the Labeled Source Domain Since we have a polarity annotated dataset in the source domain, a statistical test like χ 2 test can be applied to find the significance of a word in the corpus for sentiment classification <ref type="bibr" target="#b7">(Cheng and Zhulyn, 2012;</ref><ref type="bibr" target="#b37">Zheng et al., 2004</ref>). We have used goodness of fit chi 2 test with equal number of re- views in positive and negative corpora. This test is generally used to determine whether sample data is consistent with a null hypothesis. <ref type="bibr">4</ref> Here, the null hypothesis is that the word is equally used in the positive and the negative corpora. The χ 2 test is formulated as follows:</p><formula xml:id="formula_0">χ 2 (w) = ((c w p − µ w ) 2 + (c w n − µ w ) 2 )/µ w (1)</formula><p>Where, c w p is the observed count of a word w in the positive documents and c w n is the observed count in the negative documents. µ w represents an average of the word's count in the positive and the negative documents. Here, µ w is the expected count or the value of the null-hypothesis. There is an inverse relation between χ 2 value and the p-value which is probability of the data given null hypothesis is true. In such a case where a word results in a p- value smaller than the critical p-value (0.05), we reject the null-hypothesis. Consequently, we as- sume that the word w belongs to a particular class (positive or negative) in the data, hence it is a sig- nificant word for classification <ref type="bibr" target="#b30">(Sharma and Bhattacharyya, 2013)</ref>.</p><p>Polarity of Words in the Labeled Source Do- main: Chi-square test substantiates the statisti- cally significant association of a word with a class label. Based on this association we assign a polar- ity orientation to a word in the domain. In other words, if a word is found significant by χ 2 test, then the exact class of the word is determined by comparing c w p and c w n . For instance, if c w p is higher than c w n , then the word is positive, else negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Extracting Significant Words with the Polarity Orientation from the Unlabeled Target Domain</head><p>Target domain data is unlabeled and hence, χ 2 test cannot be used to find significance of the words. However, to obtain SCP words across domains, we take advantage of the fact that we have to identify significance of only those words in the target do- main which are already proven to be significant in the source domain. We presume that a word which is significant in the source domain as per χ 2 test and occurs with a frequency greater than a certain threshold (θ) in the target domain is significant in the target domain also.</p><formula xml:id="formula_1">count t (signif icant s (w)) &gt; θ ⇒ signif icant t (w)<label>(2)</label></formula><p>Equation <ref type="formula" target="#formula_1">(2)</ref> formulates the significance test in the unlabeled target (t) domain. Here, function signif icant s assures the significance of the word w in the labeled source (s) domain and count t gives the normalized count of the w in t. 5 χ 2 test has one key assumption that the expected value of an observed variable should not be less than 5 to be significant. Considering this assumption as a base, we fix the value of θ as 10. <ref type="bibr">6</ref> Polarity of Words in the Unlabeled Target Domain: Generally, in a polar corpus, a posi- tive word occurs more frequently in context of other positive words, while a negative word oc- curs in context of other negative words ( . <ref type="bibr">7</ref> Based on this hypothesis, we ex- plore the contextual information of a word that is captured well by its context vector to assign po- larity to words in the target domain ( <ref type="bibr" target="#b26">Rill et al., 2012;</ref><ref type="bibr" target="#b27">Rong, 2014)</ref>. <ref type="bibr" target="#b18">Mikolov et al., (2013)</ref> showed that similarity between context vector of words in vicinity such as 'go' and 'to' is higher compared to distant words or words that are not in the neigh- borhood of each other. Here, the observed concept is that if a word is positive, then its context vec- tor learned from the polar review corpus will give higher cosine-similarity with a known positive po- larity word in comparison to a known negative po- larity word or vice versa. Therefore, based on the cosine-similarity scores we can assign the label of the known polarity word to the unknown polarity word. We term known polarity words as Positive- pivot and Negative-pivot.</p><p>Context Vector Generation: To compute con- text vector (conV ec) of a word (w), we have used publicly available word2vec toolkit with the skip-gram model ( <ref type="bibr" target="#b18">Mikolov et al., 2013)</ref>. 8 In this model, each word's Huffman code is used as an input to a log-linear classifier with a continuous projection layer and words within a given win- dow are predicted <ref type="bibr" target="#b11">(Faruqui et al., 2014</ref>). We construct a 100 dimensional vector for each can- <ref type="bibr">5</ref> Normalized count of w in t shows the proportion of oc- currences of w in t. <ref type="bibr">6</ref> We tried with smaller values of theta also, but they were not found as effective as theta value of 10 for significant words identification. <ref type="bibr">7</ref> For example, 'excellent' will be used more often in pos- itive reviews in comparison to negative reviews, hence, it would have more positive words in its context. Likewise, 'terrible' will be used more frequently in negative reviews in comparison to positive reviews, hence, it would have more negative words in its context. <ref type="bibr">8</ref> Available at: https://radimrehurek.com/ gensim/models/word2vec.html didate word from the unlabeled target domain data. The decision method given in Equation 3 defines the polarity assignment to the un- known polarity words of the target domain. If a word w gives a higher cosine-similarity with the PosPivot (Positive-pivot) than the NegPivot (Negative-pivot), the decision method assigns the positive polarity to the word w, else negative po- larity to the word w.</p><formula xml:id="formula_2">If(cosine(conV ec(w), conV ec(PosPivot)) &gt; cosine(conV ec(w), conV ec(NegPivot))) ⇒ Positive If(cosine(conV ec(w), conV ec(PosPivot)) &lt; cosine(conV ec(w), conV ec(NegPivot))) ⇒ Negative<label>(3)</label></formula><p>Pivot Selection Method: We empirically ob- served that a polar word which has the highest fre- quency in the corpus gives more coverage to esti- mate the polarity orientation of other words while using context vector. Essentially, the frequent oc- currence of the word in the corpus allows it to be in context of other words frequently. Therefore a polar word having the highest frequency in the target domain is observed to be more accurate as pivot for identification of polarity of input words. 9 <ref type="table" target="#tab_0">Table 1</ref> shows the examples of a few words in the electronics domain whose polarity orientation is derived based on the similarity scores obtained with PosPivot and NegPivot words in the electron- ics domain. Transferable Knowledge: The proposed algo- rithm uses the above mentioned techniques to identify the significance and the polarity of words in the labeled source data (cf. Section 3.1.1) and the unlabeled target data (cf. Section 3.1.2). The words which are found significant in both the do- mains with the same polarity orientation form a set of SCP features for cross-domain sentiment classi- fication. The weights learned for the SCP features in the labeled source domain by the classification algorithm can be reused for sentiment classifica- tion in the unlabeled target domain as SCP features have consistent impacts in both the domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word</head><p>Great  and the confidently predicted instances of D u t form a set of pseudo labeled instances R n t .</p><note type="other">Poor Polarity Noisy 0.03 0.24 Neg Crap 0.04 0.28 Neg Weak 0.05 0.21 Neg Defective 0.21 0.70 Neg Sturdy 0.43 0.04 Pos Durable 0.44 0.00 Pos Perfect 0.48 0.20 Pos Handy 0.60 0.21 Pos</note><p>4. A SVM based classifier is trained on the pseudo labeled target domain instances R n t , using unigrams in R n t as features to include the target specific words, this classifier is named as C t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Finally, a Weighted Sum Model (WSM) of</head><p>C s and C t gives a classifier in the target do- main.</p><p>The confidence in the prediction of D u t is mea- sured in terms of the classification-score of the document, i.e., the distance of the input document from the separating hyper-plane given by the SVM classifier ( <ref type="bibr" target="#b13">Hsu et al., 2003</ref>). The top n confidently predicted pseudo labeled instances (R n t ) are used to train classifier C t , where n depends on a thresh- old that is empirically set to | ± 0.2|. <ref type="bibr">10</ref> The clas- sifier C s trained on the SCP features (transferred knowledge) from the source domain and the clas- sifier C t trained on self-discovered target specific features from the pseudo labeled target domain in- stances bring in complementary information from the two domains. Therefore, combining C s and C t in a weighted ensemble (WSM) further enhances the cross-domain performance. Algorithm 1 gives the pseudo code of the proposed adaptation ap- proach.  <ref type="bibr" target="#b1">Balamurali et al., (2013)</ref> have shown that 350 to 400 la- beled documents are required to get a high accuracy classifier in a domain using supervised classification techniques, but beyond 400 labeled documents there is not much improve- ment in the classification accuracy. Hence, threshold on clas- sification score is set such that it can give a sufficient number of documents for supervised classification. Threshold |±0.2| gives documents between 350 to 400. rors produced by the individual classifier. The for- mulation of WSM is given in step-6 of the Al- gorithm 1. If C s has wrongly predicted a docu- ment at boundary point and C t has predicted the same document confidently, then weighted sum of C s and C t predicts the document correctly or vice versa. For example, a document is classi- fied by C s as negative (wrong prediction) with a classification-score of −0.07, while the same document is classified by C t as positive (correct prediction) with a classification-score of 0.33, the WSM of C s and C t will classify the document as positive with a classification-score of 0.12 (Equa- tion 4). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset &amp; Experimental Protocol</head><p>In this paper, we show comparison between SCP- based domain adaptation (our approach) and SCL- based domain adaptation approach proposed by <ref type="bibr">Bhatt el al. (2015)</ref> using four domains, viz., Elec- tronics (E), Kitchen (K), Books (B), and DVD. <ref type="bibr">11</ref> We use SVM algorithm with linear kernel <ref type="bibr" target="#b34">(Tong and Koller, 2002</ref>) to train a classifier in all the mentioned classification systems in the paper. To implement SVM algorithm, we have used the pub- licly available Python based Scikit-learn package <ref type="bibr" target="#b23">(Pedregosa et al., 2011</ref>). 12 Data in each domain is divided into three parts, viz., train (60%), val- idation (20%) and test (20%). The SCP words are extracted from the training data. The weights W S and W t for the source and target classifiers are essentially accuracies obtained by C s and C t respectively on validation dataset from the target domain. We report the accuracy for all the sys- tems on the test data. <ref type="table" target="#tab_4">Table 3</ref> shows the statistics of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain</head><p>No  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this paper, we compare our approach with Structured Correspondence Learning (SCL) and common unigrams. SCL is used by <ref type="bibr" target="#b2">Bhatt et al., (2015)</ref> for identification of transferable informa- tion from the labeled source domain to the unla- beled target domain for cross-domain sentiment analysis. They showed that transferable features extracted by SCL provide a better cross-domain sentiment analysis system than the transferable features extracted by Structured Feature Align- ment ( <ref type="bibr" target="#b20">Pan et al., 2010</ref>). The SCL-based sentiment classifier in the target domain proposed by <ref type="bibr" target="#b2">Bhatt et. al., (2015)</ref> is state-of-the-art for cross-domain sentiment analysis. On the other hand, common unigrams of the source and target are the most vis- ible transferable information. <ref type="bibr">13</ref> Gold standard SCP words: Chi-square test gives us significance and polarity of the word in the corpus by taking into account the polarity la- bels of the reviews. Application of chi-square test in both the domains, considering that the target do- main is also labeled, gives us gold standard SCP words. There is no manual annotation involved.</p><p>F-score for SCP Words Identification Task: The set of SCP words represent the usable in- formation across domains for cross-domain clas- sification, hence we compare the F-score for the SCP words identification task obtained with our approach, SCL and common-unigrams in <ref type="figure">Figure  1</ref>. It demonstrates that our approach gives a huge improvement in the F-score over SCL and com- mon unigrams for all the 12 pairs of the source and target domains. To measure the statistical sig- nificance of this improvement, we applied t-test on the F-score distribution obtained with our ap- proach, SCL and common unigrams. t-test is a statistical significance test. It is used to determine whether two sets of data are significantly different or not. <ref type="bibr">14</ref> Our approach performs significantly bet- ter than SCL and common unigrams, while SCL performs better than common unigrams as per t- test.</p><p>Comparison among C s , C t and WSM: Ta- ble 4 shows the comparison among classifiers ob- tained in the target domain using SCP given by our approach, SCL, common-unigrams, and gold stan- dard SCP for electronics as the source and movie as the target domains. Since electronics and movie are two very dissimilar domains in terms of do- main specific words, unlike, books and movie, get- ting a high accuracy classifier in the movie domain from the electronics domain is a challenging task ( <ref type="bibr" target="#b22">Pang et al., 2002</ref>). Therefore, in <ref type="table" target="#tab_6">Table 4</ref> results are reported with electronics as the source domain and movie as the target domain. <ref type="bibr">15</ref> In all four cases, there is difference in the transferred information from the source to the target, but the ensemble- based classification algorithm (Section 3.2) is the same. <ref type="table" target="#tab_6">Table 4</ref> depicts sentiment classification accuracy obtained with C s , C t and WSM. The weights W s and W t in WSM are normalized ac- curacies by C s and C t respectively on the valida- tion set from the target domain. The fourth column (size) represents the feature set size. We observed that WSM gives the highest accuracy, which vali- dates our assumption that a weighted sum of two classifiers is better than the performance of indi- vidual classifiers. The WSM accuracy obtained with SCP words given by our approach is compa- rable to the accuracy obtained with gold standard SCP words.</p><p>The motivation of this research is to learn shared representation cognizant of significant and polarity changing words across domains. Hence, we report cross-domain classification ac- curacy obtained with three different types of shared representations (transferable knowledge), viz., common-unigrams, SCL and our approach. <ref type="bibr">16</ref> System-1, system-2 and system-3 in <ref type="table" target="#tab_8">Table 5</ref> show the final cross-domain sentiment classification ac- curacy obtained with WSM in the target domain <ref type="bibr">14</ref> The detail about the test is available at: http://www. socialresearchmethods.net/kb/stat_t.php. <ref type="bibr">15</ref> The movie review dataset is a balanced corpus of 2000 reviews. Available at: http://www.cs.cornell. edu/people/pabo/movie-review-data/ <ref type="bibr">16</ref> The reported accuracy is the ratio of correctly predicted documents to that of the total number of documents in the test dataset.  for 12 pairs of source and target using common- unigrams, SCL and our approach respectively. System-1: This system considers common- unigrams of both the domains as shared repre- sentation. System-2: It differs from system-1 in the shared representation, which is learned us- ing Structured Correspondence Learning (SCL) <ref type="bibr" target="#b2">(Bhatt et al., 2015</ref>) to initiate the process. System- 3: This system implements the proposed domain adaptation algorithm. Here, the shared represen- tation is the SCP words and the ensemble-based domain adaptation algorithm (Section 3.2) gives the final classifier in the target domain. <ref type="table" target="#tab_8">Table 5</ref> depicts that the system-3 is better than system-1 and system-2 for all pairs, except K to B and B to D. For these two pairs, system-2 performs better than system-3, though the difference in accuracy is very low (below 1%).</p><p>To enhance the final accuracy in the target do- main, <ref type="bibr" target="#b2">Bhatt et al., (2015)</ref> performed iterations over the pseudo labeled target domain instances (R n t ). In each iteration, they obtained a new C t trained on increased number of pseudo labeled documents. This process is repeated till all the training instances of the target domain are consid- ered. The C t obtained in the last iteration makes WSM with C s which is trained on the transfer- able features given by SCL. <ref type="bibr" target="#b2">Bhatt et al., (2015)</ref> have shown that iteration-based domain adapta- tion technique is more effective than one-shot <ref type="figure">Figure 1</ref>: F-score for SCP words identification task (Source → Target) with respect to gold standard SCP words.   <ref type="table">Table 6</ref>: In-domain sentiment classification accu- racy using significant words and unigrams.</p><p>adaptation approaches. System-4, system-5, and system-6 in <ref type="table" target="#tab_8">Table 5</ref> incorporate the iterative pro- cess into system-1, system-2, and system-3 re- spectively. We observed the same trend after the inclusion of the iterative process also, as the SCP- based system-6 performed the best in all 12 cases. On the other hand, SCL-based system-5 performs better than the common-unigrams based system- 4. <ref type="table" target="#tab_10">Table 7</ref> shows the results of significance test (t- test) performed on the accuracy distributions pro- duced by the six different systems. The notice- able point is that the iterations over SCL (system- 5) and our approach (system-6) narrow down the difference in the accuracy between system-2 and system-3 as system-2 and system-3 have a statis- tically significant difference in accuracy with the p-value of 0.039 (Row-4 of <ref type="table" target="#tab_10">Table 7</ref>), but the dif- ference between system-5 and system-6 is not sta- tistically significant. Essentially, system-3 does not give much improvement with iterations, unlike system-2. In other words, addition of the iterative process with the shared representation given by SCL overcomes the errors introduced by SCL. On the other hand, SCP given by our approach were able to produce a less erroneous system in one- shot. <ref type="table">Table 6</ref> shows the in-domain sentiment clas- sification accuracy obtained with unigrams and significant words as features considering labeled data in the domain. System-6 tries to equalize the in-domain accuracy obtained with unigrams.  To validate our assertion that polarity preserv- ing significant words (SCP) across source and tar- get domains make a less erroneous set of trans- ferable knowledge from the source domain to the target domain, we computed Pearson product- moment correlation between F-score obtained for our approach (cf. <ref type="figure">Figure 1</ref>) and cross-domain ac- curacy obtained with SCP (System-3, cf. <ref type="table" target="#tab_8">Table  5</ref>). We observed a strong positive correlation (r) of 0.78 between F-score and cross-domain accu- racy. Essentially, an accurate set of SCP words positively stimulates an improved classifier in the unlabeled target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Error Analysis</head><p>The pairs of domains which share a greater num- ber of domain-specific words, result in a higher ac- curacy cross-domain classifier. For example, Elec- tronics (E) and Kitchen (K) domains share many domain-specific words, hence pairing of such sim- ilar domains as the source and the target results into a higher accuracy classifier in the target do- main. <ref type="table" target="#tab_8">Table 5</ref> shows that K→E outperforms B→E and D→E, and E→K outperforms B→K and D→K. On the other hand, DVD (D) and elec- tronics are two very different domains unlike elec- tronics and Kitchen, or DVD and books. The DVD dataset contains reviews about the music albums. This difference in types of reviews makes them to share less number of words. <ref type="table">Table 8</ref> shows the percent (%) of common words among the 4 do- mains. The percent of common unique words are common unique words divided by the summation of unique words in the domains individually. <ref type="table" target="#tab_0">15  22  17  14  22  17   Table 8</ref>: Common unique words between the do- mains in percent (%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E -D E -K E -B D -K D -B K -B</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed that the Significant Consistent Polarity (SCP) words represent the transferable information from the labeled source domain to the unlabeled target domain for cross- domain sentiment classification. We showed a strong positive correlation of 0.78 between the SCP words identified by our approach and the sen- timent classification accuracy achieved in the un- labeled target domain. Essentially, a set of less erroneous transferable features leads to a more ac- curate classification system in the unlabeled tar- get domain. We have presented a technique based on χ 2 test and cosine-similarity between context vector of words to identify SCP words. Results show that the SCP words given by our approach represent more accurate transferable information in comparison to the Structured Correspondence Learning (SCL) algorithm and common-unigrams. Furthermore, we show that an ensemble of the classifiers trained on the SCP features and target specific features overcomes the errors of the indi- vidual classifiers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>.</head><label></label><figDesc>765 and 0.712 are the weights W s and W t to the classifiers C s and C t respectively. Weights to the Classifiers in WSM: The weights W s and W t are the classification accuracies ob- tained by C s and C t respectively on the cross- validation data from the target domain. The weights W s and W t allow C s and C t to partici- pate in the WSM in proportion of their accuracy on the cross-validation data. This restriction fa- cilitates the domination of the classifier which is more accurate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Cosine-similarity scores with PosPivot 
(great) and NegPivot (poor), and inferred polarity 
orientation of the words. 

Symbol 
Description 
s, t 
Represent Source (s) and Target (t) respectively 
l, u 
Represent labeled and unlabeled respectively 
D l 
s , D u 

t 

Represent Dataset in s and t domains respectively 
Vs, Vt 
Vocabularies of words in the s and t respectively 
r i 
s ,r i 

t 

i th review in D l 
s and D u 
t respectively 
sigP ol() 
Identifies significant words with their polarity 
f 
Set of features 
SVM 
Implemented classification algorithm 
Cs 
Classifier Cs is trained on D l 
s with SCP as features 
R n 

t 

Top-n reviews in t as per classification score by Cs 
Ct 
Classifier Ct is trained on R t 

n 

unigrams() 
Gives bag-of-words 
Ws, Wt 
Weights for Cs and Ct respectively 
WSM 
Weighted Sum Model 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Notations used in the paper 

3.2 Ensemble-based Cross-domain 
Adaptation Algorithm 

Apart from the transferable SCP words (Obtained 
in Section 3.1), each domain has specific discrim-
inating words which can be discovered only from 
that domain data. The proposed cross-domain 
adaptation approach (Algorithm 1) attempts to 
learn such domain specific features from the tar-
get domain using a classifier trained on SCP words 
in the source domain. An ensemble of the clas-
sifiers trained on the SCP features (transferred 
from the source) and domain specific features 
(learned within the target) further enhances the 
cross-domain performance. Table 2 lists the no-
tations used in the algorithm. The working of the 
cross-domain adaptation algorithm is as follows: 

1. Identify SCP features from the labeled source 
and the unlabeled target domain data. 

2. A SVM based classifier is trained on SCP 
words as features using labeled source do-
main data, named as C s . 

3. The classifier C s is used to predict the labels 
for the unlabeled target domain instances D u 
t , 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Dataset statistics</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Classification accuracy in % given by C s , 
C t and WSM with different feature sets for elec-
tronics as source and movie as target. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Cross-domain sentiment classification accuracy in the target domain (Source (S) → Target (T)). 

Domain 
Significant Words Unigrams 
Books (B) 
76 
89 
DVD (D) 
82.5 
84 
Electronics (E) 
82.5 
85 
Kitchen (K) 
82.5 
86 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>t-test (α = 0.05) results on the difference 
in accuracy produced by various systems (cf. Ta-
ble 5). 

</table></figure>

			<note place="foot" n="1"> The word &apos;unpredictable&apos; is a classic example of changing (inconsistent) polarity across domains (Turney, 2002; Fahrni and Klenner, 2008).</note>

			<note place="foot" n="2"> SCP words are words which are significant in both the domains with consistent polarity orientation. 3 Majority of this work is done at Conduent Labs India till February 2016.</note>

			<note place="foot" n="4"> http://stattrek.com/chi-square-test/ goodness-of-fit.aspx?Tutorial=AP.</note>

			<note place="foot" n="9"> To obtain the highest frequency based pivots, words in the target corpus (unlabeled) were ordered based on their frequency in the corpus, then a few top words were manually observed (by three human annotators) to pick out a positive word and a negative word. The positive and negative polarity of pivots were confirmed manually to get rid of random high frequency words (for example, function words). These highest frequency polar words were set as Positive-pivot and Negative-pivot.</note>

			<note place="foot" n="11"> The same multi-domain dataset is used by Bhatt et al. (2015), available at: http://www.cs.jhu.edu/ ˜ mdredze/datasets/sentiment/index2.html. 12 Available at: http://scikit-learn.org/ stable/modules/svm.html.</note>

			<note place="foot" n="13"> Common unigrams is a set of unique words which appear in both the domains.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Automatic arabic text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Al-Harbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Almuhareb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al-Thubaity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khorsheed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al-Rajeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lost in translation: viability of machine translation for cross language sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Balamurali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="38" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An iterative similarity based adaptation technique for cross-domain text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Himanshu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepali</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Semwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Natural Language Learning</title>
		<meeting>Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multilingual Projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer International Publishing</publisher>
			<pubPlace>Cham</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying expressions of opinion in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Artificial Intelligence</title>
		<meeting>International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2683" to="2688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">New avenues in opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Schuller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunqing</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A system for multilingual sentiment learning on large data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oles</forename><surname>Zhulyn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computational Linguistics</title>
		<meeting>International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="577" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain-specific sentiment analysis using contextual feature generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonjung</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hyon</forename><surname>Myaeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st international CIKM workshop on Topicsentiment analysis for mass opinion</title>
		<meeting>the 1st international CIKM workshop on Topicsentiment analysis for mass opinion</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="37" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Determining the semantic orientation of terms through gloss classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Information and Knowledge Management</title>
		<meeting>International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="617" to="624" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Old wine or warm beer: Target-specific sentiment analysis of adjectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fahrni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Klenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Symposium on Affective Language in Human and Machine, AISB</title>
		<meeting>of the Symposium on Affective Language in Human and Machine, AISB</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="60" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sujay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4166</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A practical guide to support vector classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Wei</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, National Taiwan University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transfer learning via multiview principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang-Sheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Jun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="98" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Instance weighting for domain adaptation in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fully automatic lexicon expansion for domain-oriented sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuya</forename><surname>Nasukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="355" to="363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A nonnegative matrix tri-factorization approach to sentiment classification with lexical prior knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Joint Conference on Natural Language Processing</title>
		<meeting>International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="244" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A method based on the chi-square test for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Oakes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helene</forename><surname>Fowkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="440" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via spectral feature alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochuan</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on World Wide Web</title>
		<meeting>International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentiment analysis: A combined approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudy</forename><surname>Prabowo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Thelwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Informetrics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="157" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Expanding domain sentiment lexicon through double propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1199" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A generic approach to generate opinion lists of phrases for opinion mining applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Rill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Scheidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Drescher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Schütz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Reinel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wogenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Issues of Sentiment Discovery and Opinion Mining</title>
		<meeting>the First International Workshop on Issues of Sentiment Discovery and Opinion Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Rong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.2738</idno>
		<title level="m">word2vec parameter learning explained</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 9: Sentiment analysis in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott L</forename><surname>Duvall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="97" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Detecting domain dedicated polar words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raksha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Natural Language Processing</title>
		<meeting>the International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="661" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Domain sentiment matters: A two stage sentiment analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raksha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Natural Language Processing</title>
		<meeting>the International Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adjective intensity and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raksha</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Astha</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Lexicon-based methods for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maite</forename><surname>Taboada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Tofiloski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimberly</forename><surname>Voll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="307" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Computational Linguistics</title>
		<meeting>Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Feature ensemble plus sample selection: domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuelei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Feature selection for text categorization on imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohini</forename><surname>Srihari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sig KDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="89" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hybrid heterogeneous transfer learning through deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2213" to="2220" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
