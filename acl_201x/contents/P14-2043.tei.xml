<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Part-of-Speech Tagging using Conditional Random Fields: Exploiting Sub-Label Dependencies for Improved Accuracy</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miikka</forename><surname>Silfverberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Modern Languages</orgName>
								<orgName type="institution">University of Helsinki</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teemu</forename><surname>Ruokolainen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Signal Processing and Acoustics</orgName>
								<orgName type="institution">Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krister</forename><surname>Lindén</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Modern Languages</orgName>
								<orgName type="institution">University of Helsinki</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Signal Processing and Acoustics</orgName>
								<orgName type="institution">Aalto University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Part-of-Speech Tagging using Conditional Random Fields: Exploiting Sub-Label Dependencies for Improved Accuracy</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="259" to="264"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We discuss part-of-speech (POS) tagging in presence of large, fine-grained label sets using conditional random fields (CRFs). We propose improving tagging accuracy by utilizing dependencies within sub-components of the fine-grained labels. These sub-label dependencies are incorporated into the CRF model via a (rela-tively) straightforward feature extraction scheme. Experiments on five languages show that the approach can yield significant improvement in tagging accuracy in case the labels have sufficiently rich inner structure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We discuss part-of-speech (POS) tagging using the well-known conditional random field (CRF) model introduced originally by <ref type="bibr" target="#b8">Lafferty et al. (2001)</ref>. Our focus is on scenarios, in which the POS labels have a rich inner structure. where the compound labels PRON+1SG, V+NON3SG+PRES, and N+SG stand for pro- noun first person singular, verb non-third singular present tense, and noun singular, respectively. Fine-grained labels occur frequently in mor- phologically complex languages <ref type="bibr" target="#b3">(Erjavec, 2010;</ref><ref type="bibr">Haverinen et al., 2013</ref>). We propose improving tagging accuracy by uti- lizing dependencies within the sub-labels (PRON, 1SG, V, NON3SG, N, and SG in the above ex- ample) of the compound labels. From a technical perspective, we accomplish this by making use of the fundamental ability of the CRFs to incorporate arbitrarily defined feature functions. The newly- defined features are expected to alleviate data spar- sity problems caused by the fine-grained labels. Despite the (relative) simplicity of the approach, we are unaware of previous work exploiting the sub-labels to the extent presented here.</p><p>We present experiments on five languages (En- glish, Finnish, Czech, Estonian, and Romanian) with varying POS annotation granularity. By uti- lizing the sub-labels, we gain significant improve- ment in model accuracy given a sufficiently fine- grained label set. Moreover, our results indi- cate that exploiting the sub-labels can yield larger improvements in tagging compared to increasing model order.</p><p>The rest of the paper is organized as follows. Section 2 describes the methodology. Experimen- tal setup and results are presented in Section 3. Section 4 discusses related work. Lastly, we pro- vide conclusions on the work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Conditional Random Fields</head><p>The (unnormalized) CRF model ( <ref type="bibr" target="#b8">Lafferty et al., 2001</ref>) for a sentence x = (x 1 , . . . , x |x| ) and a POS sequence y = (y 1 , . . . , y |x| ) is defined as</p><formula xml:id="formula_0">p (y | x; w) ∝ |x| i=n exp w·φ(y i−n , . . . , y i , x, i) ,</formula><p>(1) where n denotes the model order, w the model pa- rameter vector, and φ the feature extraction func- tion. We denote the tag set as Y, that is, y i ∈ Y for i ∈ 1 . . . |x|.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Baseline Feature Set</head><p>We first describe our baseline feature set {φ j (y i−1 , y i , x, i)} |φ| j=1 by defining emission and transition features. The emission feature set as- sociates properties of the sentence position i with the corresponding label as</p><formula xml:id="formula_1">{χ j (x, i)1(y i = y i ) | j ∈ 1 . . . |X | , ∀y i ∈ Y} ,<label>(2)</label></formula><p>where the function 1(q) returns one if and only if the proposition q is true and zero otherwise, that is</p><formula xml:id="formula_2">1(y i = y i ) = 1 if y i = y i 0 otherwise ,<label>(3)</label></formula><p>and</p><formula xml:id="formula_3">X = {χ j (x, i)} |X |</formula><p>j=1 is the set of functions characterizing the word position i. Following the classic work of <ref type="bibr" target="#b10">Ratnaparkhi (1996)</ref>, our X com- prises simple binary functions:</p><p>1. Bias (always active irrespective of input).</p><p>2. Word forms x i−2 , . . . , x i+2 .</p><p>3. Prefixes and suffixes of the word form x i up to length δ suf = 4.</p><p>4. If the word form x i contains (one or more) capital letter, hyphen, dash, or digit.</p><p>Binary functions have a return value of either zero (inactive) or one (active). Meanwhile, the transi- tion features</p><formula xml:id="formula_4">{1(y i−k = y i−k ) . . . 1(y i = y i ) | y i−k , . . . , y i ∈ Y , ∀k ∈ 1 . . . n}<label>(4)</label></formula><p>capture dependencies between adjacent labels ir- respective of the input x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Expanded Feature Set Leveraging</head><p>Sub-Label Dependencies The baseline feature set described above can yield a high tagging accuracy given a conveniently sim- ple label set, exemplified by the tagging results of Collins (2002) on the Penn Treebank <ref type="bibr" target="#b9">(Marcus et al., 1993)</ref>. (Note that conditional random fields correspond to discriminatively trained hid- den Markov models and <ref type="bibr" target="#b2">Collins (2002)</ref> employs the latter terminology.) However, it does to some extent overlook some beneficial dependency infor- mation in case the labels have a rich sub-structure. In what follows, we describe expanded feature sets which explicitly model the sub-label dependen- cies.</p><p>We begin by defining a function P(y i ) which partitions any label y i into its sub-label compo- nents and returns them in an unordered set. For example, we could define P(PRON+1+SG) = {PRON, 1, SG}. (Label partitions employed in the experiments are described in Section 3.2.) We denote the set of all sub-label components as S.</p><p>Subsequently, instead of defining only (2), we additionally associate the feature functions X with all sub-labels s ∈ S by defining {χ j (x, i)1(s ∈ P(y i )) | ∀j ∈ 1 . . . |X | , ∀s ∈ S} , (5) where 1(s ∈ P(y i )) returns one in case s is in P(y i ) and zero otherwise. Second, we exploit sub- label transitions using features</p><formula xml:id="formula_5">{1(s i−k ∈ P(y i−k )) . . . 1(s i ∈ P(y i )) | ∀s i−k , . . . , s i ∈ S , ∀k ∈ 1 . . . m} .<label>(6)</label></formula><p>Note that we define the sub-label transitions up to order m, 1 ≤ m ≤ n, that is, an nth-order CRF model is not obliged to utilize sub-label tran- sitions all the way up to order n. This is be- cause employing high-order sub-label transitions may potentially cause overfitting to training data due to substantially increased number of features (equivalent to the number of model parameters, |w| = |φ|). For example, in a second-order (n = 2) model, it might be beneficial to em- ploy the sub-label emission feature set (5) and first-order sub-label transitions while discarding second-order sub-label transitions. (See the exper- imental results presented in Section 3.) In the remainder of this paper, we use the fol- lowing notations. <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_4">(4)</ref> is denoted as CRF(n,-).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">A standard CRF model incorporating</head><p>2. A CRF model incorporating <ref type="formula" target="#formula_1">(2)</ref>, <ref type="formula" target="#formula_4">(4)</ref>, and <ref type="formula">(5)</ref> is denoted as CRF(n,0).</p><p>3. A CRF model incorporating (2), (4), (5), and (6) is denoted as CRF(n,m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">On Linguistic Intuition</head><p>This section aims to provide some intuition on the types of linguistic phenomena that can be captured by the expanded feature set. To this end, we con- sider an example on the plural number in Finnish. First, consider the plural nominative word form kissat (cats) where the plural number is denoted by the 1-suffix -t. Then, by employing the features (2), the suffix -t is associated solely with the com- pound label NOMINATIVE+PLURAL. However, by incorporating the expanded feature set (5), -t will also be associated to the sub-label PLURAL. This can be useful because, in Finnish, also adjec- tives and numerals are inflected according to num- ber and denote the plural number with the suffix -t ( <ref type="bibr">Hakulinen et al., 2004, §79</ref>). Therefore, one can exploit -t to predict the plural number also in words such as mustat (plural of black) with a com- pound analysis ADJECTIVE+PLURAL.</p><p>Second, consider the number agreement (con- gruence). For example, in the sentence fragment mustat kissat juoksevat (black cats are running), the words mustat and kissat share the plural num- ber. In other words, the analyses of both mustat and kissat are required to contain the sub-label PLURAL. This short-span dependency between sub-labels will be captured by a first-order sub- label transition feature included in (6).</p><p>Lastly, we note that the feature expansion sets (5) and (6) will, naturally, capture any short-span dependencies within the sub-labels irrespective if the dependencies have a clear linguistic interpre- tation or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>For a quick overview of the data sets, see <ref type="table">Table 1</ref>.</p><p>Penn Treebank. The English Penn Treebank ( <ref type="bibr" target="#b9">Marcus et al., 1993</ref>) is divided into 25 sections of newswire text extracted from the Wall Street Journal. We split the data into training, develop- ment, and test sets using the sections 0-18, 19-21, and 22-24, according to the standardly applied di- vision introduced by <ref type="bibr" target="#b2">Collins (2002)</ref>. The treebank does not have default partition to training and test sets. Therefore, from each 10 consecutive sentences, we assign the 9th and 10th to the development set and the test set, respec- tively. The remaining sentences are assigned to the training set.</p><p>Multext-East. The third data we consider is the multilingual Multext-East (Erjavec, 2010) corpus, from which we utilize the Czech, Estonian and Ro- manian sections. The corpus corresponds to trans- lations of the novel 1984 by George Orwell. We apply the same data splits as for Turku Depen- dency Treebank. <ref type="table" target="#tab_1">,219 5,527 5,462  45  45  Rom  5,216  652  652  405  391  Est  5,183  648  647  413  408  Cze  5,402  675  675  955  908  Fin  5,043  630  630  2,355  2,141   Table 1</ref>: Overview on data. The training (train.), development (dev.) and test set sizes are given in sentences. The columns titled tags and train. tags correspond to total number of tags in the data set and number of tags in the training set, respectively.</p><note type="other">lang. train. dev. test tags train. tags Eng 38</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Label Partitions</head><p>This section describes the employed compound la- bel splits. The label splits for all data sets are sub- mitted as data file attachments. All the splits are performed a priori to model learning, that is, we do not try to optimize them on the development sets.</p><p>The POS labels in the Penn Treebank are split in a way which captures relevant inflectional cat- egories, such as tense and number. Consider, for example, the split for the present tense third sin- gular verb label P(VBZ) = {VB, Z}.</p><p>In the Turku Dependency Treebank, each morphological tag consists of sub-labels mark- ing word-class, relevant inflectional categories, and their respective values.</p><p>Each inflec- tional category, such as case or tense, com- bined with its value, such as nominative or present, constitutes one sub-label. Consider, for example, the split for the singular, adessive noun P(N+CASE_ADE+NUM_SG) = {POS_N, CASE_ADE, NUM_SG}.</p><p>The labeling scheme employed in the Multext- East data set represents a considerably different annotation approach compared to the Penn and Turku Treebanks. Each morphological analysis is a sequence of feature markers, for example Pw3- r. The first feature marker (P) denotes word class and the rest (w, 3, and r) encode values of inflec- tional categories relevant for that word class. A feature marker may correspond to several differ- ent values depending on word class and its posi- tion in the analysis. Therefore it becomes rather difficult to split the labels into similar pairs of in- flectional category and value as we are able to do for the Turku Dependency Treebank. Since the in- terpretation of a feature marker depends on its po- sition in the analysis and the word class, the mark- ers have to be numbered and appended with the word class marker. For example, consider the split P(Pw3-r) = {0 : P, 1 : Pw, 2 : P3, 5 : Pr}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">CRF Model Specification</head><p>We perform experiments using first-order and second-order CRFs with zeroth-order and first- order sub-label features. Using the notation introduced in Section 2, the employed mod- els are CRF(1,-), CRF(1,1), CRF(2,-), CRF(2,0), and CRF(2,1). We do not report results us- ing CRF(2,2) since, based on preliminary exper- iments, this model overfits on all languages.</p><p>The CRF model parameters are estimated using the averaged perceptron algorithm <ref type="bibr" target="#b2">(Collins, 2002</ref>). The model parameters are initialized with a zero vector. We evaluate the latest averaged parameters on the held-out development set after each pass over the training data and terminate training if no improvement in accuracy is obtained during three last passes. The best-performing parameters are then applied on the test instances.</p><p>We accelerate the perceptron learning using beam search ( <ref type="bibr" target="#b13">Zhang and Clark, 2011</ref>). The beam width, b, is optimized separately for each lan- guage on the development sets by considering b = 1, 2, 4, 8, 16, 32, 64, 128 until the model accuracy does not improve by at least 0.01 (absolute).</p><p>Development and test instances are decoded us- ing Viterbi search in combination with the tag dic- tionary approach of <ref type="bibr" target="#b10">Ratnaparkhi (1996)</ref>. In this approach, candidate tags for known word forms are limited to those observed in the training data. Meanwhile, word forms that were unseen during training consider the full label set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Software and Hardware</head><p>The experiments are run on a standard desktop computer (Intel Xeon E5450 with 3.00 GHz and 64 GB of memory). The methods discussed in Section 2 are implemented in C++.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Results</head><p>The obtained tagging accuracies and training times are presented in <ref type="table" target="#tab_1">Table 2</ref>. The times in- clude running the averaged perceptron algorithm and evaluation of the development sets. The col- umn labeled it. corresponds to the number of passes over the training data made by the percep- tron algorithm before termination. We summarize the results as follows.</p><p>First, compared to standard feature extraction approach, employing the sub-label transition fea- tures resulted in improved accuracy on all lan- guages apart from English. The differences were statistically significant on Czech, Estonian, and Finnish. (We establish statistical significance (with confidence level 0.95) using the standard 1- sided Wilcoxon signed-rank test performed on 10 randomly divided, non-overlapping subsets of the complete test sets.) This results supports the in- tuition that the sub-label features should be most useful in presence of large, fine-grained label sets, in which case the learning is most affected by data sparsity.</p><p>Second, on all languages apart from English, employing a first-order model with sub-label fea- tures yielded higher accuracy compared to a second-order model with standard features. The differences were again statistically significant on Czech, Estonian, and Finnish. This result suggests that, compared to increasing model order, exploit- ing the sub-label dependencies can be a preferable approach to improve the tagging accuracy.</p><p>Third, applying the expanded feature set in- evitably causes some increase in the computa- tional cost of model estimation. However, as shown by the running times, this increase is not prohibitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>In this section, we compare the approach pre- sented in Section 2 to two prior systems which at- tempt to utilize sub-label dependencies in a similar manner. <ref type="bibr" target="#b11">Smith et al. (2005)</ref> use a CRF-based system for tagging Czech, in which they utilize expanded emission features similar to our (5). However, they do not utilize the full expanded transition features (6). More specifically, instead of utilizing a sin- gle chain as in our approach, Smith et al. employ five parallel structured chains. One of the chains models the sequence of word-class labels such as noun and adjective. The other four chains model gender, number, case, and lemma sequences, re- spectively. Therefore, in contrast to our approach, their system does not capture cross-dependencies between inflectional categories, such as the de- pendence between the word-class and case of ad- jacent words. Unsurprisingly, Smith et al. fail to achieve improvement over a generative HMM- based POS tagger of <ref type="bibr" target="#b4">Hajič (2001)</ref>. Meanwhile, our system outperforms the generative trigram tag- ger HunPos ( <ref type="bibr" target="#b6">Halácsy et al., 2007)</ref> which is an im-    <ref type="table">Table 3</ref>: Results using a generative HMM-based HunPos tagger of <ref type="bibr">Halacsy et al. (2007)</ref>.</p><p>Ceau¸suCeau¸su (2006) uses a maximum entropy Markov model (MEMM) based system for tag- ging Romanian which utilizes transitional behav- ior between sub-labels similarly to our feature set (6). However, in addition to ignoring the most in- formative emission-type features (5), Ceau¸suCeau¸su em- beds the MEMMs into the tiered tagging frame- work of <ref type="bibr" target="#b12">Tufis (1999)</ref>. In tiered tagging, the full morphological analyses are mapped into a coarser tag set and a tagger is trained for this reduced tag set. Subsequent to decoding, the coarser tags are mapped into the original fine-grained morpholog- ical analyses. There are several problems associ- ated with this tiered tagging approach. First, the success of the approach is highly dependent on a well designed coarse label set. Consequently, it requires intimate knowledge of the tag set and lan- guage. Meanwhile, our model can be set up with relatively little prior knowledge of the language or the tagging scheme (see Section 3.2). More- over, a conversion to a coarser label set is neces- sarily lossy (at least for OOV words) and poten- tially results in reduced accuracy since recovering the original fine-grained tags from the coarse tags may induce errors. Indeed, the accuracy 96.56, re- ported by Ceau¸suCeau¸su on the Romanian section of the Multext-East data set, is substantially lower than the accuracy 97.29 we obtain. These accuracies were obtained using identical sized training and test sets (although direct comparison is impossible because Ceau¸suCeau¸su uses a non-documented random split).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We studied improving the accuracy of CRF-based POS tagging by exploiting sub-label dependency structure. The dependencies were included in the CRF model using a relatively straightforward fea- ture expansion scheme. Experiments on five lan- guages showed that the approach can yield signif- icant improvement in tagging accuracy given suf- ficiently fine-grained label sets.</p><p>In future work, we aim to perform a more fine-grained error analysis to gain a better under- standing where the improvement in accuracy takes place. One could also attempt to optimize the compound label splits to maximize prediction ac- curacy instead of applying a priori partitions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Turku Depedency Treebank.</head><label></label><figDesc>The Finnish Turku Depedendency Treebank (Haverinen et al., 2013) contains text from 10 different domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results. 

proved open-source implementation of the well-
known TnT tagger of Brants (2000). The obtained 
HunPos results are presented in Table 3. 

Eng 
Rom 
Est 
Cze 
Fin 
HunPos 96.58 96.96 92.76 89.57 85.77 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was financially supported by Langnet (Finnish doctoral programme in language studies) and the Academy of Finland under the grant no 251170 <ref type="bibr">(Finnish Centre of Excellence Program (2012</ref><ref type="bibr">-2017</ref>). We would like to thank the anony-mous reviewers for their useful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tnt: A statistical part-ofspeech tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Conference on Applied Natural Language Processing</title>
		<meeting>the Sixth Conference on Applied Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="224" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Maximum entropy tiered tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ceausu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 11th ESSLI Student session</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="173" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminative training methods for Hidden Markov Models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2002 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multext-east version 4: Multilingual morphosyntactic specifications, lexicons and corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toma˘ Z Erjavec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Serial combination of rules and statistics: A case study in czech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Krbec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Květoň</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimír</forename><surname>Petkevič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="268" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename><surname>Hakulinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Vilkuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riitta</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vesa</forename><surname>Koivisto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irja</forename><surname>Tarja Riitta Heinonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Iso suomen kielioppi. Suomalaisen Kirjallisuuden Seura</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Hunpos: An open source trigram tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Péter</forename><surname>Halácsy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">András</forename><surname>Kornai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Csaba</forename><surname>Oravecz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="209" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katri</forename><surname>Haverinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Nyblom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Viljanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Laippala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kohonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<title level="m">Tapio Salakoski, and Filip Ginter. 2013. Building the essential resources for Finnish: the Turku Dependency Treebank. Language Resources and Evaluation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="313" to="330" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A maximum entropy model for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context-based morphological disambiguation with random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><forename type="middle">W</forename><surname>Tromble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tiered tagging and combined language models classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Text, Speech and Dialogue</title>
		<meeting>the Second International Workshop on Text, Speech and Dialogue</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="28" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Syntactic processing using the generalized perceptron and beam search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="151" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
