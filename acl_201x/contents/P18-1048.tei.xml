<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-regulation: Employing a Generative Adversarial Network to Improve Event Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">Soochow University School of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit2">Soochow University No</orgName>
								<address>
									<addrLine>1, Shizi ST</addrLine>
									<postCode>215006</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">Soochow University School of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit2">Soochow University No</orgName>
								<address>
									<addrLine>1, Shizi ST</addrLine>
									<postCode>215006</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingli</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">Soochow University School of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit2">Soochow University No</orgName>
								<address>
									<addrLine>1, Shizi ST</addrLine>
									<postCode>215006</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">Soochow University School of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit2">Soochow University No</orgName>
								<address>
									<addrLine>1, Shizi ST</addrLine>
									<postCode>215006</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">Soochow University School of Computer Science and Technology</orgName>
								<orgName type="institution" key="instit2">Soochow University No</orgName>
								<address>
									<addrLine>1, Shizi ST</addrLine>
									<postCode>215006</postCode>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-regulation: Employing a Generative Adversarial Network to Improve Event Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="515" to="526"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>515</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Due to the ability of encoding and mapping semantic information into a high-dimensional latent feature space, neural networks have been successfully used for detecting events to a certain extent. However , such a feature space can be easily contaminated by spurious features inherent in event detection. In this paper, we propose a self-regulated learning approach by utilizing a generative adversarial network to generate spurious features. On the basis, we employ a recurrent network to eliminate the fakes. Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event detection aims to locate the event triggers of specified types in text. Normally, triggers are words or nuggets that evoke the events of interest.</p><p>Detecting events in an automatic way is chal- lenging, not only because an event can be ex- pressed in different words, but also because a word may express a variety of events in different con- texts. In particular, the frequent utilization of com- mon words, ambiguous words and pronouns in event mentions makes them harder to detect: 1) Generality -taken home &lt;Transport&gt; Ambiguity 1 -campaign in Iraq &lt;Attack&gt; Ambiguity 2 -political campaign &lt;Elect&gt; Coreference -Either its bad or good &lt;Marry&gt; A promising solution to this challenge is through semantic understanding. Recently, neu- ral networks have been widely used in this direc- tion <ref type="bibr">Ghaeini et al., * Corresponding author 2016;</ref><ref type="bibr" target="#b12">Feng et al., 2016;</ref><ref type="bibr" target="#b36">Liu et al., 2017b;</ref><ref type="bibr" target="#b5">Chen et al., 2017)</ref>, which allows semantics of event mentions (trigger plus context) to be encoded in a high-dimensional latent feature space. This fa- cilitates the learning of deep-level semantics. Be- sides, the use of neural networks not only strength- ens current supervised classification of events but alleviates the complexity of feature engineering.</p><p>However, compared to the earlier study <ref type="bibr" target="#b29">(Liao and Grishman, 2010;</ref><ref type="bibr" target="#b20">Hong et al., 2011;</ref><ref type="bibr" target="#b26">Li et al., 2013)</ref>, in which the features are carefully designed by experts, the neural network based methods suf- fer more from spurious features. Here, spurious feature is specified as the latent information which looks like the semantically related information to an event, but actually not ( <ref type="bibr" target="#b33">Liu et al., 2017a</ref>). For example, in the following sample, the semantic information of the word "prison" most probably enables spurious features to come into being, be- cause the word often co-occurs with the trigger "taken" to evoke an Arrest-jail event instead of the ground-truth event Transport:</p><p>2) Prison authorities have given the nod for An- war to be taken home later in the afternoon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trigger: taken. Event Type: Transport</head><p>It is certain that spurious features often result from the semantically pseudo-related context, and during training, a neural network may mistakenly and unconsciously preserve the memory to pro- duce the fakes. However, it is difficult to deter- mine which words are pseudo-related in a specific case, and when they will "jump out" to mislead the generation of latent features during testing.</p><p>To address the challenge, we suggest to regu- late the learning process with a two-channel self- regulated learning strategy. In the self-regulation process, on one hand, a generative adversarial net- work is trained to produce the most spurious fea- tures, while on the other hand, a neural network is equipped with a memory suppressor to elimi- nate the fakes. Detailed experiments on event de- tection show that our proposed method achieves a substantial performance gain, and is capable of robust domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>The task of event detection is to determine whether there is one or more event triggers in a sentence. Trigger is defined as a token or nugget that best signals the occurrence of an event. If successfully identified, a trigger is required to be assigned a tag to indicate the event type:</p><p>Input: Either its bad or good Output: its &lt;trigger&gt;; Marry &lt;type&gt; We formalize the event detection problem as a multi-class classification problem. Given a sen- tence, we classify every token of the sentence into one of the predefined event classes ( <ref type="bibr" target="#b10">Doddington et al., 2004</ref>) or non-trigger class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Self-Regulated Learning (SELF)</head><p>SELF is a double-channel model <ref type="figure" target="#fig_0">(Figure 1</ref>), con- sisted of a cooperative network ( <ref type="bibr" target="#b23">Islam et al., 2003)</ref> and a generative adversarial net (GAN) <ref type="bibr" target="#b15">(Goodfellow et al., 2014)</ref>. A memory suppressor S is used to regulate communication between the channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cooperative Network</head><p>In channel 1, the generator G is specified as a mul- tilayer perceptron. It plays a role of a "diligent stu- dent". By a differentiable function G(x, θ g ) with parameters θ g , the generator learns to produce a vector of latent features o g that may best charac- terize the token x, i.e.,</p><formula xml:id="formula_0">o g = G(x, θ g ).</formula><p>The discriminator D (called "a lucky profes- sor") is a single-layer perceptron, implemented as a differentiable function D(o g , θ d ) with parame- ters θ d . Relying on the feature vector o g , it at- tempts to accurately predict the probability of the token x triggering an event for all event classes, i.e., ˆ y = D(o g , θ d ), and assigns x to the most probable class c (iffˆyiffˆ iffˆy c &gt; ∀ˆy∀ˆy ¯ c , ¯ c = c).</p><p>Therefore, G and D cooperate with each other during training, developing the parameters θ g and θ d with the same goal -to minimize the perfor- mance loss L(ˆ y, y) in the detection task:</p><formula xml:id="formula_1">θ g θ d = argmin L(ˆ y, y)<label>(1)</label></formula><p>where, y denotes the ground-truth probability dis- tribution over event classes, and L indicates the deviation of the prediction from the ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Generative Adversarial Network</head><p>In channel 2, the generatoř G and discriminatořdiscriminatoř D have the same perceptual structures as G and D. They also perform learning by differentiable functions, respectivelyˇGrespectivelyˇ respectivelyˇG</p><formula xml:id="formula_2">(x, θ ˇ g ) andˇDandˇ andˇD(o ˇ g , θ ˇ d ).</formula><p>A major difference, however, is that they are caught into a cycle of highly adversarial competition.</p><p>The generatoř G is a "trouble maker". It learns to produce spurious features, and utilizes them to contaminate the feature vector o ˇ g of the token x. Thuš G changes a real sample x into a fake z - sometimes successfully, sometimes less so. Using the fakes, ˇ G repeatedly instigates the discrimina- toř D to make mistakes. On the other side, ˇ D ("a hapless professor") has to avoid being deceived, and struggles to correctly detect events no matter whether it encounters x or z.</p><p>In order to outsmart the adversary, ˇ G develops the parameters θ ˇ g during training to maximize the performance loss, but on the contrary, ˇ D develops the parameters θ ˇ d to minimize the loss:</p><formula xml:id="formula_3">θ ˇ g = argmax L(ˆ y, y) (2) θ ˇ d = argmin L(ˆ y, y)<label>(3)</label></formula><p>Numerous studies have confirmed that the two- player minmax game enables bothˇGbothˇ bothˇG andˇDandˇ andˇD to im- prove their methods ( <ref type="bibr" target="#b15">Goodfellow et al., 2014;</ref><ref type="bibr" target="#b31">Liu and Tuzel, 2016;</ref><ref type="bibr" target="#b21">Huang et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Regulation with Memory Suppressor</head><p>Using a memory suppressor, we try to optimize the diligent student G. The goal is to enable G to be as dissimilar as possible to the troublemakeř G. The suppressor uses the output o ˇ g ofˇGofˇ ofˇG as a ref- erence resource which should be full of spurious features. On the basis, it looks over the output o g of G, so as to verify whether the features in o g are different to those in o ˇ g . If very different, the suppressor allows G to preserve the memory (viz., θ g in G(x, θ g )), otherwise update. In other word, for G, the suppressor forcibly erases the memory which may result in the generation of spurious fea- tures. We call this the self-regulation.</p><p>Self-regulation is performed for the whole sen- tence which is fed into G andˇGandˇ andˇG. Assume that O g is a matrix, constituted with a series of feature vec- tors, i.e., the vectors generated by G for all the to- kens in an input sentence (o g ∈ O g ), while O ˇ g is another feature matrix, generated byˇGbyˇ byˇG for the tokens (o ˇ g ∈ O ˇ g ). Thus, we utilize the matrix ap- proximation between O g and O ˇ g for measuring the loss of self-regulation learning L dif f . The higher the similarity, the greater the loss. During training, the generator G is required to develop the param- eters θ g to minimize the loss:</p><formula xml:id="formula_4">θ g = argmin L dif f (o g , o ˇ g )<label>(4)</label></formula><p>We present in detail the matrix approximate cal- culation in section 4.4, where the squared Frobe- nius norm <ref type="bibr" target="#b2">(Bousmalis et al., 2016</ref>) is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning to Predict</head><p>We incorporate the cooperative network with the GAN, and enhance their learning by joint training.</p><p>In the 4-member incorporation, i.e., {G, ˇ G, D andˇD}andˇ andˇD}, the primary beneficiary is the lucky pro- fessor D. It can benefit from both the cooperation in channel 1 and the competition in channel 2. The latent features it uses are well-produced by G, and decontaminated by eliminating possible fakes like those made byˇGbyˇ byˇG. Therefore, in experiments, we choose to output the prediction results of D.</p><p>In this paper, we use two recurrent neural net- works (RNN) <ref type="bibr" target="#b47">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b8">Chung et al., 2014</ref>) of the same structure as the generators. And both the discriminators are implemented as a fully- connected layer followed by a softmax layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Recurrent Models for SELF</head><p>RNN with long short-term memory (abbr., LSTM) is adopted due to the superior performance in a va- riety of NLP tasks ( <ref type="bibr" target="#b32">Liu et al., 2016a;</ref><ref type="bibr" target="#b30">Lin et al., 2017;</ref><ref type="bibr" target="#b33">Liu et al., 2017a</ref>). Furthermore, the bidi- rectional LSTM (Bi-LSTM) architecture <ref type="bibr" target="#b46">(Schuster and Paliwal, 1997;</ref><ref type="bibr" target="#b14">Ghaeini et al., 2016;</ref><ref type="bibr" target="#b12">Feng et al., 2016</ref>) is strictly followed. This architecture enables modeling of the semantics of a token with both the preceding and following contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">LSTM based Generator</head><p>Given a sentence, we follow Chen et al <ref type="formula" target="#formula_1">(2015)</ref> to take all the tokens of the whole sentence as the in- put. Before feeding the tokens into the network, we transform each of them into a real-valued vec- tor x ∈ R e . The vector is formed by concatenating a word embedding with an entity type embedding.</p><p>• Word Embedding: It is a fixed-dimensional real-valued vector which represents the hid- den semantic properties of a token <ref type="bibr" target="#b9">(Collobert and Weston, 2008;</ref><ref type="bibr" target="#b48">Turian et al., 2010</ref>).</p><p>• Entity Type Embedding: It is specially used to characterize the entity type associated with a token. The BIO2 tagging scheme ( <ref type="bibr" target="#b49">Wang and Manning, 2013;</ref>) is employed for assigning a type label to each token in the sentence.</p><p>For the input token x t at the current time step t, the LSTM generates the latent feature vector o t ∈ R d by the previous memory. Meanwhile, the token is used to update the current memory.</p><p>The LSTM possesses a long-term memory unit c t ∈ R d and short-term c t ∈ R d . In addition, it is equipped with the input gate i t , forgetting gate f t and a hidden state h t , which are assembled to- gether to promote the use of memory, as well as dynamic memory updating. Similarly, they are de- fined as a d-dimensional vector in R d . Thus LSTM works in the following way:</p><formula xml:id="formula_5">⎡ ⎢ ⎢ ⎣ o t c t i t f t ⎤ ⎥ ⎥ ⎦ = ⎡ ⎢ ⎢ ⎣ σ tanh σ σ ⎤ ⎥ ⎥ ⎦ W x t h t−1 + b (5) h t = o t tanh(c t ) (6) c t = c t i t + c t−1 f t (7)</formula><p>where W ∈ R 4d×(d+e) and b ∈ R 4d are parame- ters of affine transformation; σ refers to the logis- tic sigmoid function and denotes element-wise multiplication.</p><p>The output functions of both the generators in SELF, i.e., G andˇGandˇ andˇG, can be boiled down to the output gate o t ∈ R d of the LSTM cell:</p><formula xml:id="formula_6">o t = LST M (x t ; θ) (8)</formula><p>where, the function LSTM (·;·) is a shorthand for Eq. (5-7) and θ represents all the parameters of LSTM. For both G andˇGandˇ andˇG, θ are initialized with the same values in experiments. But due to the distinct training goals of G andˇGandˇ andˇG (diligence or making- trouble), the values of the parameters in the two cases will change to be very different after train- ing. Therefore, we have</p><formula xml:id="formula_7">o g,t = LST M (x t , θ g,t ) and o ˇ g,t = LST M (x t , θ ˇ g,t ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fully-connected Layer for Discrimination</head><p>Depending on the feature vectors o g,t and o ˇ g,t , the two discriminators D andˇDandˇ andˇD predict the probabil- ity of the token x t triggering an event for all event classes. As usual, they compute the probability distribution over classes using a fully connected layer followed by a softmax layer:</p><formula xml:id="formula_8">ˆ y = sof tmax( ˆ W · o t + ˆ b) (9)</formula><p>wherě y is a C-dimensional vector, in which each dimension indicates the prediction for a class; C is the class number; ˆ W ∈ R d is the weight which needs to be learned; ˆ b is a bias term.</p><p>It is noteworthy that the discriminator D andˇDandˇ andˇD don't share the weight and the bias. It means that, for the same token x t , they may make markedly different predictions:</p><formula xml:id="formula_9">ˆ y g,t = sof tmax( ˆ W g · o g,t + ˆ b g ) andˆyˇgandˆ andˆyandˆyˇ andˆyˇg,t = sof tmax( ˆ W ˇ g · o ˇ g,t + ˆ b ˇ g ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Classification Loss</head><p>We specify the loss as the cross-entropy between the predicted and ground-truth probability distri- butions over classes. Given a batch of training data that includes N samples (x i , y i ), we calculate the losses the discriminators cause as below:</p><formula xml:id="formula_10">L(ˆ y g , y) = − N i=1 C j=1 y j i log(ˆ y j g,i )<label>(10)</label></formula><formula xml:id="formula_11">L(ˆ y ˇ g , y) = − N i=1 C j=1 y j i log(ˆ y j ˇ g,i )<label>(11)</label></formula><p>where y i is a C-dimensional one-hot vector. The value of its j-th dimension is set to be 1 only if the token x i triggers an event of the j-th class, other- wise 0. BothˆyBothˆ Bothˆy g,i andˆyˇgandˆ andˆyandˆyˇ andˆyˇg,i are the predicted proba- bility distributions over the C classes for x i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Loss of Self-regulated Learning</head><p>Assume </p><formula xml:id="formula_12">of self-regulation loss L dif f (O g , O ˇ g ): L dif f (O g , O ˇ g ) = O g O ˇ g 2 F (12)</formula><p>where, · · 2 F denotes the squared Frobenius norm ( <ref type="bibr" target="#b2">Bousmalis et al., 2016)</ref>, which is used to calculate the similarity between matrices.</p><p>It is noteworthy that the feature vectors a gen- erator outputs are required to serve as the rows in the matrix, deployed in a top-down manner and arranged in the order in which they are generated. For example, the feature vector o g,t the generator G outputs at the time t needs to be placed in the t-th row of the matrix O g .</p><p>At the very beginning of the measurement, the similarity between every feature vector in O g and</p><formula xml:id="formula_13">that in O ˇ G is first calculated by the matrix-matrix multiplication O g O ˇ g : ⎛ ⎜ ⎜ ⎜ ⎜ ⎝ o g,1 o ˇ g,1 ... o g,1 o ˇ g,t ... o g,1 o ˇ g,l ... ... ... ... ... o g,1 o ˇ g,t ... o g,t o ˇ g,t ... o g,t o ˇ g,l ... ... ... ... ... o g,1 o ˇ g,l ... o g,l o ˇ g,t ... o g,l o ˇ g,l ⎞ ⎟ ⎟ ⎟ ⎟ ⎠</formula><p>where, the symbol denotes the transpose opera- tion; l is the sentence length which is defined to be uniform for all sentences (l=80), and if it is larger than the real ones, padding is used; o g,i o ˇ g,j de- notes the scalar product between the feature vec- tors o g,i and o ˇ g,j . Let A m×n be a matrix, the squared Frobenius norm of A m×n (i.e., A m×n 2 F ) is defined as:</p><formula xml:id="formula_14">A m×n 2 F = ⎛ ⎝ m i=1 n j=1 |a ij | 2 ⎞ ⎠ 1 2 (13)</formula><p>where, a ij denotes the j-th element in the i-th row of A m×n . Thus, if we let A m×n be the ma- trix produced by the matrix-matrix multiplication</p><formula xml:id="formula_15">O g O ˇ g , the self-regulation loss L dif f (O g , O ˇ g</formula><p>) can be eventually obtained by:</p><formula xml:id="formula_16">L dif f (O g , O ˇ g ) = ⎛ ⎝ l i=1 l j=1 |o g,i o ˇ g,j | 2 ⎞ ⎠ 1 2<label>(14)</label></formula><p>For a batch of training data that includes N sentences, the global self-regulation loss is spec- ified as the sum of the losses for all the sentences:</p><formula xml:id="formula_17">L SELF = N i=1 L dif f (O g , O ˇ g ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Training</head><p>We train the cooperative network in SELF to min- imize the classification loss L(ˆ y g , y) and the loss of self-regulated learning L SELF :</p><formula xml:id="formula_18">θ g = argmin (LˆyLˆy g , y) (15) θ d = argmin (L(ˆ y g , y) + λ · L SELF ) (16)</formula><p>where λ is a hyper-parameter, which is used to har- monize the two losses.</p><p>The min-max game is utilized for training the adversarial net in SELF:</p><formula xml:id="formula_19">θ ˇ g = argmax L(ˆ y ˇ g , y); θ ˇ d = argmin L(ˆ y ˇ g , y)</formula><p>. All the networks in SELF are trained jointly us- ing the same batches of samples. They are trained via stochastic gradient descent <ref type="bibr" target="#b40">(Nguyen and Grishman, 2015</ref>) with shuffled mini-batches and the AdaDelta update rule <ref type="bibr" target="#b53">(Zeiler, 2012</ref>). The gradi- ents are computed using back propagation. And regularization is implemented by a dropout (Hin- ton et al., 2012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Resource and Experimental Datasets</head><p>We test the presented model on the ACE 2005 cor- pus. The corpus is annotated with single-token event triggers and has 33 predefined event types ( <ref type="bibr" target="#b10">Doddington et al., 2004;</ref><ref type="bibr" target="#b0">Ahn, 2006</ref>), along with one class "None" for the non-trigger tokens, con- stitutes a 34-class classification problem.</p><p>For comparison purpose, we use the corpus in the traditional way, randomly selecting 30 articles in English from different genres as the develop- ment set, and utilizing a separate set of 40 English newswire articles as the test set. The remaining 529 English articles are used as the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Hyperparameter Settings</head><p>The word embeddings are initialized with the 300- dimensional real-valued vectors. We follow Chen et al <ref type="formula" target="#formula_1">(2015)</ref>  We follow <ref type="bibr" target="#b12">Feng et al (2016)</ref> to set the dropout rate as 0.2 and the mini-batch size as 10. We tune the initialized parameters mentioned above, harmonic coefficient λ, learning rate and the L2 norm on the development set. Grid search ( <ref type="bibr" target="#b33">Liu et al., 2017a</ref>) is used to seek for the optimal pa- rameters. Eventually, we take the coefficient λ of 0.1 +3 , learning rate of 0.3 and L2 norm of 0.</p><p>The source code of SELF 2 to reproduce the ex- periments has been made publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Compared Systems</head><p>The state-of-the-art models proposed in the past decade are compared with ours. By taking learn- ing framework as the criterion, we divide the mod- els into three classes:</p><p>Minimally supervised approach: is Peng et al (2016)'s MSEP-EMD.</p><p>Feature based approaches: primarily includ- ing <ref type="bibr" target="#b29">Liao and Grishman (2010)</ref>'s Cross-Event in- ference model, which is based on the max-entropy classification and embeds the document-level con- fident information in the feature space; Hong et al (2011)'s Cross-Entity inference model, in which existential backgrounds of name entities are em- ployed as the additional discriminant features; and Li et al (2013)'s Joint model, a sophisticated pre- dictor frequently ranked among the top 3 in re- cent TAC-KBP evaluations for nugget and corefer- ence detection <ref type="bibr" target="#b18">(Hong et al., , 2015</ref>. It is based on structured perceptron and combines the local and global features.</p><p>Neural network based approaches: including the convolutional neural network (CNN) <ref type="bibr" target="#b40">(Nguyen and Grishman, 2015)</ref>, the non-consecutive N- grams based CNN (NC-CNN)     FrameNet (FN) and Wikipeida (Wiki).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental Results</head><p>We evaluate our model using Precision (P), Re- call (R) and F-score (F). To facilitate the compar- ison, we review the best performance of the com- petitors, which has been evaluated using the same metrics, and publicly reported earlier.</p><p>Trigger identification <ref type="table">Table 1</ref> shows the trigger identification perfor- mance. It can be observed that SELF outperforms other models, with a performance gain of no less than 1.1% F-score. Frankly, the performance mainly benefits from the higher recall (78.8%). But in fact the relatively comparable precision (75.3%) to the recall rein- forces the advantages. By contrast, although most of the compared models achieve much higher pre- cision over SELF, they suffer greatly from the sub- stantial gaps between precision and recall. The ad- vantage is offset by the greater loss of recall.</p><p>GAN plays an important role in optimizing Bi- RNN. This is proven by the fact that SELF (Bi- LSTM+GAN) outperforms Nguyen et al (2016)'s Bi-RNN. To be honest, the models use two differ- ent kinds of recurrent units. Bi-RNN uses GRUs, but SELF uses the units that possess LSTM. Nev- ertheless, GRU has been experimentally proven to be comparable in performance to LSTM <ref type="bibr" target="#b8">(Chung et al., 2014;</ref><ref type="bibr" target="#b24">Jozefowicz et al., 2015)</ref>. This allows a fair comparison between Bi-RNN and SELF. <ref type="table" target="#tab_3">Table 2</ref> shows the performance of multi-class clas- sification. SELF achieves nearly the same F-score as <ref type="bibr" target="#b12">Feng et al (2016)</ref>'s Hybrid, and outperforms the others. More importantly, SELF is the only one which obtains a performance higher than 70% for both precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event classification</head><p>Besides, by analyzing the experimental results, we have identified the following regularities:  • Similar to the pattern classifiers that are based on hand-designed features, the CNN models enable higher precision to be obtained. How- ever the recall is lower.</p><formula xml:id="formula_20">Methods P (%) R (%) F (%) MSEP-</formula><p>• The RNN models contribute to achieving a higher recall. However the precision is lower.</p><p>• Expansion of the training data set helps to in- crease the precision.</p><p>Let us turn to the structurally more complicated models, SELF and Hybrid.</p><p>SELF inherits the merits of the RNN models, classifying the events with higher recall. Besides, by the utilization of GAN, SELF has evolved from the traditional learning strategies, being capable of learning from GAN and getting rid of the mistak- enly generated spurious features. So that it outper- forms other RNNs, with improvements of no less than 4.5% precision and 1.7% recall.</p><p>Hybrid is elaborately established by assembling a RNN with a CNN. It models an event from two perspectives: language generation and pragmatics. The former is deeply learned by using the contin- uous states hidden in the recurrent units, while the later the convolutional features. Multi-angled cog- nition enables Hybrid to be more precise. How- ever it is built using a single-channel architecture, concatenating the RNN and the CNN. This results in twofold accumulation of feature information, causing a serious overfitting problem. Therefore, Hybrid is localized to much higher precision but substantially lower recall.</p><p>Overfitting results in enlargement of the gap be- tween precision and recall when the task changes to be more difficult. For Hybrid, as illustrated in   <ref type="figure">Figure 2</ref>, the gap becomes much wider (from 9% to 19.7%) when the binary classification task (trig- ger identification) is shifted to multi-class classifi- cation (event detection). By contrast, other work shows a nearly constant gap. In particular, SELF yields a minimum gap in each task, which changes negligibly from 3.5% to 3.4%. It may be added that, similar to DM-CNN and FB-RNN, SELF is cost-effective. Compared to other models <ref type="table" target="#tab_5">(Table 3)</ref>, it either uses less training data, or is only required to learn two kinds of em- beddings, such as that of words and entity types.</p><formula xml:id="formula_21">MSEP-EMD Joint DM-CNN DM-CNN* Hybrid Bi-RNN</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Discussion: Adaptation, Robustness and Effectiveness</head><p>Domain adaptation is a key criteria for evaluating the utility of a model in practical application. A model can be thought of being adaptable only if it works well for the unlabeled data in the target do- main when trained on the source domain ( <ref type="bibr" target="#b1">Blitzer et al., 2006;</ref><ref type="bibr" target="#b44">Plank and Moschitti, 2013)</ref>.</p><p>We perform two groups of domain adaptation experiments, respectively, using the ACE 2005 corpus and the corpus for TAC-KBP 2015 event nugget track ( <ref type="bibr" target="#b11">Ellis et al., 2015)</ref>.</p><p>The ACE corpus consists of 6 domains: broad- cast conversation (bc), broadcast news (bn), tele- phone conversation (cts), newswire (nw), usenet (un) and web blogs (wl). Following the com- mon practice of adaptation research on this data <ref type="bibr">Grishman, 2014, 2015;</ref><ref type="bibr" target="#b44">Plank and Moschitti, 2013)</ref>, we take the union of bn and nw as the source domain and bc, cts and wl as three different target domains. We randomly select half of the instances from bc to constitute the develop- ment set. The TAC-KBP corpus consists of 2 do- mains: newswire (NW) and discussion forum (DF). We follow <ref type="bibr" target="#b43">Peng et al (2016)</ref> to use one of NW and DF in alternation as the source domain, while the other the target domain. We randomly select a pro- portion (20%) of the instances from the target do- main to constitute the development set.</p><p>We compare with Joint, CNN, MSEP-EMD, SSED (Sammons et al., 2015) and Hybrid. All the models except Hybrid have been reported for the performance assessment of domain adaptation. In this section, we only cite the best performance they obtained. We reproduce Hybrid by using the source code given by authors. To ensure a fair comparison, we perform 3 runs, in each of which, both Hybrid and SELF were redeveloped on a new development set. What we report herein is the av- erage performance they obtained over the 3 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptation Performance</head><p>We show the adaptation performance on the ACE corpus in <ref type="table" target="#tab_7">Tables 4 and that on TAC-KBP in Table  5</ref>. It can be observed that SELF outperforms other models in the out-of-domain scenarios.</p><p>Besides, when testing is performed on the out- of-domain ACE corpus, the performance degrada- tion of SELF is not much larger than that of CNN and Hybrid. When the out-of-domain TAC-KBP corpus is used, the performance of SELF is im- paired much less severely than SSED and Hybrid.    More importantly, the adaptability of SELF is relatively close to that of MSEP-EMD. Consider- ing that MSEP-EMD is stable due to using mini- mal supervision ( <ref type="bibr" target="#b43">Peng et al., 2016)</ref>, we suggest the fully trained networks in SELF may not appear to be extremely inflexible, but on the contrary, they should be transferable for use <ref type="bibr" target="#b13">(Ge et al., 2016)</ref>.</p><formula xml:id="formula_22">Methods In-domain (bn+nw) Out-of-domain (bc) Out-of-domain (cts) Out-of-domain (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>wl) P(%) R(%) F(%) P(%) R(%) F(%) Loss P(%) R(%) F(%) Loss P(%) R(%) F(%) Loss</head><formula xml:id="formula_23">Methods In-domain (NW) Out-of-domain (DF) In-domain (DF) Out-of-domain (NW) P(%) R(%) F(%) P(%) R(%) F(%) Loss P(%) R(%) F(%) P(%) R(%) F(%)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness in Resource-Poor Settings</head><p>There are two resource-poor conditions discussed in this section, including lack of in-domain train- ing data and that of out-domain. Hybrid and SELF are brought into the discussion.</p><p>For the former (in-domain) case, we went over the numbers of samples used for training in the adaptation experiments, which are shown in Ta- ble 6. It can be observed that there is a minimum number of training samples (triggers plus tokens) contained in the domain of NW. By contrast, the domain of bn+nw contains the smallest number of positive samples (triggers) though an overwhelm- ing number of negative samples (general tokens).</p><p>Under such conditions, Hybrid performs better in the domain of NW compared to bn+nw and DF in the three in-domain adaptation experiments (see the column labelled as "In-domain bn+nw" in Ta- ble 4 as well as "In-domain NW" and "In-domain DF" in <ref type="table" target="#tab_9">Table 5</ref>  • For a positive sample, the concerned spurious features (if have) most probably hide in some negative samples.</p><p>• It's impossible to be aware of such negative samples. Therefore, taking into consideration as many negative samples as possible may help to increase the probability that the spu- rious features will be discovered. This is demonstrated by the fact that SELF ob- tains better performance in the domain of bn+nw but not NW (see the column labeled as "Training" in <ref type="table" target="#tab_11">Table 6</ref> and "In-domain" in <ref type="table" target="#tab_7">Table 4</ref> and 5). It may be added that SELF performs worse in DF al- though there are more negative samples used for training (see <ref type="table" target="#tab_11">Table 6</ref>). Taking a glance at the num- ber of positive samples, one may find that it is ap- proximately 2.4 times more than that in bn+nw. But the number of negative samples in DF is only 1.5 times more than that in bn+nw. It implies that, if there are more positive samples used for train- ing, SELF needs to consume proportionally more negative samples for self-regulation. Otherwise, the performance will degrade.</p><p>For the out-domain case, ideally, both Hybrid and SELF encounter the problem that there is lack of target domain data available for training. In this case, SELF displays less performance degradation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Event mentions</head><p>Type And it still does Die We had no part in it Arrest-Jail Nobody questions if this is right or ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attack And that is what ha-what is happening End-Position</head><p>Oh, yeah, it wasn't perfect Marry <ref type="table">Table 7</ref>: Examples of pronouns that act as a trigger (7.2%) than Hybrid (14.8%) when NW is used for training. Considering that NW contains the mini- mum number of samples, we would like to believe that SELF is more robust than Hybrid for cross- domain event detection in a resource-poor setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall and Missing</head><p>SELF is able to accurately recall the events whose occurrence is triggered by ambiguous words, such as "fine", "charge", "campaign", etc. These am- biguous words easily causes confusion. For exam- ple, "campaign" may trigger an Elect event or Attack in the ACE corpus. More importantly, SELF fishes out the common words which serve as a trigger, although they are not closely related to any kind of events, such as "take", "try", "acquire", "become", "create", etc. In general, it is very difficult to accurately recall such triggers because their meanings are not con- crete enough, and the contexts may be full of kinds of noises (see example 2 in pg. 1). We observe that Bi-RNN and Hybrid seldom pick them up.</p><p>However, SELF fails to recall the pronouns that act as a trigger. This is because they occur in spo- ken language much more frequently than they oc- cur in written language. The lack of narrative con- tent makes it difficult to learn the relationship be- tween the pronouns and the events. Some real ex- amples collected from ACE are shown in <ref type="table">Table 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Event detection is an important subtask of event extraction ( <ref type="bibr" target="#b10">Doddington et al., 2004;</ref><ref type="bibr" target="#b0">Ahn, 2006</ref>).</p><p>The research can be traced back to the pattern based approach ( <ref type="bibr" target="#b16">Grishman et al., 2005</ref>). Encour- aged by the high accuracy and the benefit of easy- to-use, researchers have made great efforts to ex- tract discriminative patterns. <ref type="bibr" target="#b3">Cao et al (2015a;</ref><ref type="bibr" target="#b4">2015b)</ref> use dependency regularization and active leaning to generalize and expand the patterns.</p><p>In the earlier study, another trend is to explore the features that best characterize each event class, so as to facilitate supervised classification. A vari- ety of strategies have emerged for converting clas- sification clues into feature vectors <ref type="bibr" target="#b0">(Ahn, 2006;</ref><ref type="bibr" target="#b42">Patwardhan and Riloff, 2009;</ref><ref type="bibr" target="#b29">Liao and Grishman, 2010;</ref><ref type="bibr" target="#b20">Hong et al., 2011;</ref><ref type="bibr" target="#b26">Li et al., 2013</ref><ref type="bibr" target="#b50">Wei et al., 2017)</ref>. Benefiting from the general model- ing framework, the methods enable the fusion of multiple features, and more importantly, they are flexible to use by feature selection. But consider- able expertise is required for feature engineering.</p><p>Recently, the use of neural networks for event detection has become a promising line of research. The closely related work has been presented in section 5.3. The primary advantages of neural net- works have been demonstrated in the work, such as performance enhancement, self-learning capa- bility and robustness.</p><p>The generative adversarial network <ref type="bibr" target="#b15">(Goodfellow et al., 2014</ref>) has emerged as an increasingly popular approach for text processing ( <ref type="bibr" target="#b25">Lamb et al., 2016;</ref>. <ref type="bibr" target="#b33">Liu et al (2017a)</ref> use the adversarial multi-task learning for text classification. We follow the work to cre- ate spurious features, but use them to regulate the self-learning process in a single-task situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We use a self-regulated learning approach to im- prove event detection. In the learning process, the adversarial and cooperative models are utilized in decontaminating the latent feature space.</p><p>In this study, the performance of the discrimi- nator in the adversarial network is left to be evalu- ated. Most probably, the discriminator also per- forms well because it is gradually enhanced by fierce competition. Considering this possibility, we suggest to drive the two discriminators in our self-regulation framework to cooperate with each other. Besides, the global features extracted in Li et al (2013)'s work are potentially useful for de- tecting the event instances referred by pronouns, although involve noises. Therefore, in the future, we will encode the global information by neural networks and use the self-regulation strategy to re- duce the negative influence of noises.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Self-regulated learning scheme</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>and Feng et al (2016) to pre-train the embeddings over NYT corpus using Mikolov et al (2013)'s skip-gram tool. The entity type embed- dings, as usual (Nguyen et al., 2016; Feng et al., 2016; Liu et al., 2017b), are specified as the 50- dimensional real-valued vectors. They are initial- ized with the 32-bit floating-point values, which are all randomly sampled from the uniformly dis- tributed values in [-1, 1] 1 . We initialize other ad- justable parameters of the back-propagation algo- rithm by randomly sampling in [-0.1, 0.1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and the CNN that is assembled with a dynamic multi-pooling layer (DM-CNN) (Chen et al., 2015). Others include Ghaeini et al (2016)'s forward-backward recurrent neural network (FB- RNN) which is developed using gated recurrent units (GRU), Nguyen et al (2016)'s bidirectional RNN (Bi-RNN) and Feng et al (2016)'s Hybrid networks that consist of a Bi-LSTM and a CNN. Besides, we compare our model with Liu et al (2016b)'s artificial neural networks (ANNs), Liu et al (2017b)'s attention-based ANN (ANN-S2) and Chen et al (2017)'s DM-CNN * . The models recently have become popular because, although simple in structure, they are very analytic by learn- ing from richer event examples, such as those in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Method</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>g , and O ˇ g is that provided byˇG byˇ byˇG, i.e., o ˇ g,t ∈ O ˇ g , thus we compute the similarity between O g and O ˇ g and use it as the measure</head><label></label><figDesc></figDesc><table>that O g is a matrix, consisted of the fea-
ture vectors output by G for all the tokens in a sen-
tence, i.e., o g,t ∈ O </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Detection performance (trigger identifi-
cation plus multi-class classification) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Embedding types and training data (DEP: 
Dependency grammar; PSN: Position) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Experimental results of domain adaptation on the ACE 2005 corpus 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 : Experimental results of domain adaptation on the TAC-KBP 2015 corpus (NA: not released)</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head></head><label></label><figDesc>). It illustrates that Hybrid unnec- essarily relies on a tremendous number of training samples to ensure the robustness. But SELF does. It needs far more negative samples than Hybrid be- cause of the following reasons: • It relies on the use of spurious features to im- plement self-regulation during training.</figDesc><table>Domain 
Training 
Testing 
trigger 
token 
trigger 
token 
bn+nw 
1,721 
74,179 
343 
16,336 
NW 
2,098 
31,014 
2,813 
55,459 
DF 
4,106 
10,9275 
1,773 
43,877 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>Table 6 : Data distribution in the source domains</head><label>6</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> https://www.tensorflow.org/api docs/python/tf/random uniform</note>

			<note place="foot" n="2"> https://github.com/JoeZhouWenxuan/Self-regulationEmploying-a-Generative-Adversarial-Network-to-ImproveEvent-Detection/tree/master</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Xiaocheng Feng and his colleagues who shared the source code of Hybrid with us.</p><p>This work was supported by the national Natu-ral Science Foundation of China (NSFC) via Grant Nos. 61525205, 61751206, 61672368.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The stages of event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ahn</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W06-0901" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Annotating and Reasoning about Time and Events, Association for Computational Linguistics (ACL&apos;06). Association for Computational Linguistics</title>
		<meeting>the Workshop on Annotating and Reasoning about Time and Events, Association for Computational Linguistics (ACL&apos;06). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W06-1615" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 conference on Empirical Methods in Natural Language Processing (EMNLP&apos;06). Association for Computational Linguistics</title>
		<meeting>the 2006 conference on Empirical Methods in Natural Language Processing (EMNLP&apos;06). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving event detection with active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/R15-1010" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP&apos;15)</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing (RANLP&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improving event detection with dependency regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/R15-1011" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing (RANLP&apos;15)</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing (RANLP&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatically labeled data generation for large scale event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P17-1038</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1038" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL&apos;17)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="409" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Event extraction via dynamic multi-pooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics (ACL&apos;15)</title>
		<meeting>the 53th Annual Meeting of the Association for Computational Linguistics (ACL&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="doi">10.3115/v1/P15-</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<title level="m">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning (ICML&apos;08)</title>
		<meeting>the 25th international conference on Machine learning (ICML&apos;08)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program-tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>George R Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Lance A Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Overview of linguistic resources for the tac kbp 2015 evaluations: Methodologies and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Getman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Fore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Kuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of TAC KBP 2015 Workshop, National Institute of Standards and Technology (TAC&apos;15)</title>
		<meeting>TAC KBP 2015 Workshop, National Institute of Standards and Technology (TAC&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="16" to="17" />
		</imprint>
	</monogr>
	<note>Ann Bies, and Stephanie Strassel</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A languageindependent neural network for event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-2011</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-2011" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Event detection with burst information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3276" to="3286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Event nugget detection with forward-backward recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Ghaeini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasad</forename><surname>Tadepalli</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-2060</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-2060" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="369" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Westbrook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<title level="m">Nyu&apos;s English ACE 2005 system description. ACE&apos;05</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing coadaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Geoffrey E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">RPI BLENDER TAC-KBP2015 system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference (TAC&apos;15)</title>
		<meeting>Text Analysis Conference (TAC&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RPI BLENDER TAC-KBP2014 knowledge base population system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongtao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference (TAC&apos;14)</title>
		<meeting>Text Analysis Conference (TAC&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using cross-entity inference to improve event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P11-1113" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT&apos;11)</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT&apos;11)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1127" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Poursaeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hopcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<title level="m">Bidirectional LSTM-CRF models for sequence tagging</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A constructive algorithm for training cooperative neural network ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuyuki</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="820" to="834" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML&apos;15)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Professor forcing: A new algorithm for training recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex M</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alias</forename><surname>Parth Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4601" to="4609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th</title>
		<meeting>the 51th</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<ptr target="http://www.aclweb.org/anthology/P13-1008" />
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL&apos;13)</title>
		<imprint>
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Constructing information networks using one single model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/D14-1198</idno>
		<ptr target="https://doi.org/10.3115/v1/D14-1198" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;14)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1846" to="1851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Using document level cross-event inference to improve event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P10-1081" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL&apos;10)</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics (ACL&apos;10)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cicero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep fusion LSTMs for text semantic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-1098</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1098" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1034" to="1043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Adversarial multi-task learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P17-1001</idno>
		<idno type="arXiv">arXiv:1704.05742</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1001" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Leveraging framenet to improve automatic event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<idno type="doi">10.18653/v1/P16-1201</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1201" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Exploiting argument information to improve event detection via supervised attention mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P17-</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1789" to="1797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N13-1090" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;13)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Joint event extraction via recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Thien Huu Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/N16-1034</idno>
		<ptr target="https://doi.org/10.18653/v1/N16-1034" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;16)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Employing word representations and regularization for domain adaptation of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/P14-2012</idno>
		<ptr target="https://doi.org/10.3115/v1/P14-2012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)</title>
		<meeting>the 52th Annual Meeting of the Association for Computational Linguistics (ACL&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="68" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Event detection and domain adaptation with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/P15-2060</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-2060" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics (ACL&apos;15)</title>
		<meeting>the 53th Annual Meeting of the Association for Computational Linguistics (ACL&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="365" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Modeling skip-grams for event detection with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D16-1085</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1085" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;16)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="886" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A unified model of phrasal and sentential evidence for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D09-1016" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;09). Association for Computational Linguistics</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;09). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Event detection and co-reference with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D16-1038</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1038" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;16)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="392" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Embedding semantic similarity in tree kernels for domain adaptation of relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-1147" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics (ACL&apos;13)</title>
		<meeting>the 51th Annual Meeting of the Association for Computational Linguistics (ACL&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Illinois CCG TAC 2015 event nugget, entity discovery and linking, and slot filler validation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavankumar</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhro</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analytics Conference (TAC&apos;15)</title>
		<meeting>Text Analytics Conference (TAC&apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://doi.org/http://www.aclweb.org/anthology/P10-1040" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL&apos;10). Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics (ACL&apos;10). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Effect of non-linear deep architecture in sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing (IJCNLP&apos;13)</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing (IJCNLP&apos;13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1285" to="1291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">English event detection with translated language features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Korostil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hachey</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P17-2046</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-2046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL&apos;17)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="293" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">RPI BLENDER TAC-KBP2016 system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Text Analysis Conference (TAC&apos;16)</title>
		<meeting>Text Analysis Conference (TAC&apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Seqgan: Sequence generative adversarial nets with policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI&apos;17)</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence (AAAI&apos;17)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2852" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Generating text via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on Adversarial Training</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
