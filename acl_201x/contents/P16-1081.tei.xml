<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Social Norms Evolution for Personalized Sentiment Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Al Boni</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of System and Information Engineering</orgName>
								<orgName type="institution">University of Virginia</orgName>
								<address>
									<postCode>22904</postCode>
									<settlement>Charlottesville</settlement>
									<region>VA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Social Norms Evolution for Personalized Sentiment Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="855" to="865"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Motivated by the findings in social science that people&apos;s opinions are diverse and variable while together they are shaped by evolving social norms, we perform person-alized sentiment classification via shared model adaptation over time. In our proposed solution, a global sentiment model is constantly updated to capture the ho-mogeneity in which users express opinions , while personalized models are simultaneously adapted from the global model to recognize the heterogeneity of opinions from individuals. Global model sharing alleviates data sparsity issue, and individualized model adaptation enables efficient online model learning. Extensive experimentations are performed on two large review collections from Amazon and Yelp, and encouraging performance gain is achieved against several state-of-the-art transfer learning and multi-task learning based sentiment classification solutions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment is personal; the same sentiment can be expressed in various ways and the same expres- sion might carry distinct polarities across different individuals ( <ref type="bibr" target="#b32">Wiebe et al., 2005</ref>). Current main- stream solutions of sentiment analysis overlook this fact by focusing on population-level models <ref type="bibr" target="#b17">(Liu, 2012;</ref><ref type="bibr" target="#b23">Pang and Lee, 2008)</ref>. But the id- iosyncratic and variable ways in which individ- uals communicate their opinions make a global sentiment classifier incompetent and consequently lead to suboptimal opinion mining results. For in- stance, a shared statistical classifier can hardly rec- ognize that in restaurant reviews, the word "expen- sive" may indicate some users' satisfaction with a restaurant's quality, although it is generally asso- ciated with negative attitudes. Hence, a person- alized sentiment classification solution is required to achieve fine-grained understanding of individu- als' distinctive and dynamic opinions and benefit downstream opinion mining applications.</p><p>Sparse observations of individuals' opinionated data <ref type="bibr" target="#b18">(Max, 2014</ref>) prevent straightforward solu- tions from building personalized sentiment clas- sification models, such as estimating supervised classifiers on a per-user basis. Semi-supervised methods are developed to address the data spar- sity issue. For example, leveraging auxiliary in- formation from user-user and user-document re- lations in transductive learning ( <ref type="bibr" target="#b13">Hu et al., 2013;</ref><ref type="bibr" target="#b28">Tan et al., 2011</ref>). However, only one global model is estimated there, and the details of how individ- ual users express diverse opinions cannot be cap- tured. More importantly, existing solutions build static sentiment models on historic data; but the means in which a user expresses his/her opinion is changing over time. To capture temporal dynam- ics in a user's opinions with existing solutions, re- peated model reconstruction is unavoidable, albeit it is prohibitively expensive. As a result, personal- ized sentiment analysis requires effective exploita- tion of users' own opinionated data and efficient execution of model updates across all users.</p><p>To address these challenges, we propose to build personalized sentiment classification models via shared model adaptation. Our solution roots in the social psychology theories about humans' dispositional tendencies ( <ref type="bibr" target="#b5">Briley et al., 2000</ref>). Hu- mans' behaviors are shaped by social norms, a set of socially shared "feelings" and "display rules" about how one should feel and express opinions <ref type="bibr" target="#b2">(Bars√§de and Gibson, 1998;</ref><ref type="bibr" target="#b26">Sherif, 1936)</ref>. In the context of content-based sentiment classification, we interpret social norms as global model shar- ing and adaptation across users. Formally, we as- sume a global sentiment model serves as the ba- sis to capture self-enforcing sentimental regulari-ties across users, and each individual user tailors the shared model to realize his/her personal pref- erence. In addition, social norms also evolve over time <ref type="bibr" target="#b6">(Ehrlich and Levin, 2005)</ref>, which leads to shifts in individuals' behaviors. This can again be interpreted as model adaptation: a new global model is adapted from an existing one to reflect the newly adopted sentimental norms. The temporal changes in individuals' opinions can be efficiently captured via online model adaptation at the levels of both global and personalized models.</p><p>Our proposed solution can also be understood from the perspective of multi-task learning <ref type="bibr" target="#b7">(Evgeniou and Pontil, 2004;</ref><ref type="bibr" target="#b14">Jacob et al., 2009</ref>). In- tuitively, personalized model adaptations can be considered as a set of related tasks in individual users, which contribute to a shared global model adaptation. In particular, we assume the distinct ways in which users express their opinions can be characterized by a linear classifier's parame- ters, i.e., the weights of textual features. Personal- ized models are thus achieved via a series of lin- ear transformations over a globally shared classi- fier's parameters ( <ref type="bibr" target="#b31">Wang et al., 2013</ref>), e.g., shifting and scaling the weight vector. This globally shared classifier itself is obtained via another set of linear transformations over a given base classifier, which can be estimated from an isolated collection be- forehand and serves as a prior for shared sentiment classification. The shared global model adaptation makes personalized model estimation no longer independent, such that regularity is formed across individualized learning tasks.</p><p>We empirically evaluated the proposed solu- tion on two large collections of reviews, i.e., Amazon and Yelp reviews. Extensive experiment results confirm its effectiveness: the proposed method outperformed user-independent classifica- tion methods, several state-of-the-art model adap- tion methods, and multi-task learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Text-based sentiment classification forms the foundation of sentiment analysis <ref type="bibr" target="#b17">(Liu, 2012;</ref><ref type="bibr" target="#b23">Pang and Lee, 2008)</ref>. There are two typical types of studies in sentiment classification. The first is classifying input text units (such as documents, sentences and phrases) into predefined categories, e.g., positive v.s., negative <ref type="bibr">(Pang et al., 2002;</ref><ref type="bibr" target="#b10">Gao et al., 2014</ref>) and multiple classes <ref type="bibr" target="#b23">(Pang and Lee, 2005</ref>). Both lexicon-based and learning- based solutions have been explored. The second is identifying topical aspects and corresponding opinions, e.g., developing topic models to predict fine-grained aspect ratings <ref type="bibr" target="#b29">(Titov and McDonald, 2008;</ref><ref type="bibr" target="#b30">Wang et al., 2011</ref>). However, all those works emphasize population-level analysis, which applies a global model on all users and therefore fails to recognize the heterogeneity in which dif- ferent users express their diverse opinions.</p><p>Our proposed solution is closely related to multi-task learning, which exploits the relatedness among multiple learning tasks to benefit each sin- gle task. Tasks can be related in various ways. A typical assumption is that all learnt models are close to each other in some matrix norms <ref type="bibr" target="#b7">(Evgeniou and Pontil, 2004;</ref><ref type="bibr" target="#b14">Jacob et al., 2009)</ref>. This has been empirically proved to be effective for captur- ing preferences of individual users ( <ref type="bibr" target="#b9">Evgeniou et al., 2007)</ref>. Task relatedness has also been imposed via constructing a common underlying representa- tion across different tasks ( <ref type="bibr" target="#b1">Argyriou et al., 2008;</ref><ref type="bibr">Evgeniou and Pontil, 2007)</ref>. Our solution postu- lates task relatedness via a two-level model adap- tation procedure. The global model adaptation ac- counts for the homogeneity and shared dynamics in users' opinions; and personalized model adap- tation realizes heterogeneity in individual users.</p><p>The idea of model adaptation has been exten- sively explored in the context of transfer learn- ing <ref type="bibr" target="#b22">(Pan and Yang, 2010)</ref>, which focuses on ap- plying knowledge gained while solving one prob- lem to different but related problems. In opinion mining community, transfer learning is mostly ex- ploited for domain adaptation, e.g., adapting sen- timent classifiers trained on book reviews to DVD reviews ( <ref type="bibr" target="#b3">Blitzer et al., 2006;</ref><ref type="bibr" target="#b22">Pan et al., 2010)</ref>. Personalized model adaptation has also been stud- ied in literature. The idea of linear transformation based model adaptation is introduced in ( <ref type="bibr" target="#b31">Wang et al., 2013</ref>) for personalized web search. Al Boni et al. applied a similar idea to achieve personal- ized sentiment classification <ref type="bibr" target="#b0">(Al Boni et al., 2015)</ref>. ( <ref type="bibr" target="#b16">Li et al., 2010</ref>) developed an online learning al- gorithm to continue training personalized classi- fiers based on a given global model. However, all of these aforementioned solutions perform model adaptation from a fixed global model, such that the learning of personalized models is independent from each other. Data sparsity again is the ma- jor bottleneck for such solutions. Our solution as- sociates individual model adaptation via a shared global model adaptation, which leverages obser- vations across users and thus reduces preference learning complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>856</head><p>We propose to build personalized sentiment classi- fiers via shared model adaptation for both a global sentiment model and individualized models. Our solution roots in the social psychology theories about humans' dispositional tendencies, e.g., so- cial norms and the evolution of social norms over time. In the following discussions, we will first briefly discuss the social theories that motivate our research, and then carefully describe the model assumptions and technical details about the pro- posed personalized model adaptation solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Evolution of Social Norms</head><p>Social norms create pressures to establish so- cialization of affective experience and expression <ref type="bibr" target="#b27">(Shott, 1979)</ref>. Within the limit set by social norms and internal stimuli, individuals construct their sentiment, which is not automatic, physiological consequences but complex consequences of learn- ing, interpretation, and social influence. This mo- tivates us to build a global sentiment classification model to capture the shared basis on which users express their opinions. For example, the phrase "a waste of money" generally represents negative opinions across all users; and it is very unlikely that anybody would use it in a positive sense. On the other hand, members of some segments of a social structure tend to feel certain emotions more often or more intensely than members of other segments <ref type="bibr" target="#b12">(Hochschild, 1975)</ref>. Personalized model adaptation from the shared global model becomes necessary to capture the variability in affective ex- pressions across users. For example, the word "expensive" may indicate some users' satisfaction with their received service.</p><p>Studies in social psychology also suggest that social norms shift and spread through infectious transfer mediated by webs of contact and influ- ence over time <ref type="bibr" target="#b20">(Ostrom, 2014;</ref><ref type="bibr" target="#b6">Ehrlich and Levin, 2005</ref>). Members inside a social structure influ- ence the other members; confirmation of shifted beliefs leads to the development and evolution of social norms, which in turn regulate the shared so- cial behaviors as a whole over time. The evolv- ing nature of social norms urges us to take a dy- namic view of the shared global sentiment model: instead of treating it as fixed, we further assume this model is also adapted from a predefined one, which serves as prior for sentiment classification. All individual users are coupled and contribute to this shared global model adaptation. This two- level model adaptation assumption leads us to the proposed multi-task learning solution, which will be carefully discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Shared Linear Model Adaptation</head><p>In this paper, we focus on linear models for per- sonalized sentiment classification due to their em- pirically superior performance in text-based sen- timent analysis ( <ref type="bibr">Pang et al., 2002;</ref><ref type="bibr" target="#b23">Pang and Lee, 2005</ref>). We assume the diverse ways in which users express their opinions can be characterized by dif- ferent settings of a linear model's parameters, i.e., the weights of textual features.</p><p>Formally, we denote a given set of opinion- ated text documents from user u as</p><formula xml:id="formula_0">D u = {(x u d , y u d )} |D u | d=1</formula><p>, where each document x u d is rep- resented by a V -dimensional vector of textual fea- tures and y u d is the corresponding sentiment label. The task of personalized sentiment classification is to estimate a personalized model y = f u (x) for user u, such that f u (x) best captures u's opin- ions in his/her generated text content. Instead of assuming f u (x) is solely estimated from user u's own opinionated data, which is prone to over- fitting, we assume it is derived from a globally shared sentiment model f s (x) via model adapta- tion <ref type="bibr" target="#b0">(Al Boni et al., 2015;</ref><ref type="bibr" target="#b31">Wang et al., 2013)</ref>, i.e., shifting and scaling f s (x)'s parameters for each individual user. To simplify the following discus- sions, we will focus on binary classification, i.e., y d ‚àà {0, 1}, and use the logistic regression as our reference model. But the developed techniques are general and can be easily extended to multi-class classification and generalized linear models.</p><p>We only consider scaling and shifting opera- tions, given rotation requires to estimate much more free parameters (i.e., O(V 2 ) v.s., O(V )) but contributes less in final classification perfor- mance <ref type="bibr" target="#b0">(Al Boni et al., 2015)</ref>. We further assume the adaptations can be performed in a group-wise manner ( <ref type="bibr" target="#b31">Wang et al., 2013)</ref>: features in the same group will be updated synchronously by enforc- ing the same shifting and scaling operations. This enables the observations from seen features to be propagated to unseen features in the same group during adaptation. Various feature grouping meth- ods have been explored in ( <ref type="bibr" target="#b31">Wang et al., 2013)</ref>.</p><p>Specifically, we define g(i) ‚Üí j as a fea- ture grouping method, which maps feature i in {1, 2, . . . , V } to feature group j in {1, 2, . . . , K}. A personalized model adaptation matrix can then be represented as a 2K-dimensional vector</p><formula xml:id="formula_1">A u = (a u 1 , a u 2 , . . . , a u K , b u 1 , b u 2 , . . . , b u K )</formula><p>, where a u k and b u k represent the scaling and shifting operations in feature group k for user u accordingly. Plugging this group-wise model adaptation into the logistic function, we can get a personalized logistic regres- sion model P u (y d = 1|x d ) for user u as follows,</p><formula xml:id="formula_2">P u (y d = 1|x d ) = 1 1 + e ‚àí K k=1 g(i)=k (a u k w s i +b u k )x i (1)</formula><p>where w s is the feature weight vector in the global model f s (x). As a result, personalized model adaptation boils down to identifying the optimal model transformation operation A u for each user based on w s and D u . In <ref type="bibr" target="#b0">(Al Boni et al., 2015;</ref><ref type="bibr" target="#b31">Wang et al., 2013)</ref>, f s (x) is assumed to be given and fixed. It leads to isolated estimation of personalized mod- els. Based on the social norms evolution theory, f s (x) should also be dynamic and ever-changing to reflect shifted social norms. Hence, we im- pose another layer of model adaptation on top of the shared global sentiment model f s (x), by as- suming itself is also adapted from a predefined base sentiment model. Denote this base classi- fier as f 0 (x), which is parameterized by a feature weight vector w 0 and serves as a prior for senti- ment classification. Then w s can be derived via the same aforementioned model adaptation proce- dure: w s = A s Àú w 0 , whereÀúwwhereÀú whereÀúw 0 is an augmented vec- tor of w 0 , i.e., Àú w 0 = (w 0 , 1), to facilitate shifting operations, and A s is the adaptation matrix for the shared global model. We should note A s can take a different configuration (i.e., feature groupings) from individual users' adaptation matrices.</p><p>Putting these two levels of model adaptation together, a personalized sentiment classifier is achieved via,</p><formula xml:id="formula_3">w u = A u A s Àú w 0<label>(2)</label></formula><p>which can then be plugged into Eq (1) for person- alized sentiment classification.</p><p>We name this resulting algorithm as Mutli- Task Linear Model Adaptation, or MT-LinAdapt in short. The benefits of shared model adapta- tion defined in Eq (2) are three folds. First, the homogeneity in which users express their diverse opinions are captured in the jointly estimated sen- timent model f s (x) across users. Second, the learnt individual models are coupled together to reduce preference learning complexity, i.e., they collaboratively serve to reduce the models' overall prediction error. Third, non-linearity is achieved via the two-level model adaptation, which intro- duces more flexibility in capturing heterogeneity in different users' opinions. In-depth discussions of those unique benefits will be provided when we introduce the detailed model estimation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Joint Model Estimation</head><p>The ideal personalized model adaptation should be able to adjust the individualized classifier f u (x) to minimize misclassification rate on each user's his- torical data in D u . In the meanwhile, the shared sentiment model f s (x) should serve as the basis for each individual user to reduce the prediction error, i.e., capture the homogeneity. These two re- lated objectives can be unified under a joint opti- mization problem.</p><p>In logistic regression, the optimal adaptation matrix A u for an individual user u, together with A s can be retrieved by a maximum likelihood es- timator (i.e., minimizing logistic loss on a user's own opinionated data). The log-likelihood func- tion in each individual user is defined as,</p><formula xml:id="formula_4">L(A u , A s ) = |D u | d=1 y d log P u (y d = 1|x d )<label>(3)</label></formula><formula xml:id="formula_5">+ (1 ‚àí y d ) log P u (y d = 0|x d )</formula><p>To avoid overfitting, we penalize the transforma- tions which increase the discrepancy between the adapted model and its source model (i.e., between w u and w s , and between w s and w 0 ) via a L2 reg- ularization term,</p><formula xml:id="formula_6">R(A) = Œ∑1 2 ||a ‚àí 1||2 + Œ∑2 2 ||b||2<label>(4)</label></formula><p>and it enforces scaling to be close to one and shift- ing to be close to zero. By defining a new model adaptation matrix√ÖmatrixÀömatrix√Ö = {A u 1 , A u 2 , . . . , A u N , A s } to include all unknown model adaptation parameters for individual users and shared global model, we can formalize the joint optimization problem in MT-LinAdapt as,</p><formula xml:id="formula_7">max L( Àö A) = N i=1 L(A u i )‚àíR(A u i ) ‚àí R(A s )<label>(5)</label></formula><p>which can be efficiently solved by a gradient- based optimizer, such as quasi-Newton method ( <ref type="bibr" target="#b35">Zhu et al., 1997</ref>). Direct optimization over√ÖoverÀöover√Ö requires synchro- nization among all the users. But in practice, users will generate their opinionated data with differ- ent paces, such that we have to postpone model adaptation until all the users have at least one ob- servation to update their own adaptation matrix. This delayed model update is at high risk of miss- ing track of active users' recent opinion changes, but timely prediction of users' sentiment is always preferred. To monitor users' sentiment in realtime, we can also estimate MT-LinAdapt in an asyn- chronized manner: whenever there is a new ob-</p><note type="other">servation available, we update the corresponding user's personalized model together with the shared global model immediately. i.e., online optimiza- tion of MT-LinAdapt. This asychronized estimation of MT-LinAdapt reveals the insight of our two-level model adapta- tion solution: the immediate observations in user u will not only be used to update his/her own adap- tation parameters in A u , but also be utilized to up- date the shared global model, thus to influence the other users, who do not have adaptation data yet. Two types of competing force drive the adapta- tion among all the users: w s = A s Àú w 0 requires timely update of global model across users; and w u = A u</note><p>w s enforces the individual user to con- form to the newly updated global model. This ef- fect can be better understood with the actual gra- dients used in this asychronized update. We illus- trate the decomposed gradients for scaling opera- tion in A u and A s from the log-likelihood part in Eq (5) on a specific adaptation instance (x u d , y u d ):</p><formula xml:id="formula_8">‚àÇL(A u ,A s ) ‚àÇa u k = ‚àÜ u d g u (i)=k a s g s (i) w 0 i +b s g s (i) x u di (6) ‚àÇL(A u ,A s ) ‚àÇa s l = ‚àÜ u d g s (i)=l a u g u (i) w 0 i x u di<label>(7)</label></formula><p>where</p><formula xml:id="formula_9">‚àÜ u d = y u d ‚àí P u (y u d = 1|x u d )</formula><p>, and g u (¬∑) and g s (¬∑) are feature grouping functions in individual user u and shared global model f s (x).</p><p>As stated in Eq (6) and <ref type="formula" target="#formula_8">(7)</ref>, the update of scaling operation in the shared global model and individ- ual users depends on each other; the gradient with respect to global model adaptation will be accu- mulated among all the users. As a result, all users are coupled together via the global model adapta- tion in MT-LinAdapt, such that model update is propagated through users to alleviate data sparsity issue in each single user. This achieves the effect of multi-task learning. The same conclusion also applies to the shifting operations.</p><p>It is meaningful for us to compare our pro- posed MT-LinAdapt algorithm with those dis- cussed in the related work section. Different from the model adaptation based personalized senti- ment classification solution proposed in <ref type="bibr" target="#b0">(Al Boni et al., 2015)</ref>, which treats the global model as fixed, MT-LinAdapt adapts the global model to capture the evolving nature of social norms. As a result, in <ref type="bibr" target="#b0">(Al Boni et al., 2015</ref>) the individual- ized model adaptations are independent from each other; but in MT-LinAdapt, the individual learning tasks are coupled together to enable observation sharing across tasks, i.e., multi-task learning. Ad- ditionally, as illustrated in Eq (6) and <ref type="formula" target="#formula_8">(7)</ref>, nonlin- ear model adaptation is achieved in MT-LinAdapt because of the different feature groupings in indi- vidual users and global model. This enables ob- servations sharing across different feature groups, while in (Al <ref type="bibr" target="#b0">Boni et al., 2015</ref>) observations can only be shared within the same feature group, i.e., linear model adaptation. Multi-task SVM intro- duced in ( <ref type="bibr" target="#b7">Evgeniou and Pontil, 2004</ref>) can be con- sidered as a special case of MT-LinAdapt. In Multi-task SVM, only shifting operation is con- sidered in individual users and the global model is simply estimated from the pooled observations across users. Therefore, only linear model adapta- tion is achieved in Multi-task SVM and it cannot leverage prior knowledge conveyed in a predefined sentiment model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we perform empirical evaluations of the proposed MT-LinAdapt model. We verified the effectiveness of different feature groupings in individual users' and shared global model adapta- tion by comparing our solution with several state- of-the-art transfer learning and multi-task learning solutions for personalized sentiment classification, together with some qualitative studies to demon- strate how our model recognizes users' distinct ex- pressions of sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment Setup</head><p>‚Ä¢ Datesets. We evaluated the proposed model on two large collections of review documents, i.e., Amazon product reviews ( <ref type="bibr" target="#b19">McAuley et al., 2015)</ref> and Yelp restaurant reviews <ref type="bibr" target="#b34">(Yelp, 2016)</ref>. Each re- view document contains a set of attributes such as author ID, review ID, timestamp, textual content, and an opinion rating in discrete five-star range. We applied the following pre-processing steps on both datasets: 1) filtered duplicated reviews; 2) la- beled reviews with overall rating above 3 stars as positive, below 3 stars as negative, and removed the rest; 3) removed reviewers who posted more than 1,000 reviews and those whose positive re- view ratio is more than 90% or less than 10%</p><p>(little variance in their opinions and thus easy to classify). Since such users can be easily captured by the base model, the removal emphasizes com- parisons on adapted models; 4) sorted each user's reviews in chronological order. Then, we per- formed feature selection by taking the union of top unigrams and bigrams ranked by Chi-square and information gain metrics <ref type="bibr" target="#b33">(Yang and Pedersen, 1997)</ref>, after removing a standard list of stopwords and porter stemming. The final controlled vo- cabulary consists of 5,000 and 3,071 textual fea- tures for Amazon and Yelp datasets respectively; and we adopted TF-IDF as the feature weighting scheme. From the resulting data sets, we randomly sampled 9,760 Amazon reviewers and 11,733 Yelp reviewers for testing purpose. There are 105,472 positive reviews and 37,674 negative reviews in the selected Amazon dataset; 108,105 positive re- views and 32,352 negative reviews in the selected Yelp dataset.</p><p>‚Ä¢ Baselines. We compared the performance of MT-LinAdapt against seven different baselines, ranging from user-independent classifiers to sev- eral state-of-the-art model adaption methods and multi-task learning algorithms. Due to space limit, we will briefly discuss the baseline models below.</p><p>Our solution requires a user-independent classi- fier as base sentiment model for adaptation. We estimated logistic regression models from a sepa- rated collection of reviewers outside the preserved testing data on Amazon and Yelp datasets accord- ingly. We also included these isolated base mod- els in our comparison and name them as Base. In order to verify the necessity of personalized sen- timent models, we trained a global SVM based on the pooled adaptation data from all testing re- viewers, and name it as Global SVM. We also es- timated an independent SVM model for each sin- gle user only based on his/her adaptation reviews, and name it as Individual SVM. We included an instance-based transfer learning method <ref type="bibr" target="#b4">(Brighton and Mellish, 2002</ref>), which considers the k-nearest neighbors of each testing review document from the isolated training set for personalized model training. As a result, for each testing case, we esti- mated an independent classification model, which is denoted as ReTrain. <ref type="bibr" target="#b11">(Geng et al., 2012</ref>) used L2 regularization to enforce the adapted models to be close to the global model. We applied this method to get personalized logistic regression models and refer to it as RegLR. LinAdapt devel- oped in <ref type="bibr" target="#b0">(Al Boni et al., 2015</ref>) also performs group- wise linear model adaptation to build personaliza- tion classifiers. But it isolates model adaptation in individual users. MT-SVM is a multi-task learn- ing method, which encodes task relatedness via a shared linear kernel ( <ref type="bibr" target="#b7">Evgeniou and Pontil, 2004</ref>).</p><p>‚Ä¢ Evaluation Settings. We evaluated all the mod- els with both synchronized (batch) and asynchro- nized (online) model update. We should note MT- SVM can only be tested in batch mode, because it is prohibitively expensive to retrain SVM re- peatedly. In batch evaluation, we split each user's reviews into two sets: the first 50% for adapta- tion and the rest 50% for testing. In online eval- uation, once we get a new testing instance, we first evaluate the up-to-date personalized classifier against the ground-truth; then use the instance to update the personalized model. To simulate the real-world situation where user reviews arrive se- quentially and asynchronously, we ordered all re- views chronologically and accessed them one at a time for online model update. In particular, we uti- lized stochastic gradient descent for this online op- timization <ref type="bibr" target="#b15">(Kiwiel, 2001</ref>). Because of the biased class distribution in both datasets, we computed F1 measure for both positive and negative class in each user, and took macro average among users to compare the different models' performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effect of Feature Grouping</head><p>In MT-LinAdapt, different feature groupings can be postulated in individual users' and shared global model adaptation. Nonlinearity is intro- duced when different grouping functions are used in these two levels of model adaptation. Therefore, we first investigated the effect of feature grouping in MT-LinAdapt.</p><p>We adopted the feature grouping method named "cross" in ( <ref type="bibr" target="#b31">Wang et al., 2013</ref>) to cluster fea- tures into different groups. More specifically, we evenly spilt the training collection into N non- overlapping folds, and train a single SVM model on each fold. Then, we create a V √ó N matrix by putting the learned weights from N folds to- gether, on which k-means clustering is applied to extract K feature groups. We compared the batch evaluation performance of varied combinations of feature groups in MT-LinAdapt. The experiment results are demonstrated in <ref type="table">Table 1</ref>; and for com- parison purpose, we also included the base classi- fier's performance in the table.</p><p>In <ref type="table">Table 1</ref>, the two numbers in the first col- umn denote the feature group sizes in personal- ized models and global model respectively. And all indicates one feature per group (i.e., no fea- <ref type="table">Table 1</ref>: Effect of different feature groupings in MT-LinAdapt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Amazon Yelp Pos F1 Neg F1 Pos F1 Neg F1 Base 0.8092 0.4871 0.7048 0.3495 400-800 0.8318 0.5047 0.8237 0.4807 400-1600 0.8385 0.5257 0.8309 0.4978 400-all 0.8441 0.5423 0.8345 0.5105 800-800 0.8335 0.5053 0.8245 0.4818 800-1600 0.8386 0.5250 0.8302 0.4962 800-all 0.8443 0.5426 0.8361 0.5122 1600-all 0.8445 0.5424 0.8357 0.5106 all-all 0.8438 0.5416 0.8361 0.5100 ture grouping). The adapted models in MT- LinAdapt achieved promising performance im- provement against the base sentiment classifier, especially on the Yelp data set. As we increased the feature group size for global model, MT- LinAdapt's performance kept improving; while with the same feature grouping in the shared global model, a moderate size of feature groups in individual users is more advantageous. These observations are expected. Because the global model is shared across users, all their adap- tation reviews can be leveraged to adapt the global model so that sparsity is no longer an issue. Since more feature groups in the global model can be afforded, more accurate estimation of adaptation parameters can be achieved. But at the individ- ual user level, data sparsity is still the bottleneck for accurate adaptation estimation, and trade-off between observation sharing and estimation accu- racy has to be made. Based on this analysis, we selected 800 and all feature groups for individual models and global model respectively in the fol- lowing experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Personalized Sentiment Classification</head><p>‚Ä¢ Synchronized model update. <ref type="table" target="#tab_0">Table 2</ref> demon- strated the classification performance of MT- LinAdapt against all baselines on both Amazon and Yelp datasets, where binomial tests on win- loss comparison over individual users were per- formed between the best algorithm and runner-up to verify the significance of performance improve- ment. We can clearly notice that MT-LinAdapt significantly outperformed all baselines in nega- tive class, and it was only slightly worse than MT-SVM on positive class. More specifically, per-user classifier estimation clearly failed to ob- tain a usable classifier, due to the sparse obser- vations in single users. Model-adaptation based baselines, i.e., RegLR and LinAdapt, slightly im- proved over the base model. But because the adaptations across users are isolated and the base model is fixed, their improvement is very lim- ited. As for negative class, MT-LinAdapt outper- formed Global SVM significantly on both date- sets. Since negative class suffers more from the biased prior distribution, the considerable per- formance improvement indicates effectiveness of our proposed personalized sentiment classifica- tion solution. As for positive class, the perfor- mance difference is not significant between MT- LinAdapt and MT-SVM on Amazon data set nor between MT-LinAdapt and Global SVM on Yelp data set. By looking into detailed results, we found that MT-LinAdapt outperformed MT-SVM on users with fewer adaptation reviews. Further- more, though MT-SVM benefits from multi-task learning, it cannot leverage information from the given base classifier. Considering the biased class prior in these two data sets (2.8:1 on Amazon and 3.3:1 on Yelp), the improved classification per- formance on negative class from MT-LinAdapt is more encouraging. ‚Ä¢ Asynchronized model update. In online model estimation, classifiers can benefit from immedi- ate update, which provides a feasible solution for timely sentiment analysis in large datasets. In this setting, only two baseline models are appli- cable without model reconstruction, i.e., RegLR and LinAdapt. To demonstrate the utility of online update in personalized sentiment models, we illus- trate the relative performance gain of these models over the base sentiment model in <ref type="figure" target="#fig_0">Figure 1</ref>. The x- axis indicates the number of adaptation instances consumed in online update from all users, i.e., the 1st review means after collecting the first review of each user.</p><p>MT-LinAdapt converged to satisfactory perfor- mance with only a handful of observations in each user. LinAdapt also quickly converged, but its per- formance was very close to the base model, since no observation is shared across users. RegLR needs the most observations to estimate satisfac- 861 0 2 4 6 8 10 12 <ref type="bibr">14</ref>   It is meaningful to investigate how the shared global model and personalized models are updated during online learning. The shift in the shared global model reflects changes in social norms, and the discrepancy between the shared global model and personalized models indicates the variances of individuals' opinions. In particular, we calcu- lated Euclidean distance between global model w s and base model w 0 and that between individual- ized model w u and shared global model w s dur- ing online model updating. To visualize the re- sults, we computed and plotted the average Eu- clidean distances in every 3000 observations dur- ing online learning, together with the correspond- ing variance. To illustrate a comprehensive picture of online model update, we also plotted the cor- responding average F1 performance for both pos- itive and negative class. Because the Euclidean distance between w s and w 0 is much larger than that between w s and w u , we scaled ||w s ‚àí w 0 || by 0.02 on Amazon dataset in <ref type="figure">Figure 2</ref>. Similar re- sults were observed on Yelp data as well; but due to space limit, we do not include them.</p><p>As we can clearly observe that the difference between the base model and newly adapted global model kept increasing during online update. At the earlier stage, it is increasing much faster than the later stage, and the corresponding classifica- tion performance improves more rapidly (espe- cially in negative class). The considerably large variance between w 0 and w s at the beginning in- dicates the divergence between old and new social norms across users. Later on, variance decreased and converged with more observations, which can be understood as the formation of the new so- cial norms among users. On the other hand, the distance between personalized models and shared global model fluctuated a lot at the beginning; with more observations, it became stable later on. This is also reflected in the range of variance: the vari- ance is much smaller in later stage than earlier stage, which indicates users comply to the newly established social norms. <ref type="table">Table 3</ref>: Shared model adaptation for cold start on Amazon and Yelp.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Amazon</head><p>Yelp Obs.</p><p>Shared-SVM MT-SVM MT-LinAdapt Shared-SVM MT-SVM MT-LinAdapt Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 Pos F1 Neg F1 1 st 0.9004 0.7013 0.9264 0.7489 0.9122 0.7598 0.7882 0.5537 0.9040 0.7201 0.8809 0.7306 2 nd 0.9200 0.6872 0.9200 0.7319 0.8945 0.7292 0.7702 0.5266 0.8962 0.6959 0.8598 0.6968 3 rd 0.9164 0.6967 0.9164 0.7144 0.8967 0.7260 0.7868 0.5278 0.9063 0.7099 0.8708 0.7069</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Shared Adaptation Against Cold Start</head><p>Cold start refers to the challenge that a statistic model cannot draw any inference for users be- fore sufficient observations are gathered ( <ref type="bibr" target="#b25">Schein et al., 2002</ref>). The shared model adaptation in MT- LinAdapt helps alleviate cold start in personalized sentiment analysis, while individualized model adaptation method, such as RegLR and LinAdapt, cannot achieve so. To verify this aspect, we sep- arated both Amazon and Yelp reviewers into two sets: we randomly selected 1,000 reviewers from the isolated training set and exhausted all their reviews to estimate a shared SVM model, MT- LinAdapt and MT-SVM. Then those models were directly applied onto the testing reviewers for eval- uation. Again, because it is time consuming to re- train a SVM model repeatedly, only MT-LinAdapt performed online model update in this evaluation. We report the performance on the first three obser- vations from all testing users accordingly in <ref type="table">Ta- ble 3.</ref> MT-LinAdapt achieved promising performance on the first testing cases, especially on the negative class. This indicates its estimated global model is more accurate on the new testing users. Because MT-SVM cannot be updated during this online test, only its previously estimated global model from the 1,000 training users can be applied here. As we can notice, its performance is very similar to the shared SVM model (especially on Amazon dataset). MT-LinAdapt adapts to this new collec- tion of users very quickly, so that improved per- formance against the static models at later stage is achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Vocabulary Stability</head><p>One derivative motivation for personalized senti- ment analysis is to study the diverse use of vo- cabulary across individual users. We analyzed the variance of words' sentiment polarities estimated in the personalized models against the base model. <ref type="table">Table 4</ref> shows the most and the least variable fea- tures on both datasets. It is interesting to find that words with strong sentiment polarities tend to be more stable across users, such as "disgust," "re- gret," and "excel." This demonstrates the sign <ref type="table">Table 4</ref>: Top six words with the highest and lowest variances of learned polarities by MT-LinAdapt.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relative performance gain between MT-LinAdapt and baselines on Amazon and Yelp datasets. tory personalized models. The improvement in MT-LinAdapt demonstrates the benefit of shared model adaptation, which is vital when the individuals' adaptation data are not immediately available but timely sentiment classification is required.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 : Classification results in batch mode.</head><label>2</label><figDesc></figDesc><table>Method 
Amazon 
Yelp 
Pos F1 Neg F1 Pos F1 Neg F1 
Base 
0.8092 0.4871 
0.7048 0.3495 
Global SVM 
0.8352 0.5403 
0.8411 0.5007 
Individual SVM 0.5582 0.2418 
0.3515 0.3547 
ReTrain 
0.7843 0.4263 
0.7807 0.3729 
RegLR 
0.8094 0.4896 
0.7103 0.3566 
LinAdapt 
0.8091 0.4894 
0.7107 0.3575 
MT-SVM 
0.8484 0.5367 
0.8408 0.5079 
MT-LinAdapt 
0.8441 0.5422  *  0.8358 0.5119  *  
 *  indicates p-value&lt;0.05 with Binomial test. 

</table></figure>

			<note place="foot" n="6"> Acknowledgments We thank the anonymous reviewers for their insightful comments. This paper is based upon work supported by the National Science Foundation under grant IIS-1553568.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Amazon</head><p>Highest of conformation to social norms. There are also words exhibiting high variances in sentiment po- larity, such as "was-yummi," "lazi," and "cheat," which indicates the heterogeneity of users' opin- ionated expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, we proposed to perform personal- ized sentiment classification based on the notion of shared model adaptation, which is motivated by the social theories that humans' opinions are diverse but shaped by the ever-changing social norms. In the proposed MT-LinAdapt algorithm, global model sharing alleviates data sparsity issue, and individualized model adaptation captures the heterogeneity in humans' sentiments and enables efficient online model learning. Extensive experi- ments on two large review collections from Ama- zon and Yelp confirmed the effectiveness of our proposed solution.</p><p>The idea of shared model adaptation is general and can be further extended. We currently used a two-level model adaptation scheme. The adapta- tion can be performed at the user group level, i.e., three-level model adaptation. The user groups can be automatically identified to maximize the effec- tiveness of shared model adaptation. In addition, this method can also be applied to domain adapta- tion, where a domain taxonomy enables a hierar- chically shared model adaptation.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Model adaptation for personalized opinion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Al</forename><surname>Boni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keira</forename><forename type="middle">Qi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew S</forename><surname>Gerber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convex multi-task feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Argyriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="243" to="272" />
		</imprint>
	</monogr>
	<note>Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Bars√§de</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gibson</surname></persName>
		</author>
		<title level="m">Group emotion: A view from top and bottom. Research on managing groups and teams</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Blitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 EMNLP</title>
		<meeting>the 2006 EMNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Advances in instance selection for instance-based learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mellish2002] Henry</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mellish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="172" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reasons as carriers of culture: Dynamic versus dispositional models of cultural influence on decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Briley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of consumer research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="178" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The evolution of norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simon A Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">194</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Ehrlich and Levin2005</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Regularized multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGKDD</title>
		<meeting>the 10th ACM SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
	<note>Evgeniou and Pontil2004</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-task feature learning. Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">41</biblScope>
		</imprint>
	</monogr>
	<note>Evgeniou and Massimiliano Pontil</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A convex optimization approach to modeling consumer heterogeneity in conjoint estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Evgeniou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theodoros Evgeniou</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="805" to="818" />
		</imprint>
	</monogr>
	<note>Massimiliano Pontil, and Olivier Toubia</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Collective sentiment classification based on user leniency and product popularity. ≈Ç≈Ç</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="541" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ranking model adaptation for domain-specific search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="745" to="758" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The sociology of feeling and emotion: Selected possibilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arlie</forename><forename type="middle">Russell</forename><surname>Hochschild</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Inquiry</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="280" to="307" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Exploiting social relations for sentiment analysis in microblogging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th WSDM</title>
		<meeting>the 6th WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Clustered multi-task learning: A convex formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Jacob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="745" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convergence and efficiency of subgradient methods for quasiconvex minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Krzysztof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiwiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical programming</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Micro-blogging sentiment detection by collaborative online learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="893" to="898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A statistical analysis of 1.2 million amazon reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woolf</forename><surname>Max</surname></persName>
		</author>
		<ptr target="http://minimaxir.com/2014/06/reviewing-reviews" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Inferring networks of substitutable and complementary products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Collective action and the evolution of social norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elinor</forename><surname>Ostrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Natural Resources Policy Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="235" to="252" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey on transfer learning. Knowledge and Data Engineering</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Sinno Jialin Pan and Qiang Yang</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cross-domain sentiment classification via spectral feature alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th WWW</title>
		<meeting>the 19th WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL. [Pang and Lee2008] Bo Pang and Lillian Lee</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
	<note>Opinion mining and sentiment analysis. Foundations and trends in information retrieval</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Thumbs up?: sentiment classification using machine learning techniques</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
	<note>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 25th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The psychology of social norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muzafer</forename><surname>Sherif</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Emotion and social life: A symbolic interactionist analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Shott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of Sociology</title>
		<imprint>
			<biblScope unit="page" from="1317" to="1334" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Userlevel sentiment analysis incorporating social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD</title>
		<meeting>the 17th ACM SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1397" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A joint model of text and aspect ratings for sentiment summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan T</forename><surname>Mcdonald2008] Ivan Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="308" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Latent aspect rating analysis without aspect keyword supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM SIGKDD</title>
		<meeting>the 17th ACM SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Personalized ranking model adaptation for web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th ACM SIGIR</title>
		<meeting>the 36th ACM SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="323" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Annotating expressions of opinions and emotions in language. Language resources and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wiebe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="165" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A comparative study on feature selection in text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedersen1997] Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="412" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Yelp dataset challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yelp</surname></persName>
		</author>
		<ptr target="https://www.yelp.com/dataset_challenge" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Algorithm 778: Lbfgs-b: Fortran subroutines for large-scale boundconstrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="550" to="560" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
