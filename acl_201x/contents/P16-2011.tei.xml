<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Language-Independent Neural Network for Event Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 7-12, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<settlement>Troy</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
								<address>
									<settlement>Troy</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Language-Independent Neural Network for Event Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="66" to="71"/>
							<date type="published">August 7-12, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Event detection remains a challenge due to the difficulty at encoding the word semantics in various contexts. Previous approaches heavily depend on language-specific knowledge and pre-existing natural language processing (NLP) tools. However, compared to English, not all languages have such resources and tools available. A more promising approach is to automatically learn effective features from data, without relying on language-specific resources. In this paper, we develop a hybrid neural network to capture both sequence and chunk information from specific contexts, and use them to train an event detector for multiple languages without any manually encoded features. Experiments show that our approach can achieve robust, efficient and accurate results for multiple languages (English, Chinese and Spanish).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Event detection aims to extract event triggers (most often a single verb or noun) and classify them into specific types precisely. It is a cru- cial and quite challenging sub-task of event ex- traction, because the same event might appear in the form of various trigger expressions and an ex- pression might represent different event types in different contexts. <ref type="figure" target="#fig_0">Figure 1</ref> shows two examples. In S1, "release" is a verb concept and a trigger for "Transfer-Money" event, while in S2, "release " is a noun concept and a trigger for "Release-Parole" event.</p><p>Most of previous methods <ref type="bibr" target="#b4">(Ji et al., 2008;</ref><ref type="bibr" target="#b10">Liao et al., 2010;</ref><ref type="bibr" target="#b3">Hong et al., 2011;</ref><ref type="bibr" target="#b7">Li et al., 2013;</ref><ref type="bibr">Li et al., 2015b</ref>) considered event detection as a classi-  fication problem and designed a lot of lexical and syntactic features. Although such approaches per- form reasonably well, features are often derived from language-specific resources and the output of pre-existing natural language processing toolkits (e,g., name tagger and dependency parser), which makes these methods difficult to be applied to dif- ferent languages. Sequence and chunk are two types of meaningful language-independent struc- tures for event detection. For example, in S2, when predicting the type of a trigger candidate " release", the forward sequence information such as "court" can help the classifier label "release" as a trigger of a "Release-Parole" event. How- ever, for feature engineering methods, it is hard to establish a relation between "court" and "re- lease", because there is no direct dependency path between them. In addition, considering S1, "Eu- ropean Union" and "20 million euros" are two chunks, which indicate that this sentence is related to an organization and financial activities. These cluese are very helpful to infer "release" as a trig- ger of a "Transfer-Money" event. However, chun- kers and parsers are only available for a few high- resource languages and their performance varies a lot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>66</head><p>The  <ref type="figure">Figure 2</ref>: An illustration of our model for event trigger extraction (here the trigger candidate is "release"). F v and B v are the output of Bi-LSTM and C 2 , C 3 are the output of CNN with convolutional filters with widths of 2 and 3.</p><p>Recently, deep learning techniques have been widely used in modeling complex structures and proven effective for many NLP tasks, such as ma- chine translation ( <ref type="bibr" target="#b0">Bahdanau et al., 2014</ref>), rela- tion extraction ( <ref type="bibr" target="#b22">Zeng et al., 2014</ref>) and sentiment analysis ( <ref type="bibr" target="#b19">Tang et al., 2015a</ref>). Bi-directional long short-term memory (Bi-LSTM) model ( <ref type="bibr" target="#b17">Schuster et al., 1997</ref>) is a two-way recurrent neural network (RNN) ( <ref type="bibr" target="#b14">Mikolov et al., 2010</ref>) which can capture both the preceding and following context informa- tion of each word. Convolutional neural network (CNN) ( <ref type="bibr" target="#b5">LeCun et al., 1995</ref>) is another effective model for extracting semantic representations and capturing salient features in a flat structure ( ), such as chunks. In this work, we de- velop a hybrid neural network incorporating two types of neural networks: Bi-LSTM and CNN, to model both sequence and chunk information from specific contexts. Taking advantage of word se- mantic representation, our model can get rid of hand-crafted features and thus be easily adapted to multiple languages. We evaluate our system on the event detection task for various languages for which ground-truth event detection annotations are available. In En- glish event detection task, our approach achieved 73.4% F-score with average 3.0% absolute im- provement compared to state-of-the-art. For Chi- nese and Spanish, the experiment results are also competitive. We demonstrate that our combined model outperforms traditional feature-based meth- ods with respect to generalization performance across languages due to: (i) its capacity to model semantic representations of each word by captur- ing both sequence and chunk information. (ii) the use of word embeddings to induce a more general representation for trigger candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In this section, we introduce a hybrid neural net- works, which combines Bi-directional LSTM (Bi- LSTM) and convolutional neural networks to learn a continuous representation for each word in a sentence. This representation is used to predict whether the word is an event trigger or not. Specif- ically, we first use a Bi-LSTM to encode semantics of each word with its preceding and following in- formation. Then, we add a convolutional neural network to capture structure information from lo- cal contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Bi-LSTM</head><p>In this section we describe a Bidirectional LSTM model for event detection. Bi-LSTM is a type of bidirectional recurrent neural networks (RNN), which can simultaneously model word represen- tation with its preceding and following informa- tion. Word representations can be naturally con- sidered as features to detect triggers and their event types. As show in <ref type="bibr" target="#b2">(Chen et al., 2015)</ref>, we take all the words of the whole sentence as the in- put and each token is transformed by looking up word embeddings. Specifically, we use the Skip- Gram model to pre-train the word embeddings to represent each word ( <ref type="bibr" target="#b15">Mikolov et al., 2013;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2014</ref>).</p><p>We present the details of Bi-LSTM for event trigger extraction in <ref type="figure">Figure 2</ref>. We can see that Bi-LSTM is composed of two LSTM neural net- works, a forward LSTM F to model the preced-. . .</p><p>. . . ing contexts, and a backward LSTM B to model the following contexts respectively. The input of LSTM F is the preceding contexts along with the word as trigger candidate, and the input of LSTM B is the following contexts plus the word as trigger candidate. We run LSTM F from the be- ginning to the end of a sentence, and run LSTM B from the end to the beginning of a sentence. Af- terwards, we concatenate the output F v of LSTM F and B v of LSTM B as the output of Bi-LSTM. One could also try averaging or summing the last hid- den vectors of LSTM F and LSTM B as alterna- tives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max-Pooling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Convolution Neural Network</head><p>As the convolutional neural network (CNN) is good at capturing salient features from a sequence of objects ( , we design a CNN to capture some local chunks. This approach has been used for event detection in previous studies <ref type="bibr" target="#b16">(Nguyen and Grishman, 2015;</ref><ref type="bibr" target="#b2">Chen et al., 2015</ref>). Specifically, we use multiple convolutional filters with different widths to produce local context rep- resentation. The reason is that they are capable of capturing local semantics of n-grams of various granularities, which are proven powerful for event detection. In our work, multiple convolutional fil- ters with widths of 2 and 3 encode the semantics of bigrams and trigrams in a sentence. This local in- formation can also help our model fix some errors due to lexical ambiguity.</p><p>An illustration of CNN with three convo- lutional filters is given in <ref type="figure" target="#fig_1">Figure 3</ref>. Let us denote a sentence consisting of n words as {w 1 , w 2 , ...w i , ...w n }, and each word w i is mapped to its embedding representation e i ∈ R d . In addition, we add a position feature (PF), which is defined as the relative distance between the cur- rent word and the trigger candidate. A convolu- tional filter is a list of linear layers with shared pa- rameters. We feed the output of a convolutional filter to a MaxPooling layer and obtain an output vector with fixed length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Output</head><p>At the end, we concatenate the bidirectional se- quence features: F and B, which are learned from the Bi-LSTM, and local context features: C 2 and C 3 , which are the output of CNN with convolu- tional filters with width of 2 and 3, as a single vec- tor O = [F, B, C 2 , C 3 ]. Then, we exploit a soft- max approach to identify trigger candidates and classify each trigger candidate as a specific event type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training</head><p>In our model, the loss function is the cross-entropy error of event trigger identification and trigger classification. We initialize all parameters to form a uniform distribution U (−0.01, 0.01). We set the widths of convolutional filters as 2 and 3. The number of feature maps is 300 and the dimension of the PF is 5. <ref type="table" target="#tab_2">Table 1</ref> illustrates the setting param- eters used for three languages in our experiments <ref type="bibr" target="#b21">(Zeiler, 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we will describe the detailed exper- imental settings and discuss the results. We eval- uate the proposed approach on various languages (English, Chinese and Spanish) with Precision (P), Recall (R) and F-measure (F). <ref type="table" target="#tab_2">Table 1</ref> shows the detailed description of the data sets used in our ex- periments. We abbreviate our model as HNN (Hy- brid Neural Networks).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline Methods</head><p>We compare our approach with the following baseline methods.</p><p>(1) MaxEnt, a basesline feature-based method, which trains a Maximum Entropy classifier with some lexical and syntactic features ( <ref type="bibr" target="#b4">Ji et al., 2008)</ref>.</p><p>(2) Cross-Event ( <ref type="bibr" target="#b10">Liao et al., 2010)</ref>, using document-level information to improve the perfor- mance of ACE event extraction.</p><p>(3) Cross-Entity (Hong et al., 2011), extracting events using cross-entity inference.</p><p>(4) Joint Model (Li and Ji, 2014), a joint struc- tured perception approach, incorporating multi- level linguistic features to extract event triggers and arguments at the same time so that local pre- dictions can be mutually improved.    , using a pattern expansion technique to ex- tract event triggers.</p><p>(6) Convolutional Neural Network ( <ref type="bibr" target="#b2">Chen et al., 2015)</ref>, which exploits a dynamic multi-pooling convolutional neural network for event trigger de- tection. <ref type="table" target="#tab_3">Table 2</ref> shows the overall performance of all meth- ods on the ACE2005 English corpus. We can see that our approach significantly outperforms all previous methods. The better performance of HNN can be further explained by the following reasons: (1) Compared with feature based meth- ods, such as MaxEnt, Cross-Event, Cross-Entity, and Joint Model, neural network based methods (including CNN, Bi-LSTM, HNN) performs better because they can make better use of word semantic information and avoid the errors propagated from NLP tools which may hinder the performance for event detection. (2) Moreover, Bi-LSTM can cap- ture both preceding and following sequence in- formation, which is much richer than dependency path. For example, in S2, the semantic of "court" can be delivered to release by a forward sequence in our approach. It is an important clue which can help to predict "release" as a trigger for "Release- Parole". For explicit feature based methods, they can not establish a relation between "court" and "release", because they belong to different clauses, and there is no direct dependency path between them. While in our approach, the semantics of "court" can be delivered to release by a forward sequence. (3) Cross-entity system achieves higher recall because it uses not only sentence-level in- formation but also document-level information. It utilizes event concordance to predict a local trig- ger's event type based on cross-sentence infer- ence. For example, an "attack" event is more likely to occur with "killed" or "die" event rather than "marry" event. However, this method heav- ily relies on lexical and syntactic features, thus the precision is lower than neural network based methods. (4) RNN and LSTM perform slightly worse than Bi-LSTM. An obvious reason is that RNN and LSTM only consider the preceding se- quence information of the trigger, which may miss some important following clues. Considering S1 again, when extracting the trigger "releases", both models will miss the following sequence "20 mil- lion euros to Iraq". This may seriously hinder the performance of RNN and LSTM for event detec- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison On English</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison on Chinese</head><p>For Chinese, we follow previous work <ref type="bibr" target="#b1">(Chen et al., 2012</ref>) and employ Language Technology Platform ( <ref type="bibr" target="#b11">Liu et al., 2011</ref>) to do word segmentation. <ref type="table" target="#tab_5">Table 3</ref> shows the comparison results between our model and the state-of-the-art methods ( <ref type="bibr" target="#b7">Li et al., 2013;</ref><ref type="bibr" target="#b1">Chen et al., 2012</ref>). MaxEnt ( <ref type="bibr" target="#b7">Li et al., 2013</ref>) is a pipeline model, which employs human- designed lexical and syntactic features. Rich-C is developed by <ref type="bibr" target="#b1">Chen et al. (2012)</ref>, which also incorporates Chinese-specific features to improve Chinese event detection. We can see that our method outperforms methods based on human de- signed features for event trigger identification and achieves comparable F-score for event classifica- tion.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spanish Extraction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Event detection is a fundamental problem in infor- mation extraction and natural language process- ing ( <ref type="bibr" target="#b7">Li et al., 2013;</ref><ref type="bibr" target="#b2">Chen et al., 2015)</ref>, which aims at detecting the event trigger of a sentence ( <ref type="bibr" target="#b4">Ji et al., 2008)</ref>. The majority of existing methods regard this problem as a classification task, and use machine learning methods with hand-crafted features, such as lexical features (e.g., full word, pos tag), syntactic features (e.g., dependency fea- tures) and external knowledge features (WordNet). There also exists some studies leveraging richer evidences like cross-document ( <ref type="bibr" target="#b4">Ji et al., 2008)</ref>, cross-entity (Hong et al., 2011) and joint inference ( <ref type="bibr" target="#b6">Li and Ji, 2014)</ref>. Despite the effectiveness of feature-based meth- ods, we argue that manually designing feature templates is typically labor intensive. Besides, feature engineering requires expert knowledge and rich external resources, which is not always avail- able for some low-resource languages. Further- more, a desirable approach should have the abil- ity to automatically learn informative representa- tions from data, so that it could be easily adapted to different languages. Recently, neural network emerges as a powerful way to learn text represen- tation automatically from data and has obtained promising performances in a variety of NLP tasks.</p><p>For event detection, two recent studies <ref type="bibr" target="#b16">(Nguyen and Grishman, 2015;</ref><ref type="bibr" target="#b2">Chen et al., 2015</ref>) explore neural network to learn continuous word represen- tation and regard it as the feature to infer whether a word is a trigger or not. Nguyen (2015) presented a convolutional neural network with entity type in- formation and word position information as extra features. However, their system limits the con- text to a fixed window size which leads the loss of word semantic representation for long sentences.</p><p>We introduce a hybrid neural network to learn continuous word representation. Compared with feature-based approaches, the method here does not require feature engineering and could be di- rectly applied to different languages. Compared with previous neural models, we keep the advan- tage of convolutional neural network <ref type="bibr" target="#b16">(Nguyen and Grishman, 2015</ref>) in capturing local contexts. Be- sides, we also incorporate a Bi-directional LSTM to model the preceding and following information of a word as it has been commonly accepted that LSTM is good at capturing long-term dependen- cies in a sequence ( <ref type="bibr" target="#b20">Tang et al., 2015b;</ref><ref type="bibr" target="#b8">Li et al., 2015a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, We introduce a hybrid neural net- work model, which incorporates both bidirectional LSTMs and convolutional neural networks to cap- ture sequence and structure semantic information from specific contexts, for event detection. Com- pared with traditional event detection methods, our approach does not rely on any linguistic re- sources, thus can be easily applied to any lan- guages. We conduct experiments on various lan- guages ( English, Chinese and Spanish. Empirical results show our approach achieved state-of-the- art performance in English and competitive results in Chinese. We also find that bi-directional LSTM is powerful for trigger extraction in capturing pre- ceding and following contexts in long distance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Event type and syntactic parser results of an example sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CNN structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Language</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>S2 : The court decides Anwar 's earliest release date is April.</head><label>:</label><figDesc></figDesc><table>ccomp 

det 
nsubj 

poss 

nn 
amod 
p's 
cop 

nsubj 

DT 
NN 
VBZ 
NNP 's 
JJS 
NN 
NNS VBZ NNP 

S1: The European Unit will release 20 million euros to Iraq. 

prep 

drobj 
num 
pobj 

DT 
NNP 
NNP MD 
VB 
CD 
CD 
NNS IN NNP 

det 
num 
aux 
nn 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 : Hyperparameters and # of documents used in our experiments on three languages.</head><label>1</label><figDesc></figDesc><table>Word Embedding 
Gradient Learning Method 
Data Sets 
corpus 
dim 
method 
parameters 
Corpus 
Train 
Dev 
Test 
English 
NYT 
300 
SGD 
learning rate r = 0.03 
ACE2005 
529 
30 
40 
Chinese 
Gigaword 
300 
Adadelta 
p = 0.95, δ = 1e −6 
ACE2005 
513 
60 
60 
Spanish 
Gigaword 
300 
Adadelta 
p = 0.95, δ = 1e −6 
ERE 
93 
12 
12 

Model 
Trigger Identification 
Trigger Classification 
P 
R 
F 
P 
R 
F 
MaxEnt 
76.2 
60.5 
67.4 
74.5 
59.1 
65.9 
Cross-Event 
N/A 
N/A 
N/A 
68.7 
68.9 
68.8 
Cross-Entity 
N/A 
N/A 
N/A 
72.9 
64.3 
68.3 
Joint Model 
76.9 
65.0 
70.4 
73.7 
62.3 
67.5 
PR 
N/A 
N/A 
N/A 
68.9 
72.0 
70.4 
CNN 
80.4 
67.7 
73.5 
75.6 
63.6 
69.1 
RNN 
73.2 
63.5 
67.4 
67.3 
59.9 
64.2 
LSTM 
78.6 
67.4 
72.6 
74.5 
60.7 
66.9 
Bi-LSTM 
80.1 
69.4 
74.3 
81.6 
62.3 
70.6 
HNN 
80.8 
71.5 
75.9 
84.6 
64.9 
73.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparison of different methods on En-
glish event detection. 

(5) Pattern Recognition (Miao </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 presents the performance of our method on the Spanish ERE corpus. The results show that 69 Model</head><label>4</label><figDesc></figDesc><table>Trigger Identification 
Trigger Classification 
P 
R 
F 
P 
R 
F 

MaxEnt 
50.0 
77.0 
60.6 
47.5 
73.1 
57.6 

Rich-C 
62.2 
71.9 
66.7 
58.9 
68.1 
63.2 
HNN 
74.2 
63.1 
68.2 
77.1 
53.1 
63.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 3 : Results on Chinese event detection.</head><label>3</label><figDesc></figDesc><table>HNN approach performed better than LSTM and 
Bi-LSTM. It indicates that our proposed model 
could achieve the best performance in multiple 
languages than other neural network methods. We 
did not compare our system with other systems 
(Tanev et al., 2009), because they reported the re-
sults on a non-standard data set . 

Model 
Trigger Identification 
Trigger Classification 
P 
R 
F 
P 
R 
F 

LSTM 
62.2 
52.9 
57.2 
56.9 
32.6 
41.6 
Bi-LSTM 
76.2 
63.1 
68.7 
61.5 
42.2 
50.1 
HNN 
81.4 
65.2 
71.6 
66.3 
47.8 
55.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Results on Spanish event detection.</head><label>4</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>The authors give great thanks to Ying Lin (RPI) and Shen Liu for (HIT) the fruitful discussions. We also would like to thank three anonymous re-viewers for their valuable comments and sugges-tions. RPI co-authors were supported by the U.S. DARPA LORELEI Program No. HR0011-15-C-0115, DARPA DEFT Program No. FA8750-13-2-0041 and NSF CAREER Award IIS-1523198.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Joint modeling for chinese event extraction with rich linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<editor>COLING. Citeseer</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Event extraction via dynamic multi-pooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using cross-entity inference to improve event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoming</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1127" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Refining event extraction through cross-document inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="254" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series. The handbook of brain theory and neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page">3361</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eudard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00185</idno>
		<title level="m">When are tree structures necessary for deep learning of representations? arXiv preprint</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01057</idno>
		<title level="m">2015b. A hierarchical neural autoencoder for paragraphs and documents</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using document level cross-event inference to improve event extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shasha</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="789" to="797" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language technology platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="53" to="62" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.04646</idno>
		<title level="m">A dependency-based neural network for relation classification</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving event detection with active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2010-01" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Cernock`Cernock`y, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Event detection and domain adaptation with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huu</forename><surname>Thien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grishman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Short Papers</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">365</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks. Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploiting machine learning techniques to build an event extraction system for portuguese and spanish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanni</forename><surname>Zavarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Linge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mijail</forename><surname>Kabadjov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Piskorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguamática</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
