<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Parse Imputation for Dependency Annotations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mielens</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mechanical Engineering</orgName>
								<orgName type="institution" key="instit1">The University of Texas at Austin</orgName>
								<orgName type="institution" key="instit2">The University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Parse Imputation for Dependency Annotations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1385" to="1394"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Syntactic annotation is a hard task, but it can be made easier by allowing annotators flexibility to leave aspects of a sentence underspecified. Unfortunately, partial annotations are not typically directly usable for training parsers. We describe a method for imputing missing dependencies from sentences that have been partially annotated using the Graph Fragment Language, such that a standard dependency parser can then be trained on all annotations. We show that this strategy improves performance over not using partial annotations for English, Chinese, Portuguese and Kin-yarwanda, and that performance competitive with state-of-the-art unsupervised and weakly-supervised parsers can be reached with just a few hours of annotation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Linguistically annotated data is produced for many purposes in many contexts. It typically requires considerable effort, particularly for lan- guage documentation efforts in which tooling, data, and expertise in the language are scarce. The challenge presented by this scarcity is com- pounded when doing deeper analysis, such as syn- tactic structure, which typically requires greater expertise and existing tooling. In such scenar- ios, unsupervised approaches are a tempting strat- egy. While the performance of unsupervised dependency parsing has improved greatly since <ref type="bibr" target="#b6">Klein and Manning's (2004)</ref> Dependency Model with Valence (DMV), state-of-the-art unsuper- vised parsers still perform well below supervised approaches ( <ref type="bibr" target="#b10">Martins et al., 2010;</ref><ref type="bibr" target="#b18">Spitkovsky et al., 2012;</ref><ref type="bibr" target="#b1">Blunsom and Cohn, 2010)</ref>. Additionally, they typically require large amounts of raw data. While this is not a problem for some languages, many of the world's languages do not have a clean, digitized corpus available. <ref type="bibr">1</ref> For instance, the ap- proach of <ref type="bibr" target="#b12">Naseem et al. (2010)</ref> is unsupervised in the sense that it requires no dependency annota- tions, but it still makes use of the raw version of the full Penn Treebank. The approach of <ref type="bibr" target="#b9">Marecek et al. (2013)</ref> requires extra unlabeled texts to estimate parameters.</p><p>Another strategy is to exploit small amounts of supervision or knowledge. <ref type="bibr" target="#b12">Naseem et al. (2010)</ref> use a set of universal dependency rules and obtain substantial gains over unsupervised methods in many languages. <ref type="bibr" target="#b16">Spitkovsky et al. (2010b;</ref><ref type="bibr" target="#b17">2011)</ref> use web mark-up and punctuation as additional an- notations. Alternatively, one could try to obtain actual dependency annotations cheaply. We use the Graph Fragment Language (GFL), which was created with the goal of making annotations eas- ier for experts and possible for novices ( <ref type="bibr" target="#b14">Schneider et al., 2013;</ref><ref type="bibr" target="#b11">Mordowanec et al., 2014</ref>). GFL sup- ports partial annotations, so annotators can omit obvious dependencies or skip difficult construc- tions. The ability to focus on portions of a sen- tence frees the annotator to target constituents and dependencies that maximize information that will be most useful for machine-learned parsers. For example, <ref type="bibr" target="#b4">Hwa (1999)</ref> found higher-level sentence constituents to be more informative for learning parsers than lower-level ones.</p><p>To support this style of annotation while getting the benefit from partial annotations, we develop a two-stage parser learning strategy. The first stage completes the partial GFL annotations by adapting a Gibbs tree sampler <ref type="bibr" target="#b5">(Johnson et al., 2007;</ref><ref type="bibr" target="#b19">Sun et al., 2014</ref>). The GFL annotations constrain the tree sampling space by using both dependencies and the constituent boundaries they express. The sys- tem performs missing dependency arc imputation using Gibbs sampling -we refer to this approach as the Gibbs Parse Completer 2 (GPC). The sec- ond stage uses the full dependencies output by the GPC to train Turbo Parser ( <ref type="bibr" target="#b10">Martins et al., 2010)</ref>, and evaluation is done with this trained model on unseen sentences. In simulation experiments for English, Chinese and Portuguese, we show that the method gracefully degrades when applied to training corpora with increasing percentages of the gold training dependencies removed. We also do actual GFL annotations for those languages plus Kinyarwanda, and show that using the GPC to fill in the missing dependencies after two hours of annotation enables Turbo Parser to obtain 2-6% better absolute performance than when it has to throw incomplete annotations out. Furthermore, the gains are even greater with less annotation time and it never hurts to use the GPC-so an annota- tion project can pursue a partial annotation strat- egy without undermining the utility of the work for parser training.</p><p>This strategy has the further benefit of needing only a small number of sentences-in our case, under 100 sentences annotated in a 2-4 hour win- dow. Furthermore, it relies on no outside tools or corpora other than a part-of-speech tagger; a re- source that can be built with two hours of annota- tion time <ref type="bibr" target="#b3">(Garrette and Baldridge, 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>Data sources We use four languages from three language families in an effort to both verify the cross-linguistic applicability of our approach, ac- counting for variations in linguistic properties, as well as to attempt to realistically simulate a real- world, low-resource environment. Our data comes from English (ENG), Chinese (CHI), Portuguese (POR), and Kinyarwanda (KIN).</p><p>For ENG we use the Penn Treebank ( <ref type="bibr" target="#b8">Marcus et al., 1993</ref>), converted into dependencies by the standard process. Section 23 was used as a test set, and a random sample of sentences from sec- tions 02-21 were selected for annotation with GFL as described below and subsequently used as the minimal training set. For CHI we use the Chi- nese Treebank (CTB5) ( <ref type="bibr" target="#b21">Xue et al., 2005</ref>), also converted to dependencies. The testing set con- sisted of files 1-40/900-931, and the sentences pre- sented for GFL annotation were randomly sam- pled from files 81-899. The POR data is from the CoNLL-X Shared Task on Multilingual De- pendency Parsing and is derived from the Bosque portion of the Floresta sint√°(c)tica corpus ( <ref type="bibr" target="#b0">Afonso et al., 2002</ref>), using the standard provided splits for training and testing. The KIN data is a corpus con- sisting of transcripts of testimonies by survivors of the Rwandan genocide, provided by the Kigali Genocide Memorial Center -this data is described by <ref type="bibr" target="#b3">Garrette and Baldridge (2013)</ref>.</p><p>GFL annotation We use a small number of sen- tences annotated using the Graph Fragment Lan- guage (GFL), a simple ASCII markup language for dependency grammar ( <ref type="bibr" target="#b14">Schneider et al., 2013)</ref>. Unlike traditional syntactic annotation strategies requiring trained annotators and great effort, rapid GFL annotations can be collected from annotators who have minimal training. <ref type="bibr" target="#b7">Kong et al. (2014)</ref> demonstrate the feasibility of training a depen- dency parser based on a GFL-annotated corpus of English tweets.</p><p>An example of GFL is shown in <ref type="figure" target="#fig_0">Figure 1</ref>: (a) is the GFL markup itself and (b) is a graphical repre- sentation of the dependencies it encodes. <ref type="figure" target="#fig_0">Figure 1</ref> specifies several dependencies: of is a dependent of director, executive vice president and director are conjuncts and and is the coordinator. However, the complete internal structure of the phrase the equity division remains unspecified, other than di- vision being marked as the head (via an asterisk). <ref type="bibr">3</ref> Finally, Mr. Conlon in square brackets indicates it is a multiword expression.</p><formula xml:id="formula_0">CFG Rule EVG distribution Description S ‚Üí YH P (root = H) The head of the sentence is H YH ‚Üí LH RH - Split-head representation LH ‚Üí HL P (ST OP |dir = L, head = H, val = 0) H has no left children LH ‚Üí L 1 H P (CON T |dir = L, head = H, val = 0) H has at least one left child L H ‚Üí HL P (ST OP |dir = L, head = H, val = 1) H has no more left children L H ‚Üí L 1 H P (CON T |dir = L, head = H, val = 1) H has other left children L 1 H ‚Üí YAL H P (ArgA|dir = L, head = H, val = 1)</formula><p>A is a left child of H <ref type="table">Table 1</ref>: The CFG-DMV grammar schema from <ref type="bibr" target="#b6">Klein and Manning (2004)</ref>. Note that in these rules H and A are parts-of-speech. For brevity, we omit the portion of the grammar that handles the right- hand arguments since they are symmetric to the left. Valency (val) can take the value 1 (we have made attachments in the direction (dir) d) or 0 (not).   <ref type="formula" target="#formula_4">(2014)</ref> stipulate that the GFL an- notations in their corpus must be fully-specified. They are thus unable to take advantage of such un- derspecified sentences, and we address that limita- tion in this paper. From the GFL annotations we can extract and deduce dependency arcs and con- straints (see Section 3.2 for full details) in order to guide the Gibbs sampling process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CHI</head><p>Time-bounded annotation As described in Section 1, a primary goal of this work was to con- sider the time in which a useful number of depen- dency tree annotations might be collected, such as might be required during the initial phase of a language documentation project or corpus build. To this end our annotators were operating under a strict two hour time limit. We also collected two further hours for English.</p><p>The annotators were instructed to annotate as many sentences as possible in the two hours, and that they should liberally use underspecification, especially for particularly difficult sequences in a given sentence. This was done to facilitate the availability of partial annotations for experimenta- tion. All of the annotators had some previous ex- perience providing GFL annotations, so no train- ing period was needed. Annotation was done in 30-minute blocks, to provide short breaks for the annotators and so that learning curves could be generated. Each language was annotated by a single annotator. The ENG and CHI annotators were native speakers of their annotation language, while the POR and KIN annotators were non-native though proficient speakers.</p><p>The annotators achieved rates of 400-500 to- kens/hr, whereas we find rates of 150-200 to- kens/hr more typical when annotators are asked to fully specify. Requiring full specification also in- troduces more errors in cases of annotator uncer- tainty. <ref type="table" target="#tab_1">Table 2</ref> shows the size of the GFL corpora that were created. Typically, over 50% of the sentences were not fully specified-the partial annotations provided in these are useless to Turbo Parser un- less the missing dependencies are imputed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Gibbs Parse Completer (GPC)</head><p>3.1 Gibbs sampler for CFG-DMV Model CFG-DMV model The GPC is based on the DMV model, a generative model for the unsu- pervised learning of dependency structures ( <ref type="bibr" target="#b6">Klein and Manning, 2004</ref>). We denote the input cor- pus as œâ = (œâ 1 , ¬∑ ¬∑ ¬∑ , œâ N ), where each œâ s is a sentence consisting of words and in a sentence œâ, word œâ i has an corresponding part-of-speech tag œÑ i . We denote the set of all words as V œâ and the set of all parts-of-speech as V œÑ . We use the part- of-speech sequence as our terminal strings, result- ing in an unlexicalized grammar. Dependencies can be formulated as split head bilexical context free grammars (CFGs) <ref type="bibr" target="#b2">(Eisner and Satta, 1999</ref>) and these bilexical CFGs require that each termi- nal œÑ i in sentence œâ is represented in a split form by two terminals, with labels marking the left and right heads (œÑ i,L , œÑ i,R ). Henceforth, we denote w = w 0,n as our terminals in the split-form of sentence œâ (e.g., the terminals for the dog walks <ref type="table">Table 1</ref> shows the grammar rules for the DMV model, from <ref type="bibr" target="#b6">Klein and Manning (2004)</ref>.</p><formula xml:id="formula_1">are DT L DT R N N L N N R V L V R ).</formula><p>Require: A is parent node of binary rule; w i,k is a valid span of terminals and i + 1 &lt; k function TREESAMPLER(A, i, k) for i &lt; j &lt; k and pair of child nodes of A:B, C do</p><formula xml:id="formula_2">P (j, B, C) = Œ∏ w A‚ÜíBC c(i,j)c(j,k)¬∑p B,i,j ¬∑p C,j,k p A,i,k</formula><p>end forSample j * , B * , C * from multinomial distri- bution for (j, B, C) with probabilities calculated above return j * , B * , C * end function Algorithm 1: Sampling split position and rule to expand parent node.</p><p>Gibbs sampler The split-head representation encodes dependencies as a CFG. This enables the use of a Gibbs sampler algorithm for estimating <ref type="bibr">PCFGs (Johnson et al., 2007;</ref><ref type="bibr" target="#b19">Sun et al., 2014</ref>), and it is straightforward to incorporate constraints from partial annotations into this sampler. To do this, we modified the tree-sampling step to incor- porate constraints derived from GFL annotations and thereby impute the missing dependencies.</p><p>Given a string w = (w 1 , ¬∑ ¬∑ ¬∑ w n ), we define a span of w as w i,k = (w i+1 , ¬∑ ¬∑ ¬∑ , w k ), so that w = w 0,n . As introduced in <ref type="bibr" target="#b13">Pereira and Schabes (1992)</ref>, a bracketing B of w is a finite set of spans on w satisfying the requirement that no two spans in a bracketing may overlap unless one span con- tains the other. For each sentence w = w 0,n we define the auxiliary function for each span w i,j , 0 ‚â§ i &lt; j ‚â§ n:</p><formula xml:id="formula_3">c(i, j) = 1 if span w i,j is valid for B; 0 otherwise.</formula><p>Here one span is valid for B if it doesn't cross any brackets. Section 3.2 describes how to de- rive bracketing information from GFL annotations and how to determine if a span w i,j is valid or not.</p><p>Note that for parsing a corpus without any annota- tions and constraints, c(i, j) = 1 for any span, and the algorithm is equivalent to the Gibbs sampler in <ref type="bibr" target="#b19">Sun et al. (2014)</ref>. There are two parts to the tree-sampling. The first constructs an inside table as in the Inside- Outside algorithm for PCFGs and the second se- lects the tree by recursively sampling productions from top to bottom. Consider a sentence w, with sub-spans w i,k = (w i+1 , ¬∑ ¬∑ ¬∑ , w k ). Given Œ∏ w (modified rule probabilities Œ∏ given constraints of sentence w, see Section 3.2), we construct the in- side table with entries p A,i,k for each nonterminal and each span w i,k : 0 ‚â§ i &lt; k ‚â§ n. We introduce Require: Arcs is the set of all directed arcs extracted from annotation for sentence w function RULEPROB-SENT(w, Œ∏, Arcs) Œ∏ w = Œ∏ for each directed arc wi &lt; wj do if i &lt; j then for nonterminal A = LœÑ j do Œ∏ w A‚ÜíŒ≤ = 0 if Œ≤</p><note type="other">contains YœÑ i end for else for nonterminal A = RœÑ j do Œ∏ w A‚ÜíŒ≤ = 0 if Œ≤ contains YœÑ i end for end if end for return Œ∏ w end function Algorithm 2: Modifying Rule Probabilities for w to ensure parse tree contains all directed arcs.</note><p>c(i, j) into the calculation of inside probabilities:</p><formula xml:id="formula_4">p A,i,k = c(i, k)¬∑ A‚ÜíBC‚ààR i&lt;j&lt;k Œ∏ w A‚ÜíBC ¬∑ p B,i,j ¬∑ p C,j,k<label>(1)</label></formula><formula xml:id="formula_5">Here, p A,i,k = P G A (w i,k | Œ∏ w )</formula><p>is the probability that terminals i through k were produced by the non-terminal A, A ‚Üí BC ‚àà R are possible rules to expand A. The inside table is computed recur- sively using Equation 1. The resulting inside probabilities are then used to generate trees from the distribution of all valid trees of the sentence. The tree is generated from top to bottom recursively with the function T reeSampler defined in Algorithm 1, which in- troduces c(i, j) into the sampling function from <ref type="bibr" target="#b19">Sun et al. (2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constraints derived from GFL</head><p>We exploit one dependency constraint and two constituency constraints from partial GFL anno- tations.</p><p>Dependency rule Directed arcs are indicated with angle brackets pointing from the dependent to its head, e.g. black &gt; cat. Once we have a di- rected arc annotation, say œâ i &gt; œâ j , if i &lt; j, which means word j has a left child, we must have rule</p><formula xml:id="formula_6">L 1 œÑ j ‚Üí Y œÑ i L œÑ j in our parse tree (similarly if i &gt; j, we have R 1 œÑ j ‚Üí R œÑ j Y œÑ i in our parse tree)</formula><p>, where œÑ i , œÑ j are parts-of-speech for œâ i and œâ j . We en- force this by modifying the rule probabilities for sample sentence w to ensure that any sampled tree contains all specified arcs. Brackets GFL allows annotators to group words with parenthesis, which provides an explicit indi- cator of constituent brackets. Even when the inter- nal structure is left underspecified (e.g. (the eq- uity division*) in <ref type="figure" target="#fig_0">Figure 1 (a)</ref>, the head is usu- ally marked with *, and we can use this to infer sub-constituents. Given such a set of parentheses and the words inside them, we generate brackets over the split-head representations of their parts- of-speech, based on possible positions of the head. <ref type="figure" target="#fig_1">Figure 2</ref> shows how to generate brackets for three situations: the head is the leftmost word, right- most word, or is in a medial position. For exam- ple, the first annotation indicates that under is the head of under the agreement, and the rest of words are right descendants of under. This leads to the bracketing shown over the split-heads.</p><p>Half brackets We can also derive one-sided half brackets from dependency arcs by assuming that dependencies are projective. For example, in <ref type="figure">Fig- ure 3</ref>, the annotation a &gt; dog specifies that dog has a left child a, so we know that there is a right bracket before the right-head of dog. Thus, we can detect invalid spans using the half brackets; if a span starts after a and ends after dog, this span is invalid because it would result in crossing brack- ets. This half bracketing is a unique advantage provided by the split-head representation. The de- tails of this algorithm are shown in Algorithm 3.</p><p>Require: Arcs is the set of all directed arcs extracted for sentence, w a,b is a span to detect function DETECTINVALIDSPAN(a, b, Arcs) for each directed arc œâi &lt; œâj do if i &lt; j then if a &lt; 2i</p><formula xml:id="formula_7">‚àí 1 &lt; b &lt; 2j then c(a, b) = 0 end if else if 2j ‚àí 2 &lt; a &lt; 2i ‚àí 1 &lt; b then c(i, j) = 0 end if end if end for return c(a, b) end function</formula><p>Algorithm 3: Detect whether one span is invalid given all directed arcs. We use both half bracket and full bracket infor- mation, B, to determine whether a span is valid. We set c(i, j) = 0 for all spans over w detected by Algorithm 3 and violating B. Then, in the sam- pling scheme, we'll only sample parse trees that satisfy these underlying constraints. <ref type="figure" target="#fig_2">Figure 4</ref> shows the resulting blocked out spans in the chart based on both types of brackets for the given partial annotation, which is Step 1 of the process. The black dog is a constituent with dog marked as its head, so we generate a full bracket over the terminal string in Step 2. Also, barks has a right child loudly; this generates a half bracket before V R . In Step 3, the chart in <ref type="figure" target="#fig_2">Figure 4</ref> repre- sents all spans over terminal symbols. The cells in black are invalid spans based on the full bracket, and the hatched cells are invalid spans based on the half bracket.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Experiments There are two points of variation to consider in empirical evaluations of our ap- <ref type="figure">Figure 5</ref>: English oracle and degradation results proach. The first is the effectiveness of the GPC in imputing missing dependencies and the second is the effectiveness of the GFL annotations them- selves. Of particular note with respect to the latter is the reasonable likelihood of divergence between the annotator and the corpus used for evaluation- for example, how coordination is handled and whether subordinate verbs are dependents or heads of auxiliary verbs. To this end, we perform simu- lation experiments that remove increasing portions of gold dependencies from a training corpus to un- derstand imputation performance and annotation experiments to evaluate the entire pipeline in a re- alistically constrained annotation effort.</p><p>In that regard, one thing to consider are the part- of-speech tags used by the unlexicalized GPC. These do not come for free, so rather than ask annotators to provide them, the raw sentences to be annotated were tagged automatically. For En- glish and Kinyarwanda, we used taggers trained with resources built in under two hours <ref type="bibr" target="#b3">(Garrette and Baldridge, 2013)</ref>, so these results are actually constrained to the GFL annotation time plus two hours. Such taggers were not available for Chinese or Portuguese, so the Stanford tagger ( <ref type="bibr" target="#b20">Toutanova et al., 2003</ref>) was used instead.</p><p>After imputing missing dependencies, the GPC outputs fully sentences that are used to train Tur- boParser ( <ref type="bibr" target="#b10">Martins et al., 2010)</ref>. In all cases, we compare to a right-branching baseline (RB). Although comparing to a random baseline is more typical of imputation experiments, a right- branching baseline provides a stronger initial com- parison. For the GFL annotation experiments, we use two additional baselines. The first is simply to use the sentences with full annotations and drop any incomplete ones (GFL-DROP). The second is Language ENG CHI POR RB 25.0 11.6 27.0 GFL-GPC-25 58.7 33.5 60.2 GFL-GPC-50 75.0 46.1 71.4 GFL-GPC-75 77.8 50.1 73.7 Full 81.6 56.2 78.1 <ref type="table">Table 3</ref>: Results with simulated partial annota- tions, GFL-GPC-X indicates X percent of depen- dencies were retained.</p><p>to make any partial annotations usable by assum- ing a right-branching completion (GFL-RBC).</p><p>Simulated partial annotations <ref type="figure">Figure 5</ref> shows the learning curve with respect to number of an- notated tokens when retaining 100%, 75%, 50% and 25% of gold-standard training dependencies and using the GPC to impute the removed ones.</p><p>With both 75% and 50% retained, performance degrades gracefully. It is substantially lower for 25%, but the curve is steeper than the others, indi- cating it is on track to catch up. Nonetheless, one recommendation from these results is that it prob- ably makes sense to start with a small number of fully annotated sentences and then start mixing in partially annotated ones. <ref type="table">Table 3</ref> shows the attachment scores obtained for English, Chinese, and Portuguese with varying proportions of dependencies removed for the GPC to impute. <ref type="bibr">4</ref> English and Portuguese hold up well with 75% and 50% retained, while Chinese drops more precipitously, and 25% leads to substantial reductions in performance for all.</p><p>Note that these simulations indicate that, given an equivalent number of total annotated arcs, using the GPC is more beneficial than requiring annota- tors to fully specify annotations. Imputing fifty percent of the dependency arcs from sentences containing 1000 tokens is typically more effective by a few points than using the full gold-standard arcs from sentences containing 500 tokens. Ac- tually, this simulation is too generous to complete annotations in that it leaves out consideration of the time and effort required to obtain those 100% full gold-standard arcs: it is often a small part of a sentence that consumes the most effort when full annotation is required. Additionally, these simula- tion experiments randomly removed dependencies while humans tend to annotate higher-level con-Eval Length &lt; 10 &lt; 20 all GFL-DROP (4hr) 54.5 55.0 52.6 GFL-GPC (4hr) 60.1 61.8 55.1 <ref type="bibr" target="#b1">Blunsom and</ref><ref type="bibr">Cohn, 2010 67.7 - 55.7 Naseem et al., 2010</ref> 71.9 50.4 - <ref type="table">Table 4</ref>: English results compared to previous un- supervised and weakly-supervised methods.</p><p>stituents and leave internal structure (e.g. of noun phrases) underspecified. Given Hwa's (1999) find- ings, we expect non-random partial annotations to better serve as a basis for imputation.</p><p>GFL annotations We conducted three sets of experiments with GFL annotations, evaluating on sentences of all lengths, less than 10 words, and less than 20 words. This was done to determine the types of sentences that our method works best on and to compare to previous work that evaluates on sentences of different lengths. <ref type="table">Table 4</ref> shows how our results on ENG com- pare to others. <ref type="bibr" target="#b1">Blunsom and Cohn (2010)</ref> rep- resent state-of-the-art unsupervised results for all lengths, while <ref type="bibr" target="#b12">Naseem et al. (2010)</ref> was chosen as a previous weakly-supervised approach. GFL-GPC achieves similar results on the 'all lengths' crite- rion as Blunsom and Cohn and substantially out- performs Naseem et al. on sentences less than 20 words. Our poor performance on short sentences is slightly surprising, and may result from an un- even length distribution in the sentences selected for annotation-we have only 3 training sentences less than 10 words-as discussed by <ref type="bibr" target="#b15">Spitkovsky et al. (2010a)</ref>. To correct this problem, both long and short sentences should be included to construct a more representative sample for annotation.</p><p>We did not expect GFL-RBC to perform so sim- ilarly to RB. It is possible that the relatively large number of under-specified sentences led to the right-branching quality of GFL-RBC dominating, rather than the more informative GFL annotations.</p><p>The results of the ENG annotation session can be seen in <ref type="figure" target="#fig_3">Figure 6a</ref>. GFL-GPC is quite strong even at thirty minutes, with only seven sentences anno- tated. GFL-DROP picks up substantially at the end; this may be in part explained by the fact that the last block contained many short sentences, which provide greater marginal benefit to GFL-DROP than to GFL-GPC.</p><p>The learning curves for the other languages can be seen in <ref type="figure" target="#fig_3">Figures 6b-6d</ref>, with a summary avail- able in   <ref type="figure" target="#fig_3">Figure 6c</ref> exhibit a pattern unlike the other languages; specifically, the KIN data has a very high right-branching baseline (RB in figures) and responds nearly identically for all of the more informed methods. Upon investi- gation, this appears to be an artifact of the data used in KIN evaluation plus domain adaptation is- sues. The gold data consists of transcribed natural speech, whereas the training data consists of sen- tences extracted from the Kinyarwanda Wikipedia.</p><p>All of the learning curves display a large ini- tial jump after the first round of annotations. This is encouraging for approaches that use annotated sentences: just a small number of examples pro- vide tremendous benefit, regardless of the strategy employed.</p><p>Error analysis The primary errors seen on an analysis of the GPC-completed sentences varies somewhat between languages. The ENG data con- tains many short sentences, consisting often of a few words and a punctuation mark. Part of the GFL convention is that the annotator is free to an- notate punctuation as part of the sentence or in- stead view it as extra-linguistic and drop the punc- tuation from the annotation. Often the punctuation in the ENG data went unannotated, with the result being that the final parse model is not particularly good at handling these types of sentences when encountered in the test set.</p><p>Specific constructions like coordination and possession also suffer a similar issue in that an- notators (and corpora) varied slightly on how they were handled. Thus, some languages like CHI contained many of a particular type of error due to mismatches in the conventions of the annota- tor and corpus. Issues like this could have been avoided by a longer training period prior to anno- tation, although were this a real annotation project, there would be no existing corpus to compare to at first. This brings up a more basic question of eval- uation -one of usability versus representational norm matching. It is likely that the GFL anno- tations (and thus the models trained on them) di- verge from the gold standard in what amount to annotation conventions rather than substantive lin- guistic divergences. To evaluate more fully or fairly, we would need test sets produced by the same set of annotators or an external, task-based evaluation that uses the dependencies as in input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have described a modeling strategy that takes advantage of a Gibbs sampling algorithm for CFG parsing plus constraints obtained from partial an- notations to build dependency parsers. This strat- egy's performance improves on that of a parser built only on the available complete annotations. In doing so, our approach supports annotation ef- forts that use GFL to obtain guidance from non- expert human annotators and allow any annotator to put in less effort than they would to do complete annotations.</p><p>We find that a remarkably small amount of supervised data can rival existing unsupervised methods. While unsupervised methods have been considered an attractive option for low-resource parsing, they typically rely on large quantities of clean, raw sentences. Our method uses less than one hundred sentences, so in a truly low-resource scenario, it has the potential to require much less total effort. For instance, a single native speaker could easily both generate and annotate the sen- tences required for our method in a few hours, while the many thousands of raw sentences needed for state-of-the-art unsupervised methods could take much longer to assemble if there is no ex- isting corpus. This also means our method would be useful for getting in-domain training data for domain adaptation for parsers.</p><p>Finally, our method has the ability to encode both universal grammar and test-language gram- mar as a prior. This would be done by replacing the uniform prior used in this paper with a prior favoring those grammar rules during the updating- rule-probabilities phase of the GPC, and would es- sentially have the effect of weighting those gram- mar rules.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: GFL example for Mr. Conlon was executive vice president and director of the equity division.</figDesc><graphic url="image-1.png" coords="2,335.05,53.86,162.73,170.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Generating brackets for known head</figDesc><graphic url="image-2.png" coords="5,72.00,49.91,226.78,180.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Process of generating brackets and detecting invalid spans.</figDesc><graphic url="image-4.png" coords="5,307.28,266.78,226.77,141.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: GPC results by annotation time for eval sentences of all lengths.</figDesc><graphic url="image-9.png" coords="8,302.86,257.61,208.64,177.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Two Hour GFL Annotation Statistics</head><label>2</label><figDesc></figDesc><table>Kong et al. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 5 . Like ENG, CHI and POR both</head><label>5</label><figDesc></figDesc><table>Language 

KIN 
CHI 
POR 
RB 

52.6 11.6 27.0 
GFL-DROP (2hr) 64.4 36.7 59.8 
GFL-GPC (2hr) 
64.5 38.8 65.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 5 : Non-English results summary</head><label>5</label><figDesc></figDesc><table>show clear wins for the GPC strategy. Of particu-
lar note is that the CHI annotations contained many 
fewer fully-completed sentences (4) than the ENG 
annotations (15). This somewhat addresses the 
question raised by the 25% retention simulation 
experiments-the GPC method improves results 
over dropping partial annotations. The POR results 
show a consistent strong win for GPC throughout. 
The KIN results in </table></figure>

			<note place="foot" n="1"> In fact, standardized writing systems have yet to be adopted for some languages.</note>

			<note place="foot" n="2"> The software, instructions, and data are available at http://www.github.com/jmielens/gpc-acl-2015</note>

			<note place="foot" n="3"> The graphical representation shows both of these as FE nodes, for fudge expression, indicating they are grouped together but otherwise underspecified.</note>

			<note place="foot" n="4"> These are based on the same sentences used in the next section&apos;s GFL annotation experiments for each language.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the U. S. Army Research Laboratory and the U. S. Army Research Office under contract/grant number W911NF-10-1-0533</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Floresta sint√°(c)tica&quot;: a Treebank for Portuguese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 3rd International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1698" to="1703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised induction of tree substitution grammars for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1204" to="1213" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Efficient parsing for bilexical context-free grammars and head automaton grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</title>
		<meeting>the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning a part-of-speech tagger from two hours of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="138" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supervised grammar induction using training data with limited constituent information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Hwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</title>
		<meeting>the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="73" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bayesian inference for PCFGs via Markov chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Corpusbased induction of syntactic structure: Models of dependency and constituency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 478. Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics, page 478. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A dependency parser for tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archna</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stopprobability estimates computed on a large corpus improve unsupervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Marecek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="281" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Turbo parsers: Dependency parsing by approximate variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Andr√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Q</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>M√°rio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="34" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Simplified dependency annotations with GFL-Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">T</forename><surname>Mordowanec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">121</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using universal linguistic knowledge to guide grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1234" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Insideoutside reestimation from partially bracketed corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Schabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual meeting on Association for Computational Linguistics</title>
		<meeting>the 30th annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A framework for (under) specifying dependency syntax without overloading annotators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Oconnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Saphra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>LAW VII &amp; ID</publisher>
			<biblScope unit="page">51</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">From baby steps to leapfrog: How less is more in unsupervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="751" to="759" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Profiting from mark-up: Hyper-text annotations for guided parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alshawi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1278" to="1287" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Punctuation: Making a point in unsupervised dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Three dependency-and-boundary models for grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiyan</forename><surname>Valentin I Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Alshawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="688" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parsing low-resource languages using Gibbs sampling for PCFGs with latent annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Mielens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Feature-rich part-ofspeech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Penn Chinese TreeBank: Phrase structure annotation of a large corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural language engineering</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="207" to="238" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
