<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Disambiguating prepositional phrase attachment sites with sense information captured in contextualized distributional data</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 22-27 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Greenberg</surname></persName>
							<email>cgreenbe@alumni.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics and Phonetics Universität des Saarlandes</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Disambiguating prepositional phrase attachment sites with sense information captured in contextualized distributional data</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the ACL 2014 Student Research Workshop</title>
						<meeting>the ACL 2014 Student Research Workshop <address><addrLine>Baltimore, Maryland USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="71" to="77"/>
							<date type="published">June 22-27 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This work presents a supervised preposi-tional phrase (PP) attachment disambigua-tion system that uses contextualized distri-butional information as the distance metric for a nearest-neighbor classifier. Con-textualized word vectors constructed from the GigaWord Corpus provide a method for implicit Word Sense Disambiguation (WSD), whose reliability helps this system outperform baselines and achieve comparable results to those of systems with full WSD modules. This suggests that targeted WSD methods are preferable to ignoring sense information and also to implementing WSD as an independent module in a pipeline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Arriving at meaning from a linguistic expression is hardly a trivial process, but a "simple" four-word expression shows some of the kinds of knowledge and interactions involved:</p><p>(1) a. eat [seeds <ref type="bibr">[in plants]]</ref> b.</p><p>[eat seeds] [in plants]</p><p>(a) and (b) illustrate two possible interpretations for the expression. In (a), the seeds are part of larger organic units, and in (b), the eating takes place in refineries. Choosing (a) or (b) helps the system construct accurate relationships between the events and participants mentioned, which is es- sential for many natural language processing tasks including machine translation, information extrac- tion, and textual inference. These two groupings represent an example of the widely-studied phenomenon of prepositional phrase (PP) attachment ambiguity. We define the governor of a PP as the word or phrase that the PP modifies. Ambiguity arises from multi- ple candidates for the governor. Strings such as in (1) can be represented by quadruples of the form (V, N 1 , P, N 2 ), where V is a transitive verb, N 1 is the head noun of an object of V , P is a preposition, and N 2 is the head noun of the object of P . Then, (a) and (b) reflect the two possible choices of governor for the PP: V (adverbial PP) and N 1 (adjectival PP). Therefore, disambiguation for such quadruples is a binary classification of the PP as adjectival or adverbial, or equivalently, noun-attach or verb-attach.</p><p>In our example, classifying the sense of the word plant as either organic unit or refinery is key to choosing the correct struc- ture. These senses have significantly different re- spective relationships to eat and seeds. In partic- ular, we often eat most except, or only, the seeds from an organic unit, but we have no such intu- itions about refineries. The training data must be analyzed carefully in order to prevent unwanted mixing of senses, since that causes noise in pre- dictions about word relationships.</p><p>Given that V −N 2 and N 1 −N 2 relationships are very important for PP-attachment disambiguation, it is not surprising that leading PP-attachment dis- ambiguation systems include a Word Sense Dis- ambiguation (WSD) module. The challenging as- pect of this is that it introduces a subtask that in the general case has lower accuracy levels than the entire system. Hence, its place and form within the system deserves to be examined closely. Since a representation of the predicted sense is not part of the attachment decision, it does not need to be explicitly present within the procedure. In this paper, we investigate the importance of proper word sense decisions for PP-attachment disam- biguation, and describe a highly-accurate system that encodes sense information in contextualized distributional data. Its high performance shows the benefit of representing and handling sense in- formation in a targeted fashion for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>71</head><p>Sense information provides an illuminating through line for many previous PP-attachment disambiguation systems. We begin by describing a very popular dataset for the problem and its subsequent development, and then trace through the two main approaches to sense information representation and the results obtained using this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The corpus</head><p>A standard corpus for the binary classification problem described above was developed by Ratna- parkhi, <ref type="bibr" target="#b13">Reynar and Roukos (1994)</ref>. They system- atically extracted (V, N 1 , P, N 2 ) quadruples from the Penn Treebank Wall Street Journal (WSJ) cor- pus and used the manually-generated constituency parses to obtain attachment decisions for each of the extracted PPs. The final dataset con- tained 27,937 quadruples. These were divided into 20,801 training quadruples, 4,039 development quadruples, and 3,097 test quadruples. Their max- imum entropy model achieved 81.6% accuracy on this dataset and their decision tree achieved 77.7%. Accuracy on this corpus is defined to be the num- ber of quadruples for which the classifier assigned the same attachment site as the site indicated in that sentence's parse tree, divided by the total number of quadruples. Although some parse trees in the corpus are known to have errors, the accu- racy figures do not take this into account.</p><p>Also, <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> conducted hu- man experiments with a subset of their corpus. They found that humans, when given just the quadruple, were accurate 88.2% of the time. When given the entire sentence for context, ac- curacy improved to 93.2%. The perhaps un- derwhelming human performance is partially due to misclassifications by the Treebank assemblers who made these determinations by hand, and also unclear cases, which we discuss in the next sec- tion. <ref type="bibr" target="#b3">Collins and Brooks (1995)</ref> introduced modifica- tions to the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset meant to combat data sparsity and used the modified ver- sion to train their backed-off model. They re- placed four digit numbers with YEAR, other num- bers with NUM. Verbs and prepositions were con- verted to all lowercase. In nouns, all words that started with an uppercase letter followed by a low- ercase letter were replaced with NAME. Then, all strings NAME-NAME were replaced with NAME. Finally all verbs were automatically lemmatized. They did not release statistics on how these mod- ifications affected performance, so it is unclear how to allocate the performance increase between the backed-off model and the modifications to the dataset. The paper also provided some baselines: they achieve 59.0% accuracy on the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> corpus by assigning noun-attach to ev- ery quadruple, and 72.2% accuracy by assigning a default classification determined for each prepo- sition. They show, and many subsequent papers confirm, that the preposition is the most predictive dimension in the quadruple.</p><p>Abney, Schapire, and Singer (1999) used the dataset from <ref type="bibr" target="#b3">Collins and Brooks (1995)</ref> with a boosting algorithm and achieved 85.4% accuracy. Their algorithm also was able to order the spe- cific data points by how much weight they were assigned by the learning algorithm. The highest data points tended to be those that contained er- rors. Thus, they were able to improve the quality of the dataset in a systematic way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The WordNet approach</head><p>WordNet <ref type="bibr">(Fellbaum, 1998)</ref> can be quite a power- ful aid to PP-attachment disambiguation because it provides a way to systematically quantify se- mantic relatedness. The drawback is, though, that since WordNet semantic relations are between ex- plicit word senses (SynSets), the words in the quadruples must be associated with these explicit word senses. The systems described below outline the different ways to make those associations. <ref type="bibr" target="#b2">Brill and Resnik (1994)</ref> trained a transformation-based learning algorithm on 12,766 quadruples from WSJ, with modifications similar to those by <ref type="bibr" target="#b3">Collins and Brooks (1995)</ref>. As a particularly human-interpretable feature, the rules used word sense hierarchies. Namely, a WordNet rule applied to the named node and all of its hyponyms. For example, a rule involving boat would apply to instances of kayak. Importantly, each noun in the corpus inherited hypernyms from all of its senses. Therefore, they did not perform explicit WSD. Their accuracy was 81.8%.</p><p>The neural network by Nadh and Huyck (2012) also used WordNet word sense hierarchies. Only the first (intended to be the most frequent) sense of the word was used in computations. Hence, they explicitly perform WSD using a baseline method.</p><p>On a training corpus of 4,810 quadruples and a test corpus of 3,000 quadruples from WSJ, they achieve 84.6% accuracy. This shows the suc- cess of performing baseline WSD as part of a PP- attachment disambiguation system, although the different dataset makes comparison less direct.</p><p>At the other extreme, Stetina and Nagao (1997) developed a customized, explicit WSD algorithm as part of their decision tree system. For each am- biguous word in each quadruple, this algorithm selected a most semantically similar quadruple in the training data using unambiguous or previously disambiguated terms. Then, the word was as- signed the WordNet sense that was semantically closest to the sense of the corresponding word in the other quadruple. Their distance metric was</p><formula xml:id="formula_0">L 1 /D 1 + L 2 /D 2 ,</formula><p>where L i is the distance from word sense i to the common ancestor, and D i is the depth of the tree (distance to root) at word sense i. Such a metric captures the notion that more fine grained distinctions exist deeper in the WordNet graph, so the same absolute dis- tance between nodes matters less at greater depths. <ref type="bibr" target="#b14">Stetina and Nagao (1997)</ref> trained on a version of the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset that con- tained modifications similar to those by <ref type="bibr" target="#b3">Collins and Brooks (1995)</ref> and excluded forms not present in WordNet. The system achieved 88.1% accuracy on the entire test set and 90.8% accuracy on the subset of the test set in which all four of the words in the quadruple were present in WordNet.</p><p>Finally, Greenberg (2013) implemented a de- cision tree that reimplemented the WSD module from <ref type="bibr" target="#b14">Stetina and Nagao (1997)</ref>, and also used WordNet morphosemantic (teleological) links, WordNet evocations, and a list of phrasal verbs as features. The morphosemantic links and evo- cations brought more semantic relatedness infor- mation after the cost of explicit WSD had al- ready been incurred. The system achieved 89.0% on a similarly modified <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The distributional approach</head><p>As an alternative to the WordNet approach, the distributional tradition allows for implicit sense handling given that contexts from all senses of the word are represented together in the vec- tor. Without modification, the senses are repre- sented according to their relative frequencies in the data. <ref type="bibr" target="#b12">Pantel and Lin (2000)</ref> created a col- location database that, for a given word, tracked the words that appeared in specific syntactic rela- tions to it, such as subject (for verbs), adjective- modifier (for nouns), etc. Then, they used the collocation database to construct a corpus-based thesaurus that evaluated semantic relatedness be- tween quadruples. With a mix of unsupervised learning algorithms, they achieved 84.3% accu- racy. They also argued that rules involving both V and N 1 should be excluded because they cause over-fitting.</p><p>Zhao and Lin (2004) implemented a nearest neighbor system that used various vector similar- ity metrics to calculate distances between quadru- ples. The vectors were generated from the AC- QUAINT corpus with both syntactic relation and proximity-based (bag of words) models. They found that the cosine of pointwise mutual informa- tion metric on a syntactic model performed with the greatest accuracy (86.5%, k = 33). They used a version of the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset that had all words lemmatized and all digits re- placed by @.</p><p>Using the Web as a large unsupervised corpus, Nakov and Hearst (2005) created a PP-attachment disambiguation system that exploits n-grams, de- rived surface features, and paraphrases to predict classifications. The system searched for six spe- cific disambiguating paraphrases such as opened the door (with a key), which suggests verb-attach, and eat: spaghetti with sauce, which suggests noun-attach. Paraphrases and n-gram models represent the aim to gather context beyond the quadruple as a disambiguation method. Their fi- nal system had 85.0% precision and 91.8% recall on the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset. When assigning unassigned quadruples to verb-attach, it had 83.6% accuracy and 100% recall. Their sys- tem continued the trend that the most common er- ror is classifying a noun-attach quadruple as verb- attach. This is because the majority of difficult cases are verb-attach, so all of the difficult cases get assigned verb-attach as a default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Linguistic analysis</head><p>In this section, we will discuss some difficul- ties with and observations about the task of PP- attachment disambiguation. The analyses and conclusions drawn here set the linguistic founda- tion for the structure of the system described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Lexically-specified prepositions</head><p>Hindle and Rooth (1993) provided many linguis- tic insights for the PP-attachment disambiguation problem, including the tendency to be verb-attach if N 1 is a pronoun, and that idiomatic expres- sions (e.g. give way to mending) and light verb constructions (e.g. make cuts to Social Security) are particularly troublesome for humans to clas- sify. The defining feature of such constructions is a semantically-vacuous preposition. For example, in (2), we have semantically similar verbs appear- ing with different prepositions and yet the mean- ings of these sentences are still similar.</p><p>(2) a. She was blamed for the crime.</p><p>b. She was accused of the crime.</p><p>c. She was charged with the crime.</p><p>Further, when we nominalize charged we can get charges of murder, but charged of murder is usu- ally unacceptable. Also, (3) gives an analogous three-way preposition variation following nouns.</p><p>(3) a. They proposed a ban on tea.</p><p>b. They proposed a request for tea.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c. They proposed an alternative to tea.</head><p>We argue that in these cases, a preceding word completely determines the preposition selected and that no further meaning is conveyed. In fact, we might say that the prepositions in this case serve analogously to morphological case mark- ing in languages more heavily inflected than En- glish. Freidin (1992) makes a proposal along these lines. The prescriptive rules that dictate "correct" and "incorrect" prepositions associated with cer- tain verbs, nouns, and adjectives, as well as our ro- bust ability to understand these sentences with the prepositions omitted, strongly suggest that this se- lection is idiosyncratic and cannot be derived from deeper principles.</p><p>The extreme case is phrasal verbs, for which it is problematic to posit the existence of a PP because the object can occur before or after the "preposi- tion." As shown in (4d), this is not acceptable for standard prepositions.</p><p>(4) a.</p><p>He ran up the bill.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>b.</head><p>He ran the bill up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>c.</head><p>He ran up the hill.</p><p>d. * He ran the hill up.</p><p>For these, we say that there is one lexical entry for the transitive verb plus the particle (preposition without an object), as in to run up, and an optional operation reverses the order of the object of the phrasal verb and its particle. Usual paraphrase tests, such as those described in <ref type="bibr" target="#b11">Nakov and Hearst (2005)</ref>, often do not lead to consistent conclusions about the proper attach- ment site for these lexically-specified preposi- tions. Further, two separate governors do not ap- pear to be plausible. Therefore, these construc- tions probably do not belong as data points in the PP-attachment task. However, if they must conform to the task, the most reasonable attach- ment decision is likely to be the word that deter- mined the preposition. Therefore, the PPs in <ref type="formula">(2)</ref> are verb-attach and those in (3) are noun-attach. This treatment of lexically-specified prepositions accounts for light verb constructions because the N 1 in those constructions dictates the preposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The special case of of</head><p>PPs with the preposition of attach to nouns with very few exceptions. In fact, 99.1% of the quadruples with of in our training set are noun- attach. The other 0.9% were misclassifications and quadruples with verbs that lexically specify of, such as accuse. The behavior of of -PPs has been widely studied. We take the acceptability of (5a) and not (5b) as evidence that of -PPs introduce argument-like descriptions of their governors.</p><p>(5) a.</p><p>a game of cards with incalculable odds b. * a game with incalculable odds of cards</p><p>The extremely high proportion of noun- attachments within of -PPs leads some to exclude of -PPs altogether from attachment disambigua- tion corpora. In our data, excluding this most com- monly used English preposition shifts the most frequent attachment decision from noun-attach to verb-attach. This is unfortunate for systems aim- ing to mimic human processing, since Late Clo- sure <ref type="bibr" target="#b6">(Frazier, 1979)</ref> suggests a preference for noun-attach as the default or elsewhere case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>Our PP attachment disambiguation system is most closely related to <ref type="bibr" target="#b15">Zhao and Lin (2004)</ref>. We ex- perimented with several similarity measures on a slightly preprocessed version of the <ref type="bibr" target="#b13">Ratnaparkhi et al. (1994)</ref> dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training data</head><p>Because humans only perform 0.1% better than Stetina and Nagao's (1997) system when given the quadruples but not the full sentences (although technically on different datasets), we found it im- portant to locate the full sentences in the Penn Treebank. So, we carefully searched for the quadruples in the raw version of the corpus. We ensured that the corpus would be searched sequen- tially, i.e. search for the current quadruple would begin on the previous matched sentence and then proceed forward. By inspection, we could tell that the sentences were roughly in order, so this choice increased performance and accuracy. How- ever, we had to adapt the program to be flexible so that some truncated tokens in the quadruples, such as incorrectly segmented contractions, would be matched to their counterparts.</p><p>Next, we created some modified versions of the training corpus. We explored the effect of excluding quadruples with lexically-specified prepositions (usually tagged PP-CLR in WSJ), removing sentences in which there was no ac- tual V, N 1 , P, N 2 string found, manually remov- ing encountered misclassifications, and reimple- menting data sparsity modifications from <ref type="bibr" target="#b3">Collins and Brooks (1995)</ref> and <ref type="bibr" target="#b14">Stetina and Nagao (1997)</ref>. In particular, we used the WordNet lemmatizer in NLTK to lemmatize the verbs in the corpus <ref type="bibr" target="#b1">(Bird, Loper, and Klein 2009)</ref>. However, for direct com- parison with <ref type="bibr" target="#b15">Zhao and Lin (2004)</ref>, we decided to use in our final experiment a version of the cor- pus with all words lemmatized and all numbers replaced by @, but no other modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Knowledge base</head><p>In order to compute quadruple similarity mea- sures that take context information into account, we adopted the vector space model implemented by <ref type="bibr" target="#b4">Dinu and Thater (2012)</ref>. This model constructs distributional word vectors from the GigaWord corpus. We used a "filtered" model, meaning that the context for each occurrence is composed of words that are linked to that occurrence in a de- pendency parse. Therefore, the model is similar to a bag of words model, but does contain some syntactic weighting. To contextualize a vector, the model weights the components of the uncontextu- alized vector with the components of the context vector, using the formula</p><formula xml:id="formula_1">v(w, c) = w∈W α(c, w)f (w, w) e w</formula><p>where w is the target word, c is the context, W is the set of words, α is the cosine similarity of c and w, f is a co-occurrence function, and e w is a basis vector. Positive pmi-weighting was also applied to the vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation</head><p>We adopted the four-step classification procedure from <ref type="bibr" target="#b15">Zhao and Lin (2004)</ref>. At each step for each test quadruple, the training examples are sorted by a different vector composition method, a set of best examples is considered, and if these examples cast equal votes for noun-attach and verb-attach, the algorithm moves to the next step. Otherwise, the class with the greatest number of votes is as- signed to the test quadruple.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Consider only the training examples for</head><p>which all four words are equal to those in the test quadruple.</p><p>2. Consider the k highest (k experimentally de- termined) scoring examples, with the same preposition as the test quadruple, using the composition function sim(q 1 , q 2 ) = vn 1 + vn 2 + n 1 n 2 where v, n 1 , and n 2 are the vector similarities of the V , N 1 , and N 2 pairs.</p><p>3. Same as (2), except using the function sim(q 1 , q 2 ) = v + n 1 + n 2 4. Assign default class for the preposition (last resort), or noun-attach if there is no default class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Similarity measures</head><p>We implemented four similarity measures. (1) abs: absolute word similarity, which gives 1 if the tokens are identical, 0 otherwise. (2) noctxt: co- sine similarity using uncontextualized word vec- tors. (3) ctxt quad : cosine similarity using word vectors contextualized by the quadruple words. (4) ctxt sent : cosine similarity using word vectors con- textualized by words from the full sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>75</head><p>We set the k values by using five-fold cross- validation on the training quadruples. Then, for intermediate numerical checks, we tested the sys- tems on the development quadruples. The figures in the next section are the result of a single run of the final trained systems on the test quadruples. <ref type="table">Table 1</ref> presents results from our binary classifier using the different similarity measures. <ref type="table" target="#tab_1">Table 2</ref> compares our best binary classifier accuracy (us- ing ctxt quad ) to other systems.   <ref type="table" target="#tab_0">Table 3</ref>: Coverage and accuracy for classification procedure steps, using ctxt quad .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>The results above show that contextualizing the word vectors, which is meant to implic- itly represent sense information, can statistically- significantly boost performance on PP-attachment disambiguation by 1.8% (χ 2 = 4.31, p &lt; 0.04) on an already quite accurate system. We can see that using the full sentence as context, while helpful for human judgment, is not effective in this sys- tem because there are not enough examples in the knowledge base for reliable statistics. It seems as though too much context obscures generalizations otherwise captured by the system. Nominal increases in accuracy aside, this sys- tem uses only a knowledge base that is not spe- cific to the task of PP-attachment disambiguation. We obtained highly accurate results without utiliz- ing task-specific resources, such as sense invento- ries, or performing labor-intensive modifications to training data. Since systems with full WSD modules would likely require both of these, this implicit handling of sense information seems more elegant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper describes a PP-attachment disambigua- tion system that owes its high performance to cap- turing sense information in contextualized distri- butional data. We see that this implicit handling is preferable to having no sense handling and also to having a full WSD module as part of a pipeline.</p><p>In future work, we would like to investigate how to systematically extract contexts beyond the quadruple, such as sentences or full documents, while maintaining the information captured in less contextualized vectors. Perhaps there are certain particularly informative positions whose words would positively affect the vectors. Given that words tend to maintain the same sense within a document, it is a particularly well-suited context to consider. However, care must be taken to min- imize unwanted sense mixing, combat data spar- sity, and restrict the number of similarity compar- isons for efficiency.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 3 shows</head><label>3</label><figDesc></figDesc><table>the 
number, percentage, and accuracy of decisions by 
step in the classification procedure for the ctxt quad 
run. 

Similarity measure k value Accuracy 
abs 
3 
80.2% 
noctxt 
11 
86.6% 
ctxt quad 
10 
88.4% 
ctxt sent 
8 
81.9% 

Table 1: Similarity measure performance compar-
ison. 

Method 
Sense handling 
Accuracy 
BR1994 
All senses equal 
81.8% 
PL2000 
Global frequency 
84.3% 
ZL2004 
Global frequency 
86.5% 
SN1997 
Full WSD 
88.1% 
Our system Context weighting 
88.4% 
G2013 
Full WSD 
89.0% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Leading PP-attachment disambiguation 
systems. 

Step Coverage Coverage % Accuracy 
1 
244 
7.88% 
91.8% 
2 
2849 
91.99% 
88.1% 
3 
0 
0.00% 
N/A 
4 
4 
0.13% 
100.0% 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We owe sincerest thanks to Prof. Dr. Manfred Pinkal and Dr. Stefan Thater for initial direction and providing the vector space model used in our system. Also, we thank Google for travel and con-ference support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Boosting Applied to Tagging and PPattachment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<meeting>the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora<address><addrLine>College Park, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media, Inc</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A rule-based approach to prepositional phrase attachment disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Computational Linguistics (COLING94)</title>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Prepositional Attachment through a Backed-off Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Very Large Corpora</title>
		<editor>David Yarovsky and Kenneth Church</editor>
		<meeting>the Third Workshop on Very Large Corpora<address><addrLine>Somerset, New Jersey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="27" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Saarland: vector-based models of semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting><address><addrLine>Montréal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="603" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On Comprehending Sentences: Syntactic Parsing Techniques. Unpublished doctoral dissertation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyn</forename><surname>Frazier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
		<respStmt>
			<orgName>University of Connecticut</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Foundations of generative syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Freidin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Disambiguating prepositional phrase attachment sites with graded semantic data or, how to rule out elephants in pajamas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Greenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished undergraduate thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mats</forename><surname>Rooth</surname></persName>
		</author>
		<title level="m">Structural Ambiguity and Lexical Relations. In Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="229" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neurocomputational approach to prepositional phrase attachment ambiguity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailash</forename><surname>Nadh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Huyck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1906" to="1925" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using the Web as an Implicit Training Set: Application to Structural Ambiguity Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLTNAACL</title>
		<meeting>HLTNAACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An unsupervised approach to prepositional phrase attachment using contextually similar words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 38th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Maximum Entropy Model for Prepositional Phrase Attachment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Reynar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ARPA Human Language Technology Workshop</title>
		<meeting>the ARPA Human Language Technology Workshop<address><addrLine>Plainsboro, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="250" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Corpus Based PP Attachment Ambiguity Resolution with a Semantic Dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Stetina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Workshop on Very Large Corpora, Beijing and Hong Kong</title>
		<meeting>the Fifth Workshop on Very Large Corpora, Beijing and Hong Kong</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="66" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Corpus Based PP Attachment Ambiguity Resolution with a Semantic Dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojun</forename><surname>Zhao Dekang Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Joint Conference on Natural Language Processing</title>
		<meeting>the First International Joint Conference on Natural Language Processing<address><addrLine>Sanya, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
