<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interpretable Semantic Vectors from a Joint Model of Brain-and Text-Based Meaning</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
							<email>brian.murphy@qub.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">School of Electronics</orgName>
								<orgName type="institution">Electrical Engineering and Computer Science Queen&apos;s University Belfast</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Interpretable Semantic Vectors from a Joint Model of Brain-and Text-Based Meaning</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="489" to="499"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Vector space models (VSMs) represent word meanings as points in a high dimensional space. VSMs are typically created using a large text corpora, and so represent word semantics as observed in text. We present a new algorithm (JNNSE) that can incorporate a measure of semantics not previously used to create VSMs: brain activation data recorded while people read words. The resulting model takes advantage of the complementary strengths and weaknesses of corpus and brain activation data to give a more complete representation of semantics. Evaluations show that the model 1) matches a behavioral measure of semantics more closely, 2) can be used to predict corpus data for unseen words and 3) has predictive power that generalizes across brain imaging technologies and across subjects. We believe that the model is thus a more faithful representation of mental vocabularies.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vector Space Models (VSMs) represent lexical meaning by assigning each word a point in high di- mensional space. Beyond their use in NLP appli- cations, they are of interest to cognitive scientists as an objective and data-driven method to discover word meanings <ref type="bibr" target="#b18">(Landauer and Dumais, 1997)</ref>.</p><p>Typically, VSMs are created by collecting word usage statistics from large amounts of text data and applying some dimensionality reduction technique like Singular Value Decomposition (SVD). The basic assumption is that semantics drives a per- son's language production behavior, and as a result co-occurrence patterns in written text indirectly encode word meaning. The raw co-occurrence statistics are unwieldy, but in the compressed VSM the distance between any two words is con- ceived to represent their mutual semantic similar- ity <ref type="bibr" target="#b28">(Sahlgren, 2006;</ref><ref type="bibr" target="#b32">Turney and Pantel, 2010)</ref>, as perceived and judged by speakers. This space then reflects the "semantic ground truth" of shared lex- ical meanings in a language community's vocab- ulary. However corpus-based VSMs have been criticized as being noisy or incomplete representa- tions of meaning <ref type="bibr" target="#b10">(Glenberg and Robertson, 2000</ref>). For example, multiple word senses collide in the same vector, and noise from mis-parsed sentences or spam documents can interfere with the final se- mantic representation.</p><p>When a person is reading or writing, the se- mantic content of each word will be necessarily activated in the mind, and so in patterns of ac- tivity over individual neurons. In principle then, brain activity could replace corpus data as input to a VSM, and contemporary imaging techniques allow us to attempt this. Functional Magnetic Res- onance Imaging (fMRI) and Magnetoencephalog- raphy (MEG) are two brain activation recording technologies that measure neuronal activation in aggregate, and have been shown to have a pre- dictive relationship with models of word mean- ing ( <ref type="bibr" target="#b21">Mitchell et al., 2008;</ref><ref type="bibr" target="#b25">Palatucci et al., 2009;</ref><ref type="bibr" target="#b31">Sudre et al., 2012;</ref><ref type="bibr" target="#b23">Murphy et al., 2012b</ref>). <ref type="bibr">1</ref> If brain activation data encodes semantics, we theorized that including brain data in a model of semantics could result in a model more consistent with semantic ground truth. However, the inclu- sion of brain data will only improve a text-based model if brain data contains semantic information not readily available in the corpus. In addition, if a semantic test involves another subject's brain activation data, performance can improve only if the additional semantic information is consistent across brains. Of course, brains differ in shape, size and in connectivity, so additional information encoded in one brain might not translate to an-other. Furthermore, different brain imaging tech- nologies measure very different correlates of neu- ronal activity. Due to these differences, it is possi- ble that one subject's brain activation data cannot improve a model's performance on another sub- ject's brain data, or for brain data collected using a different recording technology. Indeed, inter- subject models of brain activation is an open re- search area <ref type="bibr" target="#b7">(Conroy et al., 2013)</ref>, as is learning the relationship between recording technologies <ref type="bibr" target="#b8">(Engell et al., 2012;</ref><ref type="bibr" target="#b12">Hall et al., 2013)</ref>. Brain data can also be corrupted by many types of noise (e.g. recording room interference, movement artifacts), another possible hindrance to the use of brain data in VSMs.</p><p>VSMs are interesting from both engineering and scientific standpoints. In this work we fo- cus on the scientific question: Can the inclusion of brain data improve semantic representations learned from corpus data? What can we learn from such a model? From an engineering perspective, brain activation data will likely never replace text data. Brain activation recordings are both expen- sive and time consuming to collect, whereas tex- tual data is vast and much of it is free to download. However, from a scientific perspective, combining text and brain data could lead to more consistent semantic models, in turn leading to a better un- derstanding of semantics and semantic modeling generally.</p><p>In this paper, we leverage both kinds of data to build a hybrid VSM using a new matrix factor- ization method (JNNSE). Our hypothesis is that the noise of brain and corpus derived statistics will be largely orthogonal, and so the two data sources will have complementary strengths as in- put to VSMs. If this hypothesis is correct, we should find that the resulting VSM is more suc- cessful in modeling word semantics as encoded in human judgements, as well as separate corpus and brain data that was not used in the derivation of the model. We will show that our method:</p><p>1. creates a VSM that is more correlated to an independent measure of word semantics. 2. produces word vectors that are more pre- dictable from the brain activity of different people, even when brain data is collected with a different recording technology. 3. predicts corpus representations of withheld words more accurately than a model that does not combine data sources.</p><p>4. directly maps semantic concepts onto the brain by jointly learning neural representa- tions. Together, these results suggest that corpus and brain activation data measure semantics in com- patible and complimentary ways. Our results are evidence that a joint model of brain-and text-based semantics may be closer to seman- tic ground truth than text-only models. Our findings also indicate that there is additional se- mantic information available in brain activation data that is not present in corpus data, and that there are elements of semantics currently lack- ing in text-based VSMs. We have made avail- able the top performing VSMs created with brain and text data (http://www.cs.cmu.edu/ ˜ afyshe/papers/acl2014/).</p><p>In the following sections we will review NNSE, and our extension, JNNSE. We will describe the data used and the experiments to support our posi- tion that brain data is a valuable source of semantic information that compliments text data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Non-Negative Sparse Embedding</head><p>Non-Negative Sparse Embedding (NNSE) <ref type="bibr" target="#b22">(Murphy et al., 2012a</ref>) is an algorithm that produces a latent representation using matrix factorization. Standard NNSE begins with a matrix X ∈ R w×c made of c corpus statistics for w words. NNSE solves the following objective function:</p><formula xml:id="formula_0">argmin A,D w i=1 X i,: − A i,: × D 2 + λ A 1 (1) subject to: D i,: D T i,: ≤ 1, ∀ 1 ≤ i ≤ (2) A i,j ≥ 0, 1 ≤ i ≤ w, 1 ≤ j ≤ (3)</formula><p>The solution will find a matrix A ∈ R w× that is sparse, non-negative, and represents word seman- tics in an -dimensional latent space. D ∈ R ×c gives the encoding of corpus statistics in the la- tent space. Together, they factor the original cor- pus statistics matrix X in a way that minimizes the reconstruction error. The L 1 constraint encour- ages sparsity in A; λ is a hyperparameter. Equa- tion 2 constrains D to eliminate solutions where A is made arbitrarily small by making D arbi- trarily large. Equation 3 ensures that A is non- negative. We may increase to give more dimen- sional space to represent word semantics, or de- crease for more compact representations.</p><p>The sparse and non-negative representation in A produces a more interpretable semantic space, where interpretability is quantified with a behav- ioral task <ref type="bibr" target="#b5">(Chang et al., 2009;</ref><ref type="bibr" target="#b22">Murphy et al., 2012a</ref>). To illustrate the interpretability of NNSE, we describe a word by selecting the word's top scoring dimensions, and selecting the top scoring words in those dimensions. For example, the word chair has the following top scoring dimensions:</p><p>1. chairs, seating, couches; 2. mattress, futon, mattresses; 3. supervisor, coordinator, advisor.</p><p>These dimensions cover two of the distinct mean- ings of the word chair (furniture and person of power).</p><p>NNSE's sparsity constraint dictates that each word can have a non-zero score in only a few di- mensions, which aligns well to previous feature elicitation experiments in psychology. In feature elicitation, participants are asked to name the char- acteristics (features) of an object. The number of characteristics named is usually small <ref type="bibr" target="#b20">(McRae et al., 2005</ref>), which supports the requirement of spar- sity in the learned latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Joint Non-Negative Sparse Embedding</head><p>We extend NNSEs to incorporate an additional source of data for a subset of the words in X, and call the approach Joint Non-Negative Sparse Embeddings (JNNSEs). The JNNSE algorithm is general enough to incorporate any new infor- mation about the a word w, but for this study we will focus on brain activation recordings of a human subject reading single words. We will incorporate either fMRI or MEG data, and call the resulting models JNNSE(fMRI+Text) and JNNSE(MEG+Text) and refer to them generally as JNNSE(Brain+Text). For clarity, from here on, we will refer to NNSE as NNSE(Text), or NNSE(Brain) depending on the single source of input data used.</p><p>Let us order the rows of the corpus data X so that the first 1 . . . w rows have both corpus statis- tics and brain activation recordings. Each brain activation recording is a row in the brain data ma- trix Y ∈ R w ×v where v is the number of features derived from the recording. For MEG recordings, v =sensors × time points= 306 × 150. For fMRI v = grey-matter voxels = 20, 000 depending on the brain anatomy of each individual subject. The new objective function is:</p><formula xml:id="formula_1">argmin A,D (c) ,D (b) w i=1 X i,: − A i,: × D (c) 2 + w i=1 Y i,: − A i,: × D (b) 2 + λ A 1 (4) subject to: D (c) i,: D (c) i,: T ≤ 1, ∀ 1 ≤ i ≤ (5) D (b) i,: D (b) i,: T ≤ 1, ∀ 1 ≤ i ≤ (6) A i,j ≥ 0, 1 ≤ i ≤ w, 1 ≤ j ≤ (7)</formula><p>We have introduced an additional constraint on the rows 1 . . . w , requiring that some of the learned representations in A also reconstruct the brain ac- tivation recordings (Y ) through representations in</p><formula xml:id="formula_2">D (b) ∈ R ×v .</formula><p>Let us use A to refer to the brain- constrained rows of A. Words that are close in "brain space" must have similar representations in A , which can further percolate to affect the rep- resentations of other words in A via closeness in "corpus space". With A or D fixed, the objective function for NNSE(Text) and JNNSE(Brain+Text) is convex. However, we are solving for A and D, so the prob- lem is non-convex. To solve for this objective, we use the online algorithm of Section 3 from Mairal et al. ( <ref type="bibr" target="#b19">Mairal et al., 2010)</ref>. This algorithm is guaranteed to converge, and in practice we found that JNNSE(Brain+Text) converged as quickly as NNSE(Text) for the same . We used the SPAMS package 2 to solve, and set λ = 0.025. This al- gorithm was a very easy extension to NNSE(Text) and required very little additional tuning.</p><p>We also consider learning shared representa- tions in the case where data X and Y contain the effects of known disjoint features. For example, when a person reads a word, the recorded brain activation data Y will contain the physiological response to viewing the stimulus, which is unre- lated to the semantics of the word. These sig- nals can be attributed to, for example, the num- ber of letters in the word and the number of white pixels on the screen ( <ref type="bibr" target="#b31">Sudre et al., 2012</ref>). To ac- count for such effects in the data, we augment A with a set of n fixed, manually defined fea- tures (e.g. word length) to create</p><formula xml:id="formula_3">A percept ∈ R w×(+n) . D (b) ∈ R (+n)×v is used with A percept ,</formula><p>to reconstruct the brain data Y . More gener- ally, one could instead allocate a certain num- ber of latent features specific to X or Y, both of which could be learned, as explored in some re- lated work ( <ref type="bibr" target="#b11">Gupta et al., 2013</ref>). We use 11 per- ceptual features that characterize the non-semantic features of the word stimulus (for a list, see sup- plementary material at http://www.cs.cmu. edu/ ˜ afyshe/papers/acl2014/). The JNNSE algorithm is advantageous in that it can handle partially paired data. That is, the algorithm does not require that every row in X also have a row in Y . Fully paired data is a re- quirement of many other approaches ( <ref type="bibr" target="#b33">White et al., 2012;</ref><ref type="bibr" target="#b14">Jia and Darrell, 2010)</ref>. Our approach al- lows us to leverage the semantic information in corpus data even for words without brain activa- tion recordings. JNNSE(Brain+Text) does not require brain data to be mapped to a common average brain, which is often the case when one wants to generalize be- tween human subjects. Such mappings can blur and distort data, making it less useful for subse- quent prediction steps. We avoid these mappings, and instead use the fact that similar words elicit similar brain activation within a subject. In the JNNSE algorithm, it is this closeness in "brain space" that guides the creation of the latent space A. Leveraging intra-subject distance measures to study inter-subject encodings has been studied previously ( <ref type="bibr" target="#b16">Kriegeskorte et al., 2008a;</ref><ref type="bibr" target="#b26">Raizada and Connolly, 2012)</ref>, and has even been used across species (humans and primates) <ref type="bibr" target="#b17">(Kriegeskorte et al., 2008b</ref>).</p><p>Though we restrict ourselves to using one sub- ject per JNNSE(Brain+Text) model, the JNNSE algorithm could easily be extended to include data from multiple brain imaging experiments by adding a new squared loss term for additional brain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Related Work</head><p>Perhaps the most well known related approach to joining data sources is Canonical Correlation Analysis (CCA) <ref type="bibr" target="#b13">(Hotelling, 1936)</ref>, which has been applied to brain activation data in the past <ref type="bibr" target="#b27">(Rustandi et al., 2009)</ref>. CCA seeks two linear trans- formations that maximally correlate two data sets in the transformed form. CCA requires that the data sources be paired (all rows in the corpus data must have a corresponding brain data), as corre- lation between points is integral to the objective.</p><p>To apply CCA to our data we would need to dis- card the vast majority of our corpus data, and use only the 60 rows of X with corresponding rows in Y. While CCA holds the input data fixed and maximally correlates the transformed form, we hold the transformed form fixed and seek a solu- tion that maximally correlates the reconstruction (AD (c) or A D <ref type="bibr">(b)</ref> ) with the data (X and Y respec- tively). This shift in error compensation is what allows our data to be only partially paired. While a Bayesian formulation of CCA can handle miss- ing data, our model has missing data for &gt; 97% of the full w × (v + c) brain and corpus data matrix. To our knowledge, this extreme amount of missing data has not been explored with Bayesian CCA.</p><p>One could also use a topic model style formula- tion to represent this semantic representation task. Supervised topic models <ref type="bibr" target="#b1">(Blei and McAuliffe, 2007</ref>) use a latent topic to generate two observed outputs: words in a document and a categorical la- bel for the document. The same idea could be ap- plied here: the latent semantic representation gen- erates the observed brain activity and corpus statis- tics. Generative and discriminative models both have their own strengths and weaknesses, gener- ative models being particularly strong when data sources are limited ( <ref type="bibr" target="#b24">Ng and Jordan, 2002</ref>). Our task is an interesting blend of data-limited and data-rich problem scenarios.</p><p>In the past, various pieces of additional informa- tion have been incorporated into semantic models. For example, models with behavioral data <ref type="bibr" target="#b29">(Silberer and Lapata, 2012)</ref> and models with visual information <ref type="bibr" target="#b2">(Bruni et al., 2011;</ref><ref type="bibr" target="#b30">Silberer et al., 2013</ref>) have both shown to improve semantic rep- resentations. Other works have correlated VSMs built with text or images with brain activation data ( <ref type="bibr" target="#b23">Murphy et al., 2012b;</ref><ref type="bibr" target="#b0">Anderson et al., 2013</ref>). To our knowledge, this work is the first to integrate brain activation data into the construction of the VSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Corpus Data</head><p>The corpus statistics used here are the download- able vectors from <ref type="bibr" target="#b9">Fyshe et al. (2013)</ref>  <ref type="bibr">3</ref> . They are compiled from a 16 billion word subset of ClueWeb09 (Callan and Hoy, 2009) and contain two types of corpus features: dependency and doc- ument features, found to be complimentary for most tasks. Dependency statistics were derived by dependency parsing the corpus and compil- ing counts for all dependencies incident on the word. Document statistics are word-document co-occurrence counts. Count thresholding was applied to reduce noise, and positive pointwise- mutual-information (PPMI) <ref type="bibr" target="#b6">(Church and Hanks, 1990</ref>) was applied to the counts. SVD was ap- plied to the document and dependency statistics and the top 1000 dimensions of each type were retained. We selected the rows corresponding to noun-tagged words (approx. 17000 words).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Brain Activation Data</head><p>We have MEG and fMRI data at our disposal. MEG measures the magnetic field caused by many thousands of neurons firing together, and has good time resolution (1000 Hz) but poor spatial reso- lution. fMRI measures the change in blood oxy- genation that results from differential neural ac- tivity, and has good spatial resolution but poor time resolution (0.5-1 Hz). We have fMRI data and MEG data for 18 subjects (9 in each imaging modality) viewing 60 concrete nouns ( <ref type="bibr" target="#b21">Mitchell et al., 2008;</ref><ref type="bibr" target="#b31">Sudre et al., 2012</ref>). The 60 words span 12 word categories (animals, buildings, tools, in- sects, body parts, furniture, building parts, uten- sils, vehicles, objects, clothing, food). Each of the 60 words was presented with a line drawing, so word ambiguity is not an issue. For both record- ing modalities, all trials for a particular word were averaged together to create one training instance per word, with 60 training instances in all for each subject and imaging modality. More preprocess- ing details appear in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>Here we explore several variations of JNNSE and NNSE formulations. For a comparison of the models used, see <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Correlation to Behavioral Data</head><p>To test if our joint model of Brain+Text is closer to semantic ground truth we compared the latent representation A learned via JNNSE(Brain+Text) or NNSE(Text) to an independent behavioral mea- sure of semantics. We collected behavioral data for the 60 nouns in the form of answers to 218 semantic questions. Answers were gathered with Mechanical Turk. The full list of questions ap- pear in the supplementary material. Some exam- ple questions are:"Is it alive?", and "Can it bend?". Mechanical Turk users were asked to respond to each question for each word on a scale of 1-5. At least 3 respondents answered each question and the median score was used. This gives us a se- mantic representation of each of the 60 words in a 218-dimensional behavioral space. Because we required answers to each of the questions for all words, we do not have the problems of sparsity that exist for feature production norms from other studies ( <ref type="bibr" target="#b20">McRae et al., 2005</ref>). In addition, our an- swers are ratings, rather than binary yes/no an- swers.</p><p>For a given value of we solve the NNSE(Text) and JNNSE(Brain+Text) objective function as de- tailed in Equation 1 and 4 respectively. We com- pared JNNSE(Brain+Text) and NNSE(Text) mod- els by measuring the correlation of all pairwise distances in JNNSE(Brain+Text) and NNSE(Text) space to the pairwise distances in the 218- dimensional semantic space. Distances were calculated using normalized Euclidean distance (equivalent in rank-ordering to cosine distance, but more suitable for sparse vectors). <ref type="figure" target="#fig_0">Figure 1</ref> shows the results of this correlation test. The er- ror bars for the JNNSE(Brain+Text) models rep- resent a 95% confidence interval calculated using the standard error of the mean (SEM) over the 9 person-specific JNNSE(Brain+Text) models. Be- cause there is only one NNSE(Text) model for each dimension setting, no SEM can be calculated, but it suffices to show that the NNSE(Text) corre- lation does not fall into the 95% confidence inter- val of the JNNSE(Brain+Text) models. The SVD matrix for the original corpus data has correlation 0.4279 to the behavioral data, also below the 95% confidence interval for all JNNSE models. The re- sults show that a model that incorporates brain ac- tivation data is more faithful to a behavioral mea- sure of semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Word Prediction from Brain Activation</head><p>We now show that the JNNSE(Brain+Text) vec- tors are more consistent with independent sam- ples of brain activity collected from different sub- jects, even when recorded using different record- ing technologies. As previously mentioned, be- cause there is a large degree of variation between brains and because MEG and fMRI measure very different correlates of neuronal activity, this type of generalization has proven to be very challeng- ing and is an open research question in the neuro- science community.</p><p>The output A of the JNNSE(Brain+Text) or <ref type="table">Table 1</ref>: A Comparison of the models explored in this paper, and the data upon which they operate. NNSE(Text) algorithm can be used as a VSM, which we use for the task of word prediction from fMRI or MEG recordings. A JNNSE(Brain+Text) created with a particular human subject's data is never used in the prediction framework with that same subject. For example, if we use fMRI data from subject 1 to create a JNNSE(fMRI+Text), we will test it with the remaining 8 fMRI subjects, but all 9 MEG subjects (fMRI and MEG subjects are disjoint).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Name Section(s) Text Data Brain Data Withheld Data NNSE(Text) 2, 5 x - NNSE(Brain) 2, 5.2.1, 5.3 x - JNNSE(Brain+Text) 3, 5 - JNNSE(Brain+Text): Dropout task 5.2.2 subset of brain data JNNSE(Brain+Text): Predict corpus 5.3 subset of text data</head><p>Let us call the VSM learned with JNNSE(Brain+Text) or NNSE(Text) the se- mantic vectors. We can train a weight matrix W that predicts the semantic vector a of a word from that word's brain activation vector x: a = W x. W can be learned with a variety of methods, we will use L 2 regularized regression. One can also train regressors that predict the brain activation data from the semantic vector: x = W a, but we have found this to give lower predictive accuracy. Note that we must re-train our weight matrix W for each subject (instead of re-using D (b) from Equation 4) because testing always occurs on a different subject, and the brain activation data is not inter-subject aligned.</p><p>We train independent L 2 regularized regres- sors to predict the -dimensional vectors a = {a 1 . . . a }. The predictions are concatenated to produce a predicted semantic vector: ˆ a = {â 1 , . . . , ˆ a }. We assess word prediction perfor- mance by testing if the model can differentiate be- tween two unseen words, a task named 2 vs. 2 pre- diction ( <ref type="bibr" target="#b21">Mitchell et al., 2008;</ref><ref type="bibr" target="#b31">Sudre et al., 2012)</ref>. We choose the assignment of the two held out se- mantic vectors (a (1) , a (2) ) to predicted semantic vectors (ˆ a (1) , ˆ a <ref type="bibr">(2)</ref> ) that minimizes the sum of the two normalized Euclidean distances. 2 vs. 2 ac- curacy is the percentage of tests where the correct assignment is chosen.</p><p>The 60 nouns fall into 12 word categories. Words in the same word category (e.g. screw- driver and hammer) are closer in semantic space than words in different word categories, which makes some 2 vs. 2 tests more difficult than oth- ers. We choose 150 random pairs of words (with each word represented equally) to estimate the dif- ficulty of a typical word pair, without having to test all 60 2 word pairs. The same 150 random pairs are used for all subjects and all VSMs. Ex- pected chance performance on the 2 vs. 2 test is 50%.</p><p>Results for testing on fMRI data in the 2 vs. 2 framework appear in <ref type="figure">Figure 2</ref>. JNNSE(fMRI+Text) data performed on aver- age 6% better than the best NNSE(Text), and exceeding even the original SVD corpus represen- tations while maintaining interpretability. These results generalize across brain activity recording types; JNNSE(MEG+Text) performs as well as JNNSE(fMRI+Text) when tested on fMRI data. The results are consistent when testing on MEG data: JNNSE(MEG+Text) or JNNSE(fMRI+Text) outperforms NNSE(Text) (see <ref type="figure">Figure 3)</ref>  <ref type="figure">Figure 3</ref>: Average 2 vs. 2 accuracy for NNSE(Text) and JNNSE(Brain+Text), tested on MEG data. Models created with one subject's MEG data were not used to compute 2 vs. 2 ac- curacy for that same subject.</p><p>NNSE(Text) performance decreases as the number of latent dimension increases. This im- plies that without the regularizing effect of brain activation data, the extra NNSE(Text) dimensions are being used to overfit to the corpus data, or possibly to fit semantic properties not detectable with current brain imaging technologies. How- ever, when brain activation data is included, in- creasing the number of latent dimensions strictly increases performance for JNNSE(fMRI+Text). JNNSE(MEG+Text) has peak performance with 500 latent dimensions, with ∼ 1% decrease in performance at 1000 latent dimensions. In previ- ous work, the ability to decode words from brain activation data was found to improve with added latent dimensions ( <ref type="bibr" target="#b22">Murphy et al., 2012a</ref>). Our results may differ because our words are POS tagged, and we included only nouns for the final NNSE(Text) model. We found that with the orig- inal λ = 0.05 setting from Murphy et al. (Mur- phy et al., 2012a) produced vectors that were too sparse; four of the 60 test words had all-zero vec- tors (JNNSE(Brain+Text) models did have any all- zero vectors). To improve the NNSE(Text) vectors for a fair comparison, we reduced λ = 0.025, un- der which NNSE(Text) did not produce any all- zero vectors for the 60 words.</p><p>Our results show that brain activation data con- tributes additional information, which leads to an increase in performance for the task of word pre- diction from brain activation data. This suggests that corpus-only models may not capture all rel- evant semantic information. This conflicts with previous studies which found that semantic vec- tors culled from corpus statistics contain all of the semantic information required to predict brain ac- tivation (Bullinaria and Levy, 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Prediction from a Brain-only Model</head><p>How much predictive power does the corpus data provide to this word prediction task? To test this, we calculated the 2 vs. 2 accuracy for a NNSE(Brain) model trained on brain activation data only. We train NNSE(Brain) with one sub- ject's data and use the resulting vectors to calculate 2 vs. 2 accuracy for the remaining subjects. We have brain data for only 60 words, so using ≥ 60 latent dimensions leads to an under-constrained system and a degenerate solution wherein only one latent dimension is active for any word (and where the brain data can be perfectly reconstructed). The degenerate solution makes it impossible to gen- eralize across words and leads to performance at chance levels. An NNSE(MEG) trained on MEG data gave maximum 2 vs. 2 accuracy of 67% when = 20. The reduced performance may be due to the limited training data and the low SNR of the data, but could also be attributed to the lack of cor- pus information, which provides another piece of semantic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Effect on Rows Without Brain Data</head><p>It is possible that some JNNSE(Brain+Text) di- mensions are being used exclusively to fit brain activation data, and not the semantics represented in both brain and corpus data. If a particular dimension j is solely used for brain data, the sparsity constraint will favor solutions that sets A (i,j) = 0 for i &gt; w (no brain data constraint), and A (i,j) &gt; 0 for some 0 ≤ i ≤ w (brain data constrained). We found that there were no such dimensions in the JNNSE(Brain+Text). In fact for the = 1000 JNNSE(Brain+Text), all latent di- mensions had greater than ∼ 25% non-zero en- tries, which implies that all dimensions are being shared between the two data inputs (corpus and brain activation), and are used to reconstruct both.</p><p>To test that the brain activation data is truly in- fluencing rows of A not constrained by brain acti- vation data, we performed a dropout test. We split the original 60 words into two 30 word groups (as evenly as possible across word categories). We trained JNNSE(fMRI+Text) with 30 words, and tested word prediction with the remaining 8 sub- jects and the other 30 words. Thus, the training and testing word sets are disjoint. Because of the reduced size of the training data, we did see a drop in performance, but JNNSE(fMRI+Text) vectors still gave word prediction performance 7% higher than NNSE(Text) vectors. Full results appear in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Predicting Corpus Data</head><p>Here we ask: can an accurate latent representa- tion of a word be constructed using only brain activation data? This task simulates the scenario where there is no reliable corpus representation of a word, but brain data is available. This scenario may occur for seldom-used words that fall below the thresholds used for the compilation of corpus statistics. It could also be useful for acronym to- kens (lol, omg) found in social media contexts where the meaning of the token is actually a full sentence.</p><p>We trained a JNNSE(fMRI+Text) with brain data for all 60 words, but withhold the corpus data for 30 of the 60 words (as evenly distributed as possible amongst the 12 word categories). The brain activation data for the 30 withheld words will allow us to create latent representations in A for withheld words. Simultaneously, we will learn a mapping from the latent representation to the corpus data <ref type="bibr">(D (c)</ref> ). This task cannot be per- <ref type="table">Table 2</ref>: Mean rank accuracy over 30 words using corpus representations predicted by a JNNSE(MEG+Text) model trained with some rows of the corpus data withheld. Significance is calculated using Fisher's method to combine p- values for each of the subject-dependent models. formed with a NNSE(Text) model because one cannot learn a latent representation of a word with- out data of some kind. This further emphasizes the impact of brain imaging data, which will allow us to generalize to previously unseen words in corpus space.</p><p>We use the latent representations in A for each of the words without corpus data and the mapping to corpus space D (c) to predict the withheld cor- pus data in X. We then rank the withheld rows of X by their distance to the predicted row of X and calculate the mean rank accuracy of the held out words. Results in <ref type="table">Table 2</ref> show that we can recre- ate the withheld corpus data using brain activation data. Peak mean rank accuracy (67.37) is attained at = 500 latent dimensions. This result shows that neural semantic representations can create a latent representation that is faithful to unseen cor- pus statistics, providing further evidence that the two data sources share a strong common element.</p><p>How much power is the remaining corpus data supplying in scenarios where we withhold cor- pus data? To answer this question, we trained an NNSE(Brain) model on 30 words of brain activa- tion, and then trained a regressor to predict cor- pus data from those latent brain-only representa- tions. We use the trained regressor to predict the corpus data for the remaining 30 words. Peak per- formance is attained at = 10 latent dimensions, giving mean rank accuracy of 62.37, significantly worse than the model that includes both corpus and brain activation data (67.37).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Mapping Semantics onto the Brain</head><p>Because our method incorporates brain data into an interpretable semantic model, we can directly map semantic concepts onto the brain. To do this, we examined the mappings from the latent space to the brain space via D <ref type="bibr">(b)</ref> . We found that the most interpretable mappings come from mod-  ) from latent se- mantic space (A) to brain space (Y ) for fMRI and words from three semantic categories. Shown are representations of the fMRI slices such that the back of the head is at the top of the image, the front of the head is at the bottom. els where the perceptual features had been scaled down (divided by a constant factor), which en- courages more of the data to be explained by the semantic features in A. <ref type="figure" target="#fig_2">Figure 4</ref> shows the mappings (D <ref type="bibr">(b)</ref> ) for dimensions related to shel- ter, food and body parts. The red areas align with areas of the brain previously known to be activated by the corresponding concepts ( <ref type="bibr" target="#b21">Mitchell et al., 2008;</ref><ref type="bibr" target="#b15">Just et al., 2010)</ref>. Our model has learned these mappings in an unsupervised setting by relating semantic knowledge gleaned from word usage to patterns of activation in the brain. This illustrates how the interpretability of JNNSE can allow one to explore semantics in the human brain. The mappings for one subject are available for download (http://www.cs. cmu.edu/ ˜ afyshe/papers/acl2014/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Future Work and Conclusion</head><p>We are interested in pursuing many future projects inspired by the success of this model. We would like to extend the JNNSE algorithm to incorporate data from multiple subjects, multiple modalities and multiple experiments with non-overlapping words. Including behavioral data and image data is another possibility.</p><p>We have explored a model of semantics that in- corporates text and brain activation data. Though the number of words for which we have brain acti- vation data is comparatively small, we have shown that including even this small amount of data has a positive impact on the learned latent representa- tions, including for words without brain data. We have provided evidence that the latent representa- tions are closer to the neural representation of se- mantics, and possibly, closer to semantic ground truth. Our results reveal that there are aspects of semantics not currently represented in text-based VSMs, indicating that there may be room for im- provement in either the data or algorithms used to create VSMs. Our findings also indicate that using the brain as a semantic test can separate models that capture this additional semantic information from those that do not. Thus, the brain is an im- portant source of both training and testing data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Correlation of JNNSE(Brain+Text) and NNSE(Text) models with the distances in a semantic space constructed from behavioral data. Error bars indicate SEM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>!</head><label></label><figDesc>"#$%&amp;'() (a) D (b) matrix, subject P3, dimension with top words bath- room, balcony, kitchen. MNI coordinates z=-12 (left) and z=-18 (right). Fusiform is associated with shelter words. !"#$%&amp;'$()*+ !(&amp;%&amp;'$()*+ (b) D (b) matrix; subject P1; dimension with top words ankle, elbow, knee. MNI coordinates z=60 (left) and z=54 (right). Pre- and post-central areas are activated for body part words. !"#$% &amp;'(#)*+"#,$% (c) D (b) matrix; subject P1; dimension with top scoring words buffet, brunch, lunch. MNI coordinates z=30 (left) and z=24 (right). Pars opercularis is believed to be part of the gustatory cortex, which responds to food related words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The mappings (D (b) ) from latent semantic space (A) to brain space (Y ) for fMRI and words from three semantic categories. Shown are representations of the fMRI slices such that the back of the head is at the top of the image, the front of the head is at the bottom.</figDesc><graphic url="image-3.png" coords="9,72.89,332.29,161.71,94.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>.</head><label></label><figDesc></figDesc><table>494 

250 

500 
1000 

64 

66 

68 

70 

72 

74 

Number of Latent Dimensions 

2 vs. 2 Accuracy 

2 vs. 2 Acc. for JNNSE and NNSE, tested on fMRI data 

JNNSE(fMRI+Text) 
JNNSE(MEG+Text) 
NNSE(Text) 
SVD(Text) 

Figure 2: Average 2 vs. 2 accuracy for 
NNSE(Text) and JNNSE(Brain+Text), tested on 
fMRI data. Models created with one subject's 
fMRI data were not used to compute 2 vs. 2 ac-
curacy for that same subject. 

250 
500 
1000 

66 

68 

70 

72 

74 

76 

78 

80 

82 

Number of Latent Dimensions 

2 vs. 2 Accuracy 

2 vs. 2 Acc. for JNNSE and NNSE, tested on MEG data 

JNNSE(fMRI+Text) 
JNNSE(MEG+Text) 
NNSE(Text) 
SVD(Text) 

</table></figure>

			<note place="foot" n="1"> For more details on fMRI and MEG, see Section 4.2</note>

			<note place="foot" n="2"> SPAMS Package: http://spams-devel.gforge.inria.fr/</note>

			<note place="foot" n="3"> http://www.cs.cmu.edu/ ˜ afyshe/papers/ conll2013/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by NIH un-der award 5R01HD075328-02, by DARPA under award FA8750-13-2-0005, and by a fellowship to Alona Fyshe from the Multimodal Neuroimag-ing Training Program funded by NIH awards T90DA022761 and R90DA023420.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Of words , eyes and brains : Correlating image-based distributional semantic models with neural representations of concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Andrew J Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulisse</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Bordignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods on Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Supervised topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcauliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributional semantics from text and images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Giang Binh Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP 2011 Geometrical Models for Natural Language Semantics (GEMS)</title>
		<meeting>the EMNLP 2011 Geometrical Models for Natural Language Semantics (GEMS)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Limiting factors for mapping corpus-based semantic representations to brain activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph P</forename><surname>Bullinaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">57191</biblScope>
			<date type="published" when="2013-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The ClueWeb09 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reading Tea Leaves : How Humans Interpret Topic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inter-subject alignment of human cortical anatomy using functional connectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bryan R Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swaroop Guntupalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James V</forename><surname>Peter J Ramadge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haxby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="400" to="411" />
			<date type="published" when="2013-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The fMRI BOLD signal tracks electrophysiological spectral perturbations, not eventrelated potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Andrew D Engell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Huettel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2600" to="2606" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Documents and Dependencies : an Exploration of Vector Space Models for Semantic Composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Symbol Grounding and Meaning: A Comparison of High-Dimensional and Embodied Theories of Meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David A Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="401" />
			<date type="published" when="2000-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Regularized nonnegative shared subspace learning. Data Mining and Knowledge Discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Sunil Kumar Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Phung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetha</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venkatesh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="57" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The relationship between MEG and fMRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Emma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siân E Robson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<date type="published" when="2013-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relations between two sets of variates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harold</forename><surname>Hotelling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="321" to="377" />
			<date type="published" when="1936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Factorized Latent Spaces with Structured Sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A neurosemantic theory of concrete noun representation based on the underlying brain codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Adam Just</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandesh</forename><surname>Cherkassky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Aryal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">8622</biblScope>
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Representational similarity analysis-connecting the branches of systems neuroscience. Frontiers in systems neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bandettini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-11" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Matching Categorical Object Representations in Inferior Temporal Cortex of Man and Monkey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Douglas A Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerzy</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Bodurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keiji</forename><surname>Esteky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter A</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bandettin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1126" to="1141" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="240" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Online learning for matrix factorization and sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="19" to="60" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic feature production norms for a large set of living and nonliving things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Mcrae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George S Cree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Seidenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcnorgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior research methods</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="547" to="59" />
			<date type="published" when="2005-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predicting human brain activity associated with the meanings of nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><forename type="middle">V</forename><surname>Tom M Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Shinkareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Min</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Adam</forename><surname>Robert A Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Just</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">5880</biblScope>
			<biblScope unit="page" from="1191" to="1196" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning Effective and Interpretable Semantic Models using Non-Negative Sparse Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Computational Linguistics (COLING)</title>
		<meeting>Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Selecting Corpus-Semantic Models for Neurolinguistic Decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="114" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Zero-Shot Learning with Semantic Output Codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1410" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What Makes Different People&apos;s Representations Alike : Neural Similarity Space Solves the Problem of Across-subject fMRI Decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D S</forename><surname>Rajeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew C</forename><surname>Raizada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Connolly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="868" to="877" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Integrating Multiple-Study Multiple-Subject fMRI Datasets Using Canonical Correlation Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><forename type="middle">Adam</forename><surname>Indrayana Rustandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2009 Workshop: Statistical modeling and detection issues in intraand inter-subject functional MRI data analysis</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Word-Space Model Using distributional analysis to represent syntagmatic and paradigmatic relations between words. Doctor of philosophy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Sahlgren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Stockholm University</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Grounded models of semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1423" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Models of Semantic Representation with Visual Attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Tracking Neural Coding of Perceptual and Semantic Features of Concrete Nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Sudre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dean</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Palatucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leila</forename><surname>Wehbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alona</forename><surname>Fyshe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riitta</forename><surname>Salmelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="463" to="451" />
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">From Frequency to Meaning : Vector Space Models of Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pantel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="141" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Convex multi-view subspace learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhua</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
