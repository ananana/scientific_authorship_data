<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Bao</surname></persName>
							<email>baojunwei001@gmail.com ‡ § {nanduan, peche, mingzhou}@microsoft.com ¶ zhoujs@cnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshe</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">¶</forename></persName>
							<affiliation key="aff0">
								<orgName type="department">Microsoft Search Technology Center ¶ BAICIT</orgName>
								<orgName type="laboratory">State Key Laboratory of Software Development Environment</orgName>
								<orgName type="institution" key="instit1">Beihang University ‡ Microsoft Research + Harbin Institute of Technology</orgName>
								<orgName type="institution" key="instit2">Capital Normal University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DocChat: An Information Retrieval Approach for Chatbot Engines Using Unstructured Documents</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="516" to="525"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most current chatbot engines are designed to reply to user utterances based on existing utterance-response (or Q-R) 1 pairs. In this paper, we present DocChat, a novel information retrieval approach for chat-bot engines that can leverage unstructured documents, instead of Q-R pairs, to respond to utterances. A learning to rank model with features designed at different levels of granularity is proposed to measure the relevance between utterances and responses directly. We evaluate our proposed approach in both English and Chi-nese: (i) For English, we evaluate Doc-Chat on WikiQA and QASent, two answer sentence selection tasks, and compare it with state-of-the-art methods. Reasonable improvements and good adaptability are observed. (ii) For Chinese, we compare DocChat with XiaoIce 2 , a famous chitchat engine in China, and side-by-side evaluation shows that DocChat is a perfect complement for chatbot engines using Q-R pairs as main source of responses.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Building chatbot engines that can interact with hu- mans with natural language is one of the most challenging problems in artificial intelligence. Along with the explosive growth of social media, like community question answering (CQA) web- sites (e.g., Yahoo Answers and WikiAnswers) and social media websites (e.g., Twitter and Weibo), * Contribution during internship at Microsoft Research. <ref type="bibr">1</ref> For convenience sake, we denote all utterance-response pairs (either QA pairs or conversational exchanges from so- cial media websites like Twitter) as Q-R pairs in this paper. <ref type="bibr">2</ref> http://www.msxiaoice.com the amount of utterance-response (or Q-R) pairs has experienced massive growth in recent years, and such a corpus greatly promotes the emergence of various data-driven chatbot approaches.</p><p>Instead of multiple rounds of conversation, we only consider a much simplified task, short text conversation (STC) in which the response R is a short text and only depends on the last user utter- ance Q. Previous methods for the STC task mostly rely on Q-R pairs and fall into two categories: Retrieval-based methods (e.g., <ref type="bibr" target="#b5">Ji et al., 2014)</ref>. This type of methods first retrieve the most pos- siblê Q, ˆ RR pair from a set of existing Q-R pairs, which best matches current utterance Q based on semantic matching models, then takê R as the re- sponse R. One disadvantage of such a method is that, for many specific domains, collecting such Q- R pairs is intractable. Generation based methods (e.g., <ref type="bibr" target="#b16">Shang et al., 2015)</ref>. This type of meth- ods usually uses an encoder-decoder framework which first encode Q as a vector representation, then feed this representation to decoder to gener- ate response R. Similar to retrieval-based meth- ods, such approaches also depend on existing Q-R pairs as training data. Like other language genera- tion tasks, such as machine translation and para- phrasing, the fluency and naturality of machine generated text is another drawback.</p><p>To overcome the issues mentioned above, we present a novel response retrieval approach, DocChat, to find responses based on unstruc- tured documents. For each user utterance, instead of looking for the best Q-R pair or generating a word sequence based on language generation tech- niques, our method selects a sentence from given documents directly, by ranking all possible sen- tences based on features designed at different lev- els of granularity. On one hand, using documents rather than Q-R pairs greatly improve the adapt-ability of chatbot engines on different chatting top- ics. On the other hand, all responses come from existing documents, which guarantees their fluen- cy and naturality. We also show promising results in experiments, on both QA and chatbot scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>Formally, given an utterance Q and a document set D, the document-based chatbot engine retrieves response R based on the following three steps:</p><p>• response retrieval, which retrieves response candidates C from D based on Q:</p><formula xml:id="formula_0">C = Retrieve(Q, D)</formula><p>Each S ∈ C is a sentence existing in D.</p><p>• response ranking, which ranks all response candidates in C and selects the most possible response candidate asˆSasˆ asˆS:</p><formula xml:id="formula_1">ˆ S = arg max S∈C Rank(S, Q)</formula><p>• response triggering, which decides whether it is confident enough to response Q usingˆSusingˆ usingˆS:</p><formula xml:id="formula_2">I = T rigger( ˆ S, Q)</formula><p>where I is a binary value. When I equals to true, let the response R = ˆ S and output R; otherwise, output nothing.</p><p>In the following three sections, we will describe solutions of these three components one by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Response Retrieval</head><p>Given a user utterance Q, the goal of response re- trieval is to efficiently find a small number of sen- tences from D, which have high possibility to con- tain suitable sentences as Q's response. Although it is not necessarily true that a good response always shares more words with a given utterance, this measurement is still helpful in finding possi- ble response candidates ( <ref type="bibr" target="#b5">Ji et al., 2014)</ref>.</p><p>In this paper, the BM25 term weighting formu- las ( <ref type="bibr" target="#b6">Jones et al., 2000</ref>) is used to retrieve response candidates from documents. Given each docu- ment D k ∈ D, we collect a set of sentence triples S prev , S, S next from D k , where S denotes a sen- tence in D k , S prev and S next denote S's previous sentence and next sentence respectively. Two spe- cial tags, BOD and EOD, are added at the beginning and end of each passage, to make sure that such sentence triples can be extracted for ev- ery sentence in the document. The reason for in- dexing each sentence together with its context sen- tences is intuitive: If a sentence within a document can respond to an utterance, then its context should be revelent to the utterance as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Response Ranking</head><p>Given a user utterance Q and a response candidate S, the ranking function Rank(S, Q) is designed as an ensemble of individual matching features:</p><formula xml:id="formula_3">Rank(S, Q) = k λ k · h k (S, Q)</formula><p>where h k (·) denotes the k-th feature function, λ k denotes h k (·)'s corresponding weight.</p><p>We design features at different levels of gran- ularity to measure the relevance between S and Q, including word-level, phrase-level, sentence- level, document-level, relation-level, type-level and topic-level, which will be introduced below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word-level Feature</head><p>We define three word-level features in this work: (1) h W M (S, Q) denotes a word matching feature that counts the number (weighted by the IDF val- ue of each word in S) of non-stopwords shared by S and Q. (2) h W 2W (S, Q) denotes a word-to- word translation-based feature that calculates the IBM model 1 score <ref type="bibr" target="#b2">(Brown et al., 1993</ref>) of S and Q based on word alignments trained on 'question- related question' pairs using GIZA++ <ref type="bibr" target="#b12">(Och and Ney, 2003)</ref>. <ref type="formula">(3)</ref> h W 2V (S, Q) denotes a word embedding-based feature that calculates the aver- age cosine distance between word embeddings of all non-stopword pairs v S j , v Q i . v S j represent the word vector of j th word in S and v Q j repre- sent the word vector of i th word in Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Phrase-level Feature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Paraphrase</head><p>We first describe how to extract phrase-level para- phrases from an existing SMT (statistical machine translation) phrase table.</p><p>P T = {{s i , t i , p(t i |s i ), p(s i |t i )} 3 is a phrase table, which is extracted from a bilingual cor- pus, where s i (or t i ) denotes a phrase, in source (or target) language, p(t i |s i ) (or p(s i |t i )) de- notes the translation probability from s i (or t i ) to t i (or s i ). We follow <ref type="bibr">Bannard and CallisonBurch (2005)</ref> to extract a paraphrase table P P = {{s i , s j , score(s j ; s i )}. s i and s j denote two phrases in source language, score(s j ; s i ) denotes a confidence score that s i can be paraphrased to s j , which is computed based on P T :</p><formula xml:id="formula_4">score(s j ; s i ) = t {p(t|s i ) · p(s j |t)}</formula><p>The underlying idea of this approach is that, two source phrases that are aligned to the same target phrase trend to be paraphrased.</p><p>We then define a paraphrase-based feature as:</p><formula xml:id="formula_5">h P P (S, Q) = N n=1 |S|−n j=0 Count P P (S j+n−1 j ,Q) |S|−n+1</formula><p>N where S j+n−1 j denotes the consecutive word se- quence (or phrase) in S, which starts from S j and ends with S j+n−1 , N denotes the maximum n-gram order (here is 3).</p><formula xml:id="formula_6">Count P P (S j+n−1 j , Q)</formula><p>is computed based on the following rules: • Else, CountP P (S j+n−1 j , Q) = 0.</p><formula xml:id="formula_7">• If S j+n−1 j ∈ Q, then CountP P (S j+n−1 j , Q) = 1;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Phrase-to-Phrase Translation</head><p>Similar to h P P (S, Q), a phrase translation-based feature based on a phrase table P T is defined as:</p><formula xml:id="formula_8">h P T (S, Q) = N n=1 |S|−n j=0 Count P T (S j+n−1 j ,Q) |S|−n+1 N where Count P T (S j+n−1 j , Q)</formula><p>is computed based on the following rules:</p><formula xml:id="formula_9">• If S j+n−1 j ∈ Q, then CountP T (S j+n−1 j , Q) = 1; • Else, if S j+n−1 j , s, p(S j+n−1 j |s), p(s|S j+n−1 j ) ∈ P T and S j+n−1 j 's translation s ∈ Q, then CountP T (S j+n−1 j , Q) = p(S j+n−1 j |s) · p(s|S j+n−1 j ) • Else, CountP T (S j+n−1 j , Q) = 0</formula><p>We train a phrase table based on 'question-answer' pairs crawled from community QA websites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sentence-level Feature</head><p>We first present an attention-based sentence em- bedding method based on a convolution neural network (CNN), whose input is a sentence pair and output is a sentence embedding pair. Two fea- tures will be introduced in Section 4.3.1 and 4.3.2, which are designed based on two sentence embed- ding models trained using different types of data.</p><p>In the input layer, given a sentence pair S X , S Y , an attention matrix A ∈ R |S X |×|S Y | is generated based on pre-trained word embeddings of S X and S Y , where each element A i,j ∈ A is computed as:</p><formula xml:id="formula_10">A i,j = cosine(v S X i , v S Y j )</formula><p>where</p><formula xml:id="formula_11">v S X i (or v S Y j</formula><p>) denotes the embedding vector of the i th (or j th ) word in S X (or S Y ).</p><p>Then, column-wise and row-wise max-pooling are applied to A to generate two attention vectors</p><formula xml:id="formula_12">V S X ∈ R |S X | and V S Y ∈ R |S Y | ,</formula><p>where the k th elements of V S X and V S Y are computed as:</p><formula xml:id="formula_13">V S X k = max 1&lt;l&lt;|S Y | {A k,l } and V S Y k = max 1&lt;l&lt;|S X | {A l,k } V S X k (or V S Y k )</formula><p>can be interpreted as the attention score of the k th word in S X (or S Y ) with regard to all words in S Y (or S X ).</p><p>Next, two attention distributions D S X ∈ R |S X | and D S Y ∈ R |S Y | are generated for S X and S Y based on V S X and V S Y respectively, where the k th elements of D S X and D S Y are computed as:</p><formula xml:id="formula_14">D S X k = e V S X k |S X | l=1 e V S X l and D S Y k = e V S Y k |S Y | l=1 e V S Y l D S X k (or D S Y k )</formula><p>can be interpreted as the normal- ized attention score of the k th word in S X (or S Y ) with regard to all words in S Y (or S X ).</p><p>Last, we update each pre-trained word embed-</p><formula xml:id="formula_15">ding v S X k (or v S Y k ) tô v S X k (orˆvorˆ orˆv S Y k ), by multiplying every value in v S X k (or v S Y k ) with D S X k (or D S Y k ).</formula><p>The underlying intuition of updating pre-trained word embeddings is to re-weight the importance of each word in S X (or S Y ) based on S Y (or S X ), instead of treating them in an equal manner.</p><p>In the convolution layer, we first derive an in- put matrix Z S X = {l 1 , ..., l |S X | }, where l t is the concatenation of a sequence of</p><formula xml:id="formula_16">m = 2d−1 4 updat- ed word embeddings [ˆ v S X t−d , ..., ˆ v S X t , ..., ˆ v S X t+d ]</formula><p>, cen- tralized in the t th word in S X . Then, the convo-lution layer performs sliding window-based fea- ture extraction to project each vector representa- tion l t ∈ Z S X to a contextual feature vector h S X t :</p><formula xml:id="formula_17">h S X t = tanh(W c · l t )</formula><p>where W c is the convolution matrix, tanh(x) =</p><formula xml:id="formula_18">1−e −2x</formula><p>1+e −2x is the activation function. The same oper- ation is performed to S Y as well.</p><p>In the pooling layer, we aggregate local fea- tures extracted by the convolution layer from S X , and form a sentence-level global feature vector with a fixed size independent of the length of the input sentence. Here, max-pooling is used to force the network to retain the most useful local features by</p><formula xml:id="formula_19">l S X p = [v S X 1 , ..., v S X K ]</formula><p>, where:</p><formula xml:id="formula_20">v S X i = max t=1,...,|S X | {h S X t (i)} h S X t (i)</formula><p>denotes the i th value in the vector h S X t . The same operation are performed to S Y as well.</p><p>In the output layer, one more non-linear trans- formation is applied to l S X p :</p><formula xml:id="formula_21">y(S X ) = tanh(W s · l S X p )</formula><p>W s is the semantic projection matrix, y(S X ) is the final sentence embedding of S X . The same opera- tion is performed to S Y to obtain y(S Y ). We train model parameters W c and W s by min- imizing the following ranking loss function:</p><formula xml:id="formula_22">L = max{0, M − cosine(y(S X ), y(S Y )) +cosine(y(S X ), y(S − Y ))}</formula><p>where M is a constant, S − Y is a negative instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Causality Relationship Modeling</head><p>We train the first attention-based sentence embed- ding model based on a set of 'question-answer' pairs as input sentence pairs, and then design a causality relationship-based feature as:</p><formula xml:id="formula_23">h SCR (S, Q) = cosine(y SCR (S), y SCR (Q))</formula><p>y SCR (S) and y SCR (Q) denote the sentence em- beddings of S and Q respectively. We expect this feature captures the causality relationship be- tween questions and their corresponding answers, and works on question-like utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Discourse Relationship Modeling</head><p>We train the second attention-based sentence em- bedding model based on a set of 'sentence-next sentence' pairs as input sentence pairs, and then design a discourse relationship-based feature as:</p><formula xml:id="formula_24">h SDR (S, Q) = cosine(y SDR (S), y SDR (Q))</formula><p>y SDR (S) and y SDR (Q) denote the sentence em- beddings of S and Q respectively. We expect this feature learns and captures the discourse relation- ship between sentences and their next sentences, and works on statement-like utterances. Here, a large number of 'sentence-next sentence' pairs can be easily obtained from documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Document-level Feature</head><p>We take document-level information into consid- eration to measure the semantic similarity between Q and S, and define two context features as:</p><formula xml:id="formula_25">h DM (S * , Q) = cosine(y SCR (S * ), y SCR (Q))</formula><p>where S * can be S prev and S next that denote previous and next sentences of S in the original document. The sentence embedding model trained based on 'question-answer' pairs (in Section 4.3.1) is directly used to generate context embed- dings for h DM (S prev , Q) and h DM (S next , Q). So no further training data is needed for this feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Relation-level Feature</head><p>Given a structured knowledge base, such as Free- base <ref type="bibr">5</ref> , a single relation question Q (in natural language) with its answer can be first parsed into a fact formatted as e sbj , rel, e obj , where e sbj denotes a subject entity detected from the question, rel denotes the relationship expressed by the question, e obj denotes an object entity found from the knowledge base based on e sbj and rel. Then we can get Q, rel pairs. This rel can help for modeling semantic relationships between Q and R. For example, the Q-A pair What does Jimmy Neutron do? − inventor can be parsed into Jimmy Neutron, fiction- al character occupation, inventor where the rel is fictional character occupation.</p><p>Similar to <ref type="bibr" target="#b23">Yih et al. (2014)</ref>, We use Q, rel pairs as training data, and learn a rel-CNN mod- el, which can encode each question Q (or each re- lation rel) into a relation embedding. For a giv- en question Q, the corresponding relation rel + is treated as a positive example, and randomly select- ed other relations are used as negative examples rel − . The posterior probability of rel + given Q is computed as:</p><formula xml:id="formula_26">P (rel + |Q) = e cosine(y(rel + ),y(Q))</formula><p>rel − e cosine(y(rel − ),y(Q)) y(rel) and y(Q) denote relation embeddings of rel and Q based on rel-CNN. rel-CNN is trained by maximizing the log-posterior.</p><p>We then define a relation-based feature as:</p><formula xml:id="formula_27">h RE (S, Q) = cosine(y RE (Q), y RE (S))</formula><p>y RE (S) and y RE (Q) denote relation embeddings of S and Q respectively, coming from rel-CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Type-level Feature</head><p>We extend each Q, e sbj , rel, e obj in the Sim- pleQuestions data set to Q, e sbj , rel, e obj , type, where type denotes the type name of e obj based on Freebase. Thus, we obtain Q, type pairs. Similar to rel-CNN, we use Q, type pairs to train another CNN model, denoted as type-CNN. Based on which, we define a type-based feature as:</p><formula xml:id="formula_28">h T E (S, Q) = cosine(y T E (Q), y T E (S))</formula><p>y T E (S) and y T E (Q) denote type embeddings of S and Q respectively, coming from type-CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Topic-level Feature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.1">Unsupervised Topic Model</head><p>As the assumption that Q-R pair should share similar topic distribution, We define an unsuper- vised topic model-based feature h U T M as the av- erage cosine distance between topic vectors of all non-stopword pairs v S j , v Q i , where v w = [p(t 1 |w), ..., p(t N |w)] T denotes the topic vector of a given word w. Given a corpus, various topic modeling methods, such as pLSI (probabilistic la- tent semantic indexing) and LDA (latent Dirichlet allocation), can be used to estimate p(t i |w), which denotes the probability that w belongs to a topic t i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.2">Supervised Topic Model</head><p>One shortcoming of the unsupervised topic model is that, the topic size is pre-defined, which might not reflect the truth on a specific corpus. In this pa- per, we explore a supervised topic model approach as well, based on 'sentence-topic' pairs.</p><p>We crawl a large number of S, topic pairs from Wikipedia documents, where S denotes a sentence, topic denotes the content name of the section that S extracted from. Such content names are labeled by Wikipedia article editors, and can be found in the Contents fields.</p><p>Similar to rel-CNN and type-CNN, we use the S, topic pairs to train another CNN model, de- noted as topic-CNN. Based on which, we define a supervised topic model-based feature as:</p><formula xml:id="formula_29">h ST M (S, Q) = cosine(y ST M (S), y ST M (Q))</formula><p>y ST M (S) and y ST M (Q) denote topic embeddings of S and Q respectively, coming from topic-CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Learning to Ranking Model</head><p>We employ a regression-based learning to rank method <ref type="bibr" target="#b11">(Nallapati, 2004</ref>) to train response rank- ing model, based on a set of labeled Q, C pairs, Feature weights in the ranking model are trained by SGD based on the training data that consists of a set of Q, C pairs, where Q denotes a user utterance and C denotes a set of response candi- dates. Each candidate S in C is labeled by + or −, which indicates whether S is a suitable response of Q (+), or not (−).</p><p>As manually labeled data, such as WikiQA ( <ref type="bibr" target="#b21">Yang et al., 2015)</ref>, needs expensive human an- notation effort, we propose an automatic way to collect training data. First, 'question-answer' (or Q-A) pairs {Q i , A i } M i=1 are crawled from commu- nity QA websites. Q i denotes a question. A i de- notes Q i 's answer, which includes one or more sentences A i = {s 1 , ..., s K }. Then, we index an- swer sentences of all questions. Next, for each question Q i , we run response retrieval to obtain answer sentence candidates C i = {s 1 , ..., s N }. Last, if we know the correct answer sentences of each question Q i , we can then label each candidate in C i as + or −. In experiments, manually labeled data <ref type="bibr">(WikiQA)</ref> is used in open domain question answering scenario, and automatically generated data is used in chatbot scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Response Triggering</head><p>There are two types of utterances, chit-chat ut- terances and informative utterances. The for- mer should be handled by chit-chat engines, and the latter is more suitable to our work, as docu- ments usually contain formal and informative con- tents. Thus, we have to respond to informative ut- terances only. Response retrieval cannot always guarantee to return a candidate set that contains at least one suitable response, but response rank- ing will output the best possible candidate all the time. So, we have to decide which responses are confident enough to be output, and which are not.</p><p>In this paper, we define response triggering as a function that decides whether a response candidate S has enough confidence to be output:</p><formula xml:id="formula_30">I = T rigger(S, Q) = I U (Q) ∧ I Rank (S, Q) ∧ I R (S)</formula><p>where T rigger(Q, S) returns true, if and only if all its three sub-functions return true.</p><p>I U (Q) returns true, if Q is an informative query. We collect and label chit-chat queries based on conversational exchanges from social media websites to train the classifier.</p><p>I Rank (S, Q) returns true, if the score s(S, Q) exceeds an empirical threshold τ :</p><formula xml:id="formula_31">s(S, Q) = 1 1 + e −α·Rank(S,Q)</formula><p>where α is the scaling factor that controls the dis- tribution of s(·) smooth or sharp. Both α and τ are selected based on a separated development set.</p><p>I R (S) returns true, if (i) the length of S is less than a pre-defined threshold, and (ii) S does not start with a phrase that expresses a progressive re- lation, such as but also, besides, moreover and etc., as the contents of sentences starting with such phrases usually depend on their context sentences, and they are not suitable for responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>For modeling dialogue. Previous works mainly focused on rule-based or learning-based approach- es ( <ref type="bibr" target="#b8">Litman et al., 2000;</ref><ref type="bibr" target="#b14">Schatzmann et al., 2006;</ref><ref type="bibr" target="#b20">Williams and Young, 2007)</ref>. These methods re- quire efforts on designing rules or labeling data for training, which suffer the coverage issue.</p><p>For short text conversation. With the fast de- velopment of social media, such as microblog and CQA services, large scale conversation data and data-driven approaches become possible. <ref type="bibr" target="#b13">Ritter et al. (2011)</ref> proposed an SMT based method, which treats response generation as a machine transla- tion task. <ref type="bibr" target="#b16">Shang et al. (2015)</ref> presented an RNN based method, which is trained based on a large number of single round conversation data. Gram- matical and fluency problems are the biggest issue for such generation-based approaches. Retrieval- based methods selects the most suitable response to the current utterance from the large number of Q-R pairs. <ref type="bibr" target="#b5">Ji et al. (2014)</ref> built a conversation sys- tem using learning to rank and semantic matching techniques. However, collecting enough Q-R pairs to build chatbots is often intractable for many do- mains. Compared to previous methods, DocChat learns internal relationships between utterances and responses based on statistical models at differ- ent levels of granularity, and relax the dependen- cy on Q-R pairs as response sources. These make DocChat as a general response generation solution to chatbots, with high adaptation capability.</p><p>For answer sentence selection. Prior work in measuring the relevance between question and an- swer is mainly in word-level and syntactic-level ( <ref type="bibr" target="#b17">Wang and Manning, 2010;</ref><ref type="bibr" target="#b4">Heilman and Smith, 2010;</ref><ref type="bibr" target="#b22">Yih et al., 2013)</ref>. Learning representation by neural network architecture ( <ref type="bibr" target="#b25">Yu et al., 2014;</ref><ref type="bibr" target="#b18">Wang and Nyberg, 2015;</ref><ref type="bibr" target="#b15">Severyn and Moschitti, 2015</ref>) has become a hot research topic to go beyond word-level or phrase-level methods. Com- pared to previous works we find that, (i) Large s- cale existing resources with noise have more ad- vantages as training data. (ii) Knowledge-based semantic models can play important roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Evaluation on QA (English)</head><p>Take into account response ranking task and an- swer selection task are similar, we first evaluate DocChat in a QA scenario as a simulation. Here, response ranking is treated as the answer selection task, and response triggering is treated as the an- swer triggering task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Experiment Setup</head><p>We select WikiQA 6 as the evaluation data, as it is precisely constructed based on natural language questions and Wikipedia documents, which con- tains 2,118 'question-document' pairs in the train- ing set, 296 'question-document' pairs in devel- opment set, and 633 'question-document' pairs in testing set. Each sentence in the document of a given question is labeled as 1 or 0, where 1 de- notes the current sentence is a correct answer sen- tence, and 0 denotes the opposite meaning. Given a question, the task of WikiQA is to select answer sentences from all sentences in a question's corre- sponding document. The training data settings of response ranking features are described below.</p><p>F w denotes 3 word-level features, h W M , h W 2W and h W 2V . For h W 2W , GIZA++ is used to train word alignments on 11.6M 'question-related question' pairs <ref type="bibr" target="#b3">(Fader et al., 2013</ref>) crawled from WikiAnswers. <ref type="bibr">7</ref> . For h W 2V , <ref type="bibr">Word2Vec (Mikolov et al., 2013</ref>) is used to train word embedding on sentences from Wikipedia in English.</p><p>F p denotes 2 phrase-level features, h P P and h P T . For h P P , bilingual data 8 is used to extrac- t a phrase-based translation table ( <ref type="bibr" target="#b7">Koehn et al., 2003)</ref>, from which paraphrases are extracted (Sec- tion 4.2.1). For h P T , GIZA++ trains word align- ments on 4M 'question-answer' pairs 9 crawled from Yahoo Answers 10 , and then a phrase ta- ble is extracted from word alignments using the intersect-diag-grow refinement.</p><p>F s denotes 2 sentence-level features, h SCR and h SDR . For h SCR , 4M 'question-answer' pairs (the same to h P T ) is used to train the CNN model. For h SDR , we randomly select 0.5M 'sentence-next sentence' pairs from English Wikipedia.</p><p>F d denotes document-level feature h DM . Here, we didn't train a new model. Instead, we just re- use the CNN model used in h SCR .</p><p>F r and F ty denote relation-level feature h RE and type-level feature h T E . <ref type="bibr" target="#b1">Bordes et al. (2015)</ref> released the SimpleQuestions data set 11 , which consists of 108,442 English questions. Each ques- tion (e.g., What does Jimmy Neutron do?) is written by human annotators based on a triple in Freebase which formatted as e sbj , rel, e obj (e.g., Jimmy Neutron, fictional character occupation, inventor) Here, as described in Section 4.5 and 4.6, 'question-relation' pairs and 'question-type' pairs based upon SimpleQuestions data set are used to train h RE and h T E .</p><p>F to denotes 2 topic-level features, h U T M and h ST M . For h U T M , we run LightLDA ( <ref type="bibr" target="#b26">Yuan et al., 2015</ref>) on sentences from English Wikipedi- a, where the topic is set to 1,000. For h ST M , 4M 'sentence-topic' pairs are extracted from En- glish Wikipedia (Section 4.7.2), where the most frequent 25,000 content names are used as topics. <ref type="bibr">7</ref> http://wiki.answers.com <ref type="bibr">8</ref> We use 0.5M Chinese-English bilingual sentences in phrase table extraction, i.e., LDC2003E07, LDC2003E14, LDC2005T06, LDC2005T10, LDC2005E83, LDC2006E26, LDC2006E34, LDC2006E85 and LDC2006E92. <ref type="bibr">9</ref> For each question, we only select the first sentence in its answer to construct a 'question-answer' pair, as it contains more causality information than sentences in other positions. <ref type="bibr">10</ref>   <ref type="formula">(6)</ref> DocChat+ <ref type="formula">(2)</ref> 70.08% 72.22% <ref type="table">Table 2</ref>: Evaluation of AS task on WikiQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">Results on Answer Selection (AS)</head><p>The performance of answer selection is evaluat- ed by Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR). Among all 'question- document' pairs in WikiQA, only one-third of documents contain answer sentences to their cor- responding questions. Similar to previous work, questions without correct answers in the candidate sentences are not taken into account. We first evaluate the impact of features at each level, and show results in <ref type="table">Table 1</ref>. F w , F p , and F s perform best among all features, which makes sense, as they can capture lexical features. F r and F ty perform not very good, but make sense, as the training data (i.e. SimpleQuestions) are based on Freebase instead of Wikipedia. Interestingly, we find that F to and F d can achieve comparable re- sults as well. We think the reason is that, their training data come from Wikipedia, which fit the WikiQA task very well.</p><p>We evaluate the quality of DocChat on Wik- iQA, and show results in <ref type="table">Table 2</ref>. The first four rows in <ref type="table">Table 2</ref>   <ref type="formula">2015)</ref>, which uses an enriched LSTM with a latent stochastic atten- tion mechanism to model similarity between Q-R pairs; and (4) <ref type="bibr" target="#b24">Yin et al. (2015)</ref>, which adds the at- tention mechanism to the CNN architecture. <ref type="table">Table 2</ref> shows that, without using WikiQA's training set (only development set for ranking weights), DocChat can achieve comparable per-  formance with state-of-the-art baselines. Further- more, by combining the CNN model proposed by <ref type="bibr" target="#b21">Yang et al. (2015)</ref> and trained on WikiQA training set, we achieve the best result on both metrics. Compared to previous methods, we think Doc- Chat has the following two advantages: First, our feature models depending on existing resources are readily available (such as Q-Q pairs, Q-A pairs, 'sentence-next sentence' pairs, and etc.), in- stead of requiring manually annotated data (such as WikiQA and QASent). Training of the response ranking model does need labeled data, but the size demanded is acceptable. Second, as the training data used in our approach come from open domain resources, we can expect a high adaptation capa- bility and comparable results on other WikiQA- like tasks, as our models are task-independent.</p><p>To verify the second advantage, we evaluate DocChat on another answer selection data set, QASent ( <ref type="bibr" target="#b19">Wang et al., 2007)</ref>, and list results in Ta- ble 3. CN N W ikiQA and CN NQASent refer to the re- sults of <ref type="bibr" target="#b21">Yang et al. (2015)</ref>'s method, where the CNN models are trained on WikiQA's training set and QASent's training set respectively. All these three methods train feature weights using QASent's development set.  <ref type="table" target="#tab_5">Table 4</ref> evaluates the contributions of features at different levels of granularity. To highlight the differences, we report the percent deviation by re- moving different features at the same level from DocChat. From <ref type="table" target="#tab_5">Table 4</ref> we can see that, 1) Each feature group is indispensable to DocChat; 2) Fea- tures at sentence-level are most important than other feature groups; 3) Compared to results in <ref type="table">Table 1</ref>, combining all features can significantly promote the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.3">Evaluation of Answer Triggering (AT)</head><p>In both QA and chatbot, response triggering is im- portant. Similar to <ref type="bibr" target="#b21">Yang et al. (2015)</ref>, we also evaluate answer triggering using Precision, Recall, and F1 score as metrics. We use the WikiQA de-   velopment set to tune the scaling factor α and trig- ger threshold τ that are described in Section 5, where α is set to 0.9 and τ is set to 0.5. <ref type="table" target="#tab_6">Table 5</ref> shows the evaluation results compare to <ref type="bibr" target="#b21">Yang et al. (2015)</ref>. We think the improvements come from the fact that our response ranking mod- el are more discriminative, as more semantic-level features are leveraged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation on Chatbot (Chinese)</head><p>XiaoIce is a famous Chinese chatbot engine, which can be found in many platforms including WeChat official accounts (like business pages on Facebook Messenger). The documents that each official account maintains and post to their follow- ers can be easily obtained from the Web. Mean- while, a WeChat official account can choose to au- thorize XiaoIce to respond to its followers' utter- ances. We design an interesting evaluation below to compare DocChat with XiaoIce, based on the publicly available documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Experiment Setup</head><p>For ranking features, 17M 'question-related ques- tions' pairs crawled from Baidu Zhidao are used to train word alignments for h W 2W ; sentences from Chinese Wikipedia are used to train word embeddings for h W 2V and a topic model for h U T M ; the same bilingual phrase (Beijing is a historical city that can be traced back to 3,000 years ago.) <ref type="table">Table 6</ref>: XiaoIce response is more colloquial, as it comes from Q-R pairs; while DocChat response is more formal, as it comes from documents.</p><p>h ST M . As there is no knowledge base based la- beled data for Chinese, we ignore relation-level feature h RE and type-level feature h T E .</p><p>For ranking weights, we generate 90,321 Q, C pairs based on Baidu Zhidao Q-A pairs by the au- tomatic method described in Section 4.8. This da- ta set is used to train the learning to rank model feature weights {λ k } by SGD.</p><p>For documents, we randomly select 10 WeChat official accounts, and index their documents sepa- rately. The average number of documents is 600.</p><p>Human annotators are asked to freely issue 100 queries to each official account to get XiaoIce re- sponse. Thus, we obtain 100 query, XiaoIce response pairs for each official account. We al- so send the same 100 queries of each official ac- count to DocChat based on official account's cor- responding document index, and obtain anoth- er 100 query, DocChat response pairs. Given these 1,000 query, XiaoIce response, DocChat response triples, we let human annotators do a side-by-side evaluation, by asking them which re- sponse is better for each query. Note that, the source of each response is masked during evalu- ation procedure. <ref type="table">Table 6</ref> gives an example. <ref type="table">Table 7</ref> shows the results. Better (or Worse) de- notes a DocChat response is better (or worse) than a XiaoIce response, Tie denotes a DocChat re- sponse and a XiaoIce response are equally good or bad. From <ref type="table">Table 7</ref> we observe that: (1) 156 Doc- Chat responses (58+47+51) out of 1,000 queries are triggered. The trigger rate of DocChat is 15.6%. We check un-triggered queries, and find most of them are chitchat, such as "hi", "hello", "who are you?". (2) Better cases are more than worse cases. Most queries in better cases are non- chitchat ones, and their contents are highly relat- ed to the domain of their corresponding WeChat official accounts. (3) Our proposed method is a perfect complement for chitchat engines on in- Better Worse Tie Compare to XiaoIce 58 47 51 <ref type="table">Table 7</ref>: Chatbot side-by-side evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">DocChat v.s. XiaoIce</head><p>formative utterances. The reasons for bad cas- es are two-fold: First, a DocChat response over- laps with a query, but cannot actually response it. For this issue, we need to refine the capa- bility of our response ranking model on measur- ing causality relationships. Second, we wrong- ly send a chitchat query to DocChat, as current- ly, we only use a white list of chitchat queries for chitchat/non-chitchat classification (Section 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper presents a response retrieval method for chatbot engines based on unstructured documents. We evaluate our method on both question answer- ing and chatbot scenarios, and obtain promising results. We leave better triggering component and multiple rounds of conversation handling to be ad- dressed in our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>•</head><label></label><figDesc>Else, if S j+n−1 j , s, score(s; S j+n−1 j ) ∈ P P and S j+n−1 j 's paraphrase s occurs in Q, then CountP P (S j+n−1 j , Q) = score(s; S j+n−1 j )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>represent four baseline methods, including: (1) Yih et al. (2013), which makes use of rich lexical semantic features; (2) Yang et al. (2015), which uses a bi-gram CNN model with av- erage pooling; (3) Miao et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Evaluation of AS on QASent.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 tells</head><label>3</label><figDesc>, DocChat outperforms CN N W ikiQA in terms of MAP and MRR, and achieves comparable results compared to CN NQASent. The comparisons results show a good adaptation capability of DocChat.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 : Impacts of different feature groups.</head><label>4</label><figDesc></figDesc><table>Methods 
Precision Recall 
F1 
Yang et al. (2015) 
28.34 
35.80 
31.64 
DocChat 
28.95 
44.44 
35.06 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 : Evaluation of AT on WikiQA.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="3"> We omit lexical weights that are commonly used in phrase tables, as they are not useful in paraphrase extraction.</note>

			<note place="foot" n="4"> In this paper, m is set to 3.</note>

			<note place="foot" n="5"> http://www.freebase.com/</note>

			<note place="foot" n="6"> http://aka.ms/WikiQA</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Paraphrasing with bilingual parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Bannard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="597" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Large-scale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Paraphrase-driven learning for open question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An information retrieval approach to short text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongcheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.6988</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A probabilistic model of information retrieval: development and comparative experiments: Part 2. Information Processing &amp; Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="809" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)</title>
		<meeting>Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACLHLT)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Njfun: a reinforcement learning spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satinder</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 ANLP/NAACL Workshop on Conversational systems</title>
		<meeting>the 2000 ANLP/NAACL Workshop on Conversational systems</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishu</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06038</idno>
		<title level="m">Neural variational inference for text processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Discriminative models for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. The knowledge engineering review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Weilhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Stuttle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="97" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Probabilistic tree-edit models with structured latent variables for textual entailment and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A long shortterm memory model for answer sentence selection in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasisynchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Partially observable markov decision processes for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="422" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Question answering using enhanced lexical semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pastusiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="643" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Wenpeng Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05193</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Deep learning for answer sentence selection. NIPS Deep Learning and Representation Learning Workshop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Pulman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lightlda: Big topic models on modest computer clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qirong</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinliang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">Po</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual International Conference on World Wide Web (WWW)</title>
		<meeting>the Annual International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1351" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
