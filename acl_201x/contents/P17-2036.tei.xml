<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiliang</forename><surname>Tian</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
						</author>
						<title level="a" type="main">How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="231" to="236"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2036</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Generative conversational systems are attracting increasing attention in natural language processing (NLP). Recently, researchers have noticed the importance of context information in dialog processing, and built various models to utilize context. However, there is no systematic comparison to analyze how to use context effectively. In this paper, we conduct an empirical study to compare various models and investigate the effect of context information in dialog systems. We also propose a variant that explicitly weights context vectors by context-query relevance, outper-forming the other baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, human-computer conversation is attract- ing increasing attention due to its promising poten- tials and alluring commercial values. Researchers have proposed both retrieval methods ( <ref type="bibr" target="#b2">Ji et al., 2014;</ref> and generative meth- ods ( <ref type="bibr" target="#b6">Ritter et al., 2011;</ref><ref type="bibr" target="#b9">Shang et al., 2015</ref>) for automatic conversational systems. With the suc- cess of deep learning techniques, neural networks have demonstrated powerful capability of learning human dialog patterns; given a user-issued utter- ance as an input query q, the network can gen- erate a reply r, which is usually accomplished in a sequence-to-sequence (Seq2Seq) manner <ref type="bibr" target="#b9">(Shang et al., 2015)</ref>.</p><p>In the literature, there are two typical research setups for dialog systems: single-turn and multi- turn. Single-turn conversation is, perhaps, the sim- plest setting where the model only takes q into consideration when generating r (Shang et al., <ref type="bibr">* Corresponding author.</ref> 2015; <ref type="bibr" target="#b5">Mou et al., 2016)</ref>. However, most real- world dialogs comprise multiple turns. Previous utterances (referred to as context in this paper) could also provide useful information about the di- alog status and are the key to coherent multi-turn conversation.</p><p>Existing studies have realized the importance of context, and proposed several context-aware conversational systems. For example,  directly concatenate context utterances and the current query; others use hierarchical models, first capturing the meaning of individ- ual utterances and then integrating them as dis- courses ( ). There could be several ways of combining context and the cur- rent query, e.g., pooling or concatenation ( . Unfortunately, previous literature lacks a systematic comparison of the above meth- ods.</p><p>In this paper, we conduct an empirical study on context modeling in Seq2Seq-like conversa- tional systems. We emphasize the following re- search questions:</p><p>• RQ1. How can we make better use of con- text information? Our study shows that hier- archical models are generally better than non- hierarchical ones. We also propose a variant of context integration that explicitly weights a context vector by its relevance measure, outperforming simple vector pooling or con- catenation.</p><p>• RQ2. What is the effect of context on neural dialog systems? We find context information is useful to neural conversational models. It yields longer, more informative and diversi- fied replies. To sum up, the contributions of this paper are two-fold: (1) We conduct a systematic study on context modeling in neural conversational mod- els. (2) We further propose an explicitly con-text weighting approach, outperforming the other baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non-Hierarchical Model</head><p>To model a few utterances before the current query, several studies directly concatenate these sentences together and use a single model to cap- ture the meaning of context and the query ( . They are re- ferred to as non-hierarchical models in our pa- per. Such method is also used in other NLP tasks, e.g., document-level sentiment analysis ( <ref type="bibr" target="#b14">Xu et al., 2016</ref>) and machine comprehension ( <ref type="bibr" target="#b13">Wang and Jiang, 2017)</ref>.</p><p>Following the classic encode-decoder frame- work, we use a Seq2Seq network, which trans- forms the query and context into a fixed-length vector v enc by a recurrent neural network (RNN) during encoding; then, in the decoding phase, it generates a reply r with another RNN in a word- by-word fashion. (See <ref type="figure" target="#fig_1">Figure 1a.</ref>)</p><p>In our study, we adopt RNNs with gated re- current units ( <ref type="bibr">Cho et al., 2014, GRUs)</ref>, which al- leviates the long propagation problem of vanilla RNNs. When decoding, we apply beam search with a size of 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hierarchical Model</head><p>A more complicated approach to context model- ing is to build hierarchical models with a two-step strategy: an utterance-level model captures the meaning of each individual sentences, and then an inter-utterance model integrates context and query information ( <ref type="figure" target="#fig_1">Figure 1b)</ref>.</p><p>Researchers have tried different ways of com- bining information during inter-utterance model- ing; this paper evaluates several prevailing meth- ods.</p><p>Sum pooling. Sum pooling (denoted as Sum) integrates information over a candidate set by summing the values in each dimension ( <ref type="figure" target="#fig_3">Figure  2a</ref>). Given context vectors v c 1 , · · · , v cn and the query vector v q , the encoded vector v enc is</p><formula xml:id="formula_0">v enc = n i=1 v c i + v q (1)</formula><p>Sum pooling is used in , where bag-of-words (BoW) features of context   <ref type="formula" target="#formula_1">(2015)</ref> propose hierarchical dialog systems, where an inter-utterance RNN is built upon utterance-level RNNs' features (last hidden state). Training is accomplished by end-to-end gradient propagation, and the process is illustrated in <ref type="figure" target="#fig_3">Figure 2c</ref>.</p><p>Using an RNN to integrate context and query vectors in a sequential manner enables compli- cated information interaction. Based on the RNN's hidden states, Sum and Concat could also be applied to obtain the encoded vector v enc .  However, we found their performance is worse than only using the last hidden state (denoted as Seq). One plausible reason might be that the inter-sentence RNN is not long and that RNN can preserve these information well. Therefore, this variant is adopted in our experiments, as shown in <ref type="figure" target="#fig_3">Figure 2c</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Explicitly Weighting by Context-Query Relevance</head><p>In conversation, context utterances may vary in content and semantics: context utterances that are relevant to the query may be useful, while irrele- vant ones may bring more about noise. Following this intuition, we propose a variant that explicitly weights the context vector by an attention score of context-query relevance. First, we compute the similarity between the context and query by the cosine measure</p><formula xml:id="formula_1">s c i = sim(c i , q) = e c i · e q e c i · e q<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">e c i = w∈c i e w and e q = w ∈q e w<label>(3)</label></formula><p>that is, the sentence embedding is the sum of word embeddings.</p><p>Following the spirit of attention mecha- nisms ( ), we would like to normalize these similarities by a softmax function and obtain attention probabilities:</p><formula xml:id="formula_3">α c i = exp(s c i ) n j=0 exp(s c j ) + exp(s q ) (4) α q = exp(s q ) n j=0 exp(s c j ) + exp(s q ) (5)</formula><p>where s q is computed in the same manner as s c i and is always 1, which is the cosine of two same vectors. The intuition is that, if the context is less relevant, we should mainly focus on the query it- self, but if the context is relevant, we should focus more evenly across context and the query.</p><p>In other words, our explicitly weighting ap- proach could be viewed as heuristic attention. Akin to Subsection 2.2, we aggregate the weighted context and query vectors by pooling and concate- nation, resulting in the following two variants.</p><p>• WSeq (sum), where weighted vectors are summed together</p><formula xml:id="formula_4">v enc = n i=0 α c i h c i + α q h q<label>(6)</label></formula><p>• WSeq (concat), where weighted vectors are concatenated</p><formula xml:id="formula_5">v enc = [α c 0 h c 0 ; . . . ; α cn h cn ; α q h q ] (7)</formula><p>Notice that the explicitly weighting approach can also be applied to sentence embeddings (with- out inter-sentence RNN). We denote the variants by WSum and WConcat, respectively; details are not repeated. They are included for comparison in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup</head><p>We conducted all experiments on a Chinese dataset crawled from an online free chatting plat- form, Baidu Tieba. 1 To facilitate the research of context's effect, we established a multi-turn conversational corpus following  and <ref type="bibr" target="#b7">Serban et al. (2015)</ref>. A data sam- ple contains three utterances, being a triple last context, query, reply.</p><p>In total, we had Method BLEU-1 BLEU-2 BLEU-3 BLEU-4</p><p>Context-Insensitive 4.611 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Analysis</head><p>We evaluated model performance by BLEU scores. As this paper compares various models, it is unaffordable for us to hire workers to man- ually annotate their satisfaction. BLEU scores, albeit imperfect for open-domain dialog systems, exhibits more or less correlation with human sat- isfaction ( <ref type="bibr" target="#b3">Liu et al., 2016;</ref><ref type="bibr" target="#b12">Tao et al., 2017</ref>). We present in <ref type="table">Table 1</ref> the overall performance of the models introduced in Section 2, and answer our research questions as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ1: How can we make better use of context in- formation?</head><p>We first observe that context-aware methods generally outperform the context-insensitive one. This implies context is indeed useful in open- domain, chit-chat-style dialog systems. The re- sults are consistent with previous studies <ref type="bibr" target="#b7">Serban et al., 2015</ref>).</p><p>Among context-aware neural conversational models, we have the following findings.</p><p>• Hierarchical structures outperform the non- hierarchical one.</p><p>Comparing the non-hierarchical and hierar- chical structures, we find it obvious that (most) hierarchical models outperform the non-hierarchical one by a large margin. The results show that, dialog systems are differ- ent from other NLP applications, e.g., com- prehension ( <ref type="bibr" target="#b13">Wang and Jiang, 2017)</ref>, where non-hierarchical recurrent neural networks are adopted to better integrate information across different sentences. A plausible expla- nation, as indicated by <ref type="bibr" target="#b4">Meng et al. (2017)</ref>, is that conversational sentences are not neces- sarily uttered by a same speaker, and litera- ture shows consistent evidence of the effec- tiveness of hierarchical RNNs in dialog sys- tems.</p><p>• Keeping the roles of different utterances sep- arately is important.</p><p>As mentioned in Section 2, the concatena- tion operation (Concat) distinguishes the roles of different utterances, while sum pool- ing Sum aggregates information in a homo- geneous way. We see that the former outper- forms the latter in both sentence-embedding and inter-sentence RNN levels, showing that sum pooling is not suitable for treating dialog context. Our conjecture is that sum pooling buries illuminating query information under less important context. Hence, keeping them separately will generally help.</p><p>• The context-query relevance score benefits conversational systems.</p><p>Our explicitly weighting approach computes an attention probability by context-query rel- evance. In all variants (Sum, Concat, and Seq), explicitly weighting improves the per- formance by a large margin (except BLEU-1 for Seq). The results indicate that context- query relevance is useful, as it emphasizes  relevant context utterances as well as weak- ens irrelevant contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ2:</head><p>What is the effect of context on neural dia- log systems?</p><p>We are now curious about how context informa- tion affects neural conversational systems. In Ta- ble 2, we present three auxiliary metrics, i.e., sen- tence length, entropy, and diversity. The former two are used in  and <ref type="bibr" target="#b5">Mou et al. (2016)</ref>, whereas the latter one is used in <ref type="bibr" target="#b17">Zhang and Hurley (2008)</ref>.</p><p>As shown, content-aware conversational mod- els tend to generate longer, more meaningful and diverse replies compared with content-insensitive models, given that they also improve BLEU scores. <ref type="bibr">2</ref> This shows an interesting phenomenon of neu- ral sequence generation: an encoder-decoder framework needs sufficient source information for meaningful generation of the target; it simply does not fall into meaningful content from less mean- ingful input. A similar phenomenon is also re- ported in our previous work ( <ref type="bibr" target="#b5">Mou et al., 2016)</ref>; we show that, a same network will generate more meaningful sentences if it starts from a given (meaningful) keyword. These results also partially explain why a seq2seq neural network tends to generate short and universally relevant replies in open-domain conversation, despite its success in machine translation, abstractive summarization, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we analyzed the effect of context in generative conversational models. We conducted a systematic comparison among existing meth-ods and our newly proposed variant that explic- itly weights context vectors by context-query rele- vance.</p><p>We show that hierarchical RNNs generally out- perform non-hierarchical ones, and that explicitly weighting context information can emphasize the relevant context utterances and weaken less rele- vant ones.</p><p>Our experiments also reveal an interesting phe- nomenon: with context information, neural net- works tend to generate longer, more meaningful and diverse replies, which sheds light on neural sequence generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Seq2Seq-like neural networks generate a reply r based on context C = {c 1 ,. .. , c n } and the current query q with (a) non-hierarchical or (b) hierarchical models.</figDesc><graphic url="image-2.png" coords="2,311.91,182.38,211.70,107.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The inter-utterance modeling in hierarchical models. v c i and v q are the utterance-level vectors, h c i and h q are the utterance-level hidden states, α c i and α q are the explicitly weights and v enc is the output of the encoder.</figDesc><graphic url="image-6.png" coords="3,106.92,208.91,148.39,65.27" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The length, entropy, and diversity of 
the replies on the context-insensitive and context-
aware (WSeq,concat) methods. 

</table></figure>

			<note place="foot" n="1"> https://tieba.baidu.com</note>

			<note place="foot" n="2"> This condition is important when we draw conclusions. The length, entropy and diversity metrics do not make sense by themselves alone, because a system can achieve very high scores by repetitively generating random words.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for insightful com-ments. This research is partially supported by <ref type="bibr">863 Grant No. 2015AA015403 and NSFC Grant No. 61672058.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Encoder-decoder approaches. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An information retrieval approach to short text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongcheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.6988</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D16-1230</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1230" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Hierarchical RNN with static sentence-level attention for text-based speaker change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07713</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-1316" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics</title>
		<meeting>the 26th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3349" to="3358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William B</forename><surname>Dolan</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D11-1054" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian V Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3776" to="3783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06069</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/P15-1152</idno>
		<ptr target="https://doi.org/10.3115/v1/P15-1152" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Two are better than one: An ensemble of retrieval-and generation-based dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.07149</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/N15-1020</idno>
		<ptr target="https://doi.org/10.3115/v1/N15-1020" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">RUBER: An unsupervised method for automatic evaluation of open-domain dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.03079</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Machine comprehension using match-LSTM and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cached long short-term memory neural networks for document-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danlu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D16-1172</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1172" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1660" to="1669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to respond with deep neural networks for retrievalbased human-computer conversation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Attention with intention for a neural network conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Avoiding monotony: Improving the diversity of recommendation lists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Hurley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM Conference on Recommender Systems</title>
		<meeting>the 2008 ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
