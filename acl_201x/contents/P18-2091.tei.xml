<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Learning of Style-sensitive Word Vectors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reina</forename><surname>Akama</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kento</forename><surname>Watanabe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sho</forename><surname>Yokoi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>‡3</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kobayashi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Information Sciences</orgName>
								<orgName type="department" key="dep2">Inc. ‡ RIKEN Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">Tohoku University † National Institute of Advanced Industrial Science and Technology (AIST) § Preferred Networks</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Learning of Style-sensitive Word Vectors</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="572" to="578"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>572</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents the first study aimed at capturing stylistic similarity between words in an unsupervised manner. We propose extending the continuous bag of words (CBOW) model (Mikolov et al., 2013a) to learn style-sensitive word vectors using a wider context window under the assumption that the style of all the words in an utterance is consistent. In addition, we introduce a novel task to predict lexical stylistic similarity and to create a benchmark dataset for this task. Our experiment with this dataset supports our assumption and demonstrates that the proposed extensions contribute to the acquisition of style-sensitive word embeddings.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Analyzing and generating natural language texts requires the capturing of two important aspects of language: what is said and how it is said. In the literature, much more attention has been paid to studies on what is said. However, recently, captur- ing how it is said, such as stylistic variations, has also proven to be useful for natural language pro- cessing tasks such as classification, analysis, and generation <ref type="bibr" target="#b13">(Pavlick and Tetreault, 2016;</ref><ref type="bibr" target="#b19">Wang et al., 2017)</ref>. This paper studies the stylistic variations of words in the context of the representation learning of words. The lack of subjective or objective defi- nitions is a major difficulty in studying style <ref type="bibr" target="#b20">(Xu, 2017)</ref>. Previous attempts have been made to de- fine a selected aspect of the notion of style (e.g., politeness) ( <ref type="bibr" target="#b6">Mairesse and Walker, 2007;</ref><ref type="bibr" target="#b12">Pavlick and Nenkova, 2015;</ref><ref type="bibr" target="#b2">Flekova et al., 2016;</ref><ref type="bibr">PreotiucPietro et al., 2016;</ref><ref type="bibr" target="#b16">Sennrich et al., 2016;</ref>; however, it is not straightforward to create strict guidelines for identifying the stylistic profile of a given text. The systematic evaluations of style- sensitive word representations and the learning of style-sensitive word representations in a supervised manner are hampered by this. In addition, there is another trend of research forward controlling style-sensitive utterance generation without defin- ing the style dimensions ( <ref type="bibr" target="#b5">Li et al., 2016;</ref><ref type="bibr" target="#b0">Akama et al., 2017)</ref>; however, this line of research consid- ers style to be something associated with a given specific character, i.e., a persona, and does not aim to capture the stylistic variation space.</p><p>The contributions of this paper are three-fold. (1) We propose a novel architecture that acquires style-sensitive word vectors <ref type="figure" target="#fig_0">(Figure 1</ref>) in an un- supervised manner. (2) We construct a novel dataset for style, which consists of pairs of style- sensitive words with each pair scored accord- ing to its stylistic similarity. (3) We demon- strate that our word vectors capture the stylis- tic similarity between two words successfully. In addition, our training script and dataset are available on https://jqk09a.github.io/ style-sensitive-word-vectors/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Style-sensitive Word Vector</head><p>The key idea is to extend the continuous bag of words (CBOW) ( <ref type="bibr" target="#b7">Mikolov et al., 2013a</ref>) by distin-guishing nearby contexts and wider contexts under the assumption that a style persists throughout ev- ery single utterance in a dialog. We elaborate on it in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>Let w t denote the target word (token) in the corpora and U t = {w 1 , . . . , w t−1 , w t , w t+1 , . . . , w |Ut| } de- note the utterance (word sequence) including w t . Here, w t+d or w t−d ∈ U t is a context word of w t (e.g., w t+1 is the context word next to w t ), where d ∈ N &gt;0 is the distance between the context words and the target word w t .</p><p>For each word (token) w, bold face v w and˜vand˜ and˜v w denote the vector of w and the vector predicting the word w. Let V denote the vocabulary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Baseline Model (CBOW-NEAR-CTX)</head><p>First, we give an overview of CBOW, which is our baseline model. CBOW predicts the target word w t given nearby context words in a window with width δ:</p><formula xml:id="formula_0">C near wt := {w t±d ∈ U t | 1 ≤ d ≤ δ}<label>(1)</label></formula><p>The set C near wt contains in total at most 2δ words, in- cluding δ words to the left and δ words to the right of a target word. Specifically, we train the word vectors˜vvectors˜ vectors˜v wt and v c (c ∈ C near wt ) by maximizing the following prediction probability:</p><formula xml:id="formula_1">P (w t |C near wt ) ∝ exp˜v exp˜ exp˜v wt · 1 |C near wt | c∈C near w t v c .<label>(2)</label></formula><p>The CBOW captures both semantic and syntactic word similarity through the training using nearby context words. We refer to this form of CBOW as CBOW-NEAR-CTX. Note that, in the imple- mentation of <ref type="bibr" target="#b8">Mikolov et al. (2013b)</ref>, the window width δ is sampled from a uniform distribution; however, in this work, we fixed δ for simplicity. Hereafter, throughout our experiments, we turn off the random resizing of δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning Style with Utterance-size</head><p>Context Window (CBOW-ALL-CTX)</p><p>CBOW is designed to learn the semantic and syn- tactic aspects of words from their nearby con- text ( <ref type="bibr" target="#b8">Mikolov et al., 2013b</ref>). However, an inter- esting problem is determining the location where the stylistic aspects of words can be captured. To address this problem, we start with the assumption that a style persists throughout each single utter- ance in a dialog, that is, the stylistic profile of a word in an utterance must be consistent with other words in the same utterance. Based on this assump- tion, we propose extending CBOW to use all the words in an utterance as context,</p><formula xml:id="formula_2">C all wt := {w t±d ∈ U t | 1 ≤ d},<label>(3)</label></formula><p>instead of only the nearby words. Namely, we expand the context window from a fixed width to the entire utterance. This training strategy is expected to lead to learned word vectors that are more sensitive to style rather than to other aspects. We refer to this version as CBOW-ALL-CTX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning the Style and Syntactic/Semantic Separately</head><p>To learn the stylistic aspect more exclusively, we further extended the learning strategy.</p><formula xml:id="formula_3">Distant-context Model (CBOW-DIST-CTX)</formula><p>First, remember that using nearby context is effec- tive for learning word vectors that capture semantic and syntactic similarities. However, this means that using the nearby context can lead the word vectors to capture some aspects other than style. Therefore, as the first extension, we propose excluding the nearby context C near wt from all the context C all wt . In other words, we use the distant context words only:</p><formula xml:id="formula_4">C dist wt := C all wt \ C near wt = {w t±d ∈ U t | δ &lt; d}. (4)</formula><p>We expect that training with this type of context will lead to word vectors containing the style- sensitive information only. We refer to this method as CBOW-DIST-CTX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Separate Subspace Model (CBOW-SEP-CTX)</head><p>As the second extension to distill off aspects other than style, we use both nearby and all contexts (C near wt and C all wt ). As <ref type="figure" target="#fig_1">Figure 2</ref> shows, both the vector v w and˜vand˜ and˜v w of each word w ∈ V are divided into two vectors:</p><formula xml:id="formula_5">v w = x w ⊕ y w , ˜ v w = ˜ x w ⊕ ˜ y w ,<label>(5)</label></formula><p>where ⊕ denotes vector concatenation. Vectors x w and˜xand˜ and˜x w indicate the style-sensitive part of v w and˜vand˜ and˜v w respectively. Vectors y w and˜yand˜ and˜y w indicate the syntactic/semantic-sensitive part of v w and˜v and˜ and˜v w respectively. For training, when the context words are near the target word (C near wt ), we update both the style-sensitive vectors (˜ x wt , x c ) and the syntactic/semantic-sensitive vectors (˜ y wt , y c ), i.e., ˜ v wt , v c . Conversely, when the context words are far from the target word (C dist wt ), we only update the style-sensitive vectors (˜ x wt , x c ). Formally, the prediction probability is calculated as follows:</p><formula xml:id="formula_6">P 1 (w t |C near wt ) ∝ exp˜v exp˜ exp˜v wt · 1 |C near wt | c∈C near w t v c ,<label>(6)</label></formula><formula xml:id="formula_7">P 2 (w t |C dist wt ) ∝ exp˜x exp˜ exp˜x wt · 1 |C dist wt | c∈C dist w t x c .<label>(7)</label></formula><p>At the time of learning, two prediction probabili- ties (loss functions) are alternately computed, and the word vectors are updated. We refer to this method using the two-fold contexts separately as the CBOW-SEP-CTX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We investigated which word vectors capture the stylistic, syntactic, and semantic similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Settings</head><p>Training and Test Corpus We collected Japanese fictional stories from the Web to construct the dataset. The dataset contains approximately 30M utterances of fictional characters. We sepa- rated the data into a 99%-1% split for training and testing. In Japanese, the function words at the end of the sentence often exhibit style (e.g., desu+wa, desu+ze 1 ;) therefore, we used an existing lexicon of multi-word functional expressions ( <ref type="bibr" target="#b9">Miyazaki et al., 2015)</ref>. Overall, the vocabulary size |V| was 100K.</p><p>Hyperparameters We chose the dimensions of both the style-sensitive and the syntactic/semantic- sensitive vectors to be 300, and the dimensions of the baseline CBOWs were 300. The learn- ing rate was adjusted individually for each part in {x w , y w , ˜ x w , ˜ y w } such that "the product of the learning rate and the expectation of the number of updates" was a fixed constant. We ran the optimizer with its default settings from the implementation of <ref type="bibr" target="#b7">Mikolov et al. (2013a)</ref>. The training stopped after 10 epochs. We fixed the nearby window width to δ = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Stylistic Similarity Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Data Construction</head><p>To verify that our models capture the stylistic simi- larity, we evaluated our style-sensitive vector x wt by comparing to other word vectors on a novel artificial task matching human stylistic similarity judgments. For this evaluation, we constructed a novel dataset with human judgments on the stylis- tic similarity between word pairs by performing the following two steps. First, we collected only style-sensitive words from the test corpus because some words are strongly associated with stylistic aspects <ref type="bibr" target="#b4">(Kinsui, 2003;</ref><ref type="bibr" target="#b18">Teshigawara and Kinsui, 2011</ref>) and, therefore, annotating random words for stylistic similarity is inefficient. We asked crowd- sourced workers to select style-sensitive words in utterances. Specifically, for the crowdsourced task of picking "style-sensitive" words, we pro- vided workers with a word-segmented utterance and asked them to pick words that they expected to be altered within different situational contexts (e.g., characters, moods, purposes, and the back- ground cultures of the speaker and listener.). Then, we randomly sampled 1, 000 word pairs from the selected words and asked 15 workers to rate each of the pairs on five scales (from −2: "The style of the pair is different" to +2: "The style of the pair is similar"), inspired by the syntactic/semantic similarity dataset ( <ref type="bibr" target="#b1">Finkelstein et al., 2002;</ref><ref type="bibr" target="#b3">Gerz et al., 2016</ref>). Finally, we picked only word pairs featuring clear worker agreement in which more than 10 annotators rated the pair with the same sign, which consisted of random pairs of highly agreeing style-sensitive words. Consequently, we obtained 399 word pairs with similarity scores. To our knowledge, this is the first study that created an evaluation dataset to measure the lexical stylistic similarity.</p><p>In the task of selecting style-sensitive words, the pairwise inter-annotator agreement was moderate (Cohen's kappa κ is 0.51). In the rating task, the pairwise inter-annotator agreement for two classes ({−2, −1} or {+1, +2}) was fair (Cohen's kappa κ is 0.23). These statistics suggest that, at least  in Japanese, native speakers share a sense of style- sensitivity of words and stylistic similarity between style-sensitive words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Stylistic Sensitivity</head><p>We used this evaluation dataset to compute the Spearman rank correlation (ρ style ) between the co- sine similarity scores between the learned word vectors cos(v w , v w ) and the human judgements. <ref type="table">Table 1</ref> shows the results on its left side. First, our proposed model, CBOW-ALL-CTX outper- formed the baseline CBOW-NEAR-CTX. Further- more, the x of CBOW-DIST-CTX and CBOW-SEP- CTX demonstrated better correlations for stylis- tic similarity judgments (ρ style = 56.1 and 51.3, respectively). Even though the x of CBOW- SEP-CTX was trained with the same context win- dow as CBOW-ALL-CTX, the style-sensitivity was boosted by introducing joint training with the near context. CBOW-DIST-CTX, which uses only the distant context, slightly outperforms CBOW-SEP- CTX. These results indicate the effectiveness of training using a wider context window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Syntactic and Semantic Evaluation</head><p>We further investigated the properties of each model using the following criterion: (1) the model's ability to capture the syntactic aspect was assessed through a task predicting part of speech (POS) and (2) the model's ability to capture the semantic aspect was assessed through a task cal- culating the correlation with human judgments for semantic similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Syntactic Sensitivity</head><p>First, we tested the ability to capture syntactic sim- ilarity of each model by checking whether the POS of each word was the same as the POS of a neigh- boring word in the vector space. Specifically, we calculated SYNTAXACC@N defined as follows:</p><formula xml:id="formula_8">1 |V|N w∈V w ∈N (w) I[POS(w) = POS(w )], (8)</formula><note type="other">where I[condition] = 1 if the condition is true and I[</note><p>conditon] = 0 otherwise, the function POS(w) returns the actual POS tag of the word w, and N (w) denotes the set of the N top similar words {w } to w w.r.t. cos(v w , v w ) in each vector space. <ref type="table">Table 1</ref> shows SYNTAXACC@N with N = 5 and 10. For both N , the y (the syntactic/semantic part) of CBOW-NEAR-CTX, CBOW-ALL-CTX and CBOW-SEP-CTX achieved similarly good. In- terestingly, even though the x of CBOW-SEP-CTX used the same context as that of CBOW-ALL-CTX, the syntactic sensitivity of x was suppressed. We speculate that the syntactic sensitivity was distilled off by the other part of the CBOW-SEP-CTX vector, i.e., y learned using only the near context, which captured more syntactic information. In the next section, we analyze CBOW-SEP-CTX for the dif- ferent characteristics of x and y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Semantic and Topical Sensitivities</head><p>To test the model's ability to capture the se- mantic similarity, we also measured correla- tions with the Japanese Word Similarity Dataset (JWSD) <ref type="bibr" target="#b15">(Sakaizawa and Komachi, 2018)</ref>, which consists of 4,000 Japanese word pairs annotated with semantic similarity scores by human workers. For each model, we calculate and show the Spear- man rank correlation score (ρ sem ) between the co- sine similarity score cos(v w , v w ) and the human judgements on JWSD in <ref type="table">Table 1</ref> 2 . CBOW-DIST- CTX has the lowest score (ρ sem = 15.9); however, surprisingly, the stylistic vector x wt has the high- est score (ρ sem = 28.9), while both vectors have a high ρ style . This result indicates that the proposed stylistic vector x wt captures not only the stylistic similarity but also the captures semantic similarity, contrary to our expectations (ideally, we want the stylistic vector to capture only the stylistic similar- ity). We speculate that this is because not only the style but also the topic is often consistent in single utterances. For example, "サンタ (Santa Clause)" and "トナカイ (reindeer)" are topically relevant words and these words tend to appear in a single utterance. Therefore, stylistic vectors {x w } using all the context words in an utterance also capture the topic relatedness. In addition, JWSD contains topic-related word pairs and synonym pairs; there- fore the word vectors that capture the topic similar- ity have higher ρ sem . We will discuss this point in Word w</p><p>The top similar words {w } to w w.r.t. cosine similarity cos(xw, x w ) (stylistic half) cos(y w , y w ) (syntactic/semantic half) Japanese 俺 (I; male, colloquial) おまえ (you; colloquial, rough), 僕 (I; male, colloquial, childish), あいつ (he/she; colloquial, rough), あたし (I; female, childish), ねーよ (not; colloquial, rough, male) 私 (I; formal) 拙者 (I; classical * ) でござる(be; classical), 僕 (I; male, childish), * e.g., samurai, ninja ござる(be; classical), 俺 (I; male, colloquial), ござるよ(be; classical) 私 (I; formal) かしら (wonder; female) わね (QUESTION; female), かな (wonder; childish), ないわね (not; female), でしょうか (wonder; fomal), わ (SENTENCE-FINAL; female) かしらね (wonder; female) サンタ (Santa Clause; shortened) サンタクロース (Santa Clause; -), お客 (customer; little polite), トナカイ (reindeer; -), プロデューサー (producer; -), クリスマス (Christmas; -)</p><p>メイド <ref type="formula">(</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of Trained Word Vectors</head><p>Finally, to further understand what types of features our CBOW-SEP-CTX model acquired, we show some words 3 with the four most similar words in <ref type="table" target="#tab_2">Table 2</ref>. Here, for English readers, we also report a result for English <ref type="bibr">4</ref> . The English result also shows an example of the performance of our model on another language. The left side of <ref type="table" target="#tab_2">Table 2</ref> (for stylistic vector x) shows the results. We found that the Japanese word "拙者 (I; classical)" is similar to "ござる (be; classical)" or words containing it (the second row of <ref type="table" target="#tab_2">Table 2</ref>). The result looks rea- sonable, because words such as "拙者 (I; classical)" and "ござる (be; classical)" are typically used by Japanese Samurai or Ninja. We can see that the vec- tors captured the similarity of these words, which are stylistically consistent across syntactic and se- mantic varieties. Conversely, the right side of the table (for the syntactic/semantic vector y) shows that the word "拙者 (I; classical)" is similar to the personal pronoun (e.g., "僕 (I; male, childish)"). We further confirmed that 15 the top similar words are also personal pronouns (even though they are not shown due to space limitations). These results indicate that the proposed CBOW-SEP-CTX model jointly learns two different types of lexical similar-ities, i.e., the stylistic and syntactic/semantic simi- larities in the different parts of the vectors. How- ever, our stylistic vector also captured the topic similarity, such as "サンタ (Santa Clause)" and "トナカイ (reindeer)" (the fourth row of <ref type="table" target="#tab_2">Table 2</ref>). Therefore, there is still room for improvement in capturing the stylistic similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>This paper presented the unsupervised learning of style-sensitive word vectors, which extends CBOW by distinguishing nearby contexts and wider con- texts. We created a novel dataset for style, where the stylistic similarity between word pairs was scored by human. Our experiment demonstrated that our method leads word vectors to distinguish the stylistic aspect and other semantic or syntactic aspects. In addition, we also found that our training cannot help confusing some styles and topics. A future direction will be to addressing the issue by further introducing another context such as a docu- ment or dialog-level context windows, where the topics are often consistent but the styles are not.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Word vector capturing stylistic and syntactic/semantic similarity.</figDesc><graphic url="image-1.png" coords="1,318.19,222.54,196.44,100.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The architecture of CBOW-SEP-CTX.</figDesc><graphic url="image-2.png" coords="3,72.00,62.81,218.27,123.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The top similar words for the style-sensitive and syntactic/semantic vectors learned with proposed 
model, CBOW-SEP-CTX. Japanese words are translated into English by the authors. Legend: (translation; 
impression). 

the next section. 

</table></figure>

			<note place="foot" n="1"> These words mean the verb be in English.</note>

			<note place="foot" n="2"> Note that the low performance of our baseline (ρsem = 27.8 for CBOW-NEAR-CTX) is unsurprising comparing to English baselines (cf., Taguchi et al. (2017)).</note>

			<note place="foot" n="3"> We arbitrarily selected style-sensitive words from our stylistic similarity evaluation dataset. 4 We trained another CBOW-SEP-CTX model on an English fan-fiction dataset that was collected from the Web (https://www.fanfiction.net/).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by JSPS KAKENHI Grant Number 15H01702. We thank our anony-mous reviewers for their helpful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generating stylistically consistent dialog responses with transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reina</forename><surname>Akama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Inada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoya</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="408" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yossi</forename><surname>Matians</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Solan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gadi</forename><surname>Wolfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Ruppin</surname></persName>
		</author>
		<idno type="doi">10.1145/503104.503110</idno>
		<ptr target="https://doi.org/10.1145/503104.503110" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploring stylistic variation with age and income on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucie</forename><surname>Flekova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preot¸iucpreot¸preot¸iuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><surname>Ungar</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-2051</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-2051" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="313" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simverb-3500: A largescale evaluation set of verb similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D16-1235</idno>
		<ptr target="https://doi.org/10.18653/v1/D16-1235" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2173" to="2182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Vaacharu nihongo: yakuwari-go no nazo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Kinsui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Iwanami</publisher>
			<pubPlace>Tokyo, Japan</pubPlace>
		</imprint>
	</monogr>
	<note>In Japanese</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Spithourakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/P16-1094</idno>
		<ptr target="https://doi.org/10.18653/v1/P16-1094" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="994" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Personage: Personality generation for dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop at the International Conference on Learning Representations</title>
		<meeting>Workshop at the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 26th Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic conversion of sentence-end expressions for utterance characterization of dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiaki</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Hirano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiro</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihiro</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Pacific Asia Conference on Language, Information and Computation</title>
		<meeting>the 29th Pacific Asia Conference on Language, Information and Computation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discovering stylistic variations in distributional vector space models via lexical paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/W17-4903</idno>
		<ptr target="https://doi.org/10.18653/v1/W17-4903" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Stylistic Variation at the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Workshop on Stylistic Variation at the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A study of style in machine translation: Controlling the formality of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Martindale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D17-1299</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1299" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2804" to="2809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inducing lexical style properties for paraphrase and genre differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<idno type="doi">10.3115/v1/N15-1023</idno>
		<ptr target="https://doi.org/10.3115/v1/N15-1023" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="218" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An empirical analysis of formality in online communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discovering user attribute stylistic differences via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Preotiuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyle</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3030" to="3037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Construction of a japanese word similarity dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuya</forename><surname>Sakaizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Language Resources and Evaluation</title>
		<meeting>the 11th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="948" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Controlling politeness in neural machine translation via side constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/N16-1005</idno>
		<ptr target="https://doi.org/10.18653/v1/N16-1005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Japanese word distributional representation considering of synonyms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuya</forename><surname>Taguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Tamori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Hitomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiro</forename><surname>Nishitoba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kou</forename><surname>Kikuta</surname></persName>
		</author>
		<idno>17</idno>
	</analytic>
	<monogr>
		<title level="j">The Asahi Shimbun Company</title>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Retrieva Inc</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Modern Japanese &apos;role language&apos; (yakuwarigo): fictionalised orality in Japanese literature and popular culture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihoko</forename><surname>Teshigawara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Kinsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociolinguistic Studies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">37</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Steering output style and topic in neural response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nebojsa</forename><surname>Jojic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/D17-1228</idno>
		<ptr target="https://doi.org/10.18653/v1/D17-1228" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2140" to="2150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">From shakespeare to twitter: What are language styles all about?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/W17-4901</idno>
		<ptr target="https://doi.org/10.18653/v1/W17-4901" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Stylistic Variation at the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Workshop on Stylistic Variation at the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
