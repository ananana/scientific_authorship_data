<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Methodology for Evaluating Timeline Generation Algorithms based on Deep Semantic Units</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Computer Laboratory University of Cambridge Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Methodology for Evaluating Timeline Generation Algorithms based on Deep Semantic Units</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="834" to="839"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Timeline generation is a summarisation task which transforms a narrative, roughly chronological input text into a set of timestamped summary sentences, each expressing an atomic historical event. We present a methodology for evaluating systems which create such timelines, based on a novel corpus consisting of 36 human-created timelines. Our evaluation relies on deep semantic units which we call historical content units. An advantage of our approach is that it does not require human annotation of new system summaries.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A timeline of historical events is a special kind of summary. We define a timeline as a list of textual event descriptions, each paired with a date (see <ref type="figure" target="#fig_1">Figure 1)</ref>. A timeline is different from a standard single-or multi-document summary: Each event description is accompanied by a timestamp, and event descriptions themselves are independent lin- guistic units which should be understandable on their own. Additionally, a good timeline satis- fies conflicting constraints: it should contain only salient events, and the overall time period consid- ered should be covered well by events. Timeline construction is not a new task. It has been per- formed, for example, in a multi-document sum- marisation ( <ref type="bibr" target="#b2">Chieu and Lee, 2004;</ref><ref type="bibr" target="#b12">Yan et al., 2011;</ref><ref type="bibr" target="#b6">Nguyen et al., 2014</ref>) or in a single-document clas- sification context <ref type="bibr" target="#b1">(Chasin et al., 2013)</ref>.</p><p>It is crucial to reliably evaluate algorithms that create such timelines automatically. Of course, any summary can be evaluated by surface meth- ods such as ROUGE <ref type="bibr" target="#b3">(Lin, 2004</ref>). But even for traditional summaries, ROUGE-based evaluation has been criticised for being too shallow, and it is even less adequate for timelines, because of their special properties described above. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1997</head><p>There was unrest in Albania. <ref type="bibr">June 1997</ref> Fatos Nano was elected Prime Minister. We therefore opt for a "deep" method which attempts to measure to which degree a system- generated timeline contains semantic units found in gold-standard timelines. Our content units re- semble those of van <ref type="bibr" target="#b9">Halteren and Teufel (2003)</ref> and <ref type="bibr" target="#b5">Nenkova and Passonneau (2004)</ref>, but are larger in that they correspond to historical events.</p><p>Traditional deep summarisation evaluation is expensive because it involves annotation of gold- standard summaries as well as annotation of each system summary. A major operational advantage of our approach is that we require human anno- tation only for gold-standard summaries, not for system summaries. After a one-time effort of cre- ating semantic units and mapping them to the orig- inal text, the quality of a system's content selection can be evaluated for infinitely many new system summaries for free. Our method is the following:</p><p>1. Ask timeline writers to create timelines with a fixed number of date-event pairs. 2. An HCU creator (the first author) transforms these timelines into HCUs, historical content units, which are defined based on semantic overlap between timeline text. 3. We then create a mapping between HCUs and the source text, or more precisely, TimeML events in the source text. This mapping be- tween HCUs and source text allows us to evaluate new systems without a human ever inspecting system output at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HCU 16 Action</head><p>Fatos Nano is elected Prime Minister Agent not given Patient Fatos Nano Time June 1997 Location Albania <ref type="figure">Figure 2</ref>: HCU for one event from <ref type="figure" target="#fig_1">Figure 1</ref> Any summarisation evaluation based on human judgment is inherently subjective, but we restrict this subjectivity in three ways. First, timeline cre- ation (step 1) involves the selection of important content, which is by far the most subjective of the decisions involved in our evaluation method. We therefore ask three independent timeline writers to perform this task. Second, the generation of HCUs (step 2) is prescribed by fixed rules and definitions inspired by the methodology of van <ref type="bibr" target="#b9">Halteren and Teufel (2003)</ref>. With this method, the timeline writ- ers, not the HCU creators, decide which material is available for creating the HCUs. Third, for the cre- ation of mappings between HCUs and the source text (step 3), which was performed using a differ- ent set of detailed guidelines, we report agreement between the first and second author.</p><p>In section 2, we explain and contrast our con- cept of HCUs to existing work. In section 3, we present our new evaluation corpus and explain how we derived it. In section 4, we give details on how system scores for individual HCUs are calcu- lated. In section 5, we analyse agreement of time- line writers on HCUs using two 3-person groups of annotators. We do not present our own algo- rithm for timeline generation here, but we sanity- check our evaluation methodology for a number of baseline timeline generation algorithms (sec- tion 6), where we demonstrate how systems are scored with our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Historical Content Units</head><p>Our event representation is called Historical Con- tent Unit (HCU), which is inspired by the Sum- mary Content Units (SCU) used in the pyra- mid method of Nenkova and Passonneau (2004) (henceforth NP04). Their approach is based on the idea that, due to the inherent subjectivity of summarisation tasks, there is no such thing as a single best gold standard summary. Instead, there are many equally good gold standard summaries. The way to differentiate between a good and a bad system summary is to consider each content unit selected by a system and count how many gold standard summaries it appears in. SCUs that are mentioned by many annotators contribute more to a system's score than less frequently chosen units. We follow this general weighting idea, but our HCUs are more abstract than SCUs, which are tied to a clause in the summary text without any further semantic characterisation by the annotator.</p><p>HCUs are more abstract in that they express an event, i.e. a concrete real-world action (France invades Algeria) or state change (Obama be- comes president), while SCUs are more textual, not semantically defined and generally represent a smaller unit of meaning. State descriptions, opin- ions, wishes, aspirations, intentions and utterances do not constitute events. HCUs normally contain a logical agent (for actions) or a patient (for state changes), plus possibly other semantic roles. The action occurs at a given point in time, not as a continuous (e.g. "species adapt") or regular action ("the sun sets"), and the location of the event has to be delimitable, too (e.g., "in France" is accept- able, but not "on coral reefs"). An example HCU is given in <ref type="figure">Figure 2</ref>. Our HCU definition implies that each historical event is considered equally im- portant. For system evaluation, this means that a system can score at most one point per HCU (ex- actly one point if it gives a perfect rendition of that HCU). This is different to evaluation based on the SCUs in NP04. Their method of linking words to SCUs may lead to a situation where some events are represented by multiple SCUs, and hence are effectively considered more important than others.</p><p>HCU construction proceeds by treating each line in each timeline as a single HCU candidate. If a line contains more than one event (for instance an event plus additional information), we decide what the main event is based on syntactic criteria and discard the additional information. We then have to decide whether two or more surface string descriptions of events by different timeline authors correspond to the same HCU. For this, we follow the method described by van <ref type="bibr" target="#b9">Halteren and Teufel (2003)</ref>. As long as two event descriptions do not contain conflicting information about an event and as long as their timestamps do not disagree, we can safely assume they refer to the same real-world ac- tion and map them to the same HCU, for instance, the two sentences "Nano was elected Prime Minis- ter" and "Party Chairman Nano was elected PM". This matching process results in a number of HCUs for a source text, each with associated sur- face representations by human timeline authors. In the future, these gold standard event realisations could be used to evaluate the surface form of sys- tem timelines. This paper, however, is mainly con- cerned with content selection evaluation.</p><p>We now use the number of surface representa- tions available to assign a weight to each HCU (following NP04), and the following formula is used to calculate the total score for a system:</p><formula xml:id="formula_0">score = i∈HCU s w i ·score i scoremax</formula><p>where score i denotes the individual scores (be- tween 0 and 1) calculated for each HCU i and w i is the number of annotators whose timeline contains that HCU. score max is the sum of the weighted maximum scores of the n most highly weighted HCUs in the pyramid, where n is the desired time- line length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus construction</head><p>To find suitable historical articles for our corpus, we created the intersection of all Wikipedia arti- cles whose title starts with "History of" with the articles in a large collection of timelines described by <ref type="bibr" target="#b0">Bauer et al. (2014)</ref>. Articles with errors in their Wikitext were removed. We also excluded articles that were incomplete, did not contain narrative text or were not chronologically struc- tured. None of these criteria aim at hand-picking well-written articles or articles that describe well- attested topics. The final set consists of 408 articles. We manually grouped these according to their general topic area (GEO-POLITICAL ENTITY, SCIENCE, ...). From these, we select a set of 11 articles representative in terms of length and subject area. For each of the articles in our corpus, we removed the introductions (which tend to contain a summary of the entire article). We then asked 3 annotators per text 1 to produce a his- torical digest with a given maximum length deter- mined by the number of verbs in each article (re- sulting in 25-40 events). For one text, we asked an additional 3 annotators to provide timelines, such that this one text was covered by six annotators. This means that in total, we had 36 combinations of texts and timeline writers.</p><p>Our instructions do not tell the timeline writers how content selection (in the source text) and sur-face realisation (in the timelines produced) should be performed. We merely state that the timeline should strike a balance between mentioning all and only important events and still giving a com- plete account of the time period covered. Anno- tators are also told that each line should contain exactly one event and must be given a timestamp.</p><p>Our approach brings with it the challenge of de- ciding when an algorithm operating on the source text has correctly selected an HCU. We assume that individual words in the text -verbs, nominal- isations and certain other event-like nouns (such as "war") -are associated with the core action or state change expressed by an HCU and that we or a system can find those. While our methodology does not presuppose any particular event definition or event extraction paradigm, we make use of the TimeML project ( <ref type="bibr" target="#b7">Pustejovsky et al., 2003)</ref>, which has provided a substantial body of work on how to extract events and timestamps in the form of TimeML EVENT and TIMEX instances (cf. the TempEval shared tasks <ref type="bibr" target="#b10">(Verhagen et al., 2007;</ref><ref type="bibr" target="#b11">Verhagen et al., 2010;</ref><ref type="bibr" target="#b8">UzZaman et al., 2013)</ref>).</p><p>To construct the links between the HCUs we found in the texts (between 32 and 80 per text 2 ) and the surface text, we first run a publicly avail- able, recent TimeML-based extraction system, TIPSem-B ( <ref type="bibr" target="#b4">Llorens et al., 2010</ref>), over our texts. We then manually annotate each HCU with all surface sentences that express the action or state change described by the HCU, and manually de- cide which TimeML event(s) identified in any such matching sentence express(es) the HCU's content. This results in a 1:n mapping between HCUs and events. For this matching process, we use a detailed set of guidelines. A subset of the 2066 matchings (all matchings for 60 HCUs) was re-annotated independently by the second author; inter-annotator agreement was 87.9%.</p><p>Where the TimeML system failed to recognise what we consider to be the correct event anchor, we manually tagged this event anchor, and we pro- vide this information with our corpus. This is be- cause we want our gold standard to be independent of any particular event extraction package.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Scoring system</head><p>As stated above, the reward a system may receive for a single HCU is capped to one. This is true re- gardless of how many TimeML events represent-ing the HCU are retrieved by the system. We up- hold this principle because we aim to evaluate how many HCUs a system returns, not how many tex- tual elements representing them are retrieved.</p><p>Apart from this global constraint, the general principle is to treat the contribution of each indi- vidual TimeML event additively. For example, if three events have been found to represent a third of the meaning of the HCU, respectively, and two of them are selected by the system, the total score obtained for this HCU will be 2 3 . For some pairs of TimeML events, however, this additive paradigm is not the desired behaviour: The TimeML software sometimes tends to mark two very closely related words, e.g. a verb ("start") and its object ("war"), as events. In this case, we do not want these two events, which we consider to be members of an event group, to con- tribute additively (AND); instead, an OR logic is appropriate, meaning that it is irrelevant whether one or both of the participating events are chosen. The human matcher may impose such constraints between multiple events linked to the same HCU.</p><p>In general, an event group E is a set which may contain individual events e 1 , e 2 , ... and fur- ther subgroups E 1 , E 2 , ... of events. E = {E1, E2, ..., En, e1, e2, ..., en}</p><p>Each event and subgroup in E is associated with a number v ∈ [0, 1] that denotes how much the event or subgroup contributes to the total mean- ing of event group E in context of HCU i; these numbers are set by the human matcher.</p><p>The total score i that a system will receive for an HCU i is calculated using the function S(i, E), where E is an event group that includes all events linked to HCU i by a human:</p><formula xml:id="formula_1">S(i, E) = min(1, E j ∈E vE j · S(i, Ej) + e j ∈E ve j · s(i, ej))</formula><p>S(i, E j ) represents the contribution made by all TimeML events in an event subgroup E j ∈ E, which is again capped to 1 via the recursive def- inition of the score function. s(i, e) is a function for an individual event in group E which, if the system to be evaluated has chosen the event, re- turns one, and zero otherwise: s(i, e) = 1 if the system has chosen event e 0 otherwise</p><p>Note that S(i, E) simplifies to s(i, e) if there is only one event e linked to HCU i (and if v e = 1).</p><p>See <ref type="figure" target="#fig_2">Figure 3</ref> for an example of an HCU along with all TimeML events in a sentence from the source article and their respective contributions to the HCU's meaning (in brackets). Here, the matcher has decided, according to our guidelines, that "began" fully represents the HCU's mean- ing, while "recording" only represents half of the meaning. Importantly, a system selecting both these events will still only receive a total score of 1.0 for this HCU since it is capped to that number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data analysis</head><p>While we do not expect perfect agreement for timeline generation, we hope to observe a pyra- mid form like in NP04; i.e. a situation where few HCUs are chosen by all three annotators, a higher number are chosen by two annotators, and so on. Indeed this was the case for 9 of the documents.</p><p>We also investigated how different the gold standard would have been if a different set of three humans had annotated the texts. We asked three further annotators to create historical digests of one text and then considered all possible splits into two groups of three annotators each. For illustra- tion, <ref type="table" target="#tab_1">Tables 1 and 2</ref> represent two examples out of the 10 possible configurations, showing the num- ber of annotators per group that agreed on HCUs. The grey areas in the tables capture cases where the two annotator teams chose an HCU with the same frequency or where the two frequencies dif- fer only by one. Averaged across the 10 splits, 91.9% of all HCUs fall into this area.</p><p>Consider cell (#0, #0): These are the cases where all six annotators decided that these events are not worthy of being mentioned in the timeline. Since we do not annotate non-selected HCUs, we can only give an approximation for this number based on the average observed HCU frequency per sentence. We do this since these cases should arguably also contribute posivitely to the agree- ment. Using these tables, we calculate Krippen- dorff's α across annotator groups; i.e. each HCU can receive a score between 0 and 3, depending on how many annotators expressed it in their time- line. We use an interval difference function and obtain α = 0.530. This is arguably a non-standard use of α; we provide this number to give the reader a rough idea of the agreement across groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Baseline results</head><p>To illustrate our method, we now present the re- sults of a number of baseline algorithms. We only evaluate the systems' choice of events, not the sur-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action</head><p>The <ref type="table">Southern Semites began recording their history  Agent  the Southern Semites  Patient  their history  Time  800 BC  Surface text</ref> This led (0.0) to contact (0.0) with the Phoenicians and from them , the Southern Semites adopted (0.0) their writing script in 800 BCE and began (1.0) recording (0.5) their history .    face realisation or the timestamps. In the future, a more sophisticated mechanism may be devised which takes these aspects into account as well.</p><p>Our algorithms are listed in <ref type="table" target="#tab_4">Table 3</ref>. They may select individual TimeML events from the source text (1-6), or entire sentences <ref type="bibr">(7)</ref><ref type="bibr">(8)</ref><ref type="bibr">(9)</ref><ref type="bibr">(10)</ref>; in the lat- ter case, all events in the sentences count as se- lected. Some of the baselines select events from anywhere in the article <ref type="bibr">(4,</ref><ref type="bibr">5,</ref><ref type="bibr">6,</ref><ref type="bibr">10)</ref>; others pro- ceed in a round-robin fashion by iteratively select- ing one event or sentence per section (1, 1b, 2, 3, 7, 8, 9, "RR"). For the latter methods, in each iter- ation we can proceed from the top <ref type="figure" target="#fig_1">(1, 1b, 7</ref>) or the bottom (2, 8) of the section, or we randomly select any event or sentence in the section (3, 9). Choos- ing the first or the last events of the entire article (5, 6) does not look like a good method, since the timeline needs to cover the entire timespan. Fi- nally, we examine whether selecting only events with a date in the same sentence has any effect; re- sults can only be calculated over 10 articles since one of the articles does not contain enough such events. The result in <ref type="table" target="#tab_4">Table 3</ref> is therefore marked with a star (*). The results of methods that involve randomly selecting items were averaged over 100 runs. In principle, existing systems such as that by <ref type="bibr" target="#b1">Chasin et al. (2013)</ref> could also be evaluated with our method, but we do not do this here.  Algorithms inspired by the well-established "first n words" baseline for summarisation of newswire articles perform best here too, when ap- plied on a section level <ref type="figure" target="#fig_1">(1, 1b, 7</ref>). All these al- gorithms perform significantly better when com- pared to any of the other algorithms (2-6, 8-10); statistical significance is measured for each pair of algorithms at α = 0.05 using the Wilcoxon signed-rank test (p &lt; 0.05). This suggests that im- portant events tend to be placed at the beginning of a section. Selecting the first events from the entire article (5) produces worse results than selecting the first events from each section. The best results are obtained when selecting only events with dates in their proximity (1b); however, this result is based only on 10 of the 11 articles, and the differ- ence to algorithm 1 is not significant (p = 0.1391).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have introduced a novel methodology for eval- uating timeline generation algorithms based on deep semantic content units, including a new cor- pus of 36 human-written timelines and associated HCUs. Our evaluation focuses on a deeper model of meaning (based on events) rather than n-gram overlap, and provides links between each HCU and the source text. This allows us to subse- quently evaluate an unlimited number of system summaries without any further cost, rationalising the evaluation of timeline construction algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>...) In the 1997 unrest in Albania the general elections of June 1997 brought the Socialists and their allies to power. President Berisha resigned from his post, and Socialists elected Rexhep Meidani as president of Al- bania. Albanian Socialist Party Chairman Fatos Nano was elected Prime Minister, (...)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Extract from a Wikipedia article and two lines of a corresponding timeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example HCU with links into the surface text (the HCU's location is not given)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Best split (94.1% in grey area) 

Team 2 
#0 
#1 
#2 
#3 

Team 1 

#0 
87 
17 
6 
0 
#1 
20 
9 
6 
3 
#2 
8 
14 
5 
1 
#3 
0 
2 
6 
3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Worst split (89.8% in grey area) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Baseline results (average pyramid 
scores); the result with a * is based on 10 articles 

</table></figure>

			<note place="foot" n="1"> The annotators recruited included both computational linguists and students in higher education.</note>

			<note place="foot" n="2"> We obtain 100 HCUs for the text annotated by 6 humans.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to Identify Historical Figures for Timeline Creation from Wikipedia Articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Informatics-SocInfo 2014 International Workshops</title>
		<editor>Luca Maria Aiello and Daniel A. McFarland</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-11-11" />
			<biblScope unit="volume">8852</biblScope>
			<biblScope unit="page" from="234" to="243" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Extracting and Displaying Temporal and Geospatial Entities from Articles on Historical Events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Chasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daryl</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Witmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jugal</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="page" from="403" to="426" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Query Based Event Extraction Along a Timeline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoong Keok</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;04</title>
		<meeting>the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;04<address><addrLine>Sheffield, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL04 Workshop</title>
		<editor>Stan Szpakowicz Marie-Francine Moens</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating CRFs and Semantic Roles in TempEval-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estela</forename><surname>Saquete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval &apos;10</title>
		<meeting>the 5th International Workshop on Semantic Evaluation, SemEval &apos;10<address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="284" to="291" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluating Content Selection in Summarization: The Pyramid Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL 2004: Main Proceedings</title>
		<editor>Daniel Marcu Susan Dumais and Salim Roukos</editor>
		<meeting><address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-05-02" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ranking Multidocument Event Descriptions for Building Thematic Timelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiem-Hieu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Moriceau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1208" to="1217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TimeML: Robust Specification of Event and Temporal Expressions in Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><forename type="middle">M</forename><surname>Castaño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">J</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Setzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">New Directions in Question Answering, Papers from 2003 AAAI Spring Symposium</title>
		<editor>Mark T. Maybury</editor>
		<meeting><address><addrLine>Stanford, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="28" to="34" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Examining the Consensus Between Human Summaries: Initial Experiments with Factoid Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Hans Van Halteren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teufel</surname></persName>
		</author>
		<idno>HLT-NAACL-DUC &apos;03</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL 03 on Text Summarization Workshop</title>
		<meeting>the HLT-NAACL 03 on Text Summarization Workshop<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="57" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 15: TempEval Temporal Relation Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval &apos;07</title>
		<meeting>the 4th International Workshop on Semantic Evaluations, SemEval &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SemEval-2010 Task 13: TempEval-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evolutionary Timeline Summarization: A Balanced Optimization Framework via Iterative Substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11</title>
		<meeting>the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;11<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="745" to="754" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
