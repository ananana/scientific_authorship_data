<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NeuralREG: An end-to-end approach to referring expression generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 15-20, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><forename type="middle">Castro</forename><surname>Ferreira</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Tilburg center for Cognition and Communication (TiCC)</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Moussallem</surname></persName>
							<email>moussallem@informatik.uni-leipzig.de</email>
							<affiliation key="aff1">
								<orgName type="laboratory">AKSW Research Group</orgName>
								<orgName type="institution">University of Leipzig</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Data Science Group</orgName>
								<orgName type="institution">University of Paderborn</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akos</forename><surname>Kádár</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Tilburg center for Cognition and Communication (TiCC)</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Wubben</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Tilburg center for Cognition and Communication (TiCC)</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Krahmer</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Tilburg center for Cognition and Communication (TiCC)</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NeuralREG: An end-to-end approach to referring expression generation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1959" to="1969"/>
							<date type="published">July 15-20, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1959</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Traditionally, Referring Expression Generation (REG) models first decide on the form and then on the content of references to discourse entities in text, typically relying on features such as salience and grammatical function. In this paper, we present a new approach (NeuralREG), relying on deep neural networks, which makes decisions about form and content in one go without explicit feature extraction. Using a delexicalized version of the WebNLG corpus, we show that the neu-ral model substantially improves over two strong baselines. Data and models are publicly available 1 .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural Language Generation (NLG) is the task of automatically converting non-linguistic data into coherent natural language text <ref type="bibr" target="#b30">(Reiter and Dale, 2000;</ref><ref type="bibr" target="#b12">Gatt and Krahmer, 2018)</ref>. Since the in- put data will often consist of entities and the re- lations between them, generating references for these entities is a core task in many NLG sys- tems ( <ref type="bibr" target="#b8">Dale and Reiter, 1995;</ref><ref type="bibr" target="#b21">Krahmer and van Deemter, 2012)</ref>. Referring Expression Genera- tion (REG), the task responsible for generating these references, is typically presented as a two- step procedure. First, the referential form needs to be decided, asking whether a reference at a given point in the text should assume the form of, for ex- ample, a proper name ("Frida Kahlo"), a pronoun ("she") or description ("the Mexican painter"). In addition, the REG model must account for the dif- ferent ways in which a particular referential form can be realized. For example, both "Frida" and "Kahlo" are name-variants that may occur in a text, and she can alternatively also be described as, say, "the famous female painter".</p><p>Most of the earlier REG approaches focus ei- ther on selecting referential form ( <ref type="bibr" target="#b28">Orita et al., 2015;</ref><ref type="bibr" target="#b4">Castro Ferreira et al., 2016)</ref>, or on select- ing referential content, typically zooming in on one specific kind of reference such as a pronoun (e.g., <ref type="bibr" target="#b17">Henschel et al., 2000;</ref><ref type="bibr" target="#b2">Callaway and Lester, 2002</ref>), definite description (e.g., <ref type="bibr" target="#b7">Dale and Haddock, 1991;</ref><ref type="bibr" target="#b8">Dale and Reiter, 1995)</ref> or proper name generation (e.g., <ref type="bibr" target="#b32">Siddharthan et al., 2011;</ref><ref type="bibr" target="#b9">van Deemter, 2016;</ref><ref type="bibr" target="#b5">Castro Ferreira et al., 2017b</ref>). Instead, in this paper, we propose NeuralREG: an end-to-end approach addressing the full REG task, which given a number of entities in a text, pro- duces corresponding referring expressions, simul- taneously selecting both form and content. Our approach is based on neural networks which gen- erate referring expressions to discourse entities re- lying on the surrounding linguistic context, with- out the use of any feature extraction technique.</p><p>Besides its use in traditional pipeline NLG sys- tems <ref type="bibr" target="#b30">(Reiter and Dale, 2000</ref>), REG has also be- come relevant in modern "end-to-end" NLG ap- proaches, which perform the task in a more inte- grated manner (see e.g. <ref type="bibr" target="#b20">Konstas et al., 2017;</ref><ref type="bibr" target="#b11">Gardent et al., 2017b</ref>). Some of these approaches have recently focused on inputs which references to entities are delexicalized to general tags (e.g., ENTITY-1, ENTITY-2) in order to decrease data sparsity. Based on the delexicalized input, the model generates outputs which may be likened to templates in which references to the discourse entities are not realized (as in "The ground of ENTITY-1 is located in ENTITY-2.").</p><p>While our approach, dubbed as NeuralREG, is compatible with different applications of REG models, in this paper, we concentrate on the last one, relying on a specifically constructed set of 78,901 referring expressions to 1,501 entities in the context of the semantic web, derived from a (delexicalized) version of the WebNLG corpus ( <ref type="bibr">Gardent et al., 2017a,b)</ref>. Both this data set and the model will be made publicly available. We compare NeuralREG against two baselines in an automatic and human evaluation, showing that the integrated neural model is a marked improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>In recent years, we have seen a surge of inter- est in using (deep) neural networks for a wide range of NLG-related tasks, as the generation of (first sentences of) Wikipedia entries ( <ref type="bibr" target="#b22">Lebret et al., 2016)</ref>, poetry <ref type="bibr" target="#b36">(Zhang and Lapata, 2014)</ref>, and texts from abstract meaning representations (e.g., <ref type="bibr" target="#b20">Konstas et al., 2017;</ref><ref type="bibr" target="#b3">Castro Ferreira et al., 2017a</ref>). However, the usage of deep neural networks for REG has remained limited and we are not aware of any other integrated, end-to-end model for gen- erating referring expressions in discourse.</p><p>There is, however, a lot of earlier work on selecting the form and content of referring ex- pressions, both in psycholinguistics and in com- putational linguistics. In psycholinguistic mod- els of reference, various linguistic factors have been proposed as influencing the form of referen- tial expressions, including cognitive status <ref type="bibr" target="#b16">(Gundel et al., 1993</ref>), centering ( <ref type="bibr">Grosz et al., 1995)</ref> and information density <ref type="bibr" target="#b19">(Jaeger, 2010)</ref>. In models such as these, notions like salience play a central role, where it is assumed that entities which are salient in the discourse are more likely to be re- ferred to using shorter referring expressions (like a pronoun) than less salient entities, which are typi- cally referred to using longer expressions (like full proper names).</p><p>Building on these ideas, many REG models for generating references in texts also strongly rely on the concept of salience and factors contributing to it. <ref type="bibr" target="#b30">Reiter and Dale (2000)</ref> for instance, discussed a straightforward rule-based method based on this notion, stating that full proper names can be used for initial references, typically less salient than subsequent references, which, according to the study, can be realized by a pronoun in case there is no mention to any other entity of same person, gender and number between the reference and its antecedents. More recently, Castro <ref type="bibr" target="#b4">Ferreira et al. (2016)</ref> proposed a data-driven, non-deterministic model for generating referential forms, taking into account salience features extracted from the dis- course such as grammatical position, givenness and recency of the reference. Importantly, these models do not specify which contents a particu- lar reference, be it a proper name or description, should have. To this end, separate models are typ- ically used, including, for example, <ref type="bibr" target="#b8">Dale and Reiter (1995)</ref> for generating descriptions, and <ref type="bibr" target="#b32">Siddharthan et al. (2011);</ref><ref type="bibr" target="#b9">van Deemter (2016)</ref> for proper names.</p><p>Of course, when texts are generated in practical settings, both form and content need to be cho- sen. This was the case, for instance, in the GREC shared task ( <ref type="bibr" target="#b1">Belz et al., 2010)</ref>, which aimed to evaluate models for automatically generated refer- ring expressions grounded in discourse. The input for the models were texts in which the referring expressions to the topic of the relevant Wikipedia entry were removed and appropriate references throughout the text needed to be generated (by se- lecting, for each gap, from a list of candidate refer- ring expressions of different forms and with dif- ferent contents). Some participating systems ap- proached this with traditional pipelines for select- ing referential form, followed by referential con- tent, while others proposed more integrated meth- ods. More details about the models can be seen on <ref type="bibr" target="#b1">Belz et al. (2010)</ref>.</p><p>In sum, existing REG models for text genera- tion strongly rely on abstract features such as the salience of a referent for deciding on the form or content of a referent. Typically, these features are extracted automatically from the context, and en- gineering relevant ones can be complex. More- over, many of these models only address part of the problem, either concentrating on the choice of referential form or on deciding on the con- tents of, for example, proper names or definite de- scriptions. In contrast, we introduce NeuralREG, an end-to-end approach based on neural networks which generates referring expressions to discourse entities directly from a delexicalized/wikified text fragment, without the use of any feature extraction technique. Below we describe our model in more detail, as well as the data on which we develop and evaluate it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and processing 3.1 WebNLG corpus</head><p>Our data is based on the WebNLG corpus ( <ref type="bibr" target="#b10">Gardent et al., 2017a</ref>), which is a parallel resource ini-  tially released for the eponymous NLG challenge. In this challenge, participants had to automatically convert non-linguistic data from the Semantic Web into a textual format ( <ref type="bibr" target="#b11">Gardent et al., 2017b</ref>). The source side of the corpus are sets of Resource De- scription Framework (RDF) triples. Each RDF triple is formed by a Subject, Predicate and Ob- ject, where the Subject and Object are constants or Wikipedia entities, and predicates represent a relation between these two elements in the triple. The target side contains English texts, obtained by crowdsourcing, which describe the source triples. <ref type="figure" target="#fig_0">Figure 1</ref> depicts an example of a set of 5 RDF triples and the corresponding text. The corpus consists of 25,298 texts describing 9,674 sets of up to 7 RDF triples (an average of 2.62 texts per set) in 15 domains ( <ref type="bibr" target="#b11">Gardent et al., 2017b</ref>). In order to be able to train and evalu- ate our models for referring expression generation (the topic of this study), we produced a delexical- ized version of the original corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Delexicalized WebNLG</head><p>We delexicalized the training and development parts of the WebNLG corpus by first automatically mapping each entity in the source representation to a general tag. All entities that appear on the left and right side of the triples were mapped to AGENTs and PATIENTs, respectively. Entities which appear on both sides in the relations of a set were represented as BRIDGEs. To distinguish different AGENTs, PATIENTs and BRIDGEs in a set, an ID was given to each entity of each kind (PATIENT-1, PATIENT-2, etc.). Once all entities in the text were mapped to different roles, the first two authors of this study manually replaced the re- ferring expressions in the original target texts by their respective tags. <ref type="figure" target="#fig_1">Figure 2</ref> shows the entity mapping and the delexicalized template for the ex- ample in <ref type="figure" target="#fig_0">Figure 1</ref> in its versions representing the references with general tags and Wikipedia IDs.</p><p>We delexicalized 20,198 distinct texts describ- ing 7,812 distinct sets of RDF triples, resulting in 16,628 distinct templates. While this dataset (which we make available) has various uses, we used it to extract a collection of referring expres- sions to Wikipedia entities in order to evaluate how well our REG model can produce references to entities throughout a (small) text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Referring expression collection</head><p>Using the delexicalized version of the WebNLG corpus, we automatically extracted all referring expressions by tokenizing the original and delex- icalized versions of the texts and then finding the non overlapping items. For instance, by process- ing the text in <ref type="figure" target="#fig_0">Figure 1</ref> and its delexicalized tem- plate in <ref type="figure" target="#fig_1">Figure 2</ref>, we would extract referring ex- pressions like "108 St Georges Terrace" and "It" to AGENT-1, 108 St Georges Terrace , "Perth" to BRIDGE-1, Perth , "Australia" to PATIENT- 1, Australia and so on.</p><p>Once all texts were processed and the referring expressions extracted, we filtered only the ones re- ferring to Wikipedia entities, removing references to constants like dates and numbers, for which no references are generated by the model. In total, the final version of our dataset contains 78,901 referring expressions to 1,501 Wikipedia entities, in which 71.4% (56,321) are proper names, 5.6% (4,467) pronouns, 22.6% (17,795) descriptions and 0.4% (318) demonstrative referring expres- sions. We split this collection in training, develop- ing and test sets, totaling 63,061, 7,097 and 8,743 referring expressions in each one of them.</p><p>Each instance of the final dataset consists of a truecased tokenized referring expression, the tar- get entity (distinguished by its Wikipedia ID), and the discourse context preceding and follow- ing the relevant reference (we refer to these as the pre-and pos-context). Pre-and pos-contexts are the lowercased, tokenized and delexicalized <ref type="table">Tag  Entity  AGENT-1</ref> 108 St Georges Terrace BRIDGE-1 Perth PATIENT-1 Australia PATIENT-2 1988@year PATIENT-3 "120 million (Australian dollars)"@USD PATIENT-4 50@Integer</p><p>AGENT-1 was completed in PATIENT-2 in BRIDGE-1 , PATIENT-1 . AGENT-1 has a total of PATIENT-4 floors and cost PATIENT-3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>↓ W iki</head><p>108 St Georges Terrace was completed in 1988 in Perth , Australia . 108 St Georges Terrace has a total of 50 floors and cost 20 million (Australian dollars) . pieces of text before and after the target refer- ence. References to other discourse entities in the pre-and pos-contexts are represented by their Wikipedia ID, whereas constants (numbers, dates) are represented by a one-word ID removing quotes and replacing white spaces with underscores (e.g., 120 million (Australian dollars) for "120 million (Australian dollars)" in <ref type="figure" target="#fig_1">Figure 2</ref>). Although the references to discourse entities are represented by general tags in a delexicalized tem- plate produced in the generation process (AGENT- 1, BRIDGE-1, etc.), for the purpose of disam- biguation, NeuralREG's inputs have the references represented by the Wikipedia ID of their entities. In this context, it is important to observe that the conversion of the general tags to the Wikipedia IDs can be done in constant time during the gen- eration process, since their mapping, like the first representation in <ref type="figure" target="#fig_1">Figure 2</ref>, is the first step of the process. In the next section, we show in detail how NeuralREG models the problem of generat- ing a referring expression to a discourse entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NeuralREG</head><p>NeuralREG aims to generate a referring expres- sion y = {y 1 , y 2 , ..., y T } with T tokens to refer to a target entity token x (wiki) given a discourse pre- context X (pre) = {x } with m and l tokens, respectively. The model is implemented as a multi-encoder, attention- decoder network with bidirectional <ref type="bibr" target="#b31">(Schuster and Paliwal, 1997</ref>) Long-Short Term Memory Lay- ers (LSTM) <ref type="bibr" target="#b18">(Hochreiter and Schmidhuber, 1997)</ref> sharing the same input word-embedding matrix V , as explained further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Context encoders</head><p>Our model starts by encoding the pre-and pos- contexts with two separate bidirectional LSTM encoders <ref type="bibr" target="#b31">(Schuster and Paliwal, 1997;</ref><ref type="bibr" target="#b18">Hochreiter and Schmidhuber, 1997</ref>). These modules learn feature representations of the text surrounding the target entity x (wiki) , which are used for the re- ferring expression generation. The pre-context</p><formula xml:id="formula_0">X (pre) = {x (pre) 1 , x (pre) 2 , ..., x (pre)</formula><p>m } is represented by forward and backward hidden-state vectors ]. Finally, the encoding of target entity x (wiki) is sim- ply its entry in the shared input word-embedding matrix V wiki .</p><formula xml:id="formula_1">( − → h (pre) 1 , · · · , − → h (pre) m ) and ( ← − h (pre) 1 , · · · , ← − h (pre) m ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Decoder</head><p>The referring expression generation module is an LSTM decoder implemented in 3 different ver- sions: Seq2Seq, CAtt and HierAtt. All de- coders at each timestep i of the generation process take as input features their previous state s i−1 , the target entity-embedding V wiki , the embedding of the previous word of the referring expression V y i−1 and finally the summary vector of the pre-and pos- contexts c i . The difference between the decoder variations is the method to compute c i .</p><p>Seq2Seq models the context vector c i at each timestep i concatenating the pre-and pos-context annotation vectors averaged over time:</p><formula xml:id="formula_2">ˆ h (pre) = 1 N N i h (pre) i<label>(1)</label></formula><formula xml:id="formula_3">ˆ h (pos) = 1 N N i h (pos) i (2) ci = [ ˆ h (pre) , ˆ h (pos) ]<label>(3)</label></formula><p>CAtt is an LSTM decoder augmented with an attention mechanism ( <ref type="bibr" target="#b0">Bahdanau et al., 2015</ref>) over the pre-and pos-context encodings, which is used to compute c i at each timestep. We compute ener- gies e </p><formula xml:id="formula_4">e (k) ij = v (k)T a tanh(W (k) a si−1 + U (k) a h (k) j )<label>(4)</label></formula><formula xml:id="formula_5">α (k) ij = exp(e (k) ij ) N n=1 exp(e (k) in )<label>(5)</label></formula><p>In general, the attention probability α </p><formula xml:id="formula_6">c (k) i = N j=1 α (k) ij h (k) j<label>(6)</label></formula><p>To combine c   <ref type="bibr">(k ∈ [pre, pos]</ref>).</p><note type="other">(k) b and U (k) b as well as attention vectors v (k) b trained parameters</note><formula xml:id="formula_7">e (k) i = v (k)T b tanh(W (k) b si−1 + U (k) b c (k) i )<label>(7)</label></formula><formula xml:id="formula_8">β (k) i = exp(e (k) i ) n exp(e (n) i ) (8) ci = k β (k) i U (k) b c (k) i (9)</formula><p>Decoding Given the summary-vector c i , the em- bedding of the previous referring expression to- ken V y i−1 , the previous decoder state s i−1 and the entity-embedding V wiki , the decoders predict their next state which later is used to compute a prob- ability distribution over the tokens in the output vocabulary for the next timestep as Equations 10 and 11 show.</p><formula xml:id="formula_9">si = Φ dec (si−1, [ci, Vy i−1 , V wiki ])<label>(10)</label></formula><formula xml:id="formula_10">p(y i |y &lt;i , X (pre) ,x (wiki) , X (pos) ) = softmax(W c s i + b)<label>(11)</label></formula><p>In Equation 10, s 0 and c 0 are zero-initialized vectors. In order to find the referring expression y that maximizes the likelihood in Equation 11, we apply a beam search with length normalization with α = 0.6 (Wu et al., 2016):</p><formula xml:id="formula_11">lp(y) = (5 + |y|) α (5 + 1) α<label>(12)</label></formula><p>The decoder is trained to minimize the negative log likelihood of the next token in the target refer- ring expression:</p><formula xml:id="formula_12">J(θ) = − i log p(yi|y&lt;i, X (pre) , x (wiki) , X (pos) ) (13)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models for Comparison</head><p>We compared the performance of NeuralREG against two baselines: OnlyNames and a model based on the choice of referential form method of Castro <ref type="bibr" target="#b4">Ferreira et al. (2016)</ref>, dubbed Ferreira.</p><p>OnlyNames is motivated by the similarity among the Wikipedia ID of an element and a proper name reference to it. This method refers to each entity by their Wikipedia ID, replacing each underscore in the ID for whitespaces (e.g., Appleton International Airport to "Appleton In- ternational Airport").</p><p>Ferreira works by first choosing whether a ref- erence should be a proper name, pronoun, descrip- tion or demonstrative. The choice is made by a Naive Bayes method as Equation 14 depicts.</p><formula xml:id="formula_13">P (f | X) ∝ P (f ) x∈X P (x | f ) f ∈F P (f ) x∈X P (x | f )<label>(14)</label></formula><p>The method calculates the likelihood of each referential form f given a set of features X, con- sisting of grammatical position and information status (new or given in the text and sentence). Once the choice of referential form is made, the most frequent variant is chosen in the training cor- pus given the referent, syntactic position and in- formation status. In case a referring expression for a wiki target is not found in this way, a back- off method is applied by removing one factor at a time in the following order: sentence information status, text information status and grammatical po- sition. Finally, if a referring expression is not found in the training set for a given entity, the same method as OnlyNames is used. Regarding the fea- tures, syntactic position distinguishes whether a reference is the subject, object or subject deter- miner (genitive) in a sentence. Text and sentence information statuses mark whether a reference is a initial or a subsequent mention to an entity in the text and the sentence, respectively. All features were extracted automatically from the texts using the sentence tokenizer and dependency parser of Stanford CoreNLP ( <ref type="bibr" target="#b25">Manning et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Automatic evaluation</head><p>Data We evaluated our models on the training, development and test referring expression sets de- scribed in Section 3.3.</p><p>Metrics We compared the referring expressions produced by the evaluated models with the gold- standards ones using accuracy and String Edit Dis- tance <ref type="bibr" target="#b23">(Levenshtein, 1966)</ref>. Since pronouns are highlighted as the most likely referential form to be used when a referent is salient in the discourse, as argued in the introduction, we also computed pronoun accuracy, precision, recall and F1-score in order to evaluate the performance of the mod- els for capturing discourse salience. Finally, we lexicalized the original templates with the refer- ring expressions produced by the models and com- pared them with the original texts in the corpus using accuracy and BLEU score ( <ref type="bibr" target="#b29">Papineni et al., 2002</ref>) as a measure of fluency. Since our model does not handle referring expressions for constants (dates and numbers), we just copied their source version into the template.</p><p>Post-hoc McNemar's and Wilcoxon signed ranked tests adjusted by the Bonferroni method were used to test the statistical significance of the models in terms of accuracy and string edit dis- tance, respectively. To test the statistical signifi- cance of the BLEU scores of the models, we used a bootstrap resampling together with an approxi- mate randomization method (Clark et al., 2011) 2 .</p><p>Settings NeuralREG was implemented using Dynet ( <ref type="bibr" target="#b27">Neubig et al., 2017</ref>). Source and target word embeddings were 300D each and trained jointly with the model, whereas hidden units were 512D for each direction, totaling 1024D in the bidirection layers. All non-recurrent matrices were initialized following the method of <ref type="bibr" target="#b13">Glorot and Bengio (2010)</ref>. Models were trained using stochastic gradient descent with Adadelta <ref type="bibr" target="#b35">(Zeiler, 2012)</ref> and mini-batches of size 40. We ran each model for 60 epochs, applying early stop- ping for model selection based on accuracy on the development set with patience of 20 epochs. For each decoding version (Seq2Seq, CAtt and HierAtt), we searched for the best combination of drop-out probability of 0.2 or 0.3 in both the encoding and decoding layers, using beam search with a size of 1 or 5 with predictions up to 30 tokens or until 2 ending tokens were predicted (EOS). The results described in the next section were obtained on the test set by the NeuralREG version with the highest accuracy on the develop- ment set over the epochs.</p><p>Results <ref type="table">Table 1</ref> summarizes the results for all models on all metrics on the test set and <ref type="table" target="#tab_2">Table 2</ref> depicts a text example lexicalized by each model. The first thing to note in the results of the first table is that the baselines in the top two rows performed quite strong on this task, generating more than half of the referring expressions exactly as in the gold- standard. The method based on Castro Ferreira et al. (2016) performed statistically better than On- lyNames on all metrics due to its capability, albeit to a limited extent, to predict pronominal refer- ences (which OnlyNames obviously cannot).</p><p>We reported results on the test set for Neu- ralREG+Seq2Seq and NeuralREG+CAtt using  <ref type="table">Table 1</ref>: (1) Accuracy (Acc.) and String Edit Distance (SED) results in the prediction of all referring expressions; (2) Accuracy (Acc.), Precision (Prec.), Recall (Rec.) and F-Score results in the prediction of pronominal forms; and (3) Accuracy (Acc.) and BLEU score results of the texts with the generated referring expressions. Rankings were determined by statistical significance. dropout probability 0.3 and beam size 5, and Neu- ralREG+HierAtt with dropout probability of 0.3 and beam size of 1 selected based on the high- est accuracy on the development set. Importantly, the three NeuralREG variant models statistically outperformed the two baseline systems. They achieved BLEU scores, text and referential accu- racies as well as string edit distances in the range of 79.01-79.39, 28%-30%, 73%-74% and 2.25- 2.36, respectively. This means that NeuralREG predicted 3 out of 4 references completely cor- rect, whereas the incorrect ones needed an average of 2 post-edition operations in character level to be equal to the gold-standard. When considering the texts lexicalized with the referring expressions produced by NeuralREG, at least 28% of them are similar to the original texts. Especially noteworthy was the score on pronoun accuracy, indicating that the model was well capable of predicting when to generate a pronominal reference in our dataset.</p><p>The results for the different decoding meth- ods for NeuralREG were similar, with the Neu- ralREG+CAtt performing slightly better in terms of the BLEU score, text accuracy and String Edit Distance.</p><p>The more complex Neural- REG+HierAtt yielded the lowest results, even though the differences with the other two models were small and not even statistically significant in many of the cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Human Evaluation</head><p>Complementary to the automatic evaluation, we performed an evaluation with human judges, com- paring the quality judgments of the original texts to the versions generated by our various models.</p><p>Material We quasi-randomly selected 24 in- stances from the delexicalized version of the WebNLG corpus related to the test part of the re- ferring expression collection. For each of the se- lected instances, we took into account its source triple set and its 6 target texts: one original (ran- domly chosen) and its versions with the referring expressions generated by each of the 5 models in- troduced in this study (two baselines, three neural models). Instances were chosen following 2 crite- ria: the number of triples in the source set (ranging from 2 to 7) and the differences between the target texts.</p><p>For each size group, we randomly selected 4 in- stances (of varying degrees of variation between the generated texts) giving rise to 144 trials (= 6 triple set sizes * 4 instances * 6 text versions), each consisting of a set of triples and a target text describing it with the lexicalized referring expres- sions highlighted in yellow.</p><p>Method The experiment had a latin-square de- sign, distributing the 144 trials over 6 different lists such that each participant rated 24 trials, one for each of the 24 corpus instances, making sure that participants saw equal numbers of triple set sizes and generated versions. Once introduced to a trial, the participants were asked to rate the flu- ency ("does the text flow in a natural, easy to read manner?"), grammaticality ("is the text grammat- ical (no spelling or grammatical errors)?") and clarity ("does the text clearly express the data?") of each target text on a 7-Likert scale, focussing on the highlighted referring expressions. The ex- periment is available on the website of the author 3 .</p><p>Participants We recruited 60 participants, 10 per list, via Mechanical Turk. Their average age was 36 years and 27 of them were females. The majority declared themselves native speakers of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Text</head><p>OnlyNames alan shepard was born in new hampshire on 1923-11-18 . before alan shepard death in california alan shepard had been awarded distinguished service medal (united states navy) an award higher than department of commerce gold medal .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ferreira</head><p>alan shepard was born in new hampshire on 1923-11-18 . before alan shepard death in california him had been awarded distinguished service medal an award higher than department of commerce gold medal .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Seq2Seq</head><p>alan shepard was born in new hampshire on 1923-11-18 . before his death in california him had been awarded the distinguished service medal by the united states navy an award higher than the department of commerce gold medal .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CAtt</head><p>alan shepard was born in new hampshire on 1923-11-18 . before his death in california he had been awarded the distinguished service medal by the us navy an award higher than the department of commerce gold medal .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HierAtt</head><p>alan shephard was born in new hampshire on 1923-11-18 . before his death in california he had been awarded the distinguished service medal an award higher than the department of commerce gold medal .</p><p>Original alan shepard was born in new hampshire on 18 november 1923 . before his death in california he had been awarded the distinguished service medal by the us navy an award higher than the department of commerce gold medal .  English (44), while 14 and 2 self-reported as fluent or having a basic proficiency, respectively.</p><p>Results <ref type="table" target="#tab_3">Table 3</ref> summarizes the results. Inspec- tion of the Table reveals a clear pattern: all three neural models scored higher than the baselines on all metrics, with especially NeuralREG+CAtt ap- proaching the ratings for the original sentences, although -again -differences between the neu- ral models were small. Concerning the size of the triple sets, we did not find any clear pattern.</p><p>To test the statistical significance of the pair- wise comparisons, we used the Wilcoxon signed- rank test corrected for multiple comparisons us- ing the Bonferroni method. Different from the automatic evaluation, the results of both base- lines were not statistically significant for the three metrics. In comparison with the neural models, NeuralREG+CAtt significantly outperformed the baselines in terms of fluency, whereas the other comparisons between baselines and neural models were not statistically significant. The results for the 3 different decoding methods of NeuralREG also did not reveal a significant difference. Finally, the original texts were rated significantly higher than both baselines in terms of the three met- rics, also than NeuralREG+Seq2Seq and Neu- ralREG+HierAtt in terms of fluency, and than NeuralREG+Seq2Seq in terms of clarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>This study introduced NeuralREG, an end-to-end approach based on neural networks which tack- les the full Referring Expression Generation pro- cess. It generates referring expressions for dis- course entities by simultaneously selecting form and content without any need of feature extraction techniques. The model was implemented using an encoder-decoder approach where a target referent and its surrounding linguistic contexts were first encoded and combined into a single vector repre- sentation which subsequently was decoded into a referring expression to the target, suitable for the specific discourse context. In an automatic evalua- tion on a collection of 78,901 referring expressions to 1,501 Wikipedia entities, the different versions of the model all yielded better results than the two (competitive) baselines. Later in a complementary human evaluation, the texts with referring expres- sions generated by a variant of our novel model were considered statistically more fluent than the texts lexicalized by the two baselines.</p><p>Data The collection of referring expressions used in our experiments was extracted from a novel, delexicalized and publicly available version of the WebNLG corpus ( <ref type="bibr">Gardent et al., 2017a,b)</ref>, where the discourse entities were replaced with general tags for decreasing the data sparsity. Be- sides the REG task, these data can be useful for many other tasks related to, for instance, the NLG process <ref type="bibr" target="#b30">(Reiter and Dale, 2000;</ref><ref type="bibr" target="#b12">Gatt and Krahmer, 2018)</ref> and <ref type="bibr">Wikification (Moussallem et al., 2017)</ref>.</p><p>Baselines We introduced two strong baselines which generated roughly half of the referring ex- pressions identical to the gold standard in an auto- matic evaluation. These baselines performed rela- tively well because they frequently generated full names, which occur often for our wikified refer- ences. However, they performed poorly when it came to pronominalization, which is an important ingredient for fluent, coherent text. OnlyNames, as the name already reveals, does not manage to generate any pronouns. However, the approach of Castro <ref type="bibr" target="#b4">Ferreira et al. (2016)</ref> also did not per- form well in the generation of pronouns, revealing a poor capacity to detect highly salient entities in a text.</p><p>NeuralREG was implemented with 3 differ- ent decoding architectures: Seq2Seq, CAtt and HierAtt.</p><p>Although all the versions performed relatively similar, the concatenative- attention (CAtt) version generated the closest re- ferring expressions from the gold-standard ones and presented the highest textual accuracy in the automatic evaluation. The texts lexicalized by this variant were also considered statistically more flu- ent than the ones generated by the two proposed baselines in the human evaluation.</p><p>Surprisingly, the most complex variant (HierAtt) with a hierarchical-attention mech- anism gave lower results than CAtt, producing lexicalized texts which were rated as less fluent than the original ones and not significantly more fluent from the ones generated by the baselines. This result appears to be not consistent with the findings of Libovick´y <ref type="bibr" target="#b24">Libovick´y and Helcl (2017)</ref>, who reported better results on multi-modal machine translation with hierarchical-attention as opposed to the flat variants ( <ref type="bibr" target="#b33">Specia et al., 2016)</ref>.</p><p>Finally, our NeuralREG variant with the lowest results were our 'vanilla' sequence-to-sequence (Seq2Seq), whose the lexicalized texts were sig- nificantly less fluent and clear than the original ones. This shows the importance of the attention mechanism in the decoding step of NeuralREG in order to generate fine-grained referring expres- sions in discourse.</p><p>Conclusion We introduced a deep learning model for the generation of referring expressions in discourse texts. NeuralREG decides both on referential form and on referential content in an integrated, end-to-end approach, without using ex- plicit features. Using a new delexicalized version of the WebNLG corpus (made publicly available), we showed that the neural model substantially im- proves over two strong baselines in terms of accu- racy of the referring expressions and fluency of the lexicalized texts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of a set of triples (top) and corresponding text (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Mapping between tags and entities for the related delexicalized/wikified templates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>The final annotation vector for each encoding timestep t is obtained by the concatenation of the forward and backward representations h</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>pre) ij and e (pos) ij between encoder states h (pre) i and h (post) i and decoder state s i−1 . These scores are normalized through the application of the soft- max function to obtain the final attention proba- bility α (pre) ij and α (post) ij . Equations 4 and 5 sum- marize the process with k ranging over the two encoders (k ∈ [pre, pos]), being the projection matrices W (k) a and U (k) a and attention vectors v (k) a trained parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>ij deter- mines the amount of contribution of the jth to- ken of k-context in the generation of the ith to- ken of the referring expression. In each decoding step i, a final summary-vector for each context c (k) i is computed by summing the encoder states h (k) j weighted by the attention probabilities α (k) i :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>HierAtt implements a second attention mech- anism inspired by Libovick´yLibovick´y and Helcl (2017) in order to generate attention weights for the pre-and pos-context summary-vectors c (pre) i and c (pos) i in- stead of concatenate them. Equations 7, 8 and 9 depict the process, being the projection matrices</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>W</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Example of text with references lexicalized by each model.</head><label>2</label><figDesc></figDesc><table>Fluency Grammar Clarity 

OnlyNames 
4.74 C 
4.68 B 
4.90 B 
Ferreira 
4.74 C 
4.58 B 
4.93 B 

NeuralREG+Seq2Seq 4.95 B,C 4.82 A,B 
4.97 B 
NeuralREG+CAtt 
5.23 A,B 4.95 A,B 
5.26 A,B 
NeuralREG+HierAtt 5.07 B,C 4.90 A,B 
5.13 A,B 

Original 
5.41 A 
5.17 A 
5.42 A 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Fluency, Grammaticality and Clarity re-
sults obtained in the human evaluation. Rankings 
were determined by statistical significance. 

</table></figure>

			<note place="foot" n="1"> https://github.com/ThiagoCF05/ NeuralREG</note>

			<note place="foot" n="2"> https://github.com/jhclark/multeval</note>

			<note place="foot" n="3"> https://ilk.uvt.nl/ ˜ tcastrof/acl2018/ evaluation/</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating referring expressions in context: The GREC task evaluation challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jette</forename><surname>Viethen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Generation</title>
		<editor>Emiel Krahmer and Mariët Theune</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="294" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pronominalization in generated discourse and dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">B</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Lester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL&apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL&apos;02<address><addrLine>Philadelphia, Pennsylvania</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="88" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Linguistic realisation as machine translation: Comparing different MT models for AMR-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iacer</forename><surname>Thiago Castro Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Wubben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation, INLG&apos;17</title>
		<meeting>the 10th International Conference on Natural Language Generation, INLG&apos;17<address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards more variation in text generation: Developing and evaluating variation models for choice of referential form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Thiago Castro Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wubben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL&apos;16</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL&apos;16<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="568" to="577" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating flexible proper name references in text: Data, models and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Thiago Castro Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wubben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
	<note>Long Papers, EACL&apos;17. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Better Hypothesis Testing for Statistical Machine Translation: Controlling for Optimizer Instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers<address><addrLine>Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
	<note>Portland</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating referring expressions involving relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Haddock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth conference on European chapter of the Association for Computational Linguistics, EACL&apos;91</title>
		<meeting>the fifth conference on European chapter of the Association for Computational Linguistics, EACL&apos;91<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="161" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computational interpretations of the gricean maxims in the generation of referring expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="263" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Designing algorithms for referring with proper names</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kees Van Deemter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Natural Language Generation conference, INLG&apos;16</title>
		<meeting>the 9th International Natural Language Generation conference, INLG&apos;16<address><addrLine>Edinburgh, UK. As</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
	<note>sociation for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Creating training corpora for NLG micro-planners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL&apos;17</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The WebNLG challenge: Generating text from RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation, INLG&apos;17</title>
		<meeting>the 10th International Conference on Natural Language Generation, INLG&apos;17<address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Survey of the state of the art in natural language generation: Core tasks, applications and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Krahmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="65" to="170" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Weinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Centering: A framework for modeling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="225" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Cognitive status and the form of referring expressions in discourse. Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Jeanette K Gundel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Hedberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zacharski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="274" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pronominalization revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renate</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Conference on Computational Linguistics</title>
		<meeting>the 18th Conference on Computational Linguistics<address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="306" to="312" />
		</imprint>
	</monogr>
	<note>COLING&apos;00. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Redundancy and reduction: Speakers manage syntactic information density</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="62" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural AMR: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL&apos;17</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Computational generation of referring expressions: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kees Van Deemter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="173" to="218" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural text generation from structured data with application to the biography domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Lebret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP&apos;16</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP&apos;16<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1203" to="1213" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Binary Codes Capable of Correcting Deletions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insertions and Reversals. Soviet Physics Doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">707</biblScope>
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention strategies for multi-source sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Libovick´ylibovick´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jindřich</forename><surname>Helcl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="196" to="202" />
		</imprint>
	</monogr>
	<note>Short Papers), ACL&apos;17</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL) System Demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moussallem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Röder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C. Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<title level="m">MAG: A Multilingual, Knowledge-base Agnostic and Deterministic Entity Linking Approach</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garrette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saphra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<title level="m">The Dynamic Neural Network Toolkit</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Why discourse affects speakers&apos; choice of referring expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naho</forename><surname>Orita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliana</forename><surname>Vornov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1639" to="1649" />
		</imprint>
	</monogr>
	<note>Long Papers), ACL&apos;15. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, ACL&apos;02</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics, ACL&apos;02<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Building natural language generation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuldip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paliwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Information status distinctions and referring expressions: An empirical study of references to people in news summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="811" to="842" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A shared task on multimodal machine translation and crosslingual image description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="543" to="553" />
		</imprint>
	</monogr>
	<note>Shared Task Papers</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">ADADELTA: An adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Chinese poetry generation with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP&apos;14</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP&apos;14<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
