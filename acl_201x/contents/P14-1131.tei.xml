<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CoSimRank: A Flexible &amp; Efficient Graph-Theoretic Similarity Measure</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
							<email>sascha@cis.lmu.de</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Information &amp; Language Processing</orgName>
								<orgName type="institution">University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information &amp; Language Processing</orgName>
								<orgName type="institution">University of Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sch¨</forename><surname>Schütze</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information &amp; Language Processing</orgName>
								<orgName type="institution">University of Munich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CoSimRank: A Flexible &amp; Efficient Graph-Theoretic Similarity Measure</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1392" to="1402"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present CoSimRank, a graph-theoretic similarity measure that is efficient because it can compute a single node similarity without having to compute the similarities of the entire graph. We present equivalent formalizations that show CoSimRank&apos;s close relationship to Personalized Page-Rank and SimRank and also show how we can take advantage of fast matrix multiplication algorithms to compute CoSim-Rank. Another advantage of CoSimRank is that it can be flexibly extended from basic node-node similarity to several other graph-theoretic similarity measures. In an experimental evaluation on the tasks of synonym extraction and bilingual lexicon extraction, CoSimRank is faster or more accurate than previous approaches.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph-theoretic algorithms have been successfully applied to many problems in NLP ( <ref type="bibr" target="#b24">Mihalcea and Radev, 2011</ref>). These algorithms are often based on PageRank ( <ref type="bibr" target="#b2">Brin and Page, 1998</ref>) and other central- ity measures (e.g., <ref type="bibr" target="#b7">(Erkan and Radev, 2004)</ref>). An alternative for tasks involving similarity is Sim- Rank ( <ref type="bibr" target="#b16">Jeh and Widom, 2002</ref>). SimRank is based on the simple intuition that nodes in a graph should be considered as similar to the extent that their neighbors are similar. Unfortunately, SimRank has time complexity O(n 3 ) (where n is the num- ber of nodes in the graph) and therefore does not scale to the large graphs that are typical of NLP.</p><p>This paper introduces CoSimRank, 1 a new graph-theoretic algorithm for computing node similarity that combines features of SimRank and PageRank. Our key observation is that to compute the similarity of two nodes, we need not consider <ref type="bibr">1</ref> Code available at code.google.com/p/cistern all other nodes in the graph as SimRank does; in- stead, CoSimRank starts random walks from the two nodes and computes their similarity at each time step. This offers large savings in computa- tion time if we only need the similarities of a small subset of all n 2 node similarities.</p><p>These two cases -computing a few similari- ties and computing many similarities -correspond to two different representations we can compute CoSimRank on: a vector representation, which is fast for only a few similarities, and a matrix repre- sentation, which can take advantage of fast matrix multiplication algorithms.</p><p>CoSimRank can be used to compute many vari- ations of basic node similarity -including similar- ity for graphs with weighted and typed edges and similarity for sets of nodes. Thus, CoSimRank has the added advantage of being a flexible tool for dif- ferent types of applications.</p><p>The extension of CoSimRank to similarity across graphs is important for the application of bilingual lexicon extraction: given a set of corre- spondences between nodes in two graphs A and B (corresponding to two different languages), a pair of nodes (a ∈ A, b ∈ B) is a good candidate for a translation pair if their node similarity is high. In an experimental evaluation, we show that CoSim- Rank is more efficient and more accurate than both SimRank and PageRank-based algorithms.</p><p>This paper is structured as follows. Section 2 discusses related work. Section 3 introduces CoSimRank. In Section 4, we compare CoSim- Rank and SimRank. By providing some useful extensions, we demonstrate the great flexibility of CoSimRank (Section 5). We perform an exper- imental evaluation of CoSimRank in Section 6. Section 7 summarizes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is unsupervised. We therefore do not review graph-based methods that make extensive use of supervised learning (e.g., <ref type="bibr" target="#b5">de Melo and Weikum (2012)</ref>).</p><p>Since the original version of SimRank ( <ref type="bibr" target="#b16">Jeh and Widom, 2002</ref>) has complexity O(n 4 ), many ex- tensions have been proposed to speed up its calcu- lation. A Monte Carlo algorithm, which is scalable to the whole web, was suggested by <ref type="bibr" target="#b8">Fogaras and Rácz (2005)</ref>. However, in an evaluation of this al- gorithm we found that it does not give competitive results (see Section 6). A matrix representation of SimRank called SimFusion ( <ref type="bibr" target="#b35">Xi et al., 2005</ref>) im- proves the computational complexity from O(n 4 ) to O(n 3 ). <ref type="bibr" target="#b23">Lizorkin et al. (2010)</ref> also reduce com- plexity to O(n 3 ) by selecting essential node pairs and using partial sums. They also give a useful overview of SimRank, SimFusion and the Monte Carlo methods of <ref type="bibr" target="#b8">Fogaras and Rácz (2005)</ref>. A non-iterative computation for SimRank was intro- duced by <ref type="bibr" target="#b22">Li et al. (2010)</ref>. This is especially useful for dynamic graphs. However, all of these meth- ods have to run SimRank on the entire graph and are not efficient enough for very large graphs. We are interested in applications that only need a frac- tion of all O(n 2 ) pairwise similarities. The algo- rithm we propose below is an order of magnitude faster in such applications because it is based on a local formulation of the similarity measure. <ref type="bibr">2</ref> Apart from SimRank, many other similarity measures have been proposed. <ref type="bibr" target="#b19">Leicht et al. (2006)</ref> introduce a similarity measure that is also based on the idea that nodes are similar when their neigh- bors are, but that is designed for bipartite graphs. However, most graphs in NLP are not bipartite and <ref type="bibr" target="#b16">Jeh and Widom (2002)</ref> also proposed a SimRank variant for bipartite graphs.</p><p>Another important similarity measure is cosine similarity of Personalized PageRank (PPR) vec- tors. We will refer to this measure as PPR+cos. <ref type="bibr" target="#b13">Hughes and Ramage (2007)</ref> find that PPR+cos has high correlation with human similarity judg- ments on WordNet-based graphs. <ref type="bibr" target="#b0">Agirre et al. (2009)</ref> use PPR+cos for WordNet and for cross- lingual studies. Like CoSimRank, PPR+cos is efficient when computing single node pair simi- larities; we therefore use it as one of our base- lines below. This method is also used by <ref type="bibr" target="#b4">Chang et al. (2013)</ref> for semantic relatedness. They also experimented with Euclidean distance and KL-divergence. Interestingly, a simpler method per- formed best when comparing with human simi- larity judgments. In this method only the entries corresponding to the compared nodes are used for a similarity score. <ref type="bibr" target="#b30">Rao et al. (2008)</ref> compared PPR+cos to other graph based similarity mea- sures like shortest-path and bounded-length ran- dom walks. PPR+cos performed best except for a new similarity measure based on commute time. We do not compare against this new measure as it uses the graph Laplacian and so cannot be com- puted for a single node pair.</p><p>One reason CoSimRank is efficient is that we need only compute a few iterations of the random walk. This is often true of this type of algorithm; cf. ( <ref type="bibr" target="#b34">Schütze and Walsh, 2008)</ref>.</p><p>LexRank ( <ref type="bibr" target="#b7">Erkan and Radev, 2004</ref>) is similar to PPR+cos in that it combines PageRank and cosine; it initializes the sentence similarity matrix of a document using cosine and then applies PageRank to compute lexical centrality. Despite this superfi- cial relatedness, applications like lexicon extrac- tion that look for similar entities and applications that look for central entities are quite different.</p><p>In addition to faster versions of SimRank, there has also been work on extensions of SimRank. <ref type="bibr" target="#b6">Dorow et al. (2009)</ref> and  ex- tend SimRank to edge weights, edge labels and multiple graphs. We use their Multi-Edge Extrac- tion (MEE) algorithm as one of our baselines be- low. A similar graph of dependency structures was built by <ref type="bibr" target="#b26">Minkov and Cohen (2008)</ref>. They applied different similarity measures, e.g., cosine of de- pendency vectors or a new algorithm called path- constrained graph walk, on synonym extraction <ref type="bibr" target="#b27">(Minkov and Cohen, 2012)</ref>. We compare CoSim- Rank with their results in our experiments (see Section 6).</p><p>Some other applications of SimRank or other graph based similarity measures in NLP include work on document similarity ( <ref type="bibr" target="#b21">Li et al., 2009)</ref>, the transfer of sentiment information between lan- guages (  and named entity disambiguation <ref type="bibr" target="#b9">(Han and Zhao, 2010)</ref>. <ref type="bibr" target="#b12">Hoang and Kan (2010)</ref> use SimRank for related work sum- marization. <ref type="bibr" target="#b28">Muthukrishnan et al. (2010)</ref> combine link based similarity and content based similarity for document clustering and classification.</p><p>These approaches use at least one of cosine sim- ilarity, PageRank and SimRank. CoSimRank can either be interpreted as an efficient version of Sim-Rank or as a version of Personalized PageRank for similarity measurement. The novelty is that we compute similarity for vectors that are induced using a new algorithm, so that the similarity mea- surement is much more efficient when an applica- tion only needs a fraction of all O(n 2 ) pairwise similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CoSimRank</head><p>We first first give an intuitive introduction of CoSimRank as a Personalized PageRank (PPR) derivative. Later on, we will give a matrix formu- lation to compare CoSimRank with SimRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Personalized PageRank</head><p>Haveliwala <ref type="formula" target="#formula_1">(2002)</ref> introduced Personalized Page- Rank -or topic-sensitive PageRank -based on the idea that the uniform damping vector p (0) can be replaced by a personalized vector, which depends on node i. We usually set p (0) (i) = e i , with e i be- ing a vector of the standard basis, i.e., the i th entry is 1 and all other entries are 0. The PPR vector of node i is given by:</p><formula xml:id="formula_0">p (k) (i) = dAp (k−1) (i) + (1 − d)p (0) (i) (1)</formula><p>where A is the stochastic matrix of the Markov chain, i.e., the row normalized adjacency matrix. The damping factor d ∈ (0, 1) ensures that the computation converges. The PPR vector after k iterations is given by p (k) .</p><p>To visualize this formula, one can imagine a random surfer starting at node i and following one of the links with probability d or jumping back to the starting node i with probability <ref type="bibr">(1 − d)</ref>. Entry i of the converged PPR vector represents the prob- ability that the random surfer is on node i after an unlimited number of steps.</p><p>To simulate the behavior of SimRank we will simplify this equation and set the damping factor d = 1. We will re-add a damping factor later in the calculation.</p><formula xml:id="formula_1">p (k) = Ap (k−1)<label>(2)</label></formula><p>Note that the personalization vector p (0) was elim- inated, but is still present as the starting vector of the iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Similarity of vectors</head><p>Let p(i) be the PPR vector of node i. The cosine of two vectors u and v is computed by dividing </p><formula xml:id="formula_2">s(i, j) = p(i), p(j) |p(i)||p(j)|<label>(3)</label></formula><p>This measure s(i, j) looks at the probability that a random walker is on a certain edge after an un- limited number of steps. This is potentially prob- lematic as the example in <ref type="figure" target="#fig_0">Figure 1</ref> shows. The PPR vectors of suit and dress will have some weight on tailor, which is good. However, the PPR vector of law will also have a non-zero weight for tailor. So law and dress are similar because of the node tailor. This is undesirable.</p><p>We can prevent this type of spurious similarity by taking into account the path the random surfer took to get to a particular node. We formalize this by defining CoSimRank s(i, j) as follows:</p><formula xml:id="formula_3">s(i, j) = ∞ k=0 c k p (k) (i), p (k) (j)<label>(4)</label></formula><p>where p (k) (i) is the PPR vector of node i from Eq. 2 after k iterations. We compare the PPR vec- tors at each time step k. The sum of all similarities is the value of CoSimRank, i.e., the final similar- ity. We add a damping factor c, so that early meet- ings are more valuable than later meetings.</p><p>To compute the similarity of two vectors u and v we use the inner product ·, ·· in Eq. 4 for two reasons:</p><p>1. This is similar to cosine similarity except that the 1-norm is used instead of the 2-norm.</p><p>Since our vectors are probability vectors, we have</p><formula xml:id="formula_4">p(i), p(j) |p(i)||p(j)| = p(i), p(j)</formula><p>for the 1-norm. <ref type="bibr">3</ref> 2. Without expensive normalization, we can give a simple matrix formalization of CoSim- Rank and compute it efficiently using fast matrix multiplication algorithms.</p><p>Later on, the following iterative computation of CoSimRank will prove useful:</p><formula xml:id="formula_5">s (k) (i, j) = c k p (k) (i), p (k) (j) + s (k−1) (i, j)<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Matrix formulation</head><p>The matrix formulation of CoSimRank is:</p><formula xml:id="formula_6">S (0) = E S (1) = cAA T + S (0) S (2) = c 2 A 2 (A T ) 2 + S (1)</formula><p>. . .</p><formula xml:id="formula_7">S (k) = c k A k (A T ) k + S (k−1)<label>(6)</label></formula><p>We will see in Section 5 that this formulation is the basis for a very efficient version of CoSimRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Convergence properties</head><p>As the PPR vectors have only positive values, we can easily see in Eq. 4 that the CoSimRank of one node pair is monotonically non-decreasing. For the dot product of two vectors, the Cauchy- Schwarz inequality gives the upper bound:</p><formula xml:id="formula_8">u, v ≤ u v</formula><p>where x is the norm of x. From Eq. 2 we get p (k) 1 = 1, where ·· 1 is the 1-norm. We also know from elementary functional analysis that the 1-norm is the biggest of all p-norms and so one has p (k) ≤ 1. It follows that CoSimRank grows more slowly than a geometric series and converges if |c| &lt; 1:</p><formula xml:id="formula_9">s(i, j) ≤ ∞ k=0 c k = 1 1 − c</formula><p>If an upper bound of 1 is desired for s(i, j) (in- stead of 1/(1 − c)), then we can use s :</p><formula xml:id="formula_10">s (i, j) = (1 − c)s(i, j)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparison to SimRank</head><p>The original SimRank equation can be written as follows <ref type="bibr" target="#b16">(Jeh and Widom, 2002)</ref>:</p><formula xml:id="formula_11">r(i, j) =      1, if i = j c |N (i)||N (j)| k∈N (i) l∈N (j) r(k, l), else</formula><p>where N (i) denotes the nodes connected to i. SimRank is computed iteratively. With A be- ing the normalized adjacency matrix we can write SimRank in matrix formulation:</p><formula xml:id="formula_12">R (0) = E R (k) = max{cAR (k−1) A T , R (0) }<label>(7)</label></formula><p>where the maximum of two matrices refers to the element-wise maximum. We will now prove by in- duction that the matrix formulation of CoSimRank (Eq. 6) is equivalent to:</p><formula xml:id="formula_13">S (k) = cAS (k−1) A T + S (0)<label>(8)</label></formula><p>and thus very similar to SimRank (Eq. 7). The base case S (1) = S (1) is trivial. Inductive step:</p><formula xml:id="formula_14">S (k) (8) = cAS (k−1) A T + S (0) = cA(c k−1 A k−1 (A T ) k−1 + S (k−2) )A T + S (0) = c k A k (A T ) k + cAS (k−2) A T + S (0) = c k A k (A T ) k + S (k−1) (6) = S (k)</formula><p>Comparing Eqs. 7 and 8, we see that SimRank and CoSimRank are very similar except that they initialize the similarities on the diagonal differ- ently. Whereas SimRank sets each of these en- tries back to one at each iteration, CoSimRank adds one. Thus, when computing the two similar- ity measures iteratively, the diagonal element (i, i) will be set to 1 by both methods for those initial it- erations for which this entry is 0 for cAS (k−1) A T (i.e., before applying either max or add). The methods diverge when the entry is = 0 for the first time.</p><p>Complexity of computing all n 2 similarities. The matrix formulas of both SimRank (Eq. 7) and CoSimRank (Eq. 8) have time complexity O(n 3 ) or -if we want to take the higher efficiency of computation for sparse graphs into account - O(dn 2 ) where n is the number of nodes and d the average degree. Space complexity is O(n 2 ) for both algorithms.</p><p>Complexity of computing k 2 n 2 similar- ities. In most cases, we only want to compute k 2 similarities for k nodes. For CoSimRank, we compute the k PPR vectors in O(kdn) (Eq.</p><note type="other">2) and compute the k 2 similarities in O(k 2 n) (Eq. 5). If d &lt; k, then the time complexity of CoSimRank is O(k 2 n). If we only compute a single similar- ity, then the complexity is O(dn). In contrast, the complexity of SimRank is the same as in the all- similarities case: O(dn 2 ). It is not obvious how to design a lower-complexity version of SimRank for this case. Thus, we have reduced SimRank's cu- bic time complexity to a quadratic time complex- ity for CoSimRank or -assuming that the aver- age degree d does not depend on n -SimRank's quadratic time complexity to linear time complex- ity for the case of computing few similarities.</note><p>Space complexity for computing k 2 similarities is O(kn) since we need only store k vectors, not the complete similarity matrix. This complexity can be exploited even for the all similarities appli- cation: If the matrix formulation cannot be used because the O(n 2 ) similarity matrix is too big for available memory, then we can compute all sim- ilarities in batches -and if desired in parallel - whose size is chosen such that the vectors of each batch still fit in memory.</p><p>In summary, CoSimRank and SimRank have similar space and time complexities for comput- ing all n 2 similarities. For the more typical case that we only want to compute a fraction of all sim- ilarities, we have recast the global SimRank for- mulation as a local CoSimRank formulation. As a result, time and space complexities are much im- proved. In Section 6, we will show that this is also true in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Extensions</head><p>We will show now that the basic CoSimRank algo- rithm can be extended in a number of ways and is thus a flexible tool for different NLP applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Weighted edges</head><p>The use of weighted edges was first proposed in the PageRank patent. It is straightforward and easy to implement by replacing the row normal- ized adjacency matrix A with an arbitrary stochas- tic matrix P . We can use this edge weighted Page- Rank for CoSimRank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">CoSimRank across graphs</head><p>We often want to compute the similarity of nodes in two different graphs with a known node-node correspondence; this is the scenario we are faced with in the lexicon extraction task (see Section 6). A variant of SimRank for this task was presented by <ref type="bibr" target="#b6">Dorow et al. (2009)</ref>. We will now present an equivalent method for CoSimRank. We denote the number of nodes in the two graphs U and V by |U | and |V |, respectively. We compute PPR vec- tors p ∈ R |U | and q ∈ R |V | for each graph. Let S (0) ∈ R |U |×|V | be the known node-node corre- spondences. The analog of CoSimRank (Eq. 4) for two graphs is then:</p><formula xml:id="formula_15">s(i, j) = ∞ k=0 c k (u,v)∈S (0) p (k) u (i)q (k) v (j)<label>(9)</label></formula><p>The matrix formulation (cf. Eq. 6) is:</p><formula xml:id="formula_16">S (k) = c k A k S (0) (B T ) k + S (k−1)<label>(10)</label></formula><p>where A and B are row-normalized adjacency ma- trices. We can interpret S (0) as a change of basis. A similar approach for word embeddings was pub- lished by <ref type="bibr" target="#b25">Mikolov et al. (2013)</ref>. They call S (0) the translation matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Typed edges</head><p>To be able to directly compare to prior work in our experiments, we also present a method to integrate a set of typed edges T in the CoSimRank calcula- tion. For this we will compute a similarity matrix for each edge type τ and merge them into one ma- trix for the next iteration:</p><formula xml:id="formula_17">S (k) = c |T | τ ∈T A τ S (k−1) B T τ + S (0) (11)</formula><p>This formula is identical to the random surfer model where two surfers only meet iff they are on the same node and used the same edge type to get there. A more strict claim would be to use the same edge type at any time of their journey:</p><formula xml:id="formula_18">S (k) = c k |T | k τ ∈T k k i=1 A τ i S (0) k−1 i=0 B T τ k−i + S (k−1)<label>(12)</label></formula><p>We will not use Eq. 12 due to its space complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Similarity of sets of nodes</head><p>CoSimRank can also be used to compute the sim- ilarity s(V, W ) of two sets V and W of nodes, e.g., short text snippets. We are not including this method in our experiments, but we will give the equation here, as traditional document similarity measures (e.g., cosine similarity) perform poorly on this task although there also are known alter- natives with good results ( <ref type="bibr" target="#b32">Sahami and Heilman, 2006</ref>). For a set V , the initial PPR vector is given by:</p><formula xml:id="formula_19">p (0) i (V ) = 1 |V | , if i ∈ V 0, else</formula><p>We then reuse Eq. 4 to compute s(V, W ):</p><formula xml:id="formula_20">s(V, W ) = ∞ k=0 c k p (k) (V ), p (k) (W )</formula><p>In summary, modifications proposed for Sim- Rank (weighted and typed edges, similarity across graphs) as well as modifications proposed for PageRank (sets of nodes) can also be applied to CoSimRank. This makes CoSimRank a very flex- ible similarity measure.</p><p>We will test the first three extensions experi- mentally in the next section and leave similarity of node sets for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate CoSimRank for the tasks of syn- onym extraction and bilingual lexicon extraction. We use the basic version of CoSimRank (Eq. 4) for synonym extraction and the two-graph version (Eq. 9) for lexicon extraction, both with weighted edges. Our motivation for this application is that two words that are synonyms of each other should have similar lexical neighbors and that two words that are translations of each other should have neighbors that correspond to each other; thus, in each case the nodes should be similar in the graph- theoretic sense and CoSimRank should be able to identify this similarity.</p><p>We use the English and German graphs pub- lished by , including edge weighting and normalization. Nodes are nouns, adjectives and verbs occurring in Wikipedia. There are three types of edges, corresponding to three types of syntactic configurations extracted from the parsed Wikipedias: adjective-noun, verb- object and noun-noun coordination. <ref type="table">Table 1</ref> gives examples and number of nodes and edges. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Baselines</head><p>We propose CoSimRank as an efficient algorithm for computing the similarity of nodes in a graph. Consequently, we compare against the two main methods for this task in NLP: SimRank and exten- sions of PageRank. We also compare against the MEE (Multi-Edge Extraction) variant of SimRank ( <ref type="bibr" target="#b6">Dorow et al., 2009)</ref>, which handles labeled edges more effi- ciently than SimRank:</p><formula xml:id="formula_21">S (k) = c |T | τ ∈T A τ S (k−1) B T τ S (k) = max{S (k) , S (0) }</formula><p>where A τ is the row-normalized adjacency matrix for edge type τ (see edge types in <ref type="table">Table 1)</ref>.</p><p>Apart from SimRank, extensions of PageRank are the main methods for computing the similar- ity of nodes in graphs in NLP (e.g., <ref type="bibr" target="#b13">Hughes and Ramage (2007)</ref>, <ref type="bibr" target="#b0">Agirre et al. (2009)</ref> and other pa- pers discussed in related work). Generally, these methods compute the Personalized PageRank for each node (see Eq. 1). When the computation has converged, the similarity of two nodes is given by the cosine similarity of the Personalized PageRank vectors. We implemented this method for our ex- periments and call it PPR+cos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Synonym Extraction</head><p>We use TS68, a test set of 68 synonym pairs pub- lished by <ref type="bibr" target="#b27">Minkov and Cohen (2012)</ref>   correct synonym even if there are several equally acceptable near-synonyms (see <ref type="table">Table 3</ref> for exam- ples). We call this the one-synonym evaluation. Three native English speakers were asked to mark synonyms, that were proposed by a baseline or by CoSimRank, i.e. ranked in the top 10. If all three of them agreed on one word as being a synonym in at least one meaning, we added this as a correct answer to the test set. We call this the "extended" evaluation (see <ref type="table" target="#tab_2">Table 2</ref>). Synonym extraction is run on the English graph. To calculate PPR+cos, we computed 20 iterations with a decay factor of 0.8 and used the cosine sim- ilarity with the 2-norm in the denominator to com- pare two vectors. For the other three methods, we also used a decay factor of 0.8 and computed 5 it- erations. Recall that CoSimRank uses the simple inner product ·, ·· to compare vectors.</p><p>Our evaluation measures are proportion of words correctly translated by word in the top position (P@1), proportion of words correctly translated by a word in one of the top 10 posi- tions (P@10) and Mean Reciprocal Rank (MRR). CoSimRank's MRR scores of 0.37 (one-synonym) and 0.59 (extended) are the same or better than all baselines (see <ref type="table" target="#tab_2">Table 2</ref>). CoSimRank and SimRank have the same P@1 and P@10 accuracy (although they differed on some decisions). CoSimRank is better than PPR+cos on both evaluations, but as this test set is very small, the results are not signif- icant. <ref type="table">Table 3</ref> shows a sample of synonyms pro- posed by CoSimRank.</p><p>Minkov and Cohen (2012) tested cosine and random-walk measures on grammatical <ref type="table">relation-  keyword  expected  extracted   movie  film  film  modern  contemporary contemporary  demonstrate  protest  show  attractive  appealing  beautiful  economic  profitable  financial  close</ref> shut open <ref type="table">Table 3</ref>: Examples for extracted synonyms. Cor- rect synonyms according to extended evaluation in bold.</p><p>ships (similar to our setup) as well as on cooccur- rence statistics. The MRR scores for these meth- ods range from 0.29 to 0.59. (MRR is equivalent to MAP as reported by <ref type="bibr" target="#b27">Minkov and Cohen (2012)</ref> when there is only one correct answer.) Their best number (0.59) is better than our one-synonym result; however, they performed manual postpro- cessing of results -e.g., discarding words that are morphologically or semantically related to other words in the list -so our fully automatic results cannot be directly compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Lexicon Extraction</head><p>We evaluate lexicon extraction on TS1000, a test set of 1000 items, (Laws et al., 2010) each con- sisting of an English word and its German transla- tions. For lexicon extraction, we use the same pa- rameters as in the synonym extraction task for all four similarity measures. We use a seed dictionary of 12,630 word pairs to establish node-node corre- spondences between the two graphs. We remove a search keyword from the seed dictionary before calculating similarities for it, something that the architecture of CoSimRank makes easy because we can use a different seed dictionary S (0) for ev- ery keyword. Both CoSimRank methods outperform Sim- Rank significantly (see <ref type="table">Table 4</ref>). The differ- ence between CoSimRank with and without typed edges is not significant. (This observation was also made for SimRank on a smaller graph and test set ( .)</p><p>PPR+cos's performance at 14.8% correct trans- lations is much lower than SimRank and CoSim- Rank. The disadvantage of this similarity mea- sure is significant and even more visible on bilin- gual lexicon extraction than on synonym extrac- tion (see <ref type="table" target="#tab_2">Table 2</ref>). The reason might be that we are not comparing the whole PPR vector anymore,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P@1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P@10</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PPR+cos</head><p>14.8% † 45.7% † SimRank MEE 48.0% † 76.0% † CoSimRank 61.1% 84.0% Typed CoSimRank 61.4% 83.9% <ref type="table">Table 4</ref>: Results for bilingual lexicon extraction (TS1000 EN → DE). Best result in each column in bold.</p><p>but only entries which occur in the seed dictionary (see Eq. 9). As the seed dictionary contains 12,630 word pairs, this means that only every fourth entry of the PPR vector (the German graph has 47,439 nodes) is used for similarity calculation. This is also true for CoSimRank, but it seems that CoSim- Rank is more stable because we compare more than one vector. † We also experimented with the method of Fog- aras and <ref type="bibr">Rácz (2005)</ref>. We tried a number of differ- ent ways of modifying it for weighted graphs: (i) running the random walks with the weighted ad- jacency matrix as Markov matrix, (ii) storing the weight (product of each edge weight) of a random walk and using it as a factor if two walks meet and (iii) a combination of both. We needed about 10,000 random walks in all three conditions. As a result, the computational time was approximately 30 minutes per test word, so this method is even slower than SimRank for our application. The ac- curacies P@1 and P@10 were worse in all experi- ments than those of CoSimRank.  of edges (see <ref type="table">Table 1</ref>). Compared to PPR+cos, CoSimRank is roughly four times faster on synonym extraction and has comparable performance on lexicon extraction. We compute 20 iterations of PPR+cos to reach convergence and then calculate a single cosine similarity. For CoSimRank, we need only com- pute five iterations to reach convergence, but we have to compute a vector similarity in each itera- tion. The counteracting effects of fewer iterations and more vector similarity computations can give either CoSimRank or PPR+cos an advantage, as is the case for synonym extraction and lexicon ex- traction, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Run time performance</head><p>CoSimRank should generally be three times faster than typed CoSimRank since the typed ver- sion has to repeat the computation for each of the three types. This effect is only visible on the larger test set (lexicon extraction) because the gen- eral computation overhead is about the same on a smaller test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Comparison with WINTIAN</head><p>Here we address inducing a bilingual lexicon from a seed set based on grammatical relations found by a parser. An alternative approach is to in- duce a bilingual lexicon from Wikipedia's inter- wiki links ( <ref type="bibr" target="#b31">Rapp et al., 2012</ref>). These two ap- proaches have different strengths and weaknesses; e.g., the interwiki-link-based approach does not require a seed set, but it can only be applied to comparable corpora that consist of corresponding -although not necessarily "parallel" -documents.</p><p>Despite these differences it is still interesting to compare the two algorithms. <ref type="bibr">Rapp</ref>   WINTIAN Wikipedia data ( <ref type="bibr" target="#b31">Rapp et al., 2012)</ref> and words covered by our data. Most of the 226 miss- ing word pairs are adverbs, prepositions and plural forms that are not covered by our graphs due to the construction algorithm we use: lemmatization, re- striction to adjectives, nouns and verbs etc. <ref type="table" target="#tab_6">Table 6</ref> shows that CoSimRank is slightly, but not significantly worse than WINTIAN on P@1 (43.0 vs 43.8), but significantly better on P@10 (73.6 vs 55.4). <ref type="bibr">4</ref> The reason could be that CoSim- Rank is a more effective algorithm than WIN- TIAN; but the different initializations (seed set vs interwiki links) or the different linguistic represen- tations (grammatical relations vs bag-of-words) could also be responsible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Error Analysis</head><p>The results on TS774 can be considered conserva- tive since only one translation is accepted as being correct. In reality other translations might also be acceptable (e.g., both street and road for Straße). In contrast, TS1000 accepts more than one cor- rect translation. Additionally, TS774 was created by translating English words into German (using Google translate). We are now testing the reverse direction. So we are doomed to fail if the original English word is a less common translation of an ambiguous German word. For example, the En- glish word gulf was translated by Google to Golf, but the most common sense of Golf is the sport. Hence our algorithm will incorrectly translate it back to golf.</p><p>As we can see in <ref type="table">Table 7</ref>, we also face the prob- lems discussed by : the algo- rithm sometimes picks cohyponyms (which can still be seen as reasonable) and antonyms (which are clear errors).</p><p>Contrary to our intuition, the edge-typed vari- ant of CoSimRank did not perform significantly better than the non-edge-typed version. Looking <ref type="bibr">4</ref> We achieved better results for CoSimRank by optimizing the damping factor, but in this paper, we only present results for a fixed damping factor of 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>keyword</head><p>gold standard <ref type="table">CoSimRank   arm  poor  impoverished  erreichen  reach  achieve  gehen  go  walk  direkt  directly  direct  weit  far  further  breit  wide  narrow  reduzieren  reduce  increase  Stunde  hour  second  Westen  west  southwest  Junge</ref> boy child <ref type="table">Table 7</ref>: Examples for CoSimRank translation er- rors on TS774. We counted translations as incor- rect if they were not listed in the gold standard even if they were correct translations according to www.dict.cc (in bold).</p><p>at <ref type="table">Table 1</ref>, we see that there is only one edge type connecting adjectives. The same is true for verbs. The random surfer only has a real choice between different edge types when she is on a noun node. Combined with the fact that only the last edge type is important this has absolutely no effect for a ran- dom surfer meeting at adjectives or verbs. Two possible solutions would be (i) to use more fine-grained edge types, (ii) to apply Eq. 12, in which the edge type of each step is important. However, this will increase the memory needed for calculation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graph motivating CoSimRank algorithm. Whereas PPR gives relatively high similarity to the pair (law,suit), CoSimRank assigns the pair similarity 0.</figDesc><graphic url="image-1.png" coords="3,309.17,62.81,214.49,56.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>for evalua- tion. This gold standard lists a single word as the</figDesc><table>P@1 

P@10 MRR 

one-synonym 

PPR+cos 
20.6% 52.9% 0.32 
SimRank 
25.0% 61.8% 0.37 
CoSimRank 
25.0% 61.8% 0.37 
Typed CoSimRank 
23.5% 63.2% 0.37 

extended 

PPR+cos 
32.6% 73.5% 0.48 
SimRank 
45.6% 83.8% 0.59 
CoSimRank 
45.6% 83.8% 0.59 
Typed CoSimRank 
44.1% 83.8% 0.59 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results for synonym extraction on TS68. 
Best result in each column in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 compares</head><label>5</label><figDesc>the run time performance of CoSimRank with the baselines. We ran all exper- iments on a 64-bit Linux machine with 64 Intel Xenon X7560 2.27Ghz CPUs and 1TB RAM. The calculated time is the sum of the time spent in user mode and the time spent in kernel mode. The ac- tual wall clock time was significantly lower as we used up to 64 CPUs. Compared to SimRank, CoSimRank is more than 40 times faster on synonym extraction and six times faster on lexicon extraction. SimRank is at a disadvantage because it computes all similarities in the graph regardless of the size of the test set; it is particularly inefficient on synonym extraction because the English graph contains a large number † significantly worse than</figDesc><table>CoSimRank (α = 0.05, one-
tailed Z-Test) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Execution times in minutes for CoSim-
Rank and the baselines. Best result in each column 
in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>et al. (2012) kindly provided their test set to us. It contains 1000 English words and a single correct German translation for each. We evaluate on a subset we call TS774 that consists of the 774 test word pairs that are in the intersection of words covered by the</figDesc><table>P@1 

P@10 

Wintian 
43.8% 55.4%  † 
CoSimRank 
43.0% 73.6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Results for bilingual lexicon extraction 
(TS774 DE → EN). Best result in each column in 
bold. 

</table></figure>

			<note place="foot" n="2"> A reviewer suggests that CoSimRank is an efficient version of SimRank in a way analogous to SALSA&apos;s (Lempel and Moran, 2000) relationship to HITS (Kleinberg, 1999) in that different aspects of similarity are decoupled.</note>

			<note place="foot" n="3"> This type of similarity measure has also been used and investigated by´Oby´ by´O Séaghdha and Copestake (2008), Cha (2007), Jebara et al. (2004) (probability product kernel) and (Jaakkola et al., 1999) (Fisher kernel) among others.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Summary</head><p>We have presented CoSimRank, a new similar-ity measure that can be computed for a single node pair without relying on the similarities in the whole graph. We gave two different formaliza-tions of CoSimRank: (i) a derivation from Person-alized PageRank and (ii) a matrix representation that can take advantage of fast matrix multipli-cation algorithms. We also presented extensions of CoSimRank for a number of applications, thus demonstrating the flexibility of CoSimRank as a similarity measure.</p><p>We showed that CoSimRank is superior to SimRank in time and space complexity; and we demonstrated that CoSimRank performs bet-ter than PPR+cos on two similarity computation tasks.</p><p>Acknowledgments. This work was supported by DFG (SCHU 2246/2-2).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A study on similarity and relatedness using distributional and wordnet-based approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kravalova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies</title>
		<meeting>Human Language Technologies</meeting>
		<imprint>
			<publisher>The</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Marius Pas¸caPas¸ca, and Aitor Soroa</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL &apos;09</title>
		<imprint>
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comprehensive survey on distance/similarity measures between probability density functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hyuk</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Models and Methods in Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="300" to="307" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Getting creative with semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Yun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Harrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Seventh International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="330" to="333" />
		</imprint>
	</monogr>
	<note>Semantic Computing (ICSC)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uwn: A large multilingual lexical knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Gerard De Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (System Demonstrations)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="151" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A graphtheoretic algorithm for automatic extension of translation lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beate</forename><surname>Dorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Laws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Michelbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Utt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Geometrical Models of Natural Language Semantics, GEMS &apos;09</title>
		<meeting>the Workshop on Geometrical Models of Natural Language Semantics, GEMS &apos;09</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Intell. Res. (JAIR)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Scaling link-based similarity search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dániel</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Rácz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th international conference on World Wide Web, WWW &apos;05</title>
		<meeting>the 14th international conference on World Wide Web, WWW &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="641" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Structural semantic relatedness: a knowledge-based method to named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th</title>
		<meeting>the 48th</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics, ACL &apos;10</title>
		<imprint>
			<biblScope unit="page" from="50" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Topic-sensitive pagerank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th international conference on World Wide Web, WWW &apos;02</title>
		<meeting>the 11th international conference on World Wide Web, WWW &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards automated related work summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Duy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="427" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lexical semantic relatedness with random graph walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thad</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="581" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploiting generative models in discriminative classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="487" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Probability product kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Jebara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="819" to="844" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simrank: a measure of structural-context similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;02</title>
		<meeting>the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Authoritative sources in a hyperlinked environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="604" to="632" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A linguistically grounded graph model for bilingual lexicon extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Laws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beate</forename><surname>Lukas Ichelbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Dorow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Heid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2010: Posters</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="614" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Vertex similarity in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Leicht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petter</forename><surname>Holme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26120</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The stochastic approach for link-structure analysis (salsa) and the tkc effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronny</forename><surname>Lempel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Moran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="387" to="401" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using link-based content analysis to measure document similarity effectively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Du</surname></persName>
		</author>
		<idno>AP- Web/WAIM &apos;09</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint International Conferences on Advances in Data and Web Management</title>
		<meeting>the Joint International Conferences on Advances in Data and Web Management</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="455" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast computation of simrank for static and dynamic information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yintao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Conference on Extending Database Technology, EDBT &apos;10</title>
		<meeting>the 13th International Conference on Extending Database Technology, EDBT &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="465" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Accuracy estimate and optimization techniques for simrank computation. The VLDB Journal-The International Journal on Very Large Data Bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Lizorkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Velikhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Grinev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Turdakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="45" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Graphbased natural language processing and information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning graph walk based similarity measures for parsed text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Minkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="907" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph based similarity measures for synonym extraction from parsed text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Minkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno>TextGraphs-7 &apos;12</idno>
	</analytic>
	<monogr>
		<title level="m">Workshop Proceedings of TextGraphs-7 on Graph-based Methods for Natural Language Processing</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="20" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Edge weight regularization over multiple graphs for similarity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 10th International Conference on</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="374" to="383" />
		</imprint>
	</monogr>
	<note>Data Mining (ICDM)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semantic classification with distributional kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´o</forename><surname>Diarmuid´odiarmuid´</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Copestake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="649" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Affinity measures based on the graph Laplacian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Textgraphs Workshop on Graph-Based Algorithms for Natural Language Processing</title>
		<meeting>the 3rd Textgraphs Workshop on Graph-Based Algorithms for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Identifying word translations from comparable documents without a seed lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Babych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="460" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A web-based kernel function for measuring the similarity of short text snippets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">D</forename><surname>Heilman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on World Wide Web, WWW &apos;06</title>
		<meeting>the 15th international conference on World Wide Web, WWW &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="377" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sentiment translation through multi-edge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Scheible</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Laws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Michelbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters, COLING &apos;10</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1104" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A graphtheoretic model of lexical syntactic acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Walsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="917" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simfusion: measuring similarity using unified relationship matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensi</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiguo</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR &apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
