<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning from Chunk-based Feedback in Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Petrushkov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc. Kasernenstr</orgName>
								<address>
									<addrLine>25</addrLine>
									<postCode>52064</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc. Kasernenstr</orgName>
								<address>
									<addrLine>25</addrLine>
									<postCode>52064</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">eBay Inc. Kasernenstr</orgName>
								<address>
									<addrLine>25</addrLine>
									<postCode>52064</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning from Chunk-based Feedback in Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Short Papers) <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="326" to="331"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>326</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We empirically investigate learning from partial feedback in neural machine translation (NMT), when partial feedback is collected by asking users to highlight a correct chunk of a translation. We propose a simple and effective way of utilizing such feedback in NMT training. We demonstrate how the common machine translation problem of domain mismatch between training and deployment can be reduced solely based on chunk-level user feedback. We conduct a series of simulation experiments to test the effectiveness of the proposed method. Our results show that chunk-level feedback out-performs sentence based feedback by up to 2.61% BLEU absolute.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, machine translation (MT) quality improved rapidly, especially because of advances in neural machine translation (NMT). Most of re- maining MT errors arguably come from domain, style, or terminology mismatch between the data on which the MT was trained on and data which it has to translate. It is hard to alleviate this mis- match since usually only limited amounts of rele- vant training data are available. Yet MT systems deployed on-line in e.g. e-commerce websites or social networks can benefit from user feedback for overcoming this mismatch. Whereas MT users are usually not bilingual, they likely have a good com- mand of the target language and are able to spot severe MT errors in a given translated sentence, sometimes with the help of e.g. an accompanying image, video, or simply prior knowledge.</p><p>A common approach to get user feedback for MT is explicit ratings of translations on an n-point Likert scale. The main problem of such methods is that users are not qualified enough to provide re- liable feedback for the whole sentence. Since dif- ferent users do not adhere to a single set of guide- lines, their ratings may be influenced by various factors, such as user expectations, user knowledge, or user satisfaction with the platform. In ( <ref type="bibr">Kreutzer et al., 2018)</ref>, the authors investigate the reliability and validity of real user ratings by re-evaluating five-star ratings by three independent human anno- tators, however the inter-annotator agreement be- tween experts was relatively low and no correla- tion to the averaged user rating was found.</p><p>Instead of providing a rating, a user might be asked to correct the generated translation, in a process called post-editing. Using corrected sen- tences for training an NMT system brings larger improvements, but this method requires significant effort and expertise from the user.</p><p>Alternatively, feedback can be collected by ask- ing users to mark correct parts (chunks) of the translation <ref type="bibr" target="#b4">(Marie and Max, 2015)</ref>. It can be seen as the middle ground between quick sentence level rating and more expensive post-editing. We hy- pothesize that collecting feedback in this form im- plicitly forces guidelines on the user, making it less susceptible to various user-dependent factors. We expect marking of correct chunks in a trans- lation to be simple enough for non-experts to do quickly and precisely and also be more intuitive than providing a numerical rating.</p><p>In this paper, we investigate the empirical hy- pothesis that NMT is able to learn from the good chunks of a noisy sentence and describe a sim- ple way of utilizing such chunk-level feedback in NMT training. To the best of our knowledge, no dataset with human feedback recorded in this form is available, therefore we experiment with user feedback that was artificially created from paral- lel data.</p><p>The rest of this paper is structured as follows. In Section 2 we review related work. We describe our partial feedback approach in Section 3. Next we present our experimental results in Section 4, followed by the conclusion in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Integrating user ratings in NMT has been stud- ied in ( <ref type="bibr">Kreutzer et al., 2017</ref>), who view this as a bandit structured prediction task. They demon- strate how the user feedback can be integrated into NMT training and perform a series of experiments using GLEU ( <ref type="bibr">Wu et al., 2016</ref>) to simulate user feedback. <ref type="bibr" target="#b6">Nguyen et al. (2017)</ref> have also studied this problem and adapted an actor-critic approach <ref type="bibr" target="#b5">(Mnih et al., 2016</ref>) which has shown to be robust to skewed, high variance feedback from real users.</p><p>( <ref type="bibr">Lam et al., 2018</ref>) extended the work of ( <ref type="bibr" target="#b6">Nguyen et al., 2017)</ref> by asking users to provide feedback for partial hypotheses to iteratively gen- erate the translation, their goal is to minimize the required human involvement. They performed simulated experiments using chrF <ref type="bibr" target="#b8">(Popovic, 2015)</ref> as simulated feedback.</p><p>In all previous works feedback needs to be gen- erated on-line during the training process, however in this paper we focus on the case where there might be a significant time lag between genera- tion of translation and acquiring of the feedback. <ref type="bibr" target="#b2">Lawrence et al. (2017)</ref> have proposed a method to leverage user feedback that is available only for logged translated data for a phrase-based statisti- cal machine translation system.</p><p>( <ref type="bibr">Kreutzer et al., 2018)</ref> have experimented with sentence level star ratings collected from real users of an e-commerce site for logged translation data, but found the feedback to be too noisy to gain im- provements. They also proposed using implicit word level task feedback based on query match- ing in an e-commerce application to improve both translation quality and task specific metrics. <ref type="bibr" target="#b4">Marie and Max (2015)</ref> have proposed an in- teractive framework which iteratively improves translation generated by the phrase-based system by asking users to select correct parts. <ref type="bibr">Domingo et al. (2016)</ref> extended this idea to also include word deletions and substitutions with the goal of reduc- ing human effort in translation. <ref type="bibr">Grangier and Auli (2017)</ref> have studied the task of paraphrasing an already generated translation by excluding words that the user has marked as incorrect. They modify NMT model to also ac- cept the marked target sentence as input and train it to produce similar sentences that do not contain marked words.</p><p>( <ref type="bibr" target="#b12">Chen et al., 2017;</ref><ref type="bibr" target="#b12">Wang et al., 2017</ref>) have pro- posed sentence level weighting method for domain adaptation in NMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this work we use the encoder-decoder NMT ar- chitecture with attention, proposed by ( <ref type="bibr">Bahdanau et al., 2014;</ref><ref type="bibr" target="#b11">Sutskever et al., 2014</ref>). NMT model is trained to maximize the conditional likelihood of a target sentence e I 1 : e 1 , . . . , e I given a source sentence</p><formula xml:id="formula_0">f J 1 : f 1 , . . . , f J from a parallel dataset D: L = f J 1 ,e I 1 ∈D I i=1 log p(e i |e i−1 1 , f J 1 ).<label>(1)</label></formula><p>Training objective <ref type="formula" target="#formula_0">(1)</ref> is appropriate when the tar- get sentence e I 1 comes from real data. However, we would like to benefit from model-generated sentences˜esentences˜ sentences˜e I 1 by introducing partial feedback. We assume that partial feedback for a sentence˜e sentence˜ sentence˜e I 1 is given as a sequence of binary values w I 1 : w 1 , . . . , w I , such that w i = 1 if the word˜eword˜ word˜e i is marked as correct, w i = 0 if it is unrated or incor- rect. We propose a simple modification to the loss in Equation (1):</p><formula xml:id="formula_1">L P F = f J 1 ,˜ e I 1 ,w I 1 ∈D I i=1 w i log p(˜ e i |˜e|˜e i−1 1 , f J 1 ) (2)</formula><p>Considering the definition of the binary partial feedback, the model would be trained to predict correct target words, while ignoring unrated and incorrect ones. However, incorrect words are still used as inputs to the model and influence the pre- diction context of correct words. While partial feedback is gathered in a binary form (selected/not selected), word weights w i can take any real value, depending on the weight as- signment scheme.</p><p>Our training objective can be seen as a general- ization of sentence level weighting method <ref type="bibr" target="#b12">(Chen et al., 2017;</ref><ref type="bibr" target="#b12">Wang et al., 2017</ref>). The special case of sentence level weight can be expressed as w i = w, ∀i , where w is the weight for sentence˜esentence˜ sentence˜e I 1 .</p><p>We differentiate between two practical methods of obtaining the partial feedback data. First, gath- ering the feedback from humans, by presenting them with translations and asking to highlight cor- rect words. This method is expected to produce high quality feedback, but is relatively expensive and, to the best of our knowledge, no such dataset is publicly available.</p><p>Another method is to generate partial feedback automatically using heuristics or statistical mod- els. This type of feedback would be cheap to ob- tain, but is unlikely to be of high quality.</p><p>In this paper, to show the effectiveness of high quality chunk feedback, we generate artificial feedback by comparing model predictions to refer- ence translations using heuristic methods. This ap- proach is cheap, produces high quality feedback, but is not practically useful, because it requires ac- cess to reference human translation.</p><p>We have experimented with several methods of extracting artificial feedback. A simple match- ing method assigns w i = 1 if predicted word˜eword˜ word˜e i is present in reference translation at any position, and w i = 0 otherwise. A slightly more sophisti- cated method is to find the longest common sub- string (LCS) between the predicted and reference translations and set the weights for words which belong to the LCS to 1, and to 0 otherwise. In our experiments we have found the latter method to perform slightly better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we conduct a series of experiments to study how well an NMT system is able to learn only from partial user feedback when this feed- back is given for in-domain translations, whereas the baseline system is trained on out-of-domain data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We report results on two datasets: WMT 2017 German to English news translation task ( <ref type="bibr">Bojar et al., 2017</ref>) and an in-house English to Spanish dataset in the e-commerce domain. On all data we apply byte-pair encoding ( <ref type="bibr" target="#b9">Sennrich et al., 2016</ref>) with 40,000 merge operations learned separately for each language.</p><p>For each dataset we separate the larger out- of-domain and smaller in-domain training data. For De-En we use 1.8M sentence pairs randomly sampled from available parallel corpora as out- of-domain data and 800K sentence pairs sampled from back-translated monolingual and unused par- allel corpora as in-domain data. For En-Es we have 2.7M out-of-domain and 1.5M in-domain sentence pairs. We evaluate our models on new- stest2016 (2999 sentence pairs) for the De-En task and an in-house test set of 1000 sentence pairs for the En-Es task using case-insensitive BLEU <ref type="bibr" target="#b7">(Papineni et al., 2002</ref>) and TER ( <ref type="bibr" target="#b10">Snover et al., 2006</ref>).</p><p>We have implemented our NMT model using TensorFlow ( <ref type="bibr">Abadi et al., 2015</ref>) library. Our en- coder is a bidirectional LSTM with a layer size of 512; our decoder is an LSTM with 2 layers of the same size. We also use embedding size of 512 and MLP attention layer. We train our networks using SGD with a learning rate schedule that starts grad- ually decaying to 0.01 after the initial 4 epochs. As regularization we use dropout on the RNN inputs with dropping probability of 0.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We pre-train baseline NMT models on parallel out-of-domain data for 15 epochs. We then use the pre-trained model to generate translations from the source side of parallel in-domain corpus. Using heuristics described in Section 3 and the reference target side of the in-domain corpus we generate ar- tificial partial feedback to simulate real user input. Then we continue training with a small learning rate for another 10 epochs on in-domain data with or without user feedback.</p><p>In <ref type="table">Table 1</ref>, we show the effect of different types of feedback on translation performance. First, we see that even using no feedback slightly improves the model due to self-training on automatically translated in-domain data.</p><p>Introducing sentence level feedback improves De-En and En-Es models by at most 0.2% and 0.6% absolute BLEU, respectively. Sentence level feedback is artificially generated from parallel cor- pora using heuristics, similar to the ones described in Section 3, but w i , ∀i are set to the same sen- tence weight w. For example, we have tried using sentence BLEU (sBLEU) and a binary rule, which outputs 1 if more than 33% of predicted words were marked as correct, and 0 otherwise (binary). We have also experimented with other heuristics, but did not achieve better results.</p><p>Finally, chunk-based feedback approach based on LCS improves on top of sentence level feed- back by another 0.7% and 2.6% BLEU for De-  <ref type="table">Table 1</ref>: Chunk-level feedback compared to sentence-level feedback. Self-training is equiva- lent to having no feedback or setting all w i = 1, ∀i in the training objective in Eq. (2). sent-sBLEU and sent-binary are sentence-level methods with sentence BLEU and binary weighting rules, de- fined as in Section 4.2. chunk-match and chunk- lcs-level feedback refers to assigning w i using simple matching or LCS method described in Sec- tion 3.</p><formula xml:id="formula_2">De-En En-Es BLEU TER BLEU TER [%] [%] [%] [%]</formula><p>En and En-Es, respectively. We also note a sig- nificant improvement of 1.3% and 3.1% in TER. Chunk-based approach based on simple matching also outperforms sentence level methods, but not by as much as lcs-based, which suggests that this method benefits more from consecutive segments, rather than single correct words. We believe that the success of the partial feed- back approach can be explained by the fact that of- ten a sentence can be split into chunks which can be translated independently of the context. Re- inforcement of the correct translation of such a chunk in one training example seems to positively affect translations of such chunks in other, differ- ent sentences. By focusing on the good and mask- ing out erroneous chunks, partial feedback acts as a precise noise reduction method.</p><p>We have also trained the models using fine- tuning ( <ref type="bibr" target="#b3">Luong and Manning, 2015</ref>) on the ref- erence target in-domain data, which further im- proved translation by 2% and 3.8% BLEU on De-En and En-Es compared to using chunk-based feedback. We note that by using partial feedback we are able to recover between 30% and 45% of improvements that come from in-domain adapta- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Robustness</head><p>The proposed artificially generated partial feed- back is very precise as it does not introduce any  <ref type="table">Table 2</ref>: Impact of user errors on the translation performance. Under selection ratio% indicates on average what percentage of words in a correct chunk have not been selected in user simulation, but all selected words are correct. Incorrect se- lection ratio% indicates what percentage of words are incorrectly selected, here the total number of marked words is the same as in chunk-level feed- back. In the last row, 10% of marked words are actually incorrect and the total number of marked words is 25% less compared to system in row 1.</p><formula xml:id="formula_3">De-En En-Es # BLEU TER BLEU TER [%] [%] [%] [%] 1</formula><p>type of noise in marking of good chunks. For example, on the En-Es dataset artificial methods mark 40% of all words as correct. However, a user might not mark all the correct words in a sentence, but select only a few. Furthermore, artificially generated partial feed- back does not contain noise, given that the refer- ence translation is adequate. However, users may make mistakes in selection. We differentiate two types of errors that a user can make: under selec- tion, when a correct word was not marked; and incorrect selection, when an incorrect word was marked as correct.</p><p>To anticipate the impact of these mistakes we experiment with deliberately impairing the feed- back in <ref type="table">Table 2</ref>. We see that randomly dropping 25% of the selection has very little effect on the model, while dropping 50% and more decreases the translation performance significantly, yet still performing at the same level or better than self- training system.</p><p>When selection contains noise, the impact al- ready becomes noticeable at 10%. Increasing the amount of noise up to 25% decreases the perfor-mance by 1.6% BLEU in En-Es task. At 50% noise level, which is similar to random selection, there is no improvement from using feedback at all. While we expect users to provide mostly clean feedback, this result indicates the necessity of cleaning user feedback data, e.g. by aggregat- ing feedback from multiple users.</p><p>We have also experimented with replacing uns- elected words by random noise and saw only small decrease in translation performance, which sug- gests that our approach is able to benefit from very poor translations, as long as the selected chunk is correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Example</head><p>An example where the NMT system with chunk- based feedback yields a better translation in com- parison to other systems is the German sentence "Die Krise ist vorüber." ("The crisis is over."). The German word "vorüber" is rare and ambigu- ous, especially after the BPE-based splitting. The system with self-training translates the sentence as "The crisis is above all.", whereas the system with chunk-based feedback exactly matches the refer- ence translation. We have analyzed the feedback training set: in that data, out of nine occurrences of the word "vorüber" with the reference transla- tion "over", the baseline system got it right three times, getting rewards for the chunks "is over ...", "is over", "is over ."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and future work</head><p>In this work, we have proposed a simple way to integrate partial chunk-based feedback into NMT training. We have experimented with artificially created partial feedback and shown that using par- tial feedback results in significant improvements of MT quality in terms of BLEU and TER. We have shown that chunk-level feedback can be used more effectively than sentence-level feedback. We have studied the robustness of our approach and observed that our model is robust against a moder- ate amount of noise.</p><p>We argue that collecting partial feedback by asking users to highlight correct parts of a transla- tion is more intuitive for users than sentence level ratings and leads to less variation and errors.</p><p>In the future, we plan to investigate how to in- tegrate negative partial user feedback, as well as automatic feedback generation methods which do not rely on existing parallel data.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Tsz Kin Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kreutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riezler</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">A Reinforcement Learning Approach to Interactive-Predictive Neural Machine Translation. ArXiv:1805.01553v1</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Counterfactual learning from bandit feedback under deterministic logging : A case study in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolin</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Sokolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="2566" to="2576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stanford neural machine translation systems for spoken language domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<editor>Marcello Federico, Sebastian Stker</editor>
		<meeting>the International Workshop on Spoken Language Translation<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-01-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Touchbased pre-post-editing of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1040" to="1045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adria</forename><forename type="middle">Puigdomenech</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1928" to="1937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reinforcement learning for bandit neural machine translation with simulated human feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">L</forename><surname>Boydgraber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="1464" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">chrf: character n-gram f-score for automatic MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page" from="392" to="395" />
		</imprint>
		<respStmt>
			<orgName>The Association for Computer Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016-08-07" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Association for Machine Translation in the Americas</title>
		<meeting>Association for Machine Translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Instance weighting for neural machine translation domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lemao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kehai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1482" to="1488" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
