<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical MT Training using Max-Violation Perceptron</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 23-25 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
							<email>{kzhao@gc,huang@cs.qc}.cuny.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate Center &amp; Queens College City</orgName>
								<orgName type="department" key="dep2">T. J. Watson Research Center IBM</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate Center &amp; Queens College City</orgName>
								<orgName type="department" key="dep2">T. J. Watson Research Center IBM</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate Center &amp; Queens College City</orgName>
								<orgName type="department" key="dep2">T. J. Watson Research Center IBM</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Ittycheriah</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate Center &amp; Queens College City</orgName>
								<orgName type="department" key="dep2">T. J. Watson Research Center IBM</orgName>
								<orgName type="institution">University of New York</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical MT Training using Max-Violation Perceptron</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="785" to="790"/>
							<date type="published">June 23-25 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Large-scale discriminative training has become promising for statistical machine translation by leveraging the huge training corpus; for example the recent effort in phrase-based MT (Yu et al., 2013) significantly outperforms mainstream methods that only train on small tuning sets. However, phrase-based MT suffers from limited reorderings, and thus its training can only utilize a small portion of the bi-text due to the distortion limit. To address this problem, we extend Yu et al. (2013) to syntax-based MT by generalizing their latent variable &quot;violation-fixing&quot; percep-tron from graphs to hypergraphs. Experiments confirm that our method leads to up to +1.2 BLEU improvement over mainstream methods such as MERT and PRO.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many natural language processing problems in- cluding part-of-speech tagging <ref type="bibr" target="#b6">(Collins, 2002</ref>), parsing <ref type="bibr" target="#b18">(McDonald et al., 2005</ref>), and event extrac- tion ( <ref type="bibr" target="#b16">Li et al., 2013)</ref> have enjoyed great success us- ing large-scale discriminative training algorithms. However, a similar success on machine translation has been elusive, where the mainstream methods still tune on small datasets.</p><p>What makes large-scale MT training so hard then? After numerous attempts by various re- searchers ( <ref type="bibr" target="#b17">Liang et al., 2006</ref>; <ref type="bibr" target="#b20">Watanabe et al., 2007;</ref><ref type="bibr" target="#b0">Arun and Koehn, 2007;</ref><ref type="bibr" target="#b1">Blunsom et al., 2008;</ref><ref type="bibr" target="#b4">Chiang et al., 2008;</ref><ref type="bibr" target="#b8">Flanigan et al., 2013;</ref><ref type="bibr" target="#b9">Green et al., 2013)</ref>, the recent work of <ref type="bibr" target="#b21">Yu et al. (2013)</ref> finally reveals a major reason: it is the vast amount of (inevitable) search errors in MT decod- ing that astray learning. To alleviate this prob- lem, their work adopts the theoretically-motivated framework of violation-fixing perceptron <ref type="bibr" target="#b12">(Huang et al., 2012</ref>) tailed for inexact search, yielding great results on phrase-based MT (outperforming small-scale MERT/PRO by a large margin for the first time). However, the underlying phrase-based model suffers from limited distortion and thus can only employ a small portion (about 1/3 in their Ch- En experiments) of the bitext in training.</p><p>To better utilize the large training set, we propose to generalize from phrase-based MT to syntax-based MT, in particular the hierarchical phrase-based translation model (HIERO) <ref type="bibr" target="#b5">(Chiang, 2005)</ref>, in order to exploit sentence pairs beyond the expressive capacity of phrase-based MT.</p><p>The key challenge here is to extend the latent variable violation-fixing perceptron of <ref type="bibr" target="#b21">Yu et al. (2013)</ref> to handle tree-structured derivations and translation hypergraphs. Luckily, <ref type="bibr" target="#b22">Zhang et al. (2013)</ref> have recently generalized the underlying violation-fixing perceptron of <ref type="bibr" target="#b12">Huang et al. (2012)</ref> from graphs to hypergraphs for bottom-up parsing, which resembles syntax-based decoding. We just need to further extend it to handle latent variables. We make the following contributions:</p><p>1. We generalize the latent variable violation- fixing perceptron framework to inexact search over hypergraphs, which subsumes previous algorithms for PBMT and bottom- up parsing as special cases (see <ref type="figure" target="#fig_0">Fig. 1</ref>).</p><p>2. We show that syntax-based MT, with its bet- ter handling of long-distance reordering, can exploit a larger portion of the training set, which facilitates sparse lexicalized features.</p><p>3. Experiments show that our training algo- rithm outperforms mainstream tuning meth- ods (which optimize on small devsets) by +1.2 BLEU over MERT and PRO on FBIS.</p><p>id rule</p><formula xml:id="formula_0">r 0 S → X 1 , X 1 r 1 S → S 1 X 2 , S 1 X 2 r 2 X → B` ushí, Bush r 3 X → Sh¯ alóng, Sharon r 4 X →hù ıtán, talks r 5 X → yˇuyˇu X 1 jˇuxíngjˇuxíng X 2 ,</formula><p>held X 2 with X 1 r 6 X → yˇuyˇu Sh¯ alóng, with Sharon</p><formula xml:id="formula_1">r 7 X → X 1 jˇuxíngjˇuxíng X 2 , X 1 held X 2 S [0:5]</formula><p>X <ref type="bibr">[1:5]</ref> X <ref type="bibr">[4:5]</ref> hù ıtán 5 jˇuxíngjˇuxíng 4</p><formula xml:id="formula_2">X [2:3] Sh¯ alóng 3 | yˇuyˇu 2 S [0:1] X [0:1] 0 B` ushí 1 S X X Sharon 5 with 4 X talks 3 held 2 S X 0 Bush 1 S [0:5]</formula><p>X <ref type="bibr">[1:5]</ref> X <ref type="bibr">[4:5]</ref> hù ıtán 5 jˇuxíngjˇuxíng 4 X <ref type="bibr">[1:3]</ref> Sh¯ alóng 3 yˇuyˇu 2 </p><formula xml:id="formula_3">S [0:1] X [0:1] 0 B` ushí 1 S X X talks 5 held 4 X Sharon 3 with 2 S X 0 Bush 1 (a) HIERO rules (b) gold derivation (c) Viterbi derivation</formula><formula xml:id="formula_4">X [0:1] X [2:3] X [4:5] X [1:5] X [1:3] S [0:1] S [0:5]</formula><p>Figure 3: A −LM hypergraph with two deriva- tions: the gold derivation <ref type="figure" target="#fig_1">(Fig. 2b</ref>) in solid lines, and the Viterbi derivation ( <ref type="figure" target="#fig_1">Fig. 2c</ref>) in dashed lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Review: Syntax-based MT Decoding</head><p>For clarity reasons we will describe HIERO decod- ing as a two-pass process, first without a language model, and then integrating the LM. This section mostly follows <ref type="bibr" target="#b11">Huang and Chiang (2007)</ref>. In the first, −LM phase, the decoder parses the source sentence using the source projection of the synchronous grammar (see <ref type="figure" target="#fig_1">Fig. 2</ref> (a) for an ex- ample), producing a −LM hypergraph where each node has a signature N <ref type="bibr">[i:j]</ref> , where N is the nonter- minal type (either X or S in HIERO) and <ref type="bibr">[i : j]</ref> is the span, and each hyperedge e is an application of the translation rule r(e) (see <ref type="figure">Figure 3)</ref>.</p><p>To incorporate the language model, each node also needs to remember its target side boundary words. Thus a −LM node N <ref type="bibr">[i:j]</ref> is split into mul- tiple +LM nodes of signature N aab <ref type="bibr">[i:j]</ref> , where a and b are the boundary words. For example, with a bi- gram LM, X heldSharon <ref type="bibr">[1:5]</ref> is a node whose translation starts with "held" and ends with "Sharon".</p><p>More formally, the whole decoding process can be cast as a deductive system. Take the partial translation of "held talks with Sharon" in <ref type="figure" target="#fig_1">Figure 2</ref> (b) for example, the deduction is X SharonSharon <ref type="bibr">[2:3]</ref> : s 1 X talkstalks <ref type="bibr">[4:5]</ref> : s 2 X heldSharon <ref type="bibr">[1:5]</ref> :</p><formula xml:id="formula_5">s 1 + s 2 + s(r 5 ) + λ r 5 ,</formula><p>where s(r 5 ) is the score of rule r 5 , and the LM combo score λ is log P lm (talks | held)P lm (with | talks)P lm (Sharon | with).  <ref type="formula">(2012)</ref> from graphs to hypergraphs for bottom-up parsing, which resembles HIERO decoding. So we just need to combine the two generalizing directions (latent variable and hyper- graph, see <ref type="figure" target="#fig_0">Fig. 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Latent Variable Hypergraph Search</head><p>The key difference between bottom-up parsing and MT decoding is that in parsing the gold tree for each input sentence is unique, while in MT many derivations can generate the same reference translation. In other words, the gold derivation to update towards is a latent variable.</p><p>Here we formally define the latent variable "max-violation" perceptron over a hypergraph for MT training. For a given sentence pair x, y, we denote H(x) as the decoding hypergraph of HI- ERO without any pruning. We say D ∈ H(x) if D is a full derivation of decoding x, and D can be derived from the hypergraph. Let good (x, y) be the set of y-good derivations for x, y:</p><formula xml:id="formula_6">good (x, y) ∆ = {D ∈ H(x) | e(D) = y},</formula><p>where e(D) is the translation from derivation D. We then define the set of y-good partial derivations that cover x <ref type="bibr">[i:j]</ref> with root N <ref type="bibr">[i:j]</ref> as</p><formula xml:id="formula_7">good N [i:j] (x, y) ∆ = {d ∈ D | D ∈ good (x, y), root(d) = N [i:j] }</formula><p>We further denote the real decoding hypergraph with beam-pruning and cube-pruning as H (x). The set of y-bad derivations is defined as</p><formula xml:id="formula_8">bad N [i:j] (x, y) ∆ = {d ∈ D | D ∈ H (x, y), root(d) = N [i:j] , d ∈ good N [i:j] (x, y)}.</formula><p>Note that the y-good derivations are defined over the unpruned whole decoding hypergraph, while the y-bad derivations are defined over the real de- coding hypergraph with pruning.</p><p>The max-violation method performs the update where the model score difference between the incorrect Viterbi partial derivation and the best y-good partial derivation is maximal, by penaliz- ing the incorrect Viterbi partial derivation and re- warding the y-good partial derivation.</p><p>More formally, we first find the Viterbi partial derivation d − and the best y-good partial deriva- tion d + for each N <ref type="bibr">[i:j]</ref> group in the pruned +LM hypergraph:</p><formula xml:id="formula_9">d + N [i:j] (x, y) ∆ = argmax d∈good N [i:j] (x,y) w · Φ(x, d), d − N [i:j] (x, y) ∆ = argmax d∈bad N [i:j] (x,y) w · Φ(x, d),</formula><p>where Φ(x, d) is the feature vector for derivation d. Then it finds the group N * [i * :j * ] with the max- imal score difference between the Viterbi deriva- tion and the best y-good derivation:</p><formula xml:id="formula_10">N * [i * :j * ] ∆ = argmax N [i:j] w · ∆Φ(x, d + N [i:j] (x, y), d − N [i:j] (x, y)),</formula><p>and update as follows:</p><formula xml:id="formula_11">w ← w + ∆Φ(x, d + N * [i * :j * ] (x, y), d − N * [i * :j * ] (x, y)),</formula><p>where</p><formula xml:id="formula_12">∆Φ(x, d, d ) ∆ = Φ(x, d) − Φ(x, d ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Forced Decoding for HIERO</head><p>We now describe how to find the gold derivations. 1 Such derivations can be generated in way similar to <ref type="bibr" target="#b21">Yu et al. (2013)</ref> by using a language model tai- lored for forced decoding:</p><formula xml:id="formula_13">P forced (q | p) = 1 if q = p + 1 0 otherwise ,</formula><p>where p and q are the indices of the boundary words in the reference translation. The +LM node now has signature N ppq <ref type="bibr">[i:j]</ref> , where p and q are the in- dexes of the boundary words. If a boundary word does not occur in the reference, its index is set to ∞ so that its language model score will always be −∞; if a boundary word occurs more than once in the reference, its −LM node is split into multiple +LM nodes, one for each such index. <ref type="bibr">2</ref> We have a similar deductive system for forced decoding. For the previous example, rule r 5 in <ref type="figure" target="#fig_1">Figure 2</ref> (a) is rewritten as X → yˇuyˇu X 1 jˇuxíngjˇuxíng X 2 , 1 X 2 4 X 1 , where 1 and 4 are the indexes for reference words "held" and "with" respectively. The deduction for X <ref type="bibr">[1:5]</ref> in <ref type="figure" target="#fig_1">Figure 2 (</ref> where λ = log i∈{1,3,4} P forced (i + 1 | i) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Following <ref type="bibr" target="#b21">Yu et al. (2013)</ref>, we call our max- violation method MAXFORCE. Our implemen- tation is mostly in Python on top of the cdec system ( <ref type="bibr" target="#b7">Dyer et al., 2010</ref>) via the pycdec in- terface ( <ref type="bibr" target="#b2">Chahuneau et al., 2012</ref>). In addition, we use minibatch parallelization of ( ) to speedup perceptron training. We evalu- ate MAXFORCE for HIERO over two CH-EN cor- pora, IWSLT09 and FBIS, and compare the per- formance with vanilla n-best MERT (Och, 2003) from Moses ( , Hypergraph MERT ( <ref type="bibr" target="#b15">Kumar et al., 2009)</ref>, and PRO (Hopkins and May, 2011) from cdec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Features Design</head><p>We use all the 18 dense features from cdec, in- cluding language model, direct translation prob- ability p(e|f ), lexical translation probabilities p l (e|f ) and p l (f |e), length penalty, counts for the source and target sides in the training corpus, and flags for the glue rules and pass-through rules.</p><p>For sparse features we use Word-Edges fea- tures <ref type="bibr" target="#b3">(Charniak and Johnson, 2005;</ref><ref type="bibr" target="#b13">Huang, 2008)</ref> which are shown to be extremely effective in both parsing and phrase-based MT ( <ref type="bibr" target="#b21">Yu et al., 2013)</ref>. We find that even simple Word-Edges features boost the performance significantly, and adding complex Word-Edges features from <ref type="bibr" target="#b21">Yu et al. (2013)</ref> brings limited improvement and slows down the decoding. So in the following experi- ments we only use Word-Edges features consisting of combinations of English and Chinese words, and Chinese characters, and do not use word clus- ters nor word types. For simplicity and efficiency reasons, we also exclude all non-local features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets and Preprocessing</head><p>Our first corpus, IWSLT09, contains ∼30k short sentences collected from spoken language. IWSLT04 is used as development set in MAX- FORCE training, and as tuning set for n-best MERT, Hypergraph MERT, and PRO. IWSLT05 is used as test set. Both IWSLT04 and IWSLT05 contain 16 references.We mainly use this corpus to investigate the properties of MAXFORCE.</p><p>The second corpus, FBIS, contains ∼240k sen- tences. NIST06 newswire is used as development set for MAXFORCE training, and as tuning set for all other tuning methods. NIST08 newswire is used as test set. Both NIST06 newswire and NIST08 newswire contain 4 references. We mainly use this corpus to demonstrate the perfor- mance of MAXFORCE in large-scale training.</p><p>For both corpora, we do standard tokeniza- tion, alignment and rule extraction using the cdec tools. In rule extraction, we remove all 1-count rules but keep the rules mapping from one Chi- nese word to one English word to help balancing sent. words <ref type="table" target="#tab_1">phrase-based MT 32% 12%  HIERO  35% 30%  HIERO (all rules)</ref> 65% 55% <ref type="table">Table 1</ref> See text below for "loose" and "tight".</p><p>between overfitting and coverage. We use a tri- gram language model trained from the target sides of the two corpora respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Forced Decoding Reachability</head><p>We first report the forced decoding reachability for HIERO on FBIS in <ref type="table">Table 1</ref>. With the full rule set, 65% sentences and 55% words of the whole cor- pus are forced decodable in HIERO. After pruning 1-count rules, our forced decoding covers signif- icantly more words than phrase-based MT in <ref type="bibr" target="#b21">Yu et al. (2013)</ref>. Furthermore, in phrase-based MT, most decodable sentences are very short, while in HIERO the lengths of decodable sentences are more evenly distributed. However, in the following experiments, due to efficiency considerations, we use the "tight" rule extraction in cdec that is more strict than the standard "loose" rule extraction, which generates a reduced rule set and, thus, a reduced reachabil- ity. We show the reachability distributions of both tight and loose rule extraction in <ref type="figure" target="#fig_3">Figure 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation on IWSLT</head><p>For IWSLT, we first compare the performance from various update methods in <ref type="figure">Figure 5</ref>. The max-violation method is more than 15 BLEU 788 points better than the standard perceptron (also known as "bold-update" in <ref type="bibr" target="#b17">Liang et al. (2006)</ref>) which updates at the root of the derivation tree. <ref type="bibr">3,</ref><ref type="bibr">4</ref> This can be explained by the fact that in train- ing ∼58% of the standard updates are invalid (i.e., they do not fix any violation). We also use the "skip" strategy of <ref type="bibr" target="#b22">Zhang et al. (2013)</ref> which up- dates at the root of the derivation only when it fixes a search error, avoiding all invalid updates. This achieves ∼10 BLEU better than the standard up- date, but is still more than ∼5 BLEU worse than Max-Violation update. Finally we also try the "local-update" method from <ref type="bibr" target="#b17">Liang et al. (2006)</ref> which updates towards the derivation with the best Bleu +1 in the root group S <ref type="bibr">[0:|x|]</ref> . This method is about 2 BLEU points worse than max-violation.</p><p>We further investigate the contribution of sparse features in <ref type="figure" target="#fig_4">Figure 6</ref>. On the development set, max-violation update without Word-Edges fea- tures achieves BLEU similar to n-best MERT and <ref type="bibr">3</ref> We find that while MAXFORCE generates translations of length ratio close to 1 during training, the length ratios on dev/test sets are significantly lower, due to OOVs. So we run a binary search for the length penalty weight after each training iteration to tune the length ratio to ∼0.97 on dev set. <ref type="bibr">4</ref> We report BLEU with averaged reference lengths. algorithm # feats dev test n-best MERT 18 44.9 47.9 Hypergraph MERT 18 46.6 50.7 PRO 18 45.0 49.5 local update perc. 443K 45.6 49.1 MAXFORCE 529K 47.4 51.5   <ref type="table" target="#tab_1">Table 2</ref> for details. The results of n-best MERT, Hypergraph MERT, and PRO are averages from 3 runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Evaluation on FBIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have presented a latent-variable violation- fixing framework for general structured predic- tion problems with inexact search over hyper- graphs. Its application on HIERO brings signif- icant improvement in BLEU, compared to algo- rithms that are specially designed for MT tuning such as MERT and PRO.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Relationship with previous work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example of HIERO translation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3</head><label></label><figDesc>Violation-Fixing Perceptron for HIERO As mentioned in Section 1, the key to the success of Yu et al. (2013) is the adoption of violation- fixing perceptron of Huang et al. (2012) which is tailored for vastly inexact search. The general idea is to update somewhere in the middle of the search (where search error happens) rather than at the very end (standard update is often invalid). To adapt it to MT where many derivations can output the same translation (i.e., spurious ambiguity), Yu et al. (2013) extends it to handle latent variables which correspond to phrase-based derivations. On the other hand, Zhang et al. (2013) has generalized Huang et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>:Figure 4 :</head><label>4</label><figDesc>Figure 4: Reachability vs. sent. length on FBIS. See text below for "loose" and "tight".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 5: Comparison of various update methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>BLEU scores (with 16 references) of var-
ious training algorithms on IWSLT09. 

algorithm 
# feats dev test 
Hypergraph MERT 
18 
27.3 23.0 
PRO 
18 
26.4 22.7 
MAXFORCE 
4.5M 27.7 23.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>BLEU scores (with 4 references) of vari-
ous training algorithms on FBIS. 

PRO, but lower than Hypergraph MERT. Adding 
simple Word-Edges features improves BLEU by 
∼2 points, outperforming the very strong Hyper-
graph MERT baseline by ∼1 point. See </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 shows</head><label>3</label><figDesc></figDesc><table>BLEU scores of Hypergraph MERT, 
PRO, and MAXFORCE on FBIS. MAXFORCE ac-
tives 4.5M features, and achieves +1.2 BLEU over 
PRO and +0.9 BLEU over Hypergraph MERT. The 
training time (on 32 cores) for Hypergraph MERT 
and PRO is about 30 min. on the dev set, and is 
about 5 hours for MAXFORCE on the training set. 

</table></figure>

			<note place="foot" n="1"> We only consider single reference in this paper. 2 Our formulation of index-based language model fixes a bug in the word-based LM of Yu et al. (2013) when a substring appears more than once in the reference (e.g. &quot;the man...the man...&quot;); thanks to Dan Gildea for pointing it out.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Part of this work was done during K. Z.'s intern-ship at IBM. We thank Martiň Cmejrek and Lemao Liu for discussions, David Chiang for pointing us to pycdec, Dan Gildea for Footnote 2, and the anonymous reviewers for comments. This work is supported by DARPA FA8750-13-2-0041 (DEFT), DARPA HR0011-12-C-0015 (BOLT), and a Google Faculty Research Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Online learning methods for discriminative training of phrase based statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT Summit XI</title>
		<meeting>of MT Summit XI</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A discriminative latent variable model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="200" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">pycdec: A python interface to cdec</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="issue">98</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Coarseto-fine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Online large-margin training of syntactic and structural translation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A hierarchical phrase-based model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnathan</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendra</forename><surname>Setiawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
		<meeting>the ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Large-scale discriminative training for statistical machine translation using held-out line search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2013</title>
		<meeting>NAACL 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fast and adaptive online training of feature-rich translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>to appear) ACL</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tuning as ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Forest rescoring: Fast decoding with integrated language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Prague, Czech Rep</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Structured perceptron with inexact search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suphan</forename><surname>Fayong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Forest reranking: Discriminative parsing with non-local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL: HLT</title>
		<meeting>the ACL: HLT<address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Moses: open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of ACL and AFNLP</title>
		<meeting>the Joint Conference of ACL and AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Joint event extraction via structured prediction with global features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An end-to-end discriminative approach to machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Bouchard-Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
		<meeting>COLING-ACL<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd ACL</title>
		<meeting>the 43rd ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Joseph</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Online large-margin training for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Max-violation perceptron and forced decoding for scalable MT training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Online learning with inexact hypergraph search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Minibatch and parallelization for online large margin structured learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2013</title>
		<meeting>NAACL 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
