<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Platforms for Non-Speakers Annotating Names in Any Language</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>July 15-20, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Rensselaer Polytechnic Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Platforms for Non-Speakers Annotating Names in Any Language</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations</title>
						<meeting>the 56th Annual Meeting of the Association for Computational Linguistics-System Demonstrations <address><addrLine>Melbourne, Australia</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1" to="6"/>
							<date type="published">July 15-20, 2018</date>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We demonstrate two annotation platforms that allow an English speaker to annotate names for any language without knowing the language. These platforms provided high-quality &quot;silver standard&quot; annotations for low-resource language name taggers (Zhang et al., 2017) that achieved state-of-the-art performance on two surprise languages (Oromo and Tigrinya) at LoreHLT2017 1 and ten languages at TAC-KBP EDL2017 (Ji et al., 2017). We discuss strengths and limitations and compare other methods of creating silver-and gold-standard annotations using native speakers. We will make our tools publicly available for research use.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although researchers have been working on unsu- pervised and semi-supervised approaches to alle- viate the demand for training data, most state-of- the-art models for name tagging, especially neu- ral network-based models ) still rely on a large amount of train- ing data to achieve good performance. When ap- plied to low-resource languages, these models suf- fer from data sparsity. Traditionally, native speak- ers of a language have been asked to annotate a cor- pus in that language. This approach is uneconom- ical for several reasons. First, for some languages We thank Kevin Blissett and Tongtao Zhang from RPI for their contributions to the annotations used for the exper- iments. This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) un- der Contracts No. HR0011-15-C-0115 and No. HR0011-16- C-0102. The views, opinions and/or findings expressed are those of the authors and should not be interpreted as represent- ing the official views or policies of the Department of Defense or the U.S. Government.</p><p>1 https://www.nist.gov/itl/iad/mig/lorehlt-evaluations with extremely low resources, it's not easy to ac- cess native speakers for annotation. For example, Chechen is only spoken by 1.4 million people and Rejiang is spoken by 200,000 people. Second, it is costly in both time and money to write an anno- tation guideline for a low-resource language and to train native speakers (who are usually not lin- guists) to learn the guidelines and qualify for an- notation tasks. Third, we observed poor annotation quality and low inter-annotator agreement among newly trained native speakers in spite of high lan- guage proficiency. For example, under DARPA LORELEI, 2 the performance of two native Uighur speakers on name tagging was only 69% and 73% F 1 -score respectively. Previous efforts to generate "silver-standard" annotations used Web search <ref type="bibr" target="#b0">(An et al., 2003)</ref>, par- allel data( <ref type="bibr" target="#b10">Wang and Manning, 2014</ref>), Wikipedia markups ( <ref type="bibr" target="#b6">Nothman et al., 2013;</ref><ref type="bibr" target="#b9">Tsai et al., 2016;</ref>, and crowdsourcing ( <ref type="bibr" target="#b2">Finin et al., 2010)</ref>. Annotations produced by these methods are usually noisy and specific to a particular writing style (e.g., Wikipedia articles), yielding unsatisfac- tory results and poor portability.</p><p>It is even more expensive to teach English- speaking annotators new languages. But can we annotate names in a language we don't know? Let's examine a Somali sentence:</p><p>"Sida uu saxaafadda u sheegay Dr Jaamac Warsame Cali oo fadhigiisu yahay magaal- ada Baardheere hadda waxaa shuban caloolaha la yaalla xarumaha caafimaadka 15-cunug oo lagu arkay fuuq bax joogto ah, wuxuu xusay dhakhtarku in ay wadaan dadaallo ay wax kaga qabanayaan xaaladdan"</p><p>Without knowing anything about Somali, an En- glish speaker can guess that "Jaamac Warsame Cali" is a person name because it's capitalized, the word on its left, "Dr," is similar to "Dr." in En- glish, and its spelling looks similar to the English "Jamac Warsame Ali." Similarly, we can identify "Baardheere" as a location name if we know that "magaalada" in English is "town" from a common word dictionary, and its spelling is similar to the English name "Bardhere."</p><p>What about languages that are not written in Ro- man (Latin) script? Fortunately language universal romanization ( <ref type="bibr" target="#b3">Hermjakob et al., 2018</ref>) or translit- eration 3 tools are available for most living lan- guages. For example, the following is a Tigrinya sentence and its romanized form: An English speaker can guess that "ዓብደልፈታሕ አል-ሲሲ" is a person name because its romanized form "aabedalefataahhe 'ale-sisi" sounds simi- lar to the English name "Abdel-Fattah el-Sissi," and the romanized form of the word on its left, "ፕረዝደንት," (perazedanete) sounds similar to the English word "president."</p><p>Moreover, annotators (may) acquire language- specific patterns and rules gradually during anno- tation; e.g., a capitalized word preceded by "mag- aalaa" is likely to be a city name in Oromo, such as "magaalaa Adaamaa" (Adama city). Synchro- nizing such knowledge among annotators both im- proves annotation quality and boosts productivity.</p><p>The Information Sciences Institute (ISI) devel- oped a "Chinese Room" interface 4 to allow a non- native speaker to translate foreign language text into English, based on a small set of parallel sen- tences that include overlapped words. Inspired by this, RPI and JHU developed two collaborative an- notation platforms that exploit linguistic intuitions and resources to allow non-native speakers to per- form name tagging efficiently and effectively.</p><p>Word recognition. Presentation of text in a fa- miliar alphabet makes it easier to see similarities and differences between text segments, to learn as- pects of the target language morphology, and to re- member sequences previously seen.</p><p>Word pronunciation. Because named entities often are transliterated into another language, ac- cess to the sound of the words is particularly impor- tant for annotating names. Sounds can be exposed either through a formal expression language such as IPA, <ref type="bibr">5</ref> or by transliteration into the appropriate letters of the annotator's native language.</p><p>Word and sentence meaning. The better the annotator understands the full meaning of the text being annotated, the easier it will be both to iden- tify which named entities are likely to be men- tioned in the text and what the boundaries of those mentions are. Meaning can be conveyed in a va- riety of ways: dictionary lookup to provide fixed meanings for individual words and phrases; de- scription of the position of a word or phrase in a semantic space (e.g., Brown clusters or embedding space) to define words that are not found in a dic- tionary; and full sentence translation.</p><p>Word context. Understanding how a word is used in a given instance can benefit greatly from understanding how that word is used broadly, either across the document being annotated, or across a larger corpus of monolingual text. For ex- ample, knowing that a word frequently appears ad- jacent to a known person name suggests it might be a surname, even if the adjacent word in the current context is not known to be a name.</p><p>World knowledge. Knowledge of some of the entities, relations, and events referred to in the text allows the annotator to form a stronger model of what the text as a whole might be saying (e.g., a document about disease outbreak is likely to in- clude organizations like Red Cross), leading to bet- ter judgments about components of the text.</p><p>History. Annotations previously applied to a use of a word form a strong prior on how a new in- stance of the word should be tagged. While some of this knowledge is held by the annotator, it is dif- ficult to maintain such knowledge over time. Pro- grammatic support for capturing prior conclusions (linguistic patterns, word translations, possible an- notations for a mention along with their frequency) and making them available to the annotator is es- sential for large collaborative annotation efforts.</p><p>Adjudication. Disagreements among annota- tors can indicate cases that require closer exami- nation. An adjudication interface is beneficial to enhance precision (see Section 4).</p><p>The next section discusses how we embody these requirements in two annotation platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Annotation Platforms</head><p>We developed two annotation tools to explore the range of ways the desiderata might be fulfilled: ELISA and Dragonfly. After describing these interfaces, <ref type="figure" target="#fig_1">Figure 1</ref> shows how they fulfill the desiderata outlined in <ref type="table" target="#tab_3">Table 2</ref>. Annotation Panel. For each sentence in a doc- ument, we show the text in the original language, its English translation if available, and automatic romanization results generated with a language- universal transliteration library. <ref type="bibr">7</ref> To label a name mention, the annotator clicks its first and last to- kens, then chooses the desired entity type in the annotation panel. If the selected text span has been labeled before, previous annotations are displayed at the bottom of the panel for reference. clicking a token in the document will show its full definition in lexicons and bilingual example sen- tences containing that token. A floating pop-up displaying romanization and simple definition ap- pears instantly when hovering over a token. Rule Editor. Annotators may discover useful hueristics to identify and classify names, such as personal designators and suffixes indicative of lo- cations. They can encode such clues as rules in the rule editor. Once created, each rule is rendered as a strikethrough line in the text and is shared among annotators. For example <ref type="figure" target="#fig_1">(Figure 1</ref>, if an annotator marks "agency" as an organization, all annotators will see a triangular sign below each occurrence of this word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ELISA</head><p>Adjudication Interface. If multiple users pro- cess the same document we can consolidate their annotations through an adjudication interface <ref type="figure" target="#fig_3">(Fig- ure 3)</ref>. This interface is similar to the annota- tion interface, except that competing annotations are displayed as blocks below the text. Clicking a block will accept the associated annotation. The adjudicator can accept annotations from either an- notator or accept the agreed cases at once by click- ing one of the three interface buttons. Then, the ad- judicator need only focus on disputed cases, which are highlighted with a red background.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dragonfly</head><p>Dragonfly, developed at the Johns Hopkins Uni- versity Applied Physics Laboratory, takes a more word-centric approach to annotation. Each sen- tence to be annotated is laid out in a row, each col- umn of which shows a word augmented with a va- riety of information about that word. <ref type="figure" target="#fig_4">Figure 4</ref> shows a screenshot of a portion of the Dragonfly tool being used to annotate text written in the Kannada language. The top entry in each column is the Kannada word. Next is a Roman- ization of the word <ref type="figure" target="#fig_1">(Hermjakob et al., 2018)</ref>. The third entry is one or more dictionary translations, if available. The fourth entry is a set of dictionary translations of other words in the word's Brown cluster. ( <ref type="bibr" target="#b1">Brown et al., 1992</ref>) While these tend to be less accurate than translations of the word, they can give a strong signal that a word falls into a particular category. For example, a Brown clus- ter containing translations such as "Paris," "Rome" and "Vienna" is likely to refer to a city, even if no translation exists to indicate which city. Finally, if automated labels for the sentence have been gen- erated, e.g., by a trained name tagger, those labels  are displayed at the bottom of the column.</p><p>In addition to word-specific information, Drag- onfly can present sentence-level information. In <ref type="figure" target="#fig_4">Figure 4</ref>, an automatic English translation of the sentence is shown above the words of the sentence (in this example, from Google Translate). Trans- lations might also be available when annotating a parallel document collection. Other sentence-level information that might prove useful in this slot in- cludes a topic model description, or a bilingual em- bedding of the entire sentence. <ref type="figure" target="#fig_4">Figure 4</ref> shows a short sentence that has been annotated with two name mentions. The first word of the sentence (Romanization "uttara") has translations of "due north," "northward," "north," etc. The second word has no direct translations or Brown cluster entries. However, its Roman- ization, "koriyaavannu," begins with a sequence that suggests the word 'Korea' with a morpho- logical ending. Even without the presence of the phrase "North Korea" in the MT output, an an- notator likely has enough information to draw the conclusion that the GPE "North Korea" is men- tioned here. The presence of the phrase "North Korea" in the machine translation output confirms this choice.</p><p>The sentence also contains a word whose Ro- manization is "ttramp." This is a harder call. There is no translation, and the Brown cluster translations do not help. Knowledge of world events, examina- tion of other sentences in the document, the trans- lation of the following word, and the MT output together suggest that this is a mention of "Donald Trump;" it can thus be annotated as a person.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We asked ten non-speakers to annotate names using our annotation platforms on documents in various low-resource languages released by the DARPA LORELEI program and the NIST TAC- KBP2017 EDL Pilot ( ). The gen- res of these documents include newswire, discus- sion forum and tweets. Using non-speaker annota- tions as "silver-standard" training data, we trained   <ref type="bibr" target="#b8">(Rolston and Kirchhoff, 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overall Performance</head><p>The agreement between non-speaker annotations from the ELISA annotation platform and gold stan- dard annotations from LDC native speakers on the same documents is between 72% and 85% for var- ious languages. The ELISA platform enables us to develop cross-lingual entity discovery and link- ing systems which achieved state-of-the-art per- formance at both NIST LoreHLT2017 <ref type="bibr">11</ref> and ten languages at TAC-KBP EDL2017 evaluations ( ).  Four annotators used two platforms (two each) to annotate 50 VOA news documents for each of the five languages listed in <ref type="table" target="#tab_3">Table 2</ref>. Their anno- tations were then adjudicated through the ELISA adjudication interface. The process took about one week. For each language we used 40 documents for training and 10 documents for test in the TAC- KBP2017 EDL Pilot. In <ref type="table" target="#tab_3">Table 2</ref> we see that the languages with more annotated names (i.e., Alba- nian and Swahili) achieved higher performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Albanian Kannada Nepali Polish Swahili</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Silver Standard Creation</head><p>We compare our method with Wikipedia based silver standard annotations ( ) on Oromo and Tigrinya, two low-resource languages in the LoreHLT2017 evaluation. <ref type="table" target="#tab_5">Table 3</ref> shows the data statistics. We can see that with the ELISA annotation platform we were able to acquire many more topically-relevant training sentences and thus achieved much higher performance.   <ref type="table">Table 4</ref>: Comparison of Silver Standard Creation Methods (F-score %). Native-speaker Annotation Non-speaker Annotation <ref type="figure">Figure 5</ref>: Russian Name Tagging Performance Us- ing Native-speaker and Non-speaker Annotations. <ref type="figure">Figure 5</ref> compares the performance of Rus- sian name taggers trained from Gold Standard by LDC native speakers and Silver Standard by non- speakers through our annotation platforms, test- ing on 1,952 sentences with ground truth anno- tated by LDC native speakers. Our annotation plat- forms got off to a good start and offered higher performance than annotations from native speak- ers, because non-speakers quickly capture com- mon names, which can be synthesized as effective features and patterns for our name tagger. How- ever, after all low-hanging fruit was picked, it be- came difficult for non-speakers to discover many uncommon names due to the limited coverage of lexicon and romanization; thus the performance of the name tagger converged quickly and hits an upper-bound. For example, the most frequently missed names by non-speakers include organiza- tion abbreviations and uncommon person names. <ref type="table" target="#tab_7">Table 5</ref> shows that the adjudication process sig- nificantly improved precision because annotators were able to fix annotation errors after extensive discussions on disputed cases and also gradually learned annotation rules and linguistic patterns. Most missing errors remained unfixed during the adjudication so the recall was not improved.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with Native Speaker Annotations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Impact of Adjudication</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Adjudication P (%) R (%) F (%)</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>"</head><label></label><figDesc>ናይዚ እዋን'ዚ ፕረዝደንት ዓብደልፈታሕ አል-ሲሲ ነቲ ናይ 2011 ዓ.ም.ፈ ተቃውሞ ብምንኣድ እቲ ተቃውሚ ሓዳስ ግብጺ ዘምጸአ'ዩ ኢሎም።" "naayezi 'ewaane'zi perazedanete 'aabedale- fataahhe 'ale-sisi nati naaye 2011 'aa.me.fa taqaawemo bemene'aade 'eti taqaawemi hhaadaase gebetsi zametsa'a 'yulome ."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: ELISA IE Annotation Architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: ELISA IE Annotation Interface in use annotating a Tigrinya document.</figDesc><graphic url="image-6.png" coords="4,72.00,62.81,453.55,259.67" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: ELISA IE Adjudication Interface in use annotating a Tigrinya document.</figDesc><graphic url="image-7.png" coords="4,72.00,368.16,218.27,133.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The Dragonfly tool in use annotating a Kannada document.</figDesc><graphic url="image-8.png" coords="5,72.00,63.80,468.00,145.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Data Statistics and Performance on 
KBP2017 EDL Pilot 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 : # Sentences in Oromo and Tigrinya Data.</head><label>3</label><figDesc></figDesc><table>Method 
Oromo Tigrinya 
ELISA Annotated 
68.2 
71.3 
Wikipedia Markup 
6.2 
2.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 : Impact of Annotation Adjudication</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> https://www.darpa.mil/program/low-resourcelanguages-for-emergent-incidents</note>

			<note place="foot" n="2"> Desiderata We see the following requirements as being most important to allow a non-speaker to annotate a language, independent of interface. None of these requirements is necessary, but the more that are satisfied, the easier it will be for the annotator to produce accurate annotations: 3 https://github.com/andyhu/transliteration 4 https://www.isi.edu/ ulf/croom/ChineseRoomEditor.html</note>

			<note place="foot" n="5"> https://en.wikipedia.org/wiki/IPA</note>

			<note place="foot" n="8"> https://panlex.org/ 9 http://www.geonames.org/ 10 https://www.wiktionary.org/ 11 https://www.nist.gov/itl/iad/mig/lorehlt-evaluations</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic acquisition of named entity tagged corpus from world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Class-based n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J D</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>COLING</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Annotating named entities in twitter data with crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Murnane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karandikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT 2010 Workshop</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Outof-the-box universal romanization tool uroman</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PRoc. ACL2018 Demo Track</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Overview of TACKBP2017 13 languages entity discovery and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nothman</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mayfield</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcnamee</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Costello</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning multilingual named entity recognition from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ringland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-lingual name tagging and linking for 282 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Collection of bilingual data for lexicon transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leanne</forename><surname>Rolston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UWEE Technical Report</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Crosslingual named entity recognition via wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mayhew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cross-lingual projected expectation regularization for weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">RPI BLENDER TAC-KBP2017 13 languages EDL system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Blissett</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kazemi</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Whitehead</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
			<affiliation>
				<orgName type="collaboration">TAC</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
