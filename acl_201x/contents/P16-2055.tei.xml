<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text Simplification as Tree Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
							<email>bingel@hum.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Language Technology</orgName>
								<orgName type="department" key="dep2">Centre for Language Technology</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
							<email>soegaard@hum.ku.dk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Centre for Language Technology</orgName>
								<orgName type="department" key="dep2">Centre for Language Technology</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Text Simplification as Tree Labeling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="337" to="343"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new, structured approach to text simplification using conditional random fields over top-down traversals of dependency graphs that jointly predicts possible compressions and paraphrases. Our model reaches readability scores comparable to word-based compression approaches across a range of metrics and human judgements while maintaining more of the important information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentence-level text simplification is the problem of automatically modifying sentences so that they become easier to read, while maintaining most of the relevant information in them. This can benefit applications as pre-processing for machine trans- lation <ref type="bibr" target="#b1">(Bernth, 1998)</ref> and assisting technologies for readers with reduced literacy <ref type="bibr" target="#b2">(Carroll et al., 1999;</ref><ref type="bibr">Watanabe et al., 2009;</ref><ref type="bibr" target="#b24">Rello et al., 2013)</ref>.</p><p>Sentence-level text simplification ignores sen- tence splitting and reordering, and typically fo- cuses on compression (deletion of words) and paraphrasing or lexical substitution <ref type="bibr" target="#b4">(Cohn and Lapata, 2008)</ref>. We include paraphrasing and lexi- cal substitution here, while previous work in sen- tence simplification has often focused exclusively on deletion. Approaches that address compres- sion and paraphrasing (or more tasks) integrally include ( <ref type="bibr">Zhu et al., 2010;</ref><ref type="bibr" target="#b21">Narayan and Gardent, 2014;</ref><ref type="bibr" target="#b16">Mandya et al., 2014)</ref>.</p><p>Simplification beyond deletion is motivated by <ref type="bibr" target="#b23">Pitler's (2010)</ref> observation that abstractive sen- tence summaries written by humans often "include paraphrases or synonyms <ref type="bibr">('said' versus 'stated')</ref> and use alternative syntactic constructions ('gave John the book' versus 'gave the book to John')." Such lexical or syntactic alternations may con- tribute strongly to the readability of a sentence if they replace difficult words with shorter or more familiar ones, in particular for low-literacy readers ( <ref type="bibr" target="#b24">Rello et al., 2013)</ref>. Our joint approach to deletion and paraphrasing works against the limitation that abstractive simplifications "are not capable of be- ing generated by <ref type="bibr">[..</ref>.] most sentence compression algorithms" <ref type="bibr" target="#b23">(Pitler, 2010)</ref>.</p><p>Furthermore, a central concern in text simplifi- cation is to ensure the grammaticality of the out- put, especially with low-proficiency readers as the target audience. Our approach to this problem is to remove or paraphrase entire syntactic units in the original sentence, thus avoiding to remove phrase heads without removing their arguments or mod- ifiers. Like <ref type="bibr" target="#b9">Filippova and Strube (2008)</ref>, we rely on dependency structures rather than constituent structures, which promises more robust syntactic analysis and allows us to operate on discontinuous syntactic units.</p><p>Contributions We present a sentence simplifi- cation model which is, to the best of our knowl- edge, the first model that uses structured predic- tion over dependency trees and models compres- sion and paraphrasing jointly. Our model uses Viterbi decoding rather than scoring of all can- didates and outputs probabilities reflecting model confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>We use the publicly available Google compres- sion data set, 1 which consists of 10,000 English sentence triples with (1) the original sentence as present in the body of an online news article, (2) a headline based on the original sentence, and (3) a compression that is automatically derived from the original such that it only contains word forms (1) In official documents released earlier this month it appears the Queen of England used the wrong name for the Republic of Ireland when writing to president Patrick Hillery.</p><p>(2) Queen elizabeth ii used wrong name for Republic The data is pre-processed with the Stanford CoreNLP tools ( <ref type="bibr" target="#b17">Manning et al., 2014</ref>), retrieving lemmas, parts-of-speech, named entities and de- pendency trees. We reserve the first 200 sentences from the data set for evaluation, the next 200 for tuning parameters (including the used PPDB ver- sions, see next paragraph), and use the remaining 9,600 sentences for training our model. Deletion and paraphrase targets As our ap- proach operates on dependency trees, aiming to prune or paraphrase subtrees from the dependency tree of a sentence, we identify deleted or para- phrased subtrees, marking their heads with a cor- responding label. A subtree receives a Delete label if none of the words subsumed by this subtree oc- cur in the compressed version of the sentence.</p><p>We identify paraphrased subsequences in an original sentence by looking up the subsequence string in the Paraphrase Database (PPDB) ( <ref type="bibr" target="#b12">Ganitkevitch et al., 2013</ref>) and testing if one of its pos- sible paraphrases occurs in the headline version of the sentence in question. The Paraphrase Database 1.0 is a set of phrasal and lexical pairs that were automatically acquired from bilingual parallel cor- pora, and thus contain a portion of flawed para- phrase pairs. The database comes in a number of different sizes, where small editions are re- stricted to high-precision paraphrases with rela- tively high paraphrase probabilities. As the two smallest editions of PPDB only yield a very low number of paraphrase targets (less than 100 in the entire Google compression data set), we opt to em- ploy a medium-sized version of the resource (size 'L') and find a total of 510 phrasal and lexical paraphrases in the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We assume that text simplification is a genera- tive process on syntactic dependency graphs with a paraphrase dictionary. A dependency graph G = (V, A) is a labeled directed graph in the standard graph-theoretic sense and consists of nodes, V , and arcs, A, such that for sen- tence S = w 0 w 1 . . . w n and label set R, V ⊆ {w 0 , w 1 , . . . , w n }, and A ⊆ V × R × V hold, and if (w i , r, w j ) ∈ A then (w i , r , w j ) = A for all r = r. We restrict the dependency graphs to the class of trees, i.e., for</p><formula xml:id="formula_0">(w i , r, w j ) ∈ A, if (w k , r, w j ) ∈ A then k = i.</formula><p>The generative process traverses the tree in a top-down fashion, deleting or paraphrasing sub- trees (see <ref type="figure" target="#fig_0">Figure 1</ref>). Note that elements in sub- trees dominated by a deleted node are automati- cally deleted (analogously for paraphrases).</p><p>For each dependency tree G = (V, A) in a training set of T sentences, we derive an in- put sequence of K-dimensional feature vectors x = x 1 , . . . , x n and an output sequence of y = y 1 , . . . , y n . Our tree-to-string simplification model is a second-order linear-chain conditional random field (CRF)</p><formula xml:id="formula_1">p(y|x) = 1 Z(x) n i=1 exp{ K k=1 θ k f k (y t , y t−1 , x t )}</formula><p>with y i = Delete if and only if x i represents the least upper bound in G covering a deleted span in the training data, and y i = Paraphrase if and only if x i represents the least upper bound in G covering a paraphrased span in the training data. For example, if the entire sentence is deleted, and (w 0 , r, w i ) ∈ A, then y i = Delete (but y j = Leave for j = i).</p><p>This encoding means that theoretically we can predict to paraphrase a subtree that is dominated by a node which is in turn predicted to be deleted (or vice versa). However, once an operation is car- ried out on a subtree, none of its dominated nodes are considered in the remainder of the top-down simplification process. Giving preference to op- erations at higher-level syntactic environments in this manner serves as a mechanism to resolve am- biguities in the decision process by taking a wider context into account.</p><p>Furthermore, predicting a node to get para- phrased at the right corner of a deleted subtree can potentially influence labeling decisions out- side this subtree as a consequence of the dynamic- program Viterbi decoding. We acknowledge that this is a theoretical drawback of the presented ap- proach, but given that we do not observe any such dependency graphs in our data, we do not expect this to be a serious problem in most cases.</p><p>Whenever our model predicts that a subtree be paraphrased, we look up the respective token se- quence in PPDB and replace it with the candi- date paraphrase (if available) that maximises the product of frequency and translation probability according to PPDB.</p><p>Features for CRF model We train a second- order CRF model using MarMoT <ref type="bibr" target="#b19">(Mueller et al., 2013)</ref>, an efficient higher-order CRF implementa- tion. The model computes its observational prob- abilities from features based on properties of the subtree root token (incl. POS, language model probability, NE mention, word difficulty), of the internal structure of the subtree (incl. number of children, depth, length of sequence), and of the external grammatical structure (incl. dependency relation, parent POS, distance from parent, posi- tion in sentence).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>Baselines In the following experiments, we compare our approach to state-of-the-art ap- proaches to sentence compression and joint com- pression/paraphrasing. For the first of these two categories, we consider the LSTM system de- scribed in <ref type="bibr" target="#b10">Filippova et al. (2015)</ref> as well as the results reported therein for the MIRA system <ref type="bibr" target="#b18">(McDonald, 2006</ref>). As a joint approach, we consider Reluctant Trimmer (RT), a simplification system that employs synchronous dependency grammars ( <ref type="bibr" target="#b16">Mandya et al., 2014</ref>). Since the LSTM system re- quires great amounts of training data, which were not available to us, we cannot reproduce its out-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall Precision F1</head><p>Reluctant  <ref type="table">Table 1</ref>: Performance on joint deletion and para- phrasing detection for our tree labeling system (evaluating both on entire subtrees and token level) as well as for the RT baseline (tokens only).</p><p>Note that RT is trained on the (Simple) English Wikipedia, not on the Google compressions, and therefore the results may not be directly compara- ble.</p><p>put and therefore limit our comparison of human rankings to the eleven output examples provided in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F-Scores</head><p>We first evaluate our tree labeling model (TL) on its ability to predict subtree dele- tion and paraphrasing (i.e. whether a subtree should be paraphrased, independent of the actual replacement). The results for this evaluation setup, as well as word-level performance, are listed in <ref type="table">Table 1</ref> and compared to RT. Note that for dele- tion and paraphrasing, our model consistently has higher precision than recall, thus generating more confident simplifications and less ungrammatical output. <ref type="table" target="#tab_2">Table 2</ref> reports the compression ratio (CR, percentage of retained words) as well as automated readability scores that our model achieves on the test set and compares it to the output of the RT baseline. Our system man- ages to compress the original texts by more than one third, but the gold simplifications (headlines and compressions) are still considerably shorter. Our approach improves readability as mea- sured by the Flesch Reading Ease score 2 (Flesch,   1948) and the Dale-Chall formula <ref type="bibr" target="#b6">(Dale and Chall, 1948)</ref>. The former score measures textual diffi- culty as a function of sentence length and the num- ber of syllables per word, while the latter aims to estimate a US school grade level at which a text can be well understood, based on a vocabulary list. Both metrics deem the output of our system eas- ier to read than the original texts, while the Dale- Chall formula also rates our system better than the gold simplifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Readability Scores</head><note type="other">Data version CR ↓ Flesch ↑ Dale-C.</note><p>Human Readability Ratings Following Filip- pova et al. (2015) in their evaluation setup for the sake of comparability, we ask raters to as- sign scores on a one-to-five Likert scale to the first 200 sentences from the Google compression data paired with the output of our system. Each pair is rated by three native or near-native speakers of English.</p><p>The raters are asked to evaluate the sentence ric is due to an over-representation of longer words in head- lines.</p><p>pairs for readability and informativeness. The former, following <ref type="bibr" target="#b10">Filippova et al. (2015)</ref>, "cov- ers the grammatical correctness, comprehensibil- ity and fluency of the output." The latter metric pertains to the relation between the original sen- tence and the system output as it "measures the amount of important content preserved in the com- pression." <ref type="table" target="#tab_3">Table 3</ref> compares the performance of our model to the figures reported in <ref type="bibr" target="#b10">Filippova et al. (2015)</ref> for their LSTM model and McDonald's (2006) system (MIRA). For a comparison with the same judges, we repeat the evaluation with the 11 sample out- put compressions listed in <ref type="bibr" target="#b10">Filippova et al. (2015)</ref>as well as the respective output from Reluctant Trim- mer; see the lower part of <ref type="table" target="#tab_3">Table 3</ref>. The results suggest that, compared to the compression-only LSTMs, our approach yields comparable perfor- mance in terms of readability, while maintaining more of the central information in the original sen- tences. Compared to RT, our system does con- siderably better in terms of readability and retains slightly more of the important information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Several approaches to sentence compression have been presented in the last decade. <ref type="bibr" target="#b15">Knight and Marcu (2002)</ref> and <ref type="bibr">Turner and Charniak (2005)</ref> ap- ply noisy channel models, using language models to control for grammaticality. <ref type="bibr" target="#b18">McDonald (2006)</ref> introduces a different approach, discriminatively training a scoring function, informed by syntac- tic features, to score all possible subtrees of a sentence. His work was inspired by <ref type="bibr" target="#b25">Riezler et al. (2003)</ref> scoring substrings generated from LFG parses. A third approach to sentence compression is sequence labeling, which has been explored by Most recent approaches to sentence compres- sion make use of syntactic analysis, either by operating directly on trees ( <ref type="bibr" target="#b25">Riezler et al., 2003;</ref><ref type="bibr" target="#b22">Nomoto, 2007;</ref><ref type="bibr" target="#b9">Filippova and Strube, 2008;</ref><ref type="bibr" target="#b4">Cohn and Lapata, 2008;</ref><ref type="bibr" target="#b5">Cohn and Lapata, 2009</ref>) or by incorporating syntactic information in their model <ref type="bibr" target="#b18">(McDonald, 2006;</ref><ref type="bibr" target="#b3">Clarke and Lapata, 2008)</ref>. Recently, however, <ref type="bibr" target="#b10">Filippova et al. (2015)</ref> pre- sented an approach to sentence compression using Original Sentence &amp; Simplifications O OG&amp;E is warning customers about a prepaid debit card scam that is targeting utility customers across the county. C OG&amp;E is warning customers about a scam. R OG&amp;E is warning customers about a debit card scam that is targeting utility customers across the country. T OG&amp;E is warning customers regarding a prepaid debit card scam. O The husband of murdered Melbourne woman Jill Meagher will return to Ireland later this month "to clear his head" while fighting for parole board changes. C The husband of murdered woman Jill Meagher will return to Ireland. R The husband of Melbourne woman Jill Meagher will return to Ireland this month to clear his head fighting for parole board changes. T The husband of murdered Melbourne woman Jill Meagher will return to Ireland. O A research project has found that taxi drivers often don't know what the speed limit is. C Taxi drivers don't know the speed limit is. R A research project has found that drivers often do not know what the speed limit is. T A project has found taxi drivers don't know what the speed limit is. <ref type="table">Table 4</ref>: Example output for original sentences (O) as generated by the Reluctant Trimmer baseline (R) and our tree labeling system (T), as well as the headline-generated Google compressions (C).</p><p>LSTMs with word embeddings, with no syntactic features. We return to working directly on trees, presenting a tree-to-string model of sentence sim- plification. Our model has interesting similarities to ( <ref type="bibr" target="#b25">Riezler et al., 2003</ref>), but uses Viterbi decod- ing rather than scoring of all candidates. Also, it follows <ref type="bibr" target="#b4">Cohn and Lapata (2008)</ref> in going be- yond most of these models, modeling compression and paraphrasing.</p><p>For lexical simplification, most systems typi- cally use pre-compiled dictionaries <ref type="bibr" target="#b7">(Devlin, 1999;</ref><ref type="bibr" target="#b13">Inui et al., 2003)</ref> and select the synonym candidate with the highest frequency. More recently, <ref type="bibr">BaezaYates et al. (2015)</ref> introduced an algorithm for lex- ical simplification in Spanish that selects the best synonym candidate in a context-sensitive fashion.</p><p>Cohn and Lapata (2008), Woodsend and Lap- ata (2011) and <ref type="bibr" target="#b16">Mandya et al. (2014)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a new approach to sentence sim- plification that uses linear-chain conditional ran- dom fields over dependency graphs to jointly pre- dict compression and paraphrasing of entire syn- tactic units. The objective of our model is to delete or paraphrase entire subtrees in dependency graphs as a strategy to avoid ungrammatical out- put. Our approach makes innovative use of a three-fold parallel monolingual corpus that fea- tures headlines and compressions to learn para- phrases and deletions, respectively. Human eval- uation shows that our approach leads to readabil- ity figures that are comparable to previous state- of-the-art approaches to the more basic sentence compression task, and better than previous work on joint compression and paraphrasing. While our model does rely on syntactic analysis, it only needs a tiny fraction (less than 0.5%) of the train- ing data used by <ref type="bibr" target="#b10">Filippova et al. (2015)</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example simplification tree</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 3 )</head><label>3</label><figDesc>The Queen of England used the wrong name for the Republic of Ireland.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Elming et al. (2013) using linear-chain CRFs with syntactic features, and more recently by Filippova et al. (2015) and Klerke et al. (2016) using recur- rent neural networks with LSTM cells.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>present joint approaches to compression and paraphrasing that are based on (quasi-) synchronous grammars, and similarly Zhu et al. (2010) take a syntax-based approach, but employ a probabilistic model of various simplification operations. Napoles et al. (2011) do not use syntactic information, but in- stead employ a character-based metric to compress and paraphrase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Compression ratios and automatic read-
ability scores for the Google compression data set, 
compared to the system output. Readability is in-
dicated by a high Flesh Reading Ease score and a 
low Dale-Chall score. * indicates differences com-
pared to the original sentences that are significant 
at p &lt; 10 −3 . 

System 
Readability Informativeness 
MIRA 
4.31 
3.55 
LSTM 
4.51 
3.78 
TL 
4.14 
4.01 

RT (11) 
3.09 
4.12 
LSTM (11) 
4.23 
3.42 
TL (11) 
4.21 
4.15 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Mean readability and informativeness rat-
ings for the first 200 sentences in the Google data 
(upper) and for the 11 sample sentences listed in 
Filippova et al. (2015) (lower). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computa- tional Linguistics on Human Language Technology- Volume 1, pages 118-125. Association for Compu- tational Linguistics.</head><label>In</label><figDesc></figDesc><table>Jenine Turner and Eugene Charniak. 2005. Super-
vised and unsupervised learning for sentence com-
pression. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics, 
pages 290-297. Association for Computational Lin-
guistics. 

Willian Massami Watanabe, Arnaldo Candido Junior, 
Vinícius Rodriguez Uzêda, Renata Pontin de Mat-
tos Fortes, Thiago Alexandre Salgueiro Pardo, and 
Sandra Maria Aluísio. 2009. Facilita: reading as-
sistance for low-literacy readers. In Proceedings of 
the 27th ACM international conference on Design of 
communication, pages 29-36. ACM. 

Kristian Woodsend and Mirella Lapata. 2011. Learn-
ing to simplify sentences with quasi-synchronous 
grammar and integer programming. In Proceedings 
of the conference on empirical methods in natural 
language processing, pages 409-420. Association 
for Computational Linguistics. 

Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 
2010. A monolingual tree-based translation model 
for sentence simplification. In Proceedings of the 
23rd international conference on computational lin-
guistics, pages 1353-1361. Association for Compu-
tational Linguistics. </table></figure>

			<note place="foot" n="1"> http://storage.googleapis.com/ sentencecomp/compressiondata.json</note>

			<note place="foot" n="2"> The negative value that the headlines receive for this met</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was partially funded by the ERC Starting Grant LOWLANDS No. 313695, as well as by Trygfonden.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cassa: A context-aware synonym simplification algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luz</forename><surname>Rello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Dembowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1380" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">EasyEnglish: Preprocessing for MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arendse</forename><surname>Bernth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Controlled Language Applications</title>
		<meeting>the Second International Workshop on Controlled Language Applications</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="30" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simplifying text for language-impaired readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darren</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><surname>Canning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siobhan</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="269" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global inference for sentence compression: An integer linear programming approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="399" to="429" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sentence compression beyond word deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sentence compression as tree transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="637" to="674" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A formula for predicting readability: Instructions. Educational research bulletin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Dale</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948" />
			<biblScope unit="page" from="37" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Simplifying natural language for aphasic readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siobhan</forename><forename type="middle">Lucy</forename><surname>Devlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Sunderland</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Down-stream effects of tree-to-dependency conversions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Elming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sigrid</forename><surname>Klerke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Lapponi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><forename type="middle">Martinez</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="617" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dependency tree based sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Natural Language Generation Conference</title>
		<meeting>the Fifth International Natural Language Generation Conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sentence compression by deletion with lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Colmenares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new readability yardstick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph</forename><surname>Flesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of applied psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">221</biblScope>
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">PPDB: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Text simplification for reading assistance: a project note</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryu</forename><surname>Iida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Iwakura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international workshop on Paraphrasing</title>
		<meeting>the second international workshop on Paraphrasing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving sentence compression by learning to predict gaze</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sigrid</forename><surname>Klerke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2016</title>
		<meeting>ACL 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>short</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Summarization beyond sentence extraction: A probabilistic approach to sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="107" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lexico-syntactic text simplification and compression with typed dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angrosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadashi</forename><surname>Mandya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Nomoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1996" to="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative sentence compression with soft syntactic evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ryan T Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient higher-order CRFs for morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
	<note>Seattle, Washington, USA, October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Paraphrastic sentence compression with a character-based metric: Tightening without deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Monolingual Text-To-Text Generation</title>
		<meeting>the Workshop on Monolingual Text-To-Text Generation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="84" to="90" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hybrid simplification using deep semantics and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="435" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discriminative sentence compression with conditional random fields. Information Processing and Management: an</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tadashi</forename><surname>Nomoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1571" to="1587" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Methods for sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer and Information Science, University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Frequent words improve readability and short words improve understandability for people with dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luz</forename><surname>Rello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Demperemarco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HumanComputer Interaction-INTERACT 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="203" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Statistical sentence condensation using ambiguity packing and stochastic disambiguation methods for lexical-functional grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tracy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaenen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
