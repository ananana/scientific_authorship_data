<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified Kernel Approach for Learning Typed Sentence Rewritings</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 26-31, 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Gleize</surname></persName>
							<email>gleize@limsi.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brigitte</forename><surname>Grau</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">LIMSI-CNRS</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Université Paris-Sud</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">LIMSI-CNRS</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">ENSIIE</orgName>
								<address>
									<settlement>Evry</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified Kernel Approach for Learning Typed Sentence Rewritings</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
						<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="939" to="949"/>
							<date type="published">July 26-31, 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Many high level natural language processing problems can be framed as determining if two given sentences are a rewriting of each other. In this paper, we propose a class of kernel functions, referred to as type-enriched string rewriting kernels , which, used in kernel-based machine learning algorithms, allow to learn sentence rewritings. Unlike previous work, this method can be fed external lexical semantic relations to capture a wider class of rewriting rules. It also does not assume preliminary syntactic parsing but is still able to provide a unified framework to capture syntactic structure and alignments between the two sentences. We experiment on three different natural sentence rewriting tasks and obtain state-of-the-art results for all of them.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Detecting implications of sense between state- ments stands as one of the most sought-after goals in computational linguistics. Several high level tasks look for either one-way rewriting between single sentences, like recognizing textual entail- ment (RTE) ( <ref type="bibr" target="#b5">Dagan et al., 2006</ref>), or two-way rewritings like paraphrase identification ( <ref type="bibr" target="#b7">Dolan et al., 2004</ref>) and semantic textual similarity ( <ref type="bibr" target="#b0">Agirre et al., 2012</ref>). In a similar fashion, selecting sen- tences containing the answer to a question can be seen as finding the best rewritings of the ques- tion among answer candidates. These problems are naturally framed as classification tasks, and as such most current solutions make use of super- vised machine learning. They have to tackle sev- eral challenges: picking an adequate language rep- resentation, aligning semantically equivalent el- ements and extracting relevant features to learn the final decision. Bag-of-words and by extension bag-of-ngrams are traditionally the most direct ap- proach and features rely mostly on lexical match- ing ( <ref type="bibr" target="#b23">Wan et al., 2006</ref>; <ref type="bibr" target="#b11">Lintean and Rus, 2011;</ref><ref type="bibr" target="#b10">Jimenez et al., 2013</ref>). Moreover, a good solving method has to account for typically scarce labeled training data, by enriching its model with lexical semantic resources like WordNet <ref type="bibr" target="#b16">(Miller, 1995)</ref> to bridge gaps between surface forms ( <ref type="bibr" target="#b15">Mihalcea et al., 2006;</ref><ref type="bibr" target="#b9">Islam and Inkpen, 2009;</ref><ref type="bibr" target="#b27">Yih et al., 2013)</ref>. Models based on syntactic trees remain the typical choice to account for the structure of the sentences <ref type="bibr" target="#b8">(Heilman and Smith, 2010;</ref><ref type="bibr" target="#b24">Wang and Manning, 2010;</ref><ref type="bibr" target="#b20">Socher et al., 2011;</ref><ref type="bibr" target="#b2">Calvo et al., 2014</ref>). Usually the best systems manage to com- bine effectively different methods, like Madnani et al.'s meta-classifier with machine translation met- rics ( <ref type="bibr" target="#b14">Madnani et al., 2012)</ref>. A few methods ( <ref type="bibr" target="#b28">Zanzotto et al., 2007;</ref><ref type="bibr" target="#b29">Zanzotto et al., 2010;</ref><ref type="bibr" target="#b1">Bu et al., 2012</ref>) use kernel func- tions to learn what makes two sentence pairs sim- ilar. Building on this work, we present a type- enriched string rewriting kernel giving the oppor- tunity to specify in a fine-grained way how words match each other. Unlike previous work, rewrit- ing rules learned using our framework account for syntactic structure, term alignments and lexico- semantic typed variations in a unified approach. We detail how to efficiently compute our kernel and lastly experiment on three different high-level NLP tasks, demonstrating the vast applicability of our method. Our system based on type-enriched string rewriting kernels obtains state-of-the-art re- sults on paraphrase identification and answer sen- tence selection and outperforms comparable meth- ods on RTE.</p><p>like SVM, they allow complex decision functions to be learned in classification tasks <ref type="bibr" target="#b22">(Vapnik, 2000)</ref>. The goal of a well-designed kernel function is to have a high value when computed on two instances of same label, and a low value for two instances of different label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">String rewriting kernel</head><p>String rewriting kernels ( <ref type="bibr" target="#b1">Bu et al., 2012</ref>) count the number of common rewritings between two pairs of sentences seen as sequences of words. The rewriting rule (A) in <ref type="figure" target="#fig_4">Figure 1</ref> can be viewed as a kind of phrasal paraphrase with linked vari- ables ( <ref type="bibr" target="#b13">Madnani and Dorr, 2010)</ref>. Rule (A) rewrites (B)'s first sentence into its second but it does not however rewrite the sentences in (C), which is what we try to fix in this paper. Following the terminology of string kernels, we use the term string and character instead of sen- tence and word. We denote (s, t) ∈ (Σ * × Σ * ) an instance of string rewriting, with a source string s and a target string t, both finite sequences of elements in Σ the finite set of characters. Sup- pose that we are given training data of such in- stances labeled in {+1, −1}, for paraphrase/non- paraphrase or entailment/non-entailment in appli- cations. We can use a kernel method to train on this data and learn to automatically classify unla- beled instances. A kernel on string rewriting in- stances is a map:</p><formula xml:id="formula_0">K : (Σ * × Σ * ) × (Σ * × Σ * ) → R such that for all (s 1 , t 1 ), (s 2 , t 2 ) ∈ Σ * × Σ * , K((s 1 , t 1 ), (s 2 , t 2 )) = Φ(s 1 , t 1 ), Φ(s 2 , t 2 ) (1)</formula><p>where Φ maps each instance into a high dimen- sion feature space. Kernels allow us to avoid the potentially expensive explicit representation of Φ through the inner product space they define. The purpose of the string rewriting kernels is to mea- sure the similarity between two pairs of strings in term of the number of rewriting rules of a set R that they share. Φ is thus naturally defined by Φ(s, t) = (φ r (s, t)) r∈R with φ r (s, t) = n the number of contiguous substring pairs of (s, t) that rewriting rule r matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Typed rewriting rules</head><p>Let the wildcard domain D ⊆ Σ * be the set of strings which can be replaced by wildcards. We now present the formal framework of the type- enriched string rewriting kernels. Let Γ p be the set of pattern types and Γ v the set of variable types. To a type γ p ∈ Γ p , we associate the typing relation</p><formula xml:id="formula_1">γp ≈ ⊆ Σ × Σ.</formula><p>To a type γ v ∈ Γ v ,we associate the typing relation</p><formula xml:id="formula_2">γv ; ⊆ D × D.</formula><p>Together with the typing relations, we call the as- sociation of Γ p and Γ v the typing scheme of the kernel. Let Σ p be defined as</p><formula xml:id="formula_3">Σ p = γ∈Γ {[a|b] | ∃a, b ∈ Σ, a γ ≈ b}<label>(2)</label></formula><p>We finally define typed rewriting rules. A typed rewriting rule is a triple r = (β s , β t , τ ), where β s , β t ∈ (Σ p ∪ { * }) * denote source and target string typed patterns and τ ⊆ ind * (β s )×ind * (β t ) denotes the alignments between the wildcards in the two string patterns. Here ind * (β) denotes the set of indices of wildcards in β.</p><p>We say that a rewriting rule (β s , β t , τ ) matches a pair of strings (s, t) if and only if the following conditions are true:</p><p>• string patterns β s , resp. β t , can be turned into s, resp. t, by:</p><p>-substituting each element <ref type="bibr">[a|b]</ref> of Σ p in the string pattern with an a or b (∈ Σ) -substituting each wildcard in the string pattern with an element of the wildcard domain D</p><p>• ∀(i, j) ∈ τ , s, resp. t, substitutes the wild- cards at index i, resp. j, by s * ∈ D, resp. t * , such that there exists a variable type γ ∈ Γ v with s * γ ; t * .</p><p>A type-enriched string rewriting kernel (TESRK) is simply a string rewriting kernel as defined in Equation 1 but with R a set of typed rewriting rules. This class of kernels depends on wildcard domain D and the typed rewriting rules R which can be tuned to allow for more flexibility in the matching of pairs of characters in a rewriting rule. Within this framework, the k-gram bijective string rewriting kernel (kb-SRK) is defined by the wild- card domain D = Σ and the ruleset     We now present an example of how kb-SRK is applied to real pairs of sentences, what its limita- tions are and how we can deal with them by re- working its typing scheme. Let us consider again <ref type="figure" target="#fig_4">Figure 1</ref>, (A) is a rewriting rule with β s = (heard, * , * ), β t = ( * , was, * ), τ = {(2, 1); (3, 3)}. Each string pattern has the same length, and pairs of wildcards in the two patterns are aligned bijec- tively. This is a valid rule for kb-SRK. It matches the pair of strings (B): each aligned pair of wild- cards is substituted in source and target sentences by the same word and string patterns of (A) can in- deed be turned into pairs of substrings of the sen- tences. However, it cannot match the pair of sen- tences (C) in the original kb-SRK. We change Γ p to {hypernym, id} where a b if and only if verb a has a relation of entailment with b in WordNet. By redefining the typing scheme, rule (A) can now match (C).</p><formula xml:id="formula_4">R = {(β s , β t , τ ) | β s , β t ∈ (Σ p ∪{ * }) k , τ bijective} under Γ p = Γ v = {id}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Computing TESRK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Formulation</head><p>The k-gram bijective string rewriting kernel can be computed efficiently ( <ref type="bibr" target="#b1">Bu et al., 2012</ref>). We show that we can compute its type-enriched equivalent at the price of a seemingly insurmountable loosen- ing of theoretical complexity boundaries. Experi- ments however show that its computing time is of the same order as the original kernel. A type-enriched kb-SRK is parameterized by k the length of k-grams, and its typing scheme the sets Γ p and Γ v and their associated relations. The an- notations of Γ p and Γ v to K k and ¯ K k will be omit- ted for clarity and because they typically will not change while we test different values for k. We rewrite the inner product in Equation 1 to bet- ter fit the k-gram framework:</p><formula xml:id="formula_5">K k ((s 1 , t 1 ), (s 2 , t 2 )) = αs 1 ∈k-grams(s 1 ) α t 1 ∈k-grams(t 1 ) αs 2 ∈k-grams(s 2 ) α t 2 ∈k-grams(t 2 ) ¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 ))<label>(3)</label></formula><p>where ¯ K k is the number of different rewriting rules which match two pairs of k-grams (the same rule cannot trigger twice in k-gram substrings):</p><formula xml:id="formula_6">¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 )) = r∈R 1 r (α s 1 , α t 1 )1 r (α s 2 , α t 2 ) (4)</formula><p>with 1 r the indicator function of rule r: 1 if r matches the pair of k-grams, 0 otherwise. Computing K k as defined in Equation 3 is obvi- ously intractable. There is O((n − k + 1) 4 ) terms in the sum, where n is the length of the longest string, and each term involves enumerating every rewriting rule in R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Computing ¯ K k in type-enriched kb-SRK</head><p>Enumerating all rewriting rules in Equation 4 is itself intractable: there are more than |Σ| 2k rules without wildcards, where |Σ| is conceivably the size of a typical lexicon. In fact, we just have to constructively generate the rules which substi- tute their string patterns correctly to simultane- ously produce both pairs of k-grams (α s 1 , α t 1 ) and</p><formula xml:id="formula_7">(α s 2 , α t 2 ).</formula><p>Let the operator ⊗ be such that</p><formula xml:id="formula_8">α 1 ⊗ α 2 = ((α 1 [1], α 2 [1]), ..., (α 1 [k], α 2 [k]))</formula><p>. This operation is generally known as zipping in functional pro- gramming. We use the function CountPerfect- Matchings computed by Algorithm 1 to recur- sively count the number of rewriting rules match- ing both (α s 1 , α t 1 ) and (α s 2 , α t 2 ). The workings of the algorithm will make clearer why we can compute ¯ K k with the following formula:</p><formula xml:id="formula_9">¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 )) = CountPerfectMatchings(α s 1 ⊗ α s 2 , α t 1 ⊗ α t 2 )<label>(5)</label></formula><p>Algorithm 1 takes as input remaining character pairs in α s 1 ⊗ α s 2 and α t 1 ⊗ α t 2 , and outputs the number of ways they can substitute aligned wild- cards in a matching rule. First (lines 2 and 3) we have the base case where both remaining sets are empty. There is exactly 1 way the empty set's wildcards can be aligned with each other: nothing is aligned. In lines 4 to 9, there is no source pairs anymore, so the algorithm con- tinues to deplete target pairs as long as they have a common pattern type, i.e. as long as they do not have to substitute a wildcard. If a candidate wildcard is found, as the opposing set is empty, we cannot align it and we return 0. In the general case (lines 11 to 19), consider the first character pair (a 1 , a 2 ) in the reminder of α s 1 ⊗ α s 2 in line 12. What follows in the computation depends on its types. Every character pair in α t 1 ⊗ α t 2 that can be paired through variable types with (a 1 , a 2 ) (lines 15 to 19) is a new potential wildcard align- ment, so we try all the possible alignment and re- cursively continue the computation after removing both aligned pairs. And if (a 1 , a 2 ) does not need to substitute a wildcard because it has common pat- tern types (lines 13 and 14), we can choose to not create any wildcard pairing with it and ignore it in the recursive call. This algorithm enumerates all configurations such that each character pair has a common pattern type or is matched 1-for-1 with a character pair with common variable types, which is exactly the defi- nition of a rewriting rule in TESRK.</p><p>This problem is actually equivalent to count- ing the perfect matchings of the bipartite graph of potential wildcards. It has been shown in- tractable <ref type="bibr" target="#b21">(Valiant, 1979)</ref> and Algorithm 1 is a naive recursive algorithm to solve it. In our im- plementation we represent the graph with its bi- adjacency matrix, and if our typing relations are independent of k, the function has a O(k) time complexity without including its recursive calls. The number of recursive calls can be greater than k! 2 which is the number of perfect matchings in a complete bipartite graph of 2k vertices. In our ex- periments on linguistic data however, we observed a linear number of recursive calls for low values of k, and up to a quadratic number for k &gt; 10 -which is way past the point where the kernel be- comes ineffective.</p><p>As an example, <ref type="figure" target="#fig_6">Figure 2</ref> shows the zipped k- grams for source and target as a bipartite graph Algorithm 1: Counting perfect matchings 1 CountPerfectMatchings(remS, remT) Data: remS: remaining char. pairs in source remT: remaining char. pairs in target graph: α s 1 ⊗ α s 2 and α t 1 ⊗ α t 2 as a bipartite graph, not added in the arguments to avoid cluttering the recursive calls ruleSet: Γ p and Γ v Result: Number of rewriting rules matching (α s 1 , α t 1 ) and (α s 2 , α t 2 )</p><p>2 if remS == ∅ and remT == ∅ then 3 return 1; with 2k vertices and potential wildcard edges. As- suming that vertices (a, a) and (b, b ) have com- mon pattern types, they can be ignored as in lines 7 and 14. (c 1 , c 2 ) to (f 1 , f 2 ) however must substi- tute wildcards in a matching rewriting rule. If we align (c 1 , c 2 ) with (e 1 , e 2 ) in line 16, the recur- sive call will return 0 because the other two pairs cannot be aligned. A valid rule is generated if c's are paired with f 's and d's with e's. This kind of choices is the main source of computational cost. This problem did not arise in the original kb-SRK because of the transitivity of its only type (iden- tity). In type-enriched kb-SRK, wildcard pairing is less constrained.</p><formula xml:id="formula_10">4 else if remS == ∅ then 5 (b 1 , b 2 ) = remT.first(); 6 if ∃γ ∈ Γ p | b 1 γ ≈ b 2 then 7 return CountPerfectMatchings(∅, remT -{(b 1 , b 2 )}); 8 else 9 return 0; 10 else 11 result = 0; 12 (a 1 , a 2 ) = remS.first(); 13 if ∃γ ∈ Γ p | a 1 γ ≈ a 2 then 14 res += CountPerfectMatchings(remS - {(a 1 , a 2 )}, remT); 15 for (b 1 , b 2 ) ∈ remT 16 | ∃γ ∈ Γ v | a 1 γ ; b 1 and a 2 γ ; b 2 do 17 res += CountPerfectMatchings( 18 remS -{(a 1 , a 2 )}, 19 remT -{(b 1 , b 2 )} 20 ); (s[1], s[1]) (s[k], s[k]) (t[1], t[1]) (t[k], t[k]) (a, a) (b, b') (e1, e2) (f1, f2) (d1, d2) (c1, c2) ... ... ... ... ... ... ... ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Computing K k</head><p>Even with an efficient method for computing ¯ K k , implementing K k directly by applying Equation 3 remains impractical. The main idea is to effi- ciently compute a reasonably sized set C of el- ements ((α s 1 , α t 1 ), (α s 2 , α t 2 )) which has the es- sential property of including all elements such that</p><formula xml:id="formula_11">¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 )) = 0.</formula><p>By definition of C, we can compute efficiently</p><formula xml:id="formula_12">K k ((s 1 , t 1 ), (s 2 , t 2 )) = ((αs 1 ,αs 2 ),(αt 1 ,αt 2 ))∈C ¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 ))<label>(6)</label></formula><p>There are a number of ways to do it, with a trade-off between computation time and num- ber of elements in the reduced domain C.</p><p>The main idea of our own algorithm is that ; b 2 for some γ ∈ Γ v . This is conversely true for character pairs in α t 1 ⊗ α t 2 with no common pattern type. More simply, character pairs with no common pattern type are mismatched and have to substitute a wild- card in a rewriting rule matching both (α s 1 , α t 1 ) and (α s 2 , α t 2 ). But introducing a wildcard on one side of the rule means that there is a matching wildcard on the other side, so we can eliminate k-gram quadruples that do not fill this wildcard inclusion. This filtering can be done efficiently and yields a manageable number of quadruples on which to compute ¯ K k . Algorithm 2 computes a set C to be used in Equation 6 for computing the final value of kernel K k . In our experiments, it efficiently produces a reasonable number of inputs. All maps in the algo- rithm are maps to multisets, and multisets are used extensively throughout. Multisets are an extension of sets where elements can appear multiple times, the number of times being called the multiplicity. Typically implemented as hash tables from set elements to integers, they allow for constant-time retrieval of the number of a given element. Union (∪) and intersection (∩) have special definitions on multisets. If 1 A (x) is the multiplicity of x in</p><formula xml:id="formula_13">¯ K k ((α s 1 , α t 1 ), (α s 2 , α t 2 )) = 0 if the character pairs (a 1 , a 2 ) ∈ α s 1 ⊗ α</formula><note type="other">A, we have 1 A∪B (x) = max(1 A (x), 1 B (x)) and 1 A∩B</note><formula xml:id="formula_14">(x) = min(1 A (x), 1 B (x)).</formula><p>Algorithm 2: Computing a set including all elements on which ¯ K k = 0 Data: s 1 , t 1 , s 2 , t 2 strings, and k an integer Result: Set C which include all inputs such that ¯ K k = 0 1 Initialize maps e i s→t and maps e i t→s , for i ∈ {1, 2}; </p><formula xml:id="formula_15">2 for i ∈ {1, 2} do 3 for a ∈ s i , b ∈ t i | a γ ; b, γ ∈ Γ v do 4 e i s→t [a] += (b, γ); e i t→s [b] += (a</formula><formula xml:id="formula_16">(b 1 , b 2 ) | ∃γ ∈ Γ v , (a 1 , a 2 ) ∈ α s 1 ⊗ α s 2 , (b i , γ) ∈ e i [a i ] ∀i ∈ {1, 2} do 17 d[(b 1 , b 2 )] += (α s 1 , α s 2 );</formula><p>18 for (α t 1 , α t 2 ) ∈ kgrams(t 1 ) × kgrams(t 2 ) do Let us now comment on how the algorithm un- folds. In lines 1 to 4, we index characters in source strings by characters in target strings which have common variable types, and vice versa. It allows in lines 15 to 19 to quickly map a character pair to the set of opposing k-gram pairs with a matching -in the sense of variable types-character pair, i.e. potential aligned wildcards. In lines 20 to 28 we keep only the k-gram quadruples whose wildcard candidates (character pairs with no common pat- tern) from one side all find matches on the other side. We do not check for the other inclusion, hence the name of the function OneWayInclusion. At line 26, we did not find any character pair with no common pattern, so we save the k-gram pair as "all-pattern". All-pattern k-grams will be paired in lines 8 to 10 in the result. Finally, in line 11, we add the union of one-way compatible k-gram quadruples; calling swap on all the pairs of one set is necessary to consistently have sources on the left side and targets on the right side in the result.</p><formula xml:id="formula_17">19 for (b 1 , b 2 ) ∈ α t 1 ⊗ α t 2 | b 1 γ = b 2 ∀γ ∈ Γ p do 20 if compatWkgrms not initialized then 21 Initialize multiset compatWkgrms = d[(b 1 , b 2 )]; 22 compatWkgrms = compatWkgrms ∩ d[(b 1 , b 2 )]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Systems</head><p>We experimented on three tasks: paraphrase iden- tification, recognizing textual entailment and an- swer sentence selection. The setup we used for all experiments was the same save for the few param- eters we explored such as: k, and typing scheme. We implemented 2 kernels, kb-SRK, henceforth simply denoted SRK, and the type-enriched kb- SRK, denoted TESRK. All sentences were tok- enized and POS-tagged using OpenNLP <ref type="bibr" target="#b17">(Morton et al., 2005</ref>). Then they were stemmed us- ing the Porter stemmer <ref type="bibr" target="#b19">(Porter, 2001</ref>) in the case of SRK. Various other pre-processing steps were applied in the case of TESRK: they are consid- ered as types in the model and are detailed in Ta- ble 1. We used LIBSVM ( <ref type="bibr" target="#b3">Chang and Lin, 2011)</ref> to train a binary SVM classifier on the training data with our two kernels. The default SVM al- gorithm in LIBSVM uses a parameter C, roughly akin to a regularization parameter. We 10-fold cross-validated this parameter on the training data, optimizing with a grid search for f-score, or MRR for question-answering. All kernels were normal- ized using˜Kusing˜ using˜K(x, y) =</p><formula xml:id="formula_18">K(x,y) √ K(x,x) √ K(y,y)</formula><p>. We de- note by "+" a sum of kernels, with normalizations applied both before and after summing. Follow- ing Bu et al. ( <ref type="bibr" target="#b1">Bu et al., 2012</ref>) experimental setup, we introduced an auxiliary vector kernel denoted PR of features named unigram precision and re- call, defined in ( <ref type="bibr" target="#b23">Wan et al., 2006</ref>). In our experi- ments a linear kernel seemed to yield the best re- sults. Our Scala implementation of kb-SRKs has an average throughput of about 1500 original kb- SRK computations per second, versus 500 type- enriched kb-SRK computations per second on a 8- core machine. It typically takes a few hours on a 32-core machine to train, cross-validate and test on a full dataset. Finally, <ref type="table" target="#tab_3">Table 1</ref> presents an overview of our types with how they are defined and implemented. Ev- ery type can be used both as a pattern type or as a variable type, but the two roles are differ- ent. Pattern types are useful to unify different sur- face forms of rewriting rules that are semantically equivalent, i.e. having semantically similar pat- terns. Variable types are useful for when the se- mantic relation between 2 entities across the same rewriting is more important than the entities them- selves. That is why some types in <ref type="table" target="#tab_3">Table 1</ref> are in- herently more fitted to be used for one role rather than the other. For example, it is unlikely that replacing a word in a pattern of a rewriting rule by one of its holonyms will yield a semantically similar rewriting rule, so holonym would not be a good pattern type for most applications. On the contrary, it can be very useful in a rewriting rule to type a wildcard link with the relation holonym, as this provides constrained semantic roles to the linked wildcards in the rule, thus holonym would be a good variable type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Paraphrase identification</head><p>Paraphrase identification asks whether two sen- tences have the same meaning. The dataset we used to evaluate our systems is the MSR Para- phrase Corpus <ref type="bibr" target="#b6">(Dolan and Brockett, 2005</ref>), con- taining 4,076 training pairs of sentences and 1,725 testing pairs. For example, the sentences "An in- jured woman co-worker also was hospitalized and was listed in good condition." and "A woman was listed in good condition at Memorial's HealthPark campus, he said." are paraphrases in this corpus. On the other hand, "'There are a number of lo- cations in our community, which are essentially vulnerable,' Mr Ruddock said." and "'There are a range of risks which are being seriously exam- ined by competent authorities,' Mr Ruddock said." are not paraphrases. We report in <ref type="table" target="#tab_4">Table 2</ref> our best results, the sys- tem TESRK + PR, defined by the sum of PR and typed-enriched kb-SRKs with k from 1 to 4, with types Γ p = Γ v = {stem, synonym}. We observe  that our results are state-of-the-art and in particu- lar, they improve on the orignal kb-SRK by a good margin. We tried other combinations of types but it did not yield good results, this is probably due to the nature of the MSR corpus, which did not con- tain much more advanced variations from Word- Net. The only statistically significant improve- ment we obtained was between TESRK + PR and our PR baseline (p &lt; 0.05). The performances obtained by all the cited systems and ours are not significantly different in any statistical sense. We made a special effort to try to reproduce as best as we could the original kb-SRK performances ( <ref type="bibr" target="#b1">Bu et al., 2012</ref>), although our implementation and theirs should theoretically be equivalent. <ref type="figure">Figure 3</ref> plots the average number of recursive calls to CountPerfectMatchings (algorithm 1) dur- ing a kernel computation, as a function of k. Com- posing with log k , we can observe whether the em- piric number of recursive calls is closer to O(k) or O(k 2 ). We conclude that this element of complex- ity is linear for low values of k, but tends to ex- plode past k = 7. Thankfully, counting common rewriting rules on pairs of 7-to-10-grams rarely yields non-zero results, so in practice using high  <ref type="figure">Figure 4</ref> plots the average size of set C computed by algorithm 2, as a function of k (divided by the sum of lengths of the 4 sentences involved in the kernel computation). We can observe that this</p><note type="other">Type Typing relation on words (a, b) Tool/resources id words have same surface form and tag OpenNLP tagger idMinusTag words have same surface form OpenNLP tokenizer lemma words have same lemma WordNetStemmer stem words have same stem Porter stemmer synonym, antonym words are [type] WordNet hypernym, hyponym b is a [type] of a WordNet entailment, holonym ne a and b are both tagged with the same Named Entity BBN Identifinder lvhsn words are at edit distance of 1 Levenshtein distance</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RTE system</head><p>Accuracy All entailments <ref type="bibr">51.2 Heilman and Smith (2010)</ref> 62.8 <ref type="bibr" target="#b1">Bu et al. (2012)</ref> 65.1 <ref type="bibr" target="#b28">Zanzotto et al. (2007)</ref> 65.8 <ref type="bibr">Hickl et al. (2006)</ref> 80.0 PR 61.8 TESRK (All) 62.1 SRK + PR 63.8 TESRK (Syn) + PR 64.1 TESRK (All) + PR 66.1 <ref type="table">Table 3</ref>: Evaluation results on RTE-3 quantity is small, except for a peak at low values of k, which is not an issue because the computation of ¯ K k is very fast for those values of k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Recognizing textual entailment</head><p>Recognizing Textual Entailment asks whether the meaning of a sentence hypothesis can be inferred by reading a sentence text. The dataset we used to evaluate our systems is RTE-3. Following sim- ilar work <ref type="bibr" target="#b8">(Heilman and Smith, 2010;</ref><ref type="bibr" target="#b1">Bu et al., 2012)</ref>, we took as training data (text, hypothe- sis) pairs from RTE-1 and RTE-2's whole datasets and from RTE-3's training data, which amounts to 3,767 sentence pairs. We tested on RTE-3 test- ing data containing 800 sentence pairs. For ex- ample, a valid textual entailment in this dataset is the pair of sentences "In a move widely viewed as surprising, the Bank of England raised UK in- terest rates from 5% to 5.25%, the highest in five years." and "UK interest rates went up from 5% to 5.25%.": the first entails the second. On the other hand, the pair "Former French president General Charles de Gaulle died in November. More than 6,000 people attended a requiem mass for him at Notre Dame cathedral in Paris." and "Charles de Gaulle died in 1970." does not constitute a textual entailment.</p><p>We report in <ref type="table">Table 3</ref> our best results, the sys- tem TESRK (All) + PR, defined by the sum of PR, 1b-SRK and typed-enriched kb-SRKs with k from 2 to 4, with types Γ p = {stem, synonym} and Γ v = {stem, synonym, hypernym, hyponym, entailment, holonym}. Our results are to be com- pared with systems using techniques and resources of similar nature, but as reference the top perfor- mance at RTE-3 is still reported. This time we did not manage to fully reproduce <ref type="bibr" target="#b1">Bu et al. 2012</ref>'s performance, but we observe that type-enriched kb-SRK greatly improves upon our original imple- mentation of kb-SRK and outperforms their sys- tem anyway. Combining TESRK and the PR base- line yields significantly better results than either one alone (p &lt; 0.05), and performs significantly better than the system of <ref type="bibr" target="#b8">(Heilman and Smith, 2010)</ref>, the only one which was evaluated on the same three tasks as us (p &lt; 0.10). We tried with less types in our system TESRK (Syn) + PR by removing all WordNet types but synonyms but got lower performance. This seems to indicate that rich types indeed help capturing more com- plex sentence rewritings. Note that we needed for k = 1 to replace the type-enriched kb-SRK by the original kernel in the sum, otherwise the perfor- mance dropped significantly. Our conclusion is that including richer types is only beneficial if they are captured within a context of a couple of words and that including all those variations on unigrams only add noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Answer sentence selection</head><p>Answer sentence selection is the problem of se- lecting among single candidate sentences the ones containing the correct answer to an open-domain factoid question. The dataset we used to evalu- ate our system on this task was created by ( <ref type="bibr" target="#b25">Wang et al., 2007</ref>) based on the QA track of past Text REtrieval Conferences (TREC-QA) <ref type="bibr">1</ref> . The train- ing set contains 4718 question/answer pairs, for 94 questions, originating from TREC 8 to 12. The testing set contains 1517 pairs for 89 ques- tions. As an example, a correct answer to the question "What do practitioners of Wicca wor- ship?" is "An estimated 50,000 Americans prac- tice Wicca, a form of polytheistic nature worship." On the other hand, the answer candidate "When people think of Wicca, they think of either Sa- tanism or silly mumbo jumbo." is incorrect. Sen- tences with more than 40 words and questions with only positive or only negative answers were fil- tered out ( <ref type="bibr" target="#b26">Yao et al., 2013</ref>). The average frac- tion of correct answers per question is 7.4% for training and 18.7% for testing. Performances are evaluated as for a re-ranking problem, in term of Mean Average Precision (MAP) and Mean Re- ciprocal Rank (MRR). We report our results in <ref type="table">Table 4</ref>. We evaluated several combinations of features. IDF word-count (IDF) is a baseline of System MAP MRR Random baseline 0.397 0.493 <ref type="bibr" target="#b25">Wang et al. (2007)</ref> 0.603 0.685 Heilman and Smith (2010) 0.609 0.692 <ref type="bibr" target="#b24">Wang and Manning (2010)</ref> 0.595 0.695 <ref type="bibr" target="#b26">Yao et al. (2013)</ref> 0.631 0.748 <ref type="bibr" target="#b27">Yih et al. (2013</ref>  <ref type="table">Table 4</ref>: Evaluation results on QA IDF-weighted common word counting, integrated in a linear kernel. Then we implemented SRK and TESRK (with k from 1 to 5) with two typing schemes: WN stands for Γ p = {stem, synonym} and Γ v = {stem, synonym, hypernym, hyponym, entailment, holonym}, and WN+NE adds type ne to both sets of types. We finally summed our ker- nels with the IDF baseline kernel. We observe that types which make use of WordNet variations seem to increase the most our performance. Our as- sumption was that named entities would be useful for question answering and that we could learn as- sociations between question type and answer type through variations: NE does seem to help a little when combined with WN alone, but is less use- ful once TESRK is combined with our baseline of IDF-weighted common words. Overall, typing ca- pabilities allow TESRK to obtain way better per- formances than SRK in both MAP and MRR, and our best system combining all our features is com- parable to state-of-the-art systems in MRR, and significantly outperforms SRK + IDF, the system without types (p &lt; 0.05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Lodhi et al. ( <ref type="bibr" target="#b12">Lodhi et al., 2002</ref>) were among the first in NLP to use kernels: they apply string ker- nels which count common subsequences to text classification. Sentence pair classification how- ever require the capture of 2 types of links: the link between sentences within a pair, and the link between pairs. Zanzotto et al. ( <ref type="bibr" target="#b28">Zanzotto et al., 2007</ref>) used a kernel method on syntactic tree pairs. They expanded on graph kernels in ( <ref type="bibr" target="#b29">Zanzotto et al., 2010)</ref>. Their method first aligns tree nodes of a pair of sentences to form a single tree with placeholders. They then use tree kernel <ref type="bibr" target="#b18">(Moschitti, 2006</ref>) to compute the number of common subtrees of those trees. <ref type="bibr" target="#b1">Bu et al. (Bu et al., 2012</ref>) introduced a string rewriting kernel which can capture at once lexical equivalents and com- mon syntactic dependencies on pair of sentences. All these kernel methods require an exact match or assume prior partial matches between words, thus limiting the kind of learned rewriting rules. Our contribution addresses this issue with a type- enriched string rewriting kernel which can account for lexico-semantic variations of words. Limita- tions of our rewriting rules include the impossibil- ity to skip a pattern word and to replace wildcards by multiple words. Some recent contributions ( <ref type="bibr" target="#b4">Chang et al., 2010;</ref><ref type="bibr" target="#b24">Wang and Manning, 2010</ref>) also provide a uniform way to learn both intermediary representations and a decision function using potentially rich feature sets. They use heuristics in the joint learning pro- cess to reduce the computational cost, while our kernel approach with a simple sequential repre- sentation of sentences has the benefit of efficiently computing an exact number of common rewriting rules between rewriting pairs. This in turn allows to precisely fine-tune the shape of desired rewrit- ing rules through the design of the typing scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We developed a unified kernel-based framework for solving sentence rewriting tasks. Types al- low for an increased flexibility in counting com- mon rewriting rules, and can also add a semantic layer to the rewritings. We show that we can effi- ciently compute a kernel which takes types into ac- count, called type-enriched k-gram bijective string rewriting kernel. A SVM classifier with this kernel yields state-of-the-art results in paraphrase identi- fication and answer sentence selection and outper- forms comparable systems in recognizing textual entailment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>with a id ≈ b, resp. a id ; b, if and only if a = b.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Mary</head><label></label><figDesc>was shouting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Rewriting rule (A) matches pair of strings (B) but does not match (C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>if and only if a and b have a common hypernym in WordNet. And we change Γ v to Γ v = {same pronoun, en- tailment, id} where a same pronoun ; b if and only if a and b are a pronoun of the same person and same number, and a entailment ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Bipartite graph of character pairs, with edges between potential wildcards</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Evolution of the number of recursive calls to CountPerfectMatchings with k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>;</head><label></label><figDesc></figDesc><table>23 

if compatWkgrms not initialized then 

24 

resAllPatterns += (α t 1 , α t 2 ); 

25 

for (α s 1 , α s 2 ) ∈ compatWkgrms do 

26 

resWildcards+=((α s 1 , α s 2 ), (α t 1 , α t 2 )); 

27 return (resWildcards, resAllPatterns); 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 1 : Types</head><label>1</label><figDesc></figDesc><table>Paraphrase system 
Accuracy F-score 
All paraphrase 
66.5 
79.9 
Wan et al. (2006) 
75.6 
83.0 
Bu et al. (2012) 
76.3 
N/A 
Socher et al. (2011) 
76.8 
83.6 
Madnani et al. (2012) 
77.4 
84.1 
PR 
73.5 
82.1 
SRK + PR 
76.2 
83.6 
TESRK 
76.6 
83.7 
TESRK + PR 
77.2 
84.0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 : Evaluation results on MSR Paraphrase</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> Available at http://nlp.stanford.edu/ mengqiu/data/qg-emnlp07-data.tgz</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2012 task 6: A pilot on semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="385" to="393" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">String re-writing kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dependency vs. constituent based syntactic n-grams in text similarity measures for paraphrase recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiram</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Segura-Olivares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computación y Sistemas</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="517" to="554" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Libsvm: a library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Chih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2011" />
			<publisher>TIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Discriminative learning over constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="429" to="437" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="177" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWP</title>
		<meeting>of IWP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics, page 350. Association for Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics, page 350. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic similarity of short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing V</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Softcardinality: hierarchical text overlap for student response analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Becerra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd joint conference on lexical and computational semantics</title>
		<meeting>the 2nd joint conference on lexical and computational semantics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="280" to="284" />
		</imprint>
	</monogr>
	<note>Av Juan Dios Bátiz, and Av Mendizábal</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dissimilarity kernels for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mihai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasile</forename><surname>Lintean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FLAIRS Conference</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Text classification using string kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huma</forename><surname>Lodhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Watkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="419" to="444" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generating phrasal and sentential paraphrases: A survey of data-driven methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="387" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Re-examining machine translation metrics for paraphrase identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="182" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Corpus-based and knowledge-based measures of text semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="775" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern</forename><surname>Kottmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gann</forename><surname>Bierner</surname></persName>
		</author>
		<ptr target="http://opennlp.sourceforge.net" />
		<title level="m">Opennlp: A java-based nlp toolkit</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient convolution kernels for dependency and constituent syntactic trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: ECML 2006</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="318" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Snowball: A language for stemming algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic pooling and unfolding recursive autoencoders for paraphrase detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="801" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The complexity of enumeration and reliability problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="410" to="421" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The nature of statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using dependency-based features to take the para-farce out of paraphrase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cécile</forename><surname>Paris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Workshop</title>
		<meeting>the Australasian Language Technology Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Probabilistic tree-edit models with structured latent variables for textual entailment and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasisynchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teruko</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Question answering using enhanced lexical semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pastusiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26rd International Conference on Computational Linguistics</title>
		<meeting>the 26rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shallow semantics in fast textual entailment rule learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing</title>
		<meeting>the ACL-PASCAL workshop on textual entailment and paraphrasing</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Efficient graph kernels for textual entailment recognition. Fundamenta Informaticae</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Dellarciprete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
