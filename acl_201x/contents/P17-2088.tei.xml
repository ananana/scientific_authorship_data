<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On the Equivalence of Holographic and Complex Embeddings for Link Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>July 30-August 4, 2017. July 30-August 4, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhiko</forename><surname>Hayashi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Shimbo</surname></persName>
						</author>
						<title level="a" type="main">On the Equivalence of Holographic and Complex Embeddings for Link Prediction</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</title>
						<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) <address><addrLine>Vancouver, Canada; Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="554" to="559"/>
							<date type="published">July 30-August 4, 2017. July 30-August 4, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/p17-2088</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We show the equivalence of two state-of-the-art models for link prediction/ knowledge graph completion: Nickel et al&apos;s holographic embeddings and Trouil-lon et al.&apos;s complex embeddings. We first consider a spectral version of the holo-graphic embeddings, exploiting the frequency domain in the Fourier transform for efficient computation. The analysis of the resulting model reveals that it can be viewed as an instance of the complex em-beddings with a certain constraint imposed on the initial vectors upon training. Conversely , any set of complex embeddings can be converted to a set of equivalent holographic embeddings.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, there have been efforts to build and maintain large-scale knowledge bases represented in the form of a graph (knowledge graph) <ref type="bibr" target="#b0">(Auer et al., 2007;</ref><ref type="bibr" target="#b1">Bollacker et al., 2008;</ref><ref type="bibr" target="#b11">Suchanek et al., 2007)</ref>. Although these knowledge graphs con- tain billions of relational facts, they are known to be incomplete. Knowledge graph completion (KGC) ( <ref type="bibr" target="#b7">Nickel et al., 2015</ref>) aims at augmenting missing knowledge in an incomplete knowledge graph automatically. It can be viewed as a task of link prediction <ref type="bibr" target="#b6">(Liben-Nowell and Kleinberg, 2003;</ref><ref type="bibr" target="#b5">Hasan and Zaki, 2011</ref>) studied in the field of statistical relational learning <ref type="bibr" target="#b3">(Getoor and Taskar, 2007)</ref>. In recent years, methods based on vec- tor embeddings of graphs have been actively pur- sued as a scalable approach to <ref type="bibr">KGC (Bordes et al., 2011;</ref><ref type="bibr" target="#b10">Socher et al., 2013;</ref><ref type="bibr" target="#b4">Guu et al., 2015;</ref><ref type="bibr">Yang et al., 2015;</ref><ref type="bibr" target="#b8">Nickel et al., 2016;</ref><ref type="bibr">Trouillon et al., 2016b)</ref>.</p><p>In this paper, we investigate the connection between two models of graph embeddings that have emerged along this line of research: The holographic embeddings ( <ref type="bibr" target="#b8">Nickel et al., 2016</ref>) and the complex embeddings ( <ref type="bibr">Trouillon et al., 2016b</ref>). These models are simple yet achieve the current state-of-the-art performance in KGC.</p><p>We begin by showing that holographic embed- dings can be trained entirely in the frequency do- main induced by the Fourier transform, thereby reducing the time needed to compute the scoring function from O(n log n) to O(n), where n is the dimension of the embeddings.</p><p>The analysis of the resulting training method reveals that the Fourier transform of holographic embeddings can be regarded as an instance of the complex embeddings, with a specific constraint (viz. conjugate symmetry property) cast on on the initial values.</p><p>Conversely, we also show that every set of com- plex embeddings has a set of holographic embed- dings (with real vectors) that is equivalent, in the sense that their scoring functions are equal up to scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>Let i denote the imaginary unit, R be the set of real values, and C the set of complex values. We write <ref type="bibr">[v]</ref> j to denote the jth component of vector v. A superscript T (e.g., v T ) represents vector/matrix transpose. For a complex scalar z, vector z, and matrix Z, z, z, and Z represent their complex con- jugate, and Re(z), Re(z), and Re(Z) denote their real parts, respectively.</p><formula xml:id="formula_0">Let x = [x 0 · · · x n−1 ] T ∈ R n and y = [y 0 · · · y n−1 ] T ∈ R n .</formula><p>Note that the vector indices start from 0 for notational convenience. The cir- cular convolution of x and y, denoted by x * y, is defined by <ref type="bibr">[x * y]</ref> </p><formula xml:id="formula_1">j = n−1 k=0 x [( j−k) mod n] y k ,<label>(1)</label></formula><p>where mod denotes modulus. Likewise, circular correlation x y is defined by</p><formula xml:id="formula_2">[x y] j = n−1 k=0 x [(k− j) mod n] y k .<label>(2)</label></formula><p>While circular convolution is commutative, cir- cular correlation is not; i.e., x * y = y * x, but x y y x in general. As it can be verified with Eqs. <ref type="formula" target="#formula_1">(1)</ref> and <ref type="formula" target="#formula_2">(2)</ref>, x y = flip(x) * y, where</p><formula xml:id="formula_3">flip(x) = [x n−1 · · · x 0 ]</formula><p>T is a vector obtained by arranging the components of x in reverse. For n-dimensional vectors, naively computing circular convolution/correlation by Eqs. <ref type="formula" target="#formula_1">(1)</ref> and (2) requires O(n 2 ) multiplications. However, we can take advantage of the Fast Fourier Transform (FFT) algorithm to accelerate the computation: For circular convolution, first compute the discrete Fourier transform (DFT) of x and y, and then com- pute the inverse DFT of their elementwise vector product, i.e.,</p><formula xml:id="formula_4">x * y = F −1 (F(x) F(y)),</formula><p>where F : R n → C n and F −1 : C n → R n re- spectively denote the DFT and inverse DFT, and denotes the elementwise product. DFT and in- verse DFT can be computed in O(n log n) time with the FFT algorithm, and thus the computation time for circular convolution is also O(n log n). The same can be said of circular correlation. Since F(flip(x)) = F(x), we have</p><formula xml:id="formula_5">x y = F −1 (F(x) F(y)).<label>(3)</label></formula><p>By analogy to how the Fourier transform is used in signal processing, the original real space R n is called the "time" domain, and the complex space C n where DFT vectors reside is called the "fre- quency" domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Holographic embeddings for</head><p>knowledge graph completion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knowledge graph completion</head><p>Let E and R be the finite sets of entities and (bi- nary) relations over entities, respectively. For each relation r ∈ R and each pair s, o ∈ E of entities, <ref type="table">Table 1</ref>: Correspondence between operations in time and frequency domains. r ↔ ρ indicates ρ = F(r) (and also r = F −1 (ρ)). operation time frequency</p><formula xml:id="formula_6">scalar mult. αx ←→ α F(x) summation x + y ←→ F(x) + F(y) flip flip(x) ←→ F(x) convolution x * y ←→ F(x) F(y) correlation x y ←→ F(x) F(y) dot product x · y = 1 n F(x) · F(y)</formula><p>we are interested in whether r(s, o) holds 1 or not; we write r(s, o) = +1 if it holds, and r(s, o) = −1 if not. To be precise, given a training set </p><formula xml:id="formula_7">D = R × E × E × {−1, +1} such that (r, s, o, y) ∈ D indicates y = r(s, o), our task is to design a scor- ing function f : R × E × E → R such that</formula><formula xml:id="formula_8">= +1] = σ( f (r, s, o)), where σ : R → (0, 1) is a sigmoid function.</formula><p>Dataset D can be regarded as a directed graph in which nodes represent entities E and edges are la- beled by relations R. Thus, the task is essentially that of link prediction <ref type="bibr" target="#b6">(Liben-Nowell and Kleinberg, 2003;</ref><ref type="bibr" target="#b5">Hasan and Zaki, 2011</ref>). Often, it is also called knowledge graph completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Holographic embeddings (HolE)</head><p>Nickel et al. <ref type="formula" target="#formula_1">(2016)</ref> proposed holographic em- beddings (HolE) for knowledge graph completion. Using training data D, this method learns the vec- tor embeddings e k ∈ R n of entities k ∈ E and the embeddings w r ∈ R n of relations r ∈ R. The score for triple (r, s, o) is then given by</p><formula xml:id="formula_9">f HolE (r, s, o) = w r · (e s e o ).<label>(4)</label></formula><p>Eq. (4) can be evaluated in time O(n log n) if e s e o is computed by Eq. (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Spectral training of HolE</head><p>To compute the circular correlation in the scoring function of Eq. <ref type="formula" target="#formula_9">(4)</ref>  Depending on the context, letter r is used either as an index to an element in R or the binary relation it signifies. sider training HolE solely in the frequency do- main. That is, real-valued embeddings e k , w r ∈ R n in the original "time" domain are abolished, and instead we train their DFT counterparts ε k = F(e k ) ∈ C n and ω k = F(w r ) ∈ C n in the frequency domain. This formulation eliminates the need of FFT and inverse FFT, which are the major com- putational bottleneck in HolE. As a result, Eq. <ref type="formula" target="#formula_9">(4)</ref> can be computed in time O(n) directly from ε k and ω k .</p><p>Indeed, equivalent counterparts in the frequency domain exist for not only convolution/correlation but all other computations needed for HolE: scalar multiplication, summation (needed when vectors are updated by stochastic gradient descent), and dot product (used in Eq. <ref type="formula" target="#formula_9">(4)</ref>). The frequency- domain equivalents for these operations are sum- marized in <ref type="table">Table 1</ref>. All of these can be performed efficiently (in linear time) in the frequency do- main.</p><p>In particular, the following relation holds for the dot product between any "time" vectors x, y ∈ R n .</p><formula xml:id="formula_10">x · y = 1 n F(x) · F(y),<label>(5)</label></formula><p>where the dot product on the right-hand side is the complex inner product defined by a · b = a T b. Eq. (5) is known as Parseval's theorem (also called the power theorem in <ref type="bibr" target="#b9">(Smith, 2007)</ref>), and it states that dot products in two domains are equal up to scaling. After embeddings ε k , ω r ∈ C n are learned in the frequency domain, their time-domain coun- terparts e k = F −1 (ε k ) and w r = F −1 (ω r ) can be recovered if needed, but this is not required as far as computation of the scoring function is con- cerned. Thanks to Parseval's theorem, Eq. (4) can be directly computed from the frequency vectors ε k , ω r ∈ C n by</p><formula xml:id="formula_11">f HolE (r, s, o) = 1 n ω r · (ε s ε o ).<label>(6)</label></formula><p>4.1 Conjugate symmetry of spectral components</p><formula xml:id="formula_12">A complex vector ξ = [ξ 0 · · · ξ n−1 ] T ∈ C n is said to be conjugate symmetric (or Hermitian) if ξ j = ξ [(n− j) mod n] for j = 0, .</formula><p>. . , n − 1, or, in other words, if it can be written in the form</p><formula xml:id="formula_13">ξ =          ξ 0 γ flip(γ) T , if n is odd, ξ 0 γ ξ n/2 flip(γ)</formula><p>T , if n is even, for some γ ∈ C n/2−1 and ξ 0 , ξ n/2 ∈ R.</p><p>The DFT F(x) is conjugate symmetric if and only if x is a real vector. Thus, maintaining con- jugate symmetry of "frequency" vectors is the key to ensure their "time" counterparts remain in real space. Below, we verify that this property is in- deed preserved with stochastic gradient descent. Moreover, conjugate symmetry provides a suffi- cient condition under which dot product takes a real value. It also has implications on space re- quirement. These topics are covered in the rest of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Vector initialization and update in frequency domain</head><p>Typically where λ ∈ R is the hyperparameter controlling the degree of regularization, and · F denotes the Frobenius norm. In our version of spectral training of HolE, the parameters matrix consists of frequency vec- tors ε k and ω r instead of e k and w r , i.e.,</p><formula xml:id="formula_14">Θ = [ε 1 · · · ε |E | ω 1 · · · ω |R| ] ∈ C n×(|E |+|R|)</formula><p>. Let us dis- cuss the stochastic gradient descent (SGD) update with respect to these frequency vectors. In partic- ular, we are interested in whether conjugate sym- metry of vectors is preserved by the update.</p><p>Suppose vectors ω r , ε s , ε o are conjugate sym- metric. Neglecting the contribution from the regularization term 2 in Eq. <ref type="formula">(7)</ref>, we see that in an SGD update step, α∂ f HoLE /∂ω r , α∂ f HoLE /∂ε s , and α∂ f HoLE /∂ε o are respectively subtracted from ω r , ε s , ε o , where α ∈ R is a factor not depending on these parameters. Noting the equalities</p><formula xml:id="formula_15">w r · (e s e o ) = e s · (w r e o ) = e o · (w r * e s )</formula><p>(see ( <ref type="bibr">Nickel et al., 2016, Eq. (12)</ref>, p. 1958)) and their frequency counterparts</p><formula xml:id="formula_16">ω r · (ε s ε o ) = ε s · (ω r ε o ) = ε o · (ω r ε s ),</formula><p>obtained through the translation of <ref type="table">Table 1</ref>, we can derive</p><formula xml:id="formula_17">∂ f HolE ∂ω r = ε s ε o , ∂ f HolE ∂ε s = ω r ε o , ∂ f HolE ∂ε o = ω r ε s .</formula><p>As seen from above, conjugation, scalar multipli- cation, summation, and elementwise product are used in the SGD update. And it is straightforward to verify that all these operations preserve con- jugate symmetry. It follows that if ω r , ε s , ε o are initially conjugate symmetric, they will remain so during the course of training, which assures that the inverse DFTs of the learned embeddings are real vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Real-valued dot product</head><p>In the scoring function of HolE (Eq. <ref type="formula" target="#formula_9">(4)</ref>), dot prod- uct is used for generating a real-valued "score" out of two vectors, w r and e s e o . Likewise, in Eq. (6), the dot product is applied to ω r and ε s ε o , which are complex-valued. However, pro- vided that the conjugate symmetry of these vec- tors is maintained, their dot product is always real. This follows from Parseval's theorem; the inverse DFTs of these frequency vectors are real, and thus their dot product is also real. Therefore, the dot product of the corresponding frequency vectors is real as well, according to Eq. (5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Space requirement</head><p>A general complex vector ξ ∈ C n can be stored in memory as 2n floating-point numbers, i.e., one each for the real and imaginary part of a compo- nent. In our spectral representation of HolE, how- ever, the first n/2 components suffice to specify the frequency vector ξ, since the vector is con- jugate symmetric. Moreover, ξ 0 (and ξ n/2 if n is even) are real values. Thus, a spectral repre- sentation of HolE can be specified with exactly n floating-point numbers, which can be stored in the same amount of memory as needed by the original HolE. </p><formula xml:id="formula_18">f ComplEx (r, s, o) = Re          n−1 j=0 [w r ] j [e s ] j [e o ] j          . (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Equivalence of holographic and complex embeddings</head><p>Now let us rewrite Eq. (8). Noting the definition of complex dot product, i.e., a · b = a T b, we have</p><formula xml:id="formula_19">n−1 j=0 [w r ] j [e s ] j [e o ] j = (e s e o ) T w r = (e s e o ) · w r ( a · b = a T b) = (e s e o ) · w r = w r · (e s e o ) ( a · b = b · a)</formula><p>and since Re(z) = Re(z),</p><formula xml:id="formula_20">Re(w r · (e s e o )) = Re(w r · (e s e o )).</formula><p>Thus, Eq. <ref type="formula">(8)</ref> can be written as</p><formula xml:id="formula_21">f ComplEx (r, s, o) = Re w r · (e s e o )</formula><p>. <ref type="formula">(9)</ref> Here, a marked similarity is noticeable between Eq. <ref type="formula">(9)</ref> and Eq. <ref type="formula" target="#formula_11">(6)</ref>, the scoring function of our spectral version of HolE (spectral HolE); Com- plEx extracts the real part of complex dot prod- uct, whereas in the spectral HolE, dot product is guaranteed to be real because all embeddings sat- isfy conjugate symmetry. Indeed, Eq. (6) can be equally written as</p><formula xml:id="formula_22">f HolE (r, s, o) = 1 n Re ω r · (ε s ε o ) .<label>(10)</label></formula><p>although the operator Re(·) in this formula is re- dundant, since the inner product is guaranteed to be real-valued. Nevertheless, Eq. (10) elucidates the fact that the spectral HolE can be viewed as an instance of ComplEx, with the embeddings con- strained to be conjugate symmetric to make the inner product in Eq. <ref type="formula" target="#formula_1">(10)</ref> real-valued. Conversely, given a set of complex embeddings for entities and relations, we can construct their equivalent holographic embeddings, in the sense that f ComplEx (r, s, o) = c f HolE (r, s, o) for every r, s, o, where c &gt; 0 is a constant. For each n- dimensional complex embeddings x ∈ {e k } k∈E ∪ {w r } r∈R ⊂ C n computed by ComplEx, we make a corresponding HolE h(x) ∈ R 2n+1 as follows: For a given complex embedding</p><formula xml:id="formula_23">x = [x 0 · · · x n−1 ] ∈ C n , first compute s(x) ∈ C 2n+1 by s(x) = 0 x 0 · · · x n−1 x n−1 · · · x 0 T = 0 x flip(x) T<label>(11)</label></formula><p>and then define h(x) = F −1 (s(x)). Since s(x) is conjugate symmetric, h(x) is a real vector. To verify if this conversion defines an equiva- lent scoring function for any triple (r, s, o), let us now suppose complex embeddings w r ∈ C n and e s , e o ∈ C n are given. Since we regard real vec- tors h(w r ), h(e s ), h(e o ) ∈ R 2n+1 as the holographic embeddings of r, s and o, respectively, the HolE score for the triple (r, s, o) is given as</p><formula xml:id="formula_24">f HolE (r, s, o) = h(w r ) · (h(e s ) h(e o )) = 1 n s(w r ) · (s(e s ) s(e o )) ( Eq. (6)) = 1 n s(w r ) · 0 e s e o flip(e s e o ) T ( Eq. (11)) = 1 n 0 w r flip(w r ) T · 0 e s e o flip(e s e o ) T = 1 n w r · (e s e o ) + flip(w r ) · flip(e s e o ) = 1 n w r · (e s e o ) + w r · (e s e o ) = 1 n w r · (e s e o ) + w r · (e s e o ) = 2 n Re w r · (e s e o ) = 2 n f ComplEx (r, s, o),</formula><p>which shows that h(·) (or s(·)) gives the desired conversion from ComplEx to HolE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we have shown that the holographic embeddings (HolE) can be trained entirely in the frequency domain. If stochastic gradient descent is used for training, the conjugate symmetry of frequency vectors is preserved, which ensures the existence of the corresponding holographic em- bedding in the original real space (time domain). Also, this training method eliminates the need of FFT and inverse FFT, thereby reducing the compu- tation time of the scoring function from O(n log n) to O(n). Moreover, we have established the equivalence of HolE and the complex embeddings (ComplEx): The spectral version of HolE is subsumed by Com- plEx as a special case in which conjugate symme- try is imposed on the embeddings. Conversely, ev- ery set of complex embeddings can be converted to equivalent holographic embeddings.</p><p>Many systems for natural language process- ing, such as those for semantic parsing and ques- tion answering, benefit from access to information stored in knowledge graphs. We plan to further in- vestigate the property of spectral HolE and Com- plEx in these applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>for each of the triples (r, s, o) not observed in D, func- tion f should give a higher value if r(s, o) = +1 is more likely, and a smaller value for those that are less likely. If necessary, f (r, s, o) can be converted to probability by P[r(s, o)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>5</head><label></label><figDesc>Relation to Trouillon et al.'s complex embeddings 5.1 Complex embeddings (ComplEx) Trouillon et al. (2016b) proposed a model of embedding-based knowledge graph completion, called complex embeddings (ComplEx). The ob- jective is similar to Nickel et al.'s; the embed- dings e k of entities and w r of relations are to be learned. In their model, however, these vectors are complex-valued, and are based on the eigen- decomposition of complex matrix X r = EW r E T that encodes relation r ∈ R over pairs of entities, where X r ∈ C |E |×|E | , E = [e 1 , . . . , e |E | ] T ∈ C |E |×n , and W r = diag(w r ) ∈ C n×n is a diagonal matrix (with diagonal elements w r ∈ C n ). In practice, X r needs to be a real matrix, because its (r, s)- component must define the score for r(s, o). To this end, Trouillon et al. simply extracted the real part; i.e., X r = Re(EW r E T ). Trouillon et al. (2016a) advocated this approach, by showing that any real matrix X r can be expressed in this form. With this formulation, the score for triple (r, s, o) is given by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>, at the beginning of training HolE, each individual embedding is initialized by a random vector. When we train HolE in the frequency do- main, we could first generate a random real vector, regard them as a HolE vector in the time domain, and compute its DFT as the initial value in the fre- quency domain. An alternative, easier approach is to directly generate a random complex vector that is conjugate symmetric, and use it as the ini- tial frequency vector.</figDesc><table>This guarantees the inverse 
DFT to be a real vector, i.e., there exists a valid 
corresponding image in the time domain. 
Given a training set D (see Section 3.1), 
HolE is trained by minimizing the following 
objective function over parameter matrix Θ = 
[e 1 · · · e |E | w 1 · · · w |R| ] ∈ R n×(|E |+|R|) : 

(r,s,o,y)∈D 

log{1 + exp(−y f HolE (r, s, o))} + λ||Θ|| 2 
F (7) 

</table></figure>

			<note place="foot" n="2"> It can be easily verified that the contribution from the regularization term to SGD update do not violate conjugate symmetry.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for helpful comments. This work was partially supported by JSPS Kakenhi Grants 26730126 and 15H02749.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DBpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: Proceedings of the 6th International Semantic Web Conference and the 2nd Asian Semantic Web Conference (ISWC &apos;07/ASWC &apos;07)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4825</biblScope>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data (SIGMOD &apos;08)</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data (SIGMOD &apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI &apos;11)</title>
		<meeting>the 25th AAAI Conference on Artificial Intelligence (AAAI &apos;11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="301" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Introduction to Statistical Relational Learning. Adaptive Computation and Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Traversing knowledge graphs in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;15)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP &apos;15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="318" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey of link prediction in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Network Data Analytics</title>
		<editor>Charu C. Aggarwal</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="243" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The link prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Liben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12nd Annual ACM International Conference on Information and Knowledge Management (CIKM &apos;03)</title>
		<meeting>the 12nd Annual ACM International Conference on Information and Knowledge Management (CIKM &apos;03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="556" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A review of relational machine learning for knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE pages</title>
		<meeting>the IEEE pages</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI &apos;16)</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence (AAAI &apos;16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1955" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julius</forename><forename type="middle">O</forename><surname>Iii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<title level="m">Mathematics of the Discrete Fourier Transform (DFT): with Audio Applications. W3K Publishing</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26 (NIPS &apos;13)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">YAGO: A core of semantic knowledge unifying Wordnet and Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on World Wide Web (WWW &apos;07)</title>
		<meeting>the 16th International Conference on World Wide Web (WWW &apos;07)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
