<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing Grammatical Cohesion: Generating Transitional Expressions for SMT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 23-25</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Enhancing Grammatical Cohesion: Generating Transitional Expressions for SMT</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics <address><addrLine>Baltimore, Maryland, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="850" to="860"/>
							<date type="published">June 23-25</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Transitional expressions provide glue that holds ideas together in a text and enhance the logical organization, which together help improve readability of a text. However, in most current statistical machine translation (SMT) systems, the outputs of compound-complex sentences still lack proper transitional expressions. As a result, the translations are often hard to read and understand. To address this issue, we propose two novel models to encourage generating such transitional expressions by introducing the source compound-complex sentence structure (CSS). Our models include a CSS-based translation model, which generates new CSS-based translation rules, and a generative transfer model, which encourages producing transitional expressions during decoding. The two models are integrated into a hierarchical phrase-based translation system to evaluate their effectiveness. The experimental results show that significant improvements are achieved on various test data meanwhile the translations are more cohesive and smooth.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the last decade, great progress has been made on statistical machine translation (SMT) models. However, these translations still suffer from poor readability, especially translations of compound-complex sentences. One of the main reasons may be that most existing models con- centrate more on producing well-translated local sentence fragments, but largely ignore global cohesion between the fragments. Generally, co- hesion, including lexical and grammatical cohe- sion, contributes much to the understandability and smoothness of a text.</p><p>Recently, researchers have begun addressing the lexical cohesion of SMT ( <ref type="bibr" target="#b3">Gong et al., 2011;</ref><ref type="bibr" target="#b21">Xiao et al., 2011;</ref><ref type="bibr">Wong and Kit, 2012;</ref><ref type="bibr">Xiong, 2013)</ref>. These efforts focus mainly on the co- occurrence of lexical items in a similar environ- ment. Grammatical cohesion 1 <ref type="bibr">(Halliday and Hassan, 1976</ref>) in SMT has been little mentioned in previous work. Translations without grammatical cohesion is hard to read, mostly due to loss of cohesive and transitional expressions between two sentence fragments. Thus, generating transi- tional expressions is necessary for achieving grammatical cohesion. However, it is not easy to produce such transitional expressions in SMT.</p><p>As an example, consider the Chinese-to-English translation in <ref type="figure" target="#fig_0">Figure 1</ref>. already , more show environment protection of urgent .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target English golden translation:</head><p>Despite frequent calls for cutting pollution, and growing public anger, the problem has only got worse, which increasingly shows the urgency of environmental protection. There are 4 sub-sentences separated by com- mas in the Chinese sentence. We have tried to translate the Chinese sentence using many well-known online translators, but find that it is very difficult to generate the target transitional ex- pressions, especially when there is no explicit connective word in the source sentence, such as generating "and " and "which" in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Fortunately, the functional relationships be- tween two neighboring source sub-sentences provide us with a good perspective and the inspi- ration to generate those transitional phrases. <ref type="figure" target="#fig_0">Fig- ure 1</ref> shows that the first and the second Chinese sub-sentences form a parallel relation. Thus, even though there is no distinct connective word at the beginning of the second source sub- sentence, a good translator is still able to insert or generate an "and" as a connection word to make the target translation more cohesive.</p><p>Based on the above analysis, this paper focus- es on the target grammatical cohesion in SMT to make the translation more understandable, espe- cially for languages with great difference in lin- guistic structure like Chinese and English. To the best of our knowledge, our work is the first at- tempt to generate target transitional expressions for SMT grammatical cohesion by introducing the functional relationships of source sentences. In this work, we propose two models. One is a new translation model that is utilized to generate new translation rules combined with the infor- mation of source functional relationships. The other is a generative transfer model that encour- ages producing transitional phrases during de- coding. Our experimental results on Chinese-to- English translation demonstrate that the transla- tion readability is greatly improved by introduc- ing the cohesive information.</p><p>The remainder of the paper is organized as follows. In Section 2, we describe the functional relationships of Chinese compound-complex sen- tences. In Section 3, we present our models and show how to integrate the models into an SMT system. Our experimental results are reported in Section 4. A survey of related work is conducted in Section 5, and we conclude our work and out- line the future work in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Chinese Compound-Complex Sen- tence Structure</head><p>To acquire the functional relationships of a Chi- nese compound-complex sentence, <ref type="bibr" target="#b26">Zhou (2004)</ref> proposed a well-annotated scheme to build the Compound-complex Sentence Structure (CSS). The structure explicitly shows the minimal se- mantic spans, called elementary units (eus), and also depicts the hierarchical relations among eus.</p><p>There are 11 common types of functional rela- tionships 2 annotated in the Tsinghua Chinese Treebank <ref type="bibr" target="#b26">(Zhou, 2004)</ref>. Under the annotation scheme of the Tsinghua Chinese Treebank, the Chinese sentence of ex- ample in <ref type="figure" target="#fig_0">Figure 1</ref> is represented as the tree shown in <ref type="figure">Figure 2</ref>. In this example, each sub- sentence is an eu. eu <ref type="bibr">1</ref> and eu 2 are combined with a parallel relationship, followed by eu 3 with an adversative relationship. eu 1, eu 2, and eu 3 form a large semantic span 3 , connected with eu 4 by a consequence relationship. All of the eus are or- ganized into various functional relationships and finally form a hierarchical tree.  <ref type="figure">Figure 2</ref>: The compound-complex sentence structure of the Chinese sentence in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>parallel-[(1,1), (2,2)] adversative-[(1,2),(3,3)] consequence-[(1,3),(4,4)]</head><p>Formally, given a compound-complex sen- tence structure (CSS), each node in the CSS can be represented as a tuple</p><formula xml:id="formula_0">11 [( , ),...( , ),...,( , )]  l l L L R s e s e s e</formula><p>. R represents the relationship, which has L children. For each child of R , a pair ( , ) l l se records its start and end eus. For example, adversative-[(1,2), (3,3)] in <ref type="figure">Figure 2</ref> means that two children are controlled by the relationship adversative, and the left child consists of eu 1 and eu 2 , while the right child con- tains only eu <ref type="bibr">3</ref> .</p><p>CSS has much in common with Rhetorical Structure ( <ref type="bibr" target="#b8">Mann and Thompson, 1988</ref>) in Eng- lish, which also describe the semantic relation between discourse units. But the Rhetorical Structure involves much richer relations on the document-level, and little corpus is open for Chinese.</p><p>In the following, we will describe in detail how to utilize such CSS information for model- ling in SMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Modelling</head><p>Our purpose is to enhance the grammatical cohe- sion by exploiting the source CSS information. Therefore, theoretically, the conditional probabil- ity of a target translation e s conditioned on the source CSS-based tree f t is given by ( | ) Following <ref type="bibr" target="#b13">Och and Ney (2002)</ref>, our model is framed as a log-linear model: <ref type="bibr">where ( , )</ref> st h efis a feature with weight  . Then, the best translation is:</p><formula xml:id="formula_1">exp ( , ) ( | ) (2) exp ( , )       s k k k s t st k k k s t h P h e ef ef e' f</formula><formula xml:id="formula_2">arg max exp ( , )<label>(3)</label></formula><formula xml:id="formula_3">s s k k k s t h    e e e f</formula><p>Our models make use of CSS with two strate- gies:</p><p>1) CSS-based translation model: following formula (1), we obtain the cohesion information by modifying the translation rules with their probabilities ( | ) st P ef based on word align- ments between the source CSS-tree and the tar- get string;</p><p>2) CSS-based transfer model: following formula (3), we introduce a transfer score to en- courage the decoder to generate transitional words and phrases; the score is utilized as an ad- ditional feature ( , )</p><formula xml:id="formula_4">k s t</formula><p>h ef in the log-linear model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CSS-based Translation Model</head><p>For the existing translation models, the entire training process is conducted at the lexical or syntactic level without grammatically cohesive information. As a result, it is difficult to utilize such cohesive information during decoding. In- stead, we reserve the cohesive information in the training process by converting the original source sentence into tagged-flattened CSS and then per- form word alignment and extract the translation rules from the bilingual flattened source CSS and the target string. As introduced in Section 2, a CSS consists of nodes, and a node can be represented as a tuple</p><formula xml:id="formula_5">11 [( , ),...( , ),...,( , )] LL ll R s e s e s e  .</formula><p>In this represen- tation, the relationship R is the most important factor because different relationships directly reflect different cohesive expressions. In addition, the children's positions always play a strong role in choosing cohesive expressions because transi- tional expressions vary for children with differ- ent positions. For example, when translating the last child of a parallel relation, we always use word "and" as the transitional expression seen in <ref type="figure">Figure 3</ref>, but we will not use it for the first child of a parallel relation. Therefore, in the training process we just keep the information of relation- ships and children's positions when converting Figure 3: An example of modifying translation rules. @B means the current structure information comes from the first child, and @E means from the last child.</p><p>the source CSS to a tagged-flattened string.</p><p>Considering that the absolute position (index of the eu, such as 1, 2, 3) is somehow sparse in the corpus, we employ the relative position in- stead. B (Beginning) represents the first child of a relationship, E (End) means the last child of a relationship, and M (Middle) represents all the middle children.</p><p>Under this agreement, the original Chinese CSS-based tree will be converted to a new tagged-flattened string. Note the converting ex- ample from <ref type="figure">Figure 3</ref>(a) to <ref type="figure">Figure 3</ref>(b): node par- allel-[(1,1), (2,2)] (see <ref type="figure">Figure 2</ref>) is converted to a flat string. Its first child is represented as &lt;par- allel, @B&gt; with the semantic span, while the last child is &lt;parallel, @E&gt; with the corresponding semantic span.</p><p>We then perform word alignment on the modi- fied bilingual sentences, and extract the new translation rules based on the new alignment, as shown in <ref type="figure">Figure 3</ref>(b) to <ref type="figure">Figure 3</ref>(c). Now the newly extracted rule "&lt;parallel, @E &gt; [X] 日渐 ||| and growing <ref type="bibr">[X]</ref> " is tagged with cohesive in- formation. Thus, if the similar relationship paral- lel occurs in the test source sentence, this type of rule is more likely to be chosen to generate the cohesive word "and" during decoding because it is more discriminating than the original rules ( <ref type="bibr">[X]</ref> 日渐 ||| and growing <ref type="bibr">[X]</ref>). The conditional prob- abilities of the new translation rules are calculat- ed following <ref type="bibr" target="#b1">(Chiang, 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CSS-based Transfer model</head><p>In general, according to formula (3), the transla- tion quality based on the log-linear model is re- lated tightly with the features chosen. Most trans- lation systems adopt the features from a transla- tion model, a language model, and sometimes a reordering model. To give a bonus to generating cohesive expressions during decoding, we have designed a special additional feature. The addi- tional feature is represented as a probability cal- culated by a transfer model. Given the source CSS information, we want our transfer model to predict the most possible cohesive expressions. For example, given two semantic spans with a parallel relationship and many translation candidates, our transfer model is expected to assign higher scores to those with transitional expressions such as "and" or "as well as". Let 01 , ,... n w w w  w represent the transitional expressions observed in the target string. Our transfer model can be represented as a condition- al probability:</p><p>( | ) (4) P CSS w By deriving each node of the CSS, we can obtain a factored formula: Considering that ij w commonly appears at the beginning of the target translation of a source semantic span such as "which …", namely, the left-frontier phrases, we focus only on the left- frontier phrases when training this model. Note that if there exists a target word before a left frontier, and this word is aligned to NULL, we will expand the left frontier to this word. The expansion process will be repeated until there is no such word. For example, if we take the CSS and the alignment in <ref type="figure">Figure 3</ref>(a) for training, the left frontier of the second child will be expanded from "growing" to "and". In addition, taking the tri-gram left-frontier phrase for example, we can obtain a training sample such as ij w = and grow- ing public, R=parallel, RP = E. By learning such probabilities for different transitional expressions conditioned on different relationships, we are able to capture the inner connection between the source CSS and the pro- jected target cohesive phrases. Thus, during de- coding, if we add the probability generated by the transfer model of ( | ) P CSS w as a feature in formula (3), it will certainly contribute to select- ing more cohesive candidates.</p><formula xml:id="formula_6">, ( | ) ( | , )<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Elementary-Unit Cohesion Constraint</head><p>As mentioned in Section 3.2, in the transfer model, the transitional phrases are expected to occur at the left frontier of a projected span on target side. In fact, this depends on the assump- tion that the projected translations of any two disjoint source semantic spans are also disjoint to keep their own semantic integrity. We call this assumption the integrity assumption. This as- sumption is intuitive and supported by statistics. After analyzing 1,007 golden aligned Chinese- English sentence-pairs, we find that approxi- mately 90% of the pairs comply with the as- sumption. However, in real automatically aligned noisy data, the ratio of complying pairs reduces to 71% 4 . Two projected translations that violate the integrity assumption may mutually overlap, which causes our confusion on where to extract the transitional phrases. In this case, extracted transitional phrases are likely to be wrong.</p><p>To increase the chance of extracting correct transitional phrases, the alignment results must be modified to reduce the impact of incorrect alignment. We propose a dynamic cleaning method to ensure that the most expressive transi- tional phrases fall in the accessible extraction range before training the transfer model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">EUC and non-EUC</head><p>As we have defined in Section 2, the minimal semantic span is called elementary unit (eu). If the source eu and its projected target span com- ply with the integrity assumption, we say that such an eu and its projected span have Elemen- tary-Unit-Cohesion (EUC). We define EUC formally as follows.</p><p>Given  <ref type="figure">Figure.4</ref> The schematic diagram of EUC cases and non-EUC case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">A Dynamic Cleaning Method</head><p>An intuitive method to clean the alignment re- sults is to drop off the noisy word-to-word links that cause non-EUC. Considering that the drop- ping process is a post-editing method for the original alignment obtained by a state-of-the-art aligner such as GIZA++, we do not expect over- deleting. Therefore, we tend to take a relatively conservative strategy to minimize the deleting operation. . If A is the word alignment of (f, e), then the goal is to con- struct the maximum subset * A A  under the condition that * A is the word alignment with the constraint of EU. The search process can be de- scribed as the pseudo code in <ref type="figure" target="#fig_3">Figure 5</ref>.</p><p>In <ref type="figure" target="#fig_3">Figure 5</ref>, we scan each target word and each source eu to assign each word to a unique eu un- der the EUC constraint with the lowest cost. Before the next iteration, the bad branches are pruned, as seen in line 5. We adopt the following two ways to prune: (1) EUC constraint: if the current link violates EUC alignment, delete it. (2) Keep the hypothesis with a fixed maximum size to avoid too large a searching space. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>To obtain the CSSs of Chinese sentences, we use the Chinese parser proposed in ( <ref type="bibr" target="#b18">Tu et al., 2013a</ref>). Their parser first segments the compound- complex sentence into a series of elementary units, and then builds structure of the hierarchical relationships among these elementary units. Their parser was reported to achieve an F-score for elementary unit segmentation of approxi- mately 0.89. The progressive, causal, and condi- tion terms of functional relationships can be rec- ognized with precisions of 0.86, 0.8, and 0.75, respectively, while others, such as purpose, par- allel, and flowing, achieve only 0.5, 0.59 and 0.62, respectively.</p><p>The translation experiments have been con- ducted in the Chinese-to-English direction. The bilingual training data for translation model and CSS-based transfer model is FBIS corpus with approximately 7.1 million Chinese words and 9.2 million English words. We obtain the word alignment with the grow-diag-final-and strategy with GIZA++. Before training the CSS-based transfer model, the alignment for transfer model is modified by our dynamic cleaning method. During the cleaning process, the maximum size of hypothesis is limited to 5. A 5-gram language model is trained with SRILM 5 on the combina- tion of the Xinhua portion of the English Giga- word corpus combined with the English part of FBIS. For tuning and testing, we use NIST03 evaluation data as the development set. NIST04/05/06, CWMT08-Development 6 and CWMT08-Evaluation data are used for testing under the measure metric of BLEU-4 ( <ref type="bibr" target="#b14">Papineni et al. 2002)</ref> with the shortest length penalty. <ref type="table">Table 1</ref> shows how the CSS is distributed in all testing sets. According to the statistics in Ta- ble 1, we see that CSS is really widely distribut- ed in the NIST and CWMT corpora, which im- plies that the translation quality may benefit sub- stantially from the CSS information, if it is well considered in SMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Extracted Transitional Expressions</head><p>Eleven types of Chinese functional relationships and their English left-frontier phrases (tri-gram) learned by our transfer model are given in <ref type="table" target="#tab_6">Table  2</ref>.</p><p>The results in <ref type="table" target="#tab_6">Table 2</ref> show that some left- frontier phrases reflect the source functional rela- tionship well, especially for those with better precision of relationship recognition, such as progressive, causal and condition. Conversely, lower precision of relationship recognition may weaken the learning ability of the transfer model. For example, noisy left-frontier phrases are easi- ly generated under relationships such as parallel and purpose. Score N m ;</p><p>Total CSS Ratio(%) NIST04</p><p>1,788 1,307 73.1 NIST05</p><p>1,082 849 78.5 NIST06</p><p>1,000 745 74.5 CWMT08-Dev.</p><p>1,006 818 81.3 CWMT08-Eval.</p><p>1,006 818 81.3 <ref type="table">Table 1</ref>. The numbers of sentences and the CSS ratios of all sentences. CWMT08-Dev. is short for CWMT08 Development data and CWMT08-Eval. is CWMT08 Evaluation da- ta.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results on SMT with Different Strategies</head><p>For this work, we use an in-house decoder to build the SMT baseline; it combines the hierar- chical phrase-based translation model <ref type="bibr" target="#b1">(Chiang, 2005;</ref><ref type="bibr" target="#b2">Chiang, 2007</ref>) with the BTG (Wu, 1996) reordering model ( <ref type="bibr" target="#b22">Xiong et al., 2006;</ref><ref type="bibr" target="#b25">Zens and Ney, 2006;</ref><ref type="bibr">He et al., 2010)</ref>.</p><p>To test the effectiveness of the proposed mod- els, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log prob- ability generated by the transfer model as a fea- ture into the baseline features. The baseline fea- tures include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features, and the language model feature. The tri-gram left- frontier phrase was adopted in the experiment. Then the probability generated by the transfer model with EUC constraint is added. Finally, we incorporated the tagged-flattened rules and the additional transfer model feature together. <ref type="table">Table 3</ref> shows the results of these different in- tegrated strategies. In <ref type="table">Table 3</ref>, almost all BLEU scores are improved, no matter what strategy is used. In particular, the best performance marked in bold is as high as 1.24, 0.94, and 0.82 BLEU points, respectively, over the baseline system on NIST04, CWMT08 Development, and CWMT08 Evaluation data. The strategy of "TFS+ Flat- tened Rule" is the most stable. Meanwhile the "Flattened Rule" achieves better performance than "TFS". The merits of "Flattened Rule" are two-fold: 1) In training process, the new word alignment upon modified sentence pairs can align transitional expressions to flattened CSS tags; 2) In decoding process, the CSS-based rules are more discriminating than the original rules, which is more flexible than "TFS". From the table, we cannot conclude that the EUC con- straint will certainly promote translation quality, but the transfer model performs better with the constraint on most testing sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis of Different Effects of Different N-grams</head><p>As mentioned in Section 4.3, we have noted the effectiveness of tri-gram transfer model, which means 2 n  in formula <ref type="bibr">(7)</ref>. In fact, the lengths of common transitional expressions vary from one word to several words. To evaluate the effects of different n-grams for our proposed transfer mod- el, we compared the uni-/bi-/tri-gram transfer models in SMT, and illustrate the results in Fig-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation</head><p>Left-frontier phrases (tri-gram) parallel as well as; at the same; … progressive but will also; in addition to;… causal therefore , the; for this reason; as a result; because it is; so it is;… condition as long as; only when the… hypothesis if we do; if it is; if the us; … alternative regardless of whether;… purpose it is necessary; further promote the ;… explanation that is ,; the first is; first is the;… adversative however , the ; but it is; … flowing this is a; which is an; … consequence so that the; to ensure that… only use the transfer model score as an additional feature (based on 3-gramtransitional phrase) + TFS + Flattened Rule: both are used *: value with * means that it is significantly better than the baseline with p&lt;0.05 **: value with ** means that it is significantly better than the baseline with p&lt;0.01 <ref type="table">Table 3</ref>. BLEU scores of the testing sets with different integrating strategies ure 6. In this experiment, the CSS-based transla- tion rules and the CSS-based transfer model are both incorporated. Considering time and compu- ting resources, in the rest of our paper, our analy- sis is conducted on NIST05 and NIST06. We choose 0,1, 2 n  in this experiment for that the common English transitional expressions are primarily conjunctions, most of which are less than 4 words. Results in <ref type="figure">Figure 6</ref> show that the uni-gram and tri-gram transitional expres- sions seem more fitting for our transfer model. One possible reason is that uni-gram or tri-gram conjunctions are more utilized in an English text. In a conjunction expression list proposed by <ref type="bibr" target="#b16">(Williams, 1983)</ref> which summarizes the differ- ent kinds of conjunctions based on the work of <ref type="bibr">Halliday and Hassan (1976)</ref>, we obtain the statis- tical results on uni-/bi-/tri-gram expressions, which are about 52.1%/16.9%/23.9% respective- ly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Experiments on Big Training Data</head><p>To further evaluate the effectiveness of the pro- posed models, we also conducted an experiment on a larger set of bilingual training data from the LDC corpus 7 for translation model and transfer model. The training corpus contains 2.1M sen- tence pairs with approximately 27.7M Chinese words and 31.9M English words. All the other settings were the same as the SMT experiments of sub-section 4.3. The final BLEU scores on NIST05 and NIST06 are given in <ref type="table">Table 4</ref>.</p><p>The results in <ref type="table">Table 4</ref> further verify the effec- tiveness of our proposed models. The best per- formance with bold marking scored as high as 0.83 and 0.64 BLEU points, respectively over the 7 LDC category number: LDC2000T50, DC2002E18, LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27, LDC2005T10 and LDC2005T34.</p><p>baseline system on NIST05 and NIST06 evalua- tion data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Translation Examples</head><p>Two SMT examples of Chinese-to-English are given in <ref type="table">Table 5</ref>. We observe that compared to the baseline, our approach has obvious ad- vantages on translating the implicit relations, due to generating translational expressions on target side. Moreover, with the transitional expressions, cohesion of the entire translation improves. No- tably, the transitional expressions in this work like "including, there are, the core of which" are not linguistic conjunctions. We would like to call them "generalized" conjunctions, because they tie semantic fragments together, analogously to linguistic conjunctions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Improving cohesion for complex sentences or discourse translation has attracted much attention in recent years. Such research efforts can be roughly divided into two groups: 1) research on lexical cohesion, which mainly contributes to the selection of generated target words; 2) efforts to improve the grammatical cohesion, such as dis- ambiguation of references and connectives.</p><p>In lexical cohesion work, <ref type="bibr" target="#b3">(Gong et al., 2011;</ref><ref type="bibr" target="#b21">Xiao et al., 2011;</ref><ref type="bibr">Wong and Kit, 2012</ref>) built dis- course-based models to ensure lexical cohesion or consistency. In ( <ref type="bibr">Xiong et al., 2013a</ref>), three different features were designed to capture the lexical cohesion for document-level machine translation. ( <ref type="bibr">Xiong et al., 2013b</ref>) incorporated lexical-chain-based models <ref type="bibr" target="#b11">(Morris and Hirst, 1991)</ref> into machine translation. They generated the target lexical chains based on the source <ref type="figure">Figure 6</ref>. Different translation qualities along with different n-grams for transfer model.  value with * means that it is significantly better than the baseline with p&lt;0.05 **: value with ** means that it is significantly better than the baseline with p&lt;0.01 <ref type="table">Table 4</ref>. BLEU scores on the large-scale training data.</p><p>chains via maximum entropy classifiers, and used the target chains to work on the word selec- tion. Limited work has been conducted on gram- matical cohesion. ( <ref type="bibr">Marcu et al., 2000</ref>) designed a discourse structure transfer module, but it fo- cused on converting the semantic structure rather than actual translation. ( <ref type="bibr" target="#b19">Tu et al., 2013b</ref>) provid- ed a Rhetorical-Structure-Theory-based tree-to- string translation method for complex sentences with explicit relations inspired by ( <ref type="bibr">Marcu et al., 2000</ref>), but their models worked only for explicit functional relations, and they were concerned mainly with the translation integrity of semantic span rather than cohesion. <ref type="bibr">(Meyer and PopescuBelis, 2012</ref>) used sense-labeled discourse con- nectives for machine translation from English to French. They added the labels assigned to con- nectives as an additional input to an SMT system, but their experimental results show that the im- provements under the evaluation metric of BLEU were not significant. <ref type="bibr" target="#b12">(Nagard and Koehn, 2010)</ref> addresses the problems of reference or anaphora resolution inspired by work of <ref type="bibr" target="#b9">Mitkov et al. (1995)</ref>.</p><p>To the best of our knowledge, our work is the first attempt to exploit the source functional rela- tionship to generate the target transitional ex- pressions for grammatical cohesion, and we have successfully incorporated the proposed models into an SMT system with significant improve- ment of BLEU metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we focus on capturing cohesion information to enhance the grammatical cohesion of machine translation. By taking the source CSS into consideration, we build bridges to connect the source functional relationships in CSS to tar- get transitional expressions; such a process is very similar to human translating.</p><p>Our contributions can be summarized as: 1) the new translation rules are more discriminative and sensitive to cohesive information by convert- ing the source string into a CSS-based tagged- flattened string; 2) the new additional features embedded in the log-linear model can encourage the decoder to produce transitional expressions. The experimental results show that significant improvements have been achieved on various test data, meanwhile the translations are more cohesive and smooth, which together demon- strate the effectiveness of our proposed models.</p><p>In the future, we will extend our methods to other translation models, such as the syntax- based model, to study how to further improve the performance of SMT systems. Besides, more language pairs with various linguistic structures will be taken into consideration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of Chinese-to-English translation. The English translation sentence has three transitional phrases: Despite, and, which.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Despite frequent calls for cutting pollution , and growing public anger ,</head><label></label><figDesc>&lt;Parallel @B&gt; 尽管 减轻 污染 的 呼声 不断 ， &lt;Parallel @E&gt; 公众 日渐 愤怒 ， parallel 尽管 减轻 污染 的 呼声 不断 ， 公众 日渐 愤怒 ， Despite frequent calls for cutting pollution , and growing public anger , (a) (b) Original hierarchical rules: [X] 日渐 ||| and growing [X] Modified hierarchical rules: &lt;parallel @E &gt; [X] 日渐 ||| and growing [X] (c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The pseudo code of dynamic cleaning method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5</head><label></label><figDesc>http://www.speech.sri.com/projects/srilm/ 6 The China Workshop on Machine Translation //Pseudo code for dynamic cleaning 1: Score [N+1][M]={[0]} NM  /* initialize cumulative cost score chart*/ 2: Path [M]=[[]] /*initialize tracking path*/ 3: for n = 1 N  :{ /* scan target words*/ 4: for 01 mM    :{ /*scan source U set */ 5: PrunePath(); /* prune invalid path and high-cost path*/ 6: Score[n][m]=GetScore(Score[n-1], cost(n, m)) /*compute current cumulative cost score by previ- ous score and current cost*/ 7: SaveCurrentPath(Path[m]); /*add current index to Path*/ 8: }//end m 9:}//end n 10: OptimalPath = [] arg max{ [ ][ ]} Path m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>30</head><label>30</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Source Chinese sentence: [尽管 减轻 污染 的 呼声 不断 ，]1 [ 公众</head><label>Source</label><figDesc></figDesc><table>Although reduce pollution of calls continue , 
public 

日渐 
愤怒 ，] 2 [污染 
还是 变得 
更 
糟糕 

growing angry , 
pollution still become more worse 

了 ，] 3 [越发 显出 
环保 
的 紧迫性 。] 4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>node. For the th j child in the th i node, j RP is its relative position (B, M or E) introduced in</head><label></label><figDesc></figDesc><table>i j 
ij 
i 
j 

P 
CSS 
P 
R RP 

  

ww 

where ij 
w is the transitional expression produced 

by the th 
j child of the th 
i node of the CSS. i 
R is 

the relationship type of the th 
i Section 3.1. 
The process of training this transfer model and 
smoothing is similar to the process of training a 
language model. We obtain the factored transfer 
probability as follows, 

1 

1 

00 

( | , 
) 

( | , 
) 
( | 
, , 

) (6) 

ij 
i 
j 

i 

n 
k 
j 
k 
k 

ij 

P 
R RP 

P w R RP 
P w w 
R RP 

 

 

 

 

w 

where 

00 ,... 
(7) 

n 
ij 
n 

w 
w w 
 
w 

Following (Bilmes and Kirchhoff, 2003), the 
conditional probabilities 

1 
0 

( | 
, , 
) 

i 

k 
j 
k 

P w w 
R RP 

 

in 
formula (6) are estimated in the same way as a 
factored language model, which has the ad-
vantage of easily incorporating various linguistic 
information. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>two elementary units A eu and B eu , and their projected target spans A ps and B ps bound by the word alignment, the alignment complies with EUC only if there is no overlap between A ps and B ps . Otherwise, the alignment is called non-EUC. The common EUC and non- EUC cases areby elementary units are certainly subject to the integrity assumption. eu A eu B ps A ps B</head><label></label><figDesc></figDesc><table>illustrated in Figure 4. 
EUC is the basic case for the integrity as-
sumption. For the best cases, the elementary 
units comply with EUC, and thus the semantic 

4 The aligning tool is GIZA++ with 5 iterations of Model 1, 
5 iterations of HMM, and 10 iterations of Model 4. The 
GIZA++ 
code 
can 
be 
downloaded 
from 
https://code.google.com/p/giza-pp/ 

spans combined (a) mono EUC case 

euA 
euB 

ps A 
ps B 

(b) swap EUC case 

euA 
euB 

psA 
psB 

(c) non-EUC case 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are fil- tered because they are unlikely to be the transi- tional phrases.</figDesc><table>NIST04 
NIST05 
NIST06 
CWMT08's 
Dev. 

CWMT08's 
Eval. 
Baseline 
33.42 
31.99 
33.88 
26.14 
23.88 
+Flattened Rule 
34.54** 
32.32 
34.58** 
26.79** 
24.70** 
+TFS (without EUC) 
33.93** 
32.04 
34.40* 
26.44 
24.58** 
+TFS 
33.84** 
32.63* 
34.15 
27.08** 
24.65** 
+TFS+ Flattened Rule 
34.66** 
32.54 
34.52** 
26.87** 
24.49** 

+ Flattened Rule: only use the tagged-flattened translation rules 
+ TFS: </table></figure>

			<note place="foot" n="1"> Grammatical cohesion can make relations among sentences more explicit. There are various grammatically cohesive devices (reference, substitution ellipsis and conjunction) that tie fragments together in a cohesive way.</note>

			<note place="foot" n="2"> They are parallel, consequence, progressive, alternative, causal, purpose, hypothesis, condition, adversative, explanation, and flowing relationships. 3 A semantic span can include one or more eus.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank Jiajun Zhang for provid-ing the BTG-based hierarchical decoder. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>过去三年中，已有三对染色体完成排序， 包括第二十对、第二十一对和第二十二 对 。</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>In the past three years, the sequencing of three chromosomes has been completed, including chromosomes 20 , 21 , and 22 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline</head><p>In the past three years , now has three terms of the completion of the chromosomes , 20 , 21 and 22 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improved</head><p>In the past three years , there are three chromosomes to accomplish , including 20 , 21 and 22 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>上述主张构成了一个中国原则的基本涵义，核心是维护中国的主权和领土完整。</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>The above-mentioned propositions constitute the basic connotation of this one-china principle with safeguarding china ' s sovereignty and territorial integrity as its core .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline</head><p>The above-mentioned propositions constitute the basic meaning of the one-china principle is the core of safeguard china ' s sovereignty and territorial integrity .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Improved</head><p>The above-mentioned propositions constitute the basic meaning of the one-china principle , the core of which is to safeguard china ' s sovereignty and territorial integrity. <ref type="table">Table 5</ref>. Examples of baseline and the improved system outputs.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Factored language models and generalized parallel backoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><forename type="middle">A</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLT-NAACL</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="4" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hierarchical phrase-based model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cache-based document-level statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxian</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="909" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysing lexical consistency in translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liane</forename><surname>Guillou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Discourse in Machine Translation</title>
		<meeting>the Workshop on Discourse in Machine Translation<address><addrLine>Sofia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Cohesion in English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Halliday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hasan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<publisher>Longman</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum Entropy Based Phrase Reordering for Hierarchical Phrase-based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conf. on Empirical Methods for Natural Language Processing (EMNLP)</title>
		<meeting>of the Conf. on Empirical Methods for Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="555" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A coherence model based on syntactic patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="1157" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rhetorical structure theory: Toward a functional theory of text organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Anaphora resolution in Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Kwon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Sharp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation</title>
		<meeting>the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using sense-labeled discourse connectives for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Popescu-Belis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation (ESIRMT) and Hybrid Approaches to Machine Translation (HyTra)</title>
		<meeting>the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation (ESIRMT) and Hybrid Approaches to Machine Translation (HyTra)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="129" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lexical cohesion computed by thesaural relations as an indicator of the structure of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="48" />
			<date type="published" when="1991-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Aiding pronoun translation with co-reference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Nagard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR</title>
		<meeting>the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="252" to="261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative training and maximum entropy models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Penn Discourse Treebank 2.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Dinesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Miltsakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio</forename><surname>Robaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC</title>
		<meeting>the 6th International Conference on Language Resources and Evaluation (LREC</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Teaching the Recognition of Cohesive Ties in Reading a Foreign</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename><surname>Ray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="35" to="52" />
		</imprint>
	</monogr>
	<note>Reading in a foreign language</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sentence level discourse parsing using syntactic and lexical information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Conference of the North American Chapter</title>
		<meeting>the 2003 Conference of the North American Chapter</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="149" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Novel Translation Framework Based on Rhetorical Structure Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="370" to="374" />
		</imprint>
	</monogr>
	<note>short paper</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatically Parsing Chinese Discourse Based on Maximum Entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2nd Conference on Natural Language Processing &amp; Chinese Computing</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Smaller alignment models for better translations: unsupervised word alignment with the l 0-norm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="311" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Document-level consistency verification in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 MT summit XIII</title>
		<meeting>the 2011 MT summit XIII<address><addrLine>Xiamen, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09" />
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maximum entropy based phrase reordering model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 44th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="521" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling lexical cohesion for document-level machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI-13)</title>
		<meeting>the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI-13)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
		</imprint>
	</monogr>
	<note>2013 (a)</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<biblScope unit="page" from="1563" to="1573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Discriminative reordering models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of theWorkshop on Statistical Machine Translation</title>
		<meeting>theWorkshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Annotation Scheme for Chinese Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Chinese Information Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
