<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Annotating and Predicting Non-Restrictive Noun Phrase Modifications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-12, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
							<email>gabriel.satanovsky@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
							<email>dagan@cs.biu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Bar-Ilan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Annotating and Predicting Non-Restrictive Noun Phrase Modifications</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
						<meeting>the 54th Annual Meeting of the Association for Computational Linguistics <address><addrLine>Berlin, Germany</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1256" to="1265"/>
							<date type="published">August 7-12, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The distinction between restrictive and non-restrictive modification in noun phrases is a well studied subject in linguistics. Automatically identifying non-restrictive modifiers can provide NLP applications with shorter, more salient arguments, which were found beneficial by several recent works. While previous work showed that restrictiveness can be annotated with high agreement, no large scale corpus was created, hindering the development of suitable classification algorithms. In this work we devise a novel crowdsourcing annotation methodology, and an accompanying large scale corpus. Then, we present a robust automated system which identifies non-restrictive modifiers, notably improving over prior methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Linguistic literature provides a large body of re- search distinguishing between two types of mod- ifiers within noun phrases: (1) Restrictive modi- fiers, which constitute an integral part of the entity referenced by the NP, e.g., the underlined modifier in "She wore the necklace that her mother gave her", versus (2) Non-restrictive modifiers, which provide an additional or parenthetical information on an already definite entity, e.g., "The speaker thanked president Obama who just came into the room" ( <ref type="bibr" target="#b13">Huddleston et al., 2002;</ref><ref type="bibr" target="#b6">Fabb, 1990;</ref><ref type="bibr" target="#b24">Umbach, 2006</ref>).</p><p>The distinction between the two types is seman- tic in nature and relies heavily on the context of the NP. Evidently, many syntactic constructions can appear in both restrictive and non-restrictive uses. While the previous examples were of rela- tive clauses, <ref type="figure" target="#fig_0">Figure 1</ref> demonstrates this distinction in various other syntactic constructions.</p><p>Identifying and removing non-restrictive mod- ifiers yields shorter NP arguments, which proved beneficial in many NLP tasks. In the context of abstractive summarization ( <ref type="bibr" target="#b8">Ganesan et al., 2010)</ref> or sentence compression ( <ref type="bibr" target="#b16">Knight and Marcu, 2002</ref>), non-restrictive modifiers can be removed to shorten sentences, while restrictive modification should be preserved.</p><p>Further, recent work in information extraction showed that shorter arguments can be beneficial for downstream tasks. <ref type="bibr" target="#b0">Angeli et al. (2015)</ref> built an Open-IE system which focuses on shorter ar- gument spans, and demonstrated its usefulness in a state-of-the-art Knowledge Base Population sys- tem. <ref type="bibr" target="#b23">Stanovsky et al. (2015)</ref> compared the per- formance of several off-the-shelf analyzers in dif- ferent semantic tasks. Most relevant to this work is the comparison between Open-IE and Seman- tic Role Labeling ( <ref type="bibr" target="#b3">Carreras and M` arquez, 2005</ref>). Specifically, they suggest that SRL's longer argu- ments introduce noise which hurts performance for downstream tasks.</p><p>Finally, in question answering, omitting non- restrictive modification can assist in providing more concise answers, or in matching between multiple answer occurrences.</p><p>Despite these benefits, there is currently no con- sistent large scale annotation of restrictiveness, which hinders the development of automatic tools for its classification. In prior art in this field, <ref type="bibr" target="#b5">Dornescu et al. (2014)</ref> used trained annotators to mark restrictiveness in a large corpus. Although they reached good agreement levels in restrictiveness annotation, their corpus suffered from inconsisten- cies, since it conflated restrictiveness annotation with inconsistent modifier span annotation.</p><p>The contributions of this work are twofold. Pri- marily, we propose a novel crowdsroucing anno-tation methodology which decouples the binary (restrictive / non-restrictive) distinction from the modifier span annotation (Section 3). Following this methodology, in Section 4 we present a large scale annotated corpus, which will allow further research into the automatic identification of non- restrictive modification.</p><p>Additionally, we developed a strong automatic classifier, which learns from our new corpus (Sec- tion 5). This classifier uses new linguistically mo- tivated features which are robust enough to per- form well over automatically predicted parse trees.</p><p>The corpus and the automatic classifier are both made publicly available. <ref type="bibr">1</ref> While there is still much room for improve- ment, especially in some of the harder, more context-dependent, cases (most notably, preposi- tional and adjectival modifiers), our system pro- vides an applicable means for identifying non- restrictive modification in a realistic NLP setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section we cover relevant literature from several domains. In Section 2.1 we discuss the es- tablished linguistic distinction between restrictive and non-restrictive modification. Following, in Section 2.2 we discuss previous NLP work on an- notating and identifying this distinction. Finally, in Section 2.3 we briefly describe the recent QA- SRL annotation paradigm ( <ref type="bibr" target="#b10">He et al., 2015)</ref>, which we utilize in Section 3 as part of our annotation scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Non-Restrictive Modification</head><p>Throughout the paper we follow <ref type="bibr">Huddleston et al.'s (2002)</ref> well-known distinction between two types of NP modifiers: (1) Restrictive modifiers, for which the content of the modifier is an integral part of the meaning of the containing NP, and, in contrast, (2) Non-restrictive modifiers, that present a separate, parenthetical unit of information about the NP.</p><p>While some syntactic modifiers (such as deter- miners or genitives) are always restrictive, others are known to appear in both restrictive as well as non-restrictive uses, depending on semantics and context <ref type="bibr" target="#b13">(Huddleston et al., 2002;</ref><ref type="bibr" target="#b6">Fabb, 1990;</ref><ref type="bibr" target="#b24">Umbach, 2006</ref>). Among these are relative clauses, ad- jectival, prepositional, non-finite, and verbal mod-(RC1) The necklace that her mother gave her + is in the safe. (RC2) The governor disagreed with the U.S am- bassador to China who seemed nervous − . (NF1) People living near the site + will have to be evacuated. (NF2) sheriff Arthur Lester, standing against the wall − , looked tired. (PP1) The kid from New York + won the lottery. (PP2) The assassination of Franz Ferdinand from Austria − started WWI. (AD1) The good + boys won. (AD2) The water level rose a good − 12 inches. ifiers. See <ref type="figure" target="#fig_0">Figure 1</ref> for examples of different syn- tactic constructions appearing in both restrictive as well as non-restrictive contexts.</p><p>For example, for relative clause, Huddleston et al. <ref type="bibr">[p. 1058]</ref> identifies both restrictive as well as non-restrictive uses (for which they use the terms integrated and supplementary, respec- tively). In the sentence marked (RC1), the high- lighted relative clause is restrictive, distinguishing the necklace being referred to from other neck- laces, while in sentence (RC2), the relative clause does not pick an entity from a larger set, but in- stead presents separate information about an al- ready specified definite entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Non-Restrictive Modification in NLP</head><p>Syntactic and semantic annotations generally avoid the distinction between restrictive and non- restrictive modification (referred here as "restric- tiveness" annotation).</p><p>The syntactic annotation of the Penn TreeBank ( <ref type="bibr" target="#b17">Marcus et al., 1993)</ref> and its common conversion to dependency trees (e.g., (de Marneffe and Man- ning, 2008)) do not differentiate the cases dis- cussed above, providing the same syntactic struc- ture for the semantically different instances. See <ref type="figure" target="#fig_1">Figure 2</ref> for an example.</p><p>Furthermore, prominent semantic annotations, such as PropBank ( <ref type="bibr" target="#b22">Palmer et al., 2005</ref>), AMR ( <ref type="bibr" target="#b2">Banarescu et al., 2013</ref>), CCG <ref type="bibr" target="#b11">(Hockenmaier and Steedman, 2007)</ref>, or FrameNet ( <ref type="bibr" target="#b1">Baker et al., 1998</ref>), also avoid this distinction. For exam- ple, PropBank does not differentiate between such modifiers, treating both types of modification as an integral part of an argument NP.</p><p>Two recent works have focused on automat- ically identifying non-restrictive modifications. <ref type="bibr" target="#b12">Honnibal et al. (2010)</ref> added simple automated restrictiveness annotations to NP-modifiers in the CCGbank ( <ref type="bibr" target="#b11">Hockenmaier and Steedman, 2007)</ref>. Following a writing style and grammar rule, a modifier was judged as non-restrictive if and only if it was preceded by a comma. <ref type="bibr">2</ref> This annotation was not intrinsically evaluated, as it was carried as part of an extrinsic evaluation of a statistical parser.</p><p>Having similar goals to ours, <ref type="bibr" target="#b5">Dornescu et al. (2014)</ref> sets the prior art at annotating and predict- ing non-restrictive modification. In the annotation phase, each of their trained annotators was asked to (1) Mark spans of words in the sentence as forming an NP modifier, and (2) Mark each span they annotated in (1) as either restrictive or non- restrictive, and specify its type from a predefined list (e.g., relative clause, adjectival modifier, etc.).</p><p>Their inter-annotator agreement on the first task (modifier span) was low, reaching pairwise F1 score of only 54.9%, possibly due to problems in the annotation procedure, as acknowledged by the authors. The second part of the annotation achieved better agreement levels, reaching kappa of 0.78 (substantial agreement) for type annotation and 0.51 (moderate agreement) for restrictiveness annotation. <ref type="bibr">3</ref> Following the creation of the annotated dataset, they developed rule based and machine learning classifiers. All of their classifiers performed only at about 47% F1, at least partly due to the incon- sistencies in span annotation discussed above.</p><p>To conclude this survey, although an effort was made by <ref type="bibr">Dorenscu et al. (2014)</ref>, there is currently no available consistent corpus annotated with non- restrictive modifiers. <ref type="bibr">2</ref> Notice that this is indeed the case in some of the non- restrictive examples in <ref type="figure" target="#fig_0">Figure 1</ref>. <ref type="bibr">3</ref> Note that the agreement for the first task is reported in F1 while the second task is reported in Cohen's kappa. the boy who entered the room </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">QA-SRL</head><p>Traditional Semantic Role Labeling (SRL) <ref type="bibr" target="#b3">(Carreras and M` arquez, 2005</ref>) is typically perceived as answering argument role questions, such as who, what, to whom, when, or where, regarding a tar- get predicate. For instance, PropBank's ARG0 for the predicate say answers the question "who said something?". QA-SRL ( <ref type="bibr" target="#b10">He et al., 2015</ref>) suggests that answer- ing explicit role questions is an intuitive means to solicit predicate-argument structures from non- expert annotators. Annotators are presented with a sentence in which a target predicate 4 was marked, and are requested to annotate argument role ques- tions, phrased using a restricted grammar, and cor- responding answers.</p><p>For example, given the sentence "President Obama who flew to Russia called the vice presi- dent" and the target predicate called, an annotator can intuitively provide the following QA pairs: (1) Who called? President Obama and (2) Whom did someone call? the vice president.</p><p>In order to assess the validity of their annotation scheme, He et al. annotated a large sample of the PropBank corpus (1241 sentences) with QA-SRL, and showed high agreement with PropBank over this sample. In the following sections we make use of these explicit role questions for annotating non-restrictive modifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Annotation Methodology</head><p>As mentioned in the Introduction, the first goal of this work is to assemble a large and consis- tent corpus, annotated with non-restrictive modifi- cations. In this section, we present a crowdsourc- ing methodology which allows us to generate such corpus in a cost-effective manner (Section 3.2). As a preliminary step, we conducted a smaller scale expert annotation (Section 3.1), which will serve as a gold standard with which to test the crowsd- sourced annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Expert Annotation</head><p>Two researchers, with linguistics and NLP educa- tion, were presented with a sample of 219 mod- ifiers of NPs in 100 sentences, <ref type="bibr">5</ref> and were asked to annotate each modifier as either restrictive or non-restrictive, according to the linguistic defini- tion presented in Section 2. Prior to annotating the expert dataset, the annotators discussed the pro- cess and resolved conflicts on a development set of 20 modifiers.</p><p>The annotators agreement was found to be high, reaching agreement on 93.5% of the instances, and κ of 84.2% . An analysis of the few disagreements found that the deviations between the annotators stem from semantic ambiguities, where two legit- imate readings of the sentence led to disagreeing annotations. For example, in "sympathetic fans have sent Ms. Shere copies of her recipes clipped from magazines over the years", one annotator read the underlined modifier clause as restrictive, identifying particular recipes, while the second an- notator read the modifier as non-restrictive, adding supplementary information on the sent recipes.</p><p>Finally, we compose the expert annotation dataset from the 207 modifiers agreed upon by both annotators. In the next section we use this dataset to evaluate the quality of our crowd- sourced annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Crowdsourcing Annotation Process</head><p>In our scheme, each annotation instance assigns a binary label (restrictive or non-restrictive) to a 4- tuple (s, v, p, m) -where m is a modifier of the noun phrase p, which is an argument of a verbal predicate v, in a sentence s. We incorporate v in our scheme in order to provide non-trained anno- tators with an argument role question (discussed in 2.3), as elaborated below. <ref type="bibr">6</ref> Consider, for example, the sentence s -"the speaker thanked [President Obama who just en- tered the room]". We want to annotate the re- strictiveness value of the relative clause m (under- lined), which modifies the matrix noun phrase p (bracketed), which is in turn an argument of a gov- erning predicate v (in bold).</p><p>Our annotation procedure does not require the annotator to be familiar with the formal linguistic definition of restrictiveness. Instead, we use bi- nary question-answering (true / false questions) as an intuitive formulation of non-restrictive modifi- cation. We present annotators with the argument role question pertaining to the argument NP, and ask whether this NP without the modifier gives the same answer to the argument role question as the original NP did.</p><p>In our example, an annotator is presented with the argument role question "whom did someone thank?" (which is answered by p), and is asked to decide whether the reduced NP, "President Obama", provides the same answer to the ques- tion as the full NP does. If the answer is positive (as in this case), we consider the modifier to be non-restrictive, otherwise we consider it to be re- strictive.</p><p>As an example for the restrictive case, consider "she wore [the necklace that her mother gave her]", and the respective argument role-question "what did someone wear?". In this case, as op- posed to the previous example, the reduced NP ("the necklace") does not refer to the same entity as the original NP, since we lose the specific iden- tity of the necklace which was worn.</p><p>The intuition for this process arises from the linguistic definition for modifier restrictiveness. Namely, a restrictive modifier is defined as an in- tegral part of the NP, and a non-restrictive modifier as providing supplementary or additional informa- tion about it. Therefore, in the restrictive case, omitting the modifier would necessarily change the meaning of the answer, while in the non- restrictive case, omitting it would not change the entity referenced by the full NP, and would there- fore provide the same answer to the argument role question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Corpus</head><p>In this section we describe the creation of a consis- tent human-annotated restrictiveness corpus, using the annotation process described in the previous section. We show this corpus to be of high quality by comparing it with the independent expert anno- tation. In Section 5 we use this corpus to train and test several automatic classifiers.   <ref type="table">Table 1</ref>: Corpus statistics by modifier types, which were identified by part of speech (pos) and depen- dency label (rel) (Section 4.1). The number of instances (#) and non-restrictiveness percentage refer to the full crowdsourced annotation. Agreement (Cohen's κ and percent of matching instances) is reported for the expert-annotated data <ref type="bibr">(Section 4.2)</ref>, between the expert and crowdsourced annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Collection</head><p>We use the dataset which He et al. <ref type="formula">(2015)</ref>   <ref type="bibr" target="#b18">Meyers et al., 2004</ref>), and converted into depen- dency grammar by <ref type="bibr" target="#b14">(Johansson and Nugues, 2008)</ref>.</p><p>As mentioned in Section 3.2, each of our anno- tation instances is composed of a sentence s, a ver- bal predicate v, a noun phrase p, and a modifier m. We extract each such possible tuple from the set of sentences in the following automatic manner:</p><p>1. Identify a verb v in the gold dependency tree.</p><p>2. Follow its outgoing dependency arcs to a noun phrase argument p (a dependent of v with a nominal part of speech).</p><p>3. Find m, a modifying clause of p which might be non-restrictive, according to the rules de- scribed in <ref type="table">Table 1</ref>, under the "Identified By" column. This filters out modifiers which are always restrictive, such as determiners or genitives, following <ref type="bibr" target="#b13">(Huddleston et al., 2002</ref>), as discussed in Section 2. Notice that this automatic modifier detection decouples the span annotation from the restrictiveness annotation, which was a source for inconsis- tencies in Dornescu et al's annotation (Sec- tion 2.2).</p><p>This automatic process yields a dataset of 2191 modifiers of 1930 NPs in 1241 sentences. We note that our collection process ensures that the cor- pus correlates with the syntactic dependency an- notation of the CoNLL 2009 shared task, and can therefore be seen as an augmentation of its modi- fier labels to include restrictiveness annotations.</p><p>In order to find the corresponding argument role question, we follow the process carried by He et al.; An argument NP is matched to an annotated Question-Answer pair if the NP head is within the annotated answer span. Following this matching process yields a match for 1840 of the NPs.</p><p>For the remaining 90 NPs we manually com- pose an argument role question by looking at the governing predicate and its argument NP. For ex- ample, given the sentence "[The son of an im- migrant stonemason of Slovenian descent] was raised in a small borough outside Ebensburg", the predicate raised and the bracketed NP argument, we produce the argument role question "Who was raised?".</p><p>The corpus category distribution is depicted in <ref type="table">Table 1</ref>, under column labeled "#". In later sec- tions we report agreement and performance across these categories to produce finer grained analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Crowdsourcing Annotation</head><p>We use Amazon Mechanical Turk 7 to annotate the 2191 modifiers for restrictiveness, according to the process defined in Section 3.2. Each modifier was given to 5 annotators, and the final tag was as- signed by majority vote. We used the development set to refine the guidelines, task presentation, and the number of annotators.</p><p>Each annotator was paid 5c for the annotation of an NP, which in average provided 1.16 modifiers. This sets the average price for obtaining a single modifier annotation at 5 · 5</p><p>1.16 = 21.5c. The agreement with the 217 NP modifiers anno- tated by the experts (Section 3.1) and percentage of positive (non-restrictive) examples per category can be found in <ref type="table">Table 1</ref>, in the columns labeled "agreement". The labels are generally balanced, with 51.12% non-restrictive modifiers in the entire dataset (varying between 36.22% for prepositional modifiers and 79.07% for relative clauses).</p><p>Overall, the crowdsourced annotation reached good agreement levels with our expert annota- tion, achieving 73.79 κ score (substantial agree- ment). The lowest agreement levels were found on prepositional and appositive modifiers (61.65% and 60.29%). 8 Indeed, as discussed in Section 2, these are often subtle decisions which rely heavily on context. For example, the following instances were disagreed upon between our ex- pert annotation and the crowdsourced annotation: In "[Charles LaBella , the assistant U.S. attor- ney prosecuting the Marcos case], did n't return phone calls seeking comment" (an appositive ex- ample), the experts annotated the underlined mod- ifier as non-restrictive, while the crowdsource an- notation marked it as restrictive. Inversely, in "The amendment prompted [an ironic protest] from Mr. Thurmond", the experts annotated the adjecti- val modifier as restrictive, while the crowdsource annotation tagged it as non-restrictive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Predicting Non-Restrictive Modification</head><p>In this section we present an automatic system which: (1) Identifies NP modifiers in a depen- dency parser's output (as shown in <ref type="table">Table 1</ref>, col- umn "Identified By") and (2) Uses a CRF model to classify each modifier as either restrictive or non- restrictive, based on the features listed in <ref type="table" target="#tab_3">Table 2</ref>, <ref type="bibr">8</ref> While linguistic literature generally regards appositives as non-restrictive, some of the appositions marked in the de- pendency conversion are in fact misclassified coordinations, which explains why some of them were marked as restrictive. and elaborated below. <ref type="bibr">9</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baselines</head><p>We begin by replicating the algorithms in the two prior works discussed in Section 2.2. This allows us to test their performance consistently against our new human annotated dataset.</p><p>Replicating ( <ref type="bibr" target="#b12">Honnibal et al., 2010</ref>) They anno- tated a modifier as restrictive if and only if it was preceded with a comma. We re-implement this baseline and classify all of the modifiers in the test set according to this simple property.</p><p>Replicating ( <ref type="bibr" target="#b5">Dornescu et al., 2014</ref>) Their best performing ML-based algorithm 10 uses the super- vised CRFsuite classifier <ref type="bibr" target="#b21">(Okazaki, 2007)</ref> over "standard features used in chunking, such as word form, lemma and part of speech tags". Replicat- ing their baseline, we extract the list of features detailed in <ref type="table" target="#tab_3">Table 2</ref> (in the row labeled "chunking features").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Our Classifier</head><p>In addition to Dornescu et al.'s generic chunking framework, we also extract features which were identified in the linguistic literature as indicative for non-restrictive modifications. These features are then used in the CRFsuite classifier (the same CRF classifier used by <ref type="bibr">Donescu et al.)</ref> to make the binary decision. The following paragraphs elabo- rate on the motivation for each of the features.</p><p>Enclosing commas We extend Honnibal's et al.'s classification method as a binary feature which marks whether the clause is both preceded and terminated with a comma. This follows from a well-known writing style and grammar rule which indicates that non-restrictive clausal modi- fiers should be enclosed with a comma.</p><p>Governing relative In the linguistic literature, it was posited that the word introducing a clausal modifier (termed relative) is an indication for the restrictiveness of the subordinate clause. For ex- ample, <ref type="bibr" target="#b13">Huddleston. et al. (2002)</ref>  <ref type="bibr">[p. 1059]</ref> analyzes the word "that" as generally introduc- ing a restrictive modifier, while a wh-pronoun is more likely to introduce non-restrictive modifica- tion. We therefore extract features of the word which governs the relative, such as the surface form, its lemma, POS tag, and more. The full list is shown under "Governing relative" in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>Named entities As illustrated throughout the paper, modifiers of named entities tend to be non- restrictive. We run the Stanford Named Entity Recognizer (NER) ( <ref type="bibr" target="#b7">Finkel et al., 2005</ref>) and intro- duce a feature indicating the type of named entity (PERSON, ORG or LOC), where applicable.</p><p>Lexical word embeddings We include the pre- trained word embeddings of the modifier's head word, calculated by <ref type="bibr" target="#b19">(Mikolov et al., 2013</ref>). These distributional features help the classifier associate between similar words (for example, if "good" is non-restrictive in some contexts, it is likely that "fine" is also non-restrictive within similar con- texts).</p><p>Modifier type We add the automatically identi- fied modifier type as a feature, to associate certain features as indicative for certain types of modifiers (e.g., enclosing commas might be good indicators for relative clause, while word embeddings can be specifically helpful for adjectival modifiers).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>We use the QA-SRL test section (containing 412 NP modifiers) to evaluate each of the systems de- scribed in Section 5 on gold and predicted trees, both provided in the CoNLL 2009 dataset (the pre- dicted dependency relations were obtained using MaltParser ( <ref type="bibr" target="#b20">Nivre et al., 2007)</ref>). The gold setting allows us to test the performance of the systems without accumulating parser errors. In addition, it allows us to partition and analyze our dataset ac- cording to the gold modifier type. The predicted setting, on the other hand, allows us to evaluate our classifier in a real-world application scenario, given automatic parsing output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Gold Trees</head><p>The results for each of the systems across our cate- gories on the gold trees are shown in <ref type="table" target="#tab_5">Table 3</ref>. Note that we regard non-restrictive modification as pos- itive examples, and restrictive modification as neg- ative examples. This is in line with the applicative goal of reducing argument span by removing non- restrictive modifiers, discussed in the Introduction. Switching the labels does not significantly change  the numbers, since the corpus is relatively well balanced between the two labels (as can be seen in <ref type="table">Table 1</ref>). Following are several observations based on an error analysis of these results.</p><p>Prepositional and adjectival modifiers are harder to predict All systems had more diffi- culties in classifying both of these categories. This reiterates the relatively lower agreement for these categories between the crowdsource and expert annotation, discussed in Section 4.2.</p><p>For clausal modifiers, preceding commas are good in precision but poor for recall As can be seen in Honnibal et al.'s columns, a preceding comma is a good indication for a non-restrictive clausal modifier (all categories excluding adjecti- val or verbal modifiers), but classifying solely by its existence misses many of the non-restrictive in- stances.   <ref type="table">Table 4</ref>: Feature ablation tests on gold trees. Each row specifies a different feature set -"All" speci- fies the entire feature set from <ref type="table" target="#tab_3">Table 2</ref>, while each subsequent line removes one type of features.</p><p>( <ref type="bibr" target="#b5">Dornescu et al., 2014</ref>) performs better on our dataset Their method achieves much better re- sults on our dataset (compare 64% overall F1 on our dataset with their reported 45.29% F1 on their dataset). This speaks both for their method as a valid signal for restrictiveness annotation, as well as for the improved consistency of our dataset.</p><p>Our system improves recall Overall, our sys- tem significantly outperforms both baselines by more than 8% gain in F1 score. Specifically, the numbers show clearly that we improve recall in the frequent categories of prepositional and adjectival modifiers. Furthermore, the results of an ablation test on our features (shown in <ref type="table">Table 4)</ref> show that chunking and governing relative features provide the highest individual impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Predicted Trees</head><p>To test our classifier in a realistic setting we evalu- ate its performance on predicted dependency trees.</p><p>To  trained on the gold train set of the same corpus. For evaluation, we use the gold labels and com- pute (1) precision -the percent of predicted non- restrictive modifiers which match a gold non- restrictive modifier, and (2) recall -the percent of gold non-restrictive modifiers which match a pre- dicted non-restrictive modifier. Note that this met- ric is strict, conflating both parser errors with our classifier's errors. The results are shown in <ref type="table" target="#tab_7">Table  5</ref>.</p><p>The first line in the table measures the perfor- mance of the modifier extractor module on the pre- dicted trees. A predicted modifier is considered correct if it agrees with a gold modifier on both its syntactic head as well as its span. The modifier extractor module is shared across all classifiers, as discussed in Section 5, and its performance on the predicted trees imposes an upper bound on all the classifiers.</p><p>Both our and Dornescu's classifiers drop 5-6 points in F1, keeping the differences observed on the gold trees, while Honnibal et al.'s simple comma-based classifier is less sensitive to parser errors, dropping only one point in F1.</p><p>This small drop stems from our classifiers largely relying only on the modifier head and its span for feature computation, generally ignoring parsing errors within the modifier subtree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We presented an end-to-end framework for restric- tiveness annotation, including a novel QA-SRL based crowdsourcing methodology and a first con- sistent human-annotated corpus. Furthermore, we presented a linguistically motivated classifier, sur- passing the previous baseline by 8% gain in F1.</p><p>Future work can use our annotated corpus to de- velop classifiers that deal better with prepositional and adjectival modifiers, which require deeper se- mantic analysis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Restrictive (marked in red and a plus sign) and non-restrictive (marked in blue and a minus sign) examples in different syntactic constructions, see elaboration in Section 2. Examples index: RC-Relative clause, NF-Non-finite clauses (Huddleston et al. [p. 1265]), PP-Prepositional modifiers, AD-Adjectival modifiers (Huddleston et al. [p. 528]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Restrictive (top) and non-restrictive (bottom) NP modifications receive the same representation in dependency trees. See Section 2.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Modifier</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Type</head><label></label><figDesc></figDesc><table>Identified By 
# 
Non-Restrictive 
Agreement 

κ 
% 

Adjectival 
pos = JJ 
684 
41.36% 74.70 87.36 
Prepositional 
pos = IN / TMP / LOC 
693 
36.22% 61.65 85.10 
Appositive 
rel = APPO / PRN 
342 
73.68% 60.29 80.00 
Non-Finite 
rel = TO 
279 
68.82% 71.04 86.48 
Verbal 
pos = VB and not relative clause 
150 
69.33% 
100 
100 
Relative clause pos = VB and child pos = WP 
43 
79.07% 
100 
100 
Total 
-
2191 
51.12% 73.79 87.00 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Features used for classification in each 
of the systems as described in Section 5. head -
head of the modifier in the dependency tree. par-
ent -parent of head in the dependency tree. pobj 
-object of the preposition, in case of prepositional 
head. feats[i] refers to extracting the following 
features from the word i: POS tag, lemma, is title, 
is all lower case, is all upper case, is beginning / 
end of sentence. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Test set performance of the 3 different systems described in Sections 5 and 6 on gold trees from 
the CoNLL 2009 dataset, across the different categories defined in Section 4. 

Features 
P 
R 
F1 
All 
.73 .68 .72 

Baseline 
-comma 
.72 .68 .70 
-chunking 
.72 .66 .69 

New 
-governing relative .74 .61 .67 
-prepositions 
.73 .67 .70 
-word embeddings .72 .69 .71 
-NER 
.71 .68 .70 
-mod type 
.74 .66 .70 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Restrictiveness results (bottom three 
lines) on predicted trees. The top line (Candidate 
Extraction) measures the percent of correct modi-
fiers identified in the predicted trees (shared across 
all of the classifiers). See Section 6.2. 

</table></figure>

			<note place="foot" n="1"> http://www.cs.biu.ac.il/ ˜ nlp/ resources/downloads</note>

			<note place="foot" n="4"> Currently consisting of automatically annotated verbs.</note>

			<note place="foot" n="5"> These were taken at random from the development partition of the corpus described in Section 4. 6 Our annotation currently covers the most common case of NPs which serve as arguments of verbal predicates.</note>

			<note place="foot" n="7"> https://www.mturk.com</note>

			<note place="foot" n="9"> We use our new crowdsourced corpus to train our model as well as the baseline model. 10 They also implement a rule-based method, named DAPR, which, when combined with the described ML approach surpasses their ML algorithm by ∼1.5% increase in F1. We could not find a publicly available implementation of this method.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Michael Elhadad and Yoav Goldberg for fruitful discussions, and the anony-mous reviewers for their helpful comments.</p><p>This work was supported in part by grants from the MAGNET program of the Israeli Office of the Chief Scientist (OCS), the Israel Science Founda-tion grant 880/12, and the German Research Foun-dation through the German-Israeli Project Cooper-ation (DIP, grant DA 1600/1-1).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leveraging linguistic structure for open domain information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><forename type="middle">Johnson</forename><surname>Premkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The berkeley framenet project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Collin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John B</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2005 shared task: Semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lluís</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CONLL</title>
		<meeting>CONLL</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The stanford typed dependencies representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Relative clause extraction for syntactic simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iustin</forename><surname>Dornescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The difference between english restrictive and nonrestrictive relative clauses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Fabb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="57" to="77" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavita</forename><surname>Ganesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on computational linguistics</title>
		<meeting>the 23rd international conference on computational linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="340" to="348" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Stěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning: Shared Task</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Question-answer driven semantic role labeling: Using natural language to annotate natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ccgbank: A corpus of ccg derivations and dependency structures extracted from the penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rebanking ccgbank for improved np interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>James R Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="207" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The cambridge grammar of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Huddleston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">K</forename><surname>Pullum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Language. Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dependency-based syntactic-semantic analysis with propbank and nombank</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Conference on Computational Natural Language Learning</title>
		<meeting>the Twelfth Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="183" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Summarization beyond sentence extraction: A probabilistic approach to sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="107" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Mitchell P Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The nombank project: An interim report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Macleod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Szekely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Zielinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL 2004 workshop: Frontiers in corpus annotation</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Maltparser: A language-independent system for data-driven dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atanas</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gülsen</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetoslav</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Crfsuite: a fast implementation of conditional random fields (crfs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoaki</forename><surname>Okazaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Open IE as an intermediate structure for semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Non-restrictive modification and backgrounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><surname>Umbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Symposium on Logic and Language</title>
		<meeting>the Ninth Symposium on Logic and Language</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
