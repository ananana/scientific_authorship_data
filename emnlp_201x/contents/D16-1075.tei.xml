<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">News Stream Summarization using Burst Information Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
							<email>getao@pku.edu.cn, lecu@microsoft.com, chbb@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
							<email>lisujian@pku.edu.cn, mingzhou@microsoft.com, szf@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ministry of Education</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<postCode>100871</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">News Stream Summarization using Burst Information Networks</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="784" to="794"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper studies summarizing key information from news streams. We propose simple yet effective models to solve the problem based on a novel and promising representation of text streams-Burst Information Networks (BINets). A BINet can be aware of redundant information, allows global analysis of a text stream, and can be efficiently built and dynamically updated, which perfectly fits the demands of text stream summarization. Extensive experiments show that the BINet-based approaches are not only efficient and can be used in a real-time online summarization setting , but also can generate high-quality summaries , outperforming the state-of-the-art approach .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text stream summarization aims to summarize key information from a text stream containing huge numbers of documents, which is an important and useful task that can be used for many real-world ap- plications. For example, a news portal website ed- itor needs to summarize news streams in the past day for generating a list of headline news; an edi- tor of Sports Weekly may want a summary of the past week news stream for editing the magazine; and geologists and meteorologists will benefit from a summary of disaster events from the past year news stream (as shown in <ref type="table" target="#tab_0">Table 1</ref>) for their study.</p><p>In contrast to traditional text summarization tasks (e.g., single and multi-document summarization) * This work was done when the first author was visiting Microsoft Research Asia that have been extensively studied for decades, the task of stream summarization is a younger research problem which attempts to solve a summarization problem in the big-data setting. For a text stream with millions of documents involving various topics and events, traditional single-and multi-document summarization approaches cannot address the infor- mation overload challenge. For example, a single- document summarization model will generate 1 mil- lion document summaries for a text stream with 1 million documents, which are still overwhelming for a person to learn the key information in the stream.</p><p>In such cases, one needs to a summary of the whole stream instead of summaries of each document. <ref type="figure" target="#fig_0">Figure 1</ref> shows the paradigm of stream sum- marization. Compared with single-and multi- document summarization, stream summarization has three differences: (1) it summarizes a text stream containing millions of documents involving a variety of topics and events while single-and 784 2009 disaster summary 2010 disaster summary • ...</p><p>• ...</p><p>• Sep 2, 2009: About 60 people die when a 7.1- magnitude earthquake hit the island of Java.</p><p>• Jan 12, 2010: A 7.0-magnitude earthquake hit Haiti, killing about 200,000 people.</p><p>• Sep 9, 2009: More than 30 people are killed when fast moving floods caused by heavy rain sweep through Istanbul.</p><p>• <ref type="bibr">Feb 27, 2010</ref>: An 8.8-magnitude earthquake rocked Chile, killing at least 700 people dead and affecting more than 1.5 million people.</p><p>• Sep 30, 2009: A 7.6-magnitude earthquake hit the island of Sumatra, leaving more than 1,000 people dead and thousands injured.</p><p>• Apr 5, 2010: An explosion in a West Virginia coal mine kills at least 25 people and leaves 4 unaccounted for.</p><p>• ...</p><p>• ... multi-document summarization summarizes one or a handful of documents about the same news event;</p><p>(2) instead of selecting sentences to generate a sum- mary, stream summarization selects representative documents to summarize a text stream; (3) sum- maries for a text stream may vary significantly for users who have different interests and preferences (e.g., summaries for an environmental expert and a sports fan should not be the same). Therefore, in order to generate targeted summaries for spe- cific users, a stream summary needs to be generated based on a reference summary. For instance, one can use the 2009 disaster summary (the left part in <ref type="table" target="#tab_0">Table 1</ref>) as a reference to learn how to write the 2010 disaster summary (the right part in <ref type="table" target="#tab_0">Table 1</ref>).</p><p>In general, there are three challenges for summa- rizing a text stream. First, a stream summarization model should be able to be aware of redundant in- formation in the stream for avoiding generating re- dundant content in the summary; second, a stream summarization algorithm should be capable of an- alyzing text content on the stream level for identi- fying the most important information in the stream; third, a stream summarization model should be effi- cient, scalable and able to run in an online fashion because data size of a text stream is usually huge, and it is dynamic and updated every second.</p><p>The previous approaches (e.g., <ref type="bibr" target="#b8">(Ge et al., 2015b</ref>)) tend to cluster similar documents as event detection to avoid redundancy, rank the clusters based on their sizes and topical relevance to the reference sum- maries, and select one document from each cluster as representative documents. Due to the high time complexity of clustering models, their approaches usually run slowly and are not scalable.</p><p>To overcome the limitations, we propose Burst In- formation Networks (BINet) as a novel representa- tion of a text stream. In a BINet <ref type="figure" target="#fig_1">(Figure 2</ref>), a node is a burst word (including entities) with the time span of one of its burst periods, and an edge between two nodes indicates how strongly they are related. Based on the BINet representation, we propose two mod- els -NodeRank and AreaRank -for summarizing a news stream. We conduct extensive experiments to evaluate our approaches by comparing several base- lines and the state-of-the-art approaches in various settings and show that the BINet-based approaches are efficient, scalable and can work in an online fash- ion and that they can generate high-quality sum- maries for a news stream, outperforming the state- of-the-art.</p><p>The major contributions of this paper are:</p><p>• We propose BINets as a novel representation of text streams. BINets can perfectly address the challenges of text stream summarization, which can be aware of information redundancy (Section 3), enables global analysis of the text stream (Section 4.1 and 4.2), and be efficiently built and updated incrementally (Section 4.3).</p><p>• We propose two ranking-based models based on the BINet representation, which can effec- tively learn to summarize a text stream from a reference summary, and outperform the state- of-the-art model. • We create and release a new benchmark dataset for evaluating real-time stream summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Stream Summarization</head><p>The task of text stream summarization is to gen- erate a summary including key information from a earthquake (Jan 12 -Jan 31) Haiti given text stream (e.g., 1-year news stream). In con- trast to traditional summarization tasks which sum- marize a single or a handful of documents related to the same event by extracting sentences, the task of stream summarization aims to summarize a text stream which contains huge numbers of documents involving a variety of topics and events by select- ing representative documents, as <ref type="figure" target="#fig_0">Figure 1</ref> shows. In a stream summary, each selected document is considered as an entry which can be shown us- ing the title or the first paragraph of the document. Since documents in a news stream are always about news events, we also call an entry as an event en- try and call a stream summary as an event chron- icle which is a list of event entries, as shown in <ref type="table" target="#tab_0">Table 1</ref>. In a stream summary, entries should not be redundant. Formally, we define a stream sum- mary (i.e., event chronicle) E = {e 1 , e 2 , · · · , e K } where e k = (t e k , w e k ) is an event entry including the event's time information t e k and text description w e k which is set of words in text.</p><p>Due to the diversity of ways to summarize a text stream as Section 1 discusses, we use a reference summary of a text stream during an early period to supervise summary generation for new text streams. It is a practical setting since many historical manu- ally edited summaries of early streams are available and can be used as an example to demonstrate what kind of information is preferred in a stream sum- mary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Representing a text stream using Burst</head><p>Information Network Specifically, if a word w is in a burst state at every time t during a period, we call this period as a burst period of w, and w has a burst during this period. In <ref type="figure" target="#fig_2">Figure 3</ref>, earthquake has 2 burst periods (i.e., (Jan 12 -Jan 31) and (Feb 27 -Mar 8))</p><p>Formally, we define P as one burst period of the word w. P is a consecutive time sequence during which w bursts at every time epoch t: P = (t i , t i+1 , t i+2 , ..., t i+n ) ∀t ∈ P s t = 1 where s t is a binary indicator of the burst state of w at time t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Burst Information Network</head><p>To build an information network which can repre- sent associations between key facts in a text stream, we propose a new representation called "Burst Infor- mation Network (BINet)" by using burst elements as nodes:</p><p>A Burst Element is a burst of a word. It can be represented by a tuple: w, P where w denotes the word and P denotes one burst period of w.</p><p>According to the above definition, a burst element is a joint representation of a word type and one of its burst periods. A word may have multiple burst peri- ods while a burst element only has one burst period. A word during its different burst periods will be re- garded as different burst elements.</p><p>Formally, we define the BINet G = V, E as fol- lows. Each node v ∈ V is a burst element and each edge e ∈ E denotes the association between burst el- ements. Intuitively, if two burst elements frequently co-occur, the edge between them should be highly weighted. We define ω i,j as the weight of an edge between v i and v j , which is equal to the number of documents where v i and v j co-occur.</p><p>Besides w(v) and P(v) that denote a node v's word and burst period respectively, we also record a node's context words 1 and its source documents which the node is from during constructing a BINet. Formally, we use C(v) and D(v) to denote the con- text word set and source document set of v. Also, for a document d in the stream, we use A(d) to denote the set of nodes whose source documents include d. Since nodes in A(d) are usually adjacent, we also call A(d) document d's area on the BINet. The con- struction of a BINet is efficient: the time complexity of building a BINet is O(n) where n is the number of documents in a stream.</p><p>BINets can be properly aware of redundant in- formation: since nodes in a community in a BINet are topically and temporally coherent, information about the same news event tends to be adjacent and redundant information of the same event is naturally removed. For example, assuming that there are hun- dreds of documents about Haiti earthquake in a text stream, by using the BINet representation, the infor- mation is concentrated in a few adjacent nodes with- out redundancy (left part in <ref type="figure" target="#fig_1">Figure 2</ref>). Moreover, in- formation about different events is not considered as redundant. For example, the information regarding Haiti earthquake and Chile earthquake is not treated as redundant, which is allocated to different areas in the BINet, as <ref type="figure" target="#fig_1">Figure 2</ref> shows. Therefore, as long as we do not select overlapping areas on the BINet, we can avoid selecting redundant content as entries. <ref type="bibr">1</ref> Here, the context window size is set to 10. Note that in our experiments, only words frequently (more than 5 times) co- occur in the context will be reserved. In addition to the awareness of information redun- dancy, BINets also allow global importance analysis on the stream level and online stream summariza- tion, which will be discussed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Summarizing a text stream on the BINet</head><p>Based on the BINet representation, we propose two models -NodeRank and AreaRank -to summarize a text stream by generating entries of the summary. As <ref type="figure" target="#fig_3">Figure 4</ref> shows, the NodeRank model scores ev- ery node on the BINet independently for identify- ing the most valuable information to be included in the stream summary, while the AreaRank model attempts to score an area that covers a handful of nodes for locating the most informative information blocks.</p><p>To train NodeRank and AreaRank models, we use reference summaries and the (reference) BINets built from the text stream during the reference sum- mary's period as supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">NodeRank</head><p>Intuitively, if we can find the most valuable infor- mation on the BINet that should be included in the summary, then we can generate a high-quality sum- mary of a text stream. For this goal, we label the corresponding nodes of words appearing in the ref- erence summary on the reference BINet as score 1 (positive). Formally, for a reference summary E, we label the following set of nodes in the reference BI- Net G r = V r , E r as score 1:</p><formula xml:id="formula_0">V pos = ek∈E {v|v ∈ V r ∧ w(v) ∈ w ek ∧ t ek ∈ P(v)} (1)</formula><p>where w(v) and P(v) are word and burst period of node v respectively, e k is an event entry in the ref- erence summary E, w e k is the set of words in e k 's text, and t e k is e k 's time. The nodes that are not in V pos in the reference BINet will be labeled as 0 (negative).</p><p>After labeling the reference BINet, we train a learning to rank (L2R) model 2 using the follow- ing features for scoring nodes in the target BINet G τ = {V τ , E τ } (shown in <ref type="figure" target="#fig_3">Figure 4</ref>):</p><p>• w(v): the word of node v, indicating its seman- tic information.</p><p>• pr(v): node v's PageRank value can reflect the global importance of the node on the stream level, which can be easily obtained by running the PageRank algorithm on the BINet. • C(v): the context words of node v defined in Section 3.2, indicating the topic information. After scoring nodes in the target BINet, we greed- ily choose a document area A(d) that covers a set of nodes whose score is the largest:</p><formula xml:id="formula_1">d * = arg max d∈Dτ v∈A(d) score N R (v)<label>(2)</label></formula><p>where D τ is the document sets in the target stream and score N R (v) is the score of node v outputted by NodeRank model. Document d * 's first paragraph and its document creation time (DCT) will be used to generate an event entry for the summary of the target stream. Note that though we do not normal- ize the length of a document in Eq (2), we constrain the maximum length of a document's first paragraph is 50 words and will not select the document whose first paragraph is longer than 50 words. By repeating this step for k times, we can generate a stream summary with k event entries. Note that in order to avoid generating redundant entries in the summary, we will not choose d * if its document area A(d * ) overlaps with the areas of the documents that have been already chosen as entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">AreaRank</head><p>Instead of scoring nodes independently like NodeR- ank, we propose AreaRank model for scoring an area on the BINet for finding areas that corresponds to the most important news events in the stream.</p><p>Different from NodeRank where each instance is one node in the BINet, instances are areas on the BI- Net in the AreaRank model, as shown in <ref type="figure" target="#fig_3">Figure 4</ref>. In this paper, we mainly consider document area A(d) since we select representative documents as entries in the summary.</p><p>As NodeRank, we first label reference BINet us- ing the reference summary. In the AreaRank model, we find the areas on the reference BINet correspond- ing to each event entry in the reference summary and label such areas as score 1 (positive). Formally, for a reference summary E, the positive areas are in the following set:</p><formula xml:id="formula_2">A pos = ek∈E {A|A = V ek }<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">V e k = {v|v ∈ V r ∧ w(v) ∈ w e k ∧ t e k ∈ P(v)</formula><p>} is the set of nodes to which words in e k cor- respond in the reference BINet.</p><p>We label other document areas that do not over- lap any positive area on the reference BINet as score 0. Then, we use the training data to train AreaRank using the following features:</p><p>• w(A): words of nodes in area A, indicating the area's semantic and topic information.</p><p>• pr(A): this feature includes maximum, sum and average of PageRank value of nodes in the area and sum of top 3 PageRank value of nodes in the area, indicating the area's general im- portance, which can reflects the impact of the events corresponding to the area in the stream.</p><p>• C(A): context of nodes in area A. This feature is useful for indicating topical information. In the test phase, we use AreaRank model to score all possible document areas on the target BINet. Then, we greedily choose the document area with the top score to generate an event entry for the sum- mary:</p><formula xml:id="formula_4">d * = arg max d∈Dτ score AR (A(d))<label>(4)</label></formula><p>As NodeRank, d * 's first paragraph and DCT will be used to generate an event entry for the stream summary if d * 's area A(d) does not overlap the areas of the documents that have been already selected for generating event entries. The maximum length of the first paragraph of a document is 50 words. This step will be repeated for multiple times for generat- ing event entries of the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Online stream summarization</head><p>An advantage of the BINet is that it can be incre- mentally updated when new streams arrive, which is useful for online stream summarization. Assuming we have a news stream from time t 0 to t k at hand, we can detect word bursts and construct a BINet G based on the stream. When the news stream at t k+1 comes, we first detect burst words in the newly arriv- ing data, update the BINet and calculate the PageR- ank value for G(t k+1 ) which denotes the slice of BI- Net G at time t k+1 , which is defined as follows:</p><p>G(t) = V (t), E(t) where V (t) = {v|t ∈ P(v)} and E(t) = {e i,j |e i,j ∈ E ∧ i ∈ V (t) ∧ j ∈ V (t)}. Then, we can apply NodeRank and AreaRank on G(t k+1 ) to generate a stream summary at t k+1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Evaluations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiments on Gigaword corpus</head><p>For comparison to the previous work, we use the same data with Ge et al. (2015b) (i.e., 2009 and 2010 APW and XIN news stories in English Giga- word ( <ref type="bibr" target="#b9">Graff et al., 2003)</ref>) as a news stream. We de- tect burst words using Kleinberg algorithm <ref type="bibr" target="#b15">(Kleinberg, 2003</ref>), which models word burst detection as a burst state decoding problem. In total, there are 140,557 documents in the dataset.  as reference summaries for summarizing the news stream during 2010. The information of the refer- ence summaries is summarized in <ref type="table" target="#tab_2">Table 2</ref>. In evalu- ation, they pooled entries in stream sumamries gen- erated by various approaches, annotated each entry based on the reference summary and the manually edited event chronicles on the web, and used preci- sion@K to evaluate the quality of top K event entries in a stream summary instead of using ROUGE <ref type="bibr" target="#b20">(Lin, 2004</ref>) because news stream summaries are event- centric.</p><p>In this paper, we adopt the same evaluation setting and use the same reference summaries and the anno- tations with our previous work <ref type="bibr" target="#b8">(Ge et al., 2015b</ref>) to evaluate our summaries' quality. For the event en- tries that are not in <ref type="bibr" target="#b8">Ge et al. (2015b)</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>'s annotations, we have 3 human judges annotate them according to the previous annotation guideline and consider an entry correct if it is annotated as correct by at least 2 judges. We evaluate our approaches by comparing to Ge et al. (2015b)'s approach and the baselines in their work:</head><p>• RANDOM: this baseline randomly selects doc- uments in the dataset as event entries.</p><p>• NB: this baseline uses Naive Bayes to clus- ter documents for event detection and ranks the clusters based on the combination score of top- ical relevance and the event impact (i.e., event cluster size). The earliest documents in the top- ranked clusters are selected as entries.</p><p>• B-HAC: similar to NB except that BurstVSM representation ( <ref type="bibr" target="#b36">Zhao et al., 2012</ref>) is used for event detection using Hierarchical Agglomera- tive Clustering algorithm.</p><p>• TAHBM: similar to NB except that the state- of-the-art event detection model (TaHBM) pro- posed by <ref type="bibr" target="#b8">Ge et al. (2015b)</ref> is used for event de- tection.</p><p>• <ref type="bibr" target="#b8">Ge et al. (2015b)</ref>: the state-of-the-art stream summarization approach which used TaHBM to detect events and L2R model to rank events. Note that we did not compare with previous multi- document summarization models because the goal and setting of stream summarization are different from multi-document summarization, as Section 1  discussed. Moreover, these two tasks differ greatly in the data size and redundancy identification mech- anism. Therefore, it is not feasible to directly com- pare multi-document summarization models to our approaches unless they are adapted for our setting.</p><p>The results are shown in <ref type="table" target="#tab_4">Table 3</ref>. It can be clearly observed that BINet-based approaches outperform baselines and perform comparably to the state-of- the-art model on generating the summaries on most topics: AreaRank achieves the significant improve- ment over the state-of-the-art model on sports and disasters, and performs comparably on politics and military and NodeRank's performance achieves the comparable performance to previous state-of-the-art model though it is inferior to AreaRank on most top- ics. Among these five topics, almost all models per- form well on disaster and military topics because disaster and military reference summaries have more entries than the topics such as politics and sports and topics of event entries in the summaries are fo- cused. The high-quality training data benefits mod- els' performance especially for AreaRank which is purely data-driven. In contrast, on sports and pol- itics, the number of entries in the reference sum- maries is small, which results in weaker supervi- sion and affect the performance of models. It is no- table that AreaRank does not perform well on gen- erating the comprehensive summary in which top- ics of event entries are miscellaneous. The reason for the undesirable performance is that the topics of event entries in the comprehensive reference sum- mary are not focused, which results in very few ref- erence (positive) examples for each topic. As a re- sult, the miscellaneousness of topics of positive ex- amples makes them tend to be overwhelmed by large numbers of negative examples during training the model, leading to very week supervision and mak- ing it difficult for AreaRank to learn the patterns</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Features Precision@100</p><p>NodeRank</p><formula xml:id="formula_5">w(v) 0.18 w(v)+pr(v) 0.22 w(v)+C(v) 0.46 w(v)+pr(v)+C(v) 0.51 AreaRank w(A) 0.25 w(A) + pr(A) 0.34 w(A)+C(A)</formula><p>0.58 w(A)+pr(A)+C(A) 0.62  of positive examples. Compared to AreaRank, the strategy of selecting documents for generating event entries in other baselines and NodeRank use more or less heuristic knowledge, which makes these models perform stably even if the training examples are not sufficient.</p><p>We conducted an ablation test to study the effects of features on generating summaries in our model. <ref type="table" target="#tab_5">Table 4</ref> shows the performance of models using vari- ous feature combination on generating disaster sum- maries. In both NodeRank and AreaRank models, PageRank features enhance the models that only use word features of nodes, demonstrating the effects of global importance analysis on the stream level. Con- text features are also useful for improving the results because words (both burst and non-burst words) in context can help the model learn the preference of topics and styles from the reference summary.</p><p>We conducted error analysis for NodeRank and AreaRank, shown in <ref type="table" target="#tab_6">Table 5</ref>. Among topically irrel- evant, minor and redundant event entries, minor (i.e.,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Module</head><p>Run time Can be run in parallel   trivial) event entries that are not important enough to be included in the stream summary account for the majority of errors for both models. This is because it is difficult to distinguish these trivial events since the corpus we used as a text stream is not as ideal as the assumption that the more important events, the more times they are reported. As shown in <ref type="table" target="#tab_2">Table 2</ref>, many entries in the reference summaries even do not appear or burst in our corpus because the Gigaword corpus used is just a small sample of news stream during the period. As a result, the importance fea- tures (e.g., PageRank value) in our ranking model do not work very well for distinguishing trivial events. At last, we tested the run time of our BINet ap- proach and compare to the state-of-the-art model proposed by <ref type="bibr" target="#b8">Ge et al. (2015b)</ref> in terms of efficiency. The results are shown in <ref type="table" target="#tab_8">Table 6</ref>. The run time is tested on a workstation with Intel Xeon 3.5 GHz CPU and 64GB RAM. The efficiency of our model is much better than <ref type="bibr" target="#b8">Ge et al. (2015b)</ref>'s approach whose event detection model takes much time to it- erate thousands of times for Gibbs sampling. For memory cost, the peak memory cost of our BINet- based approaches is 5GB while <ref type="bibr" target="#b8">Ge et al. (2015b)</ref>'s approach needs more than 10GB memory to run the event detection model and thus cannot work on a large dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiments on a real-time news stream</head><p>To evaluate our approaches in a real setting, we cre- ate a benchmark dataset 4 containing 7.9 million En- glish news stories (without exact duplication) dur- ing Feb 5 to Mar 31, 2015, collecting from Bing news portal <ref type="bibr">5</ref>   NodeRank and AreaRank) on the real-time stream. Specifically, we used news stream during Feb 5 to Mar 23 for training to generate news summaries for every day during Mar 24 to Mar 30 in an online fash- ion. This is a practical setting and can be useful for automatically generating headline news every day. Daily news summaries in Current Event Portal 6 at Wikipedia are used as reference summaries for train- ing and gold standard for evaluating our approaches.</p><p>In this paper, we tested on generating summaries on Disaster and accident (Disaster) and Armed con- flicts and attacks (Attack) topics. Instead of evaluat- ing Precision@K as we did on the Gigaword corpus which is a small dataset, we used Mean Reciprocal Rank (MRR) which is defined as follows to see the ranking position of event entries of the gold standard in the summaries generated by our approaches:</p><formula xml:id="formula_6">M RR = t∈Ttest ( ek∈E (t) gold 1 rank (t) e k ) t∈Ttest |E (t) gold | (5)</formula><p>where</p><formula xml:id="formula_7">E (t)</formula><p>gold is the gold standard summaries at time t, T test is the period of test set (i.e., Mar 24 to Mar 30) and rank</p><formula xml:id="formula_8">(t)</formula><p>e k is the highest rank of an event entry e k of the gold standard summary in our summary at t. A high MRR means the event entries of gold standard tend to be ranked at top positions in our generated summaries. The evaluation is conducted manually. <ref type="table" target="#tab_10">Table 7</ref> shows the performance of BINet-based 6 https://en.wikipedia.org/wiki/Portal:Current events/ approaches on the real-time news stream. The BINet-based approaches achieve better results than the online version of B-HAC model on both topics, demonstrating the advantages of the BINet represen- tation. It is also notable that AreaRank performs better than NodeRank because it scores a document area as a whole by taking into account various in- formation of the area. For AreaRank, MRR on the disaster topic is about 0.2, meaning that the average ranking position of gold standard event entries is 5, which is a promising result and shows our approach can be effective to find key information. More im- portantly, it only takes 500 seconds to build a BINet and 388 seconds to run PageRank for 1,000 itera- tions for global importance analysis on the 7.9 mil- lion documents while other methods in <ref type="table" target="#tab_4">Table 3</ref> even cannot be applied on the stream because they cannot handle so large scale of data or work in an online fashion, which is why we did not compare to them in this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Stream summarization is not a hot topic in NLP community. Despite the related work that studies corpus summarization of research papers (Sipos et al., 2012), <ref type="bibr" target="#b8">Ge et al. (2015b)</ref> is the only work ex- actly dealing with the news stream summarization challenge. However, they studied the problem on a static timestamped corpus instead of on a dynamic text stream and their proposed pipeline-style ap- proach cannot be applied on a real-time text stream due to high complexity in time and space. Other previous work dealing with stream data is mainly focused on topic and event detection ( <ref type="bibr" target="#b33">Yang et al., 1998;</ref><ref type="bibr" target="#b26">Swan and Allan, 2000;</ref><ref type="bibr" target="#b1">Allan, 2002</ref>  <ref type="bibr" target="#b16">and Cardie, 2014)</ref>. Different from traditional single and multi- document summarization <ref type="bibr" target="#b3">(Carbonell and Goldstein, 1998;</ref><ref type="bibr" target="#b20">Lin, 2004;</ref><ref type="bibr" target="#b6">Erkan and Radev, 2004;</ref><ref type="bibr" target="#b5">Conroy et al., 2004;</ref><ref type="bibr" target="#b18">Li et al., 2007;</ref><ref type="bibr" target="#b29">Wan and Yang, 2008;</ref><ref type="bibr" target="#b19">Chen and Chen, 2012;</ref><ref type="bibr" target="#b30">Wan and Zhang, 2014)</ref> whose focus is to select important sentences, the fo- cus of stream summarization is to select representa- tive documents referring to important news events. The novel paradigm focuses on the summarization problem in the big data age and is useful for many applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future work</head><p>In this paper, we study the news stream summa- rization problem by proposing a novel text stream representation -Burst Information Networks and presenting two summarization models based on it.</p><p>The proposed approaches can efficiently generate high-quality summaries, achieving the state-of-the- art performance. Moreover, the experiments on our created benchmark dataset showed our approach can be effectively applied on the real-time news stream for finding key information, demonstrating its po- tential values for many real-world applications (e.g., personalized headline news recommendation).</p><p>In the future, we plan to generalize the stream summarization problem to various streams such as social (e.g., Twitter), image (e.g., Imgur) and even video streams (e.g., Youtube), which would yield many interesting and practical applications ( <ref type="bibr" target="#b21">Lu et al., 2016)</ref> to deal with the information overload chal- lenge in the big data era.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Stream summarization paradigm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of a BINet. Due to space limitation, we only show the burst period of some nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3Figure 3 :</head><label>3</label><figDesc>Figure 3: Frequency of earthquake during the first 90 days in the 2010 news stream.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: NodeRank (left) and AreaRank (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>BINet</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>; He et al., 2007; Sayyadi et al., 2009; Sakaki et al., 2010; Zhao et al., 2012; Ge et al., 2015a), dynamic language and topic modelling (Blei and Lafferty, 2006; Iwata et al., 2010; Wang et al., 2012; Yogatama et al., 2014), incremental (temporal) summarization and timeline generation for one major news event (Allan et al., 2001; Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013; Kedzie et al., 2015; Tran et al., 2015; Yao et al., 2016), a sports match (Taka- mura et al., 2011) or users on the social network (Li</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Stream summary about disasters in 2009 and 2010. The disaster summary of 2009 can be used a reference summary to 

supervise generating a disaster summary for the 2010 news stream. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>The number of event entries in the reference sum- maries. The third column is the number of event entries exclud- ing those events that do not appear in the corpus. We removed stopwords and used Stanford CoreNLP (Manning et al., 2014) to do lemmatiza- tion and named tagging, and built BINets on the news stream during 2009 and 2010 separately. On the 2009 news stream, there are 31,888 nodes and 833,313 edges while there are 32,997 nodes and 825,976 edges on the 2010 stream. Ge et al. (2015b) used manually edited event chronicles of various topics on the web 3 during 2009 3 http://www.mapreport.com; http://www.infoplease.com;</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance of various approaches on stream summarization on five topics. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Ablation test on feature combination for generating 

disaster summaries. 

Model 
Topic 
Irrelevant Minor Redundant 

NodeRank 
disaster 
35.3% 
64.7% 
0 
sports 
21.3% 
77.5% 
1.3% 
comprehensive 
-
100% 
0 

AreaRank 
disaster 
34.2% 
63.1% 
2.6% 
sports 
7.5% 
91.1% 
1.5% 
comprehensive 
-
100% 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Error analysis of BINet-based approaches. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Run time of BINet-based approaches and Ge et al. (2015b)'s approach 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>MRR of BINet-based approaches on generating sum-

maries for the real-time news stream. 

</table></figure>

			<note place="foot" n="2"> We use SVMRank (Joachims, 2006). During training, we randomly sample 50% of negative examples which are used to generate the training set with positive examples.</note>

			<note place="foot" n="4"> The dataset and the gold standard are available at http://getao.github.io 5 https://www.bing.com/news</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their helpful comments. We also want to specially thank Prof. Heng Ji for her valuable suggestions and discussion on the early ideas of this work. This work is supported by the National Key Basic Re-search Program of China (No.2014CB340504) and the National Natural Science Foundation of China (No.61375074,61273318). The contact author is Zhifang Sui.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Khandelwal</surname></persName>
		</author>
		<title level="m">Temporal summaries of new topics. In SIGIR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Topic detection and tracking: eventbased information organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The use of mmr, diversity-based reranking for reordering documents and producing summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tscan: A content anatomy approach to temporal topic summarization. Knowledge and Data Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng Chang</forename><surname>Chien Chin Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="170" to="183" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Left-brain/right-brain multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">D</forename><surname>John M Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jade</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianne</forename><forename type="middle">P</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oleary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DUC</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lexrank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir R Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Distinguishing specific and daily topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>In APWeb</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bring you to the past: Automatic generation of topically relevant event chronicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>English gigaword. Linguistic Data Consortium</publisher>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using burstiness to improve clustering of topics in news streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ee-Peng</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generating breakpoint-based timeline overview for news topic retrospection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">K</forename><surname>Usadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online multiscale dynamic topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoharu</forename><surname>Iwata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasushi</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Training linear svms in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Predicting salient updates for disaster summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Kedzie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bursty and hierarchical structure in streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="397" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Timeline generation: Tracking individuals on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evolutionary hierarchical dirichlet process for timeline summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Multi-document summarization using support vector regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Sun</surname></persName>
		</author>
		<editor>DUC. Citeseer</editor>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generating event storylines from microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingding</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out: Proceedings of the ACL-04 workshop</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cross-media event extraction and recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clare</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangbo</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rostyslav</forename><surname>Korolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongtao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongzhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL Demo Session</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (System Demonstrations)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Earthquake shakes twitter users: real-time event detection by social sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Sakaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Okazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Event detection and tracking in social streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sayyadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Maykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal corpus summarization using submodular word coverage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Sipos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adith</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pannaga</forename><surname>Shivaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic generation of overview timelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Swan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Summarizing a document stream</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroya</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hikaru</forename><surname>Yokono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="177" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Timeline summarization from relevant headlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giang</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Alrifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eelco</forename><surname>Herder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-document summarization using cluster-based link analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Ctsum: extracting more certain summaries for news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Zhang</surname></persName>
		</author>
		<editor>SIGIR</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Heckerman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.3298</idno>
		<title level="m">Continuous time dynamic topic models</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolutionary timeline summarization: a balanced optimization framework via iterative substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahna</forename><surname>Otterbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A study of retrospective and on-line event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Pierce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tweet timeline generation with determinantal point processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Ge</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dynamic language models for streaming text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bryan R Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A novel burst-based text representation model for scalable event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishan</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
