<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Context Information for Dialog Act Classification in DNN Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Applied Machine Learning</orgName>
								<address>
									<settlement>Facebook</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Applied Machine Learning</orgName>
								<address>
									<settlement>Facebook</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Applied Machine Learning</orgName>
								<address>
									<settlement>Facebook</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Lei</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Applied Machine Learning</orgName>
								<address>
									<settlement>Facebook</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Context Information for Dialog Act Classification in DNN Framework</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2170" to="2178"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Previous work on dialog act (DA) classification has investigated different methods, such as hidden Markov models, maximum entropy, conditional random fields, graph-ical models, and support vector machines. A few recent studies explored using deep learning neural networks for DA classification , however, it is not clear yet what is the best method for using dialog context or DA sequential information, and how much gain it brings. This paper proposes several ways of using context information for DA classification, all in the deep learning framework. The baseline system classifies each utterance using the con-volutional neural networks (CNN). Our proposed methods include using hierarchical models (recurrent neural networks (RNN) or CNN) for DA sequence tagging where the bottom layer takes the sentence CNN representation as input, concatenat-ing predictions from the previous utterances with the CNN vector for classification , and performing sequence decoding based on the predictions from the sentence CNN model. We conduct thorough experiments and comparisons on the Switchboard corpus, demonstrate that incorporating context information significantly improves DA classification, and show that we achieve new state-of-the-art performance for this task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dialog act (DA) represents a function of a speaker's utterance in either human-to-human or human-to-computer conversations. Correct identi- fication of DAs is important for understanding hu- man conversations, as well as for developing intel- ligent human-to-computer dialog systems (either written or spoken dialogs). For example, recogniz- ing DAs can help identify questions and answers in meetings, customer service, online forum, etc. Many machine learning techniques have been in- vestigated and shown reasonable performance for DA classification, for example, ( <ref type="bibr" target="#b0">Ang et al., 2005;</ref><ref type="bibr" target="#b5">Ji and Bilmes, 2005;</ref><ref type="bibr" target="#b7">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b15">Ribeiro et al., 2015)</ref>, just to name a few. Intuitively we would expect that leveraging dia- log context can help classify the current utterance. For example, if the previous sentence is a question, then there is a high probability that the current sen- tence is a response to that question. Such con- text information has been explored in some pre- vious methods, for example, hidden Markov mod- els (HMM), conditional random fields (CRF), dy- namic Bayesian networks (DBN). Given the re- cent success of the deep learning framework in various language processing tasks, in this work we also employ neural networks for DA classifica- tion. In fact, such models have been used in some recent studies for DA classification, e.g., <ref type="bibr">(RojasBarahona et al., 2016;</ref><ref type="bibr" target="#b7">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b20">Zhou et al., 2015)</ref>; however, previous work has not thoroughly evaluated the use of context in- formation for this task, and there is still a lack of good understanding about how we can use context information and how useful it is. This is the ques- tion we aim to answer in this work.</p><p>The contributions of this paper are: 1) We pro- pose several ways to incorporate context informa- tion for DA classification over the baseline method of using convolutional neural networks (CNN) for sentence classification, including: (a) a hierarchi- cal RNN/LSTM and CNN to model the utterance sequence in the conversation, where the input to the higher level LSTM and CNN unit is the sen- tence vector from the sentence level CNN model; (b) a two-step approach where the predicted DA results for the previous utterances, either labels or probability distributions, are concatenated with the sentence CNN vector for the current utterance as the new input for classification; (c) sequence level decoding based on the predicted DA prob- abilities and the transition probabilities between DA labels. Some of these methods have not been exploited previously for this task. 2) We perform a detailed and thorough analysis of different mod- eling approaches and some impacting factors in the models (such as the context length, represen- tations and quality of the predictions). This is the first study with such kind of comparisons. 3) We achieve new state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Previous work has investigated different machine learning techniques for DA classification such as Maximum entropy, <ref type="bibr">DBN, HMM, and SVM (Ang et al., 2005;</ref><ref type="bibr" target="#b5">Ji and Bilmes, 2005;</ref><ref type="bibr" target="#b18">Venkataraman et al., 2003;</ref><ref type="bibr" target="#b19">Webb et al., 2005;</ref><ref type="bibr" target="#b4">Fernandez and Picard, 2002;</ref><ref type="bibr" target="#b13">Mast et al., 1996;</ref><ref type="bibr" target="#b12">Liu, 2006;</ref><ref type="bibr" target="#b10">Kral and Cerisara, 2014</ref>). Different features have been ex- plored in these models, including lexical, syntac- tic features, prosodic cues, and speaker interac- tions. In particular, context information has been previously used in some methods. For example, some early studies used HMMs ( <ref type="bibr" target="#b18">Venkataraman et al., 2003;</ref><ref type="bibr" target="#b17">Stolcke et al., 2000</ref>), where the "hid- den" states are the DA tags, which generate the se- quence of words as observations. The observation probabilities are obtained by DA specific word- based language models, and a DA tag based n- gram language model provides the transition prob- abilities between the DA tags. ( <ref type="bibr" target="#b5">Ji and Bilmes, 2005;</ref><ref type="bibr" target="#b3">Dielmann and Renals, 2008)</ref> used DBN for sequence decoding and examined both the gen- erative and the conditional modeling approaches. CRF, as a powerful sequence labeling method, has also been widely used to incorporate context in- formation for DA classification <ref type="bibr" target="#b8">(Kim et al., 2010;</ref><ref type="bibr" target="#b14">Quarteroni et al., 2011;</ref><ref type="bibr" target="#b1">Chen and Eugenio, 2013;</ref><ref type="bibr" target="#b3">Dielmann and Renals, 2008)</ref>. It is worth noting that ( <ref type="bibr" target="#b15">Ribeiro et al., 2015</ref>) used different configu- rations to capture information from previous con- text in the SVM classifiers, such as n-grams or DA predictions. This is similar to our work in that we also evaluate using the previous utterances, and the predicted DAs for them. However, our mod- eling approaches are all based on DNNs, as de- scribed in more details in Section 3, and the inter- action between utterances and DA labels is mod- eled in the hierarchical models in a more princi- pled way.</p><p>Recently deep learning has been widely adopted in many language processing tasks, including DA classification. Context or sequence information is also explored in this framework. For exam- ple, <ref type="bibr" target="#b16">(Rojas-Barahona et al., 2016)</ref> proposed to use DNN for DA classification and slot filling, and evaluated on two different sets. They showed that their proposed CNN+LSTM model has negligible gain on one data set, and significant improvement on the other one for the joint DA classification and slot filling task. <ref type="bibr" target="#b7">(Kalchbrenner and Blunsom, 2013)</ref> proposed methods for discourse decompo- sition, and investigated using recurrent CNN for DA classification, reporting some positive results, e.g., 2.9% improvement over the LM-HMM base- line. In this paper we propose different meth- ods in the deep learning framework to incorporate context information. Our hierarchical LSTM and CNN method has some similarities to that used in (Rojas- <ref type="bibr" target="#b16">Barahona et al., 2016;</ref><ref type="bibr" target="#b7">Kalchbrenner and Blunsom, 2013</ref>), but unlike those that focus on just one method, we propose a few approaches and per- form comparisons among them for a deeper under- standing of different methods and their contribut- ing factors.</p><p>The discussions above are limited to DA clas- sification using speech/text data. Other knowl- edge sources have also been used in a multimodal setting (e.g., haptic actions in <ref type="bibr" target="#b1">(Chen and Eugenio, 2013)</ref>). In this study we just rely on tex- tual information. Also note that in some scenar- ios, for example, speech conversations where tran- scripts are from speech recognition systems, DA segmentation is also needed. This problem has been addressed in some previous work, for exam- ple, <ref type="bibr" target="#b11">(Lendvai, 2007;</ref><ref type="bibr" target="#b14">Quarteroni et al., 2011;</ref><ref type="bibr" target="#b0">Ang et al., 2005</ref>), which often uses a classification or sequence labeling setup for the segmentation task, or performs joint DA segmentation and classifica- tion. We use pre-segmented utterances and focus just on the DA classification task in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DA Classification Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task</head><p>Our task is to classify each utterance in a conversa- tion into a predefined DA tag set. We use Switch- board data in our experiments (see Section 4.1 for DA type speaker sentence statement-opinion B I always kind of think it would be neat to be able to watch them and be there for them all the time back-channel A Uh-huh question-yes-no B Is that what you do? yes-answer A Uh yeah statement A Actually I teach my kids at home statement A so I'm here all the time summarize/reformulate B: Oh so they don't go to school <ref type="table">Table 1</ref>: An example of Switchboard conversation with the DA labels.</p><p>additional information on the data). There are dif- ferent granularities of the tag sets. In this work we use 42 tags ( <ref type="bibr" target="#b6">Jurafsky et al., 1997</ref>), which has been widely used in previous studies of DA classifica- tion on this data set. <ref type="table">Table 1</ref> shows an example of some utterances in a Switchboard conversation.</p><p>We can see that the 'answer' DA follows the 'ques- tion' one, which is quite intuitive. Our goal is thus to model such sequential information for DA clas- sification. Again in this work we only use the tran- scriptions of the utterances along with the speaker information (i.e., if the current utterance is from the same or different speaker as the previous one), without any speech related features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">CNN for utterance classification</head><p>All of our methods are built based on the ba- sic CNN sentence representation, which has been widely used recently in sentence as well as doc- ument classification <ref type="bibr" target="#b2">(Collobert et al., 2011;</ref><ref type="bibr" target="#b9">Kim, 2014</ref>), therefore we first briefly describe this base- line. <ref type="figure" target="#fig_0">Figure 1</ref> shows the context independent CNN-based classification method. Let w <ref type="bibr">[1...n]</ref> rep- resent the word embedding sequence for a sen- tence with n words, where w i ∈ R d is the d- dimensional embedding vector for the i th word. A temporal convolution operation is applied to the sentence:</p><formula xml:id="formula_0">c [1...n] = ˜ w [1...n] * f where˜wwhere˜ where˜w [1...n] denotes the sequence w [1...n]</formula><p>with zero padding, and f is a filter map for the convo- lution operation. A max pooling layer is then ap- plied over the resulting sequence c [1...n] to obtain one value for the sentence. If we use l window sizes and k filters for each window, then l × k con- volutional sequences are generated for each sen- tence, and after max pooling, we obtain a fixed- length vector s with a dimension of l × k. This is the feature vector representation for the sentence, which is then used as the input in a multi-layer perceptron (MLP) or feedforward neural network for sentence classification. We only use one layer MLP in this work. This baseline CNN model learns textual infor- mation in each sentence for DA classification. We can incorporate additional features into this model, for example, if the current sentence is from the same speaker as the previous one. <ref type="figure" target="#fig_0">Figure 1</ref> shows the use of such additional features -they are con- catenated with the CNN-based textural vector, and then fed to the MLP for DA classification. In the rest of the paper, when there is no confusion, we also use CNN for the cases when additional fea- tures are concatenated with the standard CNN for sentence-level representation. We use this CNN model as a baseline, and in the following will ex- plore several methods using context information for DA classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Use history DA information</head><p>As discussed earlier, we expect there is valuable sequential information among the DA tags, there- fore in the first approach, we combine the history DA information with the current utterance to clas- sify its DA tag. This is represented as additional features concatenated with the CNN sentence rep- resentation, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We evaluate dif- ferent configurations in this framework.</p><p>• Use DA labels. We compare using reference and system predicted DA labels in training and testing. Note that using reference labels in testing is not a real testing setup. This is just meant to provide an upper bound and un- derstand the performance degradation due to prediction errors.</p><p>• Use probabilities for system predictions. In- stead of taking the hard decisions from the system's predictions, we evaluate using the posterior probabilities from the system in or- der to capture more information.</p><p>• History length. We compare using DA infor- mation from different number of previous ut- terances.</p><p>Note that for most of these setups above when system's predicted DA information is used, we need to go through the following procedure:</p><p>• train a context-independent sentence CNN model</p><p>• use it to generate predictions, for training and test data</p><p>• add the corresponding history DA informa- tion in the training set to retrain a model</p><p>• add the history DA information in the test set and apply the new model</p><p>The only scenario where these steps are not re- quired is when reference DA tags are used in both training and testing. There is one additional caveat that is worth pointing out -when generating the DA predictions for the training data, ideally we need to perform cross validation for the training set such that all the training sentences are labeled by a model trained from data that does not include this sentence, and thus we have matched infor- mation used in training and testing; however, we noticed that our model does not overfit the train- ing data very much, and the training accuracy is not significantly different from the test accuracy, therefore we simply apply the trained CNN model to the training set itself to obtain the DA predic- tions for all the training sentences, and train the new model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">CNN + DA transition decoding</head><p>In this approach, we perform conversation level decoding that combines the probabilities from the context-independent CNN model and the DA tag transition probabilities. The DA classification problem can be represented as:</p><formula xml:id="formula_1">ˆ Y = argmaxP (Y |X) = argmaxP (Y )P (X|Y ) = argmaxP (Y ) i P (x i |y i )</formula><p>where Y is the DA tag sequence, and X con- tains the entire conversation, i.e., sequence of sen- tences. P (Y ) can be computed for the DA tag sequence (similar to word-based n-gram language model, here "words" are DA tags), and the prob- ability of a tag given the utterance (P (x i |y i )) can be obtained from the rescaled probability from the CNN model (that is P (y i |x i )). For decoding, we can use either Viterbi decoding to find the most likely DA sequence (as shown above) or forward- backward decoding to determine the best tag for each utterance in the sequence. This model is similar to the HMM model used previously for this task ( <ref type="bibr" target="#b17">Stolcke et al., 2000</ref>), and the difference is in that the probability of a DA given the sen- tence is estimated by the CNN model, a discrim- inative model, in contrast to the word-based lan- guage model that is a generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Hierarchical model: CNN+CNN</head><p>Once we have the sentence vector representation built based on the baseline CNN model, we use another CNN to incorporate context information of an utterance for its classification. <ref type="figure" target="#fig_1">Figure 2</ref> shows this method. The sequence of sentences is represented by a sequence of fixed length vectors s <ref type="bibr">[1...m]</ref> , where m is the number of sentences in the conversation, and s i is the vector representa- tion for sentence i from the baseline CNN model. Similar to the CNN model for word sequence, we apply a temporal convolutional layer with differ- ent filters to s <ref type="bibr">[1...m]</ref> . Different from the sentence CNN model for word sequences, here we do not perform pooling for the entire dialog sequence, as the classification task is for each sentence, not the whole conversation (sentence sequence). Instead, for each sentence, the output of every convolu- tional filter is concatenated to form the sentence's representation, and then an MLP is used for its classification. This approach can be thought as a hierarchical neural network, where the high level CNN is used to capture context information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Hierarchical model: CNN+RNN</head><p>The hierarchical CNN method uses the neighbor- ing sentences to learn the dependencies among consecutive utterances. A different method to model the sequential information is via an RNN that is intrinsically capable of learning the tempo- ral dynamics, which is suitable for the problem. In this hierarchical model, the representation for each sentence is still learned by the CNN as in the base- line, while the dialog-level sequence information among sentences is modeled by the RNN. Here, we use bidirectional-LSTM (BLSTM) to learn the context before and after the current sentence. The left-to-right LSTM output and the one from the reverse direction are concatenated and input to a hidden layer for classification. BLSTM has been widely used recently for various sequence labeling problems (such as part-of-speech tagging, named entity recognition) and achieved state-of-the-art performance. <ref type="figure" target="#fig_2">Figure 3</ref> shows the structure of the model. Note that the difference between these last two models and the one using history DA infor- mation is in that DA labels are not explicitly rep- resented in these hierarchical models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We use Switchboard data in our experiments. This corpus has been widely used in the community for DA classification. In this data, two people talked over the phone about a given topic for several min- utes. 1155 conversations have been manually la- beled with DAs. 40 conversations were held out for testing and development. However, there is no standard as to what are the test ones (it is unknown from the earliest paper using this data ( <ref type="bibr" target="#b17">Stolcke et al., 2000)</ref>). Therefore we randomly split the set into two, 20 conversations in each, with similar amount of utterances. We use one set as the devel- opment set and evaluate on the other set. As men- tioned earlier, we do not use speech features, and only use textual information and speaker change feature in this study. For all the experiments, we use human transcripts. This setup is expected to be applicable to written conversations/dialogs. <ref type="table" target="#tab_0">Ta-ble 2 shows the basic statistics of the data.   conversations sentences  training  1115  196,753  test set 1  20  3,764  test set 2  20</ref> 3,771  <ref type="table">Table 3</ref> shows the baseline classification accu- racy results when no context information is used, for three setups: the baseline sentence CNN model with the pretrained embeddings, when speaker change information is added, and when no pre- trained embeddings are used. We can see the slight performance change because of the added speaker change feature. When no pretrained em- beddings are used, i.e., no additional information is used from other resources, there is a perfor- mance degradation of 2-3%. Note that these re- sults are better or at least comparable to state- of-the-art performance. In fact, we also imple- mented a CRF tagging model for this data set, where we used bag-of-word features for each ut- terance, therefore the information is similar to that used in the DNN framework (but the CRF does model DA tag sequential information). This CRF model has an accuracy of about 74% for the two sets combined. The CNN model without using pretrained embeddings has worse results than the CRF system that is trained just using the Switch- board data, confirming that when using word em- beddings as word representations, pretrained em- beddings are beneficial when the training size is small. However, the CNN model can effectively leverage word embedding information (obtained from unlabeled data), whereas it is not straightfor- ward to use such information in the CRF classi- fiers. This shows an advantage of the DNN-based method. set 1 set 2 CNN 74.47 76.88 + speaker change 74.73 77.12 no pretrained embedding 71.81 74.49 <ref type="table">Table 3</ref>: DA classification accuracy (%) when us- ing the baseline CNN without context information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Hierarchical models: CNN+CNN/RNN</head><p>For the hierarchical models described in Sec- tion 3.5 and 3.6, i.e., adding CNN and BLSTM on top of the baseline sentence CNN, we kept the same model parameters in the sentence CNN part. The dimension is 64 for both the higher level CNN and LSTM. For these sequence labeling tasks, we use stochastic gradient descent (SGD), with a learning rate of 0.01. We observed this yielded better performance than Adagrad learning.  <ref type="table" target="#tab_1">Table 4</ref>: DA classification results (%) when using the hierarchical structure: sentence CNN followed by dialog sequence level CNN or RNN/BLSTM.</p><p>From the table we can see that using LSTM and CNN to model context information for DA clas- sification is effective, both models significantly outperforming the baseline. Regarding the effect of context, in general there is slightly more gain when more context is used, as in BLSTM, or larger windows in CNN. For CNN, when we increase the window more, to beyond 4, there is no further im- provement. The greatest difference comes from using context vs. not using it at all. history DA = ref or sys DA representation set 1 set 2 training testing ref ref label 78. <ref type="bibr">19</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">CNN + DA prediction</head><p>As described in Section 3.3, another method to in- corporate context information is to use the DAs from previous utterances. We perform a detailed analysis to examine three factors under this frame- work:</p><p>• context history: we use a window of up to 3, i.e., information from the previous one, two, or three utterances;</p><p>• representation of the DA information, whether it is DA label or probabilities;</p><p>• reference vs. system predicted DA labels dur- ing training and testing.</p><p>Using the reference DA labels in testing is ex- pected to give an oracle or upper bound perfor- mance for this set of experiments. <ref type="table" target="#tab_3">Table 5</ref> shows the results for these setups. The predictions for the utterances are generated using the baseline CNN model, with the pretrained embeddings and speaker information (i.e., the best utterance clas- sification model). The model parameters in the second-round CNN training (when additional his- tory DA information is included) are the same as the baseline CNN.</p><p>From <ref type="table" target="#tab_3">Table 5</ref> we can see that in terms of the representation of the history DA information, us- ing hard labels and soft predictions achieves sim- ilar performance. For model training, it is better to have matched information in training and test- ing. Using reference DA labels during training and system predictions in testing (second row in the re- sults) is less effective compared to using both sys- tem predictions in training and testing. The quality of the prediction also affects the usefulness of the DA prediction information, as demonstrated by the better performance when the reference labels are used compared to using system predicted DAs, which is expected. The immediate previous utter- ance has the largest impact on the prediction of the current utterance (comparing to not using context at all), and adding longer context helps less. In addition, using the reference previous DA labels (ref train and ref test condition) benefits more than using system predicted DA labels when longer his- tory is used, suggesting that more predicted DAs, when used together, become more noisy and bring less gain.  <ref type="table" target="#tab_4">Table 6</ref>: DA classification results (%) using differ- ent systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Overall results</head><p>when context information is used. All the meth- ods using context yield significant improvement over the baseline (statistically significant based on t-test). Comparing representing context informa- tion via the DA labels of the previous utterances vs. using the hierarchical CNN or RNN model, we see there is not much difference. This observation is somewhat different from that found in ( <ref type="bibr" target="#b15">Ribeiro et al., 2015;</ref><ref type="bibr" target="#b8">Kim et al., 2010</ref>) where using previ- ous DA predictions yields more gain than adding n-gram features from the previous utterances. We believe one reason for this difference is the use of the DNN framework to model the utterance se- quences. Given the current data size and the oracle performance in <ref type="table" target="#tab_3">Table 5</ref>, we expect that when more data is available, using larger neural networks will further improve the performance. Furthermore, we want to mention that overall these results rep- resent new state-of-the-art performance for this task <ref type="bibr" target="#b7">((Kalchbrenner and Blunsom, 2013</ref>) reported 73.9% accuracy using recurrent CNN, though the results are not directly comparable since they only evaluated on 19 test conversations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Final remarks</head><p>As expected, our experimental results demonstrate that we can effectively incorporate context infor- mation to improve DA classification. We con- ducted some analyses to see what errors are cor- rected when we use the context models compared to the baseline results. Due to space limit, we show one positive example below where adding context changes the prediction from 'backchannel' to 'answer'.</p><p>• Example:</p><p>-Is this a mail order parts house that special- izes in parts for parts for uh old imports? -right</p><p>It is clear that using context can help disam- biguate and better predict the DAs for the current utterance. In fact, we noticed that close to 5% of errors are correctly changed from 'back channel' to 'reply' when context information is used.</p><p>One of the most frequent errors we notice the system makes is the mislabels between 'state- ment' and 'statement-opinion'. To correctly iden- tify statement-opinion DAs, we can perform some opinion or subjectivity recognition, but that is out of the scope of this study. Another frequent error is the confusion between backchannel and agree- ment. For example, 'right' and 'yeah' are common words for both categories, and even with context information, they are still hard to disambiguate for the current models.</p><p>Finally it is worth pointing out that our work uses an offline setting where we perform DA tag- ging for the entire conversation. In real world ap- plications, an online setting may be needed; how- ever, information from previous utterances can still be used there. In fact, most of the per- formance gain from incorporating context infor- mation comes from the previous utterances (e.g., the difference between the hierarchical LSTM and BLSTM is very small). Our findings about the ef- fectiveness of context information are applicable to the online setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Baseline context-independent CNN-based DA classification method.</figDesc><graphic url="image-1.png" coords="4,87.76,88.52,419.30,186.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Hirarchical CNN: sequence CNN on top of sentence CNN for DA classification.</figDesc><graphic url="image-2.png" coords="5,72.00,72.27,223.62,153.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: RNN/Bi-LSTM on top of sentence CNN for DA classification.</figDesc><graphic url="image-3.png" coords="5,307.28,78.74,223.62,140.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Data information. 

4.2 Results 

4.2.1 Baseline CNN 
For all the DNN models, we did not tune model 
parameters very much. Most of the parameters 
were chosen based on literature or our experience 
with other DNN-based text classification tasks. 
We used pretrained embeddings (dimension 200) 
to initialize word vectors to use in CNN, and then 
update them during training. 1 To avoid overfitting, 
we use a dropout of 0.5. The baseline CNN uses 
three windows: 1, 2, and 3, and 100 filter maps for 
each. The output hidden layer dimension is 100. 
For learning, we use Adagrad with a learning rate 
of 0.01. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 4 shows</head><label>4</label><figDesc>the results for different setups in these two models to evaluate the impact of context informa- tion. For LSTM, we compare using LSTM and BLSTM; for CNN, we show results when using different context window sizes in the top layer.</figDesc><table>set 1 set 2 
baseline CNN 
74.73 77.12 
window 2 76.2 79.16 
CNN+CNN window 3 76.78 79.05 
window 4 77.15 79.74 
BLSTM 76.91 79.71 
CNN+RNN 
LSTM 
76.35 79.71 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>DA classification results (%) when incorporating history DA information in the current utterance 
in the CNN method. Three factors are examined: context history length, DA representations, and where 
DA information is from. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 6 summarizes</head><label>6</label><figDesc></figDesc><table>the results for different sys-
tems, including the baseline CNN model without 
using context information (this baseline uses pre-
trained embeddings and speaker change feature), 
and four different ways of using context: (a) pre-
dicted DA information (posterior probabilities) is 
combined with the current sentence's CNN-based 
representation; (b) applying a BLSTM on top of 
the sentence CNN representation; (c) hierarchical 
CNN that combines the current sentence's CNN 
representation with its neighbors; (d) sequence de-
coding by combining CNN posteriors with DA 
transition scores. 
From the results, we can see the positive effect </table></figure>

			<note place="foot" n="1"> The embeddings we used are generated based on our collected web data. We compared it to other embeddings, e.g., Senna, and found the performance difference is very small.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We proposed several approaches to incorporate context information in the deep learning frame-work for DA classification in conversations, in-cluding expanding the sentence CNN vector with the predicted DA information from previous ut-terances to train another model, hierarchical mod-els based on CNN or LSTM to model the DA se-quence on top of the sentence CNN representation, or dialog level decoding once the sentence CNN generates its hypothesis. Compared to the base-line using CNN for utterance classification, our proposed methods effectively leverage context in-formation and achieve significantly better perfor-mance. We observe that there is very small dif-ference among different approaches. Our results represent the state-of-the-art for DA classification on the Switchboard data. We conducted thorough evaluations to understand the impact of different factors, and our results shed lights on the use of context information for similar tasks. In our future work, we plan to apply these approaches to other tasks, such as intent recognition and slot filling in language understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Yandi Xia for preparing the Switchboard data, Xian Qian, Antoine Raux and Benoit Dumoulin for various discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic dialog act segmentation and classification in multiparty meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Ang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICASSP</title>
		<meeting>of ICASSP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multimodality and dialogue act classification in the robohelper project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">Di</forename><surname>Eugenio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceddings of Sigdial</title>
		<meeting>eddings of Sigdial</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recognition of dialogue acts in multiparty meetings using a switching dbn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Dielmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech and Language Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dialog act classification from prosodic features using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosalind</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Speech Prosody</title>
		<meeting>of Speech Prosody</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dialog act tagging using graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICASSP</title>
		<meeting>of ICASSP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Switchboard swbd-damsl shallow-discourse-function annotation coders manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Biasca</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>University of Colorado at Boulder</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Recurrent convolutional neural networks for discourse compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Classifying dialog acts in one-on-one live chats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic dialogue act recognition with syntactic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisophe</forename><surname>Cerisara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Token-based chunking of turninternal dialogue act sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piroska</forename><surname>Lendvai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Using svm and error-correcting codes for multiclass dialog act classification in meeting corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dialog act classification with the help of prosody</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Mast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Kompe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Harbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kiebling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Niemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Noth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICSLP</title>
		<meeting>of ICSLP</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simultaneous dialog segmentation and classification from human-human spoken conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Quarteroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">V</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The influence of context on dialogue act recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugenio</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martins De Matos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Exploiting sentence and context representation in deep neural models for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Tsung-Hsien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Dialog act modeling for automatic tagging and recognition of conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Meteer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Training a prosody based dialog act tagger from unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucianna</forename><surname>Ferrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICASSP</title>
		<meeting>of ICASSP</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Andreas Stolcke, and Elizabeth Shriberg</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dialog act classification based on intra-utterances features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yorick</forename><surname>Wilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI workshop on Spoken Language Understanding</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Combining heterogeneious deep neural networks with conditional random fields for chinese dialogue act recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
