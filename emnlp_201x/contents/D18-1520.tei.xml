<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:49+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Refining Pretrained Word Embeddings Using Layer-wise Relevance Propagation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Utsumi</surname></persName>
							<email>utsumi@uec.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics &amp; Artificial Intelligence eXploration Research Center</orgName>
								<orgName type="institution">The University of Electro-Communications</orgName>
								<address>
									<postCode>182-8585</postCode>
									<settlement>Chofu, Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Refining Pretrained Word Embeddings Using Layer-wise Relevance Propagation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4840" to="4846"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4840</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose a simple method for refining pretrained word embeddings using layer-wise relevance propagation. Given a target semantic representation one would like word vectors to reflect, our method first trains the mapping between the original word vectors and the target representation using a neural network. Estimated target values are then propagated backward toward word vectors , and a relevance score is computed for each dimension of word vectors. Finally, the relevance score vectors are used to refine the original word vectors so that they are projected into the subspace that reflects the information relevant to the target representation. The evaluation experiment using binary classification of word pairs demonstrates that the refined vectors by our method achieve the higher performance than the original vectors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The recent success of neural NLP is partially but largely due to the development of word embedding techniques <ref type="bibr" target="#b10">(Goldberg, 2017)</ref>. Although a consid- erable number of studies have been made on train- ing word embeddings from distributional informa- tion of language ( <ref type="bibr" target="#b17">Mikolov et al., 2013;</ref><ref type="bibr" target="#b20">Pennington et al., 2014;</ref><ref type="bibr" target="#b3">Bojanowski et al., 2017;</ref><ref type="bibr" target="#b19">Nickel and Kiela, 2017)</ref>, one recent research trend is to refine or fine-tune pretrained word embeddings. One promising approach is the use of other in- formation such as multimodal information <ref type="bibr" target="#b6">(Bruni et al., 2014;</ref><ref type="bibr" target="#b14">Kiela et al., 2014;</ref><ref type="bibr" target="#b12">Kiela and Clark, 2015;</ref><ref type="bibr" target="#b11">Kiela et al., 2015a;</ref><ref type="bibr" target="#b25">Silberer et al., 2017</ref>) and language resources <ref type="bibr" target="#b13">Kiela et al., 2015b;</ref><ref type="bibr" target="#b23">Rothe and Schütze, 2017;</ref><ref type="bibr" target="#b32">Yu and Dredze, 2014</ref>). Other refinement methods include task-specific embed- dings ( <ref type="bibr" target="#b5">Bolukbasi et al., 2016;</ref><ref type="bibr" target="#b31">Yu et al., 2017</ref>) and the selective use of multiple embeddings <ref type="bibr" target="#b4">(Bollegala et al., 2017;</ref><ref type="bibr" target="#b15">Kiela et al., 2018)</ref>.</p><p>In this paper, we propose a different approach to refining pretrained word embeddings so that word vectors reflect the information relevant for a spe- cific knowledge. Our method utilizes layer-wise relevance propagation ( <ref type="bibr" target="#b0">Bach et al., 2015;</ref><ref type="bibr" target="#b24">Samek et al., 2017)</ref>, which has been proposed as a general framework for decomposing predictions of mod- ern AI systems, in particular deep learning sys- tems. The basic idea of layer-wise relevance prop- agation is to quantitatively measure the contribu- tion of each fragment of an input vector (e.g., a single pixel of an image) to the prediction as a rel- evance score. Using relevance scores, our method projects word vectors into the subspace that better reflects the target knowledge. The assumption un- derlying our approach is that the information for any given target knowledge is contained in pre- trained word embeddings. Our method attempts to make the best use of the information contained in word vectors by estimating the importance in reflecting a target knowledge.</p><p>To the best of our knowledge, this paper is the first to employ the technique of layer-wise rele- vance propagation for refining word embeddings. Our method can be applied to word vectors x trained by any word embedding method. This im- plies that our method does not compete with other refinement methods, but they are complementary; it can be used for word vectors refined by other methods. In addition, our method can refine word vectors for any target knowledge y, from a single binary value to a structured representation, as long as a function y = f (x) can be learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method for Refining Word Vectors</head><p>Our method comprises the following three steps: (1) it trains a prediction function from a pretrained word vector to a target representation; (2) com- putes a relevance score for each dimension of the word vector; and (3) projects word vectors into the subspace using the relevance scores. In this sec- tion, these three steps are explained in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training the Prediction Function</head><p>Given pairs of an input word vector x (i) to be re- fined and a target knowledge representation y (i) for a word w (i) , the proposed method trains a func- tion y (i) = f (x (i) ). In this paper, we use a neural network as a learning method, but other learning methods such as linear transformation and SVM can also be used. Note that a scalar value or a class label can be used as a target representation y (i) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Computing Relevance Scores</head><p>This step derives an explanation of the predic- tion in terms of input variables, namely the impor- tance of each dimension of a word vector x (i) for the predictionˆypredictionˆ predictionˆy (i) = f (x (i) ). In layer-wise rele- vance propagation, the score of the correct predic- tionˆytionˆ tionˆy</p><formula xml:id="formula_0">(i)</formula><p>j is redistributed backward using relevance propagation rules. By repeatedly applying prop- agation rules, it assigns a relevance score r</p><formula xml:id="formula_1">(i,j) k to each dimension x (i)</formula><p>k of a word vector x <ref type="bibr">(i)</ref> . As a re- sult, a relevance score vector r (i,j) is obtained for each word vector x (i) and target dimension y </p><formula xml:id="formula_2">R (l,l+1) i←j = R (l+1) j · ( α z + ij ∑ i z + ij + β z − ij ∑ i z − ij ) (1) R (l) i = ∑ j R (l,l+1) i←j (2) z (l,l+1) ij = x (l) i w (l,l+1) ij (3) where x (l)</formula><p>i is an activation of the unit u</p><formula xml:id="formula_3">(l) i , w (l,l+1) ij is a weight connecting u (l) i to u (l+1) j</formula><p>, and z + ij and z − ij denote the positive and negative part of z</p><formula xml:id="formula_4">(l,l+1) ij .</formula><p>As a result, relevance scores r</p><formula xml:id="formula_5">(i,j) k</formula><p>of the word vec- tor x (i) and the target dimension y k of the input layer. The parameters α and β denote the importance of pos- itive and negative evidence for predicting a tar- get representations and should be chosen such that α + β = 1. In this paper, we assume that posi- tive and negative evidence equally contributes to the prediction and thus set α = β = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Projecting Word Vectors into a Subspace</head><p>The basic idea of projection is that n-dimensional word vectors are projected into m-dimensional vectors whose relevance scores are more than or equal to a threshold θ R .</p><p>First, for a target dimension j of y, relevance score vectors are averaged over words relevant to the target dimension as follows:</p><formula xml:id="formula_6">r (j) = g 2 ( ∑ w i ∈V j g 1 (r (i,j) ) |V j | ) (4) {g 1 (x)} i = { x i (x i ≥ θ R 1 ) 0 (otherwise) {g 2 (x)} i = { x i max i x i ( x i max i x i ≥ θ R 2 ) 0 (otherwise)</formula><p>where V j is a set of words w (i) such thatˆythatˆ thatˆy</p><formula xml:id="formula_7">(i) j ≥ θ T .</formula><p>The functions g 1 and g 2 are used for downplay- ing irrelevant dimensions. For example, the tar- get knowledge is the property of Visually dark and V visually dark is {chocolate, crow, night}. By aver- aging relevance score vectors of these words, we obtain the mean relevance vector r <ref type="bibr">(visually dark)</ref> that represents the importance of word vector di- mension in predicting whether a given word has the property of Visually dark.</p><p>Finally, using the mean relevance vector r (j) , word vectors x i is transformed into vectors z (j) i of a subspace for the target dimension. This is achieved by weighting x i by component-wise multiplication of x i and r <ref type="bibr">(j)</ref> and removing the di- mensions of zero relevance. Formally, the projec- tion is defined by the n by m projection matrix T (j) as follows:</p><formula xml:id="formula_8">z (j) i = x i T (j)<label>(5)</label></formula><formula xml:id="formula_9">T (j) ik =    r (j) i (r (j) i &gt; 0 and it is the k-th nonzero dimension of r (j) ) 0 (otherwise)<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Experiment</head><p>In order to justify the effectiveness of the proposed method, we conducted an evaluation experiment using binary classification of word pairs. Corpus: All word vectors were trained on the Corpus of Contemporary American English Domain Properties Vision Vision, Bright, Dark, Color, Pattern, Large, Small, Motion, Biomotion, Fast, Slow, Shape, Complexity, Face, Body Somatic Touch, Temperature, Texture, Weight, Pain Audition Audition, Loud, Low, High, Sound, Music,   <ref type="table" target="#tab_0">Table 1</ref>, which are based entirely on functional divisions in the human brain. Each word is represented as a 65-dimensional vector and each dimension corre- sponds to one of these properties. Each value of the brain-based vectors represents the salience of the corresponding property, which is calculated as a mean salience rating on a 7-point scale ranging from 0 to 6. Because these properties are based on not only perceptual properties but also a variety of other properties such as affective, social, and cog- nitive ones, this dataset is suitable for evaluation.</p><note type="other">Speech Gustation Taste Olfaction Smell Motor Head, UpperLimb, LowerLimb, Practice Spatial Landmark, Path, Scene, Near, Toward, Away, Number Temporal Time, Duration, Long, Short Causal Caused, Consequential Social Social, Human, Communication, Self Cognition Cognition Emotion Benefit, Harm, Pleasant, Unpleasant, Happy, Sad, Angry, Disgusted, Fearful, Surprised Drive Drive, Needs Attention Attention, Arousal</note><p>Refining word vectors: The prediction func- tion f was trained using a three-layer neural net- work comprising an input layer for n-dimensional word vectors, one hidden layer with n/2 sigmoid units, and a linear output layer. The parameters θ T , θ R 1 and θ R 2 for projection were estimated us- 1 http://www.neuro.mcw.edu/semanticrepresentations.html Bright, Dark, Color, Pattern, Large, Small, Motion, Fast, Slow, Shape, Temperature, Texture, Weight, Loud, Sound, Taste, Smell, Fearful <ref type="table">Table 2</ref>: 18 properties in CSLB dataset ing 10-fold cross-validation and grid search. <ref type="bibr">2</ref> Task: We used a binary classification task of judging whether a pair of words is similar or not with respect to each property of <ref type="table" target="#tab_0">Table 1</ref>. For ex- ample, night and chocolate should be judged as similar with respect to the property of Dark, while night and ice should be judged as dissimilar with respect to that property. For each property, we chose 10 words with the highest salience and 10 words with the lowest salience from the vocabu- lary of brain-based vectors, and generated 45 high- salience word pairs and 100 pairs of high-salience and low-salience words. Note that we did not consider low-score word pairs because it does not make sense to ask whether words (e.g., peace and wit) that do not have a property (e.g., Dark) are similar with respect to that property.</p><p>To confirm the generality of our method, we also generated another evaluation dataset for un- trained words (i.e., words not included in Binder et al.'s vocabulary) using CSLB concept property norms of 638 words <ref type="bibr" target="#b7">(Devereux et al., 2014</ref>). <ref type="bibr">3</ref> Af- ter removing words contained in Binder et al.'s vo- cabulary, we chose properties that were closely re- lated to Binder et al.'s properties and possessed by at least 10 words. As a result, the generated dataset contained 18 properties listed in <ref type="table">Table 2</ref>, because the property norm mainly includes perceptual and functional properties.</p><p>Binary classification was carried out by com- puting cosine similarity between vectors of paired words and classifying the n highest pairs into sim- ilar pairs. Hence, the classification performance was measured by average precision.   cantly higher than that of the original vectors by Wilcoxon signed-rank test (p &lt; .05). For all word embeddings, the refined vectors achieved higher mean average precision than the original ones. Furthermore, in almost all cases, the improvement is statistically significant. This result demonstrates that the proposed method is successful in refining word embeddings so that vector similarity better reflects the target knowledge. <ref type="figure" target="#fig_3">Figure 1</ref> depicts the difference of average pre- cision between the original word vectors and the refined vectors for each target property. Most of the properties are plotted above the diagonal ref- erence line, indicating that these properties are better represented by the refined vectors. Note</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGNS GloVe win dim Orig Refn</head><p>Orig Refn 10 300 57.9 60.4* 56.8 58.5 10 200 58.0 59.3 56.3 56.6 10 100 58.8 58.3 55.9 56.0 5 300 58.8 61.1* 56.4 59.3* 5 200 58.5 62.6* 55.6 56.8 5 100 58.9 60.9 56.5 55.5 3 300 58.5 58.8 55.2 55.6 3 200 58.9 59.3 54.5 54.1 3 100 59.3 58.8 53.5 54.4 that properties plotted below the diagonal line, for which refined word vectors yielded lower preci- sion than the original vectors, are sensorimotor or spatiotemporal properties. This result is consis- tent with <ref type="bibr" target="#b28">Utsumi's (2018)</ref> finding that these kinds of knowledge are less likely to be encoded in word vectors. <ref type="table" target="#tab_3">Table 4</ref> shows the result of binary classification for CSLB property norm dataset. In most cases, the refined vectors of untrained words also yielded better performance than the original vectors. In some cases, however, refinement did not improve the performance. One of the reasons for this fail- ure would be that a small set of vocabulary words in <ref type="bibr">Binder et al.'s (2016)</ref> dataset is not enough for the subspace to generalize to untrained words.</p><p>To confirm whether the projected subspace bet- ter reflects the target knowledge than the original space, we visualize both spaces using MDS in <ref type="figure" target="#fig_5">Fig- ure 2</ref>. Although all 535 words are embedded into the two-dimensional space, <ref type="figure" target="#fig_5">Figure 2</ref> only shows words used in binary classification task, namely words with the 10 highest salience (denoted by red dots) and 20 lowest salience for a given prop- erty. As shown in <ref type="figure" target="#fig_5">Figure 2</ref>, our method refines the vectors of salient words to be more similar in the subspace, while preserving the other similarity of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Prior work on word embedding refinement can be classified into general purpose refinement and specific target refinement. Many existing stud- ies have attempted to refine word vectors to im- prove the performance of general-purpose simi- larity computation. These studies generally re-  fine word vectors by solving an optimization prob- lem whose objective function reflects the simi- larity obtained by language resources, such as WordNet ( <ref type="bibr" target="#b32">Yu and Dredze, 2014;</ref><ref type="bibr" target="#b23">Rothe and Schütze, 2017)</ref>, <ref type="bibr">Freebase (Rothe and Schütze, 2017)</ref>, Paraphrase Database ( <ref type="bibr" target="#b32">Yu and Dredze, 2014</ref>), free associ- ation norm ( <ref type="bibr" target="#b13">Kiela et al., 2015b)</ref>, and dictionary ( <ref type="bibr" target="#b30">Wang et al., 2015)</ref>. Our method differs from them in that it is proposed for specific target refinement. In other words, the refined vectors by general pur- pose refinement method can be further refined to extract a specific knowledge by our method.</p><p>Most prior studies for specific purpose refine- ment propose a method specialized for a specific task such as sentiment analysis <ref type="bibr" target="#b16">(Labutov and Lipson, 2013;</ref><ref type="bibr" target="#b26">Tang et al., 2016;</ref><ref type="bibr" target="#b31">Yu et al., 2017)</ref> and lexical entailment <ref type="bibr" target="#b18">(Mrkši´Mrkši´c et al., 2016;</ref><ref type="bibr" target="#b29">Vuli´cVuli´c and Mrkši´Mrkši´c, 2018)</ref>. On the other hand, our method refines word vectors for a specific knowledge or task, but it is not specialized for a knowledge or task.  and  are conceptually similar to our approach; their method refines word vectors for a specific knowledge but it is not specialized for a certain task. The merit of our method is that any types of representation can be used as a target, while their method is limited to binary labels. Furthermore, while their method learns an orthogonal transfor- mation of pretrained word vectors by directly op- timizing the objective function, our method can project word vectors to a subspace independent of training method for a prediction function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a method for refin- ing pretrained word vectors using layer-wise rele- vance propagation. We demonstrated that the pro- posed method can refine word vectors so that they better reflect the target knowledge. One of our mo- tivation is to make embeddings more interpretable and useful. In other studies <ref type="bibr" target="#b27">(Utsumi, 2015</ref><ref type="bibr" target="#b28">(Utsumi, , 2018</ref>, we have analyzed the internal knowledge encoded in text-based word embeddings, while this study is the first step toward a general method for utilizing the internal knowledge of word embeddings.</p><p>In future work, we have to modify the refine- ment method by relevance propagation to be more effective by exploring the mechanism of how the internal knowledge of word vectors is extracted by multilayer neural networks and examining the ef- fectiveness of other relevance propagation meth- ods. It would also be vital for future work to ex- plore efficient combinations with other refinement methods using language resources.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Among a number of propagation rules (Bach et al., 2015), we use the "alpha-beta" rule for mul- tilayer neural networks. The relevance score R (l) i of the i-th unit u (l) i in the l-th layer is a function of upper-layer relevances R (l+1) j defined by:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>COCA), which includes 0.56G word tokens. Words that occurred less than 30 times in the cor- pus were ignored, resulting in the vocabulary of 108,230 words. Three context windows of size 3, 5, and 10 were used for training. Word embedding: We used two representative models, namely skip-gram with negative sampling (SGNS) (Mikolov et al., 2013) and GloVe (Pen- nington et al., 2014). We trained 100-, 200-and 300-dimensional word vectors from the corpus. Target knowledge representation: We used Binder et al.'s (2016) brain-based semantic vec- tors of 535 words as a target representation. 1 This representation comprises 65 properties in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A scatterplot of average precision of the original versus refined vectors for 65 properties in the case of SGNS with win= 5 and dim= 200. The diagonal reference line y = x indicates that the original and refined vectors have equal precision.</figDesc><graphic url="image-1.png" coords="4,54.89,233.24,255.77,255.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two-dimensional MDS visualization of the original space (trained by SGNS with win= 5 and dim= 200) and the projected subspace (θ T = 3.0, θ R1 = 0.026 and θ R2 = 0.10). Left: Original space, Right: Projected subspace</figDesc><graphic url="image-4.png" coords="5,51.47,288.90,257.07,116.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : 65 properties in Binder et al.'s (2016) dataset</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 3 shows</head><label>3</label><figDesc>mean average precisions across 65 properties for the original word embeddings (Orig) and the refined embeddings by our method (Refn). The asterisk indicates that the mean av- erage precision of the refined vectors is signifi-</figDesc><table>SGNS 
GloVe 
win dim Orig Refn 
Orig Refn 
10 300 75.3 78.6* 
67.4 70.4* 
10 200 75.9 79.3* 
67.8 73.7* 
10 100 76.1 77.0* 
68.7 71.6* 
5 300 75.4 78.8* 
67.7 71.8* 
5 200 75.6 79.4* 
68.0 73.9* 
5 100 77.2 78.3 
68.9 70.1 
3 300 75.5 79.3* 
67.6 71.5* 
3 200 76.5 77.9* 
68.2 70.8* 
3 100 77.4 79.0* 
68.4 71.2* 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Mean average precision for Binder et al.'s 
(2016) dataset 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Mean average precision for CSLB property 
norm dataset 

</table></figure>

			<note place="foot" n="2"> The range in grid search was [3.0, 4.5] with a step size of 0.1 for θT , [0.0, 0.02n] with a step size of 0.001n for θR 1 of n hundred word vector dimension, and [0.0, 0.7] with a step size of 0.05 for θR 2. 3 https://cslb.psychol.cam.ac.uk/propnorms</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by JSPS KAKENHI Grant Numbers JP15H02713 and SCAT Research Grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">130140</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">R</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><forename type="middle">L</forename><surname>Conant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">J</forename><surname>Humphries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Fernandino</surname></persName>
		</author>
		<imprint>
			<pubPlace>Stephen B. Simons, Mario</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Toward a brainbased componential semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rutvik</forename><forename type="middle">H</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Desai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="130" to="174" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning linear transformations between counting-based and prediction-based word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danushka</forename><surname>Bollegala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken-Ichi</forename><surname>Kawarabayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">184544</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Man is to computer programmer as woman is to homemaker? debiasing word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="4349" to="4357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">K</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jounral of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Centre for Speech, Language and the Brain (CSLB) concept property norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><forename type="middle">K</forename><surname>Devereux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billi</forename><surname>Geertzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1119" to="1127" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Retrofitting word vectors to semantic lexicons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Kumar Sujay Jauhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Noah</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1606" to="1615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nondistributional word vector representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="464" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Neural Network Methods for Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoab</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grounding semantics in olfactory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luana</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="231" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-and cross-modal semantics beyond vision: Grounding in auditory perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2461" to="2470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Specializing word embeddings for similarity or relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2044" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Context-attentive embeddings for improved sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07983</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>cs.CL</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Re-embedding words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="489" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop at the International Conference on Learning Representation</title>
		<meeting>Workshop at the International Conference on Learning Representation</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Counter-fitting word vectors to linguistic constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´o</forename><surname>Diarmuid´odiarmuid´</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Blaisethomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="142" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Poincaré embeddings for learning hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6338" to="6347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ultradense word embeddings by orthogonal transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="767" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Word embedding calculus in meaningful ultradense subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="512" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autoextend: Combining word embeddings with semantic resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="593" to="617" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.08296[cs.A1</idno>
		<title level="m">Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visually grounded meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Recognition and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2284" to="2297" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sentiment embeddings with applications to sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="496" to="509" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A complex network approach to distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Utsumi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">136277</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A neurobiologically motivated analysis of distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akira</forename><surname>Utsumi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Conference of the Cognitive Science Society (CogSci2018)</title>
		<meeting>the 40th Annual Conference of the Cognitive Science Society (CogSci2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1147" to="1152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Specialising word vectors for lexical entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1134" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning lexical embeddings with syntactic and lexicographic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel-Rahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="458" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Refining word embeddings for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chih</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Robert</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuejie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="534" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improving lexical embeddings with semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="545" to="550" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
