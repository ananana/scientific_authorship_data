<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploiting Word Internal Structures for Generic Chinese Sentence Representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaonan</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CASIA</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CASIA</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CASIA</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">CAS Center for Excellence in Brain Science and Intelligence Technology</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploiting Word Internal Structures for Generic Chinese Sentence Representation</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="298" to="303"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce a novel mixed character-word architecture to improve Chinese sentence representations, by utilizing rich semantic information of word internal structures. Our architecture uses two key strategies. The first is a mask gate on characters , learning the relation among characters in a word. The second is a max-pooling operation on words, adaptively finding the optimal mixture of the atomic and compositional word representations. Finally, the proposed architecture is applied to various sentence composition models, which achieves substantial performance gains over baseline models on sentence similarity task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>To understand the meaning of a sentence is a pre- requisite to solve many natural language process- ing problems. Obviously, this requires a good rep- resentation of the meaning of a sentence. Recent- ly, neural network based methods have shown ad- vantage in learning task-specific sentence repre- sentations ( <ref type="bibr" target="#b10">Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b20">Tai et al., 2015;</ref><ref type="bibr" target="#b1">Chen et al., 2015a;</ref><ref type="bibr" target="#b3">Cheng and Kartsaklis, 2015)</ref> and generic sentence representations ( <ref type="bibr" target="#b15">Le and Mikolov, 2014;</ref><ref type="bibr">Hermann and Blunsom, 2014;</ref><ref type="bibr" target="#b14">Kiros et al., 2015;</ref><ref type="bibr" target="#b11">Kenter et al., 2016;</ref>. To learn generic sentence representation- s that perform robustly across tasks as effective as word representations, <ref type="bibr" target="#b24">Wieting et al. (2016b)</ref> proposes an architecture based on the supervision from the Paraphrase Database ( <ref type="bibr" target="#b5">Ganitkevitch et al., 2013)</ref>.</p><p>Despite the fact that Chinese has unique word internal structures, there is no work focusing on learning generic Chinese sentence representation-  <ref type="figure">Figure 1</ref>: An example sentence that consists of five words as "搭乘(take) 出租车(taxi) 到(to) 虹 桥(Hongqiao) 机场(airport)". Most of these word- s are compositional, namely word "搭乘" consists of characters "搭(take)" and "乘(ride)", word "出 租车" constitutes characters "出(out)", "租(rent)" and "车(car)", and word "机场" is composed of characters "机(machine)" and "场(field)". The color depth represents (1) contributions of each character to the compositional word meaning, and (2) contributions of the atomic (which ignore in- ner structures) and compositional word to the final word meaning. The deeper color means more con- tributions.</p><p>s. In contrast to English, Chinese characters con- tain rich information and are capable of indicat- ing semantic meanings of words. As illustrated in <ref type="figure">Figure 1</ref>, the internal structures of Chinese word- s express two characteristics: (1) Each character in a word contribute differently to the composi- tional word meaning ( <ref type="bibr" target="#b25">Wong et al., 2009</ref>) such as the word "出租车(taxi)". The first two charac- ters "出租(rent)" are descriptive modifiers of the last character "车(car)", and make the last char- acter play the most important role in expressing word meaning. (2) The atomic and compositional representations contribute differently to different types of words <ref type="bibr" target="#b16">(MacGregor and Shtyrov, 2013)</ref>. For instance, the meaning of "机 场(airport)", a low-frequency word, can be better expressed by the compositional word representation, while the non-transparent word "虹桥(Hongqiao)" is better expressed by the atomic word representation.</p><p>The word internal structures have been proven to be useful for Chinese word representations. <ref type="bibr" target="#b2">Chen et al. (2015b)</ref> proposes a character-enhanced word representation model by adding the averaged character embeddings to the word embedding. <ref type="bibr" target="#b26">Xu et al. (2016)</ref> extends this work by using weight- ed character embeddings. The weights are co- sine similarities between embeddings of a word's English translation and its constituent character- s' English translations. However, their work cal- culates weights based on a bilingual dictionary, which brings lots of mistakes because words in t- wo languages do not mantain one-to-one relation- ship. Furthermore, they only consider the first characteristic of word internal structures, but ig- nore the contributions of the atomic and compo- sitional word to the final word meaning. Similar ideas of adaptively utilizing character level infor- mations have also been investigated in English re- cently ( <ref type="bibr" target="#b6">Hashimoto and Tsuruoka, 2016;</ref><ref type="bibr" target="#b19">Rei et al., 2016;</ref><ref type="bibr" target="#b18">Miyamoto and Cho, 2016)</ref>. It should be not- ed that these studies are not focus on learning sen- tence embeddings.</p><p>In this paper, we explore word internal struc- tures to learn generic sentence representations, and propose a mixed character-word architecture which can be integrated into various sentence composition models. In the proposed architecture, a mask gate is employed to model the relation a- mong characters in a word, and pooling mecha- nism is leveraged to model the contributions of the atomic and compositional word embeddings to the final word representations. Experiments on sentence similarity (as well as word similarity) demonstrate the effectiveness of our method. In addition, as there are no publicly available Chinese sentence similarity datasets, we build a dataset to directly test the quality of sentence representation- s. The code and data will be publicly released.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Description</head><p>The problem of learning compositional sentence representations can be formulated as g comp = f (x), where f is the composition function which combines the word representations x = x 1 , x 2 , ..., x n into the compositional sentence representation g comp .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mixed Character-Word Representation</head><p>In our method, the final word representation is a fusion of the atomic and compositional word em- beddings. The atomic word representation is cal- culated by projecting word level inputs into a high- dimensional space by a look up table, while the compositional word representation is computed as a gated composition of character representations:</p><formula xml:id="formula_0">x comp i = m j=1 v ij · c ij ,<label>(1)</label></formula><p>where c ij is the j-th character representation in the i-th word. The mask gate v ij ∈ R d control- s the contribution of the j-th character in the i-th word. This is achieved by using a feed-forward neural network operated on the concatenation of a character and a word, under the assumption that the contribution of a character is correlated with both character itself and its relation with the cor- responding word:</p><formula xml:id="formula_1">v ij = tanh(W · [c ij ; x i ]),<label>(2)</label></formula><p>where W ∈ R d×2d is a trainable parameter. The proposed mask gate is a vector instead of a single value, which introduces more variations to charac- ter meaning in the composition process. Then, the atomic and compositional word rep- resentations are mixed with max-pooling:</p><formula xml:id="formula_2">x f inal i = d max k=1 (x atomic ik , x comp ik ),<label>(3)</label></formula><p>the max is an element-wise function to capture the most important features (i.e., the highest value in each dimension) in the two word representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentence Composition Model</head><p>Given word embeddings, we make a systematic comparison of five different composition models for sentence representations as follows:</p><formula xml:id="formula_3">1. g = Average(x) = 1 n n i=1 xi 2. g = M atrix(x) = 1 n n i=1 f (Wmxi) 3. g = Dan(x) = f (W d ( 1 n n i=1 xi) + b) 4. g = RN N (x) = f (Wxxi + W h hi−1 + b) 5. g = LST M (x) = ot f (ci), where ci = fi · ci−1 + ii · ci and ci = σ(Wxcxi + W hc hi−1)</formula><p>Average model, as the simplest composition model, represents sentences with averaged word vectors which are updated during training. The</p><p>Matrix and Dan models are proposed in <ref type="bibr" target="#b27">Zanzotto et al. (2010)</ref> and <ref type="bibr" target="#b9">Iyyer et al. (2015)</ref>, respective- ly. By using matrix transformations and nonlin- ear functions, the two models represent sentence meaning in a more flexible way ( </p><note type="other">). We also include RNN and LSTM models, which are widely used in recent years. The pa- rameters {i t , f t , o t } ∈ R d denote the input gate, the forget gate and the output gate, respectively. c t ∈ R d is the short-term memory state to store the history information. {Wm, W d , Wx, W h , Wxc, W hc } ∈ R d×d are trainable parameters. h i−1 denotes representations in hidden layers. Sentence repre- sentations in RNN and LSTM models are hidden vectors of the last token.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Objective Function</head><p>This paper aims to learn the general-purpose sen- tence representations based on supervision from Chinese paraphrase pairs. Following the approach of <ref type="bibr" target="#b24">Wieting et al. (2016b)</ref>, we employ the max- margin objective function to train sentence rep- resentations by maximizing the distance between positive examples and negative examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setting and Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setting</head><p>We construct four groups of models (G1˜G4) which serve as baselines to test the proposed mixed character-word models (G5). Group G1 includes six baseline models, which have shown impressive performance in English. The first two are averaged word vectors and averaged character vectors. Followed by PV-DM model which uses auxiliary vectors to represent sentences and train- s them together with word vectors, and FastSen- t model which utilizes a encoder-decoder model and encodes sentences as averaged word embed- dings. The last two are Char-CNN model which is CNN model with character n-gram filters, and Charagram model which represents sentences with a character n-gram count vector. Group G2 are the sentence representation models proposed by <ref type="bibr" target="#b24">Wieting et al. (2016b)</ref>, which utilize only word level information. We also compared our method with word representation models of <ref type="bibr" target="#b2">Chen et al. (2015b)</ref> and <ref type="bibr" target="#b26">Xu et al. (2016)</ref> in Group G3 and G4 respec- tively, by incorporate them into five sentence com- position models in Section 2.2.</p><p>In all models, the word and character embed- dings are initialized with 300-dimension vectors trained by Skip-gram model ( <ref type="bibr" target="#b17">Mikolov et al., 2013</ref>) on a corpus with 3 billion Chinese words. Al- l models are implemented with <ref type="bibr">Theano (Bergstra et al., 2010</ref>) and Lasagne ( <ref type="bibr" target="#b4">Dieleman et al., 2015)</ref>, and optimized using Adam ( <ref type="bibr" target="#b13">Kingma and Ba, 2014</ref>). The hyper-parameters 1 are selected by test- ing different values and evaluating their effects on the development set. In this paper, we run all ex- periments 5 times and report the mean values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Dataset</head><p>The training dataset is a set of paraphrase pairs in which two sentences in each pair represent the same meanings. Specifically, we extract Chinese paraphrases in machine translation evaluation corpora NIST2003 2 and CWMT2015 3 . Moreover, we select aligned sub-sentence pairs between paraphrases to enlarge the training corpus. Specifically, we first segment the sentences into sub-sentences according to punctuations of com- ma, semicolon, colon, question mark, ellipses, and periods. Then we pair all sub-sentences between a paraphrase and select sub-sentence pairs (s 1 , s 2 ) which satisfy the following two constraints: (1) the number of overlapping words of sub-sentence s 1 and s 2 should meet the condition: 0.9 &gt; len(overlap(s 1 , s 2 ))/min(len(s 1 ), len(s 2 )) &gt; 0.2, where len(s) denotes the number of words in sentence s; (2) the relative length of sub-sentence should meet the condition: max(len(s 1 ), len(s 2 ))/min(len(s 1 ), len(s 2 )) &lt;= 2. Finally, we get 30,846 paraphrases (18,187 paraphrases from NIST including 11,413 sub-sentence pairs, and 12,659 paraphrases from CWMT which include 7,912 sub-sentence pairs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Testing Dataset</head><p>We also build the testing dataset, which are sen- tence pairs collocated with human similarity rat- ings. We choose candidate sentences from the People's Daily and Baidu encyclopedia corpora. To assure sentence pairs to be representative of the full variation in semantic similarity, we choose high similarity sentence pairs <ref type="bibr">4</ref> and then random- ly pair the single sentences to construct low sim- ilarity sentence pairs. To collect human similari- ty ratings for sentence pairs, we use online ques- tionnaire <ref type="bibr">5</ref> and follow the gold standard <ref type="bibr">6</ref> to guide the rating process of participants. The subjects are paid 7 cents for rating each sentence pair within a range of 0 5 score. In total, we obtain 104 valid questionnaires and every sentence pair is evaluat- ed by average 8 persons. We use the average sub- jects' ratings for one paraphrase as its final simi- larity score, and the higher score means that the t- wo sentences have more similar meaning. We then randomly partition the datasets into test and devel- opment splits in 9:1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>We use the Pearson's correlation coefficient to examine relationships between the averaged hu- man ratings and the predicted cosine similarity s- cores of all models. Moreover, the Wilcoxon's test shows that significant difference (p &lt; 0.01) exits between our models with baseline models.</p><p>From <ref type="table">Table 1</ref>, we can see superiority of the pro- posed mixed character-word models (G5), which have significantly improved the performance over both word and character-word based models. This result indicates that it is important to find the ap- propriate way to fuse character and word level in- formations. Using mask gate alone and max pool- ing alone yield an improvement of 1.05 points and 0.83 points respectively, and using both strategies improves the averaged character-word models by 1.52 points. Another observation is that models with character level information (G3, G4, G5) per- form better than word based models (G2), which indicates the great potential of Chinese characters in learning sentence representations. Comparing different composition functions, we can see that t- wo simple models outperform others in all groups: the DAN model and the Matrix model. The sim- plest Average model achieves competitive result- s while the most complex LSTM model does not show advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group</head><p>Model Test</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G1: Baselines</head><p>Add (character) 0.6737 Add (word) 0.7518 PV-DM ( <ref type="bibr" target="#b15">Le and Mikolov, 2014)</ref> 0.7561 FastSent ( <ref type="bibr" target="#b8">Hill et al., 2016)</ref> 0.7369 Char-CNN ( <ref type="bibr" target="#b12">Kim et al., 2016)</ref> 0.8095 Charagram( <ref type="bibr" target="#b23">Wieting et al., 2016a</ref>  <ref type="table">Table 1</ref>: Correlation coefficients of model predic- tions with subject similarity ratings on Chinese sentence similarity task. The bold data refers to best among models with same composition func- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Effects of Mask Gate and Max Pooling</head><p>The mask gate assigns different weights to char- acters in a word, hopefully leading to better word representations. To intuitively show effects of the mask gate, we check characters whose l2-norm increase after applying the mask gate approach. We find that characters like "罪(crime)" in "罪 状(guilty)", "虎 (tiger)" in "美洲虎 (jaguar)" and "瓜 (melon)" in "黄瓜 (cucumber)" achieve more weights. The above results show that the mask gate approach successfully model the first charac- teristic of word internal structure (i.e., assigning more weights to key characters). To quantitatively display the results, we extract the word represen- tations calculated by the five composition models in four different groups and evaluate their quality on WordSim-297 dataset 7 using the Pearson cor- relation method. As shown in <ref type="table">Table 2</ref>, the mask gate approach significantly improves the quality of word representations.  <ref type="table">Table 2</ref>: Correlation coefficients of model predic- tions with subject similarity ratings on Chinese word similarity task, where G2 ∼ G5 are the same as in <ref type="table">Table 1</ref>.</p><p>The max-pooling approach is supposed to mod- el different contributions of the atomic and compo- sitional word vectors to the final word vector. To find out what have max-pooling method learned, we use contribution weights by calculating cosine similarities between the final word representation with the atomic and compositional word represen- tations. The results show interesting relationships with word frequency. For high-frequency word- s, the contribution of compositional word repre- sentations are more dominant. While for low- frequency words, both high 8 and low contribu- tion ratios of compositional word representations can be found. When looking into the words with the most lowest ratio, we find a large portion of English abbreviations like NBA, BBC, GDP etc., and a portion of metaphor words like "挂靴(retire, hanging boots)" and "扯皮(wrangle, pull skin)". Both kinds of these words are non-transparent, which indicates that the max-pooling method can successfully model the second characteristic of word internal structure and encode word trans- parency to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Further work</head><p>In this paper, we introduce a novel mixed character-word architecture to improve generic Chinese sentence representations by exploiting the complex internal structures of words. Extensive experiments and analyses have indicated that our models can encode word transparency and learn different semantic contributions across characters. We have also created a dataset to evaluate compo- sition models of Chinese sentences, which could advance the research for related fields.</p><p>Future work includes applying the proposed method to other aspects of nominal semantics, such as understanding compound nouns in other</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>搭乘 出租车 到 虹桥 机场 搭-乘 出-租-车 到 虹桥 机-场 Final word embedding: Atomic word: Compositional word: 搭乘 出租车 到 虹桥 机场 搭-乘 出-租-车 到 虹桥 机-场 Final word: 搭乘 出租车 到 虹桥 机场 Atomic(Full-form): Compositional: 搭乘 出租车 到 虹桥 机场 搭-乘 出-租-车 到 虹桥 机-场 Final word: 搭乘 出租车 到 虹桥 机场</figDesc></figure>

			<note place="foot" n="1"> We use a mini-batch of 25 and tune the initial learning rate over {0.001, 0.005, 0.0001, 0.0005}. For the Dan and the Matrix models, we tune over activation function (tanh or linear or rectified linear unit) and number of layers (1 or 2). 2 which contains 1,100 English sentences with 4 Chinese translations and can be found at: https://catalog. ldc.upenn.edu/LDC2006T04 3 which contains 1,859 English sentences with 4 Chinese translations and can be found at: http://www.ai-ia. ac.cn/cwmt2015/evaluation.html</note>

			<note place="foot" n="4"> Here we choose high similarity sentence pairs by using edit distance and human post-processing. 5 https://wj.qq.com/ 6 http://alt.qcri.org/semeval2015/task2/index.php?id=semantictextual-similarity-for-english</note>

			<note place="foot" n="7"> https://github.com/Leonard-Xu/CWE/tree/master/data</note>

			<note place="foot" n="8"> The high ratio is more reasonable because low-frequency words generally learn poor atomic word representations. languages, and to explore the compositionality of words and compounds.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The research work has been supported by the Nat-ural Science Foundation of China under <ref type="bibr">Grant No. 61333018 and No. 61403379.</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Theano: A cpu and gpu math compiler in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for Scientific Computing Conference (SciPy)</title>
		<meeting>the Python for Scientific Computing Conference (SciPy)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentence modeling with gated recursive neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="793" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint learning of character and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan-Bo</forename><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1236" to="1242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Syntaxaware multi-sense word embeddings for deep compositional models of meaning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Kartsaklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1531" to="1542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Sander Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eben</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Olson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Søren Kaae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kelly</surname></persName>
		</author>
		<title level="m">Lasagne: First release</title>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ppdb: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adaptive joint learning of compositional and noncompositional phrase embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54 th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54 th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="205" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multilingual models for compositional distributed semantics</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52 nd Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<meeting>the 52 nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1367" to="1377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep unordered composition rivals syntactic methods for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53 rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53 rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1681" to="1691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52 nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52 nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="655" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Siamese cbow: Optimizing word embeddings for sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Borisov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<idno>arX- iv:1606.04640</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Character-aware neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>essings of the Thirtieth AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
		<title level="m">Skip-thought vectors. Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31 st International Conference on Machine Learning</title>
		<meeting>the 31 st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multiple routes for compound word processing in the brain: evidence from eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lucy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Macgregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shtyrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and language</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="229" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>arX- iv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gated word-character recurrent language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Miyamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1992" to="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attending to characters in neural sequence labeling models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pyysalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26 t h International Conference on Computational Linguistics</title>
		<meeting>COLING 2016, the 26 t h International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="309" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.00075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning sentence representation with guidance of human attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaonan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Comparison study on critical components in composition model for phrase representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaonan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Charagram: Embedding words and sentences via character n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1504" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Introduction to chinese natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengsheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="148" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improve chinese word embeddings by exploiting internal structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanhuan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1041" to="1050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Estimating linear models for compositional distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Korkontzelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Fallucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23 rd International Conference on Computational Linguistics</title>
		<meeting>the 23 rd International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1263" to="1271" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
