<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:08+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mise en Place: Unsupervised Interpretation of Instructional Recipes</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloé</forename><surname>Kiddon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesa</forename><surname>Thandavam Ponnuraj</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Stony Brook University</orgName>
								<address>
									<settlement>Stony Brook</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mise en Place: Unsupervised Interpretation of Instructional Recipes</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an unsupervised hard EM approach to automatically mapping instructional recipes to action graphs, which define what actions should be performed on which objects and in what order. Recovering such structures can be challenging, due to unique properties of procedural language where, for example, verbal arguments are commonly elided when they can be inferred from context and disambigua-tion often requires world knowledge. Our probabilistic model incorporates aspects of procedural semantics and world knowledge , such as likely locations and selec-tional preferences for different actions. Experiments with cooking recipes demonstrate the ability to recover high quality action graphs, outperforming a strong sequential baseline by 8 points in F1, while also discovering general-purpose knowledge about cooking.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Instructional language describes how to achieve a wide variety of goals, from traveling successfully to a desired location to cooking a particular dish for dinner. Despite the fact that such language is important to our everyday lives, there has been rel- atively little effort to design algorithms that can automatically convert it into an actionable form. Existing methods typically assume labeled train- ing data ( <ref type="bibr" target="#b15">Lau et al., 2009;</ref><ref type="bibr" target="#b17">Maeta et al., 2015</ref>) or access to a physical simulator that can be used to test understanding of the instructions <ref type="bibr" target="#b4">(Branavan et al., 2009;</ref><ref type="bibr" target="#b8">Chen and Mooney, 2011;</ref><ref type="bibr" target="#b3">Bollini et al., 2013)</ref>. In this paper, we present the first approach for unsupervised learning to interpret instructional recipes using text alone, with application to cook- ing recipes.</p><p>Given a recipe, our task is to segment it into text spans that describe individual actions and con- struct an action graph whose nodes represent ac- tions and edges represent the flow of arguments across actions, for example as seen in <ref type="figure">Fig. 1</ref>. This task poses unique challenges for semantic anal- ysis. First, null arguments and ellipses are ex- tremely common <ref type="bibr" target="#b35">(Zwicky, 1988)</ref>. For example, sentences such as "Bake for 50 minutes" do not explicitly mention what to bake or where. Second, we must reason about how properties of the phys- ical objects are changed by the described actions, for example to correctly resolve what the phrase "the wet mixture" refers to in a baking recipe. Al- though linguistic context is important to resolving both of these challenges, more crucial is common sense knowledge about how the world works, in- cluding what types of things are typically baked or what ingredients could be referred to as "wet." <ref type="bibr">1</ref> These challenges seemingly present a chicken and egg problem -if we had a high quality se- mantic analyzer for instructions we could learn common sense knowledge simply by reading large bodies of text. However, correctly understand- ing instructions requires reasoning with exactly this desired knowledge. We show that this con- flict can be resolved with an unsupervised learn- ing approach, where we design models to learn various aspects of procedural knowledge and then fit them to unannotated instructional text. Cook- ing recipes are an ideal domain to study these two challenges simultaneously, as vast amounts of recipes are available online today, with significant redundancy in their coverage that can help boot- strap the overall learning process. For example, there are over 400 variations on "macaroni and cheese" recipes on allrecipes.com, from "chipotle Figure 1: An input recipe (left) and a partial corresponding output action graph (right). Each rectangle (e i ) represents an action. The leftmost oval (v i ) in each action is the action's verb and the following ovals (a ij ) represents the verb's arguments. The yellow ovals represent foods; the grey ovals represent locations. Argument ovals with dotted boundaries are implicit, i.e., not present in text. The inner white ovals (s k ij ) are string spans. The red dashed lines represent connections to string spans from their origi- nating verb or raw ingredient. The string spans also connect to their associated verb in the action diagram to model the flow of ingredients. For example, there is a directed path from each raw ingredient to the implicit object of bake, representing that the object being baked is composed of all of the raw ingredients. macaroni and cheese," to "cheesy salsa mac."</p><p>We present two models that are learned with hard EM algorithms: (1) a segmentation model to extract the actions from the recipe text, and (2) a graph model that defines a distribution over the connections between the extracted actions. The common sense knowledge is encoded in the sec- ond model which can, for example, prefer graphs that model implicit verb arguments when they better match the learned selectional preferences. The final action graph is constructed with a local search algorithm, that allows for global reasoning about ingredients as they flow through the recipe.</p><p>Experiments demonstrate the ability to recover high quality action graphs, gaining up to 8 points in F1 over a strong baseline where the ingredients flow sequentially through the verbs. The learned models are also highly interpretable, specifying for example that "dough" likely contains "flour" and that "add" generally requires two food argu- ments, even if only one is mentioned in the sen- tence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>Procedural text such as a recipe defines a set of actions, i.e. predicates, applied to a set of objects, i.e. arguments. A unique challenge in procedu- ral text understanding is to recover how different arguments flow through a chain of actions; the re- sults of intermediate actions (e.g., "Boil the pasta until al dente.") provide the inputs for future ac- tions (e.g., "Drain."). We represent these corre- spondences with an action graph. In this section, we first describe our structured representation of recipe text, then we define how components of the recipe connect. Finally, we will show how given a recipe and a set of connections we can construct an action graph that models the flow of ingredi- ents through the recipe. <ref type="figure">Fig. 1</ref> provides a detailed running example for the section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Recipe R</head><p>A recipe R is a piece of text that describes a list of instructions and a (possibly-empty) set of raw ingredients that are required to perform the in- structions. The first step is to segment the text into a list of verb-argument tuples, called actions, E R = {e 1 = (v 1 , a 1 ), . . . , e n = (v n , a n )}. Sec. 6 will describe an unsupervised approach for learn- ing to segment recipes. Each action e i pairs a verb v i with a list of arguments a i , where a ij is the j th argument of verb v i . In <ref type="figure">Fig. 1</ref>, each row contains an action with a verb in the white oval and its ar- guments in the yellow and gray ovals.</p><p>Each argument is a tuple a ij = (t syn ij , t sem ij , S ij ) with a syntactic type t syn (a) ∈ T syn = {DOBJ, P P }, a semantic type t sem (a) ∈ T sem = {f ood, location, other}, and a list of text string spans S ij = {s 1 ij , . . . , s |S ij | ij }, where s k ij is the k th span in the j th argument of verb v i . In <ref type="figure">Fig. 1</ref>, the spans of each argument are repre- sented by the white ovals inside of the argument ovals. For example, a 21 contains a span for each raw ingredient being mixed in the second action (e.g., s 1 21 ="ground beef," s 6 21 ="brown sugar"). The syntactic type determines whether the argu- ment is the direct object or a prepositional phrase argument of the verb in the recipe text. All other syntactic constructs are ignored and left for future work. The semantic types include food, location, and other. In <ref type="figure">Fig. 1</ref>, yellow ovals represent foods and gray ovals represent locations. Arguments of other semantic types are marked as other (e.g., "Mash using a fork").</p><p>We also augment the set of arguments for each verb to include implicit arguments with empty string spans. This allows making connections to arguments that the author does not mention explic- itly (e.g., the elided direct object of "bake" in e 5 ). Every verb is assigned one implicit P P argument, and, if a verb has no argument with syntactic type DOBJ, an implicit direct object. These argu- ments have indeterminate semantic types, which are to be determined based on how they connect to other actions. For example, in <ref type="figure">Fig. 1</ref>, when the implicit object of "bake" is connected to the out- put of the "lay" action, it is inferred to be of type f ood since that is what is created by the "lay" ac- tion. However, when the implicit P P argument of "bake" is connected to the output of the "pre- heat" action, it is inferred to be a location since "preheat" does not generate a food.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Connections C</head><p>Given a segmented recipe, we can build graph con- nections. A connection identifies the origin of a given string span as either the output of a previ- ous action or as a new ingredient or entity being introduced into the recipe. A connection is a six- tuple (o, i, j, k, t syn , t sem ) indicating that there is a connection from the output of v o to the argu- ment span s k ij with syntactic type t syn ∈ T syn and semantic type t sem ∈ T sem . We call o the origin index and i the destination index. For ex- ample, in <ref type="figure">Fig. 1</ref>, the connection from the output of the "press" verb (e 3 ) to "over the top" (s 1 42 ) would be (3, 4, 2, 1, P P, f ood). If a span introduces raw ingredient or new location into the recipe, then o = 0; in <ref type="figure">Fig. 1</ref>, this occurs for each of the spans that represent raw ingredients as well as "oven" and "into loaf pan."</p><p>Given a recipe R, a set of connections C is valid for R if there is a one-to-one correspondence be- tween spans in R and connections in C, and if the origin indexes of connections in C are 0 or valid verb indexes in R, ∀(o, i, j, k, t syn , t sem ) ∈ C, o ∈ {Z | 0 ≤ o ≤ |E R |}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Action graph G</head><p>A recipe R and a set of connections C define an action graph, which is a directed graph G = (V, E). Each raw ingredient, verb, and argu- ment span is represented by a vertex in V . Each argument span vertex is connected to its asso- ciated verb vertex, and each connection c = (o, i, j, k, t syn , t sem ) adds a corresponding edge to E. Edges from connections with seman- tic type f ood propagate ingredients through the recipe; edges from connections with semantic type location propagate a location. <ref type="figure">Fig. 1</ref> shows an ac- tion graph. By following the edges, we can tell that the implicit food entity that is being baked in the final action has been formed from the set of ingredients in the mixing action and the bacon from e 4 and that the baking action occurs inside the oven preheated in e 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Probabilistic connection model</head><p>Our goal is, given a segmented recipe R, to deter- mine the most likely set of connections, and thus the most likely action graph. We model (1) a prior probability over C, P (C) (Sec. 3.1), and (2) the probability of seeing a segmented recipe R given a set of connections C, P (R|C) (Sec. 3.2). The most likely set of connections will maximize the joint probability: P (R|C)P (C). A summary of this model is presented in <ref type="figure" target="#fig_0">Fig. 2</ref>, and the details are described in the this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Connections prior model</head><p>The probability of a set of connections C depends on features of the incoming set of connections for each action. Let a destination subset d i ⊆ C be the subset of C that contains all connections that have i as the destination index. In <ref type="figure">Fig. 1</ref>, d 3 con- tains the connection from v 2 to the implicit object as well as a connection to "into loaf pan" with an origin index of 0. Using the chain rule, the proba- bility of C is equal to the product of the probability</p><p>• Input: A set of connections C and a recipe R segmented (Sec. 6) into its actions {e1 = (v1, a1), . . . , en = (vn, an)} • The joint probability of C and R is P (C, R) = P (C)P (R|C), each defined below:</p><p>1. Connections Prior (Sec. 3.1): P (C) = i P (di|d1, . . . , di−1) Define di as the list of connections with destination index i. Let cp = (o, i, j, k, t syn , t sem ) ∈ di. Then,</p><formula xml:id="formula_0">• P (di|d1, . . . , di−1) = P (vs(d i )) cp∈d i P (1(o → s k ij )|vs(d i ), d1, . . . , di−1, c1, . . . , cp−1) (a) P (vs(d i )): multinomial verb signature model (Sec. 3.1.1) (b) P (1(o → s k ij )|vs(d i ), d1, . . . , di−1, c1, .</formula><p>. . , cp−1): multinomial connection origin model, conditioned on the verb signature of di and all previous connections (Sec. 3.1.2) 2. Recipe Model (Sec. 3.2): P (R|C) = i P (ei|C, e1, . . . , ei−1) For brevity, define hi = (e1, . . . , ei−1).</p><p>• P (ei|C, hi) = P (vi|C, hi) j P (aij|C, hi) (Sec. 3.2) Define argument aij by its types and spans, aij = (t syn ij , t sem ij , Sij). of each of the destination subsets:</p><formula xml:id="formula_1">(a) P (vi|C, hi) = P (vi|gi): multinomial verb distribution conditioned on verb signature (Sec. 3.2) (b) P (aij|C, hi) = P (t syn ij , t sem ij |C, hi) s k ij ∈S ij P (s k ij |t syn ij , t sem ij , C, hi) i. P (t syn ij , t sem ij |C, hi): deterministic argument types model given connections (Sec. 3.2.1) ii. P (s k ij |t syn ij , t sem ij , C, hi):</formula><formula xml:id="formula_2">P (C) = i P (d i |d 1 , . . . , d i−1 ).</formula><p>The probability of each destination subset de- composes into two distributions, a verb signature model and a connection origin model:</p><formula xml:id="formula_3">P (d i |d 1 , . . . , d i−1 ) = P (vs(d i )) × cp∈d i P (1(o → s k ij )|vs(d i ), d i−1 1 , c p−1 1 ).</formula><p>We define each of these distributions below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Verb signature model</head><p>A destination subset d i deterministically defines a verb signature g i for verb v i based on the syntac- tic and semantic types of the connections in d i as well as whether or not each connection has a non- zero origin index. If the origin index is 0 for all connections in d i , we call v i a leaf. <ref type="figure">(In Fig, 1</ref>, v 1 (preheat) and v 2 (mix) are leafs.) The formal definition of a verb signature is as follows:</p><formula xml:id="formula_4">Definition 1</formula><p>The verb signature g i for a verb v i given a destination set d i consists of two parts:</p><formula xml:id="formula_5">1. type: {t syn | ∃(o, i, j, k, t syn , f ood) ∈ d i } 2. leaf: true iff (o, i, j, k, t syn , t sem ) ∈ d i ⇒ o = 0</formula><p>For example, in <ref type="figure">Fig. 1</ref>, the signature for the "mix" action is g 2 = ({DOBJ}, true) and the signature for the "lay" action is g 4 = ({DOBJ, P P }, f alse). Given that there are two syntactic types (i.e., DOBJ and P P ) and each verb signature can either be labeled as a leaf or not, there are eight possible verb signatures.</p><p>We define a deterministic function that re- turns the verb signature of a destination subset:</p><formula xml:id="formula_6">vs(d i ) = g i . P (vs(d i ))</formula><p>is a multinomial distri- bution over the possible verb signatures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Connection origin model</head><p>We define 1(o → s k ij ) as an indicator function that is 1 if there is a connection from the action with in- dex o to the span s k ij . The probability that a string span has a particular origin depends on (1) the verb signature of the span's corresponding verb, and (2) the previous connections. If, for example, g i has leaf= true, then the origin of s k ij must be 0. If an origin has been used in a previous connection, it is much less likely to be used again. <ref type="bibr">2</ref> We assume that a destination subset is a list of connections: if c p ∈ d i , we define c p−1 1 as the con- nections that are prior to c p in the list. Similarly,</p><formula xml:id="formula_7">d i−1 1</formula><p>is the set of destination sets (d 1 , . . . , d i−1 ). The connection origin model is a multinomial dis- tribution that defines the probability of an origin for a span conditioned on the verb signature and all previous connections:</p><formula xml:id="formula_8">P (1(o → s k ij )|vs(d i ), d i−1 1 , c p−1 1 ),</formula><p>where c p = (o, i, j, k, t syn , t sem ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Recipe model</head><p>Given a set of connections C for a recipe R, we can determine how the actions of the recipe inter- act and we can calculate the probability of gen- erating a set of recipe actions E R = {e 1 = (v 1 , a 1 ), . . . , e n = (v n , a n )}. Intuitively, R is more likely given C if the destinations of the con- nections are good text representations of the ori- gins. For example, a string span "oven" is much more likely to refer to the output of the action "Preheat the oven" than "Mix flour and sugar." We define the history h i of an action to be the set of all previous actions: h i = (e 1 , . . . , e i−1 ). The probability of a recipe R given a set of con- nections C can be factored by the chain rule:</p><formula xml:id="formula_9">P (R|C) = i P (e i |C, h i ).</formula><p>Given C and a history h i , we assume the verb and arguments of an action are independent:</p><formula xml:id="formula_10">P (e i |C, h i ) = P (v i |C, h i ) j P (a ij |C, h i ).</formula><p>Since the set of connections deterministically de- fines a verb signature g i for a verb v i , we can sim- plify P (v i |C, h i ) to the multinomial distribution P (v i |g i ). For example, if g i defines the verb to have an ingredient direct object, then the probabil- ity of "preheat" given that signature will be lower than the probability of "mix."</p><p>The probability of an argument a ij = (t syn ij , t sem ij , S ij ) given the connections and history decomposes as follows:</p><formula xml:id="formula_11">P (a ij |C, h i ) = P (t syn ij , t sem ij |C, h i ) × P (S ij |t syn ij , t sem ij , C, h i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Argument types model</head><p>The first distribution, P (t syn ij , t sem ij |C, h i ), ensures that the syntactic and semantic types of the argu- ment match the syntactic and semantic type of the incoming connections to spans of that argument. The probability is 1 if all the types match, 0 oth- erwise. For example, in <ref type="figure">Fig. 1</ref>, this distribution would prevent a connection from the "preheat" ac- tion to the food argument a 42 , i.e., "over the top," since the semantic types would not match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">String span models</head><p>The second distribution, P (S ij |t syn ij , t sem ij , C, h i ), models how likely it is to generate a particular string span given the types of its encompassing ar- gument, the connections, and history. We assume the probability of each span is independent:</p><formula xml:id="formula_12">P (Sij|t syn ij , t sem ij , C, hi) = s k ij ∈S ij P (s k ij |t syn ij , t sem ij , C, hi).</formula><p>We break this distribution into three cases. To help describe the separate cases we define the function origin(s, C) to determine the origin in- dex of the connection in C to the span s. That is, origin(s k ij , C) = o ⇔ ∃(o, i, j, k, t syn , t sem ) ∈ C. Part-composite model When the encompassing argument is a food and the origin is a previous verb (i.e., P (s k ij |t syn ij , t sem ij = f ood, origin(s k ij ) = 0, C, h i )), then the probability of the span depends on the ingredients that the span represents given the connections in C. For example, "dressing" is more likely given ingredients "oil" and "vinegar" than given "chicken" and "noodles". We use IBM Model 1 ( <ref type="bibr" target="#b6">Brown et al., 1993</ref>) to model the prob- ability of a composite destination phrase given a set of origin food tokens. Let f ood(s k ij , C) be the set of spans in food arguments such that there is a directed path from those arguments to s k ij . IBM Model 1 defines the probability of a span given the propagated food spans, P (s k ij |f ood(s k ij , C)). 3 Raw food model When the encompassing ar- gument is a food but the origin index is 0 (i.e., P (s k ij |t syn ij , t sem ij = f ood, origin(s k ij ) = 0, C, h i )), then there is no flow of ingredients into the span. A span that represents a newly intro- duced raw ingredient (e.g., "bacon" in e 4 of <ref type="figure">Fig. 1</ref>) should have a high probability. However, spans that denote the output of actions (e.g, 'batter," "ba- nana mixture") should have low probability. We use a na¨ıvena¨ıve Bayes model over the tokens in the span P (s|is raw) = P (w |is raw) where w is the th token in s (e.g., "mixture" would have a very low probability but "flour" would be likely). P (S ij |t syn ij , t sem ij , C, h) models the appropriate- ness of the origin action's location for the destina- tion. If the string span is not implicit, the model deterministically relies on string match between the span and the location argument of the verb at the origin index. For example, the probability of "the preheated oven" conditioned on an origin with location "oven" is 1, but 0 for an origin with location "bowl." If the span s k ij is empty, we use a multinomial model P (loc(origin(s k ij , C))|v i ) that determines how likely it is that an action v i occurs in the location of the origin verb. For ex- ample, baking generally happens in an oven and grilling on a grill, but not vice versa. For example, in <ref type="figure">Fig. 1</ref>, the probability of the location span of "bake" is determined by P ("oven" | "bake").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Local Search</head><p>Connections among actions and arguments iden- tify which ingredients are being used by which action. For example, in <ref type="figure">Fig. 1</ref>, we know that we are baking something that contains all the ingre- dients introduced in e 2 and e 4 because there is a path of connections from the introduction of the raw ingredients to the implicit object of "bake" . We cannot make decisions about the origins of argu- ments independently; the likelihood of each edge depends on the other edges. Identifying the most likely set of connections is, therefore, intractable.</p><p>We adopt a local search approach to infer the best set of connections. <ref type="bibr">4</ref> We initialize the set of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Pseudocode for learning P (C, R)</head><p>Input: Initialized P (C, R), recipe dataset R Repeat until convergence: E-step: Update C ←− arg max C P (C, R) for each R ∈ R using local search (Sec. 4) M-step: Update parameters of P (C, R) using action graphs generated in E-step Return P (C, R) connections using a sequential algorithm that con- nects the output of each event to an argument of the following event, which is a strong baseline as shown in Sec. 8. We score potential local search operators that can be applied to the current set of connections C and make a greedy selection that improves P (C, R) the most until no search opera- tor can improve the probability. We constrain the search so all verbs have a direct object (i.e., im- plicit direct objects connect to a previous action).</p><p>We employ three types of search operators (see <ref type="figure" target="#fig_1">Fig. 3</ref> for details). OP ADD changes the origin in- dex of a connection in C from 0 to the index of an event. OP 2SWAP swaps the origin indexes of two connections. This works even if one of the origin indexes is 0. OP 3SWAP rotates the origin indexes of three connections. This works even if one of the origin indexes is 0. For efficiency rea- sons, we only allow 3-way swaps with destination indexes within 4 events of each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Learning</head><p>We use hard EM to learn the probabilistic mod- els. Pseudocode is given in Alg. 1. At each itera- tion, we use our local search algorithm and the cur- rent probabilistic models to annotate each recipe in the data set with its most likely set of connec- tions C <ref type="figure">(Sec. 4)</ref>. Then, we re-estimate the param- eters of the probabilistic models using the recipe- connections pairs as training data. A small (33 recipes) development set was used to determine when to stop the iterations. Experimental details and model initialization are described in Sec. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Segmentation</head><p>Our inference and learning algorithms assume as input a recipe segmented into a set of events E R = { <ref type="figure">(v 1 , a 1 )</ref>, . . . , (v n , a n )}. We designed a segmen- tation system that could be trained on our un- annotated data set of mostly imperative sentences. dency parsing ( <ref type="bibr" target="#b34">Zhang et al., 2014</ref>).</p><p>Our system achieves an F1 score of 95.6% on the task of identifying the correct verbs in the test set. <ref type="bibr">5</ref> Segmentation model We define a generative model for recipes as:</p><formula xml:id="formula_13">P (R) = P (n) n i P (v i )P (m | v i ) m j=1 P (a ij ).</formula><p>We first select a number of verbs n in the recipe from a geometric distribution. Given the number of verbs, we select a set of verbs V = {v 1 , . . . , v n } using a multinomial distribution. For each verb v i , we select a number of arguments m from a sep- arate multinomial distribution that has the prob- ability of 0, 1, 2, or 3+ arguments given the verb, P (m | v i ). For each argument, we gen- erate a string using a bigram model, P (a ij ) = P (w |w −1 ), where w is the th word of a ij . Inference Given tokenized sentence T = (w 1 , . . . , w k ), we enumerate all possible segmen- tations and choose the one with the highest prob- ability. To keep this efficient, we use a closed set of possible verbs and assume a closed set of words (e.g., prepositions, adverbs) can only follow the start token in the argument bigram model. Thus, annotating the verbs in a sentence determines a unique set of argument strings. Despite scoring the segmentations for all possible sets of verbs, we found the process to be very efficient in practice.</p><p>Learning For unsupervised learning, we again employ a hard EM approach. We initialize our models, segment all of the training data, re- estimate the parameters, and iterate these steps un- til performance on a development set converges.</p><p>We estimate the initial verb multinomial model using counts from the first word of each sentence in the dataset, which are normally verbs in imper- ative sentences, and filter out any words that have no verb synsets in WordNet <ref type="bibr" target="#b20">(Miller, 1995)</ref>. All other models are initialized to be uniform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Setup</head><p>Data Set We collected 2456 recipes (with over 23,000 sentences) from allrecipes.com by search- ing for 20 dish names (e.g., including "banana muffins", and "deviled eggs"). We randomly sam- pled, removed, and hand labeled 33 recipes for a development set and 100 recipes for test. All mod- els were trained on the unannotated recipes; the dev set was used to determine the stopping point for training. Each recipe in the test set has 13 ac- tions on average.</p><p>Recipe pre-processing To pre-process each recipe, we first use the segmentation system de- scribed in Sec. 6. Then, we use a string classifi- cation model to determine the semantic type (e.g., f ood, location, or other) of an argument based on its spans. We identify spans as raw ingredients based on string match heuristics (e.g., in <ref type="figure">Fig. 1</ref>, the span "crushed crackers" represents the ingredients "crushed butter-flavored crackers"). We stem all words and ignore function words.</p><p>Sequential Baseline Because most connections are sequential -i.e., argument spans are most of- ten connected to the output of the previous verb -sequential connections make a strong baseline; we connect the output of each predicate to the first available argument span of the following predi- cate. If no argument exists, an implicit argument is created. We run this baseline with and without first identifying raw ingredients in the recipe; if raw in- gredient spans are identified, the baseline will not connect the previous event to those spans. Perfor- mance suffers significantly if the raw ingredients are not identified beforehand.</p><p>Evaluation metrics We report F-measure by comparing the predicted connections from actions to spans (i.e., where the origin index &gt; 0) against gold standard annotations. We don't evaluate con- nections to raw ingredients as we create those con- nections during pre-processing (see Sec. 7).</p><p>Model initialization The verb signature model (Sec. 3.2) is initialized by first identifying f ood arguments using string overlap with the ingredi- ent list. All other arguments' types are considered unknown, and partial counts were awarded to all verb signatures consistent with the partial infor- mation. The first verb in each recipe was assumed to be the only leaf. The string classification model for the pre-processing step was initialized by us- ing the initialized verb signature model to identify the types of DOBJ arguments. The string classi- fication model was estimated using the argument tokens given the types. We initialized the part- composite model (Sec. 3.2.2) so that exact string matches between ingredients and spans are given Algorithm Prec Rec F1 Automatic segmentations Sequential baseline 55.7 52.7 54.1 Sequential baseline w/ ingredients 60.4 57.2 58.8 Our model before EM 65.8 62.7 64.2 Our model after EM 68.7 65.0 66.8 Oracle segmentations Sequential baseline 67.8 65.2 66.5 Sequential baseline w/ ingredients 73.5 70.7 72.0 Our model before EM 77.1 74.8 75.9 Our model after EM 81.6 78.5 80.0  high probabilities and those without are given low probabilities. Given the initialized string classifi- cation model, the raw food model (Sec. 3.2.2) is initialized counting whether or not tokens in food arguments occur in the ingredient list. The proba- bility of an implicit location (Sec. 3.2.2) is initial- ized to a hand-tuned value using the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head><p>Quantitative Results We trained our model for four iterations of hard EM until performance con- verged on the development set. <ref type="table" target="#tab_1">Table 1</ref> presents our results on the test set. We compare our model to the sequential baselines using both the output of our segmentation system and oracle segmen- tations. We perform significantly better than the sequential baselines, with an increase in F1 of 8 points over the more competitive baseline us- ing our segmentation system and an increase of 8 points using the oracle segmentations.</p><p>Qualitative Results We find that the learned models demonstrate interpretable cooking knowl- edge. <ref type="table">Table 3</ref> shows the top composite tokens for different ingredients as learned by the part- composite model (Sec. 3.2.2). The composite tokens show parts of the ingredient (e.g., after "eggs" can be split into "whites" or "yolks") or <ref type="table">Table 4</ref>: The top verb signatures for example verbs. The syntactic types identify which argu- ments of the verb are foods and "leaf" means no arguments of the verb connect to previous actions.</p><formula xml:id="formula_14">Verb Top verb signature (%) add {DOBJ, P P } 58% {DOBJ} 27% combine {DOBJ}:leaf 68% {DOBJ} 17% bake {DOBJ} 95% grease {}:leaf 75% pour {DOBJ, P P } 68% {DOBJ} 27% reduce {P P } 90% {DOBJ} 8%</formula><p>composites that are likely to contain an ingredi- ent (e.g., "flour" is generally found in "batter" and "dough"). Unsurprisingly, the word "mixture" is one of the top words to describe a combina- tion of ingredients, regardless of the ingredient. The model also learns modifiers that describe key properties of ingredients (e.g., flour is "dry" but bananas are "wet") which is important when eval- uating connections for sentences such as "Fold the wet mixture into the dry ingredients." <ref type="table" target="#tab_2">Table 2</ref> shows the location preferences of verbs learned by the location model (Sec. 3.2.2). Some verbs show strong preferences on locations (e.g., "bake" occurs in an oven, "mix" in a bowl). The top location for a "boil" action is in "water," but in other recipes "water" is an ingredient.</p><p>Finally, <ref type="table">Table 4</ref> shows learned verb signatures. For example, "add" tends to be a non-leaf action, and can take one or two food arguments (e.g., one food argument: "Heat the pan. Add onions." vs. two food arguments: "Add the wet mixture to the dry mixture.") We learn that the most likely verb signature for "add" has two food arguments; since over 74% of the occurrences of "add" in the dataset only have one visible argument, the seg- mentation alone is not enough to determine the signature.</p><p>Errors Finally, we performed an error analysis on the development set. 24% of the errors were due to missing or incorrect actions caused by seg- mentation errors. Among the actions that were segmented correctly, 82% of the outgoing connec- tions were sequential. Of those, our system missed 17.6% of the sequential connections and 18.3% of the non-sequential connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ingredient</head><p>Top composite tokens eggs egg, yolk, mixture, noodles, whites, cook, top, potato, cold, fill beef beef, mixture, grease, meat, excess, cook, top, loaf, sauce, ground flour flour, mixture, dough, batter, top, crust, ingredients, sauce, dry, pie noodles noodles, cook, mixture, egg, sauce, top, meat, drain, pasta, layer chicken chicken, mixture, salad, cook, dressing, pasta, soup, breast, vegetables, noodles pumpkin pumpkin, mixture, pie, filling, temperature, seeds, mash, oven, crust, dough bananas banana, mixture, batter, muffin, bread, egg, wet, cup, ingredients, slice <ref type="table">Table 3</ref>: Examples of ingredients with their top inferred composite words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related work</head><p>Our work relates to a substantial body of research that transforms natural language instructions into actionable plans <ref type="bibr" target="#b0">(Artzi and Zettlemoyer, 2013</ref><ref type="bibr" target="#b8">, Chen and Mooney, 2011</ref><ref type="bibr" target="#b5">, Branavan et al., 2011</ref><ref type="bibr" target="#b4">, Branavan et al., 2009</ref><ref type="bibr">, McMahon et al., 2006</ref>). Most of these approaches do interactive learning in virtual environments or simulations, while we learn from the redundancy seen in the text of dif- ferent instances of similar recipes. There is also significant related work on su- pervised learning for instructions. A recent se- ries of studies have explored parsing of cook- ing recipes <ref type="bibr" target="#b21">(Mori et al., 2012;</ref><ref type="bibr" target="#b22">Mori et al., 2014;</ref><ref type="bibr" target="#b17">Maeta et al., 2015</ref>). However, they assume anno- tated data, study Japanese recipes, and make edge connections independently without taking into ac- count the flow of ingredients. <ref type="bibr" target="#b31">Tasse and Smith (2008)</ref> develops annotation for English recipes, but do not mark connections from implicit roles, and only studied segmentation models. <ref type="bibr" target="#b15">Lau et al. (2009)</ref> develop models to interpret how-to in- structions, but also assume supervision, and do not make connections between different actions.</p><p>Data-driven extraction of cooking knowledge has been explored in the context of building a cooking ontology ( <ref type="bibr" target="#b13">Gaillard et al., 2012;</ref><ref type="bibr" target="#b23">Nanba et al., 2014</ref>). In contrast, our work induces prob- abilistic cooking knowledge as part of unsuper- vised learning process for understanding recipes. Cooking knowledge is also closely related to script knowledge, but most prior work focus on newswire and children's books rather than proce- dural language ( <ref type="bibr" target="#b12">Fujiki et al., 2003;</ref><ref type="bibr" target="#b7">Chambers and Jurafsky, 2009;</ref><ref type="bibr" target="#b25">Pichotta and Mooney, 2014;</ref><ref type="bibr" target="#b1">Balasubramanian et al., 2013</ref>) or rely on crowdsourced descriptions to learn procedural knowledge <ref type="bibr" target="#b26">(Regneri et al., 2010;</ref><ref type="bibr" target="#b27">Regneri et al., 2011;</ref><ref type="bibr" target="#b11">Frermann et al., 2014</ref>). There is work on related, but dis- tinct, tasks that use recipes, including identifying actionable refinements from online recipe reviews <ref type="bibr" target="#b9">(Druck and Pang, 2012)</ref> and extracting structured information from ingredient lists <ref type="bibr" target="#b14">(Greene, 2015)</ref> Cooking recipes have also been studied in the context of grounded language learning, e.g., to build robots that can cook (e.g., <ref type="bibr" target="#b3">Bollini et al., 2013</ref><ref type="bibr" target="#b2">, Beetz et al., 2011</ref>, or to align cooking videos to natural language descriptions of actions ( <ref type="bibr" target="#b28">Regneri et al., 2013</ref>) or recipe texts <ref type="bibr" target="#b18">(Malmaud et al., 2014;</ref><ref type="bibr" target="#b19">Malmaud et al., 2015)</ref>. Our work com- plements these efforts by recovering fine-grained procedural semantics from text alone.</p><p>Finally, detection and resolution of implicit ar- guments is an instance of zero anaphora detec- tion and resolution <ref type="bibr" target="#b30">(Silberer and Anette, 2012</ref><ref type="bibr" target="#b32">, Tetreault 2002</ref><ref type="bibr" target="#b33">, Whittemore et al., 1991</ref><ref type="bibr" target="#b24">, Palmer et al., 1986</ref>. We present an empirical approach for understanding these phenomena in instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>We presented unsupervised methods for segment- ing and identifying latent connections among ac- tions in recipe text. Our model outperformed a strong linear baseline, while learning a variety of domain knowledge, such as verb signatures and probable ingredient components for different com- posites. Future work includes learning a more comprehensive model of locations (e.g., identify- ing nested locations such as an oven and a pan in the oven), enriching action graphs with greater se- mantic coverage (e.g., durations, tools, amounts), and training and evaluating on larger datasets. We also plan to use our techniques to support related tasks, such as instructional recipe generation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Summary of the joint probabilistic model P (C, R) over connection set C and recipe R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The three types of search operators. For swaps, one of the origins can be 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Performance of our algorithm against the 
sequential baselines. 

Verb 
Top location tokens 

bake 
oven -55.4% 
min -0.7% 
mix 
bowl -32.6% 
hand -0.9% 
press 
pan -24.7% 
dish -6.5% 
stir 
bowl -5.5% 
skillet -2.0% 
fry 
heat -11.9% 
skillet -10.2% 
cool 
rack -10.5% 
pan -3.8% 
boil 
water -15.5% 
saucepan -5.2% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The top scoring location token for exam-
ple verbs. The percentage is the percent of times 
the verb has that as a visible location token. 

</table></figure>

			<note place="foot" n="1"> The goal of representing common sense world knowledge about actions and objects also drives theories of frame semantics (Fillmore, 1982) and script knowledge (Schank and Abelson, 1977). However, our focus is on inducing this style of knowledge automatically from procedural texts.</note>

			<note place="foot" n="2"> A counterexample in the cooking domain is separating egg yolks from egg whites to be used in separate components, only to be incorporated again in a later action.</note>

			<note place="foot" n="3"> IBM Model 1 cannot handle implicit arguments. In this case, we model the probability of having an implicit food argument given the length of the connection (i.e., implicit food arguments nearly deterministically connect to the previous action). The probability of non-empty string spans is scaled accordingly to ensure a valid probability distribution.</note>

			<note place="foot" n="4"> Similar local search methods have been shown to work well for other NLP tasks, including recent work on depen</note>

			<note place="foot" n="5"> Early efforts using a state-of-the-art parser could only achieve an F1 score of 73.6% for identifying verbs, likely due to a lack of imperative sentences in the training data. This result motivated us to develop our segmentation system.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers, Mike Lewis, Dan Weld, Yoav Artzi, Antoine Bosselut, Kenton Lee, Luheng He, Mark Yatskar, and Gagan Bansal for helpful comments, and Polina Kuznetsova for the preliminary work. This research was sup-ported in part by the Intel Science and Technol-ogy Center for Pervasive Computing (ISTC-PC) and the NSF (IIS-1252835 and IIS-1524371).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generating coherent event schemas at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niranjan</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods on Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1721" to="1731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robotic roommates making pancakes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Beetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Klank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingo</forename><surname>Kresse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenz</forename><surname>Mosenlechner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejan</forename><surname>Pangercic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ruhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Tenorth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids)</title>
		<meeting>the 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Interpreting and executing recipes with a cooking robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bollini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Robotics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="481" to="495" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Non-linear monte-carlo search in civilization ii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R K</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Second International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2404" to="2410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised learning of narrative schemas and their participants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI2011)</title>
		<meeting>the 25th AAAI Conference on Artificial Intelligence (AAAI2011)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spice it up? Mining refinements to online instructions from user generated content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Druck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="545" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Frame semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>South Korea</publisher>
			<biblScope unit="page" from="111" to="137" />
			<pubPlace>Seoul</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hierarchical bayesian model for unsupervised induction of script knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lea</forename><surname>Frermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic acquisition of script knowledge from a text collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Fujiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetsugu</forename><surname>Nanba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Conference on European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Tenth Conference on European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="91" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting generic cooking adaptation knowledge for the TAAABLE case-based reasoning system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuelle</forename><surname>Gaillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Nauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amélie</forename><surname>Cordier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Cooking with Computers (CwC)</title>
		<meeting>the 1st Workshop on Cooking with Computers (CwC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Extracting structured data from recipes using conditional random fields. The New York Times Open Blog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erica</forename><surname>Greene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Interpreting written how-to instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Drews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-First International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1433" to="1438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Walk the talk: Connecting language, knowledge, and action in route instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Macmahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Stankiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kuipers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st National Conference on Artificial Intelligence</title>
		<meeting>the 21st National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1475" to="1482" />
		</imprint>
	</monogr>
	<note>AAAI&apos;06</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A framework for procedural text understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokuni</forename><surname>Maeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Parsing Technologies</title>
		<meeting>the 14th International Conference on Parsing Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="50" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Cooking with semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Earl</forename><forename type="middle">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Workshop on Semantic Parsing</title>
		<meeting>the ACL 2014 Workshop on Semantic Parsing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">What&apos;s cookin&apos;? Interpreting cooking videos using text, speech and vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A machine learning approach to recipe text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Yamakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichiro</forename><surname>Yoshino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Cooking with Computers (CwC)</title>
		<meeting>the 1st Workshop on Cooking with Computers (CwC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Flow graph corpus from recipe texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokuni</forename><surname>Maeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Yamakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Construction of a cooking ontology from cooking recipes and patents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetsugu</forename><surname>Nanba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Doi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miho</forename><surname>Tsujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiyuki</forename><surname>Takezawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazutoshi</forename><surname>Sumiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication</title>
		<meeting>the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recovering implicit information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">S</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deborah</forename><forename type="middle">A</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Schiffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynette</forename><surname>Hirschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcia</forename><surname>Linebarger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dowding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 24th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="10" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Statistical script learning with multi-argument events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pichotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning script knowledge with web experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="979" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning script participants from unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the Conference on Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="463" to="470" />
		</imprint>
	</monogr>
	<note>Josef Ruppenhofer, and Manfred Pinkal</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dominikus Wetzel, Stefan Thater, Bernt Schiele, and Manfred Pinkal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Regneri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="25" to="36" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Grounding action descriptions in videos</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scripts, plans, goals and understanding : an inquiry into human knowledge structures. The Artificial intelligence series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Schank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Abelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">L. Erlbaum</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Casting implicit role linking as an anaphora resolution task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><surname>Silberer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the First Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>Proceedings of the Sixth International Workshop on Semantic Evaluation</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">SOUR CREAM: Toward semantic processing of recipes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>CMU-LTI-08-005</idno>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Implicit role reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Joel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Reference Resolution for Natural Language Processing</title>
		<meeting>the International Symposium on Reference Resolution for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="109" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Event-building through role-filling and anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Whittemore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Macpherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 29th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Greed is good if randomized: New inference for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1013" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On the subject of bare imperatives in english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">M</forename><surname>Zwicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On Language: Rhetorica, Phonologica, Syntactica-A Festschrift for Robert P. Stockwell from His Friends and Colleagues</title>
		<editor>C. Duncan-Rose and T. Vennemann</editor>
		<meeting><address><addrLine>Routledge, London</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="437" to="450" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
