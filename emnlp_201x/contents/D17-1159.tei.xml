<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
							<email>marcheggiani@uva.nl ititov@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ILLC</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ILLC</orgName>
								<orgName type="institution" key="instit2">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">ILCC</orgName>
								<orgName type="department" key="dep2">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1506" to="1515"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard NLP pipeline. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of neural networks operating on graphs, suited to model syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence en-coders, producing latent feature representations of words in a sentence. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and En-glish.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic role labeling (SRL) ( <ref type="bibr" target="#b13">Gildea and Jurafsky, 2002</ref>) can be informally described as the task of discovering who did what to whom. For ex- ample, consider an SRL dependency graph shown above the sentence in <ref type="figure" target="#fig_0">Figure 1</ref>. Formally, the task includes (1) detection of predicates (e.g., makes); (2) labeling the predicates with a sense from a sense inventory (e.g., make.01); (3) identifying and assigning arguments to semantic roles (e.g., Sequa is A0, i.e., an agent / 'doer' for the corre- sponding predicate, and engines is A1, i.e., a pa- tient / 'an affected entity'). SRL is often regarded as an important step in the standard NLP pipeline, providing information to downstream tasks such as information extraction and question answering. The semantic representations are closely re- lated to syntactic ones, even though the syntax- semantics interface is far from trivial <ref type="bibr" target="#b26">(Levin, 1993)</ref>. For example, one can observe that many arcs in the syntactic dependency graph (shown in black below the sentence in <ref type="figure" target="#fig_0">Figure 1</ref>) are mir- rored in the semantic dependency graph. Given these similarities and also because of availability of accurate syntactic parsers for many languages, it seems natural to exploit syntactic information when predicting semantics. Though historically most SRL approaches did rely on syntax <ref type="bibr" target="#b43">(Thompson et al., 2003;</ref><ref type="bibr" target="#b36">Pradhan et al., 2005;</ref><ref type="bibr" target="#b37">Punyakanok et al., 2008;</ref><ref type="bibr" target="#b18">Johansson and Nugues, 2008)</ref>, the last generation of SRL models put syntax aside in fa- vor of neural sequence models, namely LSTMs ( <ref type="bibr" target="#b46">Zhou and Xu, 2015;</ref><ref type="bibr" target="#b30">Marcheggiani et al., 2017)</ref>, and outperformed syntactically-driven methods on standard benchmarks. We believe that one of the reasons for this radical choice is the lack of sim- ple and effective methods for incorporating syn- tactic information into sequential neural networks (namely, at the level of words). In this paper we propose one way how to address this limitation.</p><p>Specifically, we rely on graph convolutional networks (GCNs) ( <ref type="bibr" target="#b6">Duvenaud et al., 2015;</ref><ref type="bibr" target="#b22">Kipf and Welling, 2017;</ref><ref type="bibr" target="#b19">Kearnes et al., 2016)</ref>, a recent class of multilayer neural networks operating on graphs. For every node in the graph (in our case a word in a sentence), GCN encodes relevant in- formation about its neighborhood as a real-valued feature vector. GCNs have been studied largely in the context of undirected unlabeled graphs. We in- troduce a version of GCNs for modeling syntactic dependency structures and generally applicable to labeled directed graphs.</p><p>One layer GCN encodes only information about immediate neighbors and K layers are needed to encode K-order neighborhoods (i.e., informa- tion about nodes at most K hops aways). This contrasts with recurrent and recursive neural net- works <ref type="bibr" target="#b8">(Elman, 1990;</ref><ref type="bibr" target="#b40">Socher et al., 2013</ref>) which, at least in theory, can capture statistical dependencies across unbounded paths in a trees or in a sequence. However, as we will further discuss in Section 3.3, this is not a serious limitation when GCNs are used in combination with encoders based on recurrent networks (LSTMs). When we stack GCNs on top of LSTM layers, we obtain a substantial improve- ment over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark <ref type="bibr">(CoNLL-2009)</ref>, both for En- glish and Chinese. <ref type="bibr">1</ref> Interestingly, again unlike recursive neural net- works, GCNs do not constrain the graph to be a tree. We believe that there are many applica- tions in NLP, where GCN-based encoders of sen- tences or even documents can be used to incor- porate knowledge about linguistic structures (e.g., representations of syntax, semantics or discourse). For example, GCNs can take as input combined syntactic-semantic graphs (e.g., the entire graph from <ref type="figure" target="#fig_0">Figure 1</ref>) and be used within downstream tasks such as machine translation or question an- swering. However, we leave this for future work and here solely focus on SRL.</p><p>The contributions of this paper can be summa- rized as follows:</p><p>• we are the first to show that GCNs are effec- tive for NLP;</p><p>• we propose a generalization of GCNs suited <ref type="bibr">1</ref> The code is available at https://github.com/ diegma/neural-dep-srl.</p><p>to encoding syntactic information at word level;</p><p>• we propose a GCN-based SRL model and obtain state-of-the-art results on English and Chinese portions of the CoNLL-2009 dataset;</p><p>• we show that bidirectional LSTMs and syntax-based GCNs have complementary modeling power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Graph Convolutional Networks</head><p>In this section we describe GCNs of <ref type="bibr" target="#b22">Kipf and Welling (2017)</ref>. Please refer to <ref type="bibr" target="#b14">Gilmer et al. (2017)</ref> for a comprehensive overview of GCN ver- sions.</p><p>GCNs are neural networks operating on graphs and inducing features of nodes (i.e., real-valued vectors / embeddings) based on properties of their neighborhoods. In <ref type="bibr" target="#b22">Kipf and Welling (2017)</ref>, they were shown to be very effective for the node clas- sification task: the classifier was estimated jointly with a GCN, so that the induced node features were informative for the node classification prob- lem. Depending on how many layers of convolu- tion are used, GCNs can capture information only about immediate neighbors (with one layer of con- volution) or any nodes at most K hops aways (if K layers are stacked on top of each other).</p><p>More formally, consider an undirected graph G = (V, E), where V (|V | = n) and E are sets of nodes and edges, respectively. <ref type="bibr" target="#b22">Kipf and Welling (2017)</ref> assume that edges contain all the self-loops, i.e., (v, v) 2 E for any v. We can de- fine a matrix X 2 R m⇥n with each its column x v 2 R m (v 2 V) encoding node features. The vectors can either encode genuine features (e.g., this vector can encode the title of a paper if citation graphs are considered) or be a one-hot vector. The node representation, encoding information about its immediate neighbors, is computed as</p><formula xml:id="formula_0">h v = ReLU 0 @ X u2N (v) (W x u + b) 1 A , (1)</formula><p>where W 2 R m⇥m and b 2 R m are a weight ma- trix and a bias, respectively; N (v) are neighbors of v; ReLU is the rectifier linear unit activation function. <ref type="bibr">2</ref> Note that v 2 N (v) (because of self- loops), so the input feature representation of v (i.e. x v ) affects its induced representation h v .</p><p>Lane disputed those estimates Parameter matrices are sub-indexed with syntactic functions, and apostrophes (e.g., subj') signify that information flows in the direction opposite of the dependency arcs (i.e., from dependents to heads).</p><formula xml:id="formula_1">ReLU (·) ReLU (·) ReLU (·) ReLU (·) W (1) self W (1) self W (1) self W (1) self W ( 1 ) s u b j W (1 ) ob j W ( 1 ) n m o d W ( 1 ) n m o d W (1 ) ob j W ( 1 ) s u b j ReLU (·) ReLU (·) ReLU (·) ReLU (·) W (2) self W (2) self W (2) self W (2) self W ( 2 ) s u b j W ( 2 ) s u b j W (2 ) ob j W (2 ) ob j W ( 2 ) n m o d W ( 2 ) n m o d … … … … NMOD SBJ OBJ</formula><p>As in standard convolutional networks ( <ref type="bibr" target="#b24">LeCun et al., 2001</ref>), by stacking GCN layers one can in- corporate higher degree neighborhoods:</p><formula xml:id="formula_2">h (k+1) v = ReLU 0 @ X u2N (v) W (k) h (k) u + b (k) 1 A</formula><p>where k denotes the layer number and h</p><formula xml:id="formula_3">(1) v = x v .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Syntactic GCNs</head><p>As syntactic dependency trees are directed and la- beled (we refer to the dependency labels as syn- tactic functions), we first need to modify the com- putation in order to incorporate label information (Section 3.1). In the subsequent section, we incor- porate gates in GCNs, so that the model can decide which edges are more relevant to the task in ques- tion. Having gates is also important as we rely on automatically predicted syntactic representations, and the gates can detect and downweight poten- tially erroneous edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Incorporating directions and labels</head><p>Now, we introduce a generalization of GCNs ap- propriate for syntactic dependency trees, and in general, for directed labeled graphs. First note that there is no reason to assume that information flows only along the syntactic dependency arcs (e.g., from makes to Sequa), so we allow it to flow in the opposite direction as well (i.e., from depen- dents to heads). We use a graph G = (V, E), where the edge set contains all pairs of nodes (i.e., words) adjacent in the dependency tree. In our example, both (Sequa, makes) and (makes, Sequa) belong to the edge set. The graph is labeled, and the label L(u, v) for (u, v) 2 E contains both information about the syntactic function and indicates whether the edge is in the same or opposite direction as the syntactic dependency arc. For example, the la- bel for (makes, Sequa) is subj, whereas the label for (Sequa, makes) is subj 0 , with the apostrophe indicating that the edge is in the direction oppo- site to the corresponding syntactic arc. Similarly, self-loops will have label self . Consequently, we can simply assume that the GCN parameters are label-specific, resulting in the following computa- tion, also illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>:</p><formula xml:id="formula_4">h (k+1) v = ReLU 0 @ X u2N (v) W (k) L(u,v) h (k) u + b (k) L(u,v) 1 A .</formula><p>This model is over-parameterized, 3 especially given that SRL datasets are moderately sized, by deep learning standards. So instead of learning the GCN parameters directly, we define them as</p><formula xml:id="formula_5">W (k) L(u,v) = V (k) dir(u,v) ,<label>(2)</label></formula><p>where dir(u, v) indicates whether the edge (u, v) is directed (1) along, (2) in the opposite direction to the syntactic dependency arc, or (3) is a self- loop; V (k) dir(u,v) 2 R m⇥m . Our simplification cap- tures the intuition that information should be prop- agated differently along edges depending whether this is a head-to-dependent or dependent-to-head edge (i.e., along or opposite the corresponding syntactic arc) and whether it is a self-loop. So we do not share any parameters between these three very different edge types. Syntactic functions are important, but perhaps less crucial, so they are en- coded only in the feature vectors b L(u,v) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Edge-wise gating</head><p>Uniformly accepting information from all neigh- boring nodes may not be appropriate for the SRL setting. For example, we see in <ref type="figure" target="#fig_0">Figure 1</ref> that many semantic arcs just mirror their syntactic counter- parts, so they may need to be up-weighted. More- over, we rely on automatically predicted syntactic structures, and, even for English, syntactic parsers are far from being perfect, especially when used out-of-domain. It is risky for a downstream ap- plication to rely on a potentially wrong syntactic edge, so the corresponding message in the neural network may need to be down-weighted.</p><p>In order to address the above issues, inspired by recent literature (van den <ref type="bibr">Oord et al., 2016;</ref><ref type="bibr" target="#b5">Dauphin et al., 2016)</ref>, we calculate for each edge node pair a scalar gate of the form</p><formula xml:id="formula_6">g (k) u,v = ⇣ h (k) u · ˆ v (k) dir(u,v) + ˆ b (k) L(u,v) ⌘ ,<label>(3)</label></formula><p>where is the logistic sigmoid function,</p><formula xml:id="formula_7">ˆ v (k) dir(u,v) 2 R m andˆbandˆandˆb (k)</formula><p>L(u,v) 2 R are weights and a bias for the gate. With this additional gating mechanism, the final syntactic GCN computation is formulated as</p><formula xml:id="formula_8">h (k+1) v = ReLU ( X u2N (v) g (k) v,u (V (k) dir(u,v) h (k) u + b (k) L(u,v) )). (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Complementarity of GCNs and LSTMs</head><p>The inability of GCNs to capture dependencies between nodes far away from each other in the graph may seem like a serious problem, especially in the context of SRL: paths between predicates and arguments often include many dependency arcs <ref type="bibr" target="#b38">(Roth and Lapata, 2016)</ref>. However, when graph convolution is performed on top of LSTM states (i.e., LSTM states serve as input</p><formula xml:id="formula_9">x v = h (1) v</formula><p>to GCN) rather than static word embeddings, GCN may not need to capture more than a couple of hops.</p><p>To elaborate on this, let us speculate what role GCNs would play when used in combinations with LSTMs, given that LSTMs have already been shown very effective for SRL ( <ref type="bibr" target="#b46">Zhou and Xu, 2015;</ref><ref type="bibr" target="#b30">Marcheggiani et al., 2017)</ref>. Though LSTMs are capable of capturing at least some degree of syn- tax ( <ref type="bibr" target="#b29">Linzen et al., 2016</ref>) without explicit syntactic supervision, SRL datasets are moderately sized, so LSTM models may still struggle with harder cases. Typically, harder cases for SRL involve ar- guments far away from their predicates. In fact, 20% and 30% of arguments are more than 5 to- kens away from their predicate, in our English and Chinese collections, respectively. However, if we imagine that we can 'teleport' even over a sin- gle (longest) syntactic dependency edge, the 'dis- tance' would shrink: only 9% and 13% arguments will now be more than 5 LSTM steps away (again for English and Chinese, respectively). GCNs pro- vide this 'teleportation' capability. These observa- tions suggest that LSTMs and GCNs may be com- plementary, and we will see that empirical results support this intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Syntax-Aware Neural SRL Encoder</head><p>In this work, we build our semantic role la- beler on top of the syntax-agnostic LSTM-based SRL model of <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref>, which already achieves state-of-the-art results on the CoNLL-2009 English dataset. Following their ap- proach we employ the same bidirectional (BiL- STM) encoder and enrich it with a syntactic GCN.</p><p>The CoNLL-2009 benchmark assumes that predicate positions are already marked in the test set (e.g., we would know that makes, repairs and engines in <ref type="figure" target="#fig_0">Figure 1</ref> are predicates), so no predicate identification is needed. Also, as we focus here solely on identifying arguments and labeling them with semantic roles, for predicate disambiguation (i.e., marking makes as make.01) we use of an off- the-shelf disambiguation model <ref type="bibr" target="#b38">(Roth and Lapata, 2016;</ref><ref type="bibr" target="#b2">Björkelund et al., 2009)</ref>. As in <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref> and in most previous work, we process individual predicates in isolation, so for each predicate, our task reduces to a sequence la- beling problem. That is, given a predicate (e.g., disputed in <ref type="figure" target="#fig_2">Figure 3</ref>) one needs to identify and la- bel all its arguments (e.g., label estimates as A1 and label those as 'NULL', indicating that those is not an argument of disputed).</p><p>The semantic role labeler we propose is com- posed of four components (see <ref type="figure" target="#fig_2">Figure 3</ref>):</p><p>• look-ups of word embeddings;</p><p>• a BiLSTM encoder that takes as input the word representation of each word in a sen- tence;</p><p>• a syntax-based GCN encoder that re-encodes the BiLSTM representation based on the au- tomatically predicted syntactic structure of the sentence;</p><p>• a role classifier that takes as input the GCN representation of the candidate argument and the representation of the predicate to predict the role associated with the candidate word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word representations</head><p>For each word w i in the considered sentence, we create a sentence-specific word representation x i . We represent each word w as the concatenation of four vectors: 4 a randomly initialized word em- bedding x re 2 R dw , a pre-trained word embed- ding x pe 2 R dw estimated on an external text col- lection, a randomly initialized part-of-speech tag embedding x pos 2 R dp and a randomly initial- ized lemma embedding x le 2 R d l (active only if the word is a predicate). The randomly initialized embeddings x re , x pos , and x le are fine-tuned dur- ing training, while the pre-trained ones are kept fixed. The final word representation is given by x = x re x pe x pos x le , where represents the concatenation operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bidirectional LSTM layer</head><p>One of the most popular and effective ways to represent sequences, such as sentences ( <ref type="bibr" target="#b31">Mikolov et al., 2010)</ref>, is to use recurrent neural networks (RNN) <ref type="bibr" target="#b8">(Elman, 1990</ref>). In particular their gated versions, Long Short-Term Memory (LSTM) net- works <ref type="bibr" target="#b17">(Hochreiter and Schmidhuber, 1997</ref>) and Gated Recurrent Units (GRU) ( <ref type="bibr" target="#b4">Cho et al., 2014</ref>), have proven effective in modeling long sequences ( <ref type="bibr" target="#b3">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b41">Sutskever et al., 2014</ref>). Formally, an LSTM can be defined as a func- tion LST M ✓ (x 1:i ) that takes as input the sequence x 1:i and returns a hidden state h i 2 R d h . This state can be regarded as a representation of the sentence from the start to the position i, or, in other words, it encodes the word at position i along with its left context. However, the right context is also important, so Bidirectional LSTMs (Graves, 2008) use two LSTMs: one for the for- ward pass, and another for the backward pass, LST M F and LST M B , respectively. By con- catenating the states of both LSTMs, we cre- ate a complete context-aware representation of a word BiLST M (x 1:n , i) = LST M F (x 1:i ) LST M B (x n:i ). We follow <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref> and stack J layers of bidirectional LSTMs, where each layer takes the lower layer as its input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Graph convolutional layer</head><p>The representation calculated with the BiLSTM encoder is fed as input to a GCN of the form de- fined in Equation (4). The neighboring nodes of a node v, namely N (v), and their relations to v are predicted by an external syntactic parser.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Semantic role classifier</head><p>The classifier predicts semantic roles of words given the predicate while relying on word repre- sentations provided by GCN; we concatenate hid- den states of the candidate argument word and the predicate word and use them as input to a classi- fier <ref type="figure" target="#fig_2">(Figure 3, top)</ref>. The softmax classifier com- putes the probability of the role (including special 'NULL' role):</p><formula xml:id="formula_10">p(r|t i , t p , l) / exp(W l,r (t i t p )),<label>(5)</label></formula><p>where t i and t p are representations produced by the graph convolutional encoder, l is the lemma of predicate p, and the symbol / signifies pro- portionality. <ref type="bibr">5</ref> As <ref type="bibr" target="#b10">FitzGerald et al. (2015)</ref> and <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref>, instead of using a fixed matrix W l,r or simply assuming that W l,r = W r , <ref type="figure">Figure 4</ref>: F 1 as function of word distance. The distance starts from zero, since nominal predicates can be arguments of themselves.</p><p>we jointly embed the role r and predicate lemma l using a non-linear transformation:</p><formula xml:id="formula_11">W l,r = ReLU (U (q l q r )),<label>(6)</label></formula><p>where U is a parameter matrix, whereas q l 2 R d 0 l and q r 2 R dr are randomly initialized embed- dings of predicate lemmas and roles. In this way each role prediction is predicate-specific, and, at the same time, we expect to learn a good represen- tation for roles associated with infrequent predi- cates. As our training objective we use the cate- gorical cross-entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and parameters</head><p>We tested the proposed SRL model on the English and Chinese CoNLL-2009 dataset with standard splits into training, test and development sets. The predicted POS tags for both languages were pro- vided by the CoNLL-2009 shared-task organizers.</p><p>For the predicate disambiguator we used the ones from Roth and Lapata (2016) for English and from <ref type="bibr" target="#b2">Björkelund et al. (2009)</ref> for Chinese. We parsed English sentences with the BIST Parser <ref type="bibr" target="#b21">(Kiperwasser and Goldberg, 2016)</ref>, whereas for Chinese we used automatically predicted parses provided by the CoNLL-2009 shared-task organizers. For English, we used external embeddings of , learned using the structured skip n-gram approach of . For Chinese we used external embeddings produced with the neural language model of <ref type="bibr" target="#b0">Bengio et al. (2003)</ref>. We used edge dropout in GCN: when  v , we ignore each node v 2 N (v) with probability . Adam ( <ref type="bibr" target="#b20">Kingma and Ba, 2015)</ref> was used as an optimizer. The hyperparameter tuning and all model selection were performed on the English development set; the chosen values are shown in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and discussion</head><p>In order to show that GCN layers are effective, we first compare our model against its version which lacks GCN layers (i.e. essentially the model of <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref>). Importantly, to mea- sure the genuine contribution of GCNs, we first tuned this syntax-agnostic model (e.g., the number of LSTM layers) to get best possible performance on the development set. <ref type="bibr">6</ref> We compare the syntax-agnostic model with 3 syntax-aware versions: one GCN layer over syn- tax (K = 1), one layer GCN without gates and two GCN layers (K = 2). As we rely on the same System (Chinese) P R F 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LSTMs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="78.3">72.3 75.2 LSTMs + GCNs (K=1) 79.9 74.4 77.1 LSTMs + GCNs (K=2)</head><p>78.7 74.0 76.2 LSTMs + GCNs (K=1), no gates 78.2 74.8 76.5</p><p>GCNs (no LSTMs), K=1 78.7 58.5 67.1 GCNs (no LSTMs), K=2 79.7 62.7 70.1 GCNs (no LSTMs), K=3 76.8 66.8 71.4 GCNs (no LSTMs), K=4 79.1 63.5 70.4  off-the-shelf disambiguator for all versions of the model, in <ref type="table">Table 1</ref> and 2 we report SRL-only scores (i.e., predicate disambiguation is not evaluated) on the English and Chinese development sets. For both datasets, the syntax-aware model with one GCN layers (K = 1) performs the best, outper- forming the LSTM version by 1.9% and 0.6% for Chinese and English, respectively. The reasons why the improvements on Chinese are much larger are not entirely clear (e.g., both languages are rela- tive fixed word order ones, and the syntactic parses for Chinese are considerably less accurate), this may be attributed to a higher proportion of long- distance dependencies between predicates and ar- guments in Chinese (see Section 3.3). Edge-wise gating (Section 3.2) also appears important: re- moving gates leads to a drop of 0.3% F 1 for En- glish and 0.6% F 1 for Chinese. Stacking two GCN layers does not give any ben- efit. When BiLSTM layers are dropped altogether, stacking two layers (K = 2) of GCNs greatly im- proves the performance, resulting in a 3.8% jump in F 1 for English and a 3.0% jump in F 1 for Chi-   <ref type="figure">Figure 4</ref>, we show the F 1 scores results on the English development set as a function of the distance, in terms of tokens, between a candidate argument and its predicate. As expected, GCNs appear to be more beneficial for long distance de- pendencies, as shorter ones are already accurately captured by the LSTM encoder.</p><p>We looked closer in contribution of specific de- pendency relations for Chinese. In order to assess this without retraining the model multiple times, we drop all dependencies of a given type at test time (one type at a time, only for types appear- ing over 300 times in the development set) and ob- serve changes in performance. In <ref type="figure" target="#fig_3">Figure 5</ref>, we see that the most informative dependency is COMP (complement). Relative clauses in Chinese are very frequent and typically marked with particle Ñ (de). The relative clause will syntactically de- pend on Ñ as COMP, so COMP encodes impor- tant information about predicate-argument struc- ture. These are often long-distance dependencies and may not be accurately captured by LSTMs. Although TMP (temporal) dependencies are not as frequent (⇠2% of all dependencies), they are also important: temporal information is mirrored in se- mantic roles.</p><p>In order to compare to previous work, in Ta- ble 3 we report test results on the English in- domain (WSJ) evaluation data. Our model is lo- cal, as all the argument detection and labeling de- cisions are conditionally independent: their inter- action is captured solely by the LSTM+GCN en- coder. This makes our model fast and simple, though, as shown in previous work, global mod- eling of the structured output is beneficial. <ref type="bibr">8</ref> We leave this extension for future work. Interestingly, <ref type="bibr">7</ref> Note that GCN layers are computationally cheaper than LSTM ones, even in our non-optimized implementation.</p><p>8 As seen in  we outperform even the best global model and the best ensemble of global models, without using global modeling or ensembles. When we create an ensemble of 3 models with the product-of-expert combination rule, we improve by 1.2% over the best previous result, achieving 89.1% F 1 . <ref type="bibr">9</ref> For Chinese <ref type="table" target="#tab_4">(Table 4</ref>), our best model outper- forms the state-of-the-art model of <ref type="bibr" target="#b38">Roth and Lapata (2016)</ref> by even larger margin of 3.1%.</p><p>For English, in the CoNLL shared task, systems are also evaluated on the out-of-domain dataset. Statistical models are typically less accurate when they are applied to out-of-domain data. Con- sequently, the predicted syntax for the out-of- domain test set is of lower quality, which neg- atively affects the quality of GCN embeddings. However, our model works surprisingly well on out-of-domain data <ref type="table" target="#tab_6">(Table 5)</ref>, substantially out- performing all the previous syntax-aware mod- els. This suggests that our model is fairly robust to mistakes in syntax. As expected though, our model does not outperform the syntax-agnostic model of <ref type="bibr" target="#b30">Marcheggiani et al. (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Perhaps the earliest methods modeling syntax- semantics interface with RNNs are due to <ref type="bibr" target="#b16">(Henderson et al., 2008;</ref><ref type="bibr" target="#b12">Gesmundo et al., 2009)</ref>, they used shift-reduce parsers for joint SRL and syntactic parsing, and relied on RNNs to model statistical dependencies across syntactic and semantic parsing actions. A more modern (e.g., based on LSTMs) and effective rein- carnation of this line of research has been pro- posed in <ref type="bibr" target="#b42">Swayamdipta et al. (2016)</ref>. Other re- cent work which considered incorporation of syn- tactic information in neural SRL models include: <ref type="bibr" target="#b10">FitzGerald et al. (2015)</ref> who use standard syntac- tic features within an MLP calculating potentials of a CRF model; <ref type="bibr" target="#b38">Roth and Lapata (2016)</ref> who en- riched standard features for SRL with LSTM rep- resentations of syntactic paths between arguments and predicates; <ref type="bibr" target="#b25">Lei et al. (2015)</ref> who relied on low-rank tensor factorizations for modeling syn- tax. Also <ref type="bibr" target="#b11">Foland and Martin (2015)</ref> used (non- graph) convolutional networks and provided syn- tactic features as input. A very different line of research, but with similar goals to ours (i.e. inte- grating syntax with minimal feature engineering), used tree kernels ( <ref type="bibr" target="#b33">Moschitti et al., 2008)</ref>.</p><p>Beyond SRL, there have been many propos- als on how to incorporate syntactic information in RNN models, for example, in the context of neural machine translation ( <ref type="bibr" target="#b9">Eriguchi et al., 2017;</ref><ref type="bibr" target="#b39">Sennrich and Haddow, 2016)</ref>. One of the most popular and attractive approaches is to use tree- structured recursive neural networks <ref type="bibr" target="#b40">(Socher et al., 2013;</ref><ref type="bibr" target="#b23">Le and Zuidema, 2014;</ref>, including stacking them on top of a sequential BiLSTM ( <ref type="bibr" target="#b32">Miwa and Bansal, 2016</ref>). An ap- proach of <ref type="bibr" target="#b34">Mou et al. (2015)</ref> to sentiment analysis and question classification, introduced even before GCNs became popular in the machine learning community, is related to graph convolution. How- ever, it is inherently single-layer and tree-specific, uses bottom-up computations, does not share pa- rameters across syntactic functions and does not use gates. Gates have been previously used in <ref type="bibr">GCNs (Li et al., 2016</ref>) but between GCN layers rather than for individual edges.</p><p>Previous approaches to integrating syntactic in- formation in neural models are mainly designed to induce representations of sentences or syntac- tic constituents. In contrast, the approach we pre- sented incorporates syntactic information at word level. This may be attractive from the engineering perspective, as it can be used, as we have shown, instead or along with RNN models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We demonstrated how GCNs can be used to in- corporate syntactic information in neural models and specifically to construct a syntax-aware SRL model, resulting in state-of-the-art results for Chi- nese and English. There are relatively straightfor- ward steps which can further improve the SRL re- sults. For example, we relied on labeling argu- ments independently, whereas using a joint model is likely to significantly improve the performance. Also, in this paper we consider the dependency version of the SRL task, however the model can be generalized to the span-based version of the task (i.e. labeling argument spans with roles rather that syntactic heads of arguments) in a relatively straightforward fashion.</p><p>More generally, given simplicity of GCNs and their applicability to general graph structures (not necessarily trees), we believe that there are many NLP tasks where GCNs can be used to incorporate linguistic structures (e.g., syntactic and semantic representations of sentences and discourse parses or co-reference graphs for documents).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example sentence annotated with semantic (top) and syntactic dependencies (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A simplified syntactic GCN (bias terms and gates are omitted); the syntactic graph of the sentence is shown with dashed lines at the bottom. Parameter matrices are sub-indexed with syntactic functions, and apostrophes (e.g., subj') signify that information flows in the direction opposite of the dependency arcs (i.e., from dependents to heads).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Predicting an argument and its label with an LSTM + GCN encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Performance with dependency arcs of given type dropped, on Chinese development set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>SRL results without predicate disam-
biguation on the Chinese development set. 

System 
P 
R F 1 

Lei et al. (2015) (local) 
-
-86.6 
FitzGerald et al. (2015) (local) 
-
-86.7 
Roth and Lapata (2016) (local) 
88.1 85.3 86.7 
Marcheggiani et al. (2017) (local) 88.7 86.8 87.7 
Ours (local) 
89.1 86.8 88.0 

Björkelund et al. (2010) (global) 
88.6 85.2 86.9 
FitzGerald et al. (2015) (global) 
-
-87.3 
Foland and Martin (2015) (global) -
-86.0 
Swayamdipta et al. (2016) (global) -
-85.0 
Roth and Lapata (2016) (global) 
90.0 85.5 87.7 

FitzGerald et al. (2015) (ensemble) -
-87.7 
Roth and Lapata (2016) (ensemble) 90.3 85.7 87.9 
Ours (ensemble 3x) 
90.5 87.7 89.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Results on the test set for English.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results on the Chinese test set. 

nese. Adding a 3rd layer of GCN (K = 3) further 
improves the performance. 7 This suggests that ex-
tra GCN layers are effective but largely redundant 
with respect to what LSTMs already capture. 
In </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 ,</head><label>3</label><figDesc></figDesc><table>labelers of FitzGerald et al. (2015) 
and Roth and Lapata (2016) gained 0.6-1.0%. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results on the out-of-domain test set. 

</table></figure>

			<note place="foot" n="2"> We dropped normalization factors used in Kipf and Welling (2017), as they are not used in our syntactic GCNs.</note>

			<note place="foot" n="3"> Chinese and English CoNLL-2009 datasets used 41 and 48 different syntactic functions, which would result in having 83 and 97 different matrices in every layer, respectively.</note>

			<note place="foot" n="4"> We drop the index i from the notation for the sake of brevity.</note>

			<note place="foot" n="5"> We abuse the notation and refer as p both to the predicate word and to its position in the sentence.</note>

			<note place="foot" n="6"> For example, if we would have used only one layer of LSTMs, gains from using GCNs would be even larger.</note>

			<note place="foot" n="9"> To compare to previous work, we report combined scores which also include predicate disambiguation. As we use disambiguators from previous work (see Section 5.1), actual gains in argument identification and labeling are even larger.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would thank Anton Frolov, Michael Schlichtkrull, Thomas Kipf, Michael Roth, Max Welling, Yi Zhang, and Wilker Aziz for their suggestions and comments. The project was supported by the European Research Council (ERC StG BroadSem 678254), the Dutch National Science Foundation (NWO VIDI 639.022.518) and an Amazon Web Services (AWS) grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Janvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A high-performance syntactic and semantic dependency parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING: Demonstrations</title>
		<meeting>COLING: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multilingual semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Love</forename><surname>Hafdell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
		<title level="m">Named entity recognition with bidirectional LSTM-CNNs. TACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grangier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08083</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Aguilera-Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alán</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transitionbased dependency parsing with stack long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning to parse and translate improves neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Eriguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.03525</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semantic role labeling with neural network factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dependencybased semantic role labeling using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Foland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the Fourth Joint Conference on Lexical and Computational Semantics (*SEM)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Latent variable model of synchronous syntactic-semantic parsing for multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Merlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="245" to="288" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01212</idno>
		<title level="m">Neural message passing for quantum chemistry</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Supervised sequence labelling with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>München, Techn. Univ., Diss.</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A latent variable model of synchronous parsing for syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Merlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Musillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The effect of syntactic representation on semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Nugues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="595" to="608" />
		</imprint>
	</monogr>
	<note>Journal of computer-aided molecular design</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliyahu</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<title level="m">Simple and accurate dependency parsing using bidirectional LSTM feature representations. TACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="313" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The insideoutside recursive neural network model for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem</forename><surname>Zuidema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Intelligent Signal Processing</title>
		<meeting>Intelligent Signal Processing</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">High-order lowrank tensors for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">English verb classes and alternations: A preliminary investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Levin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>University of Chicago press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of word2vec for syntax problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Assessing the ability of LSTMs to learn syntax-sensitive dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Linzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="521" to="535" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Frolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukás</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Cernock´ycernock´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using lstms on sequences and tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tree kernels for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Pighin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Basili</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="224" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discriminative neural sentence modeling by tree-based convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Oriol Vinyals, and Alex Graves. 2016. Conditional image generation with PixelCNN decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic role chunking combining complementary syntactic views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kadri</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">H</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The importance of syntactic parsing and inference in semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="287" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neural semantic role labeling with dependency path embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Linguistic input features improve neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Greedy, joint syntacticsemantic parsing with stack LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A generative model for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML</title>
		<meeting>ECML</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Online projectivisation for synchronous parsing of semantic and syntactic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Merlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Musillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyotaka</forename><surname>Jun&amp;apos;ichi Kazama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Uchimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">End-to-end learning of semantic role labeling using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
