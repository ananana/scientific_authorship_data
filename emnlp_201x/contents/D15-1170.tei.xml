<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Semantic Parsing with Enriched Synchronous Context-Free Grammar</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
							<email>muhua.zmh@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Inc</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg</email>
							<affiliation key="aff2">
								<orgName type="department">Information Systems Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing Lab</orgName>
								<orgName type="institution">Soochow University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving Semantic Parsing with Enriched Synchronous Context-Free Grammar</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Semantic parsing maps a sentence in natural language into a structured meaning representation. Previous studies show that semantic parsing with synchronous context-free grammars (SCFGs) achieves favorable performance over most other alternatives. Motivated by the observation that the performance of semantic parsing with SCFGs is closely tied to the translation rules, this paper explores extending translation rules with high quality and increased coverage in three ways. First, we introduce structure informed non-terminals, better guiding the parsing in favor of well formed structure, instead of using a uninformed non-terminal in SCFGs. Second, we examine the difference between word alignments for semantic parsing and statistical machine translation (SMT) to better adapt word alignment in SMT to semantic parsing. Finally, we address the unknown word translation issue via synthetic translation rules. Evaluation on the standard GeoQuery benchmark dataset shows that our approach achieves the state-of-the-art across various languages, including English, German and Greek.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing, the task of mapping natural language (NL) sentences into a formal meaning representation language (MRL), has recently re- ceived a significant amount of attention with vari- ous models proposed over the past few years. Con- sider the NL sentence paired with its correspond- ing MRL in <ref type="figure" target="#fig_1">Figure 1</ref>  naturally viewed as a statistical machine transla- tion (SMT) task, which translates a sentence in NL (i.e., the source language in SMT) into its mean- ing representation in MRL (i.e., the target lan- guage in SMT). Indeed, many attempts have been made to directly apply statistical machine transla- tion (SMT) systems (or methodologies) to seman- tic parsing ( <ref type="bibr" target="#b24">Papineni et al., 1997;</ref><ref type="bibr" target="#b20">Macherey et al., 2001</ref>; <ref type="bibr">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b0">Andreas et al., 2013</ref>). However, although recent studies ( <ref type="bibr">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b0">Andreas et al., 2013)</ref> show that semantic parsing with SCFGs, which form the ba- sis of most existing statistical syntax-based trans- lation models <ref type="bibr">(Yamada and Knight, 2001;</ref><ref type="bibr" target="#b5">Chiang, 2007)</ref>, achieves favorable results, this approach is still behind the most recent state-of-the-art. For details, please see performance comparison in <ref type="bibr" target="#b0">Andreas et al. (2013)</ref> and <ref type="bibr" target="#b18">Lu (2014)</ref>.</p><p>The key issues behind the limited success of ap- plying SMT systems directly to semantic parsing lie in the difference between semantic parsing and SMT: MRL is not a real natural language with different properties from natural language. First, MRL is machine-interpretable and thus strictly structured with the meaning representation in a nested structure of functions and arguments. Sec- ond, the two languages are intrinsically asymmet- ric since each token in MRL carries specific mean-ing 1 while this does not hold in NL since auxil- iary words and some function words usually have no counterparts in MRL. Third and finally, the ex- pressions in NL are more flexible with respect to lexicon selection and token ordering. For exam- ple, since sentences in NL 'could you tell me the states that utah borders', 'what states does utah border', and 'utah borders what states' convey the same meaning, they should have the same expres- sion in MRL.</p><p>Motivated by the above observations, we be- lieve that semantic parsing with standard SMT components is not an ideal approach. Alterna- tively, this paper proposes an effective, yet simple way to enrich SCFG in hierarchical phrase-based SMT for better semantic parsing. Specifically, since the translation rules play a critical role in SMT, we explore to improve translation rule qual- ity and increase its coverage in three ways. First, we enrich non-terminal symbols as to capture con- textual and structured information. The enrich- ment of non-terminal symbols not only guides the translation in favor of well formed structures, but also is beneficial to translation. Second, we ex- amine the difference between word alignments for semantic parsing and SMT to better adapt word alignment in SMT to semantic parsing. Third, unlike most existing SMT systems that keep un- known words untranslated and intact in transla- tion, we exploit the translation of unknown words via synthetic translation rules. Evaluation on Geo- Query benchmark dataset shows that our approach obtains consistent improvement and achieves the state-of-the-art across various languages, includ- ing English, German and Greek.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Semantic Parsing as Statistical Machine Translation</head><p>In this section, we present the framework of semantic parsing as SMT, which was proposed in <ref type="bibr" target="#b0">Andreas et al. (2013)</ref>. Pre-Processing Various semantic formalisms have been considered for semantic parsing. Ex- amples include the variable-free semantic repre- sentations (that is, the meaning representation for each utterance is tree-shaped), the lambda calculus expressions, and dependency-based compositional semantic representations. In this work, we specifi-cally focus on the variable-free semantic represen- tations, as shown in <ref type="figure" target="#fig_1">Figure 1</ref>. On the target side, we convert these meaning representations to series of strings similar to NL. To do so, we simply take a preorder traversal of every functional form, and la- bel every function with the number of arguments it takes. <ref type="figure" target="#fig_1">Figure 1(b)</ref> shows an example of con- verted meaning representation, where each token is in the format of A@B where A is the symbol while B is either s indicating that the symbol is a string or a number indicating the symbol's arity (constants, including strings, are treated as zero- argument functions).</p><p>On the source side, we perform stemming (for English and German) and lowercasing to over- come data sparseness.</p><p>Hereafter, we refer to the pre-processed NL and MRL as NL and MRL respectively. Translation Given a corpus of NL sentences paired with MRL , we learn a semantic parser by adopting a string-to-string translation system. Typical components in such a translation system include word alignments between the source and the target languages, translation rule extraction, language model learning, parameter tuning and decoding. For more details about each component, please refer to <ref type="bibr" target="#b5">(Chiang, 2007)</ref>. In the rest of this paper, we refer to the source language (side) as NL , and the target language (side) as MRL . Post-Processing We convert MRL back into MRL by recovering parentheses and commas to reconstruct the corresponding tree structure in MRL. This can be easily done by examining each symbol's arity. It eliminates any possible ambi- guity from the tree reconstruction: given any se- quence of tokens in MRL , we can always recon- struct the tree structure (if one exists). For those translations that can not be successfully converted, we call them ill-formed translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantic Parsing with Enriched SCFG</head><p>In this section, we present the details of our en- riched SCFG for semantic parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Enriched SCFG</head><p>In hierarchical phrase-based (HPB) translation models, synchronous rules take the form X → γ, α, ∼∼, where X is the non-terminal sym- bol, γ and α are strings of lexical items and non-terminals in the source and target side re- spectively, and ∼ indicates the one-to-one cor-respondence between non-terminals in γ and α. From an aligned phrase pair &lt;state that border, state@1 next to 2@1&gt; in <ref type="figure" target="#fig_3">Figure 2</ref>(a), for ex- ample, we can get a synchronous rule X → state X 1 , state@1 X 1 , where we use boxed in- dices to indicate which nonterminal occurrences are linked by ∼. The fact that SCFGs in HPB mod- els contain only one type of non-terminal symbol 2 is responsible for ill-formed translation (e.g., an- swer@1 state@1). To this end, we enrich the non- terminals to capture the tree structure information, guiding the translation in favor of well-formed translations. The enrichment of non-terminals is two-fold: first, it can handle MRL with a nested structure to guarantee the well-formed transla- tions; second, related studies in SMT have shown that introducing multiple non-terminal symbols in SCFGs benefits translation ( <ref type="bibr">Zollmann and Venugopal, 2006;</ref><ref type="bibr" target="#b15">Li et al., 2012)</ref>. Given a word sequence e i j from position i to position j in MRL , we enrich the non-terminal symbol X to reflect the internal structure of the word sequence of e i j . A correct translation rule selection therefore not only maps source termi- nals into target terminals, but is both constrained and guided by structure information in the non- terminals. As mentioned earlier, we regard the nested structure in MRL as function-argument structure, where each function takes one or more arguments as input while its return serves as an ar- gument to the outside function. As in <ref type="figure" target="#fig_1">Figure 1</ref>, function cityid holds two arguments and returns as an argument to function area 1. For a word se- quence e i j , we examine its completeness, which is defined as: Definition 1. For word sequence e i j , it is regarded as complete if it satisfies 1) every function (if ex- ists) meets its argument requirement; and 2) it can serve as one argument to another function.</p><p>We use symbol C to label word sequences which are complete. For an incomplete word se- quence, we examine 1) the number of arguments it requires on the right to be complete; and 2) the arity of a function it requires on the left to be complete. Then the sequence is labeled as (C\Fm)/An, indicating it requires n arguments on the right and a function with m arities on the left. <ref type="bibr">3</ref> texas, stateid@1 texas@s C→ texas, stateid@1 texas@s seattle, seattle@s @0 C\F2→ seattle, seattle@s @0 that border, next to 2@1 C/A1→ that border, next to 2@1 state that border, state@1 next to 2@1 C/A1→ state C/A1 1 , state@1 C/A1 1 (a) Examples of phrase pairs in enriched SCFG. l.. one@1 ::::::: p.. 1@1 state@1 n..@1 s..@1 t..@s</p><formula xml:id="formula_0">C→ C 1 C/A1 2 , C/A1 2 C 1</formula><p>(b) Examples of glue rules in enriched SCFG. Specifically, we omit \Fm and /An if m = 0 and n = 0 respectively. 4 <ref type="table" target="#tab_0">Table 1</ref>(a) demonstrates examples of phrase pairs in our enriched SCFG. For instance, word sequence stateid@1 texas@s is complete, and thus labeled as C. Similarly, to be complete, word se- quence next to 2@1 requires one argument on the right side, labeled as C/A1 accordingly.</p><p>When extracting translation rules from aligned datasets, we follow Chiang (2007) except that we use enriched non-terminal symbols rather than X. Each translation rule is associated with a set of translation model features {φ i }, including phrase translation probability p (α | γ) and its in- verse p (γ | α), the lexical translation probability p lex (α | γ) and its inverse p lex (γ | α), and a rule penalty that learns the preference for longer or shorter derivations. Inverted Glue Rules In SMT decoding <ref type="bibr" target="#b5">(Chiang, 2007)</ref>, if no rule (e.g., a rule whose left-hand side is X) can be applied or the length of the poten- tial source span is larger than a pre-defined length (e.g., 10 as in Chiang <ref type="formula">(2007)</ref>), a glue rule (either S → X 1 , X 1 or S → S 1 X 2 , S 1 X 2 ) will be used to simply stitch two consequent translated phrases together in a monotone way. Although this will reduce computational and modeling chal- lenges, it obviously prevents some reasonable translation derivations because in certain cases, the order of phrases may be inverted on the target side. In this work, we additionally use an inverted glue rule which combines two non-terminals in a swapped way. Each glue rule, either straight or inverted, contains only two non-terminal sym- bols and is associated with two features, includ- ing phrase translation probability p (α | γ), and a glue rule penalty. <ref type="table" target="#tab_0">Table 1</ref>(b) shows examples of a straight and an inverted glue rules. Moreover, these glue rules can be applied to any two neigh- boring translation nodes if the non-terminal sym- bols are matched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Word Alignment for Semantic Parsing</head><p>Word alignment is an essential step for rule ex- traction in SMT, where recognizing that wo shi in Chinese is a good translation for I am in English requires establishing a correspondence between wo and I, and between shi and am. In the SMT community, researchers have developed standard, proven alignment tools such as GIZA++ <ref type="bibr" target="#b23">(Och and Ney, 2003)</ref>, which can be used to train IBM Mod- els 1-5. However, there is one fundamental prob- lem with the IBM models ( <ref type="bibr" target="#b3">Brown et al., 1993)</ref>: each word on one side can be traced back to ex- actly one particular on the other word (or the null token which indicates the word aligns to no word on the other side). <ref type="figure" target="#fig_3">Figure 2</ref>(a) shows an example of GIZA++ alignment output from source side to target side, from which we can see that each source word aligns to exactly one target word. While alignment of multiple target words to one source word is common in SMT, a trick is then to run IBM model training in both directions. Then two resulting word alignments can be symmetrized, for instance, taking the intersection or the union of alignment points of each alignment. For example, <ref type="figure" target="#fig_3">Figure 2</ref>(b) shows GIZA++ alignment output from target side to source side while <ref type="figure" target="#fig_3">Figure 2(c)</ref> shows the symmetrization result with widely used grow- diag-final-and strategy.</p><p>Although symmetrization of word alignments works for SMT, can it be applied to semantic pars- ing? There are reasons to be doubtful. Word align- ment for semantic parsing differs from alignment for SMT in several important aspects, at least in- cluding:</p><p>1. It is intrinsically asymmetric: within the se- mantic formalism used in this paper, NL is often longer than MRL , and commonly con- tains words which have no counterpart in MRL .</p><p>2. Little training data is available. SMT align- ment models are typically trained in unsu- pervised fashion, inducing lexical correspon- dences from massive quantities of sentence- aligned bitexts.</p><p>Consequently, the symmetrization of word align- ments may not work perfectly for semantic pars- ing. According to word alignment in <ref type="figure" target="#fig_3">Figure 2</ref>(c), a phrase extractor will generate a phrase pair have the highest, largest one@1, which is non- intuitive. By contrast, a more useful and general phrase pair highest, largest one@1 is typically excluded because largest one@1 aligns to all of have, the, and highest. Similarly, another useful phrase pair texas, texas@s is prohibited since texas aligns to both stateid@1 and texas@s.</p><p>Ideally a new semantic parsing aligner should be able to capture the semantic equivalence. Un- fortunately we are not aware of any research on alignment for semantic parsing, possibly due to lack of a paucity of high quality, publicly avail- able data from which to learn. Instead of de- veloping new alignment algorithm for semantic parsing, we make use of all the alignments as shown in <ref type="figure" target="#fig_3">Figure 2</ref>. That is to say, we triple the training data with each sentence pair having three alignments, i.e., two alignments in both di- rections, and the symmetrization alignment. <ref type="bibr">5</ref> The advantages include: first, considering more pos- sible alignments would increase the phrase cov- erage, especially when the training data is little; second, including the alignment from both direc- tions would alleviate the error propagation caused by mis-aligned stop words (e.g., be, the in NL and stateid@1 in MRL ). As a result, the phrase ex- tractor will include phrase pairs of both highest, largest one@1 and texas, texas@s. Our exper- iment shows that using the combination of all the three alignments achieve better performance than using any one, or any combination of two. More- over, we found that we could achieve comparable performance even with manual alignment. what state that border texas have the highest popula3on answer@1 largest_one@1 popula3on_1@1 state@1 next_to_2@1 stateid@1 texas@s what state that border texas have the highest popula3on answer@1 largest_one@1 popula3on_1@1 state@1 next_to_2@1 stateid@1 texas@s what state that border texas have the highest popula3on answer@1 largest_one@1 popula3on_1@1 state@1 next_to_2@1 stateid@1 texas@s (a) word alignment from source to target direc3on (b) word alignment from target to source direc3on (c) symmetriza3on of word alignment using grow-­-diag-­-final-­-and strategy </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Synthetic Translation Rules for Unknown Word Translation</head><p>Most NLP tasks face the problem of unknown words, especially if only little training data is available. For example, it is estimated that 5.7% sentences in the (English) test data in our exper- iments have unknown words. Unknown words usually remain intact in the translation in most machine translation systems ( <ref type="bibr" target="#b11">Koehn et al., 2007;</ref><ref type="bibr" target="#b7">Dyer et al., 2010)</ref>, resulting in the fact that cer- tain translations can not be converted back to tree structures. This indicates that in semantic pars- ing the translation of a word can be from two cat- egories: 1) a token in MRL; or 2) null (i.e., not translated at all), we generate synthetic translation rules for unknown word translation. As a baseline, we simply skip unknown words as <ref type="bibr" target="#b12">Kwiatkowski et al. (2010)</ref> by adding translation rules that translate them to null in MRL . Each such rule is accompanied with one feature indicat- ing that it is a translation rule for unknown word.</p><p>Alternatively, taking advantage of publicly available resources, we generate synthetic trans- lation rules for unknown words pivoted by their semantically close words. Algorithm 1 illustrates the process to generate synthetic translation rules for unknown word translation. Given an unknown word w u , it generates its synthetic rules in two steps: 1) finding top n (e.g., 5 as in our experi- ments) close words via Word2Vec; 6 and 2) gener- ating synthetic translation rules based on the close <ref type="bibr">6</ref> It is available at http://code.google.com/p/word2vec/. We use Word2Vec rather than other linguistic resources like WordNet because the approach can be easily adopted to other languages only if there exists large monolingual data to train Word2Vec models. foreach tj such wbi, tj in T1 and T2 7.</p><p>R ∪ = generate rule(wu, wbi, tj, T1, T2) 8. return R sim: returns the similarity between wu and wi.</p><p>generate rule: returns rule wu, tj with a feature indicating the similarity between wu and wbi, and two features indicating the lexical translation prob- abilities from wbi to tj and the way around.</p><p>words. Note that it may generate a synthetic rule with null at the target side since the lexical transla- tion table derived from aligned training data con- tains translation to null. Each synthetic translation rule for unknown words is associated with three features returned from function generate rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimentation</head><p>In this section, we test our approach on the Geo- Query dataset, which is publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Data GeoQuery dataset consists of 880 questions paired with their corresponding tree structured se- mantic representations. Following the experimen- tal setup in <ref type="bibr" target="#b10">Jones et al. (2012)</ref>, we use the 600 question pairs to train and tune our SMT de-coder, and evaluated on the remaining 280. Note that there is another version of GeoQuery dataset where the semantic representation is annotated with lambda calculus expressions and which is ex- tensively studied <ref type="bibr">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b16">Liang et al., 2011;</ref><ref type="bibr" target="#b14">Kwiatkowski et al., 2013)</ref>. Performance on the version of lambda calculus is higher than that on the tree structured version, however, the results ob- tained over the two versions are not directly com- parable.</p><p>SMT Setting We use cdec ( <ref type="bibr" target="#b7">Dyer et al., 2010</ref>) as our HPB decoder. As mentioned above, 600 in- stances are used to train and tune our decoder. To get fair results, we split the 600 instances into 10 folds, each having 60 instances. Then for each fold, we use it as the tuning data while the other 540 instances and the NP list are used as train- ing data. <ref type="bibr">7</ref> We use IRSTLM toolkit <ref type="bibr" target="#b8">(Federico et al., 2008</ref>) to train a 5-gram LM on the MRL side of the training data, using modified Kneser-Ney smoothing. We use Mira ( <ref type="bibr" target="#b4">Chiang et al., 2008)</ref> to tune the parameters of the system to maximize BLEU ( <ref type="bibr" target="#b25">Papineni et al., 2002</ref>). When extracting translation rules from aligned training data, we in- clude both tight and untight phrases.</p><p>Evaluation We use the standard evaluation crite- ria for evaluation by executing both the predicted MRL and the gold standard against the database and obtaining their respective answer. Specifi- cally, we convert a translation from MRL into MRL (if exists). The translation then is consid- ered correct if and only if its MRL retrieves the same answers as the gold standard MRL ( <ref type="bibr" target="#b10">Jones et al., 2012</ref>), allowing for a fair comparison between our systems and previous works. As in <ref type="bibr" target="#b10">Jones et al. (2012)</ref>, we report accuracy, i.e. the percent- age of translations with correct answers, and F1, i.e. the harmonic mean of precision (the propor- tion of correct answers out of translations with an answer) and recall (the proportion of correct an- swers out of all translations). In this section, we report our performance scores and analysis num- bers averaged on our 10 SMT models.   <ref type="table">Table 2</ref>: Performance of our (non-) enriched SCFG systems with different alignment settings. <ref type="table">Table 2</ref> shows the results of (non-) enriched SCFG systems over different alignment settings. In Ta- ble 2, src2tgt and tgt2src indicate alignment of source to target direction and alignment of tar- get to source direction, respectively; gdfa indi- cates symmetrization of alignment with grow- diag-final-and strategy; src2tgt+tgt2src indicates doubling the training data with each sentence pair having both src2tgt and tgt2src alignments, sim- ilar for src2tgt+gdfa and tgt2src+gdfa; all indi- cates tripling the training data with each sentence pair having three alignments. Finally, gold indi- cates using gold alignment. 8 Effect of Enriched SCFG From <ref type="table">Table 2</ref>, we observe that enriched SCFG systems outperform non-enriched SCFG systems over all alignment settings, indicating the effect of enriching non- terminals. In particular for tgt2src alignment, it obtains improvements of 3.5% in accuracy and 2.7% in F1. As mentioned earlier, the non-enriched SCFG system may result in ill-formed translations, which can not be converted back to tree struc- ture. One natural way to overcome this issue, as in <ref type="bibr" target="#b0">Andreas et al. (2013)</ref>, would be to simply filter n-best translation till a well-formed one is found. However, we see very limited performance changes in accuracy and F1, suggesting that the ef- fect of using n-best translation is very limited. For example, after using n-best translation, the non- enriched SCFG system with all alignment obtains 82.0 in accuracy (increased from 81.5) and 84.5 in alignment Rec. Pre.   • Semantic parsing is substantially sensitive to alignment. Surprisingly, gdfa alignment, which is widely adopted in SMT, is inferior to tgt2src alignment. As expected, src2tgt alignment achieves the worst performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>• Thanks to the increased coverage, dou- bling the training data (e.g., rows of src2tgt+tgt2src, src2tgt+gdfa, and tgt2src+gdfa) usually outperforms its cor- responding single alignment. Moreover, tripling the training data (e.g., rows of all) achieves slightly better performance than any way of doubling the training data. This is expected since the gdfa alignment actually comes from the alignments of src2tgt and tgt2src, thus doubling the training with src2tgt and tgt2src have already included most aligns in gdfa alignment.</p><p>• Our approach of tripling the training data achieves comparable performance to the one with gold alignment, suggesting that instead of developing a brand new algorithm for se- mantic parsing alignment, we can simply make use of GIZA++ alignment output.</p><p>In terms of the src2tgt, tgt2src and gdfa align- ments, the trend of the results is consistent over both non-enriched and enriched SCFG systems: the systems with tgt2src alignment work best while the systems with src2tgt alignment work worst. Next we look at the non-enriched SCFG systems to explore the behavior differences among the three alignments.</p><p>We examine the alignment accuracy against the gold alignment on training data (except the NP list part). As shown in <ref type="table" target="#tab_3">Table 3</ref>, src2tgt has the high- est recall while tgt2src has the highest precision. This is partly due to: 1) In src2tgt alignment, each source word aligns to exactly one particular tar- get word (or the null token), resulting in frequent enriched + gdfa correct wrong <ref type="table" target="#tab_0">non-enriched + gdfa  correct  211  6  wrong  10  53   enriched + all  correct  215  17  wrong  6  42   Table 4</ref>: Confusion matrices of three SMT systems on English test sentences.</p><p>alignment errors for source side words that have no counterpart in target side. For example, both words of the and be on source side, which play functional roles in NL, rather than semantic roles, align to 15 different target words. 2) Except for a few words on target side, including stateid@1, all@0 which have strong occurrence patterns (e.g., stateid@1 is always followed by a state name), each word has counterpart on source side. As to have a clearer understanding on the individual contribution of using enriched non- terminals and multiple word alignments, <ref type="table">Table 4</ref> presents two confusion matrices which show num- bers of sentences that are correctly/wrongly parsed by three SMT systems on English test sentences. It shows that, for example, 211 sentences are cor- rectly parsed by both non-enriched and enriched SCFG systems with gdfa alignment. Moving from performance of the non-enriched SMT sys- tem with gdfa alignment to that of the enriched SMT system with all alignment, we observe that on average more than half of the improvement comes from using multiple word alignments, the rest from using enriched non-terminals. Effect of Unknown Word Translation Since each of our SMT model is actually trained on 540 instances (plus the NP list), the rate of unknown words in the test data tends to be higher than that in a system trained with the whole 600 instances. Based on the system of enriched SCFG with all alignment, <ref type="table" target="#tab_4">Table 5</ref> shows the results of applying unknown word translation. It shows that translat- ing all unknown words into null obtains 2.4 points in accuracy over the system without it (e.g., 85.3 vs. 82.9). However, the slight improvement in F1 (e.g., 86.3 vs. 86.1) suggests that there are many scenarios that translating unknown words into null is incorrect. Fortunately, our semantic approach is partially able to generate correct translation rules for those unknown words which have translation in MRL . Actually, the effect of our approach is highly dependent on the quality of the close words found via Word2Vec. With a manual examination System Acc. F1 No unknown word translation 82.9 86.1 null: baseline 85.3 86.3 semantic: ours 86.3 87.1 on the test data, we found that 11 out of all 17 unknown words should be translated into a corre- sponding token in MRL. For 8 of them, the syn- thetic translation rule set returned by Algorithm 1 contains correct translation rules.</p><p>Effect across Different Languages We have also tested our approach on the same dataset with other three languages. Specifically, while we are not aware of public resources to looking for seman- tically close words in German, Greek and Thai, we translate unknown words into null for the three languages. Decoding Time Analysis We analyze the effect on the decoding time of our approach, which is closely related to the size of phrase tables. Firstly, splitting non-terminal X into enriched ones in- creases the size of phrase tables. 9 This is not surprising since a phrase with non-terminal X (e.g., the X on the source side) may be further specified as multiple phrases with various non- terminals (e.g., the C, the C/A1, etc.). As a re- sult, the average number of phrases per sentence (in English test data, hereafter) increases from 453 to 893 while the decoding time of the SMT de- coder increases from 0.11 seconds to 0.19 seconds per sentence on average. Secondly, using multiple alignments also leads to larger phrase tables. This is illustrated by the increase of average number of phrases per sentence from 893 to 2055 while the decoding time moves from 0.19 seconds to 0.38 seconds per sentence on average. Finally, finding similar words via Word2Vec, however, is quite fast since this is bounded by the vocabulary size of our training set. Thanks to the small size of unknown words, adding unknown word translation rules has a very limited impact on the size of phrase ta- ble, consequently negligible changes on decoding time. <ref type="bibr">9</ref> In cdec, we generate a phrase table for each sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>While there has been substantial work on seman- tic parsing, we focus our discussions on several approaches (e.g., SCFG approach, hybrid tree ap- proach, and others approaches) that focus on the variable-free semantic representations. WASP ( <ref type="bibr">Wong and Mooney, 2006</ref>) was strongly influenced by SMT techniques. Although WASP was also using multiple non-terminal symbols in SCFG to guarantee well-formed translations, our work differs from theirs in at least three ways. First, we use a different inventory of non-terminal symbols from theirs which was derived from MRL parses in the GeoQuery dataset. Second, to avoid the issues caused by word alignment between NL and MRL, we triple training data with each sen- tence pair having multiple alignments. However, WASP used a sequence of productions to repre- sent MRL before running GIZA++. Third, we use typical features in HPB SMT (e.g., phrase transla- tion probabilities, lexical translation probabilities, language model feature, etc.) while WASP used rule identity features. SMT-SemParse ( <ref type="bibr" target="#b0">Andreas et al., 2013</ref>) adapted standard SMT components for semantic parsing. The present work is based on theirs with all the extensions detailed in Section 3.</p><p>HYBRIDTREE+ ( <ref type="bibr" target="#b17">Lu et al., 2008</ref>) learned a synchronous generative model which simultane- ously generated a NL sentence and an MRL tree. tsVB ( <ref type="bibr" target="#b10">Jones et al., 2012</ref>) used tree transducers, which were similar to the hybrid tree structures, to learn a generative process under a Bayesian frame- work. RHT (Lu, 2014) defined distributions over relaxed hybrid tree structures that jointly repre- sented both sentences and semantics. Most re- cently, f-RHT (Lu, 2015) introduced constrained semantic forests to improve RHT model. SCISSOR <ref type="bibr" target="#b9">(Ge and Mooney, 2005</ref>) augmented syntactic parse tree with semantic information and then performed integrated semantic and syntac- tic parsing to NL sentences. KRISP <ref type="bibr" target="#b22">(Mooney, 2006</ref>) used string classifiers to label substrings of an NL with entities from the meaning representa- tion. UBL ( <ref type="bibr" target="#b12">Kwiatkowski et al., 2010</ref>) performed semantic parsing with an automatically-induced CCG lexicon. <ref type="table">Table 7</ref> shows the evaluation results of our sys- tem as well as those of several other compara- ble related works which share the same experi- ment setup as ours. We can observe from <ref type="table">Table 7</ref> that semantic parsing with SMT components gives</p><formula xml:id="formula_1">System English German Greek Thai Acc. F1 Acc. F1 Acc. F1</formula><p>Acc. F1 non-enriched + gdfa 77.5 83.5 66.0 74.9 65.6 74.1 65.4 72.4</p><p>non-enriched + all 81.5 85.2 72.1 76.8 75.2 80.5 72.7 76.4 enriched + gdfa 78.9 83.9 66.7 74.6 67.8 76.1 68.5 74.1 enriched + all 82.9 86.1 75.4 79.5 76.5 81.2 75.2 77.9 enriched + all + unknown word translation 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9  <ref type="table">Table 7</ref>: Performance comparison for the multilingual GeoQuery test set. The performance of WASP, HYBRIDTREE+, tsVB and UBL is taken from <ref type="bibr" target="#b10">Jones et al. (2012)</ref>.</p><p>competitive performance when all the extensions (described in Section 3) are used. Specifically, it significantly outperforms the semantic parser with standard SMT components ( <ref type="bibr" target="#b0">Andreas et al., 2013)</ref>. Our approach reports the best accuracy and F1 scores on English, German, and Greek. While we are able to obtain improvement on Thai, the performance is still lower than those of RHT and TREETRANS. This is probably because of the low quality of word alignment output between this Asian language and MRL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have presented an enriched SCFG approach for semantic parsing which realizes the potential of the SMT approach. The performance improvement is contributed from the extension of translation rules with informative symbols and in- creased coverage. Such an extension share a sim- ilar spirit as generalization of a CCG lexicon for CCG-based semantic parser ( <ref type="bibr" target="#b13">Kwiatkowski et al., 2011;</ref><ref type="bibr">Wang et al., 2014</ref>). Experiments on bench- mark data have shown that our model is competi- tive to previous work and achieves state-of-the-art performance across a few different languages.</p><p>Recently the research of semantic parsing in open domain with weakly (or un-) supervised se- tups, under different settings where the goal was to optimize the performance of certain downstream NLP tasks such as answering questions, has re- ceived a significant amount of attention <ref type="bibr" target="#b26">(Poon and Domingos, 2009;</ref><ref type="bibr" target="#b6">Clarke et al., 2010;</ref><ref type="bibr" target="#b2">Berant et al., 2013;</ref><ref type="bibr" target="#b1">Berant and Liang, 2014)</ref>. One direc- tion of our future work is to extend the current framework to support the generation of synthetic translation rules from weaker signals (e.g., from question-answer pairs), rather than from aligned parallel data.</p><p>We also noticed recent advance in tree-based SMT. Applying such string-to-tree or tree-to-tree translation models <ref type="bibr">(Yamada and Knight, 2001;</ref><ref type="bibr" target="#b27">Shen et al., 2008)</ref> to semantic parsing will nat- urally resolve the inconsistent semantic structure issue, though they require additional information to generate tree labels on the target side. However, due to the constraint that each target phrase needs to map to a syntactic constituent, phrase tables in tree-based translation models usually suffer from the low coverage issue, especially if the training data size is small. Therefore, another direction of our future work is to explore specific problems that will emerge when employing tree-based SMT sys- tems to semantic parsing, and provide solutions to them.</p><p>Mark Steedman. 2000. The syntactic process. The MIT Press.</p><p>Zhaopeng Tu, Yang Liu, Yifan He, Josef van Gen- abith, Qun Liu, and Shouxun Lin. 2012. Combin- ing multiple alignments to improve machine trans- lation. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a). Semantic parsing can be NL: What is the area of Sea0le MRL: answer(area_1(cityid('sea0le', _))) NL': what be the area of sea0le MRL': answer@1 area_1@1 cityid@2 sea0le@s _@0 (a) before pre-­-processing (b) aGer pre-­-processing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of a sentence pair in NL and MRL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>state</head><label></label><figDesc>:: that :::::: border , state@1 ::::::::: next to 2@1 C/A1→ C/A1 1 C/A1 2 , C/A1 1 C/A1 2 state that border :::: texas :::: have :: the :::::: highest :::::::: population, :::::::</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example of a sentence pair with different alignments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 1 :</head><label>1</label><figDesc>Generating synthetic translation rules for unknown words Input: Unknown word wu in the source language Source side training data vocabulary: W Lexical translation tables T1 and T2 (two directions) Output: Synthetic translation rule set R for wu 1. foreach word wi in W 2. si = sim(wu, wi) 3. get the top n words W B = {wb1...wbn} with the highest {si} 4. R = φ 5. foreach wbi in W B 6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>SCFG</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>F1</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Example of translation rules in enriched SCFG, 

where underline and :::::::: underwave indicate the first and the sec-
ond phrases respectively. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Alignment performance.</head><label>3</label><figDesc></figDesc><table>F1 (reduced from 85.2). 
Effect of Word Alignment With respect to the 
performance over different alignment settings, we 
have the following observations from Table 2: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 : Performance with unknown word translation.</head><label>5</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 shows</head><label>6</label><figDesc></figDesc><table>the performance over 
four different languages. It shows that our ap-
proach, including enriched SCFG, tripling train-
ing data with three alignments, and unknown word 
translation, obtains consistent improvement over 
the four languages. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="true"><head>Table 6 : Performance for the multilingual GeoQuery test set.</head><label>6</label><figDesc></figDesc><table>System 
English 
German 
Greek 
Thai 
Acc. 
F1 
Acc. 
F1 
Acc. 
F1 
Acc. 
F1 
WASP 71.1 77.7 65.7 74.9 70.7 78.6 71.4 75.0 
SMT-SemParse 80.5 81.8 68.9 71.8 69.1 72.3 70.4 70.7 
HYBRIDTREE+ 76.8 81.0 62.1 68.5 69.3 74.6 73.6 76.7 
tsVB 79.3 79.3 74.6 74.6 75.4 75.4 78.2 78.2 
RHT 83.6 83.6 74.3 74.3 78.2 78.2 79.3 79.3 
f-RHT 86.8 86.8 75.7 75.7 79.3 79.3 80.7 80.7 
UBL 82.1 82.1 73.6 73.7 75.0 75.0 66.4 66.4 
this work 86.3 87.1 79.1 80.3 80.5 81.6 76.3 77.9 

</table></figure>

			<note place="foot" n="1"> As seen in Section 2, delimiters, including parentheses and commas which do not carry any meaning will be removed in pre-processing and be recovered in post-processing</note>

			<note place="foot" n="2"> In practice, non-terminal symbol S is used in glue rules. However, this is not relevant in the present discussion. 3 This is similar to the naming convention in combinatory categorial grammar (CCG) (Steedman, 2000)</note>

			<note place="foot" n="4"> If m = 0, it indicates that no function is needed.</note>

			<note place="foot" n="5"> Combining multiple alignments from different alignment models usually improves translation performance in SMT (Tu et al., 2012). However, our preliminary experiments showed that this did not yield higher improvement in semantic parsing, which in turn also demonstrates the difference in alignments for semantic parsing and SMT.</note>

			<note place="foot" n="7"> The NP list is from GeoQUery dataset in Jones et al. (2012), which contains MRs for every noun phrase that appears in the NL utterances of each language. As in Andreas et al. (2013), the NP list is included by appending all entries as extra training sentences with 50 times the weight of regular training examples, to ensure that they are learned as translation rules.</note>

			<note place="foot" n="8"> We manually aligned sentence pairs in NL and MRL .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Zhaopeng Tu, S. Matthew English and three anony-mous reviewers for providing helpful sugges-tions, and also acknowledge Jacob Andreas for help in running SMT-SemParse.</p><p>Junhui </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing as machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2013</title>
		<meeting>ACL 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2014</title>
		<meeting>ACL 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="313" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Online large-margin training of syntactic and structural translation features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2008</title>
		<meeting>EMNLP 2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the worlds response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL 2010</title>
		<meeting>CoNLL 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendra</forename><surname>Setiawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Eidelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010 System Demonstrations</title>
		<meeting>ACL 2010 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">IRSTLM: an open source toolkit for handling large scale language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1618" to="1621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A statistical semantic parser that integrates syntax and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semantic parsing with bayesian tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bevan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2012</title>
		<meeting>ACL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="488" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2010 System Demonstrations</title>
		<meeting>ACL 2010 System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2010</title>
		<meeting>EMNLP 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lexical generalization in ccg grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2011</title>
		<meeting>EMNLP 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1512" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2013</title>
		<meeting>EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1545" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using syntactic head information in hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT 2012</title>
		<meeting>WMT 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="232" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2011</title>
		<meeting>ACL 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2008</title>
		<meeting>EMNLP 2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic parsing with relaxed hybrid trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1308" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Constrained semantic forests for improved discriminative semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-IJCNLP 2015</title>
		<meeting>ACL-IJCNLP 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="737" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural language understanding using statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroSpeech</title>
		<meeting>EuroSpeech</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="2205" to="2208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kate</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using string-kernels for learning semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-COLING 2006</title>
		<meeting>ACL-COLING 2006</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Feature-based language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EuroSpeech</title>
		<meeting>EuroSpeech</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1435" to="1438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">BLEU: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2002</title>
		<meeting>ACL 2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2009</title>
		<meeting>EMNLP 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2008</title>
		<meeting>ACL 2008</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
