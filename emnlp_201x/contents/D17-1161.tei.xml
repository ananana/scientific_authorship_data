<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Concept Learning and Semantic Parsing from Natural Language Explanations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
							<email>ssrivastava@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15217</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
							<email>ilabutov@cs.cmu.edu tom.mitchell@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15217</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Department</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15217</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Concept Learning and Semantic Parsing from Natural Language Explanations</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1527" to="1536"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Natural language constitutes a predominant medium for much of human learning and pedagogy. We consider the problem of concept learning from natural language explanations, and a small number of labeled examples of the concept. For example, in learning the concept of a phish-ing email, one might say &apos;this is a phishing email because it asks for your bank account number&apos;. Solving this problem involves both learning to interpret open-ended natural language statements, as well as learning the concept itself. We present a joint model for (1) language interpretation (se-mantic parsing) and (2) concept learning (classification) that does not require labeling statements with logical forms. Instead, the model prefers discriminative interpretations of statements in context of observable features of the data as a weak signal for parsing. On a dataset of email-related concepts, this approach yields across-the-board improvements in classification performance , with a 30% relative improvement in F1 score over competitive classification methods in the low data regime.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ability to automatically learn concepts 1 from examples is a core cognitive ability, with applica- tions across diverse domains. Examples of such concepts include the concept of a 'negative review' in product reviews, the concept of 'check' over the domain of game states in chess, the concept of 'fraud' in credit history analysis, etc. Concept learn- ing is generally approached using classification methods that can automatically leverage regulari- ties in large amounts of labeled training data. How- ever, there are two shortcomings of this paradigm. First, labeling large amounts of data is unnatural compared to how a person might teach another per- son (e.g., a human secretary) in a similar situation. For example, for identifying emails about postdoc positions, a university professor might say 'These inquiries usually seek a postdoc opportunity and include a CV', rather than label scores of examples of such emails. Second, acquiring large quanti- ties of labeled data may be infeasible because of a long tail of concepts that are highly domain or user specific. For our example of a busy profes- sor, it might be relevant to teach concepts such as 'postdoc seeking emails', 'course related questions from students', etc. to an email assistant in order to better manage her/his inbox. However, these concepts might be irrelevant to a general user.</p><p>On the other hand, humans can efficiently learn about new concepts and phenomena through lan- guage. In fact, verbal and written language form the basis for much of human learning and pedagogy, as reflected in text-books, lectures and student-teacher dialogues. Natural language explanations can be a potent mode of supervision, and can alleviate issues of data sparsity by directly encoding rele- vant knowledge about concepts. <ref type="figure" target="#fig_0">Figure 1</ref> shows  <ref type="bibr">'</ref>This email is spam'), feature labeling (e.g., <ref type="bibr">'</ref>The word 'Viagra' indicates spam'), model ex- pectations ('Spam emails rarely come from edu extensions'), etc. However, here we focus on the ability of natural language to express rich and com- positional features for characterizing concepts.</p><p>In this paper, we address the task of learning concepts from natural language statements and a small number of labeled examples of the concept. <ref type="figure" target="#fig_1">Figure 2</ref> summarizes the outline of our approach. We map statements to logical interpretations, which can be evaluated in context of new instances. In doing this, each statement s effectively acts as a binary feature function {z = f s (x) ∈ {0, 1}} that fires when the interpretation of a statement s is true for an instance x. The crux of our approach is that correct interpretations of natural language explana- tions are more likely to be useful in discriminating concepts, and this observation can be used to guide both semantic interpretation and concept learning 2 .</p><p>In Section 3, we describe our probabilistic latent variable formulation that learns a semantic parser and a concept classifier from labeled examples of the concept. The latent variables correspond to evaluations of natural language statements for dif- ferent instances, and training proceeds via a gener- alized EM procedure that iteratively (1) estimates evaluations of explanations (marginalizing over all 2 e.g., a parser may associate multiple incorrect interpretations with the statement in <ref type="figure" target="#fig_1">Figure 2</ref> (like stringMatch(attachment stringVal ('usually'))), which are unlikely to help in discriminating instances of the concept. interpretations), and (2) updates the classification and semantic parsing models. The inputs to the method consist of a small number of labeled ex- amples and non-examples of a concept, natural language statements explaining the concept, and a domain specific lexicon. The method does not require labeling sentences with logical forms.</p><p>For our empirical evaluation, we focus on per- sonal emails, a practical example of a domain where target concepts are often highly individu- alized and labeled data is scarce. The contributions of this work are:</p><p>• We introduce the problem of concept learning from natural language. We also collect a corpus of emails about common email concepts, along with statements from human users explaining these concepts.</p><p>• We provide a method for concept learning and language understanding that can be trained from a small number of labeled concept instances. Thus, we extend supervised semantic parsing by learning from a weaker form of supervision than has previously been explored.</p><p>• We demonstrate that for small labeled data, using natural language statements can achieve substan- tial gains in classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Concept learning from labeled examples has been a dominant focus of research in supervised learning <ref type="bibr" target="#b6">(Caruana et al., 2008</ref>). Notable approaches such as Generalized Expectation ( <ref type="bibr" target="#b21">Mann and McCallum, 2010)</ref> and Posterior Regularization ( <ref type="bibr" target="#b11">Ganchev et al., 2010)</ref> have explored integration of manually pro- vided 'side-information' (feature and label con- straints) to guide machine learning models. Ear- lier work on Explanation-based learning ( <ref type="bibr" target="#b22">Mitchell et al., 1986;</ref><ref type="bibr" target="#b8">DeJong and Mooney, 1986)</ref> leverages structured knowledge to 'explain' why an exam- ple belongs to a concept. Recent work by <ref type="bibr" target="#b16">Lake et al. (2015)</ref> explores visual concept learning from few examples, and presents encouraging results for one-shot learning by learning representations over Bayesian programs. However, none of these address the issue of learning from natural language. Semantic interpretation of language has been explored in diverse domains. While semantic parsers have traditionally relied on labeled datasets of statements paired with labeled logical forms <ref type="bibr" target="#b25">(Zettlemoyer and Collins, 2005)</ref>, recent approaches have focused on training semantic parsers from denotations of logical forms, rather than logical forms themselves ( <ref type="bibr" target="#b15">Krishnamurthy and Mitchell, 2012;</ref><ref type="bibr" target="#b2">Berant et al., 2013)</ref>. Our work extends this paradigm by attempting to learn from still weaker signal, where denotations (evaluations) of logical forms too are not directly observed. Similar to our work, previous approaches have used different kinds of external-world signals to guide semantic interpretation ( <ref type="bibr" target="#b18">Liang et al., 2009;</ref><ref type="bibr" target="#b4">Branavan et al., 2009)</ref>. Natural instructions have been studied in game playing frameworks <ref type="bibr" target="#b5">(Branavan et al., 2012;</ref><ref type="bibr" target="#b9">Eisenstein et al., 2009</ref>). Our work is also closely related to work by <ref type="bibr" target="#b12">Goldwasser and Roth (2014)</ref>; <ref type="bibr" target="#b7">Clarke et al. (2010)</ref>, who also train semantic parsers in weakly supervised contexts, where language in- terpretation is integrated in real-world tasks. The general idea of learning through human interactions has previously been explored in settings such as be- havioral programming <ref type="bibr" target="#b13">(Harel et al., 2012</ref>), natural language programming <ref type="bibr" target="#b3">(Biermann, 1983)</ref>, learning by instruction ( <ref type="bibr" target="#b1">Azaria et al., 2016)</ref>, etc. To the best of our knowledge, this work is the first to use semantic interpretation to guide concept learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We consider concept learning problems in which the goal is to approximate an unknown classi- fication function f : X → Y where Y = {0, 1}. The input to our learning algorithm con- sists of a set of labeled training examples T := {(x 1 , y 1 ), . . . , (x m , y m )}, along with a set of nat- ural language statements S := {s 1 . . . s n } about the concept. Our aim is to leverage statements in S to learn a better classifier for the concept. Our training data does not contain any other form of supervision (such as logical forms).</p><p>Figure 3: Our data consist of instances x i with binary labels y i and statements s 1 . . . s n about a concept. z ij denotes whether the statement s j ap- plies to instance x i , and is not observed in the data.</p><p>We assume that each statement s j defines some Boolean property over the instances X; that is, statement s j should be interpreted as defining a predicate l j : X → {0, 1}. We augment the repre- sentation of each instance, x i , with a feature vec- tor z i , that encodes the information contained in S. The individual elements of this feature vec- tor, z ij ∈ {0, 1}, denote whether the statement s j applies to instance x i (see <ref type="figure">Figure 3</ref>). In the gen- eral case, the evaluation values z i 's are not directly observed. These are obtained by parsing each state- ment s j into a logical expression l j : X → {0, 1} which can be evaluated for an instance x i to obtain z ij = l j x i . Details of this evaluation are given in Section 3.4.</p><p>In this paper, we jointly learn a classifier and a semantic parser while treating z's as latent vari- ables. For training, we maximize the conditional log likelihood of the observed data. Let us consider the log likelihood for a single data instance (ignor- ing the subscript i) for now. Since the evaluations z of natural statements for any context are latent, we marginalize over these. Using Jensen's inequality, any distribution q over the latent variables provides a lower-bound on the data log-likelihood:</p><formula xml:id="formula_0">log p(y | x, S) = log z p(y, z | x, S) ≥ z q(z) log p(y, z | x, S) q(z) = z q(z) log p θc (y | z, x) classification + log p θp (z | x, S) parsing + H q (1)</formula><p>Here, H q is the entropy term for the distribution q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Coupling parsing and classification:</head><p>In Equation 1, we observe that the data likelihood decouples into the log probability of observing the concept labels p θc (y i | z, x) conditioned on the statement evaluations and the log probability of the latent statement evaluations p θp (z | x, S). In par- ticular, the first term can be naturally parametrized by a discriminative classifier such as a loglinear model (with associated parameters θ c ). We provide more details in Section 3.3.</p><p>On the other hand, the probability of the latent statement evaluation values z can be parametrized using a probabilistic semantic parsing model (with associated parameters θ p ). The second term de- couples over evaluations of individual statements (log p θp (z | x, S) = j log p θp (z j | x, s j )). In turn, since we never observe the correct interpre- tation l for any statement, but only model its eval- uation z j , we marginalize over all interpretations whose evaluations in a context x matches z j (simi- lar to <ref type="bibr" target="#b19">Liang et al. (2011)</ref>).</p><formula xml:id="formula_1">log p θp (z j | x, s j ) = log l:lx=z j p θp (l | s j ) (2)</formula><p>Following recent work in semantic parsing ( <ref type="bibr" target="#b20">Liang and Potts, 2015;</ref><ref type="bibr" target="#b15">Krishnamurthy and Mitchell, 2012)</ref>, we use a log-linear model over logical forms:</p><formula xml:id="formula_2">p θp (l | s) ∝ exp(θ p T φ(s, l))<label>(3)</label></formula><p>where φ(s, l) ∈ R d is a feature vector over state- ments s and logical interpretations l.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning:</head><p>In Equation 1, q(z) denotes a distribution over evaluation values of statements; whereas θ c and θ p denote the model parameters for the classifier and semantic parser. The learning algorithm consists of an iterative generalized EM procedure, which can be interpreted as a block-coordinate ascent in the estimates of statement evaluations q(z) and the model parameters θ c and θ p .</p><p>E-step: In the E-step, we update our estimates of evaluation variables (z). We make a mean-field ap- proximation by assuming that the joint distribution over evaluations decouples as q(z) = q j (z j ).</p><p>Then maximizing the lower bound in Equation 1 in terms of q j leads to the following update:</p><formula xml:id="formula_3">q j (z j ) ∝ exp E j =j [log p θc (z|x)]+log p θp (z j |x, s j )<label>(4)</label></formula><p>The first term in the update prefers values of an evaluation variable that are more discriminative on average (when values of other statements are marginalized out). The second term favours values of the evaluation variable that conforms with the most likely interpretations of the corresponding statement (s j ) by the semantic parser. Thus, in the E-step, we upweight evaluations of statements that are both discriminative, as well as supported by interpretations from the semantic parser.</p><p>M-step: In the M-step, we update the model param- eters to maximize the lower bound in Equation 1. This corresponds to independently optimizing the log likelihoods for the classification model and the semantic parser, based on current estimates of q j (z j )'s of the statement evaluations. The entropy term H q is constant from the perspective of model parameters, and is not relevant for the optimiza- tion. In particular, the semantic parser is updated to agree with evaluations of natural language state- ments that are discriminative. At the same time, the classification model is updated to fit evalua- tions that are supported by interpretations from the semantic parser.</p><p>We now describe the M-step updates for the log- linear semantic parser with parameters, θ p . The updates for the classifier parameters, θ c , depend on the form of the classification model, and are described in Section 3.3. For clarity, we focus on updates corresponding to a particular statement s j from the training dataset. From Equations 1, 2 and 3, the objective for the semantic parser is given by:</p><formula xml:id="formula_4">j(θp) = i z∈{0,1} q(zij) log l:lx i =z exp(θp T φ(sj, l)) l exp(θp T φ(sj, l))<label>(5)</label></formula><p>Semantic parsers are usually optimized using gra- dient updates. Here, the gradient is:</p><formula xml:id="formula_5">j(θp) = i,z,l q(zij)p θp (l | s) p θp (zij = z|xi, s) p θp (zij = z|xi, s) φ(sj, l)<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Classification models</head><p>The model and learning procedure described in Sec- tions 3.1 and 3.2 is agnostic to the choice of the classification model (with parameters θ c ). For this work, we experimented with a logistic classifier (LR) and a Naive Bayes model (NB). We briefly describe these here: Logistic Regression (LR): The form of the logis- tic function log p(y|z) = − log(1 + exp(-θ T c z y)) means that the likelihood does not decouple for individual components in z. Hence, in the E-step, the expectation in Equation 4 cannot be computed analytically. Instead, we estimate this by drawing Bernoulli samples for individual z j 's using previ- ous estimates of q j (z j ). In the M-step, we update classification parameters θ c using stochastic gradi- ent updates, while again sampling individual z j 's. Naive Bayes (NB): The likelihood for this model is p(y, z) = j θ z j cy (1 − θ cy ) 1−z j . In this case, the individual components of z decouple in the log like- lihood, leading to simple updates in both the E and M steps. While this is not a conditional likelihood Predicate Description and evaluation stringVal Returns string value corresponding to a text span in the statement getPhraseMention Looks for matching tokens or phrases in a target text, and return true if an exact match is found. e.g., The subject contains the word postdoc → getPhraseMention(subject,stringVal('postdoc')) getPhrasesLike</p><p>Uses an alignment based Textual Entailment (RTE) model to find the closest semantic match for a phrase in a text. Uses distributional semantics to identify semantically similar words. Returns true if a match is found. e.g., The emails often want me to buy something → getPhrasesLike(email,stringVal('buy something'))</p><p>getSemanticCategory Looks for occurrences of pre-specified semantic categories in a target text (identified with Stanford CoreNLP's expanded NER tagger), and returns true if a match is found. e.g., these emails often have contain prices and quotes → getSemanticCategory(body, MONEY) stringMatch</p><p>Returns true if one string value contains another. e.g., Spam emails are rarely from a yahoo or gmail address → not( or <ref type="figure">(stringMatch(sender, stringVal('yahoo')</ref> (as expected in Section 3.1), in our experiments we found that the NB objective to be empirically effective with our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Semantic Parsing details</head><p>Semantic parsing refers to mapping a sentence s like 'The subject contains the word postdoc' to a logical form l like getPhraseMention(subject, stringVal('postdoc')).</p><p>Logical forms can be evaluated in a context x (here, an email) to yield some meaningful output l x (whether the statement is true for an email). The predicates (such as stringVal) and constants (such as subject) come from a pre-specified logical language. Since our focus in this work is concepts about emails, we specify a logical language that is expressive enough to be useful for concept learning in this domain. <ref type="table">Table 1</ref> lists the predicates in our logical language along with descriptions of their evaluation, and some illustrative examples showing how they can represent the meaning of natural statements 3 . Note that this logical language can express compositional meanings. e.g., 'These inquiries will usually seek a postdoc opportunity <ref type="bibr">3</ref> We include a special predicate (unknown) to label state- ments whose meanings go beyond our logical language (last row in <ref type="table">Table 1</ref>), essentially ignoring them. Such statements compose about 25% of our data. An agent should ideally be able to ask a user about unfamiliar concepts such as 'weird email addresses' that occur in explanations. See Section 6. and include a CV' can be expressed as and (getPhrasesLike(email, stringVal('seek postdoc opportunity')), (stringMatch attachment (stringVal'CV'))). The evalua- tions of some predicates uses NLP tools that go beyond exact keyword matching. In Section 5, we show that it is language understanding (semantic parsing), rather than these resources, which enables learning from natural explanations.</p><p>Semantic parsers involve grammars containing mappings from words to symbols in the logical lan- guage, as well as coarse syntactic rules. The gram- mar specifies the possible set of logical interpreta- tions that can be associated with a natural language sentence. For this work, we use CCG based seman- tic parsing, a popular semantic parsing approach <ref type="bibr" target="#b25">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b0">Artzi et al., 2015</ref>) that couples syntax with semantics. For the CCG grammar, we manually compile a domain lexicon containing a list of trigger words mapped to their syntactic categories and associated logical predi- cates. e.g. {'subject', NP, subject}. We then use the PAL lexicon induction algorithm <ref type="bibr" target="#b14">(Krishnamurthy, 2016</ref>) to expand the lexicon by adding automatically generated entries. For training the parser, we follow the feature set from <ref type="bibr" target="#b26">(Zettlemoyer and Collins, 2007)</ref>, consisting of indicator features for lexicon entries and rule applications that fire for a given parse of a logical form. We also include string based features denoting the number of words in a string span, and whether a string spans occur at the beginning or end of the utterance. For retriev- ing the best parses for a statement, we use beam search with a beam size of 500.</p><p>While we have chosen a particular instantia- tion of a semantic parsing formalism, our learning approach is independent of the semantic parsing framework in principle, and only assumes a log- linear parametrization over logical interpretations of sentences. Thus, while we present results for a particular parsing framework and lexicon, the method may conceptually extend to other parsing formalisms such as DCS <ref type="figure" target="#fig_0">(Liang et al., 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>We created a dataset of 1,030 emails paired with 235 natural language statements made by human users in the process of teaching a set of seven con- cepts. The dataset was collected using the Amazon Mechanical Turk crowdsourcing platform. We de- ployed two tasks: (i) a Generation task requiring workers to create original emails, and (ii) a Teach- ing task requiring workers to write statements that characterize a concept. Below, we describe the data and the two tasks in more detail.</p><p>We create an email corpus, rather than use an existing corpus such as Enron, since we wanted diverse examples representative of everyday con- cepts that most people would be able to understand as well as teach to a computer. Much of the En- ron corpus is highly specific and contextualized, making it difficult to teach for an outsider.</p><p>The Generation task consisted of a web-page resembling a traditional email composition form (with fields: recipient, subject, body, attachment), requiring workers to compose emails in a grounded setting. For this task, we recruited 146 workers residing in the United States. The workers were presented with each of the seven concepts in a se- quence, where each concept was represented by a short prompt encouraging workers to imagine a scenario (e.g., a boss writing a request to an em- ployee) and write a hypothetical email. See <ref type="table">Table 2</ref> for details of email concepts and corresponding prompts. Workers were instructed to be realistic (e.g., to include an attachment if an email is likely to have an attachment in reality), but also creative (to encourage diversity) in composing their emails.</p><p>The Teaching task was then deployed to col- lect natural language statements that people would <ref type="figure">Figure 4</ref>: The Teaching task used to collect natural language statements characterizing a concept. Each worker is given a concept prompt, together with a set of emails. A turker can enter five statements characterizing the concept.</p><p>These emails usually closes with a name or title Some reminders will have a date and time in the subject The body of the email may say funny, picture, or internet Messages to friends sometimes have jpg attachments Emails from a public domain are not office requests <ref type="table">Table 3</ref>: Examples of natural language statements collected from the Teaching task make to teach a particular concept to a machine. Workers were presented with five randomly se- lected concepts using the same prompts <ref type="table">(Table 2</ref>) used in the Generation task. For each concept, a small sample of emails were shown in a style resem- bling a traditional email inbox <ref type="figure">(Figure 4</ref>) to illus- trate the concept. Half of the emails were from the prompted concept (these emails were highlighted and "starred"), and half were sampled randomly from the other concepts. Workers were encouraged to peruse through the emails while creating up to five statements explaining the concept. A follow- up quiz assessed an understanding of the task, and contributions from workers with low scores were filtered. The final data contains between 30 and 35 statements describing each category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In this section, we evaluate the performance of our approach from the perspectives of concept learn-Concept # of emails Prompt CONTACT 167 "You are writing an email to yourself to personally keep note of a person contact" EMPLOYEE 149 "You are a boss writing an email to your employee requesting something to be done" EVENT 138 "You are writing an email to a friend asking to meet up at some event" HUMOR 134 "You are writing an email to a friend that includes something humorous from the Internet" MEETING 142 "You are writing an email to a colleague trying to request a meeting about something" POLICY 146 "You are writing an office email regarding announcement of some new policy" REMINDER 154 "You are writing an email to yourself as a reminder to do something" <ref type="table">Table 2</ref>: Email concepts used in our experiment, together with the prompts used to describe the concept to workers. The same prompt was used in both the Generation and Teaching tasks.</p><p>CONTACT  <ref type="table">Table 4</ref>: Concept learning performance (F1 scores) using n = 10 labeled examples. Columns indicate different concept learning tasks defined over emails. * for the rows corresponding to LNL-NB and LNL-LR denotes statistical significance over the best performing non-LNL model ing as well as semantic parsing. We first compare our methods against traditional supervised learn- ing methods on the task of learning email-based concepts described in the previous section. Our baselines include the following models: Text-only models:</p><p>• BoW: A logistic regression (LR) classifier over bag-of-words representation of emails • BoW tf-idf: LR classifier over bag-of-words rep- resentation, with tf-idf weighting • Para2Vec: LR classifier over a distributed repre- sentation of documents, using deep neural net- work approach by <ref type="bibr" target="#b17">Le and Mikolov (2014)</ref>.</p><p>• Bigram: LR model also incorporating bigram features, known to be competitive on several text classification tasks ( <ref type="bibr" target="#b24">Wang and Manning, 2012</ref>).</p><p>• ESA: LR model over ESA (Explicit Semantic Analysis) representations of emails ( <ref type="bibr" target="#b10">Gabrilovich and Markovitch, 2007)</ref>, which describe a text in terms of its Wikipedia topics. Models incorporating Statements:</p><p>• RTE: This uses a Textual Entailment model (based on features from <ref type="bibr" target="#b23">Sachan et al. (2015)</ref>) that computes a score for aligning of each statement to the text of each email. A logistic regression is trained over this representation of the data.</p><p>• Keyword filtering: Filters based on keywords are common in email systems. We add this as a base- line by manually filtering statements referring to occurrences of specific keywords. Such state- ments compose nearly 30% of the data. We train a logistic regression over this representation. <ref type="table">Table 4</ref> shows classification performance of our approaches for Learning from Natural Language (LNL) against baselines described above for n = 10 labeled examples. The reported numbers are aver- age F1 scores over 10 data draws. We observe that Bigram and bag-of-word methods are the most com- petitive among the baselines. On the other hand, Para2Vec doesn't perform well, probably due to the relatively small scale of the available training data, while ESA fails due to the lack of topical asso- ciations in concepts. However, most significantly, we observe that both LNL-NB (Naive Bayes) and LNL-LR (Logistic Regression) dramatically outper- form all baselines for most concepts (except EM- PLOYEE), and show a 30% relative improvement in average F1 over other methods (p &lt; 0.05, Paired Permutation test). Interestingly, we note that LNL- NB and LNL-LR show similar performance for most concepts. For evaluating semantic parsing of natu- ral language statements, we manually annotated the statements in our dataset using the logical language described in Section 3.4. In <ref type="table">Table 4</ref>, LNL-Gold denotes the classification performance with using these annotated gold parses. This corresponds to the hypothetical case where the classifier knows the correct semantic interpretation of each natu- ral language sentence from an oracle. While this provides a further 10% relative improvement over our proposed models, the results suggest that our weakly supervised method is quite effective in in- terpreting natural language statements for concept learning, without explicit supervision. We also ob- serve that LNL models perform significantly better than Keyword filtering (p &lt; 0.05), indicating that the model leverages the expressiveness of our logi- cal language.</p><p>Finally, the last three rows show performance when the LNL methods also utilize BoW represen- tations of the data. The further gains over the base LNL models suggest that original feature represen- tations and natural language explanations contain complementary information for many concepts.</p><p>A significant motivation for this work is the promise of natural language explanations in facili- tating concept learning with a relatively small num- ber of examples. <ref type="figure" target="#fig_2">Figure 5</ref> shows the dependence of concept learning performance of LNL(-LR) on the number of labeled training examples (size of training set). We observe that while our approach consistently outperforms the bag-of-words model (BoW), LNL also requires fewer examples to reach near optimal performance, before it plateaus. In particular, the generalization performance for LNL is more robust than BoW for n &lt; 10. The per- formance trajectory for LNL(-NB) is similar, and omitted in the figure for clarity.   <ref type="table">Table 5</ref>: Semantic parsing performance (exact match) for proposed weakly supervised methods vs full supervision (completely labeled logical forms)</p><p>Parsing performance: We next evaluate the pars- ing performance of our approach, which learns a semantic parser from only concept labels of exam- ples. <ref type="table">Table 5</ref> evaluates parsing performance against the gold annotation logical forms for statements. For this task, we check for exact match of logical forms. In the table, full supervision refers to tradi- tional training of a semantic parser using complete annotations of statements with their logical forms <ref type="bibr" target="#b26">(Zettlemoyer and Collins, 2007)</ref>. The results report average accuracy over 10-fold CV, and demonstrate that while not comparable to supervised parsing, our weakly supervised approach is relatively effec- tive in learning semantic parsers.</p><p>Further, exact match to gold annotated log- ical forms is a restrictive measure. Qualita- tive analysis revealed that even when the pre- dicted and gold annotation logical forms don't match, predicted logical forms are often strongly correlated in terms of evaluation to gold an- notations.</p><p>e.g., getPhraseMention( email, stringVal('postdoc')) vs getPhraseMention( body, stringVal('postdoc')). In about 5% of cases, predicted and gold interpretations are dif- ferent on the surface, but are semantically equiv- alent (e.g., stringEquals( sender, recipient) vs stringEquals( recipient, sender)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concept learning vs language interpretation:</head><p>To delineate the relationship between parsing per- formance and concept learning more clearly, we plot concept classification performance for differ- ent levels of semantic parsing proficiency in <ref type="figure" target="#fig_3">Fig- ure 6</ref>. For this, we choose the gold annotation logical form for a statement with a probability cor- responding to the semantic parsing accuracy, or randomly select a candidate logical form with a uniform probability otherwise for all the statements in our data. The figure shows a (expectedly) strong association between parsing performance and con- cept learning, although gains from parsing taper after a certain level of proficiency. This is partially explained by the fact that natural statements in our data often contain overlapping information, and that the set of statements in our data set may not be sufficient to achieve perfect classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>We show that natural language explanations can be utilized by supervised learning methods to sig- nificantly improve generalization. This suggests a broader class of possible machine learning inter- faces that use language to not only expedite learn- ing, but make machine learning accessible to every- day users. Thus, we hope that the current work will inspire further explorations in learning from natu- ral language explanations. In terms of scalability, learning from language would require specification of a logical language and a lexicon of trigger words for each new domain. However, this effort is one- time, and can find re-use across the long tail of concepts in a domain.</p><p>A consequence of the expressiveness of language is that in describing a concept, humans often invoke other concepts that may not correspond to existing predicates in the logical language. A natural so- lution could detect that a feature described in the statement is novel <ref type="bibr">4</ref> , and request the user to teach the unknown concept. The same principle can be applied recursively, resulting in a mixed-initiative dialog, much like between a student and a teacher. Future work can also incorporate other modes of supervision from language. For example, this work ignores modifiers such as 'always' and 'usually', which often carry valuable information that could be incorporated via model expectation constraints.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of concepts explained using natural language statements.</figDesc><graphic url="image-1.png" coords="1,307.28,222.54,222.23,101.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Schematic representation of approach</figDesc><graphic url="image-2.png" coords="2,72.00,62.81,222.24,185.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Figure showing Avg F1 accuracy over all concepts vs Number of labeled training examples</figDesc><graphic url="image-5.png" coords="8,72.00,602.06,222.24,123.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Figure showing concept classification performance vs parsing accuracy</figDesc><graphic url="image-6.png" coords="9,90.43,62.81,181.42,111.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>vs Number of labeled training examples</figDesc><table>Accuracy 
Fully Supervised (ZC07) 
0.63 
LNL-LR 
0.30 
LNL-NB 
0.28 
No training 
0.01 

</table></figure>

			<note place="foot" n="1"> where a concept is any Boolean function on some domain of instances.</note>

			<note place="foot" n="4"> currently the parser returns (unknown) for such statements anonymous reviewers for helpful comments and suggestions.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Yahoo! In-Mind project. The authors thank Sujay Jauhar and</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Broad-coverage ccg semantic parsing with amr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1699" to="1710" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Instructable intelligent personal agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Azaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2681" to="2689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Natural language programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Biermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Program Synthesis Methodologies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1983" />
			<biblScope unit="page" from="335" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reinforcement learning for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harr</forename><surname>Srk Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to win by reading manuals in a monte-carlo framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Srk Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="661" to="704" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An empirical evaluation of supervised learning in high dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Karampatziakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ainur</forename><surname>Yessenalina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Roth</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth conference on computational natural language learning</title>
		<meeting>the fourteenth conference on computational natural language learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="18" to="27" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explanation-based learning: An alternative view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Dejong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="176" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reading to learn: Constructing features from semantic abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="958" to="967" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Computing semantic relatedness using wikipediabased explicit semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07</title>
		<meeting>the 20th International Joint Conference on Artifical Intelligence, IJCAI&apos;07<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Posterior regularization for structured latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Gillenwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2001" to="2049" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning from natural instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="232" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Behavioral programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gera</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="90" to="100" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic models for learning a semantic parser lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="606" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="754" to="765" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th International Conference on Machine Learning</title>
		<meeting>the 31th International Conference on Machine Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning semantic correspondences with less supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="590" to="599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bringing machine learning and compositional semantics together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Linguist</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="355" to="376" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generalized expectation criteria for semi-supervised learning with weakly labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gideon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="955" to="984" />
			<date type="published" when="2010-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explanation-based generalization: A unifying view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smadar T Kedar-Cabelli</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="80" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning answerentailing structures for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumar</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Baselines and bigrams: Simple, good sentiment and topic classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="90" to="94" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI &apos;05, Proceedings of the 21st Conference in Uncertainty in Artificial Intelligence</title>
		<meeting><address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-07-26" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Online learning of relaxed ccg grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
