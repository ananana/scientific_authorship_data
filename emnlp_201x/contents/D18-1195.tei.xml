<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:11+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Learn Semantic Parsers from Natural Language Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
							<email>igor.labutov@laer.ai</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAER AI</orgName>
								<orgName type="institution" key="instit1">LAER AI, Inc. New York</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>NY, Inc. New York, NY, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
							<email>bishan.yang@laer.ai</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAER AI</orgName>
								<orgName type="institution" key="instit1">LAER AI, Inc. New York</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>NY, Inc. New York, NY, PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
							<email>tom.mitchell@cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">LAER AI</orgName>
								<orgName type="institution" key="instit1">LAER AI, Inc. New York</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>NY, Inc. New York, NY, PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Learn Semantic Parsers from Natural Language Supervision</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1676" to="1690"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As humans, we often rely on language to learn language. For example, when corrected in a conversation, we may learn from that correction , over time improving our language fluency. Inspired by this observation, we propose a learning algorithm for training semantic parsers from supervision (feedback) expressed in natural language. Our algorithm learns a semantic parser from users&apos; corrections such as &quot;no, what I really meant was before his job, not after&quot;, by also simultaneously learning to parse this natural language feedback in order to leverage it as a form of supervision. Unlike supervision with gold-standard logical forms, our method does not require the user to be familiar with the underlying logical formalism , and unlike supervision from denotation, it does not require the user to know the correct answer to their query. This makes our learning algorithm naturally scalable in settings where existing conversational logs are available and can be leveraged as training data. We construct a novel dataset of natural language feedback in a conversational setting, and show that our method is effective at learning a semantic parser from such natural language supervision.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing is a problem of mapping a natu- ral language utterance into a formal meaning rep- resentation, e.g., an executable logical form <ref type="bibr" target="#b12">(Zelle and Mooney, 1996)</ref>. Because the space of all logi- cal forms is large but constrained by an underlying structure (i.e., all trees), the problem of learning a semantic parser is commonly formulated as an in- stance of structured prediction.</p><p>Historically, approaches based on supervised learning of structured prediction models have emerged as some of the first and still remain com- mon in the semantic parsing community (Zettle- * Work done while at Carnegie Mellon University. moyer and <ref type="bibr" target="#b13">Collins, 2005</ref><ref type="bibr">Collins, , 2009</ref><ref type="bibr">Kwiatkowski et al., 2010)</ref>. A well recognized practical chal- lenge in supervised learning of structured mod- els is that fully annotated structures (e.g., logical forms) that are needed for training are often highly labor-intensive to collect. This problem is further exacerbated in semantic parsing by the fact that these annotations can only be done by people fa- miliar with the underlying logical language, mak- ing it challenging to construct large scale datasets by non-experts.</p><p>Over the years, this practical observation has spurred many creative solutions to training seman- tic parsers that are capable of leveraging weaker forms of supervision, amenable to non-experts. One such weaker form of supervision relies on logical form denotations (i.e, the results of a logi- cal form's execution) -rather than the logical form itself, as "supervisory" signal ( <ref type="bibr">Clarke et al., 2010;</ref><ref type="bibr">Liang et al., 2013;</ref><ref type="bibr">Berant et al., 2013;</ref><ref type="bibr" target="#b4">Pasupat and Liang, 2015;</ref><ref type="bibr">Liang et al., 2016;</ref><ref type="bibr">Krishnamurthy et al., 2017)</ref>. In Question Answeing (QA), for example, this means the annotator needs only to know the answer to a question, rather than the full SQL query needed to obtain that answer. Para- phrasing of utterances already annotated with log- ical forms is another practical approach to scale up annotation without requiring experts with a knowl- edge of the underlying logical formalism <ref type="bibr">(Berant and Liang, 2014;</ref><ref type="bibr" target="#b9">Wang et al., 2015)</ref>.</p><p>Although these and similar methods do reduce the difficulty of the annotation task, collecting even these weaker forms of supervision (e.g., de- notations and paraphrases) still requires a dedi- cated annotation event, that occurs outside of the normal interactions between the end-user and the semantic parser <ref type="bibr">1</ref> . Furthermore, expert knowledge may still be required, even if the underlying logi-cal form does not need to be given by the annotator (QA denotations, for example, require the annota- tor to know the correct answer to the question -an assumption which doesn't hold for end-users who asked the question with the goal of obtaining the answer). In contrast, our goal is to leverage natural language feedback and corrections that may occur naturally as part of the continuous interaction with the non-expert end-user, as training signal to learn a semantic parser.</p><p>The core challenge in leveraging natural lan- guage feedback as a form of supervision in train- ing semantic parsers, however, is the challenge of correctly parsing that feedback to extract the su- pervisory signal embedded in it. Parsing the feed- back, just like parsing the original utterance, re- quires its own semantic parser trained to inter- pret that feedback. Motivated by this observa- tion, our main contribution in this work is a semi- supervised learning algorithm that learns a task parser (e.g., a question parser) from feedback ut- terances while simultaneously learning a parser to interpret the feedback utterances. Our algorithm relies only on a small number of annotated logical forms, and can continue learning as more feedback is collected from interactions with the user.</p><p>Because our model learns from supervision that it simultaneously learns to interpret, we call our approach learning to learn semantic parsers from natural language supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>Formally, the setting proposed in this work can be modelled as follows: (i) the user poses a natural language input u i (e.g., a question) to the system, (ii) the system parses the user's utterance u i , pro- ducing a logical formˆyformˆ formˆy i , (iii) the system commu- nicatesˆynicatesˆ nicatesˆy i to the user in natural language in the form of a confirmation (i.e., "did you mean . . . "), (iv) in response to the system's confirmation, the user generates a feedback utterance f i , which may be a correction ofˆyofˆ ofˆy i expressed in natural language. The observed variables in a single interaction are the task utterance u i , the predicted task logical formˆyformˆ formˆy i and the user's feedback f i ; the true logical form y i is hidden. See <ref type="figure">Figure 1</ref> for an illustration.</p><p>A key observation that we make from the above formulation is that learning from such interactions can be effectively done in an offline (i.e., non- interactive) setting, using only the logs of past in- teractions with the user. Our aim is to formulate a model that can learn a task semantic parser (i.e., one parsing the original utterance u) from such in- teraction logs, without access to the true logical forms (or denotations) of the users' requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Modelling conversational logs</head><p>Formally, we propose to learn a semantic parser from conversational logs represented as follows:</p><formula xml:id="formula_0">D = {(u i , ˆ y i , f i )} i,...,N</formula><p>where u i is the user's task utterance (e.g., a ques- tion), ˆ y i is the system's original parse (logical form) of that utterance, f i is the user's natural lan- guage feedback towards that original parse and N is the number of dialog turns in the log. Note that the original parsê y i of utterance u i could come from any semantic parser that was deployed at the time the data was logged -there are no assump- tions made on the source of howˆyhowˆ howˆy i was produced.</p><p>Contrast this with the traditional learning set- tings for semantic parsers, where the user (or an- notator) provides the correct logical form y i or the execution of the correct logical form y i (deno- tation) <ref type="table">(Table 1)</ref>. In our setting, instead of the correct logical form y i , we only have access to the logical form produced by whatever semantic parser was interacting with the user at the time the data was collected, i.e., ˆ y i is not necessarily the correct logical form (though it could be). In this work, however, we focus only on corrective feed- back (i.e., cases wherê y = y) as our main objec- tive is to evaluate the ability to interpret rich natu- ral language feedback (which is only given when the original parse is incorrect). Our key hypothesis in this work is that although we do not observe y i directly, combiningˆycombiningˆ combiningˆy i with the user's feedback f i should be sufficient to get a better estimate of the correct logical form (closer to y i ), which we can then leverage as a "training example" to improve the task parser (and the feedback parser).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervision</head><p>Dataset Full logical forms {(ui, yi)}i,...,N Denotations {(ui, yi)}i,...,N Binary feedback {(ui, ˆ yi = yi)}i,...,N NL feedback (this work) {(ui, ˆ yi, fi)}i,...,N <ref type="table">Table 1</ref>: Different types of supervision used in litera- ture for training semantic parsers, and the correspond- ing data needed for each type of supervision. Notation used in the table: u corresponds to user utterance (lan- guage), y corresponds to a gold-standard logical form parse of u, ˆ y corresponds to a predicted logical form,</p><p>· is the result of executing an expression inside the brackets and f is the user's feedback expressed in nat- ural language in the context of an utterance and a pre- dicted logical form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Natural Language Supervision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning problem formulation</head><p>In this section, we propose a learning algorithm for training a semantic parser from natural language feedback. We will use the terms task parser and feedback parser to refer to the two distinct parsers used for parsing the user's original task utterance (e.g., question) and parsing the user's follow-up feedback utterance respectively. Our learning al- gorithm does not assume any specific underlying model for the two parsers aside from the require- ment that each parser specifies a probability distri- bution over logical forms given the utterance (for the task parser) and the utterance plus feedback (for the feedback parser):</p><formula xml:id="formula_1">Task Parser: P (y | u; θ t ) Feedback Parser: P (y | u, f, ˆ y; θ f )</formula><p>where θ t and θ f parametrize the task and feedback parsers respectively. Note that the key distinction between the task and feedback parser models is that in addition to the user's original task utterance u, the feedback parser also has access to the user's feedback utterance f , and the original parser's pre- dictionˆydictionˆ dictionˆy. We now introduce a joint model that combines task and feedback parsers in a way that encourages the two models to agree:</p><formula xml:id="formula_2">P (y | u, f, ˆ y; θt, θ f ) = 1 Z P (y | u; θt) task parser P (y | u, f, ˆ y; θ f ) feedback parser</formula><p>At training time, our objective is to maximize the above joint likelihood by optimizing the parser pa- rameters θ t and θ f of the task and feedback parsers respectively. The intuition behind optimizing the joint objective is that it encourages the "weaker" model that does not have access to the feedback utterance to agree with the "stronger" model that does (i.e., using the feedback parser's prediction as a noisy "label" to bootstrap the task parser), while conversely encouraging a more "complex" model to agree with a "simpler" model (i.e., using the simpler task parser model as a "regularizer" for the more complex feedback parser; note that the feed- back parser generally has higher model complex- ity compared to the task parser because it incorpo- rates additional parameters to account for process- ing the feedback input). <ref type="bibr">2</ref> Note the feedback parser output is not simply the meaning of the feed- back utterance in isolation, but instead the revised semantic interpretation of the original utterance, guided by the feedback utterance. In this sense, the task faced by the feedback parser is to both de- termine the meaning of the feedback, and to apply that feedback to repair the original interpretation of u i . Note that this model is closely related to co-training <ref type="bibr">(Blum and Mitchell, 1998</ref>) (and more generally multi-view learning ( <ref type="bibr" target="#b11">Xu et al., 2013)</ref>) and is also a special case of a product-of-experts (PoE) model (Hinton, 1999).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning</head><p>The problem of maximizing the joint-likelihood P (y | u, f, ˆ y; θ t , θ f ) can be approached as a stan- dard problem of maximum likelihood estimation in the presence of latent variables (i.e., unob- served logical form y), suggesting the application of the Expectation Maximization (EM) algorithm for learning parameters θ t and θ f . The direct ap- plication of EM in our setting, however, is faced with a complication in the E-step. Because the hidden variables (logical forms y) are structured, computing the posterior over the space of all log- ical forms and taking the expectation of the log- likelihood with respect to that posterior is gener- ally intractable (unless we assume certain factor- ized forms for the logical form likelihood).</p><p>Instead, we propose to approximate the E-step by replacing the expectation of the log joint- likelihood with its point estimate, using the maxi- mum a posteriori (MAP) estimate of the posterior over logical forms y to obtain that estimate (this is sometimes referred to as "hard-EM"). Obtain- ing the MAP estimate of the posterior over log-ical forms may itself be a difficult optimization problem, and the specific algorithm for obtaining it would depend on the internal models of the task and the feedback parser.</p><p>As an alternative, we propose a simple, MCMC based algorithm for approximating the MAP esti- mate of the posterior over logical forms, that does not require access to the internals of the parser models, i.e., allowing us to conveniently treat both parsers as "black boxes". The only assumption that we make is that it's easy to sample logi- cal forms from the individual parsers (though not necessarily from the joint model), as well as to compute the likelihoods of those sampled logical forms under at least one of the models.</p><p>We use Metropolis Hastings to sample from the posterior over logical forms, using one of the parser models as the proposal distribution. Specif- ically, if we choose the feedback parser as the pro- posal distribution, and initialize the Markov Chain with a logical form sampled from the task parser, it can be shown that the acceptance probability r for the first sample conveniently simplifies to the following expression:</p><formula xml:id="formula_3">r = min 1, P (ˆ y f | u, θt) P (ˆ yt | u, θt)<label>(1)</label></formula><p>wherê y t andˆyandˆ andˆy f are logical forms sampled from the task and feedback parsers respectively. In- tuitively the above expression compares the like- lihood of the logical form proposed by the task parser to the likelihood of the logical form pro- posed by the feedback parser, but with both likeli- hoods computed under the same task parser model (making the comparison fair). The proposed parse is then accepted with a probability proportional to that ratio. See Algorithm 2 for details.</p><p>Finally, given this MAP estimate of y, we can perform optimization over the parser parameters θ t and θ f using a single step with stochastic gradi- ent descent before re-estimating the latent logical form y. We also approximate the gradients of each parser model by ignoring the gradient terms asso- ciated with the log of the normalizer Z. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task Parser Model</head><p>Our task parser model is implemented based on existing attention-based encoder-decoder mod-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Semantic Parser Training from Natural Language Supervision</head><p>Input : D = {(ui, ˆ yi, fi)}1,...,N Output : Task parser parameters θt; Feedback parser parameters θ f Parameter: Number of training epochs</p><formula xml:id="formula_4">T for t = 1 to T do for i = 1 to N dôdô y f i ← MH-MAP (ui, ˆ yi, fi, θt, θ f ) ; θt ← log P (ˆ y f i | ui; θt) ; θ f ← log P (ˆ y f i | ui, fi, ˆ yi; θ f ) ; θt ← SGD (θt, θt) ; θ f ← SGD (θ f , θ f ) ; end end Algorithm 2: Metropolis Hastings-based MAP estima- tion of latent semantic parse Input : u, ˆ y, f , θt, θ f Output : latent parsê y f Parameter: Number of sampling iterations N Function MH-MAP(u, ˆ y, f , θt, θ f ): samples ← [ ] // sample parse from task parser Samplê yt ∼ P (y | u, θt) ˆ ycurr ← ˆ yt for i = 1 to N do // sample parse from feedback parser Samplê y f ∼ P (y | u, f, ˆ y, θ f ) r ← min 1, P (ˆ y f |u,θ t ) P (ˆ ycurr |u,θ t ) Sample accept ∼ Bernoulli(r) if accept then pt ← P (ˆ y f | u, θt) p f ← P (ˆ y f | u, f, ˆ y, θ f ) samples[ˆ y f ] ← pt · p f ˆ ycurr ← ˆ</formula><p>y f end endˆy endˆ endˆy f ← argmax samples returnˆyreturnˆ returnˆy f els ( <ref type="bibr">Bahdanau et al., 2014;</ref><ref type="bibr">Luong et al., 2015)</ref>. The encoder takes in an utterance (tokenized) u and computes a context-sensitive embedding h i for each token u i using a bidirectional Long Short- Term Memory (LSTM) network <ref type="bibr">(Hochreiter and Schmidhuber, 1997)</ref>, where h i is computed as the concatenation of the hidden states at position i output by the forward LSTM and the backward LSTM. The decoder generates the output logical form y one token at a time using another LSTM. At each time step j, it generates y j based on the current LSTM hidden state s j , a summary of the input context c j , and attention scores a ji , which are used for attention-based copying as in <ref type="bibr">(Jia and Liang, 2016)</ref>. Specifically,</p><formula xml:id="formula_5">p(y j = w, w ∈ V out |u, y 1:j−1 ) ∝ exp (W o [s j ; c j ]) p(y j = u i |u, y 1:j−1 ) ∝ exp (a ji )</formula><p>where y j = w denotes that y j is chosen from the output vocabulary V out ; y j = u i denotes that y j is a copy of u i ; a ji = s T j W a h i is an attention score on the input word u i ; c j = i α i h i , α i ∝ exp (a ji ) is a context vector that summarizes the encoder states; and W o and W a are matrix parame- ters to be learned. After generating y j , the decoder LSTM updates its hidden state s j+1 by taking as input the concatenation of the embedding vector for y j and the context vector c j .</p><p>An important problem in semantic parsing for conversation is resolving references of people and things mentioned in the dialog context. Instead of treating coreference resolution as a separate prob- lem, we propose a simple way to resolve it as a part of semantic parsing. For each input utterance, we record a list of previously-occurring entity men- tions m = {m 1 , ..., m L }. We consider entity men- tions of four types: persons, organizations, times, and topics. The encoder now takes in an utterance u concatenated with m 4 , and the decoder can gen- erate a referenced mention through copying.</p><p>The top parts of <ref type="figure">Figure 7</ref> and <ref type="figure">Figure 8</ref> visualize the attention mechanism of the task parser, where the decoder attends to both the utterance and the conversational context during decoding. Note that the conversational context is only useful when the utterance contains reference mentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Feedback Parser Model</head><p>Our feedback parser model is an extension of the encoder-decoder model in the previous section. The encoder consists of two bidirectional LSTMs: one encodes the input utterance u along with the history of entity mentions m and the other encodes the user feedback f . At each time step j during decoding, the decoder computes attention scores over each word u i in utterance u as well as each feedback word f k based on the decoder hidden state s j , the context embedding b k output by the feedback encoder, and a learnable weight matrix</p><formula xml:id="formula_6">W e : e jk = s T j W e b k .</formula><p>The input context vector c j in the previous section is updated by adding a con- text vector that attends to both the utterance and the feedback:</p><formula xml:id="formula_7">c j = i α i h i + k β k b k 4</formula><p>The mentions are ordered based on their types and each mention is wrapped by special boundary symbols <ref type="bibr">[ and ]</ref>.</p><p>where α i ∝ exp(a ji ) and β k ∝ exp(e jk ). Ac- cordingly, the decoder is allowed to copy words from the feedback:</p><formula xml:id="formula_8">p(y j = f k |u, f, y 1:j−1 ) ∝ exp (e jk )</formula><p>The bottom parts of <ref type="figure">Figure 7</ref> and <ref type="figure">Figure 8</ref> vi- sualize the attention mechanism of the feedback parser, where the decoder attends to the utterance, the conversational context, and the feedback dur- ing decoding.</p><p>Note that our feedback model does not explic- itly incorporate the original logical formˆyformˆ formˆy that the user was generating their feedback towards. We experimented with a number of ways to incorpo- ratê y in the feedback parser model, but found it most effective to instead use it during MAP infer- ence for the latent parse y. In sampling a logical form in Algorithm 2, we simply reject the sample if the sampled logical form matchesˆymatchesˆ matchesˆy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dataset</head><p>In this work we focus on the problem of semantic parsing in a conversational setting and construct a new dataset for this task. Note that a parser is re- quired to resolve references to the conversational context during parsing, which in turn may further amplify ambiguity and propagate errors to the fi- nal logical form. Conveniently, the same conver- sational setting also offers a natural channel for correcting such errors via natural language feed- back users can express as part of the conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset construction</head><p>We choose conversational search in the domain of email and biographical research as a setting for our dataset. Large enterprises produce large amounts of text during daily operations, e.g., emails, re- ports, and meeting memos. There is an increasing need for systems that allow users to quickly find information over text through search. Unlike reg- ular tasks like booking airline tickets, search tasks often involve many facets, some of which may or may not be known to the users when the search be- gins. For example, knowing where a person works may triggers a followup question about whether the person communicates with someone internally about certain topic. Such search tasks will often be handled most naturally through dialog. <ref type="figure">Figure 1</ref> shows example dialog turns containing the user's utterance (question) u, system's confir- mation of the original parsê y, and the user's feed- back f . To simplify and scale data collection, we decouple the dialog turns and collect feedback for each dialog turn in isolation. We do that by show- ing a worker on Mechanial Turk the original utter- ance u, the system's natural language confirmation generated by inverting the original logical formˆy formˆ formˆy, and the dialog context summarized in a table. See <ref type="figure" target="#fig_0">Figure 2</ref> </p><note type="other">for a screenshot of the Mechanical Turk interface. The dialog context is summarized by the entities (of types person, organization, time and topic) that were mentioned earlier in the con- versation and could be referenced in the original question u shown on the screen 5 . The worker is then asked to type their feedback given (u, ˆ y) and the dialog context displayed on the screen. Turkers are instructed to write a natural language feedback utterance that they might otherwise say in a real conversation when attempting to correct another person's incorrect understanding of their question.</note><p>We recognize that our data collection process results in only an approximation of a true multi- turn conversation, however we find that this ap- proach to data collection offers a convenient trade- off for collecting a large number of controlled and diverse context-grounded interactions. Qualita- tively we find that turkers are generally able to imagine themselves in the hypothetical ongoing dialog, and are able to generate realistic contextual feedback utterances using only the context sum- mary table provided to them.</p><p>The initial dataset of questions paired with orig- inal logical form parses {u i , ˆ y i } 1,...,N that we use to solicit feedback from turkers, is prepared of- fline. In this separate offline task we collect a dataset of 3556 natural language questions, anno- tated with gold standard logical forms, in the same domain of email and biographical research. We parse each utterance in this dataset with a float- ing grammar-based semantic parser trained using a structured perceptron algorithm (implemented in SEMPRE <ref type="figure" target="#fig_0">(Berant et al., 2013)</ref>) on a subset of the questions. We then construct the dataset for feed- back collection by sampling the logical formˆyformˆ formˆy from the first three candidate parses in the beam produced by the grammar-based parser. We use this grammar-based parser intentionally as a very different model from the one that we would ulti- mately train (LSTM-based parser) on the conver- sational logs produced by the original parser.</p><p>We retain 1285 out of the 3556 annotated ques- 5 zero or more of the context entities may actually be ref- erenced in the original utterance tions to form a test set. The rest 2271 questions we pair with between one and three predicted parsesˆyparsesˆ parsesˆy sampled from the beam produced by the grammar- based parser, and present each pair of original ut- terance and predicted logical form (u i , ˆ y i ) to a turker who then generates a feedback utterance f i . In total, we collect 4321 question/original parse/feedback triples (u i , ˆ y i , f i ) (averaging ap- proximately 1.9 feedback utterances per question).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>The key hypothesis that we aim to evaluate in our experiments is whether natural language feedback is an effective form of supervision for training a semantic parser. To achieve this goal, we control and measure the effect that the number of feedback utterances used during training has on the resulting performance of the task semantic parser on a held- out test set. Across all our experiments we also use a small seed training set (300 questions) that con- tains gold-standard logical forms to pre-train the task and feedback parsers. The number of "unla- beled" questions 6 (i.e., questions not labeled with gold standard logical forms but that have natural language feedback) ranges from 300, 500, 1000 to 1700 representing different experimental settings. For each experimental setting, we rerun the exper- iment 10 times, re-sampling the questions in both the training and unlabeled sets, and report the aver- aged results. The test-set remains fixed across all experiments and contains 1285 questions labeled with gold-standard logical forms. The implemen- tation details for the task parser and the feedback parser are included in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Models and evaluation metrics</head><p>In our evaluations, we compare the following four models:</p><p>• MH (full model) Joint model described in Sec- tion 3 and in Algorithm 1 (using Metropolis Hastings-based MAP inference described in Al- gorithm 2).</p><p>• MH (no feedback) Same as the full model, ex- cept we ignore the feedback f and the origi- nal logical formˆyformˆ formˆy information in the feedback model. Effectively, this reduces the model of the feedback parser to that of the task parser. Because during training, both models would be initialized differently, we may still expect the re- sulting model averaging effects to aid learning.</p><p>• MH (no feedback + rejectˆyrejectˆ rejectˆy) Same as the above baseline without feedback, but we in- corporate the knowledge of the original logical formˆyformˆ formˆy during training. We incorporatê y using the same method as described in Section ??.</p><p>• Self-training Latent logical form inference is performed using only the task parser (using beam search). Feedback utterance f and orig- inal logical formˆyformˆ formˆy are ignored. Task parser pa- rameters θ t are updated in the same way as in Algorithm 1.</p><p>Note that all models are exposed to the same train- ing seed set, and differ only in the way they take advantage of the unlabeled data. We perform two types of evaluations of each model:</p><p>• Generalization performance we use the learned task parser to make predictions on held- out data. This type of evaluation tests the ability of the parser trained with natural language feed- back to generalize to unseen utterances.</p><p>• Unlabeled data performance we use the learned task parser to make predictions on the unlabeled data that was used in training it. Note that for each experimental condition, we per- form this evaluation only on the portion of the unlabeled data that was used during train- ing. This ensures that this evaluation tests the model's ability to "recover" correct logical forms from the questions that have natural lan- guage feedback associated with them. <ref type="figure" target="#fig_2">Figure 3a</ref> shows test accuracy as a function of the number of unlabeled questions (i.e., ques- tions containing only feedback supervision with- out gold standard logical forms) used during train- ing, across all four models. As expected, using more unlabeled data generally improves general- ization performance. The self-training baseline is the only exception, where performance starts to deteriorate as the ratio of unlabeled to labeled questions increases beyond a certain point. This behavior is not necessarily surprising -when the unlabeled examples significantly outnumber the labeled examples, the model may more easily veer away to local optima without being strongly regu- larized by the loss on the small number of labeled examples. Interestingly, the MH (no feedback) baseline is very similar to self-training, but has a signifi- cant performance advantage that does not deterio- rate with more unlabeled examples. Recall that the MH (no feedback) model modifies the full model described in Algorithm 1 by ignoring the feedback f and the original logical formˆyformˆ formˆy in the feedback parser model P (y | u, ˆ y, f ; θ f ). This has the ef- fect of reducing the model of the feedback parser into the model of the task parser P (y | u; θ t ). The training on unlabeled data proceeds otherwise in the same way as described in Algorithm 1. As a result, the principle behind the MH (no feedback) model is the same as that behind self-training, i.e., a single model learns from its own predictions. However, different initializations of the two copies of the task parser, and the combined model averag- ing appears to improve the robustness of the model sufficiently to keep it from diverging as the amount of unlabeled data is increased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Generalization performance</head><p>The MH (no feedback + rejectˆyrejectˆ rejectˆy) baseline also does not observe the feedback utterance f , but incorporates the knowledge of the original parsêparsê y. As described in Section ??, this knowledge is incorporated during MAP inference of the latent parse, by rejecting any logical form samples that matchˆymatchˆ matchˆy. As expected, incorporating the knowl- edge ofˆyofˆ ofˆy improves the performance of this base- line over the one that does not.</p><p>Finally, the full model that incorporates both, the feedback utterance f and the original logical formˆyformˆ formˆy outperforms the baselines that incorporate only some of that information. The performance gain over these baselines grows as more ques- tions with natural language feedback supervision are made available during training. Note that both this and the MH (no feedback + rejectˆyrejectˆ rejectˆy) model incorporate the knowledge of the original logical formˆyformˆ formˆy, however, the performance gain from in- corporating the knowledge ofˆyofˆ ofˆy without the feed- back is relatively small, indicating that the gains from the model that observes feedback is primar- ily from its ability to interpret it. One of the main observations is that accu- racy on unlabeled training examples remains rela- tively flat, but consistently high (&gt; 80%), across all models regardless of the amount of unlabeled questions used in training (within the range that we experimented with). This suggests that while the models are able to accurately recover the un- derlying logical forms of the unlabeled questions regardless of the amount of unlabeled data (within our experimental range), the resulting generaliza- tion performance of the learned models is signif- icantly affected by the amount of unlabeled data (more is better).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Performance on unlabeled data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Effect of feedback complexity on performance</head><p>Figure 4 reports parsing accuracy on unlabeled questions as a function of the number of correc- tions expressed in the feedback utterance paired with that question. Our main observation is that the performance of the full model (i.e., the joint model that uses natural language feedback) deteri- orates for questions that are paired with more com- plex feedback (i.e., feedback containing more cor- rections). Perhaps surprisingly, however, is that all models (including those that do not incorporate feedback) deteriorate in performance for questions paired with more complex feedback. This is ex- plained by the fact that more complex feedback is generally provided for more difficult-to-parse questions. In <ref type="figure" target="#fig_3">Figure 4</ref>, we overlay the parsing per- formance with the statistics on the average length of the target logical form (number of predicates).</p><p>A more important take-away from the results in <ref type="figure" target="#fig_3">Figure 4</ref>, is that the model that takes advantage of natural language feedback gains an even greater advantage over models that do not use feedback when parsing more difficult questions. This means that the model is able to take advantage of more complex feedback (i.e., with more corrections) even for more difficult to parse questions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Early semantic parsing systems map natural lan- guage to logical forms using inductive logical programming ( <ref type="bibr" target="#b12">Zelle and Mooney, 1996)</ref>. Mod- ern systems apply statistical models to learn from pairs of sentences and logical forms <ref type="bibr">Collins, 2005, 2009;</ref><ref type="bibr">Kwiatkowski et al., 2010</ref>   <ref type="bibr">Goldwasser and Roth, 2014;</ref><ref type="bibr">Misra et al., 2015</ref>). The supervi- sion used in these methods is mostly in the form of binary feedback, partial logical forms (e.g., slots) or execution results. In this paper, we explore a new form of supervision -natural language feed- back. We demonstrate that such feedback not only provides rich and expressive supervisory signals for learning but also can be easily collected via crowd-sourcing. Recent work ( <ref type="bibr">Iyer et al., 2017)</ref> trains an online language-to-SQL parser from user feedback. Unlike our work, their collected feed- back is structured and is used for acquiring more labeled data during training. Our model jointly learns from questions and feedback and can be trained with limited labeled data. There has been a growing interest on machine learning from natural language instructions. Much work has been done in the setting where an au- tonomous agent learns to complete a task in an environment, for example, learning to play games by utilizing text manuals ( <ref type="bibr">Branavan et al., 2012;</ref><ref type="bibr">Eisenstein et al., 2009;</ref><ref type="bibr" target="#b2">Narasimhan et al., 2015)</ref> and guiding policy learning using high-level hu- man advice ( <ref type="bibr">Kuhlmann et al., 2004;</ref><ref type="bibr" target="#b6">Squire et al., 2015;</ref><ref type="bibr">Harrison et al., 2017)</ref>. Recently, natural lan- guage explanations have been used to augment la- beled examples for concept learning <ref type="bibr" target="#b7">(Srivastava et al., 2017)</ref> and to help induce programs that solve algebraic word problems ( <ref type="bibr">Ling et al., 2017)</ref>. Our work is similar in that natural language is used as additional supervision during learning, however, our natural language annotations consist of user feedback on system predictions instead of expla- nations of the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>In this work, we proposed a novel task of learning a semantic parser directly from end-users' open- ended natural language feedback during a conver- sation. The key advantage of being able to learn from natural language feedback is that it opens the door to learning continuously through natural in- teractions with the user, but it also presents a chal- lenge of how to interpret such feedback. In this work we introduced an effective approach that si- multaneously learns two parsers: one parser that interprets natural language questions and a second parser that also interprets natural language feed- back regarding errors made by the first parser.</p><p>Our work is, however, limited to interpreting feedback contained in a single utterance. A natural generalization of learning from natural language feedback is to view it as part of an integrated dia- log system capable of both interpreting feedback and asking appropriate questions to solicit this feedback (e.g., connecting to the work by <ref type="bibr" target="#b3">(Padmakumar et al., 2017)</ref>). We hope that the prob- lem we introduce in this work, together with the dataset that we release, inspires the community to develop models that can learn language (e.g., se- mantic parsers) through flexible natural language conversation with end users. instructions to actions. Transactions of the Associa- tion of Computational Linguistics, 1:49-62.</p><p>Dzmitry Bahdanau, <ref type="bibr">Kyunghyun Cho, and Yoshua Bengio. 2014</ref> original parsê y incorrect original parsê y correct <ref type="figure">Figure 5</ref>: A histogram of the number of corrections expressed in a natural language feedback utterance in our data (0 corrections means that the user affirmed the original parse as correct). We partition the feedback ut- terances according to whether the original parsê y that the feedback was provided towards is known to be cor- rect (i.e., matches the gold standard logical form parse).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Analysis of natural language feedback</head><p>The dataset we collect creates a unique opportu- nity to study the nature and the limitations of the corrective feedback that users generate in response to an incorrect parse. One of our hypotheses stated in Section 1 is that natural language affords users to express richer feedback than for example possi- ble with binary (correct/incorrect) mechanism, by allowing users to explicitly refer to and fix what they see as incorrect with the original prediction. In this section we analyze the feedback utterances in our dataset to gain deeper insight into the types of feedback users generate, and the possible limi- tations of natural language as a source of supervi- sion for semantic parsers. <ref type="figure">Figure 5</ref> breaks down the collected feedback by the number of corrections expressed in the feed- back utterance. The number of corrections ranges from 0 (no corrections, i.e., worker considers the original parsê y to be the correct parse of u) to more than 3 corrections. <ref type="bibr">7</ref> The number of correc- tions is self-annotated by the workers who write the feedback -we instruct workers to count a cor- rection constrained to a single predicate or a single entity as a single correction, and tally all such cor- rections in their feedback utterance after they have <ref type="bibr">7</ref> Note that in cases where the user indicates that they made 0 corrections, the feedback utterance that they write is often a variation of a confirmation such as "that's right" or "that's correct" User feedback error rate User feedback false positives User feedback false negatives <ref type="figure">Figure 6</ref>: Analysis of noise in feedback utterances con- tained in our dataset. Feedback false positives refers to feedback that incorrectly identifies the wrong origi- nal parsê y as correct. Feedback false negatives refers to feedback that incorrectly identifies a correct original parsê y as wrong. Users are more likely to generate false positives (i.e., miss the error) in their feedback for parses of more complex utterances (as measured by the number of predicates in the gold-standard logical form).</p><p>written it 8 . Because we also know the ground truth of whether the original parsê y (i.e., parse that the user provided feedback towards) was correct (i.e., ˆ y matches gold standard parse y), we can partition the number of corrections by whether the origi- nal parsê y was correct (green bars in <ref type="figure">Figure 5</ref>) or incorrect (red bars), allowing us to evaluate the accuracy of some of the feedback.</p><p>From <ref type="figure">Figure 5</ref>, we observe that users provide feedback that ranges in the number of corrections, with the majority of feedback utterances making one correction to the original logical formˆyformˆ formˆy (only 4 feedback utterances expressed more than 3 cor- rections). Although we do not have gold-standard annotation for the true number of errors in the original logical formˆyformˆ formˆy, we can nevertheless ob- tain some estimate of the noise in natural language feedback by analyzing cases where we know that the original logical formˆyformˆ formˆy was correct, yet the user generated feedback with at least one correction. We will refer to such feedback instances as feed- back false negatives. Similarly, cases where the original logical formˆyformˆ formˆy is incorrect, yet the user provided no corrections in their feedback, we re- fer to as feedback false positives.  <ref type="figure">Figure 7</ref>: Visualization of the attention mechanism in the task parser (top) and the feedback parser (bottom) for parsing the same utterance. We partition the input to the parser into three groups: the original utterance u being parsed (blue), the conversational context (green) and the feedback utterance f (red). This example was parsed incorrectly before incorporating feedback, but parsed correctly after its incorporation.  <ref type="figure">Figure 8</ref>: Visualization of the attention mechanism in the task parser (top) and the feedback parser (bottom) for parsing the same utterance. We partition the input to the parser into three groups: the original utterance u being parsed (blue), the conversational context (green) and the feedback utterance f (red). This example was parsed incorrectly before incorporating feedback, but parsed correctly after its incorporation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Screenshot of the Mechanical Turk web interface used to collect natural language feedback.</figDesc><graphic url="image-1.png" coords="6,324.28,62.81,184.24,90.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure 3b shows accuracy on the unlabeled data, as a function of the number of unlabeled questions used during training, across all four models. The questions used in evaluating the model's accuracy on unlabeled data are the same unlabeled questions used during training in each experimental condition. The general trend and the relationship between baselines is consistent with the generalization performance on held-out data in Figure 3a. One of the main observations is that accuracy on unlabeled training examples remains relatively flat, but consistently high (&gt; 80%), across all models regardless of the amount of unlabeled questions used in training (within the range that we experimented with). This suggests that while the models are able to accurately recover the underlying logical forms of the unlabeled questions regardless of the amount of unlabeled data (within our experimental range), the resulting generalization performance of the learned models is significantly affected by the amount of unlabeled data (more is better).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: (a) Parsing accuracy on held-out questions as a function of the number of unlabeled questions used during training. (b) Parsing accuracy on unlabeled questions as a function of the number of unlabeled questions used during training. In both panels, all parsers were initialized using 300 labeled examples consisting of questions and their corresponding logical form.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Parsing accuracy on unlabeled questions, partitioned by feedback complexity (i.e., number of corrections expressed in a single feedback utterance).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.</figDesc><table>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy 
Liang. 2013. Semantic parsing on freebase from 
question-answer pairs. In Proceedings of the 2013 
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1533-1544. 

Jonathan Berant and Percy Liang. 2014. Semantic 
parsing via paraphrasing. In Proceedings of the 
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), vol-
ume 1, pages 1415-1425. 

Avrim Blum and Tom Mitchell. 1998. Combining la-
beled and unlabeled data with co-training. In Pro-
ceedings of the eleventh annual conference on Com-
putational learning theory, pages 92-100. ACM. 

Satchuthananthavale RK Branavan, Harr Chen, Luke S 
Zettlemoyer, and Regina Barzilay. 2009. Reinforce-
ment learning for mapping instructions to actions. 
In Proceedings of the Joint Conference of the 47th 
Annual Meeting of the ACL and the 4th International 
Joint Conference on Natural Language Processing 
of the AFNLP: Volume 1-Volume 1, pages 82-90. 
Association for Computational Linguistics. 

SRK Branavan, David Silver, and Regina Barzilay. 
2012. Learning to win by reading manuals in a 
monte-carlo framework. Journal of Artificial Intel-
ligence Research, 43:661-704. 

James Clarke, Dan Goldwasser, Ming-Wei Chang, and 
Dan Roth. 2010. Driving semantic parsing from 
the world's response. In Proceedings of the four-
teenth conference on computational natural lan-
guage learning, pages 18-27. Association for Com-
putational Linguistics. 

Jacob Eisenstein, James Clarke, Dan Goldwasser, and 
Dan Roth. 2009. Reading to learn: Constructing 
features from semantic abstracts. In Proceedings 
of the 2009 Conference on Empirical Methods in 
Natural Language Processing: Volume 2-Volume 2, 
pages 958-967. Association for Computational Lin-
guistics. 

Dan Goldwasser and Dan Roth. 2014. Learning from 
natural instructions. Machine learning, 94(2):205-
232. 

Brent Harrison, Upol Ehsan, and Mark O Riedl. 2017. 
Guiding reinforcement learning exploration using 
natural language. arXiv preprint arXiv:1707.08616. 

Geoffrey E Hinton. 1999. Products of experts. 

Geoffrey E Hinton. 2002. Training products of experts 
by minimizing contrastive divergence. Neural com-
putation, 14(8):1771-1800. 

Sepp Hochreiter and Jürgen Schmidhuber. 1997. 
Long short-term memory. Neural computation, 
9(8):1735-1780. 

Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, 
Jayant Krishnamurthy, and Luke Zettlemoyer. 2017. 
Learning a neural semantic parser from user feed-
back. arXiv preprint arXiv:1704.08760. 

Robin Jia and Percy Liang. 2016. Data recombina-
tion for neural semantic parsing. arXiv preprint 
arXiv:1606.03622. 

Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gard-
ner. 2017. Neural semantic parsing with type con-
straints for semi-structured tables. In Proceedings of 
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1516-1526. 

Jayant Krishnamurthy and Tom M Mitchell. 2012. 
Weakly supervised training of semantic parsers. In 
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and 
Computational Natural Language Learning, pages 
754-765. Association for Computational Linguis-
tics. 

Gregory Kuhlmann, Peter Stone, Raymond Mooney, 
and Jude Shavlik. 2004. Guiding a reinforcement 
learner with natural language advice: Initial results 
in robocup soccer. In The AAAI-2004 workshop on 
supervisory control of learning and adaptive sys-
tems. 

Tom Kwiatkowski, Luke Zettlemoyer, Sharon Gold-
water, and Mark Steedman. 2010. Inducing proba-
bilistic ccg grammars from logical form with higher-
order unification. In Proceedings of the 2010 con-
ference on empirical methods in natural language 
processing, pages 1223-1233. Association for Com-
putational Linguistics. 

Chen Liang, Jonathan Berant, Quoc Le, Kenneth D 
Forbus, and Ni Lao. 2016. 
Neural symbolic 
machines: Learning semantic parsers on free-
base with weak supervision. 
arXiv preprint 
arXiv:1611.00020. 

Percy Liang, Michael I Jordan, and Dan Klein. 2013. 
Learning dependency-based compositional seman-
tics. Computational Linguistics, 39(2):389-446. 

Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-
som. 2017. Program induction by rationale genera-
tion: Learning to solve and explain algebraic word 
problems. arXiv preprint arXiv:1705.04146. 

Minh-Thang Luong, Hieu Pham, and Christopher D 
Manning. 2015. Effective approaches to attention-
based neural machine translation. arXiv preprint 
arXiv:1508.04025. 

Dipendra Kumar Misra, Kejia Tao, Percy Liang, and 
Ashutosh Saxena. 2015. Environment-driven lex-
icon induction for high-level instructions. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-0 
1 
2 
3 

Number of corrections expressed in feedback utterance 

0 

500 

1000 

1500 

2000 

Number of question/feedback pairs 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>The number of feedback false negatives and false positives can be</figDesc><table>Conversational Context 

Utterance 

Feedback 

Conversational Context 

Utterance 

Feedback 

Before Feedback 
(incorrect parse) 

After Feedback 
(correct parse) 

</table></figure>

			<note place="foot" n="1"> although in some cases existing datasets can be leveraged to extract this information</note>

			<note place="foot" n="2"> Note that in practice, to avoid locally optimal degenerate solutions (e.g., where the feedback parser learns to trivially agree with the task parser by learning to ignore the feedback), some amount of labeled logical forms would be required to pre-train both models.</note>

			<note place="foot" n="3"> We have experimented with a sampling based approximation of the true gradients with contrastive divergence (Hinton, 2002), however, found that our approximation works sufficiently well empirically. See Algorithm 1 for more details of the complete algorithm.</note>

			<note place="foot" n="6"> Note that from hereon we will refer to the portion of the data that contains natural language feedback as the only form of supervision as &quot;unlabeled data&quot;, to emphasize that it is not labeled with gold standard logical forms (in contrast to the seed training set).</note>

			<note place="foot">Luke S Zettlemoyer and Michael Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 976-984. Association for Computational Linguistics.</note>

			<note place="foot" n="8"> we give these instructions to workers in an easy to understand explanation without invoking technical jargon</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by AFOSR under grant FA95501710218, and in part by the CMU InMind project funded by Oath.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>We tokenize user utterances (questions) and feed- back using the Stanford CoreNLP package. In all experiments, we use 300-dimensional word em- beddings, initialized with word vectors trained us- ing the Paraphrase Database PPDB ( <ref type="bibr" target="#b10">Wieting et al., 2015)</ref>, and we use 128 hidden units for LSTMs. All parameters are initialized uniformly at ran- dom. We train all the models using Adam with initial learning rate 10 −4 and apply L2 gradient norm clipping with a threshold of 10. In all the experiments, we pre-train the task parser and the feedback parser for 20 epochs, and then switch to semi-supervised training for 10 epochs. Pre- training takes roughly 30 minutes and the semi- supervised training process takes up to 7 hours on a Titan X GPU.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping ation for Computational Linguistics and the 7th</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="992" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Language understanding for textbased games using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejas</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Integrated learning of dialog strategies and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Padmakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="547" to="557" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.00305</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without questionanswer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grounding english commands to reward functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shawn</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Arumugam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics: Scienceand Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint concept learning and semantic parsing from natural language explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashank</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Labutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1527" to="1536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language commands through human-robot dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Thomason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1923" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Building a semantic parser overnight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1332" to="1342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08198</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1304.5634</idno>
		<title level="m">A survey on multi-view learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national conference on artificial intelligence</title>
		<meeting>the national conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
