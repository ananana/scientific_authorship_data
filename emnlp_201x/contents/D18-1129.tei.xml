<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Facts That Matter</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ponza</surname></persName>
							<email>marco.ponza@di.unipi.it, {corrogg,weikum}@mpi-inf.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><forename type="middle">Del</forename><surname>Corro</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Max Planck Institute for Informatics</orgName>
								<orgName type="department" key="dep2">Saarland Informatics Campus</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Facts That Matter</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1043" to="1048"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1043</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This work introduces fact salience: The task of generating a machine-readable representation of the most prominent information in a text document as a set of facts. We also present SALIE, the first fact salience system. SALIE is unsupervised and knowledge agnostic, based on open information extraction to detect facts in natural language text, PageRank to determine their relevance, and clustering to promote diversity. We compare SALIE with several baselines (including positional, standard for saliency tasks), and in an extrinsic evaluation , with state-of-the-art automatic text sum-marizers. SALIE outperforms baselines and text summarizers showing that facts are an effective way to compress information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic knowledge acquisition at large scale requires the transformation of human-readable knowledge into a machine-understandable format. Machine-readable information is usually struc- tured in the form of facts, in which a given rela- tion links a set of arguments [e.g., ("US", "with- draws from", "Iran nuclear deal")]. Facts are at the core of several natural language understanding applications such as knowledge-base (KB) con- struction ( <ref type="bibr" target="#b18">Nguyen et al., 2017</ref>), question answer- ing ( <ref type="bibr" target="#b0">Abujabal et al., 2018)</ref>, structured search ( <ref type="bibr" target="#b4">Bast et al., 2014</ref>), or entity-linking ( <ref type="bibr" target="#b6">Cheng and Roth, 2013)</ref>.</p><p>Different approaches aim to discover facts from natural language text. In the extremes of the spec- trum, relation extraction ( <ref type="bibr" target="#b17">Mintz et al., 2009</ref>) looks for all facts linkable to a KB, whereas open in- formation extraction ( <ref type="bibr" target="#b2">Banko et al., 2007</ref>) extracts facts over an unconstrained set of arguments and relations. In this paper, we aim to additionally score facts according to their prominence.</p><p>We define fact salience as the task of discover- ing the most prominent facts in a text document. A fact is salient if it carries the essential informa- tion that the text conveys. A higher salient score denotes higher prominence, determining a ranking across all facts in the document. This ranking must reflect relevance and diversity: We want the top-k facts to compress the most relevant information in the smallest number of facts.</p><p>Fact salience is closely related to automatic text summarization ( <ref type="bibr" target="#b12">Erkan and Radev, 2004</ref>) as both try to capture the essential information in a document. However, fact salience output is re- quired to be interpreted by machines to a certain extent. Text summarization, on the contrary, is meant to be understood by humans alone; it is often composed by ungrammatical text and iso- lated keywords, making it difficult to structure in a machine-readable form ex-post.</p><p>Here we present SALIE (Salient Information Extraction), the first fact salience system able to output a ranking of salient open facts from a text document. SALIE is unsupervised and knowledge agnostic. It uses facts as atomic units and PageR- ank to detect their relevance. It also exploits the fact structure to promote diversity via clustering.</p><p>We evaluated SALIE on a real-world dataset and compared it with the strong positional base- line (facts appearing first are more relevant) and, in an extrinsic evaluation, with two top text summarizers (one reimplemented to work at fact level). SALIE outperforms baselines and text summarization competitors particularly when the size of the output is restricted, suggesting that facts, as atomic units expressing a single propo- sition <ref type="bibr" target="#b10">(Del Corro and Gemulla, 2013)</ref>, are an ef- fective way to compress information.</p><p>The source code and the processed datasets are publicly available 1 to encourage further develop- ments of the fact salience task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Fact Salience</head><p>Fact salience is the task of extracting salient facts from a text document. Salient facts must fulfil two requirements: (i) relevance and (ii) diversity.</p><p>A fact is relevant if it carries the essential infor- mation that the text conveys. A fact is not relevant per se but in a specific context. In an article about the US-Iran nuclear deal the fact ("US", "with- draws from", "Iran Nuclear Deal") is more rele- vant that ("Washington", "is", "US capital").</p><p>The output of a fact salience system must ensure that the top-k facts contain the maximum informa- tion in the smallest number of facts. This implies a dependency between facts as less relevant facts should be penalized when they carry information already contained in more relevant ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Fact salience is close to automatic text summariza- tion ( <ref type="bibr" target="#b12">Erkan and Radev, 2004</ref>); both must detect the most prominent information in the text. However, while text summarization generates summaries for humans, fact salience output must be interpretable by machines. Fluency and language cohesion are not requirements for fact salience.</p><p>Triple scoring in KBs ( <ref type="bibr" target="#b5">Bast et al., 2017</ref>) is also related. However, while in fact salience a fact is not relevant per se but locally in a textual con- text, triple KB scoring asses the global relevance of a KB fact for a specific entity [("T. Burton", "profession", "actor") vs. ("T. Burton", "profes- sion", "director")] .</p><p>Typically, a text summarization system splits the text into atomic units (usually sentences) that are scored and ranked . Di- versity is generally guaranteed by clustering them in topics and selecting the most representative members from each cluster. Once selected, the atomic units are compressed to ensure minimality.</p><p>Generating a machine-readable representation from text summarization output is difficult. This output can be incomplete or ungrammatical, given the use of compression techniques ( <ref type="bibr" target="#b28">Zajic et al., 2007)</ref>, or the inclusion of keywords or short unconnected phrases with topical informa- tion <ref type="bibr" target="#b14">(Hasan and Ng, 2014</ref>). Open information extractors will most likely fail to generate mean- ingful facts in these circumstances. However, text summarization techniques to score the atomic units can be exploited for fact salience.</p><p>Open facts have been already used in text summarization for redundancy, using syn- onymity ( <ref type="bibr" target="#b8">Christensen et al., 2013)</ref> or as input for a classifier <ref type="bibr" target="#b9">(Christensen et al., 2014)</ref>. In this case, we use facts as atomic units. Working at the fact level provides a natural framework to detect essential information in a text document, since facts are minimal comprehensive atomic units expressing a single proposition <ref type="bibr" target="#b10">(Del Corro and Gemulla, 2013)</ref>. This helps to avoid working with sentences that might express more than one proposition or arbitrary chunking the input text. Compression is also more principled at a fact level as the fact hierarchical structure is clearly defined ( <ref type="bibr" target="#b13">Gashteovski et al., 2017)</ref>. Additionally, we exploit the fact structure to promote diversity.</p><p>Several supervised and unsupervised methods have been used in text summarization to deter- mine the relative prominence of the atomic units. For instance, two of the top performer systems <ref type="bibr" target="#b11">Durrett et al. (2016)</ref> and <ref type="bibr" target="#b16">Mihalcea and Tarau (2004)</ref>, which we include in our extrinsic evalu- ation, are based on ILP and an unsupervised graph algorithm respectively. Other approaches include LDA ( , ontology-based ( <ref type="bibr" target="#b3">Baralis et al., 2013</ref>) or clustering ( <ref type="bibr" target="#b27">Yang et al., 2014)</ref>, and more recently neural-based methods <ref type="bibr" target="#b24">(See et al., 2017)</ref>. As in Mihalcea and Tarau (2004) or <ref type="bibr" target="#b12">Erkan and Radev (2004)</ref> we use PageRank to es- tablish the relative prominence of the atomic units (Sec. 4.1). However, we weight the graph edges using word vectors to allow more expressive se- mantics, avoiding the sparsity of frequency-based methods.</p><p>Different approaches have also been explored to promote diversity. <ref type="bibr" target="#b26">Xiong and Luo (2014)</ref>, for ex- ample, use LSA, and Chien and Chang (2013) rely on topic models. In our case, we generate diversity by exploiting the fact structure (Sec. 4.2). We clus- ter facts in terms of their subjects as a way to have the most relevant information about the different entities appearing in the text. The subject is typi- cally the topic of the clause or proposition <ref type="bibr" target="#b22">(Quirk et al., 1985</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SALIE: Salient Information Extraction</head><p>SALIE is a graph-based method for the extrac- tion of salient open facts in text documents. Open facts are a structured machine-readable represen- tation of the information in text. Its arguments are not linked to an existing KB. SALIE takes as in- put all open facts detected by an open information extraction system (in our implementation we use MINIE ( <ref type="bibr" target="#b13">Gashteovski et al., 2017)</ref>).</p><p>SALIE works in two stages: (i) relevance and (ii) diversification. First, a graph with open facts as nodes is instantiated so that PageRank assesses their relative relevance. Later, a clustering algo- rithm selects a diversified set of facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Fact Relevance</head><p>SALIE computes fact relevance by growing a complete graph of open facts G OF = (V, E) extracted from the input text. Coherence is in- duced by weighting the edges E between nodes V , whereas a relevance prior is induced via the in- stantiation of the PageRank's teleport vector.</p><p>Step 1 -Facts as Nodes. Each node is a fact extracted by MINIE. Undefined facts (with no clear co-reference) [("He", "plays", "soft- ball")] or facts with constituents composed by single words (generally uninformative or noisy) [("doorman", "has", "age")] are removed.</p><p>Step 2 -Coherence: Edge Weighting. We want related facts to get a higher weight assum- ing that the most relevant facts will be those more central. We weight each edge (u, v) with the se- mantic similarity between u and v as the cosine between the centroid of the word embeddings in the facts. <ref type="bibr" target="#b25">Stanovsky et al. (2015)</ref> have shown that learning word embeddings with open facts allows the generation of higher quality vectors . The as- sumption is that the relatedness of words within a fact is stronger than with words outside. This provides the basis for more accurate contextual- ization. Accordingly, in our implementation we use GloVe ( <ref type="bibr" target="#b19">Pennington et al., 2014</ref>) trained on the Wikipedia corpus using open facts extracted by MINIE for co-occurence context.</p><p>Step 3 -Relevance Prior. We introduce a prior for each fact by computing a score used to in- stantiate the PageRank's teleport vector. The as- sumption is that authors tend to express the most relevant facts at the beginning. We instantiated each fact teleport as f actP rior(i) = x i X , where</p><p>x i = |V | − i and i is the fact index. This is impor- tant especially for news where the lead paragraph is the most important part of the article. That's why the positional baseline is so strong in tasks as text summarization or entity salience ( <ref type="bibr" target="#b20">Ponza et al., 2018</ref>).</p><p>Step</p><note type="other">4 -Relevance Computation. This stage runs PageRank on the graph. The stationary distri- bution will capture the relevance of each open fact. This distribution reflects the semantic centrality of each fact weighted by its relevance prior.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fact Diversification</head><p>In this stage SALIE diversifies the set of rele- vant facts computed in the previous stage. Facts are clustered exploiting the fact structure, and the most relevant facts in each cluster are selected ac- cording to the relevance scores.</p><p>Facts have clear semantics regarding the role of each of its constituents (i.e., subject, relation, and object) in the proposition. SALIE exploits this by clustering together those facts that have the same head in the subject's constituent. As the subject is typically the theme (or topic) of a the clause ( <ref type="bibr" target="#b22">Quirk et al., 1985)</ref>, the intuition here is that facts with the same subject express informa- tion about the same entity. Therefore, each cluster will contain a ranked set of facts about each entity in the document.</p><p>After the facts have been clustered, we itera- tively select facts from each cluster according to its relevance until we reach the desired number of facts as output. The number of facts in the output is a parameter of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Methodology. Given a document we want to eval- uate how salient the top-k facts are. The number of facts in the ranking is a parameter of the model so we evaluate 5 configurations: top-1 to top-5 facts. Dataset. As there is no dataset to directly asses the saliency of facts, we compare the extracted facts in each ranking with a manually generated sum- mary. We use the New York Times <ref type="bibr" target="#b23">(Sandhaus, 2008)</ref> corpus, consisting of 3956 news articles and summaries from 2007 (with summaries larger than 50 tokens) as described by <ref type="bibr" target="#b11">Durrett et al. (2016)</ref>. Metrics. To measure how close is the rank- ing to the summary, we use the ROUGE pack- age 2 , standard for document summarization (Lin,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Summary</head><p>Body of Toni Grossi Abrams, widow and Staten Island socialite, is found in warehouse on outskirts of Panama City, Panama, where she had moved to begin career in real estate; Debra Ann Ridgley, one of her tenants, is charged with stabbing Abrams to death in her apartment on April 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Salient Facts / Summary Position 1 ("Surgery patients", "lie low in", "style retreat") 2 ("Remains", "were discovered beside warehouse at", "edge of cinder-topped soccer field on outskirts of Panama City") 3 ("Abrams", "had been stabbed to death in", "apartment") TextRank 1 ("Ridgley", "was in Abrams's apartment", "Garcia and friend") 2 ("Ridgley", "was in Abrams's apartment that", "night") 3 ("Abrams's body", "remains in", "Panama City morgue")</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Berkeley</head><p>The widow of a mortgage executive, Ms. Abrams was something of a force of nature in Staten Island society. The suspect, Debra Ann Ridgley, is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SALIE</head><p>1 ("Abrams", "had been stabbed to death in", "apartment") 2 ("Remains", "were discovered beside warehouse at", "edge of cinder-topped soccer field on outskirts of Panama City") 3 ("Apartment", "tending wounds at time of", "murder") (a) MINIE safe mode.</p><p>Human Summary Russian state oil company Rosneft has lined up $22 billion in financing from consortium of Western banks to buy assets from bankrupt rival Yukos; Rosneft says it will bid for refineries owned by Yukos as outlet for production from its Yugansk subsidiary in western Siberia; some of banks listed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Salient Facts / Summary Position 1 ("State oil company", "lined up $ from consortium of banks buy assets from", "rival") 2 ("Rosneft", "increase footprint in", "oil and gas business") 3 ("Bids", "are successful as", "expected") TextRank 1 ("Banks", "made loans to", "Rosneft and state company") 2 ("Banks", "lent company related to Rosneft", "$ increase share") 3 ("State oil company", "lined up $ from consortium of banks buy assets from", "rival") Berkeley</p><p>The Russian state oil company Rosneft has lined up $22 billion from a consortium of Western banks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SALIE</head><p>1 ("State oil company", "lined up $ from consortium of banks buy assets from", "rival") 2 ("Banks", "made loans to", "Rosneft and state company") 3 ("Rosneft", "increase footprint in", "oil and gas business") (b) MINIE aggressive mode. <ref type="table">Table 1</ref>: Top-3 salient facts automatically extracted from a sample of two NYT documents with two different MINIE modes. For Berkeley (which does not return facts) we show its produced summary. On the top of each table we show the summary written by a human for the input document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2004</head><p>). ROUGE-1 measures the presence of single words between the salient facts and the summary; ROUGE-L identifies the longest common sub- sequence (LCS) with maximum length between facts and summary; ROUGE-1.2W measures the weighted LCS by taking into account spatial re- lations and giving higher values to consecutive matches; ROUGE-SU is the number of occurring bigrams between the facts and summary with arbi- trary gaps. For each metric we report the F 1 per- formance, all computed with a 95% confidence in- terval, run with stemming and stopword removal 3 .</p><p>To compute the ROUGE score, the facts were flattened and concatenated into a sequence of to- kens respecting the ranking order. For the com- putation, this sequence is considered equivalent to a summary, so the same conditions apply: If all the extracted tokens fully cover the gold standard summary, the ROUGE score reaches its highest value. <ref type="bibr">3</ref> Package arguments: -c 95 -m -s -U -w 1.2.</p><p>Note that we do not take into account the correctness of the facts (i.e., if they are well- structured). All systems implemented, except the Berkeley summarizer <ref type="bibr" target="#b11">(Durrett et al., 2016)</ref>, use the same open facts extracted by MINIE. Also for the Berkeley summarizer, we do not evaluate the structure or fluency of the summary. SALIE. Outputs top-k facts per article. We show results for two MINIE configurations: safe and ag- gressive, which differ in the fact average size. Intrinsic Evaluation. As there is no direct fact salience competitor, we designed three baselines: The standard Position baseline which ranks facts with respect to their order of appearance, Tf-Idf which ranks them with respect to the subject's head tf-idf and the Context baseline which ranks facts with respect to the cosine-similarity between the document and the fact embedding's centroid. Extrinsic Evaluation. We used two state-of- the-art document summarizers, i.e., the unsuper- vised graph-based TextRank <ref type="bibr" target="#b16">(Mihalcea and Tarau, 2004</ref>) and the supervised Berkeley summa- <ref type="table" target="#tab_1">ROUGE-SU   1  2  3  4  5  1  2  3  4  5  1  2  3  4  5  1  2  3  4</ref>   As the size of the summaries is a parameter of the summarizer, we set it to match the average size of MINIE facts (safe is 10 and aggressive is 6), For example, for the top-5 configuration in the aggres- sive mode, the summary length is set to 30. Tab. 1 shows example outputs for the position baseline, the text summarizers and SALIE.</p><formula xml:id="formula_0">Method ROUGE-1 ROUGE-L ROUGE-1.2W</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>Tabs. 2a and 2b show the results for all the sys- tems and baselines. We use colors black, gray and light gray for the first, second and third best performing methods. In each ROUGE configura- tion, we show results for five rankings: top-1 to top-5. The difference between SALIE and the best competitor is reported in the last line of the tables.</p><p>Tab. 2a shows the results where facts have been extracted with MINIE's safe mode. SALIE outperforms all other methods and baselines for the first three rankings (top-1 to top-3), although Berkeley summarizer comes first in top-4 and 5 facts as a higher budget takes the system closer to the gold standard human-readable summaries. TextRank has an opposite behavior compared to Berkeley, performing well in top-1 and 2 but lag- ging behind as more facts are added probably due to the lack of a diversification stage. It is interest- 4 nlp.cs.berkeley.edu/projects/ summarizer.shtml ing to note that systems working at the fact level do well in constrained settings, suggesting that facts may be an effective way to compress information.</p><p>Tab. 2b shows the results when MINIE is used in aggressive mode. In this experiment, we aim to analyze the behavior of the systems in a re- stricted scenario with a very small budget size (6 tokens per fact). SALIE achieves the highest per- formance overall metrics independently the num- ber of facts used, with the only exception on the ROUGE-1.2W and ROUGE-SU score when 4 or 5 facts are used. The second and third best perform- ing methods are Position and TextRank. Again, in this case, it is suggested that facts are an appropri- ate mechanism to compress information.</p><p>Overall SALIE shows a more stable balance across all rankings in both settings. It always ranks first or second (except in ROUGE-SU top-5 where it comes third). Compared to TextRank it seems to significantly better manage redundancy, while compared to the Berkeley it does better at detect- ing relevant information in constrained settings. This is due to the use of facts as a mean to com- press information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Results on the NYT dataset with two different MINIE modes. 

rizer (Durrett et al., 2016). We adapted TextRank 
to work with facts instead of sentences. For the 
Berkeley summarizer, we used the model online 4 . 
</table></figure>

			<note place="foot" n="1"> https://github.com/mponza/SalIE</note>

			<note place="foot" n="2"> pypi.org/project/pyrouge/0.1.3</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We introduced the fact salience task. We also presented SALIE, the first fact salience system. SALIE outperformed standard baselines but also state-of-the-art automatic text summarizer. We showed that working at the fact level allows to more effectively compress information.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Never-ending learning for open-domain question answering over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishiraj</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the WWW</title>
		<meeting>the WWW</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Text summarization techniques: A brief survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Allahyari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Seyed Amin Pouriyeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Assefi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><forename type="middle">D</forename><surname>Safaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">B</forename><surname>Trippe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Gutierrez, and Krys Kochut</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Open information extraction from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Cafarella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Broadhead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-document summarization based on the Yago ontology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Baralis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Cagliero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saima</forename><surname>Jabeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Fiori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sajid</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic full-text search with Broccoli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Bäurle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Buchhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Bast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Björn</forename><surname>Buchhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Haussmann</surname></persName>
		</author>
		<title level="m">Overview of the triple scoring task at the WSDM cup 2017. Proceedings of WSDM</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Relational inference for wikification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical theme and topic model for summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jen-Tzung</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Lan</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on MLSP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards coherent multidocument summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical summarization: Scaling up multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janara</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gagan</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mausam</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ClausIE: Clause-based open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><surname>Del Corro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning-based single-document summarization with compression and anaphoricity constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LexRank: Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günes</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MinIE: minimizing facts in open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Gashteovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Gemulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luciano</forename><forename type="middle">Del</forename><surname>Corro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic keyphrase extraction: A survey of the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">ROUGE: A package for automatic evaluation of summaries. Text Summarization Branches Out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TextRank: Bringing order into text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Rion Snow, and Dan Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Query-driven on-the-fly knowledge base construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdalghani</forename><surname>Dat Ba Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VLDB</title>
		<meeting>VLDB</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Swat: A system for detecting salient wikipedia entities in texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Ponza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Piccinno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Es-lda: Entity summarization using knowledge-based topic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyedamin</forename><surname>Pouriyeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Allahyari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Kochut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Gong Cheng, and Hamid Reza Arabnia</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A Comprehensive Grammar of the English Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randolph</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sidney</forename><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Leech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svartvik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Longman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The new york times annotated corpus. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Sandhaus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Open ie as an intermediate structure for semantic tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ido Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A new approach for multi-document summarization based on latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuchu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ISCID</title>
		<meeting>ISCID</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Enhancing sentence-level clustering with ranking-based clustering framework for themebased summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Multi-candidate reduction: Sentence compression as a tool for document summarization tasks. Information Processing &amp; Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
