<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AMR-to-text generation as a Traveling Salesman Problem</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM T.J. Watson Research Center</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AMR-to-text generation as a Traveling Salesman Problem</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2084" to="2089"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The task of AMR-to-text generation is to generate grammatical text that sustains the semantic meaning for a given AMR graph. We attack the task by first partitioning the AMR graph into smaller fragments, and then generating the translation for each fragment, before finally deciding the order by solving an asym-metric generalized traveling salesman problem (AGTSP). A Maximum Entropy classifier is trained to estimate the traveling costs, and a TSP solver is used to find the optimized solution. The final model reports a BLEU score of 22.44 on the SemEval-2016 Task8 dataset.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abstract Meaning Representation (AMR) ( <ref type="bibr" target="#b1">Banarescu et al., 2013</ref>) is a semantic formalism en- coding the meaning of a sentence as a rooted, di- rected graph. Shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the nodes of an AMR graph (e.g. "boy", "go-01" and "want- 01") represent concepts, and the edges (e.g. "ARG0" and "ARG1") represent relations between concepts. AMR jointly encodes a set of different semantic phe- nomena, which makes it useful in applications like question answering and semantics-based machine translation. AMR has served as an intermediate representation for various text-to-text NLP applica- tions, such as statistical machine translation (SMT) ( <ref type="bibr" target="#b6">Jones et al., 2012)</ref>.</p><p>The task of AMR-to-text generation is to gener- ate grammatical text containing the same semantic meaning as a given AMR graph. This task is im- portant yet also challenging since each AMR graph usually has multiple corresponding sentences, and syntactic structure and function words are abstracted away when transforming a sentence into AMR ( <ref type="bibr" target="#b1">Banarescu et al., 2013)</ref>. There has been work deal- ing with text-to-AMR parsing ( <ref type="bibr" target="#b4">Flanigan et al., 2014;</ref><ref type="bibr" target="#b15">Wang et al., 2015;</ref><ref type="bibr" target="#b9">Peng et al., 2015;</ref><ref type="bibr" target="#b13">Vanderwende et al., 2015;</ref><ref type="bibr" target="#b10">Pust et al., 2015;</ref><ref type="bibr" target="#b0">Artzi et al., 2015</ref>). On the other hand, relatively little work has been done on AMR-to-text generation. One recent exception is <ref type="bibr" target="#b5">Flanigan et al. (2016)</ref>, who first generate a span- ning tree for the input AMR graph, and then apply a tree transducer to generate the sentence. Here, we directly generate the sentence from an input AMR by treating AMR-to-text generation as a variant of the traveling salesman problem (TSP).</p><p>Given an AMR as input, our method first cuts the graph into several rooted and connected frag- ments (sub-graphs), and then finds the translation for each fragment, before finally generating the sen- tence for the whole AMR by ordering the transla- tions. To cut the AMR and translate each fragment, we match the input AMR with rules, each consisting of a rooted, connected AMR fragment and a corre- sponding translation. These rules serve in a similar way to rules in SMT models. We learn the rules by a modified version of the sampling algorithm of <ref type="bibr" target="#b9">Peng et al. (2015)</ref>, and use the rule matching algorithm of .</p><p>For decoding the fragments and synthesizing the output, we define a cut to be a subset of matched rules without overlap that covers the AMR, and an ordered cut to be a cut with the rules being or- dered. To generate a sentence for the whole AMR, we search for an ordered cut, and concatenate trans- lations of all rules in the cut. TSP is used to traverse different cuts and determine the best order. Intu- itively, our method is similar to phrase-based SMT, which first cuts the input sentence into phrases, then obtains the translation for each source phrase, before finally generating the target sentence by ordering the translations. Although the computational cost of our method is low, the initial experiment is promising, yielding a BLEU score of 22.44 on a standard bench- mark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>We reformulate the problem of AMR-to-text gener- ation as an asymmetric generalized traveling sales- man problem (AGTSP), a variant of TSP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TSP and its variants</head><p>Given a non-directed graph G N with n cities, sup- posing that there is a traveling cost between each pair of cities, TSP tries to find a tour of the minimal total cost visiting each city exactly once. In contrast, the asymmetric traveling salesman problem (ATSP) tries to find a tour of the minimal total cost on a di- rected graph, where the traveling costs between two nodes are different in each direction. Given a di- rected graph G D with n nodes, which are clustered into m groups, the asymmetric generalized traveling salesman problem (AGTSP) tries to find a tour of the minimal total cost visiting each group exactly once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">AMR-to-text Generation as AGTSP</head><p>Given an input AMR A, each node in the AGTSP graph can be represented as (c, r), where c is a con- cept in A and r = (A sub , T sub ) is a rule that con- sists of an AMR fragment containing c and a trans- lation of the fragment. We put all nodes containing the same concept into one group, thereby translating each concept in the AMR exactly once.</p><p>To show a brief example, consider the AMR in <ref type="figure" target="#fig_0">Figure 1</ref> and the following rules,</p><formula xml:id="formula_0">ns (b,r4) (w,r3) (w,r1) (g,r2) (g,r3)</formula><p>ne We build an AGTSP graph in <ref type="figure" target="#fig_1">Figure 2</ref>, where each circle represents a group and each tuple (such as (b, r 4 )) represents a node in the AGTSP graph. We add two nodes n s and n e representing the start and end nodes respectively. Each belongs to a specific group that only contains that node, and a tour al- ways starts with n s and ends with n e . Legal moves are shown in black arrows, while illegal moves are shown in red. One legal tour is</p><formula xml:id="formula_1">n s → (b, r 4 ) → (w, r 3 ) → (g, r 3 ) → n e .</formula><p>The order in which nodes within a rule are visited is arbitrary; for a rule with N concepts, the number of visiting orders is O(N !).</p><p>To reduce the search space, we enforce the breadth first order by setting costs to zero or infinity. In our example, the traveling cost from (w, r 3 ) to (g, r 3 ) is 0, while the traveling cost from (g, r 3 ) to (w, r 3 ) is infinity. Traveling from (g, r 2 ) to (w, r 3 ) also has infinite cost, since there is overlap on the concept "w/want-01" between them.</p><p>The traveling cost is calculated by Algorithm 1. We first add n s and n e serving the same function as <ref type="figure" target="#fig_1">Figure 2</ref>. The traveling cost from n s directly to n e is infinite, since a tour has to go through other nodes before going to the end. On the other hand, the traveling cost from n e to n s is 0 (Lines 3-4), as a tour always goes back to the start after reaching the end. The traveling cost from n s to n i = (c i , r i ) is the model score only if c i is the first node of the AMR fragment of r i , otherwise the traveling cost is infinite (Lines 6-9). Similarly, the traveling cost from n i to n e is the model score only if c i is the last node of the fragment of r i . Otherwise, it is infinite (Lines 10-13). The traveling cost from n i = (c i , r i ) to n j = (c j , r j ) is 0 if r i and r j are the same rule and c j is the next node of c i in the AMR fragment of r i ( <ref type="bibr">Lines 16-17)</ref>.</p><p>A tour has to travel through an AMR fragment be-</p><formula xml:id="formula_2">Data: Nodes in AGTSP graph G Result: Traveling Cost Matrix T</formula><p>1 n s ← ("&lt;s&gt;","&lt;s&gt;" ); 2 n e ← ("&lt;/s&gt;","&lt;/s&gt;" );</p><formula xml:id="formula_3">3 T[n s ][n e ] ← ∞; 4 T[n e ][n s ] ← 0; 5 for n i ← (c i , r i ) in G do 6 if c i = r i .frag.first then 7 T[n s ][n i ] ← ModelScore(n s ,n i ); 8 else 9 T[n s ][n i ] ← ∞; 10 if c i = r i .frag.last then 11 T[n i ][n e ] ← ModelScore(n i ,n e ); 12 else 13 T[n i ][n e ] ← ∞; 14 for n i ← (c i , r i ) in G do 15 for n j ← (c j , r j ) in G do 16 if r i = r j and r i .frag.next(c i ) = c j then 17 T[n i ][n j ] ← 0 18 else if r i .frag ∩ r j .frag = ∅ and c i = r i .frag.last and c j = r j .frag.first then 19 T[n i ][n j ] ← ModelScore(n i ,n j ) 20 else 21 T[n i ][n j ] ← ∞ Algorithm 1:</formula><p>Traveling cost algorithm fore jumping to another fragment. We choose the breadth-first order of nodes within the same rule, which is guaranteed to exist, as each AMR fragment is rooted and connected. Costs along the breadth- first order within a rule r i are set to 0, while other costs with a rule are infinite.</p><p>If r i is not equal to r j , then the traveling cost is the model score if there is no overlap between r i and r j 's AMR fragment and it moves from r i 's last node to r j 's first node ( <ref type="bibr">Lines 18-19)</ref>, other- wise the traveling cost is infinite (Lines 20-21). All other cases are illegal and we assign infinite travel- ing cost. We do not allow traveling between overlap- ping nodes, whose AMR fragments share common concepts. Otherwise the traveling cost is evaluated by a maximum entropy model, which will be dis- cussed in detail in Section 2.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Rule Acquisition</head><p>We extract rules from a corpus of (sentence, AMR) pairs using the method of <ref type="bibr" target="#b9">Peng et al. (2015)</ref>. Given an aligned (sentence, AMR) pair, a phrase-fragment pair is a pair ( <ref type="bibr">[i, j]</ref>, f ), where <ref type="bibr">[i, j]</ref> is a span of the sentence and f represents a connected and rooted AMR fragment. A fragment decomposition forest consists of all possible phrase-fragment pairs that satisfy the alignment agreement for phrase-based MT ( <ref type="bibr" target="#b7">Koehn et al., 2003)</ref>. The rules that we use for generation are the result of applying an MCMC pro- cedure to learn a set of likely phrase-fragment pairs from the forests containing all possible pairs. One difference from the work of <ref type="bibr" target="#b9">Peng et al. (2015)</ref> is that, while they require the string side to be tight (does not include unaligned words on both sides), we expand the tight phrases to incorporate unaligned words on both sides. The intuition is that they do text-to-AMR parsing, which often involves discard- ing function words, while our task is AMR-to-text generation, and we need to be able to fill in these un- aligned words. Since incorporating unaligned words will introduce noise, we rank the translation candi- dates for each AMR fragment by their counts in the training data, and select the top N candidates. <ref type="bibr">1</ref> We also generate concept rules which directly use a morphological string of the concept for transla- tion. For example, for concept "w/want-01" in <ref type="figure" target="#fig_0">Fig- ure 1</ref>, we generate concept rules such as "(w/want- 01) ||| want", "(w/want-01) ||| wants", "(w/want-01) ||| wanted" and "(w/want-01) ||| wanting". The al- gorithm (described in section 2.2) will choose the most suitable one from the rule set. It is similar to most MT systems in creating a translation candidate for each word, besides normal translation rules. It is easy to guarantee that the rule set can fully cover every input AMR graph.</p><p>Some concepts (such as "have-rel-role-91") in an AMR graph do not contribute to the final translation, and we skip them when generating concept rules. Besides that, we use a verbalization list 2 for concept rule generation. For rule "VERBALIZE peacekeep- ing TO keep-01 :ARG1 peace", we will create a con- cept rule "(k/keep-01 :ARG1 (p/peace)) ||| peace- keeping" if the left-hand-side fragment appears in the target graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Traveling cost</head><p>Considering an AGTSP graph whose nodes are clus- tered into m groups, we define the traveling cost for a tour T in Equation 1: cost(n s , n e ) = − m i=0 log p("yes"|n T i , n T i+1 ) <ref type="formula">(1)</ref> where n T 0 = n s , n T m+1 = n e and each n T i (i ∈ [1 . . . m]) belongs to a group that is different from all others. Here p("yes"|n j , n i ) represents a learned score for a move from n j to n i . The choices be- fore n T i are independent from choosing n T i+1 given n T i because of the Markovian property of the TSP problem. Previous methods ( <ref type="bibr" target="#b18">Zaslavskiy et al., 2009</ref>) evaluate traveling costs p(n T i+1 |n T i ) by using a lan- guage model. Inevitably some rules may only cover one translation word, making only bigram language models naturally applicable. <ref type="bibr" target="#b18">Zaslavskiy et al. (2009)</ref> introduces a method for incorporating a trigram lan- guage model. However, as a result, the number of nodes in the AGTSP graph grows exponentially.</p><p>To tackle the problem, we treat it as a local binary ("yes" or "no") classification problem whether we should move to n j from n i . We train a maximum entropy model, where p("yes"|n i , n j ) is defined as:</p><formula xml:id="formula_4">p("yes"|n i , n j ) = 1 Z(n i , n j ) exp k i=1 λ i f i ("yes", n i , n j )<label>(2)</label></formula><p>The model uses 3 real-valued features: a language model score, the word count of the concatenated translation from n i to n j , and the length of the short- est path from n i 's root to n j 's root in the input AMR. If either n i or n j is the start or end node, we set the path length to 0. Using this model, we can use what- ever N-gram we have at each time. Although lan- guage models favor shorter translations, word count will balance the effect, which is similar to MT sys- tems. The length of the shortest path is used as a feature because the concepts whose translations are adjacent usually have lower path length than others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup</head><p>We use the dataset of SemEval- training instances, 1368 dev instances and 1371 test instances. Each instance consists of an AMR graph and a sentence representing the same mean- ing. Rules are extracted from the training data, and hyperparameters are tuned on the dev set. For tuning and testing, we filter out sentences that have more than 30 words, resulting in 1103 dev instances and 1055 test instances. We train a 4-gram language model (LM) with gigaword (LDC2011T07), and use BLEU ( <ref type="bibr" target="#b8">Papineni et al., 2002</ref>) as the evaluation met- ric. To solve the AGTSP, we use Or-tool 3 .</p><p>Our graph-to-string rules are reminiscent of phrase-to-string rules in phrase-based MT (PBMT). We compare our system to a baseline (PBMT) that first linearizes the input AMR graph by breadth first traversal, and then adopts the PBMT system from Moses 4 to translate the linearized AMR into a sen- tence. To traverse the children of an AMR con- cept, we use the original order in the text file. The MT system is trained with the default setting on the same dataset and LM. We also compare with JAMR- gen <ref type="bibr">5 (Flanigan et al., 2016)</ref>, which is trained on the same dataset but with a 5-gram LM from gigaword (LDC2011T07).</p><p>To evaluate the importance of each module in our system, we develop the following baselines: Only- ConceptRule uses only the concept rules, OnlyIn- ducedRule uses only the rules induced from the frag- ment decomposition forest, OnlyBigramLM uses both types of rules, but the traveling cost is evalu- ated by a bigram LM trained with gigaword.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>The results are shown in <ref type="table">Table 1</ref>. Our method (All) significantly outperforms the baseline (PBMT) (w / want-01 :ARG0 (b / boy) :ARG1 (b2 / believe-01 :ARG0 (g / girl) :ARG1 b)) Ref: the boy wants the girl to believe him All: a girl wanted to believe him JAMR-gen: boys want the girl to believe on both the dev and test sets. PBMT does not outperform OnlyBigramLM and OnlyInducedRule, demonstrating that our rule induction algorithm is effective. We consider rooted and connected frag- ments from the AMR graph, and the TSP solver finds better solutions than beam search, as consis- tent with <ref type="bibr" target="#b18">Zaslavskiy et al. (2009)</ref>. In addition, On- lyInducedRule is significantly better than OnlyCon- ceptRule, showing the importance of induced rules on performance. This also confirms the reason that All outperforms PBMT. This result confirms our ex- pectation that concept rules, which are used for ful- filling the coverage of an input AMR graph in case of OOV, are generally not of high quality. More- over, All outperforms OnlyBigramLM showing that our maximum entropy model is stronger than a bi- gram language model. Finally, JAMR-gen outper- forms All, while JAMR-gen uses a higher order lan- guage model than All (5-gram VS 4-gram).</p><p>For rule coverage, around 31% AMR graphs and 84% concepts in the development set are covered by our induced rules extracted from the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis and Discussions</head><p>We further analyze All and JAMR-gen with an ex- ample AMR and show the AMR graph, the refer- ence, and results in <ref type="table" target="#tab_1">Table 2</ref>. First of all, both All and JAMR-gen outputs a reasonable translation con- taining most of the meaning from the AMR. On the other hand, All fails to recognize "boy" as the sub- ject. The reason is that the feature set does not in- clude edge labels, such as "ARG0" and "ARG1". Finally, neither All and JAMR-gen can handle the situation when a re-entrance node (such as "b/boy" in example graph of <ref type="table" target="#tab_1">Table 2</ref>) need to be translated twice. This limitation exists for both works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Our work is related to prior work on AMR ( <ref type="bibr" target="#b1">Banarescu et al., 2013)</ref>. There has been a list of work on AMR parsing ( <ref type="bibr" target="#b4">Flanigan et al., 2014;</ref><ref type="bibr" target="#b15">Wang et al., 2015;</ref><ref type="bibr" target="#b9">Peng et al., 2015;</ref><ref type="bibr" target="#b13">Vanderwende et al., 2015;</ref><ref type="bibr" target="#b10">Pust et al., 2015;</ref><ref type="bibr" target="#b0">Artzi et al., 2015)</ref>, which predicts the AMR structures for a given sentence. On the re- verse direction, <ref type="bibr" target="#b5">Flanigan et al. (2016)</ref> and our work here study sentence generation from a given AMR graph. Different from <ref type="bibr" target="#b5">Flanigan et al. (2016)</ref> who map a input AMR graph into a tree before lineariza- tion, we apply synchronous rules consisting of AMR graph fragments and text to directly transfer a AMR graph into a sentence. In addition to AMR parsing and generation, there has also been work using AMR as a semantic representation in machine translation ( <ref type="bibr" target="#b6">Jones et al., 2012)</ref>.</p><p>Our work also belongs to the task of text genera- tion <ref type="bibr" target="#b11">(Reiter and Dale, 1997)</ref>. There has been work on generating natural language text from a bag of words ( <ref type="bibr" target="#b14">Wan et al., 2009;</ref><ref type="bibr" target="#b19">Zhang and Clark, 2015)</ref>, surface syntactic trees <ref type="bibr" target="#b20">(Zhang, 2013;</ref><ref type="bibr" target="#b12">Song et al., 2014</ref>), deep semantic graphs ( <ref type="bibr" target="#b2">Bohnet et al., 2010)</ref> and logical forms <ref type="bibr" target="#b17">(White, 2004;</ref><ref type="bibr" target="#b16">White and Rajkumar, 2009</ref>). We are among the first to investigate generation from AMR, which is a different type of semantic representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In conclusion, we showed that a TSP solver with a few real-valued features can be useful for AMR-to- text generation. Our method is based on a set of graph to string rules, yet significantly better than a PBMT-based baseline. This shows that our rule induction algorithm is effective and that the TSP solver finds better solutions than beam search.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: AMR graph for "The boy wants to go".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example AGTSP graph</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Case study. 

</table></figure>

			<note place="foot" n="1"> Our code for grammar induction can be downloaded from https://github.com/xiaochang13/AMR-generation 2 http://amr.isi.edu/download/lists/verbalization-listv1.06.txt</note>

			<note place="foot" n="3"> https://developers.google.com/optimization/ 4 http://www.statmt.org/moses/ 5 https://github.com/jflanigan/jamr/tree/Generator</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful for the help of Jeffrey Flanigan, Lin Zhao, and Yifan He. This work was funded by NSF IIS-1446996, and a Google Faculty Research Award. Yue Zhang is funded by NSFC61572245 and T2MOE201301 from Singapore Ministry of Ed-ucation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Broad-coverage CCG semantic parsing with AMR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP-15)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1699" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Broad coverage multilingual deep sentence generation with a stochastic multi-level realizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Mill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Burga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10)</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="98" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL-13)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL14)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generation from abstract meaning representation using tree transducers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-16)</title>
		<meeting>the 2016 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-16)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semanticsbased machine translation with hyperedge replacement grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bevan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics (COLING-12)</title>
		<meeting>the International Conference on Computational Linguistics (COLING-12)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1359" to="1376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-03)</title>
		<meeting>the 2003 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="48" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Conference of the Association for Computational Linguistics (ACL-02)</title>
		<meeting>the 40th Annual Conference of the Association for Computational Linguistics (ACL-02)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A synchronous hyperedge replacement grammar based approach for AMR parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Computational Natural Language Learning (CoNLL-15)</title>
		<meeting>the Nineteenth Conference on Computational Natural Language Learning (CoNLL-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Parsing English into abstract meaning representation using syntax-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP15)</title>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="1143" to="1154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Building applied natural language generation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="87" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Joint morphological generation and syntactic linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence (AAAI-14)</title>
		<meeting>the National Conference on Artificial Intelligence (AAAI-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1522" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An AMR parser for English, French, German, Spanish and Japanese and a new AMR-annotated corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-15)</title>
		<meeting>the 2015 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improving grammaticality in statistical sentence generation: Introducing a dependency spanning tree algorithm with an argument satisfaction model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cécile</forename><surname>Paris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter of the ACL (EACL-09)</title>
		<meeting>the 12th Conference of the European Chapter of the ACL (EACL-09)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="852" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for AMR parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-15)</title>
		<meeting>the 2015 Meeting of the North American chapter of the Association for Computational Linguistics (NAACL-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="366" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Perceptron reranking for CCG realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajakrishnan</forename><surname>Rajkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP-09)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="410" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Reining in CCG chart realization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Natural Language Generation (INLG-04)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="182" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Phrase-based statistical machine translation as a traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Zaslavskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Cancedda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-09)</title>
		<meeting>the 47th Annual Meeting of the Association for Computational Linguistics (ACL-09)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="333" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discriminative syntax-based word ordering for text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="503" to="538" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Partial-tree linearization: Generalized word ordering for text synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI-13)</title>
		<meeting>the International Joint Conference on Artificial Intelligence (IJCAI-13)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2232" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
