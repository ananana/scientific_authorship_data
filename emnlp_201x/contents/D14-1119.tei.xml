<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vote Prediction on Comments in Social Polls</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Persing</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Human Language Technology Research Institute University of Texas at Dallas Richardson</orgName>
								<address>
									<postCode>75083-0688</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vote Prediction on Comments in Social Polls</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1127" to="1138"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A poll consists of a question and a set of predefined answers from which voters can select. We present the new problem of vote prediction on comments, which involves determining which of these answers a voter selected given a comment she wrote after voting. To address this task, we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints. In an evaluation involving nearly one million comments collected from the popular SodaHead social polling website, we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We introduce in this paper a new opinion mining task, vote prediction on comments in social polls. Recall that a poll consists of a question accompa- nied by a set of predefined answers. A user who votes on the question will choose one of these an- swers and will be prompted to enter a comment giving an explanation of why she chose the an- swer. Given a poll and a user comment written in response to it, the task of vote prediction seeks to determine which predefined answer was chosen by the author of the comment.</p><p>A solution to the vote prediction problem would contribute significantly to our understanding of the underlying attitudes of individual social polling website users. This understanding could be ex- ploited for tasks such as improving user experi- ence or directed advertising; if we can predict how a user will vote on a question, we can make more accurate guesses about what kind of content/ads related to the question the user would like to see. Unfortunately, a major difficulty of vote predic- tion arises from the casual nature of discussion in social media. A comment often contains insuffi- cient information for inferring the user's vote, or in some cases may even be entirely absent.</p><p>In light of this difficulty, we exploit two addi- tional types of information in the prediction pro- cess. First, we employ demographic features de- rived from user profiles. Demographic features may be broadly useful for other opinion mining tasks such as stance classification <ref type="bibr" target="#b16">(Somasundaran and Wiebe, 2010)</ref>, as many social media web- sites like CreateDebate 1 allow users to create pro- files with similar demographic information. Previ- ous work has attempted to predict such latent fea- tures (e.g., <ref type="bibr" target="#b15">Rao and Yarowsky (2010)</ref>, <ref type="bibr" target="#b3">Burger et al. (2011)</ref>) rather than employing them for opin- ion mining tasks.</p><p>Second, we exploit inter-comment constraints to help us perform joint inference over votes on different questions. Note that previous work on debate stance recognition has also employed con- straints to improve the inference process. Specif- ically, in stance prediction, it is typical to em- ploy so-called author constraints (e.g., <ref type="bibr" target="#b17">Thomas et al. (2006)</ref>, <ref type="bibr" target="#b1">Bansal et al. (2008)</ref>, <ref type="bibr" target="#b19">Walker et al. (2012a)</ref>, <ref type="bibr" target="#b9">Hasan and Ng (2013)</ref>), which specify that two documents written by the same author for the same topic should have the same stance. However, in vote prediction, author constraints are not use- ful because a user is not permitted to cast more than one vote per question, unlike in stance pre- diction, where users may engage in a debate and therefore post more than once per debate topic. Consequently, we propose two new types of con- straints for exploiting inter topic user voting pat- terns. One constraint involves pairs of authors and the other involves pairs of questions. These con- straints are also potentially useful for other opin-ion mining tasks involving social media, as social media sites typically allow users to comment on multiple topics. Note that enforcing constraints in- volving two questions is by no means trivial, as the possible class values associated with the two com- ments may not necessarily be the same.</p><p>Another contribution of our work lies in our adaptation of the label propagation algorithm ( <ref type="bibr" target="#b24">Zhu and Ghahramani, 2002</ref>) to enforce constraints for vote prediction. Recall that existing stance classi- fication approaches enforce constraints using min- imum cut ( <ref type="bibr" target="#b17">Thomas et al., 2006</ref>), integer linear pro- gramming ( <ref type="bibr" target="#b11">Lu et al., 2012)</ref>, and loopy belief prop- agation <ref type="bibr" target="#b2">(Burfoot et al., 2011)</ref>. Our decision to em- ploy label propagation stems in part from the in- ability of loopy belief propagation and integer lin- ear programming to efficiently process the nearly one million comments we have, and in part from the inability of the traditional two-way minimum cut algorithm to handle multiclass classification. It is worth noting, however, that other variations of the label propagation algorithm have been pro- posed for unrelated NLP tasks such as automati- cally harvesting temporal facts from the web (e.g., <ref type="bibr" target="#b21">Wang et al. (2011)</ref> and ).</p><p>While we are the first to address the vote predic- tion task, other researchers have previously used social media to predict the outcomes of various events, primarily by analyzing Twitter data. For example, <ref type="bibr" target="#b18">Tumasjan et al. (2010)</ref> and <ref type="bibr" target="#b7">Gayo-Avello et al. (2011)</ref> performed the related task of predict- ing the outcomes of elections. Rather than pre- dicting election outcomes, O' <ref type="bibr">Connor et al. (2010)</ref> focused on finding correlations between measures derived from tweets and the outcomes of politi- cal events like elections and polls. Finally, <ref type="bibr" target="#b0">Asur and Huberman (2010)</ref> predicted movies' box of- fice success. These tasks contrast with our task of vote prediction in that they are concerned with ag- gregate measures such as the fraction of the vote each candidate or party will win in an election or how much money a movie will make at the box office, whereas vote prediction is concerned with predicting how individual people will vote on a much wider variety of news/political topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus</head><p>SodaHead 2 is a social polling website where users vote on and ask questions about a wide variety of topics ranging from the serious (e.g., "Should the U.S. raise the minimum wage?") to the silly (e.g "What is your favorite kind of pie?"). Whenever a user votes on one of these questions, choosing one of a set of predefined answers, she is prompted to enter a comment giving an explanation of why she chose the answer she did. Our corpus 3 consists of all the comments 4 users posted under all featured questions in the News &amp; Politics category of the SodaHead website between <ref type="bibr">March 12, 2008 and</ref><ref type="bibr">August 21, 2013.</ref> This dataset consists of a total of 997,379 com- ments over 4,803 different questions, so an aver- age of 208 comments are written in response to each question. The length of an average comment is 49 words. As <ref type="table" target="#tab_0">Table 1</ref> illustrates, these questions may have more than two possible answers, with an average question having 2.4 possible answers.</p><p>Each SodaHead user has her own profile that contains demographic information about her. As we can see from <ref type="table" target="#tab_1">Table 2</ref>, many users choose to provide only some information about themselves, leaving many of the demographic fields blank. 108,462 users posted at least one comment in our corpus, with an average user commenting on 9.2 of our questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Baseline Systems</head><p>To perform our experiments, we first split our comments into three sets, a test set for evaluating performance, a training set for training classifiers, and a development set for tuning parameters. In order to ensure that the comparisons of our experi- ments are valid, we construct our test set using the same 20% of comments in the dataset regardless of experiment. Since our goal is to plot a learning curve illustrating how our various vote prediction systems perform given different amounts of train- ing and development data, we vary the size of our training and development sets across experiments so that in the smallest experiment, together they comprise 25% of the remaining (non-test) com- ments, and in the largest experiment, they com- 3 http://www.hlt.utdallas.edu/%7epersingq/SocialPolls/ is the distribution site for our corpus. We preserve user anonymity by replacing the original id of each user with a random number in our corpus. <ref type="bibr">4</ref> A "comment" is the text a user posted when submitting her vote on a question. It does not include posts not associ- ated with a vote (such as responses to other posts) or votes where the user chose not to enter a comment. Thus, there is a one-to-one relationship between comments in votes in our dataset. The vote associated with a comment is always known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Vote</head><p>Comment Who Won Round Two of the Presidential Debate?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Barack Obama</head><p>Binders full of women. That is all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mitt Romney</head><p>Obama is inept and a liar. We can't survive 4 more years of his crazy crap.</p><p>What's the Best Way to Read a Magazine?</p><p>in print Upside down like Luna Lovegood. online Print costs money. It also doesn't have a Search function. on a tablet device since sooooo many people have tablet devices why read it as print or online? on a smartphone Clicked in print!!! Aargh  prise 100% of the remaining comments. For each experiment, we maintain a ratio of three training comments to one development comment.</p><p>Recall that each comment in our dataset is writ- ten in response to a particular question. For each test comment, our goal is to predict the user's an- swer to the question given the text of her comment. One of the major inherent difficulties of our task is that it consists not of one, but of 4,803 sep- arate multiclass classification problems (one for each question). As a result, our approach to the problem necessarily has to be somewhat generic, as it would be too time-consuming to develop an appropriate feature set for each question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline 1</head><p>Our first baseline's (B 1 ) approach employs 4,803 multiclass classifiers (one for each question). Each classifier is trained on one question's training set, representing each comment using only a bias fea- ture. Each of our classifiers is trained using MAL- LET's <ref type="bibr" target="#b12">(McCallum, 2002</ref>) implementation of max- imum entropy (ME) classification. This is equiv- alent to merely counting the number of training set comments that voted for each possible answer, selecting the most frequent answer, then applying this label to all the comments in the test set. This majority baseline serves primarily to tell us how well our more sophisticated baseline performs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline 2</head><p>Our second baseline (B 2 ) is constructed in exactly the same way as B 1 except that each classifier is trained using both a bias feature and a standard set of feature types described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Features</head><p>Since the questions in our dataset come from the News &amp; Politics category of the SodaHead web- site, many of the questions' topics are political. For that reason, it makes sense to use features which have been shown to work well on other political classification problems. We therefore base our feature set on that used by <ref type="bibr" target="#b20">Walker et al. (2012b)</ref> for political debate classification. Our features are described below.</p><p>N-grams. Unigrams have been shown to per- form well in ideological debates <ref type="bibr" target="#b16">(Somasundaran and Wiebe, 2010)</ref>, so we therefore present our classifiers with lemmatized unigram, bigram, and trigram features. We normalize the n-gram feature vector to unit length to avoid giving undue influ- ence to longer comments.</p><p>Cue Words. Based on other work <ref type="bibr" target="#b5">(Fox Tree and Schrock, 1999;</ref><ref type="bibr" target="#b6">Fox Tree and Schrock, 2002;</ref><ref type="bibr" target="#b8">Groen et al., 2010;</ref><ref type="bibr" target="#b20">Walker et al., 2012b</ref>), we also present our classifiers with features representing the first lemmatized unigram, bigram, and trigram appearing in each comment. These may be useful in our task when, for example, a user's comment begins with or entirely consists of a restatement of the answer she chose. So if the possible answers for a given question are "Yes" and "No", a user might write in her comment "Yes. Because ...", and this would make the "CueWord:Yes" feature useful for classifying this comment.</p><p>Emotion Frequency. For each word in a com- ment, we used the NRC Emotion Word Lexicon ( <ref type="bibr" target="#b13">Mohammad and Yang, 2011</ref>) to discover if the word conveys any emotion. Then, for each emo- tion or sentiment covered by the lexicon (anger, anticipation, disgust, fear, joy, sadness, surprise, trust, positive, or negative) e i , we construct a fea- ture e i : C(e i ) total describing how much of the comment consists of words conveying emotion e i , where C(e i ) is the count of words in the comment bear- ing emotion e i and total is the number of words in the comment. To understand why this fea- ture may be useful, consider the question "Does Sarah Palin deserve VP?" We suspect that users who post comments laden with words associated with positive emotions like joy are more likely to vote "Yes" because the positive emotions im- ply they are happy about a Sarah Palin vice presi- dency. Similarly, users who post comments laden with negative emotions like anger might be more likely to vote "No".</p><p>Dependencies. We use the Stanford Parser (de <ref type="bibr" target="#b4">Marneffe et al., 2006</ref>) to extract a set of depen- dencies from each comment. For an example of how dependencies might help in our task, con- sider the second comment in <ref type="table" target="#tab_0">Table 1</ref>. From this comment, we can extract the dependency triple dependency:(nsubj,inept,obama), which indicates that the user who wrote it does not like Obama and is therefore more likely to have voted for Romney in the question. Dependency feature vectors are normalized to unit length.</p><p>Emotion Dependencies. To form an emo- tion dependency feature, we take a regular de- pendency feature and replace each of its words where possible with the emotion it evokes as deter- mined by the NRC Emotion Word Lexicon. Thus from the dependency:(nsubj,inept,obama) exam- ple above, we would generate three features: emo- tiondependency:(nsubj,anger,obama), emotionde- pendency:(nsubj,disgust,obama), and emotionde- pendency:(nsubj,negative,obama). These features help generalize dependencies, and this is use- ful because predictive features like emotiondepen- dency:(nsubj,negative,obama) appear frequently in the comments for this question, but depen- dency:(nsubj,inept,obama) does not. Emotion De- pendency feature vectors are normalized to unit length.</p><p>Post Information. Features under this category just calculate some basic statistics about a com- ment. These features may be useful because, for example, the question "Most Scandalous Politi- cians of 2008− Who deserves the title?" has six possible answers, each except the last naming a particular well-known politician. The last choice is "The most scandalous politician of 2008 is ..." and the user is expected to name a politician in her comment. It would make sense for users choos- ing this option to have written longer responses since they have to name and possibly explain their choice to users who might not necessarily know who their chosen politician is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Feature Selection</head><p>Because some of the feature types (n-grams, cue words, dependencies, and emotion dependencies) described in the previous subsection are expected to generate a large number of non-predictive fea- tures, we trim some of the most irrelevant fea- tures out of the feature set to avoid memory prob- lems. Therefore, following <ref type="bibr" target="#b23">Yang and Pedersen (1997)</ref>, for each question we calculate the infor- mation gain of each feature of these types on the training set. We then remove those features having the lowest information gain as well as those fea- tures occurring less than ten times in the dataset. Early experiments showed that 1,000 was a rea- sonable number of features to keep, so for all ex- periments we keep only the top 1,000 features of these types. Note that we do not apply feature se- lection to emotion frequency or post information features, as each of these sets consists of a small number of real-valued features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Demographic Features</head><p>As mentioned in the introduction, a major diffi- culty inherent to our problem is that in many cases a comment contains insufficient information for inferring the underlying vote. Aside from being short, the comments shown in <ref type="table" target="#tab_0">Table 1</ref> are typ- ical of comments found in the dataset. Some comments are like the first and third in the table, requiring some obscure bit of world knowledge to understand what the writer is saying. Others like the fourth only explain why the user did not choose a particular answer, which is always po- tentially useful, but sufficient only if the comment excludes every other possible choice.</p><p>Because it is difficult to tell how a user voted given her comment, we exploit the demographic information users provide in their profiles as an additional source of information. Since many of the questions in our dataset deal with poli- tics, we anticipate that information about things such as whether a comment was written by a conservative or progressive user would be use- ful for predicting the answers of many comments. For each comment, we encode demographic in- formation as features in the following way. For each field in the user's profile shown in <ref type="table" target="#tab_1">Table 2</ref> (aside from user ID), we construct a feature of the form F i :V i if the user filled in field F i with value V i . Thus, any comment made by user 3479864 would include the features Age:25−34, Politi- calViews:Conservative, Gender:Female, and Reli- gion:Other.</p><p>Here is an example of a comment whose predicted vote gets corrected by adding demo- graphic features to our system. For the ques- tion, "LPGA Decides to Allow Transgender Com- petitors: Good or Bad Move for Golf?", user 2252750 writes, "LPGA ...can let monkeys play if they wish....nobody gives a rip... bark". Of the three possible answers for this question, "Good move", "Bad move", and "Undecided", our base- line system without demographics believes that user 2252750 probably voted for the third, as "nobody gives a rip" makes him sound apathetic toward the issue. However, our demographic system notices that his profile contains "Reli- gion:Christian", and users with this demographic attribute choose "Bad Move" 64% of the time. Thus, demographic features allowed our system to correctly predict his vote for "Bad Move".</p><p>Since demographics are also expected to gen- erate a large number of non-predictive features, we apply feature selection to them as described in Section 3.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Enforcing Constraints</head><p>We mentioned earlier that an average SodaHead question contains 208 comments. This implies that there are only about 31−125 comments 5 in the average training set for one of our ME classi- fiers. It would be difficult to train a good classi- fier from a training set this small even if we had feature sets tailored to work well on each of the 4,803 questions. While we have already attempted to exploit user information (in the form of de- mographic features) to help improve our system's performance, this approach still treats the task as 4,803 separate classification problems. It does not allow for the possibility that classification on one question may be improved by exploiting informa- tion gleaned from votes on other questions.</p><p>One way we might exploit such information is by first noticing that, for any pair of questions, there may be multiple users who commented on both. This overlap between questions allows us to calculate how predictive a user's vote on one ques- tion is of how she will vote on the other. For ex- ample, on the question "Who Would You Rather Have Dinner With?", we found that users who voted for "Mitt Romney" were much more likely to choose "No, I'm still voting for him" on the question "Does Mitt Romney's 'Entitled' Remarks Change Your Opinion of Him?". Similarly, users who voted to have dinner with "Barack Obama" were much more likely to vote "Yes, I'm not vot- ing for him anymore" on the "entitled" question. A system that somehow takes into account this in- formation might correctly classify a difficult com- ment on the "entitled" question if it notices that the comment was written by a user who commented on both questions and it knows how the user voted on the "dinner" question. We call the kind of con- straint described here a QuestionPair constraint.</p><p>We might also exploit information from other questions by noticing that there are users who share similar attitudes on a wide variety of top- ics in our dataset. We can gauge how often a pair of users agree with each other by compar- ing their votes on every question on which they have both voted where their comments appear in the training set. So for example, if we see that two users have agreed on questions about George H.W. Bush, Bill Clinton, and George W. Bush, we can guess that they will also agree on a ques- tion about Barack Obama. Similarly, if they dis- agreed on all those questions, they are likely to disagree on the last question. A system that takes into account this kind of information could cor- rectly classify an otherwise difficult comment if it knows how another user voted on this question and also knows how often the two users agree on other questions. We call the kind of constraint described here a VoterPair constraint.</p><p>In order to enforce both kinds of constraints, we introduce a variation of the label propagation algorithm ( <ref type="bibr" target="#b24">Zhu and Ghahramani, 2002</ref>). In our version of the label propagation algorithm, each comment in our dataset is represented by a node in a graph. Each node is associated with a proba- bility distribution indicating the likelihood that the comment belongs to each of its question's possible answers. Thus, when we initialize the graph, each training set node's probability distribution is set to reflect its comment's actual label (with a proba- bility of 1 for the comment's actual label and 0 for each other answer), and each development or test set node's probability distribution is set to the value predicted by another classifier such as B 2 or B 2 + Dem since the algorithm is not permitted to see the comment's actual label. Lines 7−12 in <ref type="figure">Figure 1</ref> describe the graph's initialization. Now that we have set up the graph's nodes, we need to explain how our graph's edges work. As we discussed earlier in this section, the edges in our graph will represent two kinds of soft con- straints. Each edge allows one of a node's neigh- bors to cast a vote (in the form of a probability dis- tribution over possible answers) for what it thinks the node's answer should be. Let us call the com- ment node whose label we are trying to predict the target node and the comment node which casts the vote the source node.</p><p>Our graph contains a QuestionPair edge be- tween any source and target comments written by the same user. Since a user cannot comment more than once on any question, the source and target comments will occur in two different questions. In order to determine how the source node votes over a QuestionPair edge, we need to calculate some probabilities. In particular, we need to determine the probability that a user will vote for possible answer k in the target question Q I given that she voted for answer l in the source question Q J :</p><formula xml:id="formula_0">P (Q I k |Q J l ) = C(Q I k ,Q J l )+γ m∈A(Q I ) (C(Q Im ,Q J l )+γ)</formula><p>where C(Q In , Q J l ) is the number of users who voted for answer n in Q I and answer l in Q J , and A(Q I ) is the set of possible answers on Q I . We set γ, the smoothing factor, to 10 since this value worked well in earlier experiments. The source node S casts its vote on target node T for the prob- ability distribution given by:</p><formula xml:id="formula_1">QPS,T (QI k ) = m∈A(Q J ) PS(QJ m )P (QI k |QJ m )</formula><p>where P S (Q Jm ) is the probability currently asso- ciated with answer m in S's question (Q J ).</p><p>The graph contains a VoterPair edge between any source and target nodes on the same question if the users who posted these comments have both voted on at least one other question together and their comments on the other question(s) occurred in the training set. To determine how the source node votes over a VoterPair edge, we need to cal- culate the probability that the source and target users will agree on a generic issue:</p><formula xml:id="formula_2">P agr (U S , U T ) = Cagr(U S ,U T )+1 Cagr(U S ,U T )+C dis (U S ,U T )+2</formula><p>where C agr (U S , U T ) is the number of questions on which users U S and U T voted for the same answer and both their comments occurred in the training set, C dis (U S , U T ) is the number of ques- tions on which U S and U T voted for different answers where both their comments occurred in the training set, and the +1 and +2 are used for smoothing. The probability distribution that the source node S votes for on target node T is then given by:</p><formula xml:id="formula_3">V PS,T (QI k ) = PS(QI k )Pagr(US, UT ) + m∈A(Q I ), m =k (PS(QI m )) 1 − Pagr(US, UT ) |A(QI )| − 1</formula><p>where P S (Q In ) is the probability currently asso- ciated with answer n in the source node's question (Q I ), and |A(Q I )| is the number of possible an- swers on Q I . We divide the second term, which deals with disagreement, by |A(Q I )| − 1 because, even if we know that the target and source users disagreed on the answer to a particular question and that the source user did not vote for answer k, there is only a 1 |A(Q I )|−1 chance that the target user voted for answer k since there are |A(Q I )|−1 non-k answers to choose from. Now that we have described how edges are added to the graph and how source comment nodes vote over the edges, we are ready to begin iterat- ing over the label propagation algorithm (line 13 in <ref type="figure">Figure 1</ref>). For each iteration of the algorithm, we update each development or test set node's answer probability distribution by assigning it a weighted sum of (1) the initial probability distribution as- signed to the node, (2) the sum of the Question- Pair edges' votes, and (3) the sum of the VoterPair edges' votes (line 16 in <ref type="figure">Figure 1)</ref>. Upon comple- tion of the algorithm, if our soft constraints work as expected, the new labeling of comment nodes should be more accurate than their initial labeling.</p><p>We tune the parameters W I , W V , W Q , and iterations jointly by an exhaustive search of the parameter space to maximize classification accu- racy on the development set. Each of the weight parameters is allowed to take one of the values 0, 1, or 2, and the iteration parameter is allowed take one of the values 0, 1, 2, 3, 4, 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1: LabelP ropagation(T r, D, T e, iterations, Wi, WV , WQ, I) 2: Inputs: 3:</head><p>T r, D, T e: Comments in Training, Development, and Test set 4:</p><p>iterations: The number of iterations to perform 5:</p><p>Wi, WV , WQ: Weights assigned to initial, VoterPair, and QuestionPair constraints 6:</p><p>I: Initial answer probability distribution for all comments. Should reflect actual labels for training set comments and classifier predictions for development and test set comments 7: for all C ∈ T r ∪ D ∪ T e do 8:</p><p>Create node representing C 9:</p><p>Cp ← IC 10:</p><p>// Cp: node C's current probability distribution over possible answers 11:</p><p>// IC : initial answer probability distribution for comment C 12: end for 13: for j = 1 to iterations do 14:</p><p>for all node C ∈ D ∪ T e do 15:</p><p>Add all edges targeting node C 16:</p><formula xml:id="formula_4">Cp ← N orm(WI IC + WV k V P k,C + WQ k QP k,C ) 17:</formula><p>// V P k,C , QP k,C : kth VoterPair, and kth QuestionPair votes for node C 18:</p><p>Remove all edges targeting node C 19: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20: end for</head><p>Figure 1: Our label propagation algorithm.</p><p>One may be surprised to notice how we add edges to the graph in the algorithm only to delete them three lines later (lines 15 and 18 in <ref type="figure">Figure 1</ref>). Though edges can be added at any point in the al- gorithm, one benefit of using the label propagation algorithm is that it is simple enough that it is not necessary store all the edges in memory at once. The only time we need to store an edge is when its target is being voted on. This means that the label propagation algorithm can handle large datasets like ours with huge numbers of nodes and edges without being prohibitively space-expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Setup</head><p>We mentioned in Section 3 that we split our dataset of 997,379 comments into a test set com- prising about 20% of the dataset's comments and a training and development set comprising some fraction of the remaining 80% of the comments. We actually split the data up like this five different times so that each comment appears in an experi- ment's test set exactly once. In this way, through the use of five fold cross-validation, we can report our results on the entire dataset. <ref type="figure" target="#fig_0">Figure 2a</ref> shows the accuracy of the predictions made by various systems. First, let us compare our first and second baselines. Recall that the first baseline (B 1 ) predicts that all test comments will have the same label as the majority of training comments, and the second baseline's (B 2 ) predic- tions are the output of ME classifiers trained with a generic feature set. As we can see from the graph, at very small training set sizes, the standard set of features supplied to B 2 does little more than con- fuse the ME learner, as it performs slightly but not significantly worse 6 than the first baseline when the training/development set comprises only 25% of the available data. This is understandable, as 25% of an average question's available data is only 42 comments, an extremely small number of ex- amples to learn from for most NLP tasks. Clearly a better approach than the one provided by the sec- ond baseline is needed. Though the average train- ing set sizes at the 50%, 75%, and 100% levels are still relatively small, B 2 significantly outperforms B 1 at all these levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results and Discussion</head><p>The small improvement sizes yielded by B 2 may be attributable to some of the inherent dif- ficulties of the problem, particularly that (1) it is composed of so many (4,803) separate subprob- lems that it is impractical for us to tailor a unique feature set for each one, (2) the average question is associated with a very small number of comments (about 208), making it difficult to train a reason- ably good classifier for any question, and <ref type="formula">(3)</ref>   some of these problems.</p><p>The first improvement we proposed involved exploiting demographic features provided by users to help with our prediction tasks. When we com- bine Dem and B 2 's feature sets, the resulting system (B 2 + Dem) performs better than any of the systems discussed thus far at all four train- ing/development set size levels, yielding signifi- cant improvements over B 2 at all four levels. This demonstrates that our demographic features are a useful complement to a standard approach like the one used by B 2 .</p><p>The second improvement we proposed involved using a variation of the label propagation algo- rithm to enforce QuestionPair constraints. Ques- tionPair constraints, recall, allowed us to exploit the observed voting patterns of users who voted in the training set on any particular pair of ques- tions. These constraints were expected to improve our predictions for any user who voted on both questions when at least one of their votes appeared in the test set. System B 2 + QP air corresponds to following the algorithm in <ref type="figure">Figure 1</ref>, using sys- tem B 2 's ME classifiers to initialize a label prop- agation graph, and then setting the VoterPair edge weight (W V ) to 0, thus allowing only Question- Pair constraints. When we compare this system to B 2 , we see that the performance boost Question- Pair constraints give us over the baseline is consis- tently greater than the boost given by adding de- mographic features to it (B 2 + Dem) across all training/development set sizes. The improvement over B 2 is even significant at the 75% and 100% training/development set sizes.</p><p>The last improvement we proposed involved adding VoterPair constraints to the label propaga- tion graph. Recall that VoterPair constraints al- lowed us to exploit how frequently we observed two users agreeing with each other to predict whether they will agree on any question they both voted on. System B 2 + V P air corresponds to fol- lowing the label propagation algorithm using B 2 's ME classifiers to initialize the graph, then setting the QuestionPair edge weight (W Q ) to 0, thus al- lowing only VoterPair constraints. The addition of VoterPair constraints yields the largest significant improvements over B 2 at all four levels, indicating that, in the absence of our other proposed improve- ments, VoterPair edge constraints are the most im- portant addition we can make to our baseline.</p><p>While we have now shown that each of our pro- posed extensions yields significant improvements over B 2 , this does not necessarily mean that each one is useful in the presence of the others. For example, it might be the case that QuestionPair constraints and Demographic features correct the same kinds of classification errors, and therefore it may be sufficient to use either one or the other to obtain good results, but using both is unnecessary. To test how useful they are in each other's pres-ence, we perform the following experiment. First, we run the algorithm using all three improvements (B 2 + Dem + QP air + V P air in <ref type="figure" target="#fig_0">Figure 2a</ref>). We then run the same experiment three more times, each time removing one of the three extensions. By measuring how much performance decreases when we remove each of the three improvements, we can determine whether each improvement pro- vides unique useful information, or whether the in- formation it provides is already being provided by one of the other improvements.</p><p>To see what happens when we remove demo- graphic features from the full system, we need to compare B 2 + Dem + QP air + V P air and B 2 + QP air + V P air in <ref type="figure" target="#fig_0">Figure 2a</ref>. While the decrease in performance after removing demographic fea- tures was modest, the difference is nevertheless significant at all four training/development set sizes, suggesting that demographic features do provide unique information to the system. By comparing line B 2 + Dem + QP air + V P air to line B 2 + Dem + V P air, we can deter- mine the impact of QuestionPair constraints. Re- moving QuestionPair constraints also had a mod- est impact on the full system's performance, de- creasing accuracy at all four training/development set sizes, significantly so at the 50%, 75%, and 100% levels. Interestingly, the impact of Ques- tionPair constraints appears to grow with the train- ing set, while the demographic features appear to have a greater impact when the training set is small. We can see this by noting that the two lines cross at around 55%. This suggests that Question- Pair constraints are especially useful in problems where it is cheap to obtain a lot of training data, but in problems where the data has to be manually annotated, demographic features are more useful.</p><p>Finally, we can compare line B 2 + Dem + QP air + V P air to line B 2 + Dem + QP air to see what happens when we remove VoterPair con- straints from our system. This comparison illus- trates that VoterPair constraints are by far the most important improvement we removed from the full system, as removing them yielded large significant decreases at all four levels.</p><p>Though thus far we have only used it to analyze the the contributions of different individual im- provements, the full system B 2 +Dem+QP air+ V P air is interesting in itself. Of all the systems we have constructed, it performs the best, yield- ing improvements of up to 5.18% and 3.88% when compared to B 1 and B 2 respectively. Its improve- ments over both baselines are statistically signifi- cant at all four training/development set sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Arbitrary User Vote Prediction</head><p>One interesting question that we have not yet ad- dressed is, is it possible to predict how a user would vote on a question she has not yet seen? This problem is interesting because an average question receives votes from only 0.2% of the users in our dataset, and thus a system for predict- ing an arbitrary user's vote would be able to pre- dict the votes of the other 99.8% of users. A solu- tion to this prediction problem would have practi- cal applications in areas such as directed advertis- ing (e.g., if we could predict how a user would vote on the magazine question in <ref type="table" target="#tab_0">Table 1</ref>, we would have a better idea of what kinds of reading de- vices/services would interest her).</p><p>We can mimic this problem with our dataset by treating the comment text associated with test votes as unseen since we cannot expect an arbi- trary user to have commented on any particular question we are interested in <ref type="bibr">7</ref> . It does, however, make sense for us to expect our arbitrary user to have provided some personal demographic infor- mation, and thus a system for making these types of predictions could reasonably make use of de- mographic features. Similarly, in this situation we would expect to have knowledge of all users' train- ing set voting histories. Thus, it would also be rea- sonable for our system to exploit the QuestionPair and VoterPair constraints described in Section 5. Thus, to test how well our system performs on this task, we repeat all experiments from the previous section while replacing B 2 (which uses a ME clas- sifier trained on comment-based features) with B 1 (the most frequent baseline, which uses a ME clas- sifier trained using only a bias feature). The results of these experiments are shown in <ref type="figure" target="#fig_0">Figure 2b</ref>.</p><p>If we compare the results from B 1 to B 1 +Dem (which compliments B 1 's bias feature with the de- mographic feature set), we notice that B 1 + Dem is significantly worse than B 1 at all training set sizes. This confirms our suspicion from the pre- <ref type="bibr">7</ref> Although we are trying to mimic the situation in which we predict how an arbitrary user would vote on an arbitrary question, we caution that the vote data we train and evaluate on was not obtained from a set of arbitrary SodaHead users. It consists only of votes from users who chose which questions they wanted to answer. For this reason, the data we train and evaluate on for any question might not be a representative sample of SodaHead users as a whole. vious section that demographic features by them- selves serve only to confuse the learner, though we will see in a moment that they are a helpful sup- plement to more sophisticated systems.</p><p>We can evaluate QuestionPair constraints in this setting by comparing the results from B 1 to B 1 + QP air. B 1 +QP air consistently outperforms B 1 at all four training set sizes, significantly so at the 75% and 100% levels, and thus QuestionPair con- straints are also a useful addition to our system. VoterPair constraints can be evaluated in this setting by comparing B 1 to B 1 + V P air. B 1 + V P air significantly outperforms B 1 at all four training set sizes, and from the graph it appears to be our most beneficial improvement.</p><p>To evaluate whether demographic features are useful in the presence of the other improve- ments, we compare the full system, B 1 + Dem + QP air + V P air, to its corresponding version without demographic features, B 1 + QP air + V P air. Though B 1 + QP air + V P air signif- icantly outperforms the full system at the 25% training set size, the full system significantly out- performs B 1 + QP air + V P air at the 75% and 100% levels, indicating that in this setting, demo- graphic features are useful in the presence of a large training set.</p><p>We can evaluate the utility of QuestionPair con- straints in this setting by comparing the full system to B 1 + Dem + V P air. When we remove Ques- tionPair constraints, accuracy is consistently low- ered at all four training set sizes, significantly so at 50%, 75%, and 100%. This tells us that Ques- tionPair constraints are useful in this setting.</p><p>We can evaluate how useful VoterPair con- straints are by checking how much B 1 + Dem + V P air+QP air's performance drops when we re- move VoterPair constraints from it, yielding B 1 + Dem + QP air. Performance drops considerably and significantly at all four training set sizes after removing VoterPair constraints, suggesting that in this setting, VoterPair constraints are still the most important of our proposed improvements.</p><p>Finally, while we have already established that all our proposed improvements can improve per- formance under both settings (comments visible and comments invisible), it may be worthwhile to compare the two sets of experiments to deter- mine whether the comment features used in sys- tems with B 2 are useful.</p><p>A casual inspection of the two figures shows that, broadly, each system that uses comment- based features in <ref type="figure" target="#fig_0">Figure 2a</ref> tends to slightly out- perform the most comparable system in <ref type="figure" target="#fig_0">Figure 2b</ref>. At the low end of the curves, the two systems often differ by about 1.0% in absolute accuracy, though at the high end, the difference tends to be much smaller, with the full system with comment fea- tures outperforming the full system without com- ment features by only 0.3%. Since in this setting it is reasonable to assume a large training set, this last result is the one we are most interested in, and it suggests that our full system's performance does not suffer much due to the absence of comment features. One final observation we can make is that, when comments are not visible, demographic features appear to actively harm the performance of sys- tems trained on a small amount of data, though at larger training set sizes they are mostly help- ful. We can tell this by comparing systems with demographic features to systems without them in <ref type="figure" target="#fig_0">Figure 2b</ref> (e.g., by comparing B 1 +Dem+QP air to B 1 + QP air or B 1 + Dem + V P air to B 1 + V P air) at the 25% training set size. This is not the case in the setting where comments are visi- ble, as we see that demographic features always appear helpful in <ref type="figure" target="#fig_0">Figure 2a</ref>. This reinforces the notion that demographic features provide useful information in general, but that they are by them- selves too sparsely available to do more than con- fuse the learner. They need to be supplemented by other information sources in order for the learner to draw correct conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We examined the task of vote prediction on com- ments from the SodaHead website. To address this task, we exploited not only information extracted from the comments but also extra-textual informa- tion, including demographic information and two types of inter-comment constraints, QuestionPair constraints and VoterPair constraints. Our exper- iments involving 997,379 comments showed that each of these extensions significantly improved a baseline that exploited only textual information, with VoterPair constraints being the most effective and demographic information being the least ef- fective. When used in combination, they obtained up to a 3.88% improvement in absolute accuracy over the baseline. To stimulate research on this task, we make our dataset publicly available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Five-fold cross-validation vote prediction learning curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Sample questions and comments. All of the pre-defined answers for these questions are repre-
sented by one comment. 

User ID 
3479864 
3189372 
Age 
25-34 
Smoker 
No 
Drinker 
No 
Income 
Sexual Orientation 
Straight 
Relationship Status 
Single 
Political Views 
Conservative Moderate 
Ethnicity 
Looking For 
Career Industry 
Children 
Undecided 
Education 
High School 
Gender 
Female 
Male 
Religious Views 
Other 
Christian 
Employment Status 
Weight Type 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Sample user profiles.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://www.createdebate.com/</note>

			<note place="foot" n="2"> http://www.sodahead.com</note>

			<note place="foot" n="5"> At the low and high end of the learning curve respectively.</note>

			<note place="foot" n="6"> All significance tests are paired t-tests, with p &lt; 0.05. Because we calculate a large number of significance results, the p values we report are obtained using Holm-Bonferroni multiple testing correction (Holm, 1979).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the three anonymous reviewers for their detailed and insightful comments on an earlier draft of this paper. This work was supported in part by NSF Grants IIS-1147644 and IIS-1219142. Any opinions, findings, conclusions or recommen-dations expressed in this paper are those of the au-thors and do not necessarily reflect the views or of-ficial policies, either expressed or implied, of NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting the future with social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitaram</forename><surname>Asur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology</title>
		<meeting>the 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="492" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The power of negative thinking: Exploiting label disagreement in the min-cut classification framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2008: Companion Volume: Posters</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="15" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Collective classification of congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Burfoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gender discrimination on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Zarrella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1301" to="1309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Discourse markers in spontaneous speech: Oh what a difference an oh makes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">E</forename><surname>Fox Tree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><forename type="middle">C</forename><surname>Schrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="280" to="295" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Basic meanings of you know and i mean</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">E</forename><surname>Fox Tree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><forename type="middle">C</forename><surname>Schrock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Pragmatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="427" to="447" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Limits of electoral predictions using twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gayo-Avello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Takis Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eni</forename><surname>Mustafaraj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Fifth International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="490" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The effect of substituting discourse markers on their role in dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Groen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Noyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frans</forename><surname>Verstraten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Discourse Processes: A Multidisciplinary Journal</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="388" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stance classification of ideological debates: Data, models, features, and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saidul</forename><surname>Kazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A simple sequentially rejective multiple test procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sture</forename><surname>Holm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of opposing opinion networks from forum discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 21st ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1642" to="1646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tracking sentiment in mail: How genders differ on emotional axes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</title>
		<meeting>the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="70" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">From tweets to polls: Linking text sentiment to public opinion time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramnath</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><forename type="middle">R</forename><surname>Balasubramanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Fourth International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Detecting latent user properties in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delip</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS workshop on Machine Learning for Social Networks</title>
		<meeting>the NIPS workshop on Machine Learning for Social Networks</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Recognizing stances in ideological on-line debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapna</forename><surname>Somasundaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
		<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="116" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Get out the vote: Determining support or opposition from Congressional floor-debate transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="327" to="335" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting elections with twitter: What 140 characters reveal about political sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andranik</forename><surname>Tumasjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timm</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Sandner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabell</forename><forename type="middle">Welpe</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Fourth International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stance classification using dialogic properties of persuasion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="592" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">That is your evidence?: Classifying stance in online political debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><forename type="middle">E</forename><surname>Fox Tree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Martell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="719" to="729" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Harvesting facts from textual web sources by constrained label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 20th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="837" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Coupling label propagation and constraints for temporal fact extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Dylla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 Conference Short Papers</title>
		<meeting>the ACL 2012 Conference Short Papers</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="233" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A comparative study on feature selection in text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Machine Learning</title>
		<meeting>the 14th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="412" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno>CMU-CALD-02-107</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>CMU CALD</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
