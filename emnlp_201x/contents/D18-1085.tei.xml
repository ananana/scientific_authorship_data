<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Graph-theoretic Summary Evaluation for ROUGE</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaheh</forename><surname>Shafieibavani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>Data61 CSIRO</postCode>
									<settlement>Sydney, Sydney</settlement>
									<country>Australia, Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Ebrahimi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>Data61 CSIRO</postCode>
									<settlement>Sydney, Sydney</settlement>
									<country>Australia, Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Wong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>Data61 CSIRO</postCode>
									<settlement>Sydney, Sydney</settlement>
									<country>Australia, Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>Data61 CSIRO</postCode>
									<settlement>Sydney, Sydney</settlement>
									<country>Australia, Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Graph-theoretic Summary Evaluation for ROUGE</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="762" to="767"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>ROUGE is one of the first and most widely used evaluation metrics for text summariza-tion. However, its assessment merely relies on surface similarities between peer and model summaries. Consequently, ROUGE is unable to fairly evaluate summaries including lexical variations and paraphrasing. We propose a graph-based approach adopted into ROUGE to evaluate summaries based on both lexical and semantic similarities. Experiment results over TAC AESOP datasets show that exploiting the lexico-semantic similarity of the words used in summaries would significantly help ROUGE correlate better with human judgments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Quantifying the quality of summaries is an im- portant and necessary task in the field of auto- matic text summarization. Among the metrics proposed for this task <ref type="bibr" target="#b6">(Hovy et al., 2006;</ref><ref type="bibr" target="#b23">Tratz and Hovy, 2008;</ref><ref type="bibr" target="#b3">Giannakopoulos et al., 2008</ref>), ROUGE <ref type="bibr" target="#b7">(Lin, 2004</ref>) is the first and still most widely used one <ref type="bibr" target="#b4">(Graham et al., 2015)</ref>. This met- ric measures the concordance of system-generated (peer) summaries and human-generated reference (model) summaries by determining n-grams, word sequences, and word pair matches. ROUGE as- sumes that a peer summary is of high quality if it shares many words or phrases with a model summary. However, different terminology may be used to refer to the same concepts and hence rely- ing only on lexical overlaps may underrate content quality scores. For clarity, consider the following two sentences:</p><p>(i) They strolled around the city.</p><p>(ii) They took a walk to explore the town.</p><p>These sentences are semantically similar, but lex- ically different. If one of them is included in a model summary, while a peer summary contains another one, ROUGE or other surface based eval- uation metrics cannot capture their similarity due to the minimal lexical overlap. We aim to help ROUGE with identifying the semantic similarities of linguistic items, and consequently tackling the main problem of its bias towards lexical similari- ties.</p><p>Considering senses instead of words, we use the Personalized PageRank (PPR) algorithm <ref type="bibr" target="#b5">(Haveliwala, 2002</ref>) to leverage repetitive random walks on WordNet 3.0 <ref type="bibr" target="#b1">(Fellbaum, 1998</ref>) as a semantic network. We disambiguate each word into its in- tended sense, and obtain the probability distribu- tion of each sense over all senses in the network. Weights in this distribution denote the relevance of the corresponding senses. At each iteration, we measure the semantic similarity by looking at the path taken by the random walker, and weighting the overlaps between a pair of ranked PPR vec- tors. Our graph-based approach (ROUGE-G) com- putes semantic similarity scores between n-grams, along with their match counts, to perform both se- mantic and lexical comparisons of peer and model summaries. The experiment results indicate that ROUGE-G variants significantly outperform their corresponding variants of ROUGE. Beyond en- hancing the evaluation prowess of ROUGE, due to its lexico-semantic analysis of summaries, we be- lieve that ROUGE-G has the potential to expand the applicability of ROUGE to abstractive summariza- tion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In the summarization literature, a couple of ROUGE variants (i.e., ROUGE-1, ROUGE-2, ROUGE-SU4) are reported to have a strong corre- lation with human assessments, and are frequently used to evaluate summaries ( <ref type="bibr" target="#b8">Lin and Och, 2004;</ref><ref type="bibr" target="#b14">Owczarzak and Dang, 2011;</ref><ref type="bibr" target="#b12">Over and Yen, 2004)</ref>. Although ROUGE is a popular evaluation met- ric, improving the current evaluation metrics is still an open research area. Many of these ef- forts are analyzed and gathered in the surveys pro- vided by <ref type="bibr" target="#b22">Steinberger and Ježek (2012)</ref>. Herein, we try to briefly review the most significant ones. <ref type="bibr">Since DUC 2005</ref><ref type="bibr">, the Pyramid metric (Passonneau et al., 2005</ref>) was introduced as one of the principal metrics for evaluating summaries in the TAC conference. However, this metric is semi- automated and requires manual identification of summary content units (SCUs). Soon after, <ref type="bibr" target="#b6">Hovy et al. (2006)</ref> proposed a metric based on com- parison of basic syntactic units (Basic Elements) between peer and model summaries. This met- ric, BE-HM, was specified as one of the base- lines in the TAC AESOP task. Among systems participated in this task from 2009 to 2011, Auto- SummENG (DEMOKRITOSGR) ( <ref type="bibr" target="#b3">Giannakopoulos et al., 2008</ref>) is one of the top systems which com- pares the graph representations of peer and model summaries. Recently, some evaluation metrics have studied the effectiveness of word semantic similarity to evaluate summaries including termi- nology variations and paraphrasing ( <ref type="bibr" target="#b0">Baroni et al., 2014;</ref><ref type="bibr" target="#b20">ShafieiBavani et al., 2017</ref><ref type="bibr" target="#b21">ShafieiBavani et al., , 2018</ref>. For in- stance, an automated variant of the Pyramid metric has used distributional semantics to map text con- tent within peer summaries to SCUs ( <ref type="bibr" target="#b15">Passonneau et al., 2013)</ref>. A more recent metric, ROUGE-WE, <ref type="bibr" target="#b11">(Ng and Abrecht, 2015</ref>) has also enhanced ROUGE by incorporating the use of a variant of word em- beddings, called word2vec ( <ref type="bibr" target="#b9">Mikolov et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Graph-Theoretic Summary Evaluation</head><p>Given a pair of peer and model summaries, we compute PPR vectors at the following levels: (i) sense level, to disambiguate each word (having a set of senses); and (ii) n-gram level, to measure the semantic similarity. We compare the PPR vectors of each pair of n-grams using the following mea- sures: (i) Path-based: considering the path that the random walker takes at each iteration to get to a particular node; (ii) Rank and Weight: weighting the overlaps between a pair of ranked PPR vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Vector Representation</head><p>The WordNet graph has edges of various types, with the main types being hypernymy and meronymy to connect nodes containing senses. However, we do not use these types, and consider an edge as an undirected semantic or lexical re- lation between two synsets. We have utilized the WordNet graph enriched by connecting a sense - irrespective of its part-of-speech (POS) -with all the other senses that appear in its disambiguated gloss <ref type="bibr" target="#b18">(Pilehvar and Navigli, 2015)</ref>. Dimension of the vector representation is the number of con- nected nodes in the graph. For better clarity, we consider the adjacency matrix A for our seman- tic graph, and perform iterative random walks be- ginning at a set of senses S on WordNet with the probability mass of p (0) (S), which is uniformly distributed across the senses s i ∈ S, and the mass for all s i / ∈ S set to zero. This provides a fre- quency or multinomial distribution over all senses in WordNet, with a higher probability assigned to senses that are frequently visited. The PPR vector of S is given by:</p><formula xml:id="formula_0">p (k) (S) = dAp (k−1) (S) + (1 − d)p (0) (S)<label>(1)</label></formula><p>At each iteration, the random walker may fol- low one of the edges with probability d or jump back to any node s i ∈ S with probability (1 − d)/|S|. Following the standard convention, the value of damping factor d is set to 0.85. The num- ber of iterations k is also set to 20, which is suffi- cient for the distribution to converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparing Vectors</head><p>Conventional measures for comparing PPR vec- tors calculate the probability that a random walker meets a particular node after a specific number of iterations, which is potentially problematic <ref type="bibr" target="#b19">(Rothe and Schütze, 2014</ref>). For example, consider the fol- lowing connected nodes:</p><formula xml:id="formula_1">law suit tailor dress</formula><p>The PPR vectors of suit and dress have some weight on tailor, which is desirable. However, the PPR vector of law will also have a non-zero weight for tailor. Consequently, law and dress are spuriously similar because of the node tailor.</p><p>To prevent this type of false similarity, the ran- dom walker needs to take into account the walking path to reach a particular node <ref type="bibr" target="#b19">(Rothe and Schütze, 2014</ref>). We formalize this by defining the semantic similarity of two sets of nodes I and J as:</p><formula xml:id="formula_2">Simsem(I, J) = k x=0 c x × RW (p (x) (I), p (x) (J)) (2)</formula><p>where damping factor c was optimized on the TAC 2010 <ref type="bibr" target="#b13">(Owczarzak and Dang, 2010</ref>) AESOP dataset, and set to 0.7 to ensure that early meetings are more valuable than later meetings. At each iteration x, we compare PPR vectors by ranking their dimensions (senses) based on their values, and weighting the overlaps between them (Equa- tion 3). Hence, we weight the similarity such that differences in the highest ranks (most important senses in a vector) are penalized more than differ- ences in lower ranks. This measure has proven to be superior to cosine similarity, Jensen-Shannon divergence, and Rank-Biased Overlap for compar- ing vectors ( <ref type="bibr" target="#b17">Pilehvar et al., 2013)</ref>.</p><formula xml:id="formula_3">RW (Y, Z) =    h∈H (r h (Y )+r h (Z)) −1 |H| i=1 (2i) −1 , if |H| &gt; 0 0, otherwise (3)</formula><p>where H is the intersection of all senses with non- zero probability in both vectors Y and Z. r h (Y ) denotes the rank of sense h in vector Y , where rank 1 is the highest rank. The denominator is used as a normalization factor that guarantees a maximum value of one. The minimum value is zero and oc- curs when there is no overlap, i.e., |H| = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Calculating ROUGE-G</head><p>We combine lexical and semantic similarities to compute ROUGE-G-N:</p><formula xml:id="formula_4">ROUGE-G-N = M ∈{M odelSums} n-gramm∈M, n-gramp∈P eerSum SimLS(n-gramm, n-gramp) M ∈{M odelSums} n-gramm∈M Count(n-gramm)<label>(4)</label></formula><p>where Sim LS is the score of lexico-semantic sim- ilarity between a pair of n-grams in model sum- mary (n-gram m ) and peer summary (n-gram p ):</p><p>SimLS(n-gramm, n-gramp) = β × Count match (n-gramm, n-gramp)</p><formula xml:id="formula_5">+ (1 − β) × Simsem(n-gramm, n-gramp)<label>(5)</label></formula><p>Scaling factor β was optimized on the TAC 2010 AESOP dataset, and set to 0.5 to reach the best correlation with the manual metrics. Count match (n-gram m , n-gram p ) is the maxi- mum number of the n-gram co-occurring in a peer summary and a set of model summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Disambiguation of n-grams</head><p>Prior to measuring semantic similarities, each word in n-grams has to be analyzed and dis- ambiguated into its intended sense. However, conventional word sense disambiguations are not applicable due to the lack of contextual information.</p><p>Hence, we seek the semantic alignment that maximizes the similarity of the senses of the compared words. As an example ( <ref type="bibr" target="#b17">Pilehvar et al., 2013</ref>), consider two sentences of "a1. Officers fired." and "a2. Several policemen terminated in corruption probe.", the semantic alignment procedure has been performed as "P a1 . officer 3 n , f ire 4 v ", and "P a2 . policeman 1 n , terminate 4 v , corruption 6 n , probe 1 n ". t i p denotes the i-th sense of a word t in WordNet with POS p. After alignment, among all possible pairings of all senses of f ire v to all senses of all words in a2, the sense f ire 4 v (employment termination) obtains the maximal similarity value of Sim sem (f ire 4 v , terminate 4 v ) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">OOV Handling</head><p>Out-of-vocabulary (OOV) words are the words that are not defined in the corresponding lexical resource, hence, they will be ignored while gener- ating PPR vectors. The reason is that they do not have an associated node in the WordNet graph for the random walk to be initialized from. To take them into consideration, we add an extra dimen- sion for each OOV term in the resulting PPR vec- tor. Following <ref type="bibr" target="#b18">Pilehvar and Navigli (2015)</ref>, we set the associated weights of the new dimensions to 0.5 so as to guarantee their placement among the top dimensions in their vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data and Metrics</head><p>The only available datasets for the task of Sum- marization Evaluation are three AESOP datasets 1 provided by <ref type="bibr">TAC 2009</ref><ref type="bibr" target="#b13">TAC , 2010</ref><ref type="bibr">TAC , and 2011</ref>. Among them, we optimize scaling factors using the TAC 2010 AESOP dataset, and evaluate ROUGE-G on the TAC 2011 (Owczarzak and Dang, 2011) AE- SOP dataset for two main reasons: (i) it is the only dataset on which evaluation metrics can be as- sessed for their ability to measure summary Read- ability; (ii) To be in line with the most recent work (ROUGE-WE) that has also been evaluated only on this dataset for measuring the Readability scores. This dataset consists of 44 topics, and a set of 10 documents for each topic. There are four human-crafted model summaries for each docu- ment set. A summary for each topic is generated by each of the 51 summarizers which participated in the main TAC summarization task. The out- put of participating automatic metrics is tasked to be compared against human judgments using three manual metrics of Pyramid, Readability, and Re- sponsiveness. Hence, the outputs are scored based on their summary content, linguistic quality, and a combination of both, respectively.</p><p>Prior to computing correlation of ROUGE-G variants with manual metrics, ROUGE-G scores have reliably been computed (95% confidence in- tervals) under ROUGE bootstrap resampling with the default number of sampling point (1000). Cor- relation of ROUGE-G evaluation scores with the human judgments is then assessed with three met- rics of correlation: Pearson r; Spearman ρ; and Kendall τ . We compute scores using the default NIST settings for baselines in the TAC 2011 AE- SOP task (with stemming and keeping stopwords).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>We evaluate ROUGE-G, against the top met- rics (C S IIITH3, DemokritosGR1, Catolicasc1) among the 23 metrics participated in TAC AESOP 2011, ROUGE, and the most recent related work (ROUGE-WE) ( <ref type="table">Table 1)</ref>. Overall results support our proposal to consider semantics besides sur- face with ROUGE. Since the large/small differ- ences in competing correlations with human as- sessment are not an acceptable proof of superior- ity/inferiority in performance of one metric over another, significance tests should be applied. To better clarify the effectiveness of ROUGE-G, we have used pairwise Williams significance test rec- ommended by <ref type="bibr" target="#b4">Graham et al. (2015)</ref> for summa- rization evaluation. Accordingly, evaluation of a given summarization metric, M new , takes the form of quantifying three correlations: r(M new , H), that exists between the evaluation metric scores for summarization systems and corresponding hu- man assessment scores; r(M base , H), that stands for the correlation of baseline metrics with human judges; and the third correlation, between evalu- ation metric scores themselves, r(M base , M new ). It can happen for a pair of competing metrics for which the correlation between metric scores is strong, that a small difference in competing correlations with human assessment is significant, while, for a different pair of metrics with a larger difference in correlation, the difference is not sig- nificant ( <ref type="bibr" target="#b4">Graham et al., 2015)</ref>. Using this sig- nificance test, the results show that all increases in correlations of ROUGE-G compared to ROUGE and ROUGE-WE variants are statistically signifi- cant (p &lt; 0.05). We analyze the correlation results reported in <ref type="table">Table 1</ref> in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROUGE-G-2 achieves the best correlation with</head><p>Pyramid, regarding all correlation metrics. More- over, every ROUGE-G variant outperforms its cor- responding ROUGE and ROUGE-WE variants, re- gardless of the correlation metric used. However, the only exception is ROUGE-SU4, which corre- lates slightly better with Pyramid when measuring with Pearson correlation. One possible reason is that Pyramid measures content similarity between peer and model summaries, while the variants of ROUGE-G favor semantics behind the content for measuring similarities. Since some of the seman- tics attached to the skipped words are lost in the construction of skip-bigrams, ROUGE-SU4 shows a better correlation comparing to ROUGE-G-SU4.</p><p>For Responsiveness, ROUGE-G-SU4 achieves the best correlation when measuring with Pear- son. We also observe that ROUGE-G-2 obtains the best correlation with Responsiveness while mea- suring with the Spearman and Kendall rank cor- relations. The reason is that semantic interpreta- tion of bigrams is easier, and that of contiguous bigrams is much more precise. We also see that every variant of ROUGE-G outperforms its corre- sponding ROUGE and ROUGE-WE variants.</p><p>The readability score is based on grammatical- ity, structure, and coherence. Although our main goal is not to improve the readability, ROUGE- G-SU4 and ROUGE-G-2 are observed to correlate very well with this metric when measured with the Pearson and Spearman/Kendall rank correlations, respectively. Besides, every variant of ROUGE- G represents the best correlation results compar- ing to its corresponding variants of ROUGE and ROUGE-WE for all correlation metrics. This is likely due to considering word types and POS tag- ging while aligning and disambiguating n-grams. POS features are shown by <ref type="bibr" target="#b2">Feng et al. (2010)</ref> to be helpful in predicting linguistic quality.</p><p>We optimize scaling factor β (Equation 5) on the TAC 2010 AESOP dataset. <ref type="figure" target="#fig_0">Figure 1</ref> shows metrics measured by Pearson. The best results are observed when β = 0.5. Performance deterio- rates when β approaches 1.0 which indicates the ROUGE scores without any touch of semantic sim- ilarity. Decreasing β to zero causes the exclusion of lexical match counts, and consequently inap- propriateness of the outcomes. This shows the im- portance of using both lexical and semantic simi- larities to fairly judge the quality of summaries. It is noteworthy that we have evaluated our ap- proach with the following settings for computing and comparing PPR vectors: (i) Path-based with Rank and Weight measure (current setting); (ii) Path-based with cosine similarity; (iii) Excluding path-based measure and using Rank and Weight measure solely. The results showed that the cur- rent setting performs better than the other two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper presents ROUGE-G to overcome the limitation of high lexical dependency in ROUGE.</p><p>Our approach leverages a sense-based represen- tation to calculate PPR vectors for n-grams. The semantic similarity of n-grams are then computed using a formalization of Path-based and Rank and Weight measures. We finally improve on ROUGE by performing both semantic and lexi- cal analysis of summaries. Experiments over the TAC AESOP datasets demonstrate that ROUGE- G achieves higher correlations with manual judg- ments in comparison with ROUGE.</p><p>In order to demonstrate the effectiveness of ROUGE-G to fairly evaluate abstractive sum- maries, we need to conduct experiments on a dataset composed of abstractive summaries. How- ever, we evaluated our approach on the TAC 2011 AESOP dataset, which is made of summaries that were generated mostly by extractive systems. Since there is not such dataset at the time of writ- ing this paper, we can continue building on this work by using model summaries, which are ab- stractive in nature, as a proxy. Thereupon, it is possible to incorporate jackknifing procedure in the scoring process in order to see whether our metric can differentiate between peer summaries (naturally extractive) vs. model summaries (natu- rally abstractive).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Exploring scaling factor β</figDesc></figure>

			<note place="foot" n="1"> https://tac.nist.gov/data/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the anonymous reviewers for their in-sightful comments and valuable suggestions. The first author was supported by the "Australian Gov-ernment Research Training Program Scholarship".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Don&apos;t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparison of features for automatic readability assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jansche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Huenerfauth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noémie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics: Posters (COLING 2010)</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters (COLING 2010)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Summarization system evaluation revisited: N-gram graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Giannakopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vangelis</forename><surname>Karkaletsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Vouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Stamatopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Speech and Language Processing (TSLP)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Re-evaluating automatic summarization with bleu and 192 shades of rouge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="128" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Topic-sensitive pagerank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Haveliwala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on World Wide Web</title>
		<meeting>the 11th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated summarization evaluation with basic elements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Fukumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Conference on Language Resources and Evaluation (LREC 2006)</title>
		<meeting>the 5th Conference on Language Resources and Evaluation (LREC 2006)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="604" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Looking for a few good metrics: Rouge and its evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th NII Testbeds and Community for Information Access Research: Workshops (NTCIR</title>
		<meeting>the 4th NII Testbeds and Community for Information Access Research: Workshops (NTCIR</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013</title>
		<meeting>the 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics-Human Language Technologies (NAACL HLT 2013)</title>
		<imprint>
			<publisher>ACL</publisher>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Better summarization evaluation with word embeddings for rouge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ping</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoria</forename><surname>Abrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1925" to="1930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An introduction to duc 2004 intrinsic evaluation of generic new text summarization systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Over</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology (NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overview of the tac 2010 summarization track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Text Analysis Conference</title>
		<meeting>the 3rd Text Analysis Conference</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of the tac 2011 summarization track: Guided task and aesop task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Text Analysis Conference</title>
		<meeting>the 4th Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automated pyramid scoring of summaries using distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dolores</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: Short Papers (ACL 2013). ACL</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: Short Papers (ACL 2013). ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Applying the pyramid method in duc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sigelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Document Understanding Conference</title>
		<meeting>the 2005 Document Understanding Conference</meeting>
		<imprint>
			<publisher>DUC</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Align, disambiguate and walk: A unified approach for measuring semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1341" to="1351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From senses to texts: An all-in-one graph-based approach for measuring semantic similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilehvar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">228</biblScope>
			<biblScope unit="page" from="95" to="128" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cosimrank: A flexible &amp; efficient graph-theoretic similarity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1392" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A semantically motivated approach to compute ROUGE scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaheh</forename><surname>Shafieibavani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.07441</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Summarization evaluation in the absence of human model summaries using the compositionality of word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elaheh</forename><surname>Shafieibavani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics (COLING 2018)</title>
		<meeting>the 27th International Conference on Computational Linguistics (COLING 2018)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="905" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluation measures for text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ježek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing and Informatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="275" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bewte: basic elements with transformations for evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Tratz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Text Analysis Conference</title>
		<meeting>the 1st Text Analysis Conference</meeting>
		<imprint>
			<publisher>TAC</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
