<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Broad-coverage CCG Semantic Parsing with AMR</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit1">Cornell Tech Cornell University New York</orgName>
								<orgName type="institution" key="instit2">University of Washington Seattle</orgName>
								<address>
									<postCode>10011, 98195</postCode>
									<region>NY, WA</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
							<email>{kentonl, lsz}@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit1">Cornell Tech Cornell University New York</orgName>
								<orgName type="institution" key="instit2">University of Washington Seattle</orgName>
								<address>
									<postCode>10011, 98195</postCode>
									<region>NY, WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit1">Cornell Tech Cornell University New York</orgName>
								<orgName type="institution" key="instit2">University of Washington Seattle</orgName>
								<address>
									<postCode>10011, 98195</postCode>
									<region>NY, WA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Broad-coverage CCG Semantic Parsing with AMR</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a grammar induction technique for AMR semantic parsing. While previous grammar induction techniques were designed to re-learn a new parser for each target application, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperform-ing the previous state of the art.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsers map sentences to formal repre- sentations of their meaning <ref type="bibr" target="#b45">(Zelle and Mooney, 1996;</ref><ref type="bibr" target="#b46">Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b29">Liang et al., 2011)</ref>. Existing learning algorithms have primar- ily focused on building actionable meaning repre- sentations which can, for example, directly query a database ( <ref type="bibr" target="#b29">Liang et al., 2011;</ref><ref type="bibr" target="#b22">Kwiatkowski et al., 2013)</ref> or instruct a robotic agent <ref type="bibr" target="#b8">(Chen, 2012;</ref><ref type="bibr" target="#b3">Artzi and Zettlemoyer, 2013b</ref>). However, due to their end-to-end nature, such models must be re- learned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives.</p><p>Recently, AMR ( <ref type="bibr" target="#b4">Banarescu et al., 2013</ref>) was proposed as a general-purpose meaning represen- tation language for broad-coverage text, and work is ongoing to study its use for variety of appli- cations such as machine translation <ref type="bibr" target="#b19">(Jones et al., 2012</ref>) and summarization ( <ref type="bibr" target="#b30">Liu et al., 2015</ref>). The * Work done at the University of Washington.</p><p>AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing. However, it also presents sig- nificant challenges for existing algorithms, in- cluding much longer sentences, more complex syntactic phenomena and increased use of non- compositional semantics, such as within-sentence coreference. In this paper, we introduce a new, scalable Combinatory Categorial <ref type="bibr">Grammar (CCG;</ref><ref type="bibr" target="#b40">Steedman, 1996</ref><ref type="bibr" target="#b41">Steedman, , 2000</ref>) induction approach that solves these challenges with a learned joint model of both compositional and non-compositional se- mantics, and achieves state-of-the-art performance on AMR Bank parsing.</p><p>We map sentences to AMR structures in a two- stage process (Section 5). First, we use CCG to construct lambda-calculus representations of the compositional aspects of AMR. CCG is designed to capture a wide range of linguistic phenomena, such as coordination and long-distance dependen- cies, and has been used extensively for semantic parsing. To use CCG for AMR parsing we define a simple encoding for AMRs in lambda calculus, for example, as seen with the logical form z and AMR a in <ref type="figure">Figure 1</ref> for the sentence Pyongyang officials denied their involvement. However, using CCG to construct such logical forms requires a new mech- anism for non-compositional reasoning, for exam- ple to model the long-range anaphoric dependency introduced by their in <ref type="figure">Figure 1</ref>.</p><p>To represent such dependencies while main- taining a relatively compact grammar, we fol- low Steedman's (2011) use of generalized Skolem terms, a mechanism to allow global references in lambda calculus. We then allow the CCG deriva- tion to mark when non-compositional reasoning is required with underspecified placeholders. For ex- ample, <ref type="figure">Figure 1</ref> shows an underspecified logical form u that would be constructed by the grammar with the bolded placeholder ID indicating an un-resolved anaphoric reference. These placeholders are resolved by a factor graph model that is defined over the output logical form and models which part of it they refer to, for example to find the ref- erent for a pronoun. Although primarily motivated by non-compositional reasoning, we also use this mechanism to underspecify certain relations dur- ing parsing, allowing for more effective search.</p><p>Following most work in semantic parsing, we consider two learning challenges: grammar in- duction, which assigns meaning representations to words and phrases, and parameter estimation, where we learn a model for combining these pieces to analyze full sentences. We introduce a new CCG grammar induction algorithm which in- corporates ideas from previous algorithms <ref type="bibr" target="#b46">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b24">Kwiatkowski et al., 2010</ref>) in a way that scales to the longer sentences and more varied syntactic constructions observed in newswire text. During lexical generation (Sec- tion 6.1), the algorithm first attempts to use a set of templates to hypothesize new lexical entries. It then attempts to combine bottom-up parsing with top-down recursive splitting to select the best en- tries and learn new templates for complex syntac- tic and semantic phenomena, which are re-used in later sentences to hypothesize new entries.</p><p>Finally, while previous algorithms (e.g., <ref type="bibr" target="#b46">Zettlemoyer and Collins, 2005</ref>) have assumed the ex- istence of a grammar that can parse nearly every sentence to update its parameters, this does not hold for AMR Bank. Due to sentence complex- ity and search errors, our model cannot produce fully correct logical forms for a significant portion of the training data. To learn from as much of the data as possible and accelerate learning, we adopt an early update strategy to generate effective up- dates from partially correct analyses (Section 6.2).</p><p>We evaluate performance on the publicly avail- able AMR Bank ( <ref type="bibr" target="#b4">Banarescu et al., 2013)</ref> and demonstrate that our modeling and learning con- tributions are crucial for grammar induction at this scale and achieve new state-of-the-art results for AMR parsing <ref type="bibr">(Section 8</ref>). In addition, we also present, for the first time, results without surface- form alignment heuristics, which demonstrates the need for future work, especially to generalize to other languages. The source code and learned models are available online. 1</p><p>x: Pyongyang officials denied their involvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a: (d/deny-01</head><p>:ARG0 (p/person :ARG0-of (h/have-org-role-91 :ARG1 (c/city : name (n/name :op1"Pyongyang")) :ARG2(o/official))) :ARG1 (i/involve-01 :ARG1 p))</p><formula xml:id="formula_0">u: A1(λd.deny-01(d) ∧ ARG0(d, A2(λp.person(p) ∧ REL-of REL-of REL-of(p, A3(λh.have-org-role-91(h) ∧ ARG1(h, A4(λc.city(c) ∧ name(c, A5(λn.name(n) ∧ op1(n, PYONGYANG))))) ∧ REL REL REL(h, A6(λo.official(o)))))) ∧ ARG1(d, A7(λi.involve-01(i) ∧ ARG1(i, R(ID ID ID)))))) z: A1(λd.deny-01(d) ∧ ARG0(d, A2(λp.person(p) ∧ ARG0-of(p, A3(λh.have-org-role-91(h) ∧ ARG1(h, A4(λc.city(c) ∧ name(c, A5(λn.name(n) ∧ op1(n, PYONGYANG))))) ∧ ARG2(h, A6(λo.official(o)))))) ∧ ARG1(d, A7(λi.involve-01(i) ∧ ARG1(i, R(2))))))</formula><p>Figure 1: A sentence (x) paired with its AMR (a), un- derspecified logical form (u), which contains under- specified constants in bold that are mapped to AMR re- lations to generate the fully specified logical form (z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Technical Overview</head><p>Task Let X be the set of all possible sentences and A the set of all AMR structures. Given a sen- tence x ∈ X , we aim to generate an AMR a ∈ A. We define a simple, deterministic and invertible conversion process between AMRs and lambda- calculus logical forms; roughly speaking, each AMR variable gets its own lambda term, which is scoped as low as possible, and each AMR role becomes a binary predicate applied to these vari- ables. <ref type="figure">Figure 1</ref> shows an example, and the full de- tails are provided in the supplementary materials. Therefore, henceforth we discuss the task of map- ping a sentence x ∈ X to a logical form z ∈ Z, where Z is the set of all logical forms. For ex- ample, in <ref type="figure">Figure 1</ref>, we would map the sentence x to the logical form z. We evaluate system perfor- mance using SMATCH ).</p><p>Model Given a sentence x and lexicon Λ, we generate the set of possible derivations GEN(x, Λ) using a two-stage process (Section 5). First, we use a weighted CCG to map x to an under- specified logical form u (Section 5.1), a logical form with placeholder constants for unresolved el- ements. For example, in the underspecified log- ical form u in <ref type="figure">Figure 1</ref>, the constants REL-of, REL and ID are placeholders. We then resolve these placeholders by defining a factor graph to find their optimal mapping and generate the final logical form z. In the figure, REL-of is mapped to ARG0-of, REL to ARG2 and ID to 2.</p><p>Learning We assume access to a training set of N examples {(x i , z i ) : i = 1 . . . N }, each con- taining a sentence x i and a logical form z i . Our goal is to learn a CCG, which constitutes learn- ing the lexicon and estimating the parameters of both the grammar and the factor graph. We de- fine a learning procedure (Section 6) that alter- nates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from <ref type="bibr" target="#b14">Flanigan et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>The problem of learning semantic parsers has re- ceived significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms <ref type="bibr" target="#b44">(Wong and Mooney, 2007;</ref><ref type="bibr" target="#b32">Muresan, 2011)</ref>, question-answer pairs ( <ref type="bibr" target="#b11">Clarke et al., 2010;</ref><ref type="bibr" target="#b29">Liang et al., 2011;</ref><ref type="bibr" target="#b6">Cai and Yates, 2013;</ref><ref type="bibr" target="#b22">Kwiatkowski et al., 2013)</ref>, sen- tences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), con- versational logs (Artzi and Zettlemoyer, 2011), distant supervision ( <ref type="bibr">Mitchell, 2012, 2015;</ref><ref type="bibr" target="#b38">Reddy et al., 2014</ref>) and without ex- plicit semantic supervision <ref type="bibr" target="#b35">(Poon, 2013)</ref>. Although we are first to consider using CCG to build AMR representations, our work is closely re- lated to existing methods for CCG semantic pars- ing. Previous CCG induction techniques have ei- ther used hand-engineered lexical templates (e.g., <ref type="bibr" target="#b46">Zettlemoyer and Collins, 2005</ref>) or learned tem- plates from the data directly (e.g., <ref type="bibr" target="#b24">Kwiatkowski et al., 2010</ref><ref type="bibr" target="#b23">Kwiatkowski et al., , 2012</ref>. Our two-pass reasoning for lexical generation combines ideas from both meth- ods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of first- order logic representations <ref type="bibr" target="#b5">(Bos, 2008;</ref><ref type="bibr" target="#b27">Lewis and Steedman, 2013)</ref>. However, this work lacked cor- pora to evaluate the logical forms recovered.</p><p>AMR ( <ref type="bibr" target="#b4">Banarescu et al., 2013</ref>) is a general- purpose meaning representation and has been used in a number of applications ( <ref type="bibr" target="#b34">Pan et al., 2015;</ref><ref type="bibr" target="#b30">Liu et al., 2015)</ref>. There is also work on recovering </p><formula xml:id="formula_1">N [x] /N [x] N [pl] S\N P [pl] λf.λx.f (x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; N [pl] λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))) N P [pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) &gt; S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))))</formula><p>Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plu- ral noun to a noun phrase.</p><p>AMRs, including graph parsing ( <ref type="bibr" target="#b14">Flanigan et al., 2014</ref>), methods to build AMRs from dependency trees ( <ref type="bibr" target="#b43">Wang et al., 2015</ref>) and algorithms for align- ing words to AMRs ( <ref type="bibr" target="#b36">Pourdamghani et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Background</head><p>Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics <ref type="bibr" target="#b40">(Steedman, 1996</ref><ref type="bibr" target="#b41">(Steedman, , 2000</ref>). Section 7 details our instan- tiation of CCG. In CCG trees, each node is a category. <ref type="figure" target="#fig_2">Figure 2</ref> shows a simple CCG tree.</p><formula xml:id="formula_2">For example, S\N P [pl] : λx.λd.dance-01(d) ∧ ARG0(d, x)</formula><p>is a category for an intransitive verb phrase. The syntactic type S\N P <ref type="bibr">[pl]</ref> indicates that an argument of type N P <ref type="bibr">[pl]</ref> is expected and the returned syntactic type will be S. The backward slash \ indicates the argument is expected on the left, while a forward slash / indicates it is ex- pected on the right. The syntactic attribute pl spec- ifies that the argument must be plural. Attribute variables enforce agreement between syntactic at- tributes. For example, as in <ref type="figure" target="#fig_2">Figure 2</ref>, adjectives are assigned the syntax N <ref type="bibr">[x]</ref> /N <ref type="bibr">[x]</ref> , where x is used to indicate that the attribute of the argument will determine the attribute of the returned category. The simply-typed lambda calculus logical form in the category represents its semantic meaning. The typing system includes basic types (e.g., entity e, truth value t) and functional types (e.g., e, t is the type of a function from e to t). In the example category,</p><formula xml:id="formula_3">λx.λd.dance-01(d) ∧ ARG0(d, x)</formula><p>is a e, e, t-typed function expecting an ARG0 ar- gument, and the conjunction specifies the roles of the dance-01 frame. A CCG is defined by a lexicon and a set of com- binators. The lexicon pairs words and phrases with their categorial meaning. For example, dance λx.λd.dance-01(d) ∧ ARG0(d, x) pairs dance with the category above. We adopt a factored representation of the lexicon ( <ref type="bibr" target="#b25">Kwiatkowski et al., 2011)</ref>, where entries are dynamically generated by combining lexemes and templates. For example, the above lexical entry can be generated by pair- ing the lexeme dance, {dance-01}} with the tem- plate</p><formula xml:id="formula_4">λv 1 .[S\N P : λx.λa.v 1 (a) ∧ ARG0(a, x)].</formula><p>Skolem Terms and IDs Generalized Skolem terms (henceforth, Skolem terms) for CCG were introduced by Steedman (2011) to capture com- plex dependencies with relatively local quantifi- cation. We define here a simplified version of the theory to represent entities and allow distant references. Let A be a e, t, e-typed predi- cate. Given a e, t-typed logical expression C, the logical form A n (C) is a Skolem term with the Skolem ID n. For example, A 2 (λy.boy(y)) is a Skolem term that could represent the noun phrase the boy, which introduces a new entity. Skolem IDs are globally scoped, i.e., they can be referred from anywhere in the logical form without scoping constraints. To refer to Skolem terms, we define the id, e-typed predicate R. For example, the sentence the boy loves him- self may be represented with</p><formula xml:id="formula_5">A 1 (λx.love-01(x) ∧ ARG0(x, A 2 (λy.boy(y))) ∧ ARG1(x, R(2))),</formula><p>where R(2) references A 2 (λy.boy(y)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Mapping Sentences to Logical Form</head><p>Given a sentence x and lexicon Λ, the function GEN(x, Λ) defines the set of possible derivations. Each derivation d is a tuple y, MM, where y is a CCG parse tree and M is a mapping of constants from u, the underspecified logical form at the root of y, to their fully specified form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Underspecified Logical Forms</head><p>An underspecified logical form represents multi- ple logical forms via a mapping function that maps its constants to sets of constants and Skolem IDs. For example, consider the underspecified logical form u at the top of <ref type="figure" target="#fig_1">Figure 3b</ref>. If, for example, REL can be mapped to manner or ARG2, then the sub-expression REL(h, A 6 (λo.official(o))) represents manner(h, A 6 (λo.official(o))) or ARG2(h, A 6 (λo.official(o))). During learning, we assume access to fully specified logical forms, which we convert to underspecified form as needed. In practice, all binary relations, except ARG0 and ARG1, and all Skolem ID references are underspecified.</p><p>Formally, let C be the set of all constants and I(u) the set of all Skolem IDs in the logical form u. Let S u : C → 2 C∪I(u) be a specification func- tion, such that its inverse is deterministic. We call a constant c a placeholder if |S u (c)| &gt; 1. Given an underspecified logical form u, applying S u to all constants u contains, generates a set of fully specified logical forms.</p><p>We define S u to be (a) S u (ID) = I(u), the set of Skolem IDs in u, (b) S u (REL) = {part, ARG2, . . . }, all 67 active AMR relations except ARG0 and ARG1, (c) S u (REL-of) = {part-of, ARG0-of, . . . }, all 33 passive relations, and otherwise (d) S u (c) = c. For example, in u in <ref type="figure" target="#fig_1">Figure 3b</ref>, the set of assignments to the ID place- holder is I(u) = {1, 2, 3, 4, 5, 6, 7}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Derivations</head><p>The first part of a derivation d = y, MM is a CCG parse tree y with an underspecified logical form u at its root. For example, <ref type="figure" target="#fig_1">Figure 3a</ref> shows such a CCG parse tree, where the logical form contains the placeholders REL, REL-of and ID.</p><p>The second part of the derivation is a func- tion M : CONSTS(u) → C ∪ I(u), where CONSTS(u) is the set of all occurrences of con- stants in u. For example, in <ref type="figure" target="#fig_1">Figure 3b</ref>, CONSTS(u) contains, among others, three different occur- rences of ARG1 and one of ID, and M maps REL to ARG2, REL-of to ARG0-of and ID to the Skolem ID 2. The set of potential assignments for each occurrence of constant c is S u (c), and M, which returns a single element for each constant, is a disambiguation of S u . Applying M to all con- stants in u results in the final logical form z.</p><p>Decomposing the derivation provides two ad- vantages. First, we are able to defer decisions from the CCG parse to the factor graph, thereby consid- ering fewer hypotheses during parsing and sim- plifying the computation. Second, we can repre- sent distant references while avoiding the complex parse trees that would have been required to repre- sent these dependencies with scoped variables in- stead of Skolem IDs. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Model</head><p>Given a sentence x, we use a weighted log-linear CCG ( <ref type="bibr" target="#b26">Lafferty et al., 2001;</ref><ref type="bibr" target="#b10">Clark and Curran, 2007</ref>) to rank the space of possible parses under the grammar Λ. At the root of each CCG deriva- tion is the underspecified logical form u.</p><p>To represent a probability distribution over M, we build for each u a factor graph G u = V, F, E, (a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>x:</head><p>Pyongyang officials denied their involvement</p><formula xml:id="formula_6">N P [sg] N [pl] \(N [pl] /N [pl] ) S\N P/N P N P [pl] N [nb] A 1 (λc.city(c)∧ λf.λp.person(p)∧ λx.λy.λd.deny-01(d)∧ R(ID) λi.involve-01(i) name(c, A 2 (λn.name(n)∧ REL-of(p, A 3 (f (λh.have-org-role-91(h)∧ ARG0(d, y)∧ op(n, PYONGYANG)))) REL(h, A 4 (λo.official(o)))))) ARG1(d, x) &lt; &gt; &gt; &lt; A u: A 1 (λd.deny-01(d) ∧ ARG0(d, A 2 (λp.person(p) ∧ REL-of(p, A 3 (λh.have-org-role-91(h) ∧ ARG1(h, A 4 (λc.city(c) ∧ name(c, A 5 (λn.name(n) ∧ op(n, PYONGYANG))))) ∧ REL(h, A 6 (λo.official(o)))))) ∧ ARG1(d, A 7 (λi.involve-01(i) ∧ ARG1(i, R(ID))))))</formula><p>(b) Constant mapping M: Each constant in u, the logical form at the root of y, is mapped to a Skolem ID or a logical constant to create the fully specified logical form z, which can be converted to an AMR. Only mappings that modify constants are illustrated. </p><formula xml:id="formula_7">u: A1(λd.deny-01(d) ∧ ARG0(d, A2(λp.person(p) ∧ REL-of(p, A3(λh.have-org-role-91(h) ∧ ARG1(h, A4(λc.city(c) ∧ name(c, A5(λn.name(n) ∧ op(n, PYONGYANG))))) ∧ REL(h, A6(λo.official(o)))))) ∧ ARG1(d, A7(λi.involve-01(i) ∧ ARG1(i, R(ID)))))) z: A1(λd.deny-01(d) ∧ ARG0(d, A2(λp.person(p) ∧ ARG0-of(p, A3(λh.have-org-role-91(h) ∧ ARG1(h, A4(λc.city(c) ∧ name(c, A5(λn.name(n) ∧ op(n, PYONGYANG))))) ∧ ARG2(h, A6(λo.official(o)))))) ∧ ARG1(d, A7(λi.involve-01(i) ∧ ARG1(i, R(2))))))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C2</head><p>C3 1, 2, 3, 4, 5, 6, 7</p><formula xml:id="formula_8">A 1 (d.deny-01(d)^ ARG0(d, A 2 (p.person(p)^ REL-of(p, A 3 (h.have-org-role-91(h)^ ARG1(h, A 4 (c.city(c)^ name(c, A 5 (n.name(n) ^ op(n, PYONGYANG)))))^ REL(h, A 6 (o.ocial(o))))))^ ARG1(d, A 7 (i.involve-01(i)^ ARG1(i, R(ID))))))</formula><p>Figure 4: A visualization of the factor graph constructed for the derivation in <ref type="figure" target="#fig_1">Figure 3</ref>. Variables are marked with gray background. The set of possible assignments, marked with a dashed arrow, is only specified for placeholders (REL-of, REL and ID). Only a subset of the factors are included (A, B, C2 and C3). Solid lines represent edges. Factor A captures selectional preference between the types have-org-role-91 and official to determine the relation REL. Factor B does the same for person and have-org-role-91 to determine REF-of. Factors C2 and C3 account for selectional preferences when resolving ID. In C2, we consider the assignment 2, which will create a relation of type ARG1 between the types involve-01 and person. C3 similarly considers the assignment 3.</p><p>where V = CONSTS(u) is the set of variables, F is the set of factors and E is the set of edges. Each edge is of the form (v, f ) where v ∈ V and f ∈ F . <ref type="figure">Figure 4</ref> shows the factor graph used in generating the derivation in <ref type="figure" target="#fig_1">Figure 3</ref>, including all the variables and a subset of the factors. For each variable v c ∈ V such that c ∈ CONSTS(u) the set of possible assignments is determined by S u (c).</p><p>To generate the factors F and edges E we use the function Φ(V ) that maps a set of variables V ⊆ V to a factor f and a set of edges, each one of the form (v, f ), where v ∈ V . Factors ex- press various features (Section 7), such as selec- tional preferences and control structures. In the figure, Factor A captures the selectional prefer- ence for the assignment of the relation REL be- tween have-org-role-91 and official. Factor B captures a similar preference, this time to resolve REL-of. Factor C2 captures a selectional pref- erence triplet involve-01/ARG1/person that will be created if ID is resolved to the Skolem ID 2. Finally, C3 captures a similar preference for re- solving ID to 3. Since the assignment of many of the variables is fixed, i.e., they are fully specified constants, in practice our factor graph representa- tion simply conditions on them.</p><p>Derivations are scored using a log-linear model that includes both CCG parse features and those defined by the factor graph. Let D(z) be the sub- set of derivations with the final logical form z and θ ∈ R l be a l-dimensional parameter vector. We define the probability of the logical form z as</p><formula xml:id="formula_9">p(z|x; θ, Λ) = d∈D(z) p(d|x; θ, Λ) ,</formula><p>and the probability of a derivation d is defined as</p><formula xml:id="formula_10">p(d|x; θ, Λ) = e θ·φ(x,d) d ∈GEN(x,Λ) e θ·φ(x,d ) ,<label>(1)</label></formula><p>where φ(x, d) ∈ R l is a feature vector (Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Inference</head><p>To compute the set of derivations GEN(x, Λ) we define a two-stage process. We first run the CCG parser to generate underspecified logical forms. Following previous work <ref type="bibr" target="#b46">(Zettlemoyer and Collins, 2005</ref>), we use CKY parsing to enumer- ate the top-K underspecified logical forms. 3 Dur- ing the CKY chart construction, we ignore Skolem IDs when comparing categories. This allows us to properly combine partial derivations and to fully benefit from the dynamic programming. We dy- namically generate lexical entries for numbers and dates using regular expression patterns and for named-entities using a recognizer. For every un- derspecified logical form u, we construct a factor graph and use beam search to find the top-L con- figurations of the graph. <ref type="bibr">4</ref> During learning, we use the function GENMAX(x, z, θ, Λ) to get all derivations that map the sentence x to the logical form z, given parameters θ and lexicon Λ. To compute GENMAX, we follow Zettlemoyer and <ref type="bibr" target="#b46">Collins (2005)</ref> and collect constant co-occurrence counts from z to prune from the CKY chart any category that cannot participate in a derivation leading to z. Since only constant names are changed during the second stage, setting the factor graph to get z is trivial: if the underspecified logical form is identical to z except the placeholders, we replace the placeholders with the correct final assignment, otherwise the derivation cannot result in z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Learning</head><p>Learning the two-stage model requires inducing the entries of the CCG lexicon Λ and estimating the parameters θ, which score both stages of the derivation. We assume access to a training set of N examples D = {(x i , z i ) : i = 1 . . . N }, each containing a sentence x i and a logical form z i . This data does not include information about the lexical entries and CCG parsing operations re- quired to construct the correct derivations. We consider all these decisions as latent.</p><p>The main learning algorithm (Algorithm 1) starts by initializing the lexicon (line 1) and then Algorithm 1 The main learning algorithm.</p><p>Input: Training set D = {(xi, zi) : i = 1 . . . N }, number of iterations T , mini-batch size M , seed lexicon Λ0 and learning rate µ. Definitions: SUB(D, i, j) is the set of the next j sam- ples from D starting at i. GENMAX(x, z, θ, Λ) is the set of viterbi derivations from x with the final re- sult z given parameters θ and lexicon Λ. LEX(d) is the set of lexical entries used in the derivation d. COMPUTEGRAD(x, z, θ, Λ) computes the gradient for sentence x and logical form z, given the parame- ters θ and lexicon Λ, and it described in Section 6.2. ADAGRAD(∆) applies a per-feature learning rate to the gradient ∆ <ref type="figure" target="#fig_2">(Duchi et al., 2011</ref>). Output: Lexicon Λ and model parameters θ.</p><p>1: Λ ← Λ0 2: for t = 1 to T do 3: » Generate entries and update the lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>for i = 1 to N do 5:</p><p>λnew ← λnew ∪ GENENTRIES(xi, zi, θ, Λ) 6:</p><p>Λ ← Λ ∪ λnew 7:</p><p>» Compute and apply mini-batch gradient updates. 8:</p><formula xml:id="formula_11">for i = 1 to N M do 9: ∆ ← 0 10: for (x, z) in SUB(D, i, M ) do 11:</formula><p>» Compute and aggregate the gradient. 12:</p><formula xml:id="formula_12">∆ ← ∆ + COMPUTEGRAD(x, z, θ, Λ) 13: θ ← θ + µADAGRAD(∆) 14:</formula><p>» Get all correct viterbi derivations. 15:</p><formula xml:id="formula_13">V ← (x,z)∈D GENMAX(x, z, θ, Λ) 16:</formula><p>» Retain only entries from derivations in V . 17:</p><p>Λ ← d∈V LEX(d) 18: return Λ and θ Algorithm 2 GENENTRIES: Procedure to generate lexical entries from one training sample. See Section 6.1 for details.</p><p>Input: Sample (x, z), model parameters θ and lexicon Λ. Definitions: GENLEX(x, z, Λ) and RECSPLIT(z, z, θ, Λ) are defined in Section 6.1. Output: Set of lexical entries λ.</p><p>1: » Augment lexicon with sample-specific entries. processes the data T times (line 2), each time al- ternating between batch expansion of the lexicon and a sequence of mini-batch parameter updates. An iteration starts with a batch pass to expand the lexicon. The subroutine GENENTRIES, described in Section 6.1 and Algorithm 2, is called to gener- ate a set of new entries for each sample (line 5). Next, we update the parameters θ with mini- batch updates. Given a mini-batch size of M , we use the procedure SUB <ref type="bibr">(D, i, M )</ref> to get the i-th segment of the data D of size M . We pro- cess this segment (line 10) to accumulate the mini-batch gradient ∆ by calling the procedure COMPUTEGRAD(x, z, θ, Λ) (line 12), which com- putes the gradient for x and z given θ and Λ, as described in Section 6.2. We use <ref type="bibr">AdaGrad (Duchi et al., 2011</ref>) parameter updates (line 13).</p><p>Each iteration concludes with removing all lexi- cal entries not used in max-scoring correct deriva- tions, to correct for overgeneration (lines 14-17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Lexicon Expansion: GENENTRIES</head><p>Given a sentence x, a logical form z, parameters θ and a lexicon Λ, GENENTRIES(x, z, θ, Λ) (Algo- rithm 2) computes a set of lexical entries, such that there exists at least one derivation d using these entries from x to z. We first use GENLEX(x, z, Λ) to generate a large set of potential lexical entries from u, the underspecified form of z, by generat- ing lexemes (Section 4) and pairing them with all templates in Λ. We then use a two-pass process to select the entries to return. The set of gener- ated lexemes is a union of: (a) the set G gen that includes all pairings of subsets of constants from z with spans in x up to length k gen and (b) the set that is constructed by matching named-entity constants <ref type="bibr">5</ref> in z with their corresponding mentions in the text to create new lexemes with potentially any other constant (for lexemes with multiple con- stants). Λ is augmented with the generated set of lexical entries to create Λ + (line 2).</p><p>First Pass Given the augmented lexicon Λ + , we compute the set D + = GENMAX(x, z, θ, Λ + ) (line 4).</p><p>Following Artzi and Zettlemoyer (2013b), we constrain the set of derivations to in- clude only those that use at most one lexeme from G gen . If generating new lexemes is sufficient to derive z from x, D + will contain these derivations and we return their lexical entries to be added to the lexicon Λ (lines 5-7). Otherwise, we proceed to do a second pass, where we try to generate new templates to parse the sentence.</p><p>Second Pass: RECSPLIT In this pass we try to generate max-scoring derivations in a top-down process. Starting from u, the underspecified form of z, we search for CCG parsing steps that will connect to existing partial derivations in the CKY chart to create a complete parse tree. Since the space of possible operations is extremely large, we use CCGBank <ref type="bibr" target="#b17">(Hockenmaier and Steedman, 2007</ref>) categories to prune, as described below.</p><p>The second pass is executed by calling RECSPLIT(x, z, θ, Λ + ), which returns a set of lex- ical entries to add to the model (line 10). We recur- sively apply the splitting operation introduced by <ref type="bibr" target="#b24">Kwiatkowski et al. (2010)</ref>. Given a CCG category, splitting outputs all possible category pairs that could have originally generated it. For example, given the category S\N P λy.λd.deny-01</p><formula xml:id="formula_14">(d) ∧ ARG0(d, y) ∧ ARG1(d, A 1 (λi.involve-01(i) ∧ ARG1(i, R(ID)))),</formula><p>one of the possi- ble splits will include the categories S\N P/N P λx.λy.λd.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d, x) and N P A 1 (λi.involve-01(i) ∧ ARG1(i, R(ID))) which would combine with forward application (&gt;). <ref type="bibr" target="#b24">Kwiatkowski et al. (2010)</ref> present the full details. <ref type="bibr">6</ref> The process starts from u, the underspecified form of z, and recursively applies the splitting operation while ensuring that: (1) there is at most one entry from G gen or one entry where both the template and lexemes are new in the derivation, (2) each parsing step must have at least one child that may be constructed from an existing partial derivation, and (3) for each new parsing step, the syntax of a newly generated child must match the syntax of a CCGBank category for the same span. To search the space of derivations we populate a CKY chart and do a top-down beam search, where in each step we split categories for smaller spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Gradient Computation: COMPUTEGRAD</head><p>Given a sentence x, its labeled logical form z, parameters θ and lexicon Λ, the procedure COMPUTEGRAD(x, z, θ, Λ) computes the gradi- ent for the sample (x, z).</p><p>Let D * (z) = GENMAX(x, z, θ, Λ), the set of max-scoring cor- rect derivations. The hard gradient update is:</p><formula xml:id="formula_15">1 |D * (z)| d∈D * (z) φ(xi, d) − E p(d,|x i ;θ,Λ) [φ(xi, d)] , (2)</formula><p>where φ(x, d) ∈ R l is a l-dimensional feature vec- tor (Section 5.3) and the positive portion of the gradient, rather than using expected features, av- erages over all max-scoring correct derivations.</p><p>Early updates To generate an effective update when no correct derivation is observed, we fol- low <ref type="bibr" target="#b12">Collins and Roark (2004)</ref> and do an early up- date if D * (z) is empty or if GEN(x, Λ), the set of derivations for x, does not contain a derivation with the correct final logical form z. Given the par- tial derivations, our gradient computation is identi- cal to Equation 2. However, in contrast to <ref type="bibr" target="#b12">Collins and Roark (2004)</ref> our data does not include gold derivations. Therefore, we attempt to identify max-scoring partial derivations that may lead to the correct derivation. We extract sub-expressions from u, 7 the underspecified form of z, and search the CKY chart for the top-scoring non-overlapping spans that contain categories with these logical forms. We use the partial derivations leading to these cells to compute the gradient.</p><p>The benefit of early updates is two-fold. First, as expected, it leads to higher quality updates that are focused on the errors the model makes. Sec- ond, given the complexity of the data, it allows us to have updates for many examples that would be otherwise ignored. In our experiments, we observe this behavior with nearly 40% of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Setup</head><p>Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG ( <ref type="bibr" target="#b28">Lewis and Steedman, 2014</ref>) trained with the re-banked CCGBank <ref type="bibr" target="#b17">(Hockenmaier and Steedman, 2007;</ref><ref type="bibr" target="#b18">Honnibal et al., 2010</ref>) to gener- ate CCGBank categories, the Illinois Named En- tity Tagger <ref type="bibr" target="#b37">(Ratinov and Roth, 2009)</ref> for NER, Stanford CoreNLP ( <ref type="bibr" target="#b31">Manning et al., 2014</ref>) for to- kenization and part-of-speech tagging and UW SPF <ref type="bibr" target="#b2">(Artzi and Zettlemoyer, 2013a</ref>) to develop our system. We use SMATCH  to evaluate logical forms converted back to AMRs.</p><p>CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factor- ing lexical entries, we avoid extracting binary re- lations and references, and leave them in the tem- plate. We use backward and forward binary com- binators for application, composition and cross- ing composition. We allow non-crossing compo- sition up to the third order. We also add rules to handle punctuation and unary rules for type- shifting non-adjectives in adjectival positions and verb phrases in adverbial positions. We allow shifting of bare plurals, mass nouns and named entities to noun phrases. To avoid spurious am- biguity during parsing, we use normal-form con- straints <ref type="bibr" target="#b16">(Hockenmaier and Bisk, 2010)</ref>. We use five basic lambda calculus types: entity e, truth value t, identifier id, quoted text txt and integer i.</p><p>Features During CCG parsing, we use indicator features for unary type shifting, crossing compo- sition, lexemes, templates and dynamically gen- erated lexical entries. We also use indicators for co-occurrence of part-of-speech tags and syntac- tic attributes, repetitions in logical conjunctions and attachments in the logical form. In the factor graph, we use indicator features for control struc- tures, parent-relation-child selectional preferences and for mapping a relation to its final form. See the supplementary material for a detailed description.</p><p>Initialization and Parameters We created the seed lexicon from the training data by sampling and annotating 50 sentences with lexical entries, adding entries for pronouns and adding lexemes for all alignments generated by JAMR ( <ref type="bibr" target="#b14">Flanigan et al., 2014</ref>). We initialize features weights as fol- lows: 10 for all lexeme feature for seed entries and entries generated by named-entity matching (Section 6.1), IBM Model 1 scores for all other lexemes ( <ref type="bibr" target="#b25">Kwiatkowski et al., 2011</ref>), -3 for unary type shifting and crossing composition features, 3 for features that pair singular and plural part-of- speech tags with singular and plural attributes and 0 for all other features. We set the number of it- erations T = 10 and select the best model based on development results. We set the max number of tokens for lexical generation k gen = 2, learning rate µ = 0.1, CCG parsing beam K = 50, factor graph beam L = 100, mini batch size M = 40 and use a beam of 100 for GENMAX.</p><p>Two-pass Inference During testing, we perform two passes of inference for every sentence. First, we run our inference procedure (Section 5.4). If no derivations are generated, we run inference again, allowing the parser to skip words at a fixed cost and use the entries for related words if a word is unknown. We find related words in the lexicon us- ing case, plurality and inflection string transforma- tions. Finally, if necessary, we heuristically trans- form the logical forms at the root of the CCG parse trees to valid AMR logical forms. We set the cost of logical form transformation and word skipping to 10 and the cost of using related entries to 5. <ref type="table" target="#tab_0">Table 1</ref> shows SMATCH test results. We com- pare our approach to the latest, fixed version of JAMR ( <ref type="bibr" target="#b14">Flanigan et al., 2014</ref>) available online, 8 the only system to report test results on the official LDC release. Our approach outperforms JAMR by 3 SMATCH F1 points, with a significant gain in recall. Given consensus inter-annotator agree- ment of 83 SMATCH F1 ( <ref type="bibr" target="#b14">Flanigan et al., 2014)</ref>, this improvement reduces the gap between auto- mated methods and human performance by 15%. Although not strictly comparable, <ref type="table" target="#tab_0">Table 1</ref> also in- cludes results on the pre-release AMR Bank cor- pus, including the published JAMR results, their fixed results and the results of <ref type="bibr" target="#b43">Wang et al. (2015)</ref>. <ref type="table" target="#tab_1">Table 2</ref> shows SMATCH scores for the devel- opments set, with ablations. The supplementary material includes example output derivations and qualitative comparison to JAMR outputs. We first remove underspecifying constants, which leaves the factor graph to resolve only references. While the expressivity of the model remains the same, more decisions are considered during parsing, modestly impacting performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head><p>We also study the different methods for lexical generation. Skipping the second recursive split- ting pass in GENENTRIES creates an interesting tradeoff. As we are unable to learn templates with- out splitting, we induce a significantly smaller lex- icon (500K vs. 1.6M entries). Although we are unable to recover many syntactic constructions, our search problem is in general much simpler. We therefore see a relatively mild drop in overall per- formance (1.1 F1). Removing G gen during lexi- cal generation (Section 6.1) creates a more signif- icant drop in performance (3.4 F1), demonstrating how considering all possible lexemes allows the system to recover entries that are not covered by heuristic alignments. We are also able for the first time to report AMR parsing results without any surface-form similarity heuristics, by removing both JAMR alignments and named-entity match- ing lexical generation (Section 6.1). The signifi- cant drop in performance (20 points F1) demon- strates the need for better alignment algorithm.</p><p>Finally, <ref type="figure" target="#fig_3">Figure 5</ref> plots development SMATCH F1 with and without early updates. As expected, early updates increase the learning rate signifi- cantly and have a large impact on overall perfor- mance. Without early updates we are unable to <ref type="bibr">8</ref> JAMR is available at http://tiny.cc/jamr. P R F1 JAMR (fixed) 67.8 59.2 63.2 Our approach 66.8 65.7 66.3 Pre-release corpus results JAMR ( <ref type="bibr" target="#b14">Flanigan et al., 2014</ref>) 52.0 66.0 58.0 JAMR (fixed) 66.8 58.3 62.3 <ref type="bibr" target="#b43">Wang et al. (2015)</ref> 64.0 62.0 63.0   learn from almost half of the data, and perfor- mance drops by nearly 15 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We described an approach for broad-coverage CCG induction for semantic parsing, including a joint representation of compositional and non- compositional semantics, a new grammar induc- tion technique and an early update procedure. We used AMR as the target representation and present new state-of-the-art AMR parsing results.</p><p>While we focused on recovering non- compositional dependencies, other non- compositional phenomena remain to be studied. Although our technique is able to learn certain id- ioms as multi-word phrases, learning to recognize discontinuous idioms remains open. Similarly, resolving cross-sentence references, which are not annotated in AMR Bank, is important future work. Finally, we would like to reduce the dependency on surface-form heuristics, for example to better generalize to other languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A complete derivation for the sentence Pyongyang officials denied their involvement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 :</head><label>2</label><figDesc>Λ+ ← Λ ∪ GENLEX(x, z, Λ) 3: » Get max-scoring correct derivations. 4: D+ ← GENMAX(x, z, Λ+, θ) 5: if |D+| &gt; 0 then 6: » Return entries from max-scoring derivations. 7: return d∈D + LEX(d) 8: else 9: » Top-down splitting to generate new entries. 10: return RECSPLIT(x, z, θ, Λ+)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Development SMATCH F1 without early updates (•) and with early updates ().</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Test SMATCH results. 

P 
R 
F1 
Full system 
67.2 65.1 66.1 
w/o underspecified constants 66.9 64.2 65.5 
Lexical learning ablations 
w/o splitting 
65.0 65.0 65.0 
w/o Ggen 
62.6 62.7 62.6 
w/o surface-form similarity 
55.9 38.5 45.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Development SMATCH results.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://yoavartzi.com/amr</note>

			<note place="foot" n="2"> Similar to mention clustering methods for co-reference resolution (Ng, 2010), IDs can be viewed as creating clusters.</note>

			<note place="foot" n="3"> See Artzi et al. (2014) for a description of this process and how to approximate the partition function in Equation 1. 4 Experiments with loopy belief propagation showed it to be slower and less effective for our task.</note>

			<note place="foot" n="5"> Named-entity constants are created from name instances when converting from AMR to lambda calculus. See the supplementary material for the exact procedure.</note>

			<note place="foot" n="6"> Unlike Kwiatkowski et al. (2010), we also introduce syntactic attributes (e.g., pl, sg) when splitting.</note>

			<note place="foot" n="7"> We extract all sub-expressions of type e, e, t, e, t, e, t or e, e, t from u.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by a Mi-crosoft Research PhD Fellowship, the NSF (IIS-1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award and a gift from Google. The authors thank Mark Yatskar, Tom Kwiatkowski, Chloé Kiddon, Eunsol Choi, Mike Lewis and the reviewers for their helpful advice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning compact lexicons for CCG semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrov</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bootstrapping semantic parsers from conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">UW SPF: The University of Washington Semantic Parsing Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Abstract meaning representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Annotation Workshop</title>
		<meeting>the Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Wide-coverage semantic analysis with Boxer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Semantics in Text Processing</title>
		<meeting>the Conference on Semantics in Text Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic parsing Freebase: Towards open-domain semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association of Computational Linguistics</title>
		<meeting>the Conference of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast online lexicon learning for grounded language acquisition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Widecoverage efficient statistical parsing with CCG and log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="552" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Driving semantic parsing from the world&apos;s response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roth</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computational Natural Language Learning</title>
		<meeting>the Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the Abstract Meaning Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association of Computational Linguistics</title>
		<meeting>the Conference of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning from natural instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Normalform parsing for combinatory categorial grammars with generalized composition and typeraising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bisk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CCGBank: A corpus of CCG derivations and dependency structures extracted from the Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="355" to="396" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rebanking CCGBank for Improved NP Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semantics-based machine translation with hyperedge replacement grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weakly supervised training of semantic parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning a compositional semantics for Freebase with an open predicate vocabulary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A probabilistic model of syntactic and semantic acquisition from child-directed utterances and their meanings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the European Chapter of the Association of Computational Linguistics</title>
		<meeting>the Conference of the European Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higher-order unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Combined distributional and logical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A* CCG parsing with a supertag-factored model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics</title>
		<meeting>the Conference of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Toward abstractive summarization using semantic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Association for Computational Linguistics</title>
		<meeting>the North American Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning for deep language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Supervised noun phrase coreference research: The first fifteen years</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the association for computational linguistics</title>
		<meeting>the annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised entity linking with Abstract Meaning Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Association for Computational Linguistics</title>
		<meeting>the North American Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Grounded unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Aligning English strings with Abstract Meaning Representation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Computational Natural Language Learning</title>
		<meeting>the Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Large-scale semantic parsing without questionanswer pairs</title>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Surface Structure and Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The Syntactic Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Taking Scope</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for AMR parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradhan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Association for Computational Linguistics</title>
		<meeting>the North American Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the Association for Computational Linguistics</title>
		<meeting>the Conference of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning to parse database queries using inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
