<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Capturing User and Product Information for Document Level Sentiment Analysis with Deep Memory Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi-Yi</forename><surname>Dou</surname></persName>
							<email>141242042@smail.nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Capturing User and Product Information for Document Level Sentiment Analysis with Deep Memory Network</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="521" to="526"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Document-level sentiment classification is a fundamental problem which aims to predict a user&apos;s overall sentiment about a product in a document. Several methods have been proposed to tackle the problem whereas most of them fail to consider the influence of users who express the sentiment and products which are evaluated. To address the issue, we propose a deep memory network for document-level sentiment classification which could capture the user and product information at the same time. To prove the effectiveness of our algorithm , we conduct experiments on IMDB and Yelp datasets and the results indicate that our model can achieve better performance than several existing methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentiment analysis, sometimes known as opinion mining, is the field of study that analyzes peo- ple's opinions, sentiments, evaluations, attitudes and emotions from written language. It is one of the most active and critical research areas in natu- ral language processing ( <ref type="bibr" target="#b10">Liu, 2012</ref>). On the one hand, from the industry point of view, knowing the feelings among consumers based on their com- ments is beneficial and may support strategic mar- ket decisions. On the other hand, potential cus- tomers are often interested in other people's opin- ion in order to find out the choices that best fits their preferences <ref type="bibr" target="#b14">(Moraes et al., 2013)</ref>.</p><p>Previous studies tackled the sentiment analysis problem at various levels of granularity, from doc- ument level to sentence level due to different ob- jectives of applications ( <ref type="bibr" target="#b23">Zhang et al., 2009)</ref>. In this work, we mainly focus on document-level senti- ment classification Basically, the task is to predict user's overall sentiment or polarity in a document about a product <ref type="bibr" target="#b15">(Pang and Lee, 2008)</ref>.</p><p>Most existing methods mainly utilize local text information whereas ignoring the influences of users and products ( <ref type="bibr" target="#b19">Tang et al., 2015)</ref>. As is often the case, there are certain consistencies for both users and products. To illustrate, lenient users may always give higher ratings than fastidious ones even if they post the same review. Also, it is not surprising that some products may always receive low ratings because of their poor quality and vice versa. Therefore, it is necessary to leverage indi- vidual preferences of users and overall qualities of products in order to achieve better performance. <ref type="bibr" target="#b19">Tang et al. (2015)</ref> proposed a novel method dubbed User Product Neural Network (UPNN) which capture user-and product-level information for sentiment classification. Their approach has shown great promise but one major drawback of their work is that for users and products with lim- ited information, it is hard to train the representa- tion vector and matrix for them. Inspired by the recent success of computa- tional models with attention mechanism and ex- plicit memory ( <ref type="bibr" target="#b4">Graves et al., 2014;</ref><ref type="bibr" target="#b18">Sukhbaatar et al., 2015)</ref>, we addressed the aforementioned is- sue by proposing a method based on deep memory network and Long Short-Term Memory (LSTM) <ref type="bibr" target="#b5">(Hochreiter and Schmidhuber, 1997</ref>). The model can be divided into two separate parts. In the first fart, we utilize LSTM to represent each document. Afterwards, we apply deep memory network con- sists of multiple computational layers to predict the ratings for each document and each layer is a content-based attention model.</p><p>To prove the effectiveness of our algorithm, we have conducted experiments on three datasets de- rived from IMDB and Yelp Dataset Challenge and compare to several other algorithms. Experimen- tal results show that our algorithm can outperform baseline methods for sentiment classification of documents by leveraging users and products for document-level sentiment classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Memory Network</head><p>In 2014, <ref type="bibr" target="#b22">Weston et al. (2014)</ref> introduced a new class of learning models called memory networks. Memory networks reason with inference compo- nents combined with a long-term memory com- ponent. The long-term memory can be read and written to and then it can be used for prediction. Generally, a memory network consists of an array of objects called memory m and four components I, G, O and R, where I converts input to internal feature representation, G updates old memories, O generates an output representation and R outputs a response.</p><p>Based on their work, <ref type="bibr" target="#b18">Sukhbaatar et al. (2015)</ref> proposed a neural network with a recurrent atten- tion model over a possibly large external memory. Unlike previous model, their model is trained end- to-end and hence requires significantly less super- vision during training. They have shown that their model yields improved results in language model and question answering.</p><p>Inspired by the success of memory network, <ref type="bibr" target="#b20">Tang et al. (2016)</ref> introduce a deep memory net- work for aspect-level sentiment classification. The architecture of their model is similar to the previ- ous model and experimental results demonstrate that their approach performs comparable to other state-of-the-art systems. Also, <ref type="bibr">Li et al. (2017)</ref> de- compose the task of attitude identification into two separate subtasks: target detection and polarity classification; and then solve the problem by ap- plying deep memory network so that signals pro- duced in target detection provide clues for polarity classification and the predicted polarity provides feedback to the identification of targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sentiment Classification</head><p>Most existing work tackle the problem of senti- ment classification by manually design effective features. such as text topic ( <ref type="bibr" target="#b2">Ganu et al., 2009)</ref> and bag-of-opinion ( <ref type="bibr" target="#b16">Qu et al., 2010)</ref> . Some work take user information into consideration. For ex- ample, in 2013, <ref type="bibr" target="#b3">Gao et al. (2013)</ref> design user- specific features to capture user leniency. Also, <ref type="bibr" target="#b8">Li et al. (2014)</ref> incorporate textual topic and user- word factors with supervised topic modeling. <ref type="bibr" target="#b19">Tang et al. (2015)</ref> points out that it is criti- cal to leverage users and products for document- level sentiment classification. They assume there are four types of consistencies for sentiment clas- sification and validate the influences of users and products in terms of sentiment and text on massive IMDB and Yelp reviews. Their model represent each user and product as both vector and matrix in order to capture the consistencies and then apply convolutional neural network to solve the task.</p><p>To the best of our knowledge, no one has ever applied deep memory network to capture the user and product information and solve the tasks in sen- timent classification at document-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Methods</head><p>In this section, we present the details of User Prod- uct Deep Memory Network (UPDMN) for senti- ment classification at document level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic Symbol and Definition</head><p>First we suppose U , P , D is the set of users, products and documents respectively. If user u ∈ U writes a document d ∈ D about a product p ∈ P and give the rating, we denote U (d) = {ud|ud is written by u, ud = d} and P (d) = {pd|pd is written about p, pd = d}. Then, our task can be formalized as follows: suppose u write a document d about a product p , we should output the predicted score y for the document d based on the input &lt; d, U (d), P (d) &gt; . The detail of these symbols would be illustrated in the following part. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the general framework of our approach. Basically, inspired by the use of mem- ory network in question answering and aspect- level sentiment analysis ( <ref type="bibr" target="#b18">Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b20">Tang et al., 2016)</ref>, our model consists of multiple computational layers (hops), each of which con- tains an attention layer and a linear layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">General Framework of UPDMN</head><p>For every document in U (d) and P (d), we em- bed it into a continuous vector d i and store it in the memory. The model writes all document to the memory up to a fixed buffer size. Suppose we are given {d i } = {d 1 , ..., d n } to be stored in memory, for each layer we can convert them into memory vectors {m i } using an embedding matrix. The document d should also be embedded into q. Then, we compute the match {p i } between q and each memory m i . Afterwards, we embed {d i } into  <ref type="table">Table 1</ref>: Statistical information of datasets. The output vector at last hop is fed into a softmax layer and then generates the final predic- tion y for document-level sentiment classification.</p><note type="other">Dataset #users #products #reviews #docs/user #docs/product #sents/doc #words/</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Embedding Documents</head><p>Although there are several state-of-the-art tech- niques to embed word into vectors (Mikolov et al., 2013a), for document-level sentiment classifica- tion, the document we need to classify is usually too long to be represented as a vector. People have tried different ways to solve the task. For exam- ple, <ref type="bibr" target="#b6">Kalchbrenner et al. (2014)</ref> apply convolu- tional neural network for modeling sentences and <ref type="bibr" target="#b9">Li et al. (2015)</ref> introduce an LSTM model that hi- erarchically builds an embedding for a paragraph from embeddings for sentences and words.Some of these work can be incorporated into our meth- ods. However, here we only use the LSTM model to embed each document, i.e. every word in the document is fed into LSTM and the final represen- tation is obtained by averaging the hidden state of each word, and the experimental results shows that this simple embedding method can actually obtain satisfactory results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Attention Model</head><p>After obtaining the embedding vector q for docu- ment d the memory vectors {m i } for each mem- ory, we calculate the match between q and m i us- ing the following equation:</p><formula xml:id="formula_0">p i = sof tmax(W att [m i ; q] + b att )<label>(1)</label></formula><p>where sof tmax(z i ) = e z i / j e z j . Afterwards, we compute the corresponding out- put o for each hop by summing over the c i , weighted by the probability vector from the input:</p><formula xml:id="formula_1">o = i p i c i<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Final Prediction and Training Strategy</head><p>At last hop, the output vector is fed into a softmax layer and thus generates a probability distribution {y i } over ratings. The score with the highest prob- ability would be considered as our final prediction py. During training, we try to minimize the cross entropy error of sentiment classification in a su- pervised manner. The specific equation is shown as follows:</p><formula xml:id="formula_2">Loss = − d∈D y i ∈Y I(y = y i |d)log(P (y = y i |d))<label>(3)</label></formula><p>where Y is the collection of sentiment categories, I(y = y i |d) is 1 or 0, indicating whether the cor- rect category for d is y i , and P (y = y i |d) repre- sents the probability of classifying document d as category y i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head><p>In this section, we will first discuss the experimen- tal setting and then display the results.    <ref type="table">Table 2</ref>: Experimental results.</p><note type="other">RNTN + Recurrent 0.400 1.133 1.764 0.582 0.478 0.821 0.574 0.489 0.804 Trigram + UPF 0.404 1.132 1.764 0.576 0.471 0.789 0.570 0.491 0.803 TextFeature +UPF 0.402 1.129 1.774 0.579 0.476 0.791 0.561 0.509 0.822 JMARS N/A 1.285 1.773 N/A 0.710 0.999 N/A 0.699 0.985 UPNN 0.435 0.979 1.602 0.608 0.447 0.764 0.596 0.464 0.784 UPDMN(1) 0.428 0.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We use the same datasets as <ref type="bibr" target="#b19">Tang et al. (2015)</ref>, which are derived from IMDB ( <ref type="bibr" target="#b0">Diao et al., 2014)</ref> and Yelp Dataset Challenge in 2013 and 2014 <ref type="bibr">1</ref> . Statistical information of the datasets are given in <ref type="table">Table 1</ref>. In order to measure the performance of our model, here we use three metrics. Specifically, we use accuracy to measure the overall sentiment classification performance, M AE and RM SE to measure the divergences between prediction py and ground truth gy. The formulas for these three metrics are listed as follows:</p><formula xml:id="formula_3">accuracy = T N (4) M AE = i |py i − gy i | N (5) accuracy = i (py i − gy i ) 2 N (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Models</head><p>We compare UPDMN with the following models:</p><p>(1) Majority : it assigns each review in the test dataset with the majority sentiment category in training set.</p><p>(2) Trigram : it first takes unigrams, bigrams and trigrams as features and then trains a classifier with SVM <ref type="bibr" target="#b1">(Fan et al., 2008)</ref>.</p><p>(3) TextFeature : it takes hard-crafted text fea- tures such as word/character n-grams, negation features and then trains a classifier with SVM.</p><p>(4) UPF: it extracts user-leniency features and corresponding product features from training data 1 http://www.yelp.com/dataset challenge and then concatenates them with features in model (2) and (3) ( <ref type="bibr" target="#b3">Gao et al., 2013)</ref>.</p><p>(5) AvgWordvec+SVM : it learns word em- beddings from training and development sets with word2vec , averages word embeddings and then trains an SVM classifier ( <ref type="bibr" target="#b13">Mikolov et al., 2013b)</ref>.</p><p>(6) SSWE+SVM : it learns sentiment-specific word embeddings (SSWE), uses max/min/average pooling to generate document representation and then trains an SVM classifier ( <ref type="bibr" target="#b21">Tang et al., 2014</ref>).</p><p>(7) RNTN+RNN : it represents each sentence with RNTN, composes document with recurrent neural network , and then averages hidden vectors of recurrent neural network as the features <ref type="bibr" target="#b17">(Socher et al., 2013)</ref>.</p><p>(8) Paragraph Vector: it implements the PVDM for document-level sentiment classifica- tion ( <ref type="bibr" target="#b7">Le and Mikolov, 2014)</ref>.</p><p>(9) JMARS: it is the recommendation algo- rithm which leverages user and aspects of a re- view with collaborative filtering and topic model- ing ( <ref type="bibr" target="#b0">Diao et al., 2014</ref>).</p><p>(10) UPNN : as has been stated above, it also leverages user and product information for senti- ment classification at document level ( <ref type="bibr" target="#b19">Tang et al., 2015</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results and Discussion</head><p>The experimental results are given in <ref type="table">Table 2</ref>. The results of baseline models are reported in <ref type="bibr" target="#b19">(Tang et al., 2015)</ref>. Our model is abbreviated to <ref type="bibr">UPDMN(k)</ref>, where k is the number of hops. With the increase of the number of hops, the perfor- mance of UPDMN will get better intially, which indicates that multiple hops can indeed capture more information to improve the performance. However, if there are too many hops, the perfor- mance would be not as well as before, which may be caused by over-fitting.</p><p>Compared with other models, we can see that with proper setting, our model achieve superior results. All these results prove the effectiveness of UPDMN and the necessity to utilizing user and product information at document level.</p><p>It should be noticed that there are still several improvements can be made, such as better repre- sentation of documents or more sophisticated at- tention mechanism. We believe that our model has great potential and can be improved in many ways.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: General Framework</figDesc><graphic url="image-1.png" coords="3,74.84,142.33,212.60,259.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>IMDB</head><label></label><figDesc></figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank anonymous reviewers and Hao Zhou for helpful advice.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiming</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">Wei</forename><surname>Rong En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang Rui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond the stars: Improving rating predictions using review text content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gayatree</forename><surname>Ganu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amlie</forename><surname>Marian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on the Web and Databases</title>
		<meeting><address><addrLine>Providence, Rhode Island, Usa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling user leniency and product popularity for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaru</forename><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1107" to="1111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural turing machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seppu</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jrgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eprint Arxiv</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Suit: a supervised user-item based topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TwentyEighth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1636" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A hierarchical neural autoencoder for paragraphs and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurafsky</forename><surname>Dan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">167</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep memory networks for attitude identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="671" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Document-level sentiment classification: An empirical comparison between svm and ann</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Valiati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson P O</forename><surname>Neto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="621" to="633" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The bag-of-opinions method for review rating prediction from sparse text patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Ifrim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2010, International Conference on Computational Linguistics, Proceedings of the Conference</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-08" />
			<biblScope unit="page" from="913" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning semantic representations of users and products for document level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1014" to="1023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Aspect level sentiment classification with deep memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="214" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning sentimentspecific word embedding for twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1555" to="1565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Eprint Arxiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sentiment analysis of chinese documents: From sentence to document level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changli</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2474" to="2487" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
