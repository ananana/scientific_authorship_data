<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">Miller</forename><surname>Yoder</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeju</forename><surname>Jang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolyn</forename><forename type="middle">P</forename><surname>Rosé</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Language Technologies Institute Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Dialogue Acts with Content Word Filtering and Speaker Preferences</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2179" to="2189"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present an unsupervised model of dialogue act sequences in conversation. By modeling topical themes as transitioning more slowly than dialogue acts in conversation , our model de-emphasizes content-related words in order to focus on conversational function words that signal dialogue acts. We also incorporate speaker tendencies to use some acts more than others as an additional predictor of dialogue act prevalence beyond temporal dependencies. According to the evaluation presented on two dissimilar corpora, the CNET forum and NPS Chat corpus, the effectiveness of each modeling assumption is found to vary depending on characteristics of the data. De-emphasizing content-related words yields improvement on the CNET corpus, while utilizing speaker tendencies is advantageous on the NPS corpus. The components of our model complement one another to achieve robust performance on both corpora and outperform state-of-the-art baseline models.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Dialogue acts (DAs), or speech acts, represent the intention behind an utterance in conversa- tion to achieve a conversational goal <ref type="bibr" target="#b1">(Austin, 1975)</ref>. Modeling conversations as structured DA sequences is a step toward the automated under- standing of dialogue, useful for dialogue agents <ref type="bibr" target="#b23">(Traum, 1999;</ref><ref type="bibr" target="#b14">Louwerse et al., 2002</ref>) and the processing of informal online conversational data <ref type="bibr" target="#b16">(Misra and Walker, 2013;</ref><ref type="bibr" target="#b24">Vosoughi and Roy, 2016)</ref>. Distributions of DAs can also be used as predictors of conversational outcome measures such as student learning in tutoring systems <ref type="bibr" target="#b13">(Litman and Forbes-Riley, 2006</ref>) and engagement in meetings ( <ref type="bibr" target="#b26">Wrede and Shriberg, 2003)</ref>. Unsuper- vised models for DA recognition may substitute or aid costly human annotation. We present an unsu- pervised model of DA sequences in conversation that overcomes limitations of prior models.</p><p>The first improvement our model offers is sep- arating out content-related words to emphasize words more relevant to DAs. DAs are associ- ated more closely with style and function words such as discourse markers and light verbs than with content words, which are more related to the propositional content <ref type="bibr" target="#b4">(Erkens and Janssen, 2008;</ref><ref type="bibr" target="#b18">O'Shea et al., 2012)</ref>. However, separating out con- tent words is not standard in our field. For ex- ample, in some rule-based semantic and pragmatic parsing, the content and function of dialogue acts are not formally distinguished in the formalization <ref type="bibr" target="#b2">(Becker et al., 2011</ref>), especially in domain-specific applications in dialogue systems <ref type="bibr" target="#b7">(Gavaldà, 2004)</ref>. A separation between content and function is use- ful for making cross-domain or cross-task gener- alizations about conversational processes.</p><p>Our model filters out content words by imple- menting the assumption that conversations pro- ceed against a backdrop of underlying topics that transition more slowly than DAs or that are con- stant throughout. Based on a difference in tran- sition speed, two types of language models are learned: foreground language models that capture DA-related words and background language mod- els for content words. Although some existing models assume a background or domain-specific language model to filter out words unrelated to DAs ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b19">Paul, 2012;</ref><ref type="bibr" target="#b20">Ritter et al., 2010)</ref>, they either require domain labels or do not learn topics underlying conversations.</p><p>The second improvement offered by our model is inclusion of speaker preferences, or tendencies to use some DAs more than others. Prior mod-els of DAs in conversation often rely on the dis- course property of conditional relevance <ref type="bibr" target="#b12">(Levinson, 1983;</ref><ref type="bibr" target="#b15">Martin and Rose, 2003)</ref>, i.e., tenden- cies for sequences of conversational DAs such as questions followed by answers, greetings followed by greetings, and invitations followed by accep- tances <ref type="bibr" target="#b22">(Sidnell, 2011)</ref>. Though conditional rele- vance, which motivates the use of Markov models for inducing DA representations, is one stable sig- nal to discover DAs in discourse data <ref type="bibr" target="#b3">(Brychcín and Král, 2017;</ref><ref type="bibr" target="#b11">Lee et al., 2013)</ref>, there are rea- sons that it is a less strong signal than ultimately desired. One of the reasons is that the DA of an utterance depends not only on the preceding DA, but also on the speaker's personal style ( <ref type="bibr" target="#b0">Appling et al., 2013)</ref> or preferences for certain DAs. Our model explicitly accounts for speaker preferences as a factor in determining the DA of an utterance.</p><p>Our model also includes additional structure to account for assumptions about distribution and packaging of observed DAs in running discourse. First, one utterance can involve more than one DA <ref type="bibr" target="#b12">(Levinson, 1983)</ref>; for example, asking a question in a forum may involve introducing the speaker, explaining the problem, etc. Hence, we assume that DAs operate on more than one level simultaneously, and an utterance-level DA is a mixture of finer-grained sentence-level DAs. Sec- ond, online conversations often have multi-level structure, branching into multiple conversational threads using replies. Our model supports conver- sations that have such multi-level structure.</p><p>To illustrate the generalizability of our model, we evaluate it on two corpora with very differ- ent characteristics in terms of utterance length, the number of speakers per conversation, and the do- main: CNET and NPS Chat Corpus. We evalu- ate the DA recognition accuracy of our model and compare the result with other latest models. As we tune the model parameters for each corpus, we use our model as a lens to understand the rela- tionship between the nature of conversations and effective model components for identifying DAs, which may inform future model design.</p><p>For the remainder of the paper, we will discuss prior work on dialogue acts and existing models (Section 2) and explain our model design (Section 3). Then we will describe our evaluation method and corpora (Section 4) and discuss the lessons learned from our empirical investigation (Section 5). We conclude the paper in Section 6. <ref type="bibr" target="#b1">Austin (1975)</ref> makes a distinction between the il- locutionary, social intention of an utterance (as seen in the indirect sentence "Can you pass the salt?") and the locutionary act of an utterance, which includes the ostensible surface-level mean- ing of the words. DAs are commonly thought of as describing illocutionary actions in talk. Example DAs used in computational systems include yes- no question, statement, backchannel, and opin- ion ( <ref type="bibr" target="#b9">Jurafsky et al., 1998)</ref>. <ref type="bibr" target="#b25">Winograd and Flores (1986)</ref> were some of the first to conceptualize DAs with state transitions as a model for conversation. Similarly, contem- porary unsupervised DA models often use a hid- den Markov model (HMM) to structure a genera- tive process of utterance sequences ( <ref type="bibr" target="#b20">Ritter et al., 2010)</ref>. It is commonly assumed that each hid- den state corresponds to a DA, but different ap- proaches use different representations for states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>One common representation of a state is a multinomial distribution over words, from which words related to DAs are generated. Often, this generative process includes domain-or content- related language models that are independent of states and used to filter out words unrelated to DAs ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b20">Ritter et al., 2010)</ref>. How- ever, these language models have some limita- tions. For instance, <ref type="bibr" target="#b11">Lee et al. (2013)</ref> rely on do- main labels for learning domain-specific language models, which may require human annotation, whereas our model learns them without labels. <ref type="bibr" target="#b20">Ritter et al. (2010)</ref> learn conversation-specific lan- guage models to filter out content words. We take a different approach, simultaneously learning content-related topics underlying the entire cor- pus and filtering out these content words. Al- though most models incorporate a general lan- guage model to separate out common words ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b19">Paul, 2012;</ref><ref type="bibr" target="#b20">Ritter et al., 2010</ref>), we do not learn it because we assume that common words are relevant to DAs.</p><p>Word embedding vector representations have also been researched as the outputs of latent states. For example, <ref type="bibr" target="#b3">Brychcín and Král (2017)</ref> represent an utterance as a weighted sum of word vectors from GloVe 1 . Each utterance vector is generated from a Gaussian distribution that parameterizes a latent state. This model has been shown to capture DAs effectively for short utterances.</p><p>DAs are not completely determined by preced- ing DAs <ref type="bibr" target="#b12">(Levinson, 1983)</ref>, and this difficulty can be overcome partly by modeling speaker style, as there is evidence that each speaker has preferences for certain <ref type="bibr">DAs (Appling et al., 2013)</ref>. <ref type="bibr" target="#b8">Joty et al. (2011)</ref> model speakers as outputs generated by an HMM, but this structure makes it hard to adjust the contribution of speaker preferences and may overestimate the influence of speakers. We model speaker preferences more directly such that the preceding DA and the speaker together determine an utterance's probability distribution over DAs.</p><p>One reason for the nondeterministic nature of DAs is that one utterance can involve more than one DA <ref type="bibr" target="#b12">(Levinson, 1983)</ref>; this suggests that one language model per DA may not be enough. <ref type="bibr" target="#b19">Paul (2012)</ref> represents latent states as mixtures of top- ics, but there is no one-to-one relationship be- tween states and DAs. <ref type="bibr" target="#b8">Joty et al. (2011)</ref> assume that words are drawn individually from a fixed number of language models specific to each DA. However, we observe that one sentence usually performs a consistent finer-grained act, so we con- strain each sentence in an utterance to one lan- guage model. Thus, utterances, which may consist of multiple sentences, are represented as a mixture of finer-grained sentence-level DAs.</p><p>Word order in an utterance may play an impor- tant role in determining a DA, as in the differ- ence between "I am correct" and "am I correct". <ref type="bibr" target="#b5">Ezen-Can and Boyer (2015)</ref> compute the similar- ity between utterances based on word order using a Markov random field and cluster similar utter- ances to identify DAs. This model, however, does not consider transitions between clusters.</p><p>Online conversations often have asynchronous, multi-level structure (e.g., nested replies). In Joty et al. (2011)'s model, individual reply structure paths from the first utterance to terminal utterances are teased apart into separate sequential conver- sations by duplicating utterances. However, this method counts the same utterance multiple times and requires an aggregation method for making a final decision of the DA for each utterance. We ad- dress multi-level structure without duplicating ut- terances.</p><p>The properties of the models explained so far are summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>The relative importance of each structural com- ponent in a model may not be identical across all <ref type="bibr">Sp Tr LM ML M Brychcín and Král (2017</ref> corpora. Differences, especially as they are at- tributed to meaningful contextual variables, can be interesting both practically and theoretically. One contribution of our work is considering how dif- ferences in these kinds of contextual variables lead to meaningful differences in the utility of our dif- ferent modeling assumtions. More typical work in the field has emphasized methodological con- cerns such as minimization of parameter tuning, for example, by using a hierarchical Dirichlet pro- cess to determine the number of latent DAs auto- matically ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b20">Ritter et al., 2010</ref>) or by simply assuming that a word is equally likely to be DA-related or general <ref type="bibr" target="#b19">(Paul, 2012)</ref>. While these efforts are useful, especially when maximiz- ing the likelihood of the data, searching for the op- timal values of parameters for DA recognition may allow us to better understand the contribution of each model component depending on the charac- teristics of the dialogue, which in turn can inform future model design. A transition between states is defined on every parent-child utterance pair, supporting multi-level structure. The state of an utterance is dependent on both its parent's state and its speaker. Speakers are specific to each conversation, i.e., a speaker participating in multiple conversations is treated as different speakers for different conversations. The graphical representation of CSM is in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><formula xml:id="formula_0">) N Y - N N Ezen-Can and Boyer (2015) N N - N N Lee et al. (2013) N Y GD N N Paul (2012) N Y G N Y Joty et al. (2011) Y Y U Y Y Ritter et al. (2010) N Y GD N N Our model Y Y D Y Y</formula><formula xml:id="formula_1">s z F w z B l Sentence Utterance (Cnet) ! S a Word " B # B BG Topic FG Topic # F Speaker ! A $ Conversation State " F State % ! S &amp; S State FG Topic # F ' BG Topic # B ' " B ( B Speaker ! A &amp; A " F (</formula><p>The formal generative process of conversations is as follows:</p><p>• For each speaker a, draw a preference distri- bution over states π A a ∼ Dir(γ A ).</p><p>• For each state s £ Draw a transition probability distribution over states π S s ∼ Dir(γ S ). £ Draw a probability distribution over fore-</p><formula xml:id="formula_2">ground topics θ F s ∼ Dir(α F ).</formula><p>• For each foreground topic t, draw a probabil- ity distribution over words φ F t ∼ Dir(β).</p><p>• For each background topic t, draw a proba- bility distribution over words φ B t ∼ Dir(β).</p><p>• For the corpus, draw a distribution over back- ground topics θ B ∼ Dir(α B ).</p><p>• For each conversation</p><formula xml:id="formula_3">£ Draw a background topic z B ∼ Cat(θ B ).</formula><p>£ For each utterance u, with its speaker a u , its parent p, and the parent's state s p ,</p><formula xml:id="formula_4">Draw a state s u ∼ Cat(νπ S sp +(1−ν)π A au ). For each sentence Draw a foreground topic z F ∼ Cat(θ F su ). For each word · Draw an indicator of "foreground" or "background" l ∼ Cat((η, 1 − η)). · If l is "foreground", draw a word w ∼ Cat(φ F z F ). · If l is "background", draw a word w ∼ Cat(φ B z B ).</formula><p>According to this model, content words are sep- arated out into background topics in several ways. A background topic does not transition as fre- quently as foreground topics within a conversa- tion. Accordingly, words that are consistently used across utterances in a conversation are likely to be clustered into the background topic z B , whereas words whose use is sensitive to the previous state and the speaker are likely to be clustered into fore- ground topics z F . However, common function words, such as pronouns, prepositions, and punc- tuations, may also be separated out. Hence, η, the probability of a word being foreground, adjusts the degree of filtering. The higher the η value, the more words are likely to be generated from a fore- ground topic, and thus the more function words are included in foreground topics, leaving back- ground topics with content words. Hence, we may set η high if we believe function words play an im- portant role in DAs in a corpus and low otherwise. Note that η = 0.5 is equivalent to the assump- tion of existing models that a word is equally likely to be foreground or background ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b19">Paul, 2012)</ref>. Background topics capture content words underlying the corpus, as they are shared across conversations.</p><p>Speaker preferences are captured as a probabil- ity distribution over DAs (π A ), which, along with the preceding state, affects the probability of the current state. ν adjusts the contribution of the speaker's preferences; the higher ν, the weaker the contribution. So, we may set ν low if the role or conversational style of each speaker is believed to be invariant and each speaker is expected to con- duct specific DAs. If there is not enough such ev- idence and the conversation is driven without spe- cific roles of the speakers, then we may set ν high. We find that corpora have different optimal values  of ν depending on the conversational characteris- tics.</p><p>We use collapsed Gibbs sampling for inference to integrate out π S , π A , θ F , θ B , φ F , and φ B . Given conversation text with speakers for each ut- terance, along with the hyperparameters, ν, and η, the Gibbs sampler estimates the following vari- ables using counter matrices explained in <ref type="table" target="#tab_2">Table 2</ref>:</p><formula xml:id="formula_5">π S ij = N SS ij + γ S j (N SS ij + γ S ) , π A ij = N AS ij + γ A j (N AS ij + γ A ) θ F ij = N SF ij + α F j (N SF ij + α F ) , θ B j = N B j + α B j (N B j + α B ) φ F ij = N F W ij + β j (N F W ij + β) , φ B ij = N BW ij + β j (N BW ij + β)</formula><p>.</p><p>We may use slice sampling <ref type="bibr" target="#b17">(Neal, 2003)</ref> to esti- mate ν and η too, but the estimated values of ν and η may not be optimal for DA recognition. We can also obtain state assignments for utterances by taking a sample from the Gibbs sampler. De- tailed derivation for Gibbs sampling and the code are available online 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>This section describes our evaluation method and settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task and Metrics</head><p>We evaluate our model in terms of accuracy in utterance-level DA recognition. Since the output of the model is assignments to discovered states for utterances, not pre-determined DA labels, we use a clustering evaluation method, as adopted by previous work on unsupervised DA model- ing. Specifically, we use homogeneity, complete- ness, and v-measure as metrics <ref type="bibr" target="#b21">(Rosenberg and Hirschberg, 2007</ref>   cluster by the model share the same DA in the la- beled corpus. Completeness represents the degree to which utterances that have the same DA accord- ing to the gold standard are assigned to the same cluster. V-measure is the harmonic mean of ho- mogeneity and completeness. These metrics are easy to interpret and have been demonstrated to be invariant to dataset size and number of clusters. This enables a meaningful comparison of accuracy across different corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Corpora and Preprocessing</head><p>We evaluate on two corpora: CNET and NPS Chat (see <ref type="table" target="#tab_4">Table 3</ref> for statistics).</p><p>CNET ( <ref type="bibr" target="#b10">Kim et al., 2010</ref>) is a set of post threads from the Operating System, Software, Hardware, and Web Development sub-forums of CNET. This corpus is tagged with 12 DAs, including Question- Question, Question-Confirmation, Answer-Add, Resolution, and Other ( <ref type="table" target="#tab_5">Table 4</ref>). Note that question-and answer-related DAs are two-level. Most posts are tagged with one DA; in case a post is tagged with multiple DAs, we choose the first DA in the meta-data <ref type="bibr">3</ref> . Each post is considered an utterance and each thread as a conversation. Each thread has only a few posts (median 3) and in- volves a few speakers (median 2). Since there are many URLs, email addresses, and numbers in text, we replace them with special tokens using reg- ular expressions, and tokenize with the Stanford PTBTokenizer included in Stanford Parser 3.7.0 <ref type="bibr">4</ref> .</p><p>NPS <ref type="bibr">Chat (Forsythand and Martell, 2007</ref>) is a set of conversations from various online chat ser- vices. This corpus is tagged with 15 DAs, includ- ing Emotion, System, and whQuestion <ref type="table" target="#tab_5">(Table 4)</ref>. Every turn is tagged with a DA and considered an utterance. Each conversation is long (median 706 utterances) and involves many speakers (median 94). This corpus has already been tokenized, so we only replace usernames with a special token. Conversations in NPS have no reply structure, but we build in multi-level structure, simply treating an utterance that mentions another user as a child of the nearest utterance of the mentioned user. We compare the DA accuracy of the multi-level struc- ture and the original linear structure in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Models and Parameters</head><p>We set the numbers of states and background top- ics to the numbers of DAs and domains, respec- tively, if these numbers are available. For NPS, we search for the optimal number of background top- ics between 1 and 2, because there are only a few conversations. The optimal number of foreground topics is chosen among multiples of five between the number of states and four times the number of states, and the weights for state transition (ν) and foreground topics (η) are chosen among mul- tiples of 0.1. For Dirichlet hyperparameters, we use α F = 0.1, γ A = 0.1, β = 0.001 to induce sparsity, and γ S = 1, α B = 1 for the uniform dis- tribution over all configurations.</p><p>We randomly split each corpus into five groups and use three groups for training, one for param- eter tuning, and one for testing. We run 5-fold cross-validation and report the average optimal pa- rameter values and accuracy across the folds. The number of sampling iterations was chosen such that the log-likelihood of the data has converged. For each fold, we take 10 samples during infer- ence on the test data with interval of 10 iterations and compute the mean and standard deviation of the 50 samples from all folds. We compare our model with the three most re- cent unsupervised models we surveyed. The base- line models and settings are as follows.</p><p>Gaussian mixture HMM <ref type="bibr" target="#b3">(Brychcín and Král, 2017)</ref>, based on an HMM, has a characteristic out- put representation: utterance vectors. These vec- tors are generated from Gaussian distributions in- stead of using language models as in most exist- ing models. After following their same prepro- cessing steps, we trained a model on the training data, chose the optimal word vector dimensional- ity on the validation data (among 50, 100, 200, and 300, as used in the original model), and performed inference on the test data. We used the original source code from the authors for training and mod- ified the code for inference.</p><p>MRF-based clustering <ref type="bibr" target="#b5">(Ezen-Can and Boyer, 2015)</ref> considers word order within an utterance to calculate similarity between utterances using an MRF. Then k-medoids clustering is conducted based on the similarity scores, resulting in clus- ters that represent DAs. The similarity score be- tween two utterances is asymmetric, so we took the average value of each direction and inversed it to obtain the distance between two utterances. We trained a model on the training data, chose the optimal parameter values (λ i , λ t , α d in the original paper) on the validation data, and assigned clusters to the test data. We implemented the algorithm since the original code was not available.</p><p>HDP-HMM ( <ref type="bibr" target="#b11">Lee et al., 2013</ref>) is based on an HMM, and each word comes from either the state- specific, general background, or domain-specific language model. HDP-HMM automatically de- cides the number of states using a hierarchical Dirichlet process, but we manually set the num- ber of DAs in our experiment, assuming that we know the number of DAs of interest. We trained a model on the training data and performed infer- ence on the test data; the validation data was not used since there are no parameters to tune. We used the original source code from the authors for training and modified the code for inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Accuracy of DA recognition in terms of homo- geneity, completeness, and v-measure on both cor- pora is summarized in <ref type="table">Table 5</ref>. We also tested the following configurations:</p><p>• CSM + Domain uses true domain labels when learning background topics by force- <ref type="bibr" target="#b3">Brychcín and Král (2017</ref>  <ref type="bibr" target="#b5">Ezen-Can and Boyer (2015)</ref> .03± .00 .37± .00 .05± .00 .26± .00 .33± .00 .28± .00 <ref type="bibr" target="#b11">Lee et al. (2013)</ref> .   fully assigning a conversation the back- ground topic corresponding to the true label.</p><formula xml:id="formula_6">CNET NPS Model H C V H C V</formula><p>• CSM -Speaker does not use speaker prefer- ences by setting ν = 1.</p><p>• CSM -Multi-level ignores multi-level struc- ture; that is, utterances in each conversation are ordered by time.</p><p>• CSM -Background Topics uses only one background topic.</p><p>Overall, our model performs significantly better than the baselines for CNET and marginally better for NPS. The baseline models show a large vari- ance in performance depending on the characteris- tics of the corpus. In contrast, our model has a low variance between the corpora, because the content word filtering, distinction between utterance-level and sentence-level DAs, and speaker preferences complement one another to adapt to different cor- pora. For example, content word filtering and DA level distinction play more significant roles than speaker preferences on CNET, whereas their ef- fects are reversed on NPS. The details will be de- scribed later with qualitative analyses.</p><p>There may be several reasons for the poor per- formance of the baseline models on CNET. First, in our model, each utterance-level DA (latent state) is a probability distribution over sentence- level DAs (foreground topics), which better cap- tures multiple sentence-level DAs in long utter- ances as in CNET. The utterances in CNET are long and may be too complex for the baseline models, which use a simpler representation for utterance-level DAs. Another reason for the low  performance could be that the baseline models do not filter out content words as our model does.</p><p>In the remainder of this section, we describe our qualitative analysis on the results. All examples shown in the analysis are from the result with the optimal parameter values for the first fold.</p><p>Filtering content words Our model effectively separates content words from DA-related words without using the domain label of each conver- sation. As an example, the background topics learned by our model from CNET are shown in <ref type="table" target="#tab_10">Table 6</ref>. These topics are clearly related to the sub- jects of the forum, rather than reflecting DAs, and the topics are distinctive from one another and co- hesive in themselves.</p><p>The main purpose of learning background top- ics is to filter out content words and retain DA- related words as foreground. The learned back- ground topics serve this purpose well, as these top- ics increase v-measure by 0.17 (CSM vs. CSM - Background Topics). It is also promising that the background topics learned without domain labels perform as well as when they are learned with do- main labels (CSM vs. CSM + Domain), because domain labels may not always be available.</p><p>Function words play an important role in DAs in CNET as indicated by the high optimal value of η = 0.86 (the probability of a word being foreground). The higher η means more function words are included in foreground topics, leaving background topics with content words (Section 3). The high η is evidence contrary to the common practice of designating a general background topic to filter out common words and assuming that a word is equally likely to be foreground or back- ground ( <ref type="bibr" target="#b11">Lee et al., 2013;</ref><ref type="bibr" target="#b19">Paul, 2012)</ref>.</p><p>The effectiveness of our method of separat- ing background topics turns out to diminish when there are no consistent conversational top- ics within and across conversations as in NPS. Our model learns not to use background topics (η = 1) for NPS, because background topics may filter out function words and DA-related words that occur more consistently throughout a conversation than content words do.</p><p>Mixture of foreground topics As a conse- quence of filtering out content words, the fore- ground topics reflect various acts in conversa- tion. Some of the learned foreground topics from CNET are shown in <ref type="table" target="#tab_12">Table 7a</ref>. These topics cap- ture important sentence-level DAs that constitute utterance-level DAs that are assigned to each post in CNET. For example, Question-Question is an utterance-level DA that often starts a conversation, and conducting this DA typically includes multi- ple finer-grained acts, such as explaining the en- vironment and situation, asking a question, and thanking, as shown in the post:</p><p>I am currently running Windows XP Media Edi- tion on a 500G hard drive. (FT20) / I want to move my XP to it's own partition, move all Environments (FT20) . i a ##NUMBER## and have - rrb-xp -lrb-: windows my is the dell vista Error msgs (FT12)</p><p>. the # * messages / : it log Asking (FT19) any help you ? ! . appreciated i suggestions Thanking (FT17) thanks . for the ! in advance help your all response Problem (FT8)</p><p>: \file is the c corrupted follow- ing missing or error Wishes (FT14)</p><p>. bob good luck Reference (FT5) ##URL## Praise (FT1)</p><p>. thank you˜sovereignyou˜you˜sovereign , and are excellent recommendations Explanation (FT10) the . to , i and a it you is that of (a) Foreground topics learned from CNET.  FT10 covers explanations and statements, as well as long sentences. The distinction between two levels DAs is effective for CNET, as our model beats the baselines significantly. The foreground topics learned from NPS also reflect DAs in the corpus <ref type="table" target="#tab_12">(Table 7b)</ref>. The distinc- tion between utterance-level and sentence-level DAs is not beneficial for NPS because each ut- terance is short and usually conducts only one DA. As a consequence, the model has difficulty grouping foreground topics (i.e., sentence-level DAs) that are related to one another into the same utterance-level DAs (i.e., states); for CNET, on the other hand, foreground topics that co-occur in the same utterance tend to cluster to the same state.</p><p>The DAs of some foreground topics not shown in <ref type="table" target="#tab_12">Table 7</ref> are difficult to interpret, and those topics possibly capture aspects of sentences other than DAs. However, they do not have undue influence in our model.</p><p>Speaker preferences Speaker preferences sub- stantially increase the v-measure by 0.13 for NPS (CSM vs. CSM -Speaker). Notably, speaker preferences complement the mixture of sentence- level DAs, which is not good at clustering related sentence-level DAs into the same utterance-level DA for short utterances. More specifically, each speaker is modeled to have sparse preferences for utterance-level DAs (i.e., states), so foreground topics used by the same speaker, often represent- ing the same utterance-level DA, tend to cluster to the same state.</p><p>Speaker preferences also capture the character- istic styles of some speakers. Among speakers who are found to have sparse preferences by our model, some actively express reactions and often mark laughter (FT12). Others frequently agree (FT0), greet everyone (FT5), or have many ques- tions (FT7, FT27). Accordingly, the model finds a relatively high optimal weight for speaker prefer- ences in NPS (ν = 0.58).</p><p>In contrast, CNET benefits little from speaker preferences (ν = 1), partly because there is not enough information about each speaker in such short conversations. Speakers also show little pref- erence for DAs as defined in the corpus. For instance, while a conversation initiator tends to ask questions in successive posts, these questions are annotated as different DAs (e.g., Question- Question, Question-Add, Question-Confirmation, etc.) depending on the position of the post within the conversation.</p><p>Multi-level structure Our model's ability to ac- count for multi-level structure improves the accu- racy of DA recognition for both corpora (CSM vs. CSM -Multi-level). For NPS, where multi- level structure is not explicit, this improvement comes from simple heuristics for inferring multi- level structure based on user mentions.</p><p>Sentence length and foreground topics In our model, all words in the same sentence are assigned to the same foreground topic, just as many exist- ing models assign one utterance one topic. Topic assignment is based on similarity of words in a sentence to other sentences in that topic, and short sentences often find similar sentences more easily than long sentences do. Therefore, learned topics tend to be characteristic of short sentences that are similar enough to form the separate topics, and as a result, long sentences may be assigned the same topic regardless of the DA actually performed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented an unsupervised model of DAs in conversation that separates out content words to better capture DA-related words and that incor- porates speaker preferences. Our model also uses a mixture of sentence-level DAs for utterance- level DAs and supports multi-level thread struc- ture. We find that different characteristics of con- versation require different modeling assumptions for DA recognition. Unlike the baseline mod- els, which show a large variance in performance across corpora, our model is robust for both cor- pora used in the evaluation due to the model com- ponents complementing one another. Specifically, content word filtering is found to be effective when each conversation has a consistent conversational topic, and the separation between sentence-level and utterance-level DAs is beneficial for long ut- terances. Speaker preferences are found to be helpful when speakers have characteristic styles of conversation. These findings in addition to the fact that many function words are not filtered out as background may help inform future model design.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FFigure 1 :</head><label>1</label><figDesc>Figure 1: Graphical representation. Shaded nodes represent observable variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>5 :</head><label>5</label><figDesc>Accuracy of DA recognition (the higher the better). Smaller numbers are population standard deviations. (Columns) H: homogeneity, C: completeness, V: v-measure. Optimal parameter values for CSM: # foreground topics=34, η = .86, ν = 1.00 for CNET and # foreground topics=35, η = 1.00, ν = 0.58 for NPS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Properties of baseline models. 
(Columns) Sp: speaker preferences, Tr: DA 
transitions, LM: language models unrelated to 
DAs (G: general background, D: domain-specific, 
U: unspecified), ML: multi-level structure sup-
port, M: mixture of language models for DAs. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Descriptions of counter matrices. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Corpora statistics.</head><label>3</label><figDesc></figDesc><table>CNET 
NPS 

Question-Question 
Accept 
Question-Add 
Bye 
Question-Confirmation 
Clarify 
Question-Correction 
Continuer 
Answer-Answer 
Emotion 
Answer-Add 
Emphasis 
Answer-Confirmation 
Greet 
Answer-Correction 
Reject 
Answer-Objection 
Statement 
Resolution 
System 
Reproduction 
yAnswer 
Other 
nAnswer 
whQuestion 
ynQuestion 
Other 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Dialogue act tags in the corpora.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Background topics learned from CNET. 
(Columns) Left: topic index, right: top 5 words. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Foreground topics learned from the cor-
pora. (Columns) Left: interpretation (topic in-
dex), right: top words truncated for clarity. 

of my files(music, games, work) to another, and 
then install the Windows 7 beta on another parti-
tion. (FT10) / I don't know if this is possible 
or not, but I have access to Partition Magic 8, 
and am wondering if I can do it with that or not. 
(FT10) / I am not worried about installing 7 on 
another partition, but am not sure if I can move 
my files onto a separate one while keeping XP 
intact. (FT10) / Any help is great, thank you. 
(FT17) 

Likewise, the Answer-Answer DA includes finer 
acts such as wishes or URLs, as in the posts: 

Simple -Download and install the Vista Rebel 
XT drivers from canon usa.com. (FT10) / Once 
installed...........go to camera menu and switch the 
communication to Print/PTP. (FT10) / Don't 
forget to switch it back if you're connecting to an 
XP machine. (FT10) / Good Luck (FT14) 

http://forums.microsoft.com/MSDN/ShowPost.aspx? 
PostID=1996406&amp;amp;SiteID=1 (FT5) 

When a problem is resolved, the Resolution DA 
may be performed with thanking and praising: 

Excellent summary Thank you. (FT1) / Sounds 
like at some point it's worth us making the tran-
sition to a CMS... (FT10) </table></figure>

			<note place="foot" n="1"> https://nlp.stanford.edu/projects/ glove/</note>

			<note place="foot" n="3"> Model Our model, CSM (content word filtering and speaker preferences model), is based on an HMM combined with components for content word filtering and speaker preferences. In the model, each latent state represents an utterance-level DA as a mixture of foreground topics, each of which represents a sentence-level DA. Each sentence in an utterance is assigned one foreground topic. To filter content words, there is a set of background topics shared across conversations, and each conversation is assigned a background topic that underlies the whole conversation.</note>

			<note place="foot" n="3"> Some tagging systems, such as the DAMSL-style, break down an utterance that has multiple DAs.</note>

			<note place="foot" n="4"> https://nlp.stanford.edu/software/ lex-parser.html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Kwan-jeong Educational Foundation, NIH grant R01HL122639, and NSF grant IIS-1546393.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards automated personality identification using speech acts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erica</forename><forename type="middle">J</forename><surname>Scott Appling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolph L</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mappus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How to Do Things with Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>John L Austin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DISCUSS: a dialogue move taxonomy layered over semantic representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Van Vuuren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Computational Semantics</title>
		<meeting>the Ninth International Conference on Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="310" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised dialogue act induction using gaussian mixtures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Brychcín</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Král</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="485" to="490" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic coding of dialogue acts in collaboration protocols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gijsbert</forename><surname>Erkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Janssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer-Supported Collaborative Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="447" to="470" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding Student Language: An Unsupervised Dialogue Act Classification Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristy</forename><forename type="middle">Elizabeth</forename><surname>Aysu Ezen-Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Boyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JEDMJournal of Educational Data Mining</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="78" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lexical and Discourse Analysis of Online Chat Dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig H</forename><surname>Forsythand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Semantic Computing (ICSC 2007)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Soup: A Parser for RealWorld Spontaneous Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marsal</forename><surname>Gavaldà</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
			<pubPlace>Netherlands, Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised Modeling of Dialog Acts in Asynchronous Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Volume Three</title>
		<meeting>the Twenty-Second International Joint Conference on Artificial Intelligence-Volume Volume Three</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1807" to="1813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic detection of discourse structure for speech recognition and understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Meteer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Workshop on Automatic Speech Recognition and Understanding Proceedings</title>
		<imprint>
			<biblScope unit="page" from="88" to="95" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tagging and Linking Web Forum Posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="192" to="202" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised Spoken Language Understanding for a Multi-Domain Dialog System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungduk</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonghan</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary Geunbae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2451" to="2464" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conversational structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephen C Levinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pragmatics, chapter 6</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1983" />
			<biblScope unit="page" from="284" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Correlations between dialogue acts and learning in spoken tutoring dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Diane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Forbes-Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">02</biblScope>
			<biblScope unit="page" from="161" to="176" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Andrew Olney, and the Tutoring Research Group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Louwerse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Art</forename><surname>Graesser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Good Computational Manners: Mixed-Initiative Dialog in Conversational Agents. Etiquette for Human-Computer Work: Papers from the AAAI Fall Symposium</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="71" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Negotiation: interacting in dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Century Series. Bloomsbury Academic</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Topic Independent Identification of Agreement and Disagreement in Social Media Dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amita</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Slice sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="705" to="767" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A Multi-classifier Approach to Dialogue Act Classification Using Function Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuhair</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keeley</forename><surname>Bandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Crockett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg; Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mixed membership markov models for unsupervised conversation modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="94" to="104" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Unsupervised Modeling of Twitter Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="172" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">VMeasure: A Conditional Entropy-Based External Cluster Evaluation Measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="410" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Conversation Analysis: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sidnell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Language in Society. Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Speech Acts for Dialogue Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Traum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Springer</publisher>
			<pubPlace>Netherlands, Dordrecht</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Tweet Acts : A Speech Act Classifier for Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th AAAI Conference on Weblogs and Social Media</title>
		<meeting>the 10th AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note>ICWSM</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Understanding Computers and Cognition: A New Foundation for Design. Language and being</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Flores</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Ablex Publishing Corporation</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relationship between dialogue acts and hot spots in meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Britta</forename><surname>Wrede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="180" to="185" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
