<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:54+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems for Speech Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Blackwood</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM T. J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Trmal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CLSP &amp; HLTCOE</orgName>
								<orgName type="institution" key="instit2">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems for Speech Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Speech translation is conventionally carried out by cascading an automatic speech recognition (ASR) and a statistical machine translation (SMT) system. The hypotheses chosen for translation are based on the ASR system&apos;s acoustic and language model scores, and typically optimized for word error rate, ignoring the intended downstream use: automatic translation. In this paper, we present a coarse-to-fine model that uses features from the ASR and SMT systems to optimize this coupling. We demonstrate that several standard features utilized by ASR and SMT systems can be used in such a model at the speech-translation interface, and we provide empirical results on the Fisher Spanish-English speech translation corpus .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Speech translation is the process of translating speech in the source language to text or speech in the target language. This process is typically structured as a three step pipeline.</p><p>Step one in- volves training an Automatic Speech Recognition (ASR) system to transcribe speech to text in the source language.</p><p>Step two involves extracting an appropriate form of the ASR output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to trans- late. It may be useful to consider alternative ASR hypotheses and these take the form of an N -best list or a word-lattice. An N -best list can be in- cluded easily into the tuning and the decoding pro- cess of a statistical machine translation (SMT) sys- tem ( <ref type="bibr" target="#b15">Zhang et al., 2004</ref>). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process ( <ref type="bibr" target="#b12">Saleem et al., 2004;</ref><ref type="bibr" target="#b7">Matusov et al., 2005</ref>; Bangalore and <ref type="bibr" target="#b0">Riccardi, 2000;</ref><ref type="bibr" target="#b3">Dyer et al., 2008a;</ref><ref type="bibr" target="#b1">Bertoldi and Federico, 2005;</ref><ref type="bibr" target="#b11">Quan et al., 2005;</ref><ref type="bibr" target="#b6">Mathias and Byrne, 2006;</ref>. Word lattice input to SMT for tuning and decoding increases the com- plexity of the decoding process because of the ex- ponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface.</p><p>This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows:</p><p>1. Using downstream information : Hypoth- esis selection for the input to the SMT sys- tem should be done jointly by the ASR and the SMT systems. That is, there may exist hypotheses that a trained SMT system may find easier to translate and produce better translations for than the ones that are deemed best based on the ASR acoustic and language model scores. Incorporation of knowledge from the downstream process (translation) is vital to selecting translation options, and sub- sequently producing better translations.</p><p>2. Coarse-to-fine grained decoding : An in- termediate model which acts as an interface and is a weak (coarse) version of the down- stream process may be able to select better hypotheses. In effect, a weak translation de- coder can be used as the interface to estimate the expected translation quality of an ASR hypothesis. This method of hypothesis se- lection should be able to incorporate features from the ASR and the SMT system.</p><p>3. Phrase units vs. word units : When a phrase based SMT system is used for translation, optimization for hypothesis selection at the Speech-Translation interface should be con- ducted using phrases as the basic unit instead of words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Coarse-to-Fine Speech Translation</head><p>In this section, we describe the featurized model (coarse-grain MT decoder) for hypothesis selec- tion that uses information from the ASR and SMT systems (impedance matching). We assume the presence of ASR and SMT systems that have been trained separately. In addition to creating almost no disruption in the traditional pipeline approach, this allows us to incorporate local gains from each system. To elaborate, our methods avoid joint op- timization of the ASR and the SMT system with respect to a translation metric <ref type="bibr" target="#b13">(Vidal, 1997;</ref><ref type="bibr" target="#b8">Ney, 1999</ref>), which is not feasible for larger datasets. Also, considering the dearth of speech translation training datasets, this method allows independent training of the ASR and SMT systems on data cre- ated only for ASR training and parallel data for SMT. We start by introducing the formal machin- ery that will be used and by presenting a simple example to motivate the model. The complete fea- turized model follows this exposition. Let Σ and Γ be alphabets of words and phrases respectively in the source language. Using these, we can define the following finite state machines:</p><p>1. Word Lattice (L) : A finite state accep- tor that accepts word-sequences in the source language ( L : Σ * → Σ * ). This represents the unpruned ASR word lattice output in our model ( <ref type="figure">Figure 1a</ref>).</p><p>2. Phrase segmentation Transducer (S) : A cyclic finite state transducer that transduces a sequence of words to phrases in the source language (S : Σ * → Γ * ). This is built from the source side of the phrase table. Each path represents one source side phrase in the phrase table. Traversing a path is equivalent to consuming the words in a phrase and pro- ducing the phrase as a token <ref type="figure">(Figure 1b</ref>).</p><formula xml:id="formula_0">3. Weighted word lattice ( ˜ L ASR ) : A weighted version of L ( ˜ L ASR : Σ * → Σ * /R + )</formula><p>. We use the subscript to denote the nature/source of the weights. </p><formula xml:id="formula_1">P = det(min(L • S))</formula><p>We will represent weighted versions of P as˜P as˜ as˜P ASR/M T with subscripts to denote the ori- gin of the weights ( <ref type="figure">Figure 1c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">A simple model : Maximum Spanning Phrases</head><p>We motivate our model with this fairly simple scenario. Suppose that we believe that if our SMT input could be covered by longer source side phrases 1 , we would produce better translations. This may be viewed as a tiling problem where the tiles are the source phrases in the phrase table and the goal is to select the ASR hypothesis that re- quires the least number of phrases to cover 2 . To achieve this using our existing machinery, we cre- ate˜Sate˜ ate˜S, a weighted version of S <ref type="figure">(Figure 1 (b)</ref>), such that w(δ ( ˜ S) ) = 0 : π 1 (δ (S) ) ∈ Σ and π 2 (δ (S) ) = 1 : π 2 (δ (S) ) ∈ Γ and π 1 (δ (S) ) = where δ ( ˜ S) is an edge iñ S and π 1 and π 2 are the in- put and output projections respectively. Using this segmentation transducer and an unweighted word lattice, L ( <ref type="figure">Figure : 1 (a)</ref>), we produce a phrase lattice˜Plattice˜ lattice˜P M T . Assuming the weights are in the log- semiring, the weight of a path</p><formula xml:id="formula_2">δ ( ˜ P ) * iñ P M T is w(δ ( ˜ P ) * ) = δ ( ˜ P ) ∈δ ( ˜ P ) * w(δ ( ˜ P )</formula><p>) <ref type="figure">Figure 1</ref>(c) shows an example of this phrase lat- tice. Weights in the phrase lattice follow the same definition as the weights in the segmentation trans- ducer. Hence, the weight of a path in the phrase lattice is simply the number of phrases used to cover this path. The shortest path 3 in the phrase lattice˜Plattice˜ lattice˜P M T , corresponds to the hypothesis we were looking for. This simple example, demon- strates how we may be able to use SMT features (source phrase length in this case) to select hy- potheses from the phrase lattice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">A general featurized model for hypothesis selection</head><p>We now present a general framework in which hypothesis selection can be carried out using knowledge (features) from the ASR and the SMT system. As described earlier, this form of 'impedance' matching allows us to select hypothe- ses from an unpruned ASR word lattice for which the SMT system is more likely to find good trans- lations. Incorporating ASR weights also ensures that we take into account what the ASR system considers to be good hypotheses. We start with the previously discussed idea of a phrase lattice, using weights from the ASR system only. That is,</p><formula xml:id="formula_3">˜ P ASR = det(min( ˜ L ASR • S))</formula><p>Now, we use the weighted phrase acceptor˜Wacceptor˜ acceptor˜W M T to bring in the SMT features <ref type="bibr">4</ref> . Composing this with the weighted phrase lattice, we get˜P</p><formula xml:id="formula_4">get˜ get˜P ASR,M T = det(min( ˜ P ASR • ( ˜ W M T ) * )</formula><p>where ( ˜ W M T ) * is the Kleene closure of ( ˜ W M T ). We assume that the edge weights are in the log- semiring. Hence, after these two compositions, the edge weights iñ P ASR,M T can be represented as</p><formula xml:id="formula_5">w(δ ( ˜ P ASR,M T ) ) = j β j f j,ASR + k γ k f k,M T = i λ i f i</formula><p>where δ ( ˜ P ASR,M T ) is an edge iñ P ASR,M T , β, γ are feature weights, f ASR and f M T are features from the ASR and SMT system respectively. This form represents a log-linear model (our features are al- ready assumed to be in log-space). where f i is any feature and λ i is the corresponding feature weight. We may now extract the one-best, N -best or lattice input for the SMT system from˜Pfrom˜ from˜P ASR,M T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">A discussion about related techniques</head><p>1. Decoding (Translation) : Our model closely resembles a featurized finite-state transducer based translation model. If we replace the output alphabet of the acceptor ( ˜ W M T ) * with the target side phrases, we will actually get output in the target language. Even though this model does not explicity include reorder- ing, the coarse-grained decoder has access to information that can enable better deci- sions about which hypotheses are better for the downstream process (translation).</p><p>2. Lattice Decoding : <ref type="bibr" target="#b4">(Dyer et al., 2008b</ref>) sug- gests passing the entire word lattice to the SMT system. However, even if these lattices are not pruned, a beam based decoder might not consider hypotheses that our model may produce through coarse-grained decoding.</p><p>3. Language model re-scoring : One may use a bigger source language model to re-score the ASR lattice (or an N -best list). This how- ever, does not consider any SMT features in re-scoring. With our model, we can simply use this as an additional feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Training</head><p>Training the hypothesis selection model can be carried out using standard methods for log linear models on a held-out set. This also requires decod- ing (translation) of a deep N -best list derived from the held-out set. The objective of training then simply becomes maximization of the translation quality given any metric that provides sentence level scores. Each time our model produces a hy- pothesis, its score can be looked up from the pre- translated N -best list. Also, whenever the weights are updated, the only structures that need to be re- built are˜Ware˜ are˜W * M T and˜Pand˜ and˜P ASR,M T 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Features</head><p>We use the following features in our implementa- tion of this model. However, any relevant ASR and SMT feature may be readily added to this model.</p><p>1. ASR scores : We incorporate the ASR acous- tic (AM) and language (LM) model scores as one combined feature.</p><formula xml:id="formula_6">f ASR = LM + α * AM</formula><p>Here, LM, AM are negative log- probabilities and α is the acoustic scaling parameter chosen to minimize ASR word error rate.</p><p>2. Source phrase count : As described in sec- tion 2.1, this feature may be used to cap- ture the intuition that using a fewer number of phrases to cover the input sentence may produce better translations.</p><p>3. Length normalized phrase unigram prob- ability : We may use a phrase LM feature by incorporating phrase n-gram probabilities (normalized) by length.</p><formula xml:id="formula_7">f uni (f j ) =   freq(f j ) k freq(f k )   len(f j )</formula><p>where f j is a source side phrase in the phrase table.</p><p>4. Phrase translation entropy : For each source side phrase p j , we may have multiple translations (e i ) in the phrase table with dif- ferent translation probabilities (p(e i |f j )). A simple entropy measure can be used as a fea- ture to estimate the confidence that the SMT system has in translating f j .</p><formula xml:id="formula_8">f tr (p j ) = H tr (E|p j ) = − i p tr (e i |f j ) log p tr (e i |f j )</formula><p>5. Lexical translation entropy : Similarly, we can use an entropy measure based on the lex- ical translation probability as a feature.</p><formula xml:id="formula_9">f lex (p j ) = H lex (E|p j ) = − i p lex (e i |f j ) log p lex (e i |f j )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We use the Fisher and Callhome Spanish-English Speech Translation Corpus (Post et al., 2013) for our experiments. This Fisher dataset consists of 819 transcribed and translated telephone conver- sations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model. We use the Kaldi speech recognition tools <ref type="bibr" target="#b10">(Povey et al., 2011</ref>) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of ( <ref type="bibr" target="#b16">Zhang et al., 2014</ref>). The word- error-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29.80%, 29.79% and 25.30% respectively. For the SMT system, we use the phrase based translation system of Moses ( <ref type="bibr" target="#b5">Koehn et al., 2007</ref>) with sparse features. The system is trained and tuned on the train and dev partitions of the Fisher dataset respectively. The BLEU scores of the MT output for the the dev-2 and the test partitions are 65.38% and 62.91% respectively. While decoding the ASR output, we tune on the 1-best ASR output for the dev partition. With this modified system, the BLEU scores for the ASR 1-best output of the dev2 and the test partitions are 40.06% and 40.4% respectively. We use this system as the baseline for our experiments <ref type="table">(Table 1)</ref>. We note that if we were to use the lattice oracle 6 from our ASR system as input to the SMT system, we get a BLEU score of 46.59% for the dev2 par- tition of the Fisher dataset. This indicates that the best gain (+BLEU) that an oracle lattice reranker could get is only 6.53%.</p><p>To tune the weights of the coarse decoder, we decode 500-best ASR outputs for the tuning set with the SMT system. This maps each ASR hy- pothesis to a target language translation. An OOV feature was added to handle words that were not seen by the SMT system. The tuning process was then carried out so as to maximize the BLEU with Experiment BLEU (dev2) BLEU (test) Transcripts 65.4% 62.9% Lattice Oracle 46.59% 46.17% ASR 1-best 40.06% 40.4% Coarse decoder 40.26% 40.46% <ref type="table">Table 1</ref>: Performance when using the coarse de- coder interface compared to the the decoding the human transcripts, the ASR 1-best or the lattice oracle (the path in the ASR lattice with the least WER : not available during test time.) respect to the reference translation of the ASR hy- pothesis selected by the coarse grained decoder. We used ZMERT (Zaidan, 2009) for tuning which was configured to expect a 300-best list from the decoder at every iteration using the Fisher dev set. 15 iterations of tuning were carried out for each experiment. We then use the tuned weight vec- tor to decode the Fisher-dev2 and the Fisher-test set using our coarse grained decoder. We extract the one-best output and use it as input to the pre- trained SMT system (description in the preceding section). <ref type="table">Table 1</ref> reports the results achieved the featurized coarse grained decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We present a coarse-to-fine featurized model which acts as the interface between ASR and SMT systems. By utilizing information from the up- stream (ASR) and the downstream (SMT) sys- tems, this model makes more informed decisions about which hypotheses from the ASR word lat- tice may result in better translation results. More- over, the model takes the form of a coarse finite state transducer based translation decoder which imitates the downstream system. This enables it to estimate translation quality even before the com- plete SMT system is used for decoding. Finally, the proposed model is featurized and may accept any weight from the ASR and SMT system that are deemed useful for optimizing translation quality. The Spanish Fisher corpus is one of a few con- versational speech translation datasets available, and we start with a strong baseline system. We therefore persevere with the experimental setup described above, even though the maximum (ora- cle) improvement by any rescoring method is only 6.5% BLEU, as noted above. This partially ex- plains the small gains reported here, and suggests that this method should be evaluated further on an- other corpus, e.g. the Egyptian Arabic translation dataset, with greater headroom for improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4 .Figure 1 :</head><label>41</label><figDesc>Figure 1: A toy example for producing a phrase length weighted phrase lattice. (a) An unweighted word lattice. (b) A phrase segmentation transducer which transduces words to phrases and has a weight of one per path. Each path is a source phrase in the phrase table. (c) A phrase lattice produced by composing the word lattice and phrase segmentation transducer.</figDesc><graphic url="image-1.png" coords="2,305.52,62.38,221.81,85.82" type="bitmap" /></figure>

			<note place="foot" n="1"> In phrase based translation, target translations are produced for each possible span of the input sentence allowed by the phrase table. Translation of a longer source side phrase produces fewer translation options and may be more reliable given sufficient occurrences in the training data. 2 It may be useful to incorporate a brevity penalty here, since this approach has a strong bias towards selecting shorter hypotheses. We will use other features to counter this bias in the following sections.</note>

			<note place="foot" n="3"> To compute the shortest path, we switch from the log to the tropical semiring (A semiring with ordinary addition as the multiplication operator and max as the addition operator). 4 Alternatively, we may have introduced the weights in the segmentation transducer itself. This separate machine is introduced for efficient training of this model.</note>

			<note place="foot" n="5"> This requires the use of one ASR feature, addressed in the &quot;Features&quot; section</note>

			<note place="foot" n="6"> Path in the lattice that has the least word error rate.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially supported by NSF award No ¯ IIS 0963898 and DARPA contracts No ¯ HR0011-12-C-0015 and HR0011-51-6285. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of NSF, DARPA or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Finite-state models for lexical reordering in spoken language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Bangalore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Riccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Conference on Spoken Language Processing</title>
		<meeting>the Sixth International Conference on Spoken Language Processing</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="422" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A new decoder for spoken language translation based on confusion networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Workshop on Automatic Speech Recognition and Understanding</title>
		<meeting>the IEEE Workshop on Automatic Speech Recognition and Understanding</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="86" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Speech translation by confusion network decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference in Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">IV</biblScope>
			<biblScope unit="page" from="1297" to="1300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generalizing word lattice translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="1012" to="1020" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-08: HLT</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Generalizing word lattice translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07</title>
		<meeting>the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL &apos;07<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Statistical phrasebased speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference in Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">I</biblScope>
			<biblScope unit="page" from="561" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the integration of speech recognition and statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Kanthak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th European Conference on Speech Communication and Technology</title>
		<meeting>the 9th European Conference on Speech Communication and Technology</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3177" to="3180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Speech translation: coupling of recognition and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference in Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1999-03" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="517" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">General lattice decoding for improved speech-to-text translation with the Fisher and Callhome Spanish-English speech translation corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damianos</forename><surname>Karakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Chris Callison-Burch, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Kaldi speech recognition toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Silovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Stemmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Vesely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 2011 Workshop on Automatic Speech Recognition and Understanding</title>
		<imprint>
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Integrated n-best re-ranking for spoken language translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Vu H Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cettolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th European Conference on Speech Communication and Technology</title>
		<meeting>the 9th European Conference on Speech Communication and Technology</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3181" to="3184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using word lattice information for a tighter coupling in speech translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirin</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szu-Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Jou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Spoken Language Processing</title>
		<meeting>the International Conference on Spoken Language Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Finite-state speech-to-speech translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing</title>
		<meeting>the IEEE International Conference in Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1997-04" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="111" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">F</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="79" to="88" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A unified approach in speech-to-speech translation: integrating features of speech recognition and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genichiro</forename><surname>Kikui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirofumi</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><forename type="middle">Kit</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving deep neural network acoustic models using generalized maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Trmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-05-04" />
			<biblScope unit="page" from="215" to="219" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
