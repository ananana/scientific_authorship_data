<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MoodSwipe: A Soft Keyboard that Suggests Messages Based on User-Specified Emotions</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Yang</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tristan</forename><surname>Labetoulle</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IMT Atlantique</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Hao</forename></persName>
							<email>tinghaoh@cs.cmu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Pei</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Chen</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vallari</forename><surname>Srivastava</surname></persName>
							<email>vallari357@gmail.com</email>
							<affiliation key="aff3">
								<orgName type="department">Institute of Engineering &amp; Technology</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Academia Sinica</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MoodSwipe: A Soft Keyboard that Suggests Messages Based on User-Specified Emotions</title>
					</analytic>
					<monogr>
						<title level="j" type="main">EMNLP System Demonstrations</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="73" to="78"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present MoodSwipe, a soft keyboard that suggests text messages given the user-specified emotions utilizing the real dialog data. The aim of MoodSwipe is to create a convenient user interface to enjoy the technology of emotion classification and text suggestion, and at the same time to collect labeled data automatically for developing more advanced technologies. While users select the MoodSwipe keyboard, they can type as usual but sense the emotion conveyed by their text and receive suggestions for their message as a benefit. In MoodSwipe, the detected emotions serve as the medium for suggested texts, where viewing the latter is the incentive to correcting the former. We conduct several experiments to show the superiority of the emotion classification models trained on the dialog data, and further to verify good emotion cues are important context for text suggestion.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowing how and when to express emotion is a key component of emotional intelligence <ref type="bibr" target="#b18">(Salovey and Mayer, 1990)</ref>. Effective leaders are good at expressing emotions <ref type="bibr" target="#b1">(Bachman, 1988)</ref>; expressing positive emotions in group activities improves group cooperation, fairness, and overall group performance ( <ref type="bibr" target="#b2">Barsade and Gibson, 1998)</ref>; and expressing negative emotions can promote re- lationships ( <ref type="bibr" target="#b8">Graham et al., 2008)</ref>. However, in the mobile device era where text-based commu- nication is part of life, technologies are rarely utilized to assist users to express their emotions properly via text. For instance, business people in heated disputes with their clients may need assistance to rephrase their angry messages into neutral descriptions before sending them. Sim- ilarly, people may have trouble finding the per- fect words to show how much they appreciate a friend's help. Or people may want to deliberately express anger to extract concessions in negotia- tions, or to make a joke, such as with the "Obama's Anger Translator" skit, in which the comedian "translates" the U.S. President's calm statements into emotional tirades. While emotion classifi- cation has been used in helping users to better understand other people's emotions ( <ref type="bibr" target="#b21">Wang et al., 2016;</ref><ref type="bibr" target="#b10">Huang et al., 2017)</ref>, these technologies have rarely been used to support user needs in express- ing emotions. Most prior work focuses on inter- face design, for instance using kinetic typography or dynamic text <ref type="bibr" target="#b3">(Bodine and Pignol, 2003;</ref><ref type="bibr" target="#b7">Forlizzi et al., 2003;</ref><ref type="bibr" target="#b13">Lee et al., 2006</ref>) , affective but- tons <ref type="bibr" target="#b4">(Broekens and Brinkman, 2009)</ref>, or text color and emoticons <ref type="bibr">(Sánchez et al., 2006</ref>) to enable emotion expression in instant messengers. Other work explores the relations between user typing patterns and their emotions ( <ref type="bibr">Zimmermann et al., 2003;</ref><ref type="bibr" target="#b0">Alepis et al., 2006;</ref><ref type="bibr" target="#b20">Tech, 2016)</ref>. However, the text itself is still the essential part of text-based communication; visual cues and typing patterns are only minor factors. Other work even describes attempts to incorporate body signals such as fluc- tuating skin conductivity levels ( <ref type="bibr" target="#b5">DiMicco et al., 2002</ref>), thermal feedback ( <ref type="bibr" target="#b22">Wilson et al., 2016)</ref>, or facial expressions (El <ref type="bibr" target="#b6">Kaliouby and Robinson, 2004</ref>) to enrich emotion expression, but these re- quire additional equipment and are less scalable.</p><p>In this paper we introduce MoodSwipe 1 , a soft keyboard that automatically suggests text accord- ing to user-specified emotions. As shown in <ref type="figure">Fig- ure 1</ref> Figure 1: The user interface of MoodSwipe keyboard, which includes a standard soft keyboard, a color bar above the keyboard, and a circle button to the right of the color bar. Users swipe the color bar to specify their emotions and view the messages suggested for different emotions.</p><p>the keyboard, and immediately shows the detected emotion of the input message. Seven emotions (Anger, Joy, Sadness, Fear, Anticipation, Tired and Neutral) are detected and presented by their corresponding colors as defined by the research of psychologists and user studies ( <ref type="bibr" target="#b21">Wang et al., 2016)</ref>. Users swipe the color bar to change the detected emotion according to their mood and view the messages suggested for different emo- tions. For example, if the user types "I disagree," MoodSwipe suggests a relevant message telling the user how one would say the same thing when he or she is happy, sad, or angry.</p><p>The contributions of this work are three-fold. First, we address the long-standing challenge of collecting self-reported emotion labels for dialog messages. Unlike posts on social media, where users often spontaneously tag their own emotions, self-reported emotion labels for dialog messages are expensive to collect. Users often feel disturbed when they are asked to annotate their own emo- tions on the fly. MoodSwipe provides a handy service which is entertaining and easy to use. It provides a natural incentive for users to label their own emotions on the spot. Second, MoodSwipe closes the loop of bi-directional interactive emo- tion sensing. Most prior work powered by emo- tion detection focused on helping users when re- ceiving messages ( <ref type="bibr" target="#b21">Wang et al., 2016</ref>) instead of when sending them. MoodSwipe enables auto- I'm fine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Color</head><p>Figure 2: Mapping between colors and emotions, and example suggestion texts for "I am fine." mated support, helping users express their emo- tions in text, and therefore supplies the missing piece for an emotion-sensitive text-based commu- nication environment. Finally, MoodSwipe in- troduces a new interaction paradigm, in which users explicitly provide feedback to systems about why they select this suggested response. Clas- sic response suggestion tasks such as dialog gen- eration ( ) or automated email re- ply ( <ref type="bibr" target="#b11">Kannan et al., 2016)</ref> assume that the in-the- moment context of each user (e.g., the current emotion) is unknown. MoodSwipe opens up pos- sibilities for users to explicitly and actively pro- vide context on the fly, which the automated mod- els can use to provide better suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The MoodSwipe Keyboard</head><p>The user interface and workflow of MoodSwipe are shown in <ref type="figure">Figure 1</ref>. The MoodSwipe keyboard interface contains three major parts: (i) a standard soft keyboard, (ii) a color bar above the keyboard, and (iii) a circle button to the right of the color bar. When the user starts typing, MoodSwipe de- tects the emotion of the input text in real time, and the color bar background changes color on-the-fly to reflect the current emotion of the user input text. MoodSwipe's seven emotions and their colors are shown in <ref type="figure">Figure 2</ref>, which was developed based on psychological work and user studies ( <ref type="bibr" target="#b21">Wang et al., 2016)</ref>. Based on the emotion MoodSwipe cur- rently displays, the color bar also shows the user the suggested text. Those suggested messages for the input "I am fine" are also listed in <ref type="figure">Figure 2</ref>.</p><p>When the user swipes the color bar, one of MoodSwipe's seven emotion colors is brought up in descending order of the classification probabil- ity for the input message. The user swipes right to see the predicted emotion with a lower proba- bility and its suggested text, or swipes left to see the previous one. In <ref type="figure">Figure 1</ref>, the user types "Why don't you come?" and MoodSwipe detects Anger (red) and suggests "Then tell me why you don't come!". The user swipes right to see the option "Ohhhh why cannot you come?" for emotion Sad- ness (blue). The user keeps swiping until he or she reaches a suitable message ("Oh!! But...why don't you come I don't want to go alone!") and then clicks the circle button at color bar's right side to replaces the user input with the suggested text. Then with this replacement, the user self-reports that the emotion label of the user's message "Why don't you come?" should be more Fear (green) than Anger (red) in the current dialog context.</p><p>MoodSwipe actively triggers emotion detec- tion and updates color accordingly when the user presses the spacebar, which usually indicates the completion of a word, or has a 500ms pause after the last user input. To lighten server loads and re- duce possible conflicts with the second condition, the minimum time interval between two triggers is set at 400ms. All users activities are recorded, in- cluding typed text, suggested texts, emotion labels selected/abandoned, and all the timestamps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Use Cases</head><p>In this section we outline several possible use cases of MoodSwipe. First, MoodSwipe can help users to better understand their own messages' emotions perceived by other users. Our prior study <ref type="bibr" target="#b10">(Huang et al., 2017)</ref> shows that not all users are clearly aware of what emotion their messages will convey. In this scenario, MoodSwipe is able to act as an early assistant or reminder when com- posing a message. Second, MoodSwipe can assist users to better express themselves when "words fail me." Sometimes users could experience strong emotions and have difficulty in finding good ways to express themselves via text, and they can type keywords into MoodSwipe to search for better messages from its dialog database.</p><note type="other">Third, users can alternate the perceived emotions in their own texts for various purposes. For instance, some people might need assistance to rephrase their angry messages into neutral descriptions, and some people may want to deliberately express anger to extract concessions in negotiations. Fi- nally, MoodSwipe can be used as a tool to help new users quickly adapt to the language style of a community. MoodSwipe is powered by mes- sages that were collected from young IM users. An elder new user who is not very familiar with the language styles of the young generation can use MoodSwipe to rephrase his/her sentence so that it can be better received by young users.</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Back-end System, Experiments and Discussions</head><p>Two major functions of the MoodSwipe keyboard are to guess for the users the emotion of their cur- rent text message and to provide text suggestions based on that. In this section, we describe sev- eral models we developed and different settings used to evaluate their performance. Our advan- tage in conducting these experiments comes from our emotion-based chat app EmotionPush ( <ref type="bibr" target="#b21">Wang et al., 2016</ref>) and the social dialogs it has collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Materials</head><p>For the experiments, we adopted the Emotion- Push dataset (available soon). A total number of 162,031 message logs were collected for this dataset. To evaluate the performance of emotion classification, we had native speakers manually la- bel the emotions of the randomly selected 8,818 messages. These manual emotion attribute were all chosen from the seven emotion labels defined for the keyboard. Among these 8,818 emotion la- beled messages, 70% were for training, 10% for validation and 20% for testing. Two different emo- tion corpus, LJ40K (Yang and Liu, 2013) and the tweet data, are utilized for comparison. LJ40K contains 40 emotions and for each of the emotions, 1,000 blogs are collected. The 40 emotions are then mapped to the 7 emotions according to our previous work ( <ref type="bibr" target="#b21">Wang et al., 2016</ref>). On the other hand, the tweet data is built by Twitter streaming API 2 with a filter of using the 40 emotions as hash- tag. A total number of 19,480 tweets are collected and further categorized into 7 emotions. The text message suggestion function provided by MoodSwipe recommends responses given the input text message and its corresponding emotion label from users. For the experiments, we selected messages from the labeled 8,818 messages accord- ing to two rules: 1) to ensure a proper turn, the pre- vious message must be sent from another user in- stead of the same message owner, and 2) the emo- tion label must not be neutral. We drop a small number of short messages containing hindi or pure punctuation (e.g., "!!!") for which text suggestions cannot be found, as in these cases we are unable to evaluate the performance of different settings. A total of 1,366 messages were collected for the sen- tence suggestion experiment <ref type="bibr">(707 Joy, 223 Anger, 189 Sadness, 124 Anticipation, 72 Fear and 51 Tired)</ref>. For the evaluation, text suggestions are generated for these messages using MoodSwipe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Emotion Classification</head><p>Two models are developed for emotion classifi- cation: the general CNN <ref type="bibr" target="#b12">(Kim, 2014</ref>) with 125 filters, including 25 filters for each filter length ranging from 1 to 5, and the LSTM <ref type="bibr" target="#b9">(Hochreiter and Schmidhuber, 1997)</ref>. These two models are trained on blog data, tweet data, and our dialog data, respectively, and then tested on the dialog data. In <ref type="table">Table 1</ref> we report the results of three major emotions with these two models, as the other emo- tions are minor and the training data insufficient to build a reliable model (anticipation 1.77%, tired 0.8%, fear 1.19%, total 3.77%). Only accuracies trained on the dialog data for three major emotions are all over 0.9 (see CNN 3 and LSTM 3 ), which supports the use of dialogs in MoodSwipe. Con- sidering time-consuming issue, we adopted CNN as the final model for MoodSwipe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Text Suggestion &amp; Results</head><p>The purpose of the experiments for test message suggestion is to determine whether the system generates better suggested texts given the user- specified emotion. We designed a retrieval-based model utilizing Lucene ( <ref type="bibr" target="#b16">McCandless et al., 2010)</ref> 2 https://dev.twitter.com/streaming/ overview</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Joy Anger Sadness Neutral ( <ref type="bibr" target="#b21">Wang et al., 2016</ref>  <ref type="table">Table 1</ref>: Accuracy of the emotion classification task tested on dialog data while trained on blog 1 , tweet 2 and dialog 3 data. and then applied it on the EmotionPush dataset which contains 162,031 social dialog messages. When searching for similar messages, Lucene first applies term matching on the dataset using query message. Messages containing at least one same word would be candidates which is then ranked by BM25 ( <ref type="bibr" target="#b17">Robertson et al., 2009</ref>). When the user re- ceived a message and is composing a response, the user manually specifies an emotion (e.g., Anger) that he/she wants to convey in the message, and the following two settings for generating responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">[Baseline]:</head><p>Given the message that the user received, MoodSwipe first retrieves its most similar message (by Lucene) from the database, and then returns the response of that retrieved message as the suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>[+Emotion]: The procedure is identical as <ref type="bibr">[Baseline]</ref>, just that the suggested text must convey the user-specified emotion. For instance, if the user specifies Anger, MoodSwipe takes the message that the user received and from database finds its most similar message whose response's emotion is labelled as Anger as the suggestion.</p><p>Note that the emotions in our database are anno- tated by automatic algorithms instead of humans.</p><p>To assess the quality of suggested messages in each setting, we used the 1,366 messages collected in sentence suggestion experiment to conduct hu- man evaluations with crowd workers recruited via Amazon Mechanical Turk. For each message, we first show the crowd workers its 10 previous mes- sages in the original chat log. We then show the following three messages, in a random order, as the follow-up line candidates of the displayed chat log: 1) the actual user input response, 2) the suggested texts in <ref type="bibr">[Baseline]</ref>, and 3) the sug- gested texts in <ref type="bibr">[+Emotion]</ref>. Workers are asked to rank these three candidate messages based on their   clarity, comfort, and responsiveness of being the follow-up line of the given chat log ( <ref type="bibr" target="#b15">Liu et al., 2010</ref>) (rank = 1, 2, or 3. Lower is better.) For each message, we recruit 5 workers and average their results. <ref type="table" target="#tab_3">Table 2</ref> shows the average ranking and the "Good Suggestion Rate" of each setting, which is the proportion of the suggested messages that have a better (lower) ranking than the original user input response. While the original input re- sponses still have a better (lower) average ranking, <ref type="table" target="#tab_3">Table 2</ref> shows that 26% to 28% of the suggested texts are considered good by crowd workers and thus could be useful to users. Results also show that the [+Emotion] setting on average generates slightly better suggestions than <ref type="bibr">[Baseline]</ref> setting in all three aspects. With the consideration that in the three evalua- tion aspects comfort is most relevant to emotions, we further analyze the comfort result of each emo- tion <ref type="table" target="#tab_4">(Table 3.</ref>) Among all emotions, the Good Suggestion Rates for Anger messages are the high- est (40.36% and 37.49%), which are even much higher than the average rates (about 28% as shown in <ref type="table" target="#tab_3">Table 2</ref>). This result suggests that our method is particularly useful for expressing Anger emotions.</p><p>These results show the potential benefits of in- cluding emotion signals in a response sugges- tion application. While the simple retrieval-based model (where emotions act only as "filters") may be of limited use, MoodSwipe is still able to sug- gest responses that are better than the user re- sponses around 25% of time. We believe that when MoodSwipe is deployed, more data can be collected and a more sophisticated models can be developed to boost the benefit of emotion context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Collecting User-reported Labels</head><p>One merit of MoodSwipe is the capability to col- lect user-reported labels. MoodSwipe can obtain labels from two major user actions, select and swipe, respectively.</p><p>1.</p><p>[Select] When the user first types a response, browses all suggestions, and finally selects one suggested text, MoodSwipe can record the user's original typed text and label its emotion as that of the selected text.</p><p>2.</p><p>[Swipe] When the user first types a response, swipes directly to a specific emotion (e.g., Joy) and stops there, even without selecting the suggested text, it often still indicates that the user wants to express this emotion (e.g., Joy.) Therefore, MoodSwipe can record the user's current typed text and label it as the same emotion, even the user does not select the suggested text eventually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have developed the sender side MoodSwipe to cooperate with the receiver side applications and complete the emotion sensitive communica- tion framework. MoodSwipe provided a conve- nient interface which facilitating users on using the modern emotion classification and text sug- gestion techniques. In MoodSwipe, data are la- beled automatically according to frond-end cues in the background. We show that the user-specified emotion can benefit text suggestion, though the performance can still be improved by increasing the size of the dialog database. MoodSwipe is available at Google Play, and a demo video is provided at: https://www.youtube.com/ watch?v=SZ1biWoiq3Y</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Joy Yellow (#E1D500) I'm doing fine. Sadness Navy Blue (#518CCF) I'm upset, but I'm fine. Fear Green (#17C617) (no suggestion) Anticipation Orange (#E78300) Oh, I'm fine, I'm widw awake. What's up? Tired Purple (#C350DF) I'm working. Neutral White (#FFFFFF)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>, MoodSwipe receives user input text from</head><label></label><figDesc></figDesc><table>Type 

Swipe 
Select 
Swipe(s) 

Emotion Detected 
Switch Emotion 
Switch Emotion (Again) 
Select Suggested Text 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Human evaluation results. In Baseline the 
user-specified emotions are not available. 

Good Suggestion Rate (%) 
Setting 
Anger Anticipation Fear 
Baseline 
40.36 
21.29 
31.39 
+Emotion 
37.49 
20.32 
25.28 
Setting 
Joy 
Sadness 
Tired 
Baseline 
25.35 
29.31 
27.45 
+Emotion 
28.18 
26.56 
29.41 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Good suggestion rates of comfort for 
messages of different emotions. 

</table></figure>

			<note place="foot" n="1"> MoodSwipe is available at: https://play. google.com/store/apps/details?id=sinica. moodswipe&amp;hl=en</note>

			<note place="foot">Philippe Zimmermann, Sissel Guttormsen, Brigitta Danuser, and Patrick Gomez. 2003. Affective computing-a rationale for measuring mood with mouse and keyboard. International journal of occupational safety and ergonomics, 9(4):539-551.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Research of this paper was partially supported by Ministry of Science and Technology, Taiwan, un-der the contract 105-2221-E-001-007-MY3.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Affective student modeling based on microphone and keyboard user actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efthymios</forename><surname>Alepis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Virvou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Kabassi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="139" to="141" />
		</imprint>
	</monogr>
	<note>Advanced Learning Technologies</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Nice guys finish first: A symlog analysis of us naval commands. The SYMLOG practitioner: Applications of small group research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wallace</forename><surname>Bachman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="133" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Barsade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gibson</surname></persName>
		</author>
		<title level="m">Group emotion: A view from top and bottom. Research on managing groups and teams</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="81" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Kinetic typography-based instant messaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerry</forename><surname>Bodine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Pignol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CHI&apos;03 Extended Abstracts on Human Factors in Computing Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="914" to="915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Affectbutton: Towards a standard for dynamic affective user feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Broekens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem-Paul</forename><surname>Brinkman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Conductive chat: Instant messaging with a skin conductivity channel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Morris Dimicco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidya</forename><surname>Lakshmipathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Tresolini</forename><surname>Fiore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Computer Supported Cooperative Work</title>
		<meeting>Conference on Computer Supported Cooperative Work</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Faim: integrating automated facial affect analysis in instant messaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rana</forename><forename type="middle">El</forename><surname>Kaliouby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th international conference on Intelligent user interfaces</title>
		<meeting>the 9th international conference on Intelligent user interfaces</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="244" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The kinedit system: affective messages using dynamic texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jodi</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnny</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
		<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The positives of negative emotions: Willingness to express negative emotions promotes relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><forename type="middle">Y</forename><surname>Steven M Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><forename type="middle">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Helgeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="394" to="406" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Yang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.02736</idno>
		<title level="m">Challenges in providing automatic affective feedback in instant messaging applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balint</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">László</forename><surname>Lukács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04870</idno>
		<title level="m">Smart reply: Automated response suggestion for email</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using kinetic typography to convey emotion in text-based interpersonal communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonhwan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soojin</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jodi</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Hudson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th conference on Designing Interactive systems</title>
		<meeting>the 6th conference on Designing Interactive systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep reinforcement learning for dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01541</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quality of communication experience: definition, measurement, and implications for intercultural negotiations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Leigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Günter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">469</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Lucene in Action, Second Edition: Covers Apache Lucene 3.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccandless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Hatcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otis</forename><surname>Gospodnetic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Manning Publications Co</publisher>
			<pubPlace>Greenwich, CT, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Emotional intelligence. Imagination, cognition and personality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Salovey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John D</forename><surname>Mayer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="185" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Conveying mood and emotion in instant messaging by using a twodimensional model for affective states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfredo</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norma</forename><forename type="middle">P</forename><surname>Hernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julio</forename><forename type="middle">C</forename><surname>Penagos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Ostróvskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of VII Brazilian symposium on Human factors in computing systems</title>
		<meeting>VII Brazilian symposium on Human factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="66" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">This smartphone keyboard app can read your emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cornell</forename><surname>Tech</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Sensing emotions in text messages: An application and deployment study of emotionpush</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Ming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Hui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chun</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tinghao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lun-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ku</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.04758</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hot under the collar: Mapping thermal feedback to dimensional models of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dobromir</forename><surname>Dobrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A</forename><surname>Brewster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4838" to="4849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantitative study of music listening behavior in a social and affective context. Multimedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jen-Yu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1304" to="1315" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
