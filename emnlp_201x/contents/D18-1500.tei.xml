<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:47+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Lalor</surname></persName>
							<email>*lalor@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology and Human Development</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Montréal</settlement>
									<region>Québec</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Lowell</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="4711" to="4716"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>4711</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Interpreting the performance of deep learning models beyond test set accuracy is challenging. Characteristics of individual data points are often not considered during evaluation, and each data point is treated equally. We examine the impact of a test set question&apos;s difficulty to determine if there is a relationship between difficulty and performance. We model difficulty using well-studied psychometric methods on human response patterns. Experiments on Natural Language Inference (NLI) and Sentiment Analysis (SA) show that the likelihood of answering a question correctly is impacted by the question&apos;s difficulty. As DNNs are trained with more data, easy examples are learned more quickly than hard examples.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One method for interpreting deep neural networks (DNNs) is to examine model predictions for spe- cific input examples, e.g. testing for shape bias as in <ref type="bibr" target="#b22">Ritter et al. (2017)</ref>. In the traditional classifica- tion task, the difficulty of the test set examples is not taken into account. The number of correctly- labeled examples is tallied up and reported. How- ever, we hypothesize that it may be worthwhile to use difficulty when evaluating DNNs. For ex- ample, what does it mean if a trained model an- swers the more difficult examples correctly, but cannot correctly classify what are seemingly sim- ple cases? Recent work has shown that for NLP tasks such as Natural Language Inference (NLI), models can achieve strong results by simply using the hypothesis of a premise-hypothesis pair and ignoring the premise entirely ( <ref type="bibr" target="#b10">Gururangan et al., 2016;</ref><ref type="bibr" target="#b24">Tsuchiya, 2018;</ref><ref type="bibr" target="#b21">Poliak et al., 2018)</ref>.</p><p>In this work we consider understanding DNNs by looking at the difficulty of specific test set ex- amples and comparing DNN performance under different training scenarios. Do DNN models learn examples of varying difficulty at different rates? If a model does well on hard examples and poor on easy examples, then can we say that it has really learned anything? In contrast, if a model does well on easy items, because a dataset is all easy, have we really "solved" anything?</p><p>To model difficulty we use Item Response The- ory (IRT) from psychometrics ( <ref type="bibr" target="#b2">Baker and Kim, 2004</ref>). IRT models characteristics such as diffi- culty and discrimination ability of specific exam- ples (called "items" 1 ) in order to estimate a la- tent ability trait of test-takers. Here we use IRT to model the difficulty of test items to determine how DNNs learn items of varying difficulty. IRT provides a well-studied methodology for modeling item difficulty as opposed to more heuristic-based difficulty estimates such as sentence length. IRT was previously used to build a new test set for the NLI task ( <ref type="bibr" target="#b16">Lalor et al., 2016</ref>) and show that model performance is dependent on test set difficulty. In this work we use IRT to probe specific items to try to analyze model performance at a more fine- grained level, and expand the analysis to include the task of SA.</p><p>We train three DNNs models with varying train- ing set sizes to compare performance on two NLP tasks: NLI and Sentiment Analysis (SA). Our ex- periments show that a DNN model's likelihood of classifying an item correctly is dependent on the item's difficulty. In addition, as the models are trained with more data, the odds of answering easy examples correctly increases at a faster rate than the odds of answering a difficult example correctly. That is, performance starts to look more human, in the sense that humans learn easy items faster than they learn hard items.</p><p>That the DNNs are better at easy items than hard items seems intuitive but is a surprising and inter- esting result since the item difficulties are modeled from human data. There is no underlying reason that the DNNs would find items that are easy for hu- mans inherently easy. To our knowledge this is the first work to use a grounded measure of difficulty learned from human responses to understand DNN performance. Our contributions are as follows: (i) we use a well-studied methodology, IRT, to esti- mate item difficulty in two NLP tasks and show that this human-estimated difficulty is a useful pre- dictor of DNN model performance, (ii) we show that as training size increases DNN performance trends towards expected human performance. <ref type="bibr">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Estimating Item Difficulty</head><p>To model item difficulty we use the Three Parame- ter Logistic (3PL) model from IRT <ref type="bibr" target="#b1">(Baker, 2001;</ref><ref type="bibr" target="#b2">Baker and Kim, 2004;</ref><ref type="bibr" target="#b16">Lalor et al., 2016</ref>). The 3PL model in IRT models an individual's latent ability (θ) on a task as a function of three item character- istics: discrimination ability (a), difficulty (b), and guessing (c). For a particular item i, the probability that an individual j will answer item i correctly is a function of the individual's ability and the three item characteristics:</p><formula xml:id="formula_0">p ij (θ j ) = c i + 1 − c i 1 + e −a i (θ j −b i ) (1)</formula><p>where a i is the discrimination parameter (the value of the function slope at it's steepest point), b i is the difficulty parameter (the value where p ij (θ j ) = 0.5), and c i is the guessing parameter (the lower asymptote of the function). For a set of items I and a set of individuals J, the likelihood of each individual in J's responses to the items in I is:</p><formula xml:id="formula_1">L = J j=1 I i=1 p ij (θ j ) y ij q ij (θ j ) (1−y ij ) (2)</formula><p>where q ij (θ j ) = 1 − p ij (θ j ) and y ij = 1 if indi- vidual j answered item i correctly and y ij = 0 oth- erwise. Item parameters and individual ability are jointly estimated from a set of individuals' response patterns using an Expectation-Maximization algo- rithm <ref type="bibr" target="#b4">(Bock and Aitkin, 1981)</ref>.</p><p>In this work we focus on the difficulty parameter b i , which represents the latent ability level at which an individual has a 50% chance of answering item <ref type="bibr">2</ref> Code and data available at http://jplalor.github.io i correctly. Low values of b i are associated with easier items (since an individual with low ability has a 50% chance of answering correctly), and higher values of b i represent more difficult items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data</head><p>To estimate item difficulties for NLI, we used the pre-trained IRT models of <ref type="bibr" target="#b16">Lalor et al. (2016)</ref> and extracted the difficulty item parameters. The data consists of approximately 1000 human annotator responses from Amazon Mechanical Turk (AMT) for a selection of 180 premise-hypothesis pairs from the SNLI data set <ref type="bibr" target="#b5">(Bowman et al., 2015)</ref>. Each AMT worker (Turker) was shown the premise- hypothesis pairs and was asked to indicate whether, if the premise was taken to be true, the hypothesis was (a) definitely true (entailment), (b) maybe true (neutral), or (c) definitely not true (contradiction).</p><p>For SA, we collected a new data set of labels for 134 examples randomly selected from the Stanford Sentiment Treebank (SSTB) <ref type="bibr" target="#b23">(Socher et al., 2013)</ref>, using a similar AMT setup as <ref type="bibr" target="#b16">Lalor et al. (2016)</ref>. For each randomly selected example, we had 1000 Turkers label the sentence as very negative, neg- ative, neutral, positive, or very positive. We con- verted these responses to binary positive/negative labels and fit a new IRT 3PL model ( §2.1) using the mirt R package ( <ref type="bibr" target="#b7">Chalmers et al., 2015)</ref>. Very negative and negative labels were binned together, and neutral, positive, and very positive were binned together. <ref type="table" target="#tab_0">Tables 1 and 2</ref> show examples of the items in our data sets, and the difficulty values estimated from the IRT models. The first example in <ref type="table">Table 1</ref> is a clear case of entailment, where if we assume that the premise is true, we can infer that the hypothesis is also true. The label of the second example in SNLI is contradiction, but in this case the result is not as clear. There are sports stadiums that offer lawn seating, and therefore this could potentially be a case of entailment (or neutral). Either way, one could argue that the second example here is more difficult than the first. Similarly, the first two examples of   in difficulty in both cases. Inter-rater reliability scores for the collected an- notations are showin in <ref type="table" target="#tab_2">Table 3</ref>. Scores for the NLI annotations were calculated when the origi- nal dataset was collected and are reproduced here ( <ref type="bibr" target="#b16">Lalor et al., 2016)</ref>. Human annotations for the SA annotations were converted to binary before calculating the agreement. We see that the agree- ment scores are in the range of 0.4 to 0.6 which is considered moderate agreement ( <ref type="bibr" target="#b17">Landis and Koch, 1977)</ref>. With the large number of annotators it is to be expected that there is some disagreement in the labels. However this disagreement can be inter- preted as varying difficulty of the items, which is what we expect when we fit the IRT models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Experiments</head><p>Our goal in this work is to understand how DNN performance on items of varying difficulty changes under different training scenarios. To test this, we trained three DNN models using subsets of the original SNLI and SSTB training data sets: (i) Long Short Term Memory Network (LSTM) <ref type="bibr" target="#b5">(Bowman et al., 2015)</ref>, (ii) Convolutional Neural Net- work (CNN) <ref type="bibr" target="#b13">(Kim, 2014)</ref>, and (iii) Neural Seman- tic Encoder (NSE), a type of memory-augmented RNN (Munkhdalai and Yu, 2017). <ref type="bibr">3</ref> For each task (NLI and SA), we randomly sampled subsets of training data, from 100 examples up to and includ- ing the full training data sets. <ref type="bibr">4</ref> We trained each model on the training data subsets, using the origi- nal development sets for early stopping to prevent overfitting. The IRT data with difficulty estimates were used as test sets for the trained models.</p><p>Once the models were trained and had classified the IRT data sets, we fit logistic regression models to predict whether a DNN model would label an item correctly, using the training set size and item difficulty as the dependent parameters. <ref type="figure" target="#fig_0">Figure 1</ref> plots the contour plots of our learned re- gression models. The top row plots results for the NLI task, and the bottom row plots results for the SA task. From left to right in both rows, the plots show results for the LSTM, CNN, and NSE models. In each plot, the x-axis is the training set size, the y-axis is the item difficulty, and the contour lines represent the log-odds that the DNN model would classify an item correctly. As the plots show, item difficulty has a clear effect on classification. Easier items have higher odds of being classified correctly across all of the training set sizes. In addition, the slopes of the contour lines are steeper at lower lev- els of difficulty. This indicates that, moving left to right along the x-axis, a model's odds of answering an easy item correctly increase more quickly than the odds of answering a harder item correctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The contour plots for the CNN and NSE models on the SA task <ref type="figure" target="#fig_0">(Figure 1</ref>, second row middle and right plots) show that the easier items have higher likelihood of being classified correctly, but the odds for the most difficult items decrease as training size increases. This suggests that these models are learning in such a way that improves performance on easy items but has a negative effect on hard items. This result is important for interpretability, as it could inform stakeholder decisions if they need to have difficult examples classified.</p><p>The idea that easy items should be easier than hard items is consistent with learning strategies in humans. For example, when teaching new con- cepts to students, easier concepts are presented first so that the students can learn patterns and core information before moving to more difficult con- cepts ( <ref type="bibr" target="#b8">Collins et al., 1988;</ref><ref type="bibr" target="#b0">Arroyo et al., 2010)</ref>. As students do more examples, all questions get easier, but easy questions get easier at a faster rate. Our result is also consistent with the key assumptions of curriculum learning ( <ref type="bibr" target="#b3">Bengio et al., 2009</ref>). <ref type="bibr" target="#b16">Lalor et al. (2016)</ref> introduced the idea of apply- ing IRT evaluation to NLP tasks. They built a set of scales using IRT for NLI and evaluated a single LSTM neural network to demonstrate the effectiveness of the evaluation, but did not evaluate other NLP models or tasks. <ref type="bibr" target="#b18">Martínez-Plumed et al. (2016)</ref> consider IRT in the context of evaluating ML models, but they do not use a human popula- tion to calibrate the models, and obtain results that are difficult to interpret under IRT assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>There has been work in the NLP commu- nity around modeling latent characteristics of data <ref type="bibr" target="#b6">(Bruce and Wiebe, 1999</ref>) and annota- tors ( <ref type="bibr" target="#b12">Hovy et al., 2013</ref>), but none that apply the resulting metrics to interpret DNN models. <ref type="bibr" target="#b20">Passonneau and Carpenter (2014)</ref> model the probability a label is correct with the probability of an annotator to label an item correctly according to the <ref type="bibr" target="#b9">Dawid and Skene (1979)</ref> model, but do not consider diffi- culty or discriminatory ability of the data points.</p><p>One-shot learning is an attempt to build ML mod- els that can generalize after being trained on one or a few examples of a class as opposed to a large training set ( <ref type="bibr" target="#b14">Lake et al., 2013)</ref>. One-shot learning attempts to mimic human learning behaviors (i.e., generalization after being exposed to a small num- ber of training examples) ( <ref type="bibr" target="#b15">Lake et al., 2016)</ref>. Our work instead looks at comparisons to human perfor- mance, where any learning (on the part of models) has been completed beforehand. Our goal is to analyze DNN models and training set variations as they affect ability in the context of IRT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this work we have shown that DNN model per- formance is affected by item difficulty as well as training set size. This is the first work that has used a well-established method for estimating dif- ficulty to analyze DNN model performance as op- posed to heuristics. DNN models perform better on easy items, and as more data is introduced in train- ing, easy items are learned more quickly than hard items. Learning easy examples faster than harder examples is what would be expected when exam- ining human response patterns as they learn more about a subject. However this has not previously been shown to be true in DNN models.</p><p>That the results are consistent across NLI and SA shows that the methods can be applied to a number of NLP tasks. The SA results do show that the odds of labeling a difficult item correctly decrease with more training data 1. It could be the case that these difficult items in the SA task are more subjective than the easier items, for example a review that is fairly neutral and is split between positive and negative annotations. These cases would be more difficult for a model to label, and are worth exam- ining in more detail. By identifying items such as these as difficult makes it easier to see where the model is going wrong and allows for research on better way to represent these cases.</p><p>This result has implications for how machine learning models are evaluated across tasks. The tra- ditional assumption that the test data is drawn from the same distribution as the training data, makes it difficult to understand how a model will perform in settings where that assumption does not hold. However, if the difficulty of test set data is known, we can better understand what kind of examples a given model performs well on, and specific in- stances where a model underperforms (e.g. the most difficult examples). In addition, researhers can build test sets that consist of a specific type of data (very easy, very hard, or a mix) to evalu- ate a trained model under specific assumptions to test generalization ability in a controlled way. This could allow for more confidence in model perfor- mance in more varied deployment settings, since there would be a set of tests a model would have to pass before being deployed.</p><p>It is important to note that the difficulty param- eters were estimated from a human population, meaning that those items that are difficult for hu- mans are in fact more difficult for the DNN models as well. This does not need to be the case given that DNNs learn very different patterns, etc. than humans. In fact there were exceptions in our results which shows that these models should be carefully examined using techniques like those described here. Future work can investigate why this is the case and how we can leverage this information to improve model performance and interpretability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Contour plots showing log-odds of labeling an item correctly for NLI (top row) and SA (bottom row) as a function of training set size (x-axis) and item difficulty (y-axis). Each line in the plots represents a single log-odds value for labeling an item correctly. Blue indicates low log-odds of labeling an item correctly, and pink indicates high log-odds of labeling an item correctly. The contour colors are consistent across plots and log-odds values are shown in the legend on the right.</figDesc><graphic url="image-1.png" coords="4,72.00,62.81,453.55,260.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 arewatching the tournament in the stadium The people are sitting outside on the grass Contradiction 0.51 Two girls on a bridge dancing with the city skyline in the background</head><label>2</label><figDesc>interesting. Both of these items are labeled as negative examples in the data set. The first example is clear, but the second one is more ambiguous. It could be considered a mild complement, since the author still endorses renting the movie. Therefore you could argue again that the second example is more difficult than the first. The learned difficulty parameters reflect this difference</figDesc><table>Premise 
Hypothesis 
Label 
Difficulty 
A little girl eating a sucker 
A child eating candy 
Entailment 
-2.74 
People were The girls are sisters. 
Neutral 
-1.92 

Nine men wearing tuxedos sing 
Nine women wearing dresses sing 
Contradiction 0.08 

Table 1: Examples of sentence pairs from the SNLI data sets, their corresponding gold-standard label, and 
difficulty parameter (b i ) as measured by IRT ( §2.1). 

Phrase 
Label 
Difficulty 
The stupidest, most insulting movie of 2002's first quarter. 
Negative -2.46 
Still, it gets the job done -a sleepy afternoon rental. 
Negative 1.78 
An endlessly fascinating, landmark movie that is as bold as anything the cinema has seen in 
years. 

Positive 
-2.27 

Perhaps no picture ever made has more literally showed that the road to hell is paved with good 
intentions. 

Positive 
2.05 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Examples of phrases from the SSTB data set, their corresponding gold-standard label, and 
difficulty parameter (b i ) as measured by IRT ( §2.1). 

Dataset 
Fleiss' κ 
SNLI 4GS Contradiction 
0.37 
SNLI 4GS Entailment 
0.48 
SNLI 4GS Neutral 
0.41 
SNLI 5GS Contradiction 
0.59 
SNLI 5GS Entailment 
0.63 
SNLI 5GS Neutral 
0.54 
Sentiment Analysis 
0.52 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Fleiss' κ scores for the NLI and SA anno- tations collected from AMT.</figDesc><table></table></figure>

			<note place="foot" n="1"> For the remainder of the paper we will refer to a single test set example as an &quot;item&quot; for consistency.</note>

			<note place="foot" n="3"> Please refer to the appendix for model details. 4 We sampled 100, 1000, 2000, 5000, 10000, 50000, 100000, 200000, and 500000 examples for NLI, and sampled 100, 1000, 5000, 10000, 50000, and 75000 examples for SA.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the AMT Turkers who completed our annotation task. This work was supported in part by the HSR&amp;D award IIR 1I01HX001457 from the United States Department of Veterans Affairs (VA). We also acknowledge the support of LM012817 from the National Institutes of Health. This work was also supported in part by the Center for Intel-ligent Information Retrieval. The contents of this paper do not represent the views of CIIR, NIH, VA, or the United States Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Effort-based tutoring: An empirical approach to intelligent tutoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivon</forename><surname>Arroyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hasmik</forename><surname>Mehranian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beverly P</forename><surname>Woolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Educational Data Mining</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The basics of item response theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>ERIC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Item Response Theory: Parameter Estimation Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seock-Ho</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Marginal maximum likelihood estimation of item parameters: Application of an em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Aitkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="443" to="459" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recognizing subjectivity: A case study in manual tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">F</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><forename type="middle">M</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Lang. Eng</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="205" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Chalmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Pritikin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Robitzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Zoltak</surname></persName>
		</author>
		<title level="m">mirt: Multidimensional Item Response Theory</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Seely Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive apprenticeship: Teaching the craft of reading, writing and mathematics</title>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="2" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Maximum likelihood estimation of observer error-rates using the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Dawid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><forename type="middle">M</forename><surname>Skene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series C (Applied Statistics)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="20" to="28" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Annotation artifacts in natural language inference datg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long ShortTerm Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning whom to trust with mace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1120" to="1130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One-shot learning by inverting a compositional causal process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2526" to="2534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="page" from="1" to="101" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Building an evaluation scale using item response theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Lalor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="648" to="657" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Making sense of item response theory in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Martínez-Plumed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">B C</forename><surname>Prudłncio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adolfo</forename><forename type="middle">Martnez</forename><surname>Us</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos</forename><surname>Hernndez-Orallo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAI</title>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="page" from="1140" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural semantic encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The benefits of a model of annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="311" to="326" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hypothesis only baselines in natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Joint Conference on Lexical and Computational Semantics (* SEM</title>
		<meeting>the 7th Joint Conference on Lexical and Computational Semantics (* SEM</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cognitive psychology for deep neural networks: A shape bias case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><forename type="middle">M</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance impact caused by hidden bias of training data for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Tsuchiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
