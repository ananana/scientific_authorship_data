<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Segmentation-Free Word Embedding for Unsegmented Languages *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takamasa</forename><surname>Oshikiri</surname></persName>
							<email>mail@oshikiri.org</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Graduate School of Engineering Science</orgName>
								<orgName type="department" key="dep2">RIKEN Center for Advanced Intelligence Project CyberAgent</orgName>
								<orgName type="institution">Osaka University</orgName>
								<address>
									<region>Inc</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Segmentation-Free Word Embedding for Unsegmented Languages *</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="767" to="772"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose a new pipeline of word embedding for unsegmented languages , called segmentation-free word embedding , which does not require word seg-mentation as a preprocessing step. Unlike space-delimited languages, unsegmented languages, such as Chinese and Japanese, require word segmentation as a prepro-cessing step. However, word segmenta-tion, that often requires manually annotated resources, is difficult and expensive, and unavoidable errors in word segmen-tation affect downstream tasks. To avoid these problems in learning word vectors of unsegmented languages, we consider word co-occurrence statistics over all possible candidates of segmentations based on frequent character n-grams instead of segmented sentences provided by conventional word segmenters. Our experiments of noun category prediction tasks on raw Twitter, Weibo, and Wikipedia corpora show that the proposed method outper-forms the conventional approaches that require word segmenters.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word embedding, which learns dense vector rep- resentation of words from large text corpora, has received much attention in the natural language processing (NLP) community in recent years. It is reported that the representation of words well captures semantic and syntactic properties of words ( <ref type="bibr" target="#b1">Bengio et al., 2003;</ref><ref type="bibr" target="#b11">Mikolov et al.</ref>, * This work was done while the author was at Shi- modaira laboratory, Division of Mathematical Science, Grad- uate School of Engineering Science, Osaka University, and Mathematical Statistics Team, RIKEN Center for Advanced Intelligence Project. Figure 1: t-SNE projections of vector represen- tation of Japanese nouns that generated by our proposed method without word dictionary. These proper nouns are color-coded according to its cat- egories which extracted from Wikidata.</p><p>2013; <ref type="bibr" target="#b13">Pennington et al., 2014)</ref>, and is useful for many downstream NLP tasks, including part-of- speech tagging, syntactic parsing, and machine translation <ref type="bibr" target="#b6">(Huang et al., 2011;</ref><ref type="bibr" target="#b16">Socher et al., 2013;</ref><ref type="bibr" target="#b17">Sutskever et al., 2014)</ref>. In order to train word embedding models on a raw text corpus, we have to do word segmentation as a preprocessing step. In space-delimited lan- guages such as English and Spanish, simple rule- based and co-occurrence-based approaches offer reasonable segmentations. On the other hands, these approaches are impractical for unsegmented languages such as Chinese, Japanese, and Thai. Therefore, machine learning-based approaches are widely used in NLP for unsegmented languages. Conditional random field (CRF)-based supervised word segmentation ( <ref type="bibr" target="#b8">Kudo et al., 2004;</ref><ref type="bibr" target="#b18">Tseng et al., 2005</ref>) is still the most used one in Japanese and Chinese NLP <ref type="bibr" target="#b14">(Prettenhofer and Stein, 2010;</ref><ref type="bibr" target="#b4">Funaki and Nakayama, 2015;</ref><ref type="bibr" target="#b7">Ishiwatari et al., 2015;</ref><ref type="bibr" target="#b12">Nakazawa et al., 2016)</ref>.</p><p>However, there are some problems for these supervised word segmentation as a preprocess- ing step of a word embedding pipeline. First, they require language-specific manually anno- tated resources such as word dictionaries and seg- mented corpora. Since these manually annotated resources are typically unavailable for domain- specific corpora (e.g. Twitter or Weibo cor- pora that contain many neologisms and informal words), we have to create manually annotated re- sources if we need. Second, they cannot take ad- vantage of word occurrence frequencies in a cor- pus. Even though a certain proper noun (e.g. " " (The Old Man and the Sea)) occurs frequently in a corpus, word segmenters will con- tinue to split the proper noun erroneously (e.g. " //" (a old man / and / a sea)) if it is not registered in the word dictionary. Because of seg- mentation errors incurred by these problems, the downstream word embedding model cannot learn vector representation of proper nouns, neologisms, and informal words.</p><p>In this paper, in order to learn word vectors from a raw text corpus while avoiding the above problems, we propose a new word segmentation- free pipeline for word embedding, referred to as segmentation-free word embedding (sembei). Our framework first enumerates all possible segmen- tations (referred to as a frequent n-gram lattice) based on character n-grams that frequently oc- curred in the raw corpus, and then learns n-gram vectors from co-occurrence frequencies over the frequent n-gram lattice. Using the general idea of segmentation-free word embedding, we can ex- tend existing word embedding models. Specifi- cally, in this paper, we propose a segmentation- free version of the widely used skip-gram model with negative sampling (SGNS) ( <ref type="bibr" target="#b11">Mikolov et al., 2013)</ref>, which we refer to as SGNS-sembei.</p><p>Although the frequent character n-grams nec- essarily include many non-words (i.e. n-grams that are not words), remarkably, our results show that nearest neighbor search works well for fre- quent words and even proper nouns (e.g. near- est neighbors of n-gram "" (Germany) are "" (China), "" (United Kingdom), etc.). This observation suggests that we can use the proposed method for automatic acquisition of synonyms from large raw text corpora.</p><p>We conduct experiments on a noun category prediction task on several corpora and observe that our method outperforms the conventional ap- proaches that use word segmenters. <ref type="figure">Fig. 1</ref> shows a t-SNE projection of vector representation of Japanese nouns which is learned from only a raw Twitter corpus. We can see that the proposed method can learn vector representation of these nouns, and the learnt representation achieves good separation based on their categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There are some representation models that do not rely on any segmenters. <ref type="bibr" target="#b3">Dhingra et al. (2016)</ref> pro- posed a character-based RNN model for vector representation of tweets, and Sch√ºtze (2017) pro- posed a new text embedding method that learns n-gram vectors from the corpus that segmented randomly and then constructs text embeddings by summing up the n-gram vectors. In the field of representation learning for biological sequences (e.g. DNA and RNA), <ref type="bibr" target="#b0">Asgari and Mofrad (2015)</ref> applied the skip-gram model ( <ref type="bibr" target="#b11">Mikolov et al., 2013</ref>) to fixed length fragments of biological se- quences. These methods mainly aim at learn- ing vector representation of texts or biological sequences instead of words or fragments of se- quences. On the other hand, in this paper, we focus on learning vector representation of words from a raw corpus of unsegmented languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conventional Approaches to Word Embeddings</head><p>Word embedding is also commonly used in NLP for unsegmented languages <ref type="bibr" target="#b14">(Prettenhofer and Stein, 2010;</ref><ref type="bibr" target="#b4">Funaki and Nakayama, 2015;</ref><ref type="bibr" target="#b7">Ishiwatari et al., 2015)</ref>. In these studies, they usually segment a raw corpus into words using a word seg- menter or a morphological analyzer, and then feed the segmented corpus to word embedding models (e.g. the skip-gram model ( <ref type="bibr" target="#b11">Mikolov et al., 2013)</ref> or the GloVe ( <ref type="bibr" target="#b13">Pennington et al., 2014)</ref>) as in the case of space-delimited languages. The flowchart of the above process is shown in the left part of <ref type="figure">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The original SGNS</head><p>The  <ref type="figure">Figure 2</ref>: Flowcharts of previous and proposed pipelines. Morphological analyzers are in charge of the shaded part. Our main idea is to replace a word dictionary with a set of frequent character n- grams, and omit the indentification of the optimum path.</p><p>following objective function:</p><formula xml:id="formula_0">maximize {vw }‚à™{Àúvc}}‚à™{Àúvc} ‚àë (w,c)‚ààD log œÉ(v ‚ä§ w Àú vc) + ‚àë (w,c)‚ààD ‚Ä≤ log œÉ(‚àív ‚ä§ w Àú vc)<label>(1)</label></formula><p>where œÉ(x) := (1 + e ‚àíx ) ‚àí1 , D is a multiset (bag) of positive samples (i.e. co-occurred pairs in the corpus), and D ‚Ä≤ is a multiset of negative sam- ples. This objective function is maximized using stochastic gradient descent (SGD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Segmentation-Free Word Embeddings</head><p>In this section, we first introduce the general idea of segmentation-free word embeddings (sembei), and then propose a segmentation-free version of the SGNS. While conventional word embedding ap- proaches learn word vectors from segmented corpora that provided by word segmenters, our approach learns n-gram vectors from raw corpora, as in the right part of <ref type="figure">Fig. 2</ref>. In order to learn n-gram vectors from a raw corpus of unsegmented languages, we first construct a frequent n-gram lattice, which represents all pos- sible segmentations based on frequent character n-grams of the corpus, in the same way as the construction of word lattices used in morpho- logical analysis. Then, we learn n-gram vectors using co-occurrence statistics over the frequent n-gram lattice instead of segmented corpora as in conventional approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Segmentation-Free Version of the SGNS</head><p>Here, we introduce a segmentation-free version of SGNS, referred to as SGNS-sembei, as an appli- cation of the idea of segmentation-free word em- bedding. Our method simply optimizes the origi- nal SGNS's objective function (1) with the slight modification: changing the definition of the multi- set of positive samples D.</p><p>In SGNS-sembei, D is redefined as the multi- set of character n-gram pairs (w, c) where w and c occur adjacently in the corpus (i.e. w and c are connected in the frequent n-gram lattice). In addi- tion, to discriminate co-occurrence with different order in the frequent n-gram lattice, we define con- textual words with their relative positions to the center word as the same way as <ref type="bibr" target="#b9">Ling et al. (2015)</ref> did.</p><p>We also redefine the multiset of negative sam- ples D ‚Ä≤ using D in the same way as the origi- nal SGNS, and then optimize the objective func- tion (1) using SGD. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head><p>In this section, we evaluate our method by the noun category prediction task on Twitter, Weibo, and Wikipedia corpora.</p><p>The C++ implementation of the proposed method is available on GitHub 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Settings</head><p>We used four raw text corpora: Wikipedia (Japanese), Wikipedia (Chinese), Twitter (Japanese), and Weibo (Chinese). The Wikipedia corpora consist of only a part of the Wikipedia <ref type="table">Table 2</ref>: Micro F-scores (higher is better) and coverages <ref type="bibr">[%]</ref> (in parentheses, higher is better).  <ref type="bibr">3</ref> as the frequent character n-grams for our proposed method.</p><p>We extracted the noun-category pairs from the Wikidata <ref type="bibr" target="#b19">(Vrandeƒçi¬¥Vrandeƒçi¬¥c and Kr√∂tzsch, 2014</ref>) (We used the dump dated January 9th, 2017) as fol- lows. We first extracted Wikidata entities whose headwords are also in the 1,460k frequent n- grams, and then extracted the Wikidata entities whose "instance of" properties are any of the predetermined category set 4 , and then collected names and their categories of the entities. Ex- amples of the extracted noun-category pairs are shown in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>We randomly split the noun-category pairs into a train (60%) and a test (40%) set. We trained linear C-SVM classifiers ( <ref type="bibr" target="#b5">Hastie et al., 2009</ref>) with the train set to predict categories from vector representation of the nouns.</p><p>We performed a grid search over (C, classifier) ‚àà {0.5, 1, 5, 10, 50, 100} √ó {one-vs-one, one-vs-rest} of linear SVM using the train set for each vector representation, and <ref type="bibr">2</ref> We used {ja,zh}wiki-20170220-pages-articles1.xml in https://dumps.wikimedia.org 3 In this experiment, we defined the frequent n-grams as the union of the top-kn frequent n- grams, where n and kn are the pre-specified num- bers.</p><p>And we used n = 8, (k1, . . . , k8) = (10000, 300000, 300000, 300000, 200000, 200000, 100000, 50000) for Japanese corpora, and n = 7, (k1, . . . , k7) = (10000, 400000, 400000, 300000, 200000, 100000, 50000) for Chinese corpora 4 {country, profession, ship, railway station, food, chem- ical compound, prefecture of Japan, manga, human } for Japanese, and {country, profession, television series, busi- ness enterprise, city, chemical compound, taxon, human} for Chinese reported the best scores on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline Systems</head><p>We compared SGNS-sembei with the conven- tional approaches that use the original SGNS and word segmenters. To segment the raw corpora, we used the MeCab ( <ref type="bibr" target="#b8">Kudo et al., 2004</ref>) for Japanese corpora and the Stanford Word Segmenter ( <ref type="bibr" target="#b18">Tseng et al., 2005</ref>) for Chinese corpora with their de- fault dictionaries <ref type="bibr">5</ref> . And we ignored the words that occur less than 5 times. We also ran these base- line systems in an ideal setting: running the word segmenters with the default dictionaries and ad- ditional dictionaries that consist of the nouns ex- tracted in ¬ß 5.1.</p><p>We performed a grid search over (h, t, n neg ) ‚àà {5, 8, 10} √ó {10 ‚àí5 , 10 ‚àí4 , 10 ‚àí3 } √ó {3, 10, 25} where h is the size of context window, t is the sam- pling threshold, and n neg is the number of negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>In both the original SGNS and SGNS-sembei, we fixed the dimensionality of vector representation to 200 and the number of iterations to 5 in both baseline and our method. In SGNS-sembei, we used the number of negative samples n neg = 10, size of context window h = 1, initial learning rate Œ± init = 0.01.</p><p>The resulting micro F-scores and the cover- ages (i.e. the percentages of the noun-category pairs whose nouns' vector representation exists) are shown in <ref type="table">Table 2</ref>, and the t-SNE <ref type="bibr" target="#b10">(Maaten and Hinton, 2008)</ref> projections of Japanese nouns vec- tors learned from the Twitter corpus are shown in <ref type="figure">Fig. 1</ref>. We observed that our proposed method outperforms the conventional approaches that use word segmenters. Furthermore, the coverages of our method were higher than those of the SGNS with the default dictionary (especially in Japanese) and competitive to those of the SGNS with the de- fault dictionary and Wikidata (which is an ideal setting) even though our method does not require any manually annotated resources. We can also see that the learnt representation achieves good separation based on their categories as in <ref type="figure">Fig. 1</ref>. Nearest neighbor search using Twitter and Weibo corpora was also performed as preliminary exper- iments, and surprisingly, it worked well for fre- quent words as in <ref type="table">Table.</ref> 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed segmentation-free word embedding for unsegmented languages. Although our method does not rely on any manually annotated re- sources, experimental results of the noun category prediction task on several corpora showed that our method outperforms conventional approaches that rely on manually annotated resources.</p><p>As an anonymous reviewer suggested, a pos- sible direction of future work is to leverage an- other word segmentation approach which uses lin- guistic features, such as the Stanford Word Seg- menter ( <ref type="bibr" target="#b18">Tseng et al., 2005</ref>) with k-best segmenta- tions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples of labels of entities (in 
Japanese, and in English for reference) and its cat-
egories extracted from Wikidata. 

label (ja) 
label (en) 
category 


Germany 
country 

carbon dioxide chemical compound 

firefighter 
profession 
apple pie 
food 

Yuto Nagatomo human 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results of nearest neighbor search for fre-
quent words 

Language Query 
3-Nearest Neighbors 

Japanese 

(Germany) 
(China), (UK), 
(Poland) 

(oxygen) 
(hydrogen), (iron), 
(carbon dioxide) 

Chinese 
Âæ∑ (Germany) 

(USA), (UK), 

(France) 

(badminton) 
(billiards), (tennis), ‰πí 

‰πì (pingpong) 

</table></figure>

			<note place="foot" n="1"> https://github.com/oshikiri/ w2v-sembei</note>

			<note place="foot" n="5"> We use mecab-ipadic v2.7.0 for the MeCab and dict-chris6.ser.gz for the Stanford Word Segmenter.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>I would like to thank Hidetoshi Shimodaira, Thong Pham, Kazuki Fukui, and anonymous re-viewers for their helpful suggestions. This work was partially supported by grants from Japan So-ciety for the Promotion of Science KAKENHI (JP16H02789) to HS.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Continuous distributed representation of biological sequences for deep proteomics and genomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsaneddin</forename><surname>Asgari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mofrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R√©jean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Assessing censorship on microblogs in china: Discriminatory keyword analysis and the real-name registration policy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung</forename><surname>Hong Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">King</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tweet2vec: Character-based distributed representations for social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Muehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagemediated learning for zero-shot cross-lingual document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruka</forename><surname>Funaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Nakayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="585" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Language models as representations for weakly supervised nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Downey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Fifteenth Conference on Computational Natural Language Learning<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="125" to="134" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accurate cross-lingual projection between count-based word vectors by exploiting translatable context pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shonosuke</forename><surname>Ishiwatari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuhiro</forename><surname>Kaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Toyoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaru</forename><surname>Kitsuregawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineteenth Conference on Computational Natural Language Learning</title>
		<meeting>the Nineteenth Conference on Computational Natural Language Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="300" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Applying conditional random fields to japanese morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaoru</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
		<ptr target="http://taku910.github.io/mecab/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="230" to="237" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of word2vec for syntax problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1299" to="1304" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Overview of the 3rd workshop on asian translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideya</forename><surname>Mino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isao</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Asian Translation (WAT2016)</title>
		<meeting>the 3rd Workshop on Asian Translation (WAT2016)<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Crosslanguage text classification using structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1118" to="1127" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonsymbolic text representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch√ºtze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="785" to="796" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Conditional Random Field Word Segmenter for SIGHAN bakeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huihsin</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galen</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://nlp.stanford.edu/software/segmenter.shtml" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fourth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">171</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Wikidata: A free collaborative knowledgebase. Commun</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandeƒçi¬¥vrandeƒçi¬¥c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kr√∂tzsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ACM</publisher>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="78" to="85" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
