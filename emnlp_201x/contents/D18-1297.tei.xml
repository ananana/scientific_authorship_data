<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yahui</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Bi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">AI Lab</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Gao</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">AI Lab</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuming</forename><surname>Shi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">AI Lab</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Less Generic Responses in Neural Conversation Models: A Statistical Re-weighting Method</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2769" to="2774"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2769</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sequence-to-sequence neural generation models have achieved promising performance on short text conversation tasks. However, they tend to generate generic/dull responses, leading to unsatisfying dialogue experience. We observe that in conversation tasks, each query could have multiple responses, which forms a 1-ton or m-ton relationship in the view of the total corpus. The objective function used in standard sequence-to-sequence models will be dominated by loss terms with generic patterns. Inspired by this observation, we introduce a statistical re-weighting method that assigns different weights for the multiple responses of the same query, and trains the standard neu-ral generation model with the weights. Experimental results on a large Chinese dialogue corpus show that our method improves the acceptance rate of generated responses compared with several baseline models and significantly reduces the number of generated generic responses .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many recent works have been proposed to use neural networks to generate responses for open- domain dialogue systems ( <ref type="bibr" target="#b6">Shang et al., 2015;</ref><ref type="bibr" target="#b8">Sordoni et al., 2015;</ref><ref type="bibr" target="#b11">Vinyals and Le, 2015;</ref><ref type="bibr">Li et al., 2016a,c;</ref><ref type="bibr" target="#b5">Serban et al., 2017;</ref><ref type="bibr" target="#b7">Shen et al., 2017;</ref><ref type="bibr" target="#b2">Li et al., 2017;</ref><ref type="bibr" target="#b15">Yu et al., 2017;</ref><ref type="bibr" target="#b14">Xu et al., 2017)</ref>. These methods are inspired by the sequence-to- sequence (Seq2Seq) framework <ref type="bibr" target="#b9">(Sutskever et al., 2014</ref>), which is originally applied for Neural Ma- chine Translation (NMT). They aim at maximizing the probability of generating a response given an input query, and generally use the maximum likeli- hood estimation (MLE) as their objective function. However, various problems occur when Seq2Seq * This work was done while Yahui Liu was with Tencent AI Lab.</p><p>† Corresponding author models are used for dialogue generation tasks. One of the most important problems is that such models are inclined to generate generic and dull responses (e.g., I don't know), rather than meaningful and specific answers ( <ref type="bibr" target="#b8">Sordoni et al., 2015;</ref><ref type="bibr" target="#b4">Serban et al., 2016;</ref><ref type="bibr">Li et al., 2016a,c;</ref><ref type="bibr" target="#b0">Kannan et al., 2016;</ref><ref type="bibr" target="#b2">Li et al., 2017;</ref><ref type="bibr" target="#b13">Xie, 2017;</ref><ref type="bibr" target="#b12">Wei et al., 2017;</ref>. Until now, it has attracted increasing studies to address the issue of generating generic response. For example, <ref type="bibr">Li et al. (2016a)</ref> used the mutual infor- mation theory to reconstruct MLE, but this model is easy to generate ungrammatical outputs. They fur- ther proposed a fast diverse decoding approach ( <ref type="bibr">Li et al., 2016b)</ref>, which modifies the beam search to re-rank meaningful responses into higher positions. Similar works explore different ways to encour- age response diversity for picking less generic re- sponses in the decoding search <ref type="bibr" target="#b10">(Vijayakumar et al., 2016;</ref><ref type="bibr">Li and Jurafsky, 2016)</ref>. In the reinforcement learning framework ( <ref type="bibr">Li et al., 2016c</ref>), the reward function used in the decoding considers the ease of answering, which is measured by a distance to- wards a set of 8 generic responses. Thus, it can also alleviate the problem of generating generic re- sponses to some extent. <ref type="bibr">Lison and Bibauw (2017)</ref> proposed to add a weighting model to learn the "quality" of the query and response pair, but it re- lies heavily on additional inputs. All these works tried to add extra optimized terms in the encod- ing or decoding modules in Seq2Seq, making the training or prediction more complicated.</p><p>In this work, we consider the reason why Seq2Seq often generates generic responses by an- alyzing the MLE objective function directly. We notice that multiple responses are often associated with one single input query. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the relationship between queries and responses is much looser in conversation models than that in NMT, since the space of possible responses is much larger than the space of possible translations for a given sentence. On one hand, the information of these responses is only required to be relevant to the input query but usually differs from it. On the other hand, a query accepts large semantic diversity among its responses. Hence, it is a 1-to-n relation- ship between a query and its responses <ref type="bibr" target="#b11">(Vinyals and Le, 2015;</ref>. Meanwhile, we can see there is a m-to-n relationship between all queries and responses in the training corpus. Then, we find that MLE, which learns a 1-to-1 mapping in response generation, naturally puts more empha- sis on optimizing the frequent patterns. Thus, the converged local optimum is easy to output these patterns or their combinations, leading to generic responses.  Inspired by this observation, we propose a statis- tical re-weighting method which modifies MLE by re-weighting the multiple responses for each query such that MLE will not be dominated by the fre- quent patterns or their combinations. The proposed method calculates the weights of a response with the consideration of two statistical features: simi- larity frequency and sentence length. Our model is simple and efficient to optimize without adding ad- ditional terms into the original Seq2Seq objective function. We validate the performance of our pro- posed method on a large Chinese dialogue corpus. Results show that it can improve the acceptance rate of the generated responses and significantly suppress the number of generic responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Method</head><p>Standard Seq2Seq models for NMT and dialogue generation aim at estimating the conditional proba- bility p(y|x) where x = (x 1 , . . . , x T ) is an input sequence and y = (y 1 , . . . , y T ) is its correspond- ing output sequence whose length T may differ from T . During training, we learn all the model pa- rameters θ θ θ by summing the negative log likelihood of each sample pair (x, y) in the training corpus C:</p><formula xml:id="formula_0">(x, y, θ θ θ) = − T t=1 log p(y t |x, y [t−1] ; θ θ θ), (1) L(C, θ θ θ) = (x,y)∈C (x, y, θ θ θ).<label>(2)</label></formula><p>Recall that generic responses are those that are safe and universal for many queries and thus fre- quently appear in the training corpus. Hence, if we have two responses of x in which one is generic and the other one contains more meaningful content, using L(C, θ θ θ) in Eq. 1 will put the same emphasis on optimizing each of their loss terms. Therefore, L(C, θ θ θ) contains a large amount of patterns from the generic responses, thus it is not surprised to see that the trained models are stuck into local opti- mum that are inclined to generate these patterns or their combinations.</p><p>Based on this observation, we argue that a good loss function of Seq2Seq for dialogue gen- eration should not be dominated by the patterns from generic responses. Here, we propose a re- weighting method for responses of a query x. Specifically, (x, y, θ θ θ) in Eq. 1 is modified to be:</p><formula xml:id="formula_1">w (x, y, θ θ θ) = w(y|x)(x, y, θ θ θ),<label>(3)</label></formula><p>where w(y|x) ∈ (0, 1] is a soft weight for a re- sponse y of a query x. In the implementation, we make the normalization of this loss at the mini-batch level for better computational efficiency. Hence, the loss of Eq. 2 for a mini-batch L(B, θ θ θ) takes the form:</p><formula xml:id="formula_2">L(B, θ θ θ) = x,y∈B w (x, y, θ θ θ) x,y∈B w(y|x) .<label>(4)</label></formula><p>We summarize two common properties for the responses:</p><p>• Responses with the patterns of frequently appearing in the training corpus tend to be generic. Here, the patterns refer to both the whole sentence or n-grams which can be de- scribed by similarities among responses.</p><p>• Very short and long responses should be avoid.</p><p>Owing to the MLE objective function, the Seq2Seq frameworks are inclined to gener- ate short responses that are universal replies. While long responses usually contain more specific information which may not be gener- alized to most conversation scenarios. Hence, high-quality responses tend to be with moder- ate length.</p><p>We propose an estimator by considering these two properties:</p><formula xml:id="formula_3">w(y|x, R, C) = Φ(y) max r∈R {Φ(r)} ,<label>(5)</label></formula><p>where R denotes all collected responses of x in C. For each response, the estimator gives a weight by:</p><formula xml:id="formula_4">Φ(y) = αE(y) + βF(y).<label>(6)</label></formula><p>Here, E(y) and F(y) correspond to the mentioned two properties respectively:</p><p>• E(y) = e −af (y) , where f (y) is a function re- lated to the frequency of response y. It could be formulated as</p><formula xml:id="formula_5">f (y) = max{0, Count(D(y, y j ) ≥ τ ) − b} ∀j ∈ |C|,</formula><p>where D(·) refers to the similarity between two sentences, a is a scale factor, b is bias and τ ∈ [0, 1] is a threshold specifying the similarity that two responses will be consid- ered identical. For instance, it could be the simplest strictly matching, which is used in our experiments. Other methods like cosine distance of TF-IDF (token or n-grams) can also be applied, but may encounter compu- tational issues for large corpus. A response with a higher frequency will be assigned with a smaller E(y).</p><p>• F(y) = e −c||y|−|ˆy|||ˆy|| , where |y| denotes the number of tokens in y, |ˆy||ˆy| = 1 |C| r∈C |r| refers to the average length of responses in the total training corpus, and c is a scale fac- tor. Here, the "moderate length" is set to the average length of responses of the total train- ing corpus. In practice, we have tried to use long responses (longer than average length) to fine-tune the Seq2Seq model. Though it slightly increases the average length of gener- ated responses, the generated responses suffer from more ungrammatical and influent issues. Hence, if a response is too short or long, it will receive a low score of F(y).</p><p>Mentioned hyper-parameters {α, β, a, b, τ, c} are constant values in the following experiments, which are set to {0.5, 0.5, 0.33, 3, 1.0, 0.33}. When we performed our experiments, we tried several hyper-parameter settings and found that our method is not sensitive to different hyper-parameters and achieves stable results in general. Hence, we do not spend many efforts to specifically tune these hyper-parameters. <ref type="bibr">Response</ref>  To validate that our design function in Eq. 5 and Eq. 6 are effective to weight the responses, <ref type="table">Table 1</ref> shows the weights of 8 responses for a query "其实 单身也挺好的 (It's pretty good to be single)". As can be seen, the weights are reasonable, in which the higher-ranked responses are more informative ones with low similarity frequency and moderate length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus and Evaluation</head><p>We crawl conversation pairs from some popular Chinese social media websites 1 , and select 7M high-quality pairs as our training corpus. Conven- tional metrics such as BLEU ( <ref type="bibr" target="#b3">Papineni et al., 2002</ref>) and perplexity, are improper to be used for response generation tasks. Following previous works ( <ref type="bibr">Li et al., 2016c</ref><ref type="bibr" target="#b2">Li et al., , 2017</ref>, we apply human annotations. We randomly sample 500 queries (not used in train- ing) as our test samples, and recruit 3 annotators to evaluate each generated response from two aspects:</p><p>• Fluency: 0 (unreadable), 1 (readable but with some grammar mistakes), 2 (fluent);</p><p>• Relevance: 0 (not relevant at all), 1 (relevant at a distant level), 2 (relevant, including the generic responses), 3 (relevant as well as in- teresting).</p><p>Acceptance is then automatically calculated as a metric reflecting whether the response is acceptable to real users. A response will be assigned 1 when it gets Fluency≥1 and Relevance≥2, otherwise it will be assigned 0. We implement our baseline Seq2Seq model us- ing its standard objective function in Eq. 1 with two LSTM layers for encoding/decoding and a standard beam search with a beam size of 5 (the best set- ting), termed as Seq2Seq. We also compare several Seq2Seq variants:</p><p>• Seq2Seq-RS: training with a subset by ran- domly sampling only one from the multiple responses for each query;</p><p>• Seq2Seq-MMI: applying the maximum mu- tual information ( <ref type="bibr">Li et al., 2016a</ref>) (only the MMI-bidi);</p><p>• Seq2Seq-DD: applying the diverse decoding algorithm ( <ref type="bibr">Li et al., 2016b</ref>);</p><p>• Ours-RW: calculating weights via our re- weighting method proposed in Section 2. Without applying any other tricks, we imple- ment three versions of our method by using E(·) only, F(·) only, a linear combination of E(·) and F(·) in Eq 6, termed as Ours- RW {E,F,EF} .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Discussion</head><p>Human annotation results are shown in <ref type="table" target="#tab_2">Table 2</ref>. Several observations can be made. First, Seq2Seq- RS performs slightly worse than the baseline model. This means that it does not work to simply discard a large amount of training data to construct a 1- to-1 query-response subset for training. Second, Seq2Seq-MMI not only provides no improvement for the baseline but also inclines to generate generic response. Third, Seq2Seq-DD obtains higher rel- evance and acceptance scores than the baseline, which shows its effectiveness by re-ranking more meaningful responses into higher positions in beam search. Fourth, our method achieves the best perfor- mance on almost all metrics. When we use strictly matched frequency of each response, Ours-RW E does not perform better than the baseline model because that the percentage of responses with fre- quency higher than 3 is about 0.5% in our training corpus. However, it still enhances the performance in Ours-RW EF , which performs the best and in- creases the acceptance of the baseline model from 0.42 to 0.55. This validates that the properties about similarity frequency and sentence length play important roles in generating better responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Evaluation Metrics Fluency</head><p>Relevance Acceptance Seq2Seq 1.96±3.8e-5 1.31±5.3e-3 0.42±4.7e-4 Seq2Seq-RS 1.97±8.1e-5 1.30±2.1e-3 0.42±9.9e-4 Seq2Seq-MMI 1.94±7.2e-5 1.19±4.0e-3 0.41±1.9e-4 Seq2Seq-DD 1.86±2.8e-3 1.40±1.5e-2 0.49±2.4e-3 Ours-RWE</p><p>1.95±1.9e-4 1.30±5.1e-3 0.42±4.2e-4 Ours-RWF</p><p>1.97±1.5e-4 1.47±2.1e-3 0.51±6.3e-4 Ours-RWEF 1.96±8.3e-5 1.59±1.9e-2 0.55±4.4e-3 Specifically, the average percentage of the gener- ated responses that are assigned to relevance rating 2 (relevant, including the generic responses) and 3 (relevant as well as interesting) are presented in <ref type="table" target="#tab_5">Table 4</ref>. It shows that our method achieves higher relevance score owing to generating more high- quality responses with rating 3.</p><p>To validate that our method is effective to reduce the number of generated generic responses, we calculated the distinct-1 and distinct-2 ( <ref type="bibr">Li et al., 2016a</ref>) for the compared methods respectively, which are the number of distinct unigrams and bi- grams divided by total number of generated words respectively. As shown in <ref type="table" target="#tab_6">Table 5</ref>, Ours-RW EF achieves the best performance on the two metrics. This indicates that our model often outputs more meaningful and relevant responses than the other compared methods.</p><p>We further randomly sample another 100K queries (not used in training) and use the various models to generate responses. We compare the frequencies of several common generic responses appearing in the generated results, as shown in Ta- ble 6. It shows that our method can significantly reduce the number of generic responses. For in- stance, we reduce about 75% of the case "我也 不知道 (I don't know, either.)" and 77% of the case "我也想知道 (I want to know, too)" to be generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we propose a statistical re-weighting method to weight multiple responses differently and optimize the MLE objective function.    two terms according to the similarity frequency and its length. Experiments show that our ap- proach improves the performance over the base- line models and reduces the number of generated generic responses significantly. It indicates that mismatching issue of objective function can be alleviated through such similar re-weighting meth- ods, by which current encoder-decoder architec- tures can take full use of the m-to-n training corpus and model the dialogue generation tasks better.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An illustration of the differences between NMT and dialogue generation. Response 4 is the potential cases that are not collected in corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Human annotation results.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>The weight of each response is calculated based on</figDesc><table>Query 
Response 
Seq2Seq 
Seq2Seq-MMI 
Seq2Seq-DD 
Ours-RWEF 

我要生气了 
我也生气了 
生气了 
我也生气了 
不要生气 

I'm going to be angry. 
So do I. 
I'm angry. 
So do I. 
Don't be angry. 

最近有什么好书推荐 
看你喜欢什么类型的 
我也想去看电影 
你喜欢什么类型的 
《红楼梦》 

Would you like to recom-
mend me some good books? 

It depends on what kind 
of books you like? 

I want to see the 
movie, too. 

What kind of books 
do you like? 

Dream of the Red 
Chamber 

做人不一定要风风光光 
一定要 
我也不知道 
是啊。。。 
做人一定要善良 

It's not necessary to be a suc-
cessful and grand man. 

Must be 
I don't know, ei-
ther. 

Yes... 
Everyone should try 
to be a kind man. 

这几天嗓子疼 
我也不知道 
我也想去 
我也是。。。 
我这两天也是 

I have a sore throat recently. I don't know, either. 
I want to go, too 
So do I... 
So do I these days . 

二号煤矿放几天假 
假的 
我也想放假 
假的，假的 
我放了3天 

How many days did people 
in No.2 coal mine take off? 

False 
I want to have a 
holiday, too 

False, False 
I took three days off. 

孟记普洱茶专营店一帖 
我也想吃 
我也想喝 
铁观音，茶，茶，茶 
我喜欢喝茶 

An advertising of Mengji's 
Pu'er tea shop. 

I want to eat, too. 
I want to drink, too. Tat-Kuan-Yin Tea, 
tea, tea, tea 

I like drinking tea. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 3 : Examples of responses generated by Seq2Seq, Seq2Seq-MMI, Seq2Seq-DD and Ours-RW EF .</head><label>3</label><figDesc></figDesc><table>Model 
rating 2(%) rating 3(%) 

Seq2Seq 
31.3 
10.6 
Seq2Seq-MMI 
35.8 
4.4 
Seq2Seq-DD 
37.1 
11.7 
Ours-RWEF 
36.8 
18.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Comparisons on the average percentage of 
the generated responses that are assigned to relevance 
rating 2 and 3. 

Model 
distinct-1 distinct-2 

Seq2Seq 
0.170 
0.307 
Seq2Seq-MMI 
0.140 
0.259 
Seq2Seq-DD 
0.131 
0.170 
Ours-RWEF 
0.173 
0.359 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Performances on the metrics distinct-1 and 
distinct-2. 

</table></figure>

			<note place="foot" n="1"> Weibo: www.weibo.com, Baidu Tieba: tieba. baidu.com, and Zhihu: www.zhihu.com</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Smart reply: Automated response suggestion for email</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balint</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">László</forename><surname>Lukács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">Conference on Special Interest Group on Discourse and Dialogue</title>
		<meeting><address><addrLine>SIGDIAL</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sequence to backward and forward sequences: A content-introducing approach to generative short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting on Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A conditional variational framework for dialog generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuzi</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akiko</forename><surname>Aizawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Long</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.00316</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Diverse beam search: Decoding diverse solutions from neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ashwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Vijayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02424</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Why do neural dialog systems generate short and meaningless replies? a comparison between dialog and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.02250</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziang</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.09534</idno>
		<title level="m">Neural text generation: A practical guide</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural response generation via gan with an approximate embedding layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seqgan: Sequence generative adversarial nets with policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mechanism-aware neural machine for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganbin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongyu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
