<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Summarizing topical contents from PubMed documents using a thematic analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information National Library of Medicine</orgName>
								<orgName type="institution">National Institutes of Health Bethesda</orgName>
								<address>
									<postCode>20894</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lana</forename><surname>Yeganova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information National Library of Medicine</orgName>
								<orgName type="institution">National Institutes of Health Bethesda</orgName>
								<address>
									<postCode>20894</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">John</forename><surname>Wilbur</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">National Center for Biotechnology Information National Library of Medicine</orgName>
								<orgName type="institution">National Institutes of Health Bethesda</orgName>
								<address>
									<postCode>20894</postCode>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Summarizing topical contents from PubMed documents using a thematic analysis</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Improving the search and browsing experience in PubMed is a key component in helping users detect information of interest. In particular, when exploring a novel field, it is important to provide a comprehensive view for a specific subject. One solution for providing this panoramic picture is to find sub-topics from a set of documents. We propose a method that finds sub-topics that we refer to as themes and computes representative titles based on a set of documents in each theme. The method combines a thematic clustering algorithm and the Pool Adjacent Violators algorithm to induce significant themes. Then, for each theme, a title is computed using PubMed document titles and theme-dependent term scores. We tested our system on five disease sets from OMIM and evaluated the results based on normalized point-wise mutual information and MeSH terms. For both performance measures, the proposed approach outperformed LDA. The quality of theme titles were also evaluated by comparing them with manually created titles.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>PubMed 1 , currently a collection of about 25 mil- lion bibliographic records, has grown exponen- tially in size. With the abundance and diversity of information in PubMed many queries retrieve thousands of documents making it difficult for users to browse the results and identify the infor- mation most relevant to their topic of interest. The query 'cystic fibrosis', for example, retrieves pa- pers that discuss different aspects of the disease, including its clinical features, treatment options, <ref type="bibr">1</ref> http://pubmed.gov diagnosis, etc. A possible solution to this problem is to automatically group the retrieved documents into meaningful thematic clusters or themes (these terms are used interchangeably). However, clus- tering alone does not solve the problem entirely, as a significant amount of human post-processing is required to infer the topic of the cluster.</p><p>There exists a vast collection of probabilistic clustering methods. One common problem among most of them is that different results are obtained depending on the cluster initialization, suggesting that some clusters are unstable or weak. How- ever, there is no obvious way to effectively and efficiently evaluate the quality of clusters. In this paper, we combine EM-based thematic cluster- ing <ref type="bibr" target="#b9">(Kim and Wilbur, 2012</ref>) with the Pool Adja- cent Violators (PAV) algorithm <ref type="bibr" target="#b1">(Ayer et al., 1955;</ref><ref type="bibr" target="#b19">Wilbur et al., 2005</ref>). PAV is an isotonic regression algorithm which we use as a method for convert- ing a score into a probability. Here, we show how PAV can be applied to evaluate the quality of clus- ters.</p><p>Another issue that motivated this research is that most existing algorithms produce clusters that are not self-descriptive. Presenting meaningful titles can significantly improve the user perception of clustering results. To that end, we utilize PubMed document titles and cluster-related term scores to automatically obtain a title for each theme. The method results in thematic clusters of documents with cluster titles.</p><p>Studies similar to our approach are ASI (Adap- tive Subspace Iteration) ( <ref type="bibr" target="#b10">Li et al., 2004</ref>) and SKWIC (Simultaneous Keyword Identification and Clustering of text documents) ( <ref type="bibr" target="#b5">Frigui and Nasraoui, 2004</ref>). Both perform document clus- tering and cluster-dependent keyword identifica- tion simultaneously. SKWIC can only produce hard clustering, while ASI is computationally very expensive as it heavily depends on matrix opera- tions. A study by <ref type="bibr" target="#b6">Hammouda et al. (2005)</ref> sug-gests automatic keyphrase extraction from a clus- ter of documents as a surrogate to providing a clus- ter title, but they treat document clustering and cluster-dependent keyword extraction as separate problems.</p><p>Topic modeling <ref type="bibr" target="#b7">(Hofmann, 1999;</ref><ref type="bibr" target="#b3">Blei et al., 2003;</ref><ref type="bibr" target="#b2">Blei and Lafferty, 2005</ref>) is the most pop- ular and an alternative approach that has a simi- lar underlying goal of discovering hidden thematic structure of a document collection and organizing the collection according to the discovered topics. Topic models are based upon the idea that docu- ments are mixtures of topics, where a topic is a probability distribution over words <ref type="bibr" target="#b17">(Steyvers and Griffiths, 2007)</ref>. However, topic modeling is not a document clustering scheme in nature. Although a list of keywords that represent a topic is available, the title of the cluster may not be evident.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>We here describe the EM-based clustering algo- rithm, and show how PAV is incorporated with it to yield the PAV-EM thematic clustering tech- nique. We further present a cluster summarization method to induce theme titles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Theme definition</head><p>Let D be a document set and let T be the set of terms in D. Let R denote the relation between el- ements of T and D. tRd means t ∈ d. We define a theme as a subject that is described by non-empty sets U ⊆ T and V ⊆ D, where all the elements of U have a high probability of occurring in all the element of V . An EM framework is used to ex- tract subject terms for a theme <ref type="bibr" target="#b20">(Wilbur, 2002</ref>). In addition to the observed data R, a theme is defined by the latent indicator variables</p><formula xml:id="formula_0">z d , {z d } d∈D . The parameters are Θ = U (U = n U ), {p t , q t } t∈U , {r t } t∈T , (1)</formula><p>where n U is the size of the set U . For any t ∈ U , p t is the probability that for any d ∈ V , tRd. q t is the probability that for any d ∈ D − V , tRd. For any t ∈ T , r t is the probability that for any d ∈ D, tRd. Assuming all relations tRd are in- dependent of each other, the goal is to obtain the highest probabilities</p><formula xml:id="formula_1">p(R, {z d }|Θ) = p(R|{z d }, Θ)p({z d }|Θ). (2)</formula><p>E-step (expectation step) evaluates the expectation of the logarithm of Eqn. 2. M-step (maximization</p><formula xml:id="formula_2">Algorithm 1 PAV-EM algorithm Let D be the dataset, where d ∈ D.</formula><p>Give a value for the parameter q.</p><p>Set X = ∅. for i ← 1, n do Create q random clusters. Run the theme clustering algorithm. For each cluster C and d with pz</p><formula xml:id="formula_3">C d , X ← X ∪ {&lt; pz C d , 1, 1 &gt;} 2 if d ∈ C, X ← X ∪ {&lt; pz C d , 1, 0 &gt;} if d / ∈ C.</formula><p>Obtain the PAV function, P AV (pz C d ), over X.</p><p>Set S = ∅, where S is the output cluster set. repeat Create q random clusters for {d|d / ∈ ∪S}. Run the theme clustering algorithm. Select any cluster C, where</p><formula xml:id="formula_4">C = {d|d ∈ C, P AV (pz C d ) &gt; 0.9} satisfies |C | &gt; 10. S ← S ∪ {C }.</formula><p>until no more changes in S. step) maximizes this expectation over the parame- ters Θ. For each term, t, we define a quantity α t which is the difference between the contribution coming from t depending on whether u t = 1 or u t = 0. The maximization is completed by choos- ing the n U largest α t 's and setting u t = 1 for each of them and u t = 0 for all others. Details of this theme extraction scheme can be found in Wilbur (2002).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">PAV-EM thematic clustering</head><p>In thematic clustering, a document is assigned to a theme that has the highest probability to the document ( <ref type="bibr" target="#b9">Kim and Wilbur, 2012)</ref>. Although this approach shows a reasonable performance for theme-based document clustering, the dynamic nature of random initialization and multiple sub- jects described in a document may create many weak themes. Moreover, there is no clear guide- line to distinguish strong and weak themes. Thus, we here propose a method that extracts strong themes more effectively. In the EM-based theme extraction scheme, the log odds score pz C d indi- cates the extent to which a document d is cou- pled with a specific theme C. If a cluster in-cludes a reasonable number of documents that have high pz C d s, it indicates that the cluster rep- resents a strong theme. Therefore, we can obtain strong themes by collecting these clusters.</p><p>Let the probability p(score) be a monoton- ically non-decreasing function of score. The PAV algorithm <ref type="bibr" target="#b1">(Ayer et al., 1955;</ref><ref type="bibr" target="#b19">Wilbur et al., 2005</ref>) is a regression method to derive from the data that monotonically non-decreasing estimate of p(score) which assigns maximal likelihood to the data. For our approach, score = pz C d . Algorithm 1 shows the theme clustering process using the PAV algorithm. For the given dateset D and the initial number of clusters q, theme cluster- ing is performed n times, and an isotonic regres- sion function is learned by applying the PAV algo- rithm. Note that q is an initial guess for the number of clusters and it is not guaranteed to remain the same in the output set. For our experiments, we set q = 50 and n = 100. After the PAV algorithm is applied, theme clustering is performed. At each iteration, we select any cluster in which there are more than 10 documents with PAV scores higher than 0.9. Unselected documents are re-used for clustering in the next iteration. This procedure is repeated until there are no more changes in the se- lected cluster set S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Theme summarization</head><p>After obtaining themes (document clusters and their subject terms), we summarize each theme by choosing a text segment from PubMed document titles. A title should cover as many subject terms as possible, but also it should be well-formed, i.e. be descriptive enough and humanly understand- able. To achieve this goal, we first extract all pos- sible candidates from document titles as follows: (i) Extract all possible candidates as n-grams, where n = 1, ..., 20. Noun phrases are treated as units and must be totally inside or outside a candidate.</p><p>(ii) Check POS tags for starting and ending words in a candidate. Starting with a con- junction, verb, preposition and symbol is not allowed. Ending with a conjunction, verb, preposition, symbol, determiner, adjective or certain pronouns is not allowed.</p><p>(iii) Discard any candidates that start or end with '-' or '.'. The candidates including certain characters such as '/', ';', ':' are also re- moved.</p><p>(iv) Check grammatical dependency relations. We discard candidates for which the head word of a preposition does not appear in the same candidate as the proposition. Also, we validate the case, 'between A and B', so that A and B are not separated.</p><p>Next, for each candidate, a score is calculated by score(cand i ) = log t∈U (tf t α t )</p><formula xml:id="formula_5">t / ∈U tf t ,<label>(3)</label></formula><p>where tf t is the term frequency of the term t.</p><p>However, an ideal title should have enough words to be descriptive, hence we subtract (len(cand i )− 5) 2 from score(cand i ), where len(cand i ) is the number of words in cand i , and choose the top score as a title.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>We applied our method to the five disease sets, "cystic fibrosis", "deafness", "DiGeorge syndrome", "autism" and "hypertrophic car- diomyopathy" from OMIM 3 . These sets con- sist of 3000, 3000, 956, 2917 and 1997 PubMed documents, respectively, and are avail- able at http://www.ncbi.nlm.nih.gov/ CBBresearch/Wilbur/IRET/PAVEM. For evaluating PAV-EM and comparing with the topic modeling method, latent Dirichlet allocation (LDA) ( <ref type="bibr" target="#b3">Blei et al., 2003)</ref>, both approaches were performed 10 times for each disease set and scores were averaged over all runs. Mallet 4 was used to run LDA. The same tokenization was applied to LDA and PAV-EM. The number of topics given for LDA was 50 and the recommended optimization parameter was used for producing LDA topics. <ref type="table">Table 1</ref> presents average runtimes 5 for LDA and PAV-EM. LDA and PAV-EM spent 15.2 and 13.3 seconds on average for processing the small- est set, "DiGeorge syndrome". However, in larger sets, e.g. "autism", it took 46.9 and 31.3 seconds for LDA and PAV-EM, respectively. We also ran another implementation 6 of LDA, which was 30 times slower than Mallet. While PAV-EM and <ref type="table">Table 1</ref>: Average runtimes for LDA and PAV-EM in seconds. Sets 1, 2, 3, 4 and 5 are "cystic fibro- sis", "deafness", "DiGeorge syndrome", "autism" and "hypertrophic cardiomyopathy", respectively.  LDA can be implemented in parallel computa- tion 7 , this indicates that PAV-EM may be more ef- ficient to obtain themes for a larger set of PubMed documents.</p><note type="other">Dataset LDA PAV-EM Set 1 25.7 18.4 Set 2 36.5 24.7 Set 3 15.2 13.3 Set 4 46.9 31.3 Set 5 30.3 19.2</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The PAV-EM algorithm automatically learns themes from unlabeled PubMed documents, hence the performance measures that are used in super- vised learning cannot be applied to our setup. Re- cent studies have shown more interest in topic co- herence measures ( <ref type="bibr" target="#b14">Newman et al., 2010;</ref><ref type="bibr" target="#b13">Mimno et al., 2011</ref>), which capture the semantic interpretability of topics based on subject terms. <ref type="table" target="#tab_1">Table 2</ref> shows the topic coherence scores measured by normalized point-wise mutual infor- mation (NPMI). For both top 5 and top 10 sub- ject terms, PAV-EM achieves better NMPI scores than LDA. NPMI is known to be strongly corre- lated with human ratings <ref type="bibr" target="#b0">(Aletras and Stevenson, 2013;</ref><ref type="bibr" target="#b16">Röder et al., 2015)</ref> and is defined by</p><formula xml:id="formula_6">NPMI = N i=2 i−1 j=1 log p(t i ,t j )+ p(t i )p(t j ) − log (p(t i , t j ) + ) ,<label>(4)</label></formula><p>where p(t i , t j ) is the fraction of documents con- taining both terms t i and t j , and N indicates the number of top subject terms. = 1 D is the smooth- ing factor, where D is the size of the dataset.</p><p>MeSH (Medical Subject Headings) is a con- trolled vocabulary for indexing and searching biomedical literature <ref type="bibr" target="#b11">(Lowe and Barnett, 1994)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MeSH Method</head><p>Prec. Recall F1  <ref type="table">Table 3</ref>: Classification performance based on top significant MeSH terms appearing in themes.</p><p>MeSH terms assigned to an article are often used to indicate the topics of the article, thus these terms can be used to identify how well documents are grouped by topics. In each cluster, p-values of MeSH terms are calculated using the hypergeo- metric distribution <ref type="bibr" target="#b8">(Kim and Wilbur, 2001)</ref>, and the top N significant MeSH terms are used to calculate precision, recall and F1. <ref type="table">Table 3</ref> com- pares PAV-EM with LDA 8 for the MeSH term- based performance. In the table, PAV-EM pro- vides higher recall and F1 for top 1 and top 3 MeSH terms. Higher recall has an advantage in our task because the theme summarization pro- cess uses a consensus among PubMed documents to reach a theme title.</p><p>The next experiment was performed to compare machine generated titles with manually labeled ti- tles. Although human judgements are subjective, it is not uncommon to collect human judgements for evaluating topic modeling methods ( <ref type="bibr" target="#b12">Mei et al., 2007;</ref><ref type="bibr" target="#b21">Xie and Xing, 2013)</ref>. To validate the performance of the theme summariza- tion approach, we first chose 500 documents from each disease set, and produced themes and titles. For each topic, five strongest themes were chosen, and they were shown to three human annotators with extracted subject terms. <ref type="table">Table 4</ref> shows an example of the proposed approach and the man- ual annotation for the "hypertrophic cardiomyopa- thy" set. Among 25 themes, our approach cor- rectly identified 21 theme titles. We assumed that a machine-generated title was correct if it included any of manually annotated titles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This study was inspired by an EM-based thematic clustering approach. In this probabilistic frame- work, theme terms are iteratively selected and documents are assigned to a most likely theme. The number of themes is dynamically adjusted Proposed approach <ref type="table" target="#tab_1">Annotator 1  Annotator 2  Annotator 3  cardiac myosin binding pro- tein c  myosin binding protein c  cardiac myosin binding pro- tein c  cardiac myosin binding pro- tein c  ptpn11 mutations in leopard  syndrome  ptpn11 mutations in leopard  syndrome  ptpn11 mutations in leopard  syndrome  ptpn11 mutations in leopard  syndrome  cytochrome c oxidase  cytochrome c oxidase  mitochondrial cytochrome- c-oxidase deficiency  mitochondrial cytochrome  c oxidase deficiency  friedreich ataxia and dia- betes mellitus  friedreich ataxia  friedreich ataxia  friedreich ataxia</ref> hepatitis c virus infection hepatitis c virus role of hepatitis c virus in cardiomyopathies hepatitis c virus infection <ref type="table">Table 4</ref>: Comparison of the titles generated from the proposed approach and manual annotation for the "hypertrophic cardiomyopathy" set.</p><p>by probabilistic evidence from documents. The PAV algorithm is utilized to measure the quality of themes. After themes are identified, subject term weights and PubMed document titles are used to form humanly understandable titles. The experi- mental results show that our approach provides a useful overview of a set of documents. In addition, the method may allow for a new way of brows- ing by semantically clustered documents as well as searching with context-based query suggestions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : NMPI scores for LDA and PAV-EM.</head><label>2</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> The second and the third arguments in the bracket are the weight and the probability estimate of the data, respectively.</note>

			<note place="foot" n="3"> http://www.ncbi.nlm.nih.gov/omim 4 http://mallet.cs.umass.edu 5 Both methods were tested on a single linux server. The processing times reported do not include the preprocessing stages done by Mallet and our implementation. 6 http://www.cs.princeton.edu/ ˜ blei/ lda-c</note>

			<note place="foot" n="7"> A parallel implementation of LDA appears in Wang et al. (2009)</note>

			<note place="foot" n="8"> For LDA, each document was assigned to the highest scoring topic.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Donald C. Comeau and Rezarta Islamaj Do˘ gan for their con-tribution to the manual evaluation. This research was supported by the Intramural Research Pro-gram of the NIH, National Library of Medicine.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluating topic coherence using distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Semantics (IWCS 2013)</title>
		<meeting>International Conference on Computational Semantics (IWCS 2013)</meeting>
		<imprint>
			<date type="published" when="2013-03" />
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An empirical distribution function for sampling with incomplete information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Brunk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Ewing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Silverman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="641" to="647" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Correlated topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems (NIPS 2005)</title>
		<meeting>Advances in Neural Information essing Systems (NIPS 2005)</meeting>
		<imprint>
			<date type="published" when="2005-12" />
			<biblScope unit="page" from="147" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Reading tea leaves: How humans interpret topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems (NIPS 2009)</title>
		<meeting>Advances in Neural Information essing Systems (NIPS 2009)</meeting>
		<imprint>
			<date type="published" when="2009-12" />
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Simultaneous Clustering and Dynamic Keyword Weighting for Text Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nasraoui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CorePhrase: keyphrase extraction for document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hammouda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Matute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning and Data Mining</title>
		<meeting>International Conference on Machine Learning and Data Mining</meeting>
		<imprint>
			<date type="published" when="2005-07" />
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1999-08" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Corpus-based statistical screening for content-bearing terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="259" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Thematic clustering of text documents using an EM-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. John</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Semantics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>Suppl 3</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Document clustering via adaptive subspace iteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ogihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="218" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Understanding and using the medical subject headings (MeSH) vocabulary to perform literature searches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">O</forename><surname>Barnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">271</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1103" to="1108" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic labeling of multinomial topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2007)</title>
		<meeting>ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2007)</meeting>
		<imprint>
			<date type="published" when="2007-08" />
			<biblScope unit="page" from="490" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Automatic evaluation of topic coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<title level="m">Proc. Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2010)</title>
		<meeting>Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2010)</meeting>
		<imprint>
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploring the space of topic coherence measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Röder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Both</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hinneburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM International Conference on Web Search and Data Mining (WSDM 2015)</title>
		<meeting>ACM International Conference on Web Search and Data Mining (WSDM 2015)<address><addrLine>February</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="399" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<title level="m">Probabilistic Topic Models. Erlbaum</title>
		<meeting><address><addrLine>Hillsdale, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PLDA: Parallel latent Dirichlet allocation for large-scale applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Algorithmic Aspects in Information and Management (AAIM 2009)</title>
		<meeting>International Conference on Algorithmic Aspects in Information and Management (AAIM 2009)</meeting>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="301" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. John</forename><surname>Wilbur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yeganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<title level="m">The synergy between PAV and AdaBoost. Machine Learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="71" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A thematic analysis of the AIDS literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. John</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Pacific Symposium on Biocomputing</title>
		<meeting>Pacific Symposium on Biocomputing</meeting>
		<imprint>
			<date type="published" when="2002-01" />
			<biblScope unit="page" from="386" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Integrating document clustering and topic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Uncertainty in Artificial Intelligence (UAI 2013)</title>
		<meeting>Conference on Uncertainty in Artificial Intelligence (UAI 2013)</meeting>
		<imprint>
			<date type="published" when="2013-07" />
			<biblScope unit="page" from="694" to="703" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
