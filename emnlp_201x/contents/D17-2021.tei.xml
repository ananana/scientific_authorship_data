<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Interactive Visualization and Manipulation of Attention-based Neural Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesong</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NAVER Corp</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joong-Hwi</forename><surname>Shin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NAVER Corp</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Seok</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NAVER Corp</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Interactive Visualization and Manipulation of Attention-based Neural Machine Translation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">EMNLP System Demonstrations</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="121" to="126"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>While neural machine translation (NMT) provides high-quality translation, it is still hard to interpret and analyze its behavior. We present an interactive interface for visualizing and intervening behavior of NMT, specifically concentrating on the behavior of beam search mechanism and attention component. The tool (1) visualizes search tree and attention and (2) provides interface to adjust search tree and attention weight (manually or automatically) at real-time. We show the tool help users understand NMT in various ways.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in neural machine translation (NMT) <ref type="bibr" target="#b12">(Sutskever et al., 2014</ref>) have changed the direction of machine translation community. Com- pared to traditional phrase-based statistical ma- chine translation (SMT) <ref type="bibr" target="#b5">(Koehn, 2010)</ref>, NMT pro- vides more accurate and fluent translation results. Companies also have started to adopt NMT for their machine translation service.</p><p>However, it is still challenging to analyze trans- lation behavior of NMT. While SMT provides in- terpretable features (like phrase table), NMT di- rectly learns complex features which are obscure to human. This is especially problematic in the case of wrong translation, since it is even hard to understand why the system generated such sen- tences.</p><p>To help the analysis, we propose a tool for vi- sualizing and intervening NMT behavior, concen- trated on beam search decoder and attention. The features can be grouped by two categories:</p><p>• Visualizing decoder result, including how decoder assigns probability to each token . By hovering mouse over node, its corresponding output candi- dates can be seen. User may click the candidate to expand node which are discarded during search (section 3.3).</p><p>(word, sub-word, etc.), how beam search maintains and discards intermediate hypothe- ses, and how attention layer assigns attention weight. This enables detailed observation of decoder behavior.</p><p>• Intervening in decoder behavior, including manually expanding hypothesis discarded during search and adjusting attention weight. This helps understanding how the compo- nents affect translation quality.</p><p>We show the mechanism of visualization (Sec- tion 3.1 and 3.2) and manipulation (Section 3.3 and 3.4) and its usefulness with examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been various methods proposed for vi- sualizing and intervening neural models for NLP. ( ) provides a concise literature re- view.</p><p>Visualization and manipulation of NMT could be grouped into three parts: RNN (of encoder and decoder), attention (of decoder), and beam search (of decoder).  Attention ( <ref type="bibr" target="#b0">Bahdanau et al., 2014;</ref><ref type="bibr" target="#b9">Luong et al., 2015</ref>) is an important component for improving NMT quality. Since the component behaves like alignment in traditional SMT, it has been proposed to utilize attention during training ( <ref type="bibr" target="#b1">Cheng et al., 2015;</ref><ref type="bibr" target="#b14">Tu et al., 2016b</ref>) or during decoding ( <ref type="bibr" target="#b15">Wu et al., 2016)</ref>. In this work, we propose a way to manipulate attention and to understand the behav- ior.</p><p>Beam search is known to improve quality of NMT translation output. However, it is also known that larger beam size does not always helps but rather hurts the quality ( <ref type="bibr" target="#b13">Tu et al., 2016a</ref>). There- fore it is important to understand how beam search affects quality. ( <ref type="bibr" target="#b15">Wu et al., 2016;</ref><ref type="bibr">Freitag and AlOnaizan, 2017)</ref> proposed several penalty functions and pruning methods for beam search. We directly visualize beam search result as a tree and manually explore hypotheses discarded by decoder. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interactive Beam Search</head><p>We propose an interactive tool for visualizing and manipulating NMT decoder behavior. The sys- tem consists of two parts: back-end NMT server and front-end web interface. NMT server is re- sponsible for NMT computation. Web interface is responsible for requesting computation to NMT server and showing results at real time.</p><p>For back-end implementation, we use two NMT models. For English-Korean (en-ko), we use a model used in Naver Papago ( <ref type="bibr" target="#b6">Lee et al., 2016</ref>) ser- vice 1 ported to TensorFlow. For German-English (de-en), we adopted Nematus 2 and pretrained models provided by <ref type="bibr" target="#b10">(Sennrich et al., 2016)</ref>. For front-end we implemented JavaScript-based web  page with d3.js 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Search Tree Visualization</head><p>To understand how beam search decoder selects and discards intermediate hypothesis, we first plot all hypotheses as a tree <ref type="figure" target="#fig_1">(Figure 2, 3</ref>). For each in- put token (word or sub-word) and decoder (RNN) state vector, the decoder computes output prob- ability of all possible output token, then beam search routine selects token based on its probabil- ity value <ref type="figure" target="#fig_3">(Figure 4)</ref>. We plot each input and out- put token as tree node, and input-output relation as edge. If a node is mouse-hovered, it shows its next possible tokens with highest probability, in- cluding pruned ones <ref type="figure" target="#fig_0">(Figure 1</ref>). We also visualize output probability of node using edge thickness; thicker edge means higher probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Attention Visualization</head><p>We show the attention weight of (partially) gen- erated sentence as table ( <ref type="figure" target="#fig_4">Figure 5</ref>) and as graph ( <ref type="figure" target="#fig_5">Figure 6</ref>). Table interface provides detailed infor- mation, and graph interface provides more concise view therefore better for long sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Search Tree Manipulation</head><p>We implemented an interface to manually expand nodes which are discarded during beam search. In search tree visualization <ref type="figure" target="#fig_6">(Figure 7</ref>) or attention manipulation dialog <ref type="figure">(Figure 9</ref>), a user can click one of output candidate (green node) then the sys- tem computes its next outputs and extends the tree. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Attention Manipulation</head><p>We are interested in understanding attention layer of ( <ref type="bibr" target="#b0">Bahdanau et al., 2014;</ref><ref type="bibr" target="#b9">Luong et al., 2015)</ref>, es- pecially the role and effect of attention weights. To achieve it, we modified NMT decoder to ac- cept arbitrary attention weight instead of what the decoder computes <ref type="figure" target="#fig_7">(Figure 8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Manual Adjustment of Attention Weight</head><p>For given memory cells (encoder outputs) (m 1 , · · · , m n ) and decoder internal state h, the attention layer first computes relevance score of memory cell s i = f (m i , h) and attention weight w i = softmax(s 1 , · · · , s n ) i . Then memory cells which is given by user or computed to maximize probability of output token.</p><p>Figure 9: Result of attention manipulation for two output tokens "" and "".</p><p>are summarized into one fixed vector ( ˜ m) via weighted sum: ˜ m = i w i m i . The summarized vector is fed to next layer to compute output token probabilities: p(y j ) = g( ˜ m, h) j . We modified the decoder to accept custom weight w = (w 1 , · · · w n ) instead of original ones w, when w is provided by user. We also im- plemented front-end interface to adjust custom weight <ref type="figure">(Figure 9</ref>). If user drags circle on the bar, the weights are adjusted and the system computes new output probabilities using the weight. It helps to understand what is encoded in memory cell and how decoder utilizes the attended memory˜mmemory˜ memory˜m. For example, user may increase or decrease weight of specific memory cell and observe its effect. <ref type="figure">Figure 9</ref> shows an illustrative example that how adjusting attention weight could change output probability distribution. When weight of "highly" and "tone" are high, NMT puts high probability to "" ("tone of voice"). When weight of "dis- tinctive" is high, NMT recognizes "tone" in cur- rent context (musical instrument) and puts high probability to "" ("timbre").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Automatic Adjustment of Attention Weight</head><p>We also implemented a method to find attention weight maximizing output probability of a specific token. For attention weight w and token y, we see this problem as a constrained optimization: maxi- mize log p(y|w, · · ·) s.t. w i ≥ 0, i w i = 1. Since the toolkits we use (TensorFlow 4 and Theano 5 ) provide unconstrained gradient descent optimizer, we cast the original problem to unconstrained op- timization: instead of weight w, we optimize un- normalized score s before softmax, initialized as s i = log w i . The method can be used to opti- mize weight for specific time step <ref type="figure">(Figure 9</ref>) or for whole sentence <ref type="figure" target="#fig_0">(Figure 10</ref>).</p><p>For English-Korean, this technique is particu- larly useful because the original attention weight is sometimes hard to interpret. Due to ordering differences between two languages, en-ko NMTs tend to generate diverse sentences and they have very different orderings among each other. In <ref type="figure" target="#fig_2">Figure 3</ref>, input sentence is "As a bass player, he is . . . ". NMT puts high probability to output sentences starting with either "" ("bass") or "" ("he"), since both are valid. Therefore, <ref type="figure" target="#fig_0">Figure 10</ref>: Two attention graphs of en-ko NMT. The first one shows attention weights from NMT. The second one shows attention weights adjusted to maximize target sentence. It reveals clearer and more interpretable relation than original attention.</p><p>corresponding source words have high attention weights (0.14 for "bass" and 0.07 for "he"). Since output token is chosen after attention, the atten- tion weights do not necessarily look like alignment between source and output sentences, but rather look like a mixture of alignments of possible out- put sentences.</p><p>Once output token is chosen, we can find new attention weight which increases probability of output token, which would be more interpretable than the original weight. An example of such ad- justment is shown at <ref type="figure" target="#fig_0">Figure 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose a web-based interface for visualiz- ing, investigating and understanding neural ma- chine translation (NMT). The tool provides sev- eral methods to understand beam search and at- tention mechanism in an interactive way, by visu- alizing search tree and attention, expanding search tree manually, and changing attention weight ei- ther manually or automatically. We show the vi- sualization and manipulation helps understanding NMT behavior.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Beam search tree interface. Beam search result is shown as a tree (section 3.1). By hovering mouse over node, its corresponding output candidates can be seen. User may click the candidate to expand node which are discarded during search (section 3.3).</figDesc><graphic url="image-1.png" coords="1,314.36,222.54,204.09,93.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Beam search tree of de-en NMT.</figDesc><graphic url="image-3.png" coords="2,94.68,208.22,408.17,116.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Beam search tree of en-ko NMT. Input sentence is: "As a bass player, he is known for his highly distinctive tone and phrasing."</figDesc><graphic url="image-4.png" coords="2,314.36,384.13,204.10,62.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Diagram of NMT decoder step. Search tree visualization (Figure 2) shows input and output tokens as a tree.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Attention Table. Weight is represented as number and green color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Attention Graph Dialog. Weight is represented as red color.</figDesc><graphic url="image-5.png" coords="3,94.68,62.81,408.20,157.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Manual expansion of nodes not explored at Figure 2. For the partial sentence "the Pal@@ li@@ ative Care is", new subtree ".. . used when there. .. " are created.</figDesc><graphic url="image-7.png" coords="3,314.36,318.20,204.10,114.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Diagram of attention manipulation mechanism. The dashed components are original component of NMT decoder. Here "attention weight" is replaced by "custom attention weight" which is given by user or computed to maximize probability of output token.</figDesc><graphic url="image-8.png" coords="4,72.00,109.19,226.77,140.29" type="bitmap" /></figure>

			<note place="foot" n="1"> https://papago.naver.com/ 2 https://github.com/rsennrich/nematus</note>

			<note place="foot" n="3"> https://d3js.org/</note>

			<note place="foot" n="4"> https://www.tensorflow.org/ 5 http://deeplearning.net/software/ theano/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Agreement-based joint training for bidirectional attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/1512.04650</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Beam search strategies for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<idno>abs/1702.01806</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Decoding the thought vector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02078</idno>
		<title level="m">Visualizing and understanding recurrent networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">papago: A machine translation service with word sense disambiguation and currency conversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoung-Gyu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Seok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joong-Hwi</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Xiu</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Seob</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="185" to="188" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01066</idno>
		<title level="m">Visualizing and understanding neural models in nlp</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Understanding neural networks through representation erasure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno>abs/1612.08220</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edinburgh neural machine translation systems for wmt 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="371" to="376" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Visual analysis of hidden state dynamics in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno>abs/1606.07461</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Neural machine translation with reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1611.01874</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Coverage-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1601.04811</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
