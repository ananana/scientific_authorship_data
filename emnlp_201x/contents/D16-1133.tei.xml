<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Unsupervised Probability Model for Speech-to-Translation Alignment of Low-Resource Languages</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>November 1-5, 2016. 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Notre Dame</orgName>
								<orgName type="institution" key="instit2">University of Melbourne</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Notre Dame</orgName>
								<orgName type="institution" key="instit2">University of Melbourne</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
							<email>lduong@student.unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Notre Dame</orgName>
								<orgName type="institution" key="instit2">University of Melbourne</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Unsupervised Probability Model for Speech-to-Translation Alignment of Low-Resource Languages</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1255" to="1263"/>
							<date type="published">November 1-5, 2016. 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>For many low-resource languages, spoken language resources are more likely to be annotated with translations than with transcriptions. Translated speech data is potentially valuable for documenting endangered languages or for training speech translation systems. A first step towards making use of such data would be to automatically align spoken words with their translations. We present a model that combines Dyer et al.&apos;s reparam-eterization of IBM Model 2 (fast_align) and k-means clustering using Dynamic Time Warping as a distance measure. The two components are trained jointly using expectation-maximization. In an extremely low-resource scenario, our model performs significantly better than both a neural model and a strong baseline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For many low-resource languages, speech data is easier to obtain than textual data. And because speech transcription is a costly and slow process, speech is more likely to be annotated with transla- tions than with transcriptions. This translated speech is a potentially valuable source of information -for example, for documenting endangered languages or for training speech translation systems.</p><p>In language documentation, data is usable only if it is interpretable. To make a collection of speech data usable for future studies of the language, some- thing resembling interlinear glossed text (transcrip- tion, morphological analysis, word glosses, free translation) would be needed at minimum. New technologies are being developed to facilitate col- lection of translations ( <ref type="bibr" target="#b4">Bird et al., 2014)</ref>, and there already exist recent examples of parallel speech collection efforts focused on endangered languages ( . As for the other annotation layers, one might hope that a first pass could be done automatically. A first step to- wards this goal would be to automatically align spo- ken words with their translations, capturing informa- tion similar to that captured by word glosses.</p><p>In machine translation, statistical models have tra- ditionally required alignments between the source and target languages as the first step of training. Therefore, producing alignments between speech and text would be a natural first step towards MT systems operating directly on speech.</p><p>We present a model that, in order to learn such alignments, adapts and combines two components: Dyer et al.'s reparameterization of IBM Model 2 ( <ref type="bibr" target="#b8">Dyer et al., 2013</ref>), more commonly known as fast_align, and k-means clustering using Dy- namic Time <ref type="bibr">Warping (Berndt and Clifford, 1994)</ref> as a distance measure. The two components are trained jointly using expectation-maximization.</p><p>We experiment on two language pairs. One is Spanish-English, using the CALLHOME and Fisher corpora. The other is Griko-Italian; Griko is an endangered language for which we created (and make freely available) <ref type="bibr">1</ref> gold-standard translations and word alignments ( <ref type="bibr" target="#b13">Lekakou et al., 2013)</ref>. In all cases, our model outperforms both a naive but strong baseline and a neural model ( <ref type="bibr" target="#b7">Duong et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section, we briefly describe the existing mod- els that the two components of our model are based on. In the next section, we will describe how we adapt and combine them to the present task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">IBM Model 2 and fast_align</head><p>The IBM translation models ( <ref type="bibr" target="#b6">Brown et al., 1993)</ref> aim to model the distribution p(e | f) for an En- glish sentence e = e 1 · · · e l , given a French sentence f = f 1 · · · e m . They all introduce a hidden variable a = a 1 · · · a l that gives the position of the French word to which each English word is aligned.</p><p>The general form of IBM Models 1, 2 and fast_align is</p><formula xml:id="formula_0">p(e, a | f) = p(l) l i=1 t(e i | f a i ) δ(a i | i, l, m)</formula><p>where t(e | f ) is the probability of translating French word f to English word e, and δ(a i = j | i, l, m) is the probability of aligning the i-th English word with the j-th French word.</p><p>In Model 1, δ is uniform; in Model 2, it is a categorical distribution. <ref type="bibr" target="#b8">Dyer et al. (2013)</ref> pro- pose a reparameterization of Model 2, known as fast_align:</p><formula xml:id="formula_1">h(i, j, l, m) = − i l − j m δ(a i | i, l, m) =        p 0 a i = 0 (1 − p 0 ) exp λh(i,a i ,l,m) Z λ (i,l,m) a i &gt; 0</formula><p>where the null alignment probability p 0 and preci- sion λ ≥ 0 are hyperparameters optimized by grid search. As λ → 0, the distribution gets closer to the distribution of IBM Model 1, and as λ gets larger, the model prefers monotone word alignments more strongly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">DTW and DBA</head><p>Dynamic Time Warping (DTW) <ref type="bibr" target="#b3">(Berndt and Clifford, 1994</ref>) is a dynamic programming method for measuring distance between two temporal se- quences of variable length, as well as computing an alignment based on this distance. Given two se- quences φ, φ of length m and m respectively, DTW constructs an m × m matrix w. The warping path can be found by evaluating the following recurrence:</p><formula xml:id="formula_2">w i, j = d(φ i , φ j ) + min{w i−1, j , w i−1, j−1 , w i, j−1 }</formula><p>where d is a distance measure. In this paper, we nor- malize the cost of the warping path:</p><formula xml:id="formula_3">DTW(φ, φ ) = w m,m m + m</formula><p>which lies between zero and one. DTW Barycenter Averaging (DBA) <ref type="bibr" target="#b17">(Petitjean et al., 2011</ref>) is an iterative approximate method that at- tempts to find a centroid of a set of sequences, min- imizing the sum of squared DTW distances.</p><p>In the original definition, given a set of sequences, DBA chooses one sequence randomly to be a "skele- ton." Then, at each iteration, DBA computes the DTW between the skeleton and every sequence in the set, aligning each of the skeleton's points with points in all the sequences. The skeleton is then re- fined using the found alignments, by updating each frame in the skeleton to the mean of all the frames aligned to it. In our implementation, in order to avoid picking a skeleton that is too short or too long, we randomly choose one of the sequences with median length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We use a generative model from a source-language speech segment consisting of feature frames φ = φ 1 · · · φ m to a target-language segment consisting of words e = e 1 . . . e l . We chose to model p(e | φ) rather than p(φ | e) because it makes it easier to in- corporate DTW. The other direction is also possible, and we plan to explore it in future work.</p><p>In addition to the target-language sentence e, our model hypothesizes a sequence f = f 1 · · · f l of source-language clusters (intuitively, source- language words), and spans (a i , b i ) of the source sig- nal that each target word e i is aligned to. Thus, the clusters f = f 1 · · · f l and the spans a = a 1 , . . . , a l and b = b 1 , . . . , b l are the hidden variables of the model:</p><formula xml:id="formula_4">p(e | φ) = a,b,f p(e, a, b, f | φ).</formula><p>The model generates e, a, b, and f from φ as fol- lows.</p><p>1. Choose l, the number of target words, with uni- form probability. (Technically, this assumes a maximum target sentence length, which we can just set to be very high.)</p><p>2. For each target word position i = 1, . . . , l:</p><p>(a) Choose a cluster f i .</p><p>(b) Choose a span of source frames (a i , b i ) for e i to be aligned to. (c) Generate a target word e i from f i .</p><p>Accordingly, we decompose p(e, a, b, f | φ) into sev- eral submodels:</p><formula xml:id="formula_5">p(e, a, b, f | φ) = p(l) l i=1 u( f i ) × s(a i , b i | f i , φ) × δ(a i , b i | i, l, |φ|) × t(e i | f i ).</formula><p>Note that submodels δ and s both generate spans (corresponding to step 2b), making the model de- ficient. We could make the model sum to one by</p><formula xml:id="formula_6">replacing u( f i )s(a i , b i | f i , φ) with s( f i | a i , b i , φ)</formula><p>, and this was in fact our original idea, but the model as defined above works much better, as discussed in Section 7.4. We describe both δ and s in detail be- low.</p><p>Clustering model The probability over clusters, u( f ), is just a categorical distribution. The submodel s assumes that, for each cluster f , there is a "pro- totype" signal φ f (cf. <ref type="bibr" target="#b19">Ristad and Yianilos, 1998)</ref>. Technically, the φ f are parameters of the model, and will be recomputed during the M step. Then we can define:</p><formula xml:id="formula_7">s(a, b | f, φ) = exp(−DTW(φ f , φ a · · · φ b ) 2 ) m a,b=1 exp(−DTW(φ f , φ a · · · φ b ) 2 )</formula><p>where DTW is the distance between the prototype and the segment computed using Dynamic Time Warping. Thus s assigns highest probability to spans of φ that are most similar to the prototype φ f .</p><p>Distortion model The submodel δ controls the re- ordering of the target words relative to the source frames. It is an adaptation of fast_align to our setting, where there is not a single source word po- sition a i , but a span (a i , b i ). We want the model to prefer the middle of the word to be close to the di- agonal, so we need the variable a to be somewhat to the left and b to be somewhat to the right. Therefore, we introduce an additional hyperparameter µ which is intuitively the number of frames in a word. Then we define</p><formula xml:id="formula_8">h a (i, j, l, m, µ) = − i l − j m − µ h b (i, j, l, m, µ) = − i l − j − µ m − µ δ a (a i | i, l, m) =        p 0 a i = 0 (1 − p 0 ) exp λh a (i,a i ,l,m) Z λ (i,l,m) a i &gt; 0 δ b (b i | i, l, m) =        p 0 b i = 0 (1 − p 0 ) exp λh b (i,b i ,l,m) Z λ (i,l,m) b i &gt; 0 δ(a i , b i | i, l, m) = δ a (a i | i, l, m) δ b (b i | i, l, m)</formula><p>where the Z λ (i, l, m) are set so that all distributions sum to one. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example visualisation of the the resulting distributions for the two variables of our model.</p><p>We set µ differently for each word. For each i, we set µ i to be proportional to the number of characters in e i , such that</p><formula xml:id="formula_9">i µ i = m.</formula><p>Translation model The translation model t(e | f ) is just a categorical distribution, in principle allow- ing a many-to-many relation between source clusters and target words. To speed up training (with nearly no change in accuracy, in our experiments), we re- strict this relation so that there are k source clusters for each target word, and a source cluster uniquely determines its target word. Thus, t(e | f ) is fixed to either zero or one, and does not need to be reesti- mated. In our experiments, we set k = 2, allowing each target word to have up to two source-language translations/pronunciations. (If a source word has more than one target translation, they are treated as distinct clusters with distinct prototypes.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training</head><p>We use the hard (Viterbi) version of the Expectation- Maximization (EM) algorithm to estimate the pa- rameters of our model, because calculating expected counts in full EM would be prohibitively expensive, requiring summations over all possible alignments.</p><p>Recall that the hidden variables of the model are the alignments (a i , b i ) and the source words ( f i ). The parameters are the translation probabilities t(e i | f ) and the prototypes (φ f ). The (hard) E step uses the current model and prototypes to find, for each target word, the best source segment to align it to and the best source word. The M step reestimates the prob- abilities t(e | f ) and the prototypes φ f . We describe each of these steps in more detail below.</p><p>Initialization Initialization is especially important since we are using hard EM.</p><p>To initialize the parameters, we initialize the hid- den variables and then perform an M step. We as- sociate each target word type e with k = 2 source clusters, and for each occurrence of e, we randomly assign it one of the k source clusters.</p><p>The alignment variables a i , b i are initialized to</p><formula xml:id="formula_10">a i , b i = arg max a,b δ(a, b | i, l, m).</formula><p>M step The M step reestimates the probabilities t(e | f ) using relative-frequency estimation. The prototypes φ f are more complicated. Theo- retically, the M step should recompute each φ f so as to maximize that part of the log-likelihood that depends on φ f :</p><formula xml:id="formula_11">L φ f = φ i| f i = f log s(a i , b i | f, φ) = φ i| f i = f log exp(−DTW(φ f , φ a i · · · φ b i ) 2 ) Z( f, φ) = φ i| f i = f −DTW(φ f , φ a i · · · φ b i ) 2 − log Z( f, φ)</formula><p>where the summation over φ is over all source sig- nals in the training data. This is a hard problem, but note that the first term is just the sum-of-squares of the DTW distance between φ f and all source seg- ments that are classified as f . This is what DBA is supposed to approximately minimize, so we simply set φ f using DBA, ignoring the denominator.</p><p>E step The (hard) E step uses the current model and prototypes to find, for each target word, the best source segment to align it to and the best source clus- ter.</p><p>In order to reduce the search space for a and b, we use the unsupervised phonetic boundary detec- tion method of <ref type="bibr" target="#b12">Khanagha et al. (2014)</ref>. This method operates directly on the speech signal and provides us with candidate phone boundaries, on which we restrict the possible values for a and b, creating a list of candidate utterance spans.</p><p>Furthermore, we use a simple silence detection method. We pass the envelope of the signal through a low-pass filter, and then mark as "silence" time spans of 50ms or longer in which the magnitude is below a threshold of 5% relative to the maximum of the whole signal. This method is able to detect about 80% of the total pauses, with a 90% precision in a 50ms window around the correct silence bound- ary. We can then remove from the candidate list the utterance spans that include silence, on the assump- tion that a word should not include silences. Finally, in case one of the span's boundaries happens to be within a silence span, we also move it so as to not include the silence.</p><p>Hyperparameter tuning The hyperparameters p 0 , λ, and µ are not learned. We simply set p 0 to zero (disallowing unaligned target words) and set µ as described above.</p><p>For λ we perform a grid search over candidate val- ues to maximize the alignment F-score on the devel- opment set. We obtain the best scores with λ = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>A first step towards modelling parallel speech can be performed by modelling phone-to-word alignment, instead of directly working on continuous speech. For example, <ref type="bibr" target="#b20">Stahlberg et al. (2012)</ref> extend IBM Model 3 to align phones to words in order to build cross-lingual pronunciation lexicons. Pialign ( <ref type="bibr" target="#b15">Neubig et al., 2012</ref>) aligns characters and can be ap- plied equally well to phones. <ref type="bibr" target="#b7">Duong et al. (2016)</ref> use an extension of the neural attentional model of <ref type="bibr" target="#b1">Bahdanau et al. (2015)</ref> for aligning phones to words and speech to words; we discuss this model below in Section 6.2.</p><p>There exist several supervised approaches that at- tempt to integrate speech recognition and machine translation. However, they rely heavily on the abun- dance of training data, pronunciation lexicons, or language models, and therefore cannot be applied in a low-or zero-resource setting.</p><p>A task somewhat similar to ours, which operates at a monolingual level, is the task of zero-resource spoken term discovery, which aims to discover re- peated words or phrases in continuous speech. Vari- ous approaches <ref type="bibr" target="#b21">(Ten Bosch and Cranen, 2007;</ref><ref type="bibr" target="#b16">Park and Glass, 2008;</ref><ref type="bibr" target="#b14">Muscariello et al., 2009;</ref><ref type="bibr" target="#b23">Zhang and Glass, 2010;</ref><ref type="bibr" target="#b10">Jansen et al., 2010)</ref> have been tried, in order to spot keywords, using segmental DTW to identify repeated trajectories in the speech signal. <ref type="bibr" target="#b11">Kamper et al. (2016)</ref> try to discover word segmen- tation and a pronunciation lexicon in a zero-resource setting, combining DTW with acoustic embeddings; their methods operate in a very low-vocabulary set- ting. <ref type="bibr" target="#b2">Bansal (2015)</ref> attempts to build a speech trans- lation system in a low-resource setting, by using as source input the simulated output of an unsupervised term discovery system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We evaluate our method on two language pairs, Spanish-English and Griko-Italian, against two baseline methods, a naive baseline, and the model of <ref type="bibr" target="#b7">Duong et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Data</head><p>For each language pair, we require a sentence- aligned parallel corpus of source-language speech and target-language text. A subset of these sentences should be annotated with span-to-word alignments for use as a gold standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Spanish-English</head><p>For Spanish-English, we use the Spanish CALL- HOME corpus (LDC96S35) and the Fisher corpus (LDC2010T04), which consist of telephone conver- sations between Spanish native speakers based in the US and their relatives abroad, together with English translations produced by <ref type="bibr" target="#b18">Post et al. (2013)</ref>. Span- ish is obviously not a low-resource language, but we pretend that it is low-resource by not making use of any Spanish ASR or resources like transcribed speech or pronunciation lexicons.</p><p>Since there do not exist gold standard alignments between the Spanish speech and English words, we use the "silver" standard alignments produced by <ref type="bibr" target="#b7">Duong et al. (2016)</ref> for the CALLHOME corpus, and followed the same procedure for the Fisher cor- pus as well. In order to obtain them, they first used a forced aligner to align the speech to its transcription, and GIZA++ with the gdfa symmetrization heuris- tic to align the Spanish transcription to the English translation. They then combined the two alignments to produce "silver" standard alignments between the Spanish speech and the English words.</p><p>The CALLHOME dataset consists of 17532 Spanish utterances, based on the dialogue turns. We first use a sample of 2000 sentences, out of which we use 200 as a development set and the rest as a test set. We also run our experiments on the whole dataset, selecting 500 utterances for a development set, using the rest as a test set. The Fisher dataset consists of 143355 Spanish utterances. We use 1000 of them as a development set and the rest as a test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Griko-Italian</head><p>We also run our model on a corpus that consists of about 20 minutes of speech in Griko, an endangered minority dialect of Greek spoken in south Italy, along with text translations into Italian ( <ref type="bibr" target="#b13">Lekakou et al., 2013</ref>). <ref type="bibr">2</ref> The corpus consists of 330 mostly prompted utterances by nine native speakers. Al- though the corpus is very small, we use it to show- case the effectiveness of our method in a hard setting with extremely low resources.</p><p>All utterances were manually annotated and tran- scribed by a trained linguist and bilingual speaker of both languages, who produced the Griko tran- scriptions and Italian glosses. We created full trans- lations into Italian and manually aligned the transla- tions with the Griko transcriptions. We then com-bined the two alignments (speech-to-transcription and transcription-to-translation) to produce speech- to-translation alignments. Therefore, our compar- ison is done against an accurate "gold" standard alignment. We split the data into a development set of just 30 instances, and a test set of the remain- ing 300 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Preprocessing</head><p>In both data settings, we treat the speech data as a sequence of 39-dimensional Perceptual Linear Pre- diction (PLP) vectors encoding the power spectrum of the speech signal <ref type="bibr" target="#b9">(Hermansky, 1990</ref>), computed at 10ms intervals. We also normalize the features at the utterance level, shifting and scaling them to have zero mean and unit variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Baselines</head><p>Our naive baseline assumes that there is no reorder- ing between the source and target language, and aligns each target word e i to a source span whose length in frames is proportional to the length of e i in characters. This actually performs very well on lan- guage pairs that show minimal or no reordering, and language pairs that have shared or related vocabular- ies.</p><p>The other baseline that we compare against is the neural network attentional model of <ref type="bibr" target="#b7">Duong et al. (2016)</ref>, which extends the attentional model of <ref type="bibr" target="#b1">Bahdanau et al. (2015)</ref> to be used for aligning and translating speech, and, along with several modifi- cations, achieve good results on the phone-to-word alignment task, and almost match the baseline per- formance on the speech-to-word alignment task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>To evaluate an automatic alignment between the speech and its translation against the gold/silver standard alignment, we compute alignment preci- sion, recall, and F-score as usual, but on links be- tween source-language frames and target-language words. <ref type="table" target="#tab_1">Table 1</ref> shows the precision, recall, and balanced F- score of the three models on the Spanish-English CALLHOME corpus (both the 2000-sentence subset method precision recall F-score   and the full set), the Spanish-English Fisher corpus, and the Griko-Italian corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Overview</head><p>In all cases, our model outperforms both the naive baseline and the neural attentional model. Our model, when compared to the baselines, improves greatly on precision, while slightly underperforming the naive baseline on recall. In certain applications, higher precision may be desirable: for example, in language documentation, it's probably better to err on the side of precision; in phrase-based translation, higher-precision alignments lead to more extracted phrases.</p><p>The rest of the section provides a further anal- ysis of the results, focusing on the extremely low- resource Griko-Italian dataset. <ref type="figure" target="#fig_3">Figure 2</ref> shows the alignments produced by our model for three utterances of the same sentence from the Griko-Italian dataset by three different speak- ers. Our model's performance is roughly consistent across these utterances. In general, the model does not seem significantly affected by speaker-specific variations, as shown in <ref type="table" target="#tab_3">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Speaker robustness</head><p>We do find, however, that the performance on male speakers is slightly higher compared to the female speakers. This might be because the fe- male speakers' utterances are, on average, longer by about 2 words than the ones uttered by males.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Word level analysis</head><p>We also compute F-scores for each Italian word type. As shown in <ref type="figure">Figure 3</ref>, the longer the word's utterance, the easier it is for our model to correctly align it. Longer utterances seem to carry enough in- formation for our DTW-based measure to function properly. On the other hand, shorter utterances are harder to align. The vast majority of Griko utter- ances that have less than 20 frames and are less ac- curately aligned correspond to monosyllabic deter- miners (o, i,a, to, ta) or conjunctions and preposi- tions (ka, ce, en, na, an). For such short utterances, there could be several parts of the signal that possi- bly match the prototype, leading the clustering com- ponent to prefer to align to wrong spans. Furthermore, we note that rare word types tend to be correctly aligned. The average F-score for hapax legomena (on the Italian side) is 63.2, with 53% of them being aligned with an F-score higher than 70.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Comparison with proper model</head><p>As mentioned in Section 3, our model is deficient, but it performs much better than the model that sums to one (henceforth, the "proper" model): In the Spanish-English dataset (2000 sentences sam- ple) the proper model yields an F-score of 32.1, per- forming worse than the naive baseline; in the Griko-  Italian dataset, it achieves an F-score of 44.3, which is better than the baselines, but still worse than our model. In order to further examine why this happens, we performed three EM iterations on the Griko-Italian dataset with our model (in our experience, three it- erations are usually enough for convergence), and then computed one more E step with both our model and the proper model, so as to ensure that the two models would align the dataset using the exact same prototypes and that their outputs will be comparable.</p><p>In this case, the proper model achieved an over- all F-score of 44.0, whereas our model achieved an F-score of 53.6. <ref type="figure">Figures 4 and 5</ref> show the resulting alignments for two sentences. In both of these exam- ples, it is clear that the proper model prefers extreme spans: the selected spans are either much too short or (less frequently) much too long. This is further ver- ified by examining the statistics of the alignments: the average span selected by the proper model has a length of about 30 ± 39 frames whereas the aver- age span of the alignments produced by our deficient model is 37 ± 24 frames. This means that the align- ments of the deficient model are much closer to the gold ones, whose average span is 42 ± 26 frames.</p><p>We think that this is analogous to the "garbage collection" problem in word alignment. In the IBM word alignment models, if a source word f occurs in only one sentence, then EM can align many tar- get words to f and learn a very peaked distribution t(e | f ). This can happen in our model and the proper model as well, of course, since IBM Model 2 is embedded in them. But in the proper model, some- thing similar can also happen with s( f | a, b): EM can make the span (a, b) large or small, and evi- dently making the span small allows it to learn a very peaked distribution s( f | a, b). By contrast, our model has s(a, b | f ), which seems less susceptible to this kind of effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>Alignment of speech to text translations is a rela- tively new task, one with particular relevance for low-resource or endangered languages. The model we propose here, which combines fast_align and k-means clustering using DTW and DBA, outper- forms both a very strong naive baseline and a neural attentional model, on three tasks of various sizes.</p><p>The language pairs used here do not have very much word reordering, and more divergent language pairs should prove more challenging. In that case, the naive baseline should be much less competitive. Similarly, the fast_align-based distortion model may become less appopriate; we plan to try incorpo- rating IBM Model 3 or the HMM alignment model ( <ref type="bibr" target="#b22">Vogel et al., 1996</ref>) instead. Finally, we will in- vestigate downstream applications of our alignment methods, in the areas of both language documenta- tion and speech translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sample distributions for the alignment variables a and b for m = 100, l = 5, p 0 = 0, λ = 0.5, and µ = 20.</figDesc><graphic url="image-1.png" coords="3,318.71,57.83,106.73,105.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>CALLHOME</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Male</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Alignments produced for the Italian sentence devo comprare il pane ogni giorno as uttered by three different Griko speakers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 3 :</head><label>53</label><figDesc>Figure 5: One of the rare examples where the proper model performs better than the deficient one. The hapax legomena Valeria and giornali are not properly handled by the attentional model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Our model achieves higher precision and F-score than both the naive baseline and the neural model on all datasets.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Model performance (F-score) is generally consistent 

across speakers. The second column (utt) shows the number of 

utterances per speaker; the third (len), their average length in 

words. 

</table></figure>

			<note place="foot" n="1"> https://www3.nd.edu/∼aanastas/griko/griko-data.tar.gz 1255</note>

			<note place="foot" n="2"> http://griko.project.uoi.gr</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Steven Bird, Eamonn Keogh, and the anonymous reviewers for their helpful feed-back. This research was supported in part by NSF Award 1464553.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Breaking the unwritten language barrier: The BULB project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Adda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martine</forename><surname>Adda-Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Odette</forename><surname>Ambouroue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blachon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Héì Ene Bonneau-Maynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatima</forename><surname>Godard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Hamlaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Idiatov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="8" to="14" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Speech translation without speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Bansal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. KDD</title>
		<meeting>KDD</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collecting bilingual audio in remote indigenous communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lauren</forename><surname>Gawne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Gelbart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Mcalister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Parallel speech collection for underresourced language studies using the Lig-Aikuma mobile device app</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blachon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elodie</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guynoël</forename><surname>Kouarata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martine</forename><surname>Adda-Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Rialland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="61" to="66" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><forename type="middle">J Della</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An attentional model for speech translation without transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonios</forename><surname>Anastasopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL HLT</title>
		<meeting>NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="949" to="959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple, fast, and effective reparameterization of IBM Model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL HLT</title>
		<meeting>NAACL HLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perceptual linear predictive (PLP) analysis of speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hynek</forename><surname>Hermansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1738" to="1752" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards spoken term discovery at scale with zero resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hynek</forename><surname>Hermansky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1676" to="1679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised word segmentation and lexicon discovery using acoustic word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Kamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Phonetic segmentation of speech signal using local singularity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Khanagha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Daoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Oriol Pont, and Hussein Yahia</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Documentation and analysis of an endangered language: aspects of the grammar of Griko</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marika</forename><surname>Lekakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>Baldiserra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>and Antonis Anastasopoulos</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Audio keyword extraction by unsupervised word discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armando</forename><surname>Muscariello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bimbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Machine translation without words through substring alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised pattern discovery in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="186" to="197" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A global averaging method for dynamic time warping, with applications to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Ketterlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Gançarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="678" to="693" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved speech-to-text translation with the Fisher and Callhome Spanish-English speech translation corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IWSLT</title>
		<meeting>IWSLT</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Damianos Karakos, Chris Callison-Burch, and Sanjeev Khudanpur</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning string-edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sven Ristad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter N Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="522" to="532" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Word segmentation through crosslingual word-to-phoneme alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Stahlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sue</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Spoken Language Technology Workshop (SLT)</title>
		<meeting>IEEE Spoken Language Technology Workshop (SLT)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A computational model for unsupervised word discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><surname>Louis Ten Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cranen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1481" to="1484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HMM-based word alignment in statistical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="836" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards multi-speaker unsupervised speech pattern discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James R</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="4366" to="4369" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
