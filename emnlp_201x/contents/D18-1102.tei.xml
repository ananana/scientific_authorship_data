<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Decipherment of Substitution Ciphers with Neural Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Kambhatla</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anahita</forename><forename type="middle">Mansouri</forename><surname>Bigvand</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing Science</orgName>
								<orgName type="institution">Simon Fraser University Burnaby</orgName>
								<address>
									<region>BC</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Decipherment of Substitution Ciphers with Neural Language Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="869" to="874"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>869</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Decipherment of homophonic substitution ciphers using language models (LMs) is a well-studied task in NLP. Previous work in this topic scores short local spans of possible plain-text decipherments using n-gram LMs. The most widely used technique is the use of beam search with n-gram LMs proposed by Nuhn et al. (2013). We propose a beam search algorithm that scores the entire candidate plain-text at each step of the decipherment using a neural LM. We augment beam search with a novel rest cost estimation that exploits the prediction power of a neural LM. We compare against the state of the art n-gram based methods on many different decipherment tasks. On challenging ciphers such as the Beale cipher we provide significantly better error rates with much smaller beam sizes.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Breaking substitution ciphers recovers the plain- text from a ciphertext that uses a 1:1 or homo- phonic cipher key. Previous work using pre- trained language models (LMs) for decipherment use n-gram LMs ( <ref type="bibr" target="#b14">Ravi and Knight, 2011;</ref><ref type="bibr" target="#b9">Nuhn et al., 2013)</ref>. Some methods use the Expectation- Maximization (EM) algorithm <ref type="bibr" target="#b7">(Knight et al., 2006</ref>) while most state-of-the-art approaches for decipherment of 1:1 and homophonic substitution ciphers use beam search and rely on the clever use of n-gram LMs ( <ref type="bibr" target="#b10">Nuhn et al., 2014;</ref><ref type="bibr" target="#b5">Hauer et al., 2014</ref>). Neural LMs globally score the en- tire candidate plaintext sequence ( <ref type="bibr" target="#b8">Mikolov et al., 2010)</ref>. However, using a neural LM for decipher- ment is not trivial because scoring the entire candi- date partially deciphered plaintext is computation- ally challenging. We solve both of these problems in this paper and provide an improved beam search based decipherment algorithm for homophonic ci- phers that exploits pre-trained neural LMs for the first time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Decipherment Model</head><p>We use the notation from <ref type="bibr" target="#b9">Nuhn et al. (2013)</ref>. Ci- phertext f N 1 = f 1 ..f i ..f N and plaintext e N 1 = e 1 ..e i ..e N consist of vocabularies f i ∈ V f and e i ∈ V e respectively. The beginning tokens in the ciphertext (f 0 ) and plaintext (e 0 ) are set to "$" de- noting the beginning of a sentence. The substi- tutions are represented by a function φ : V f → V e such that 1:1 substitutions are bijective while homophonic substitutions are general. A cipher function φ which does not have every φ(f ) fixed is called a partial cipher function <ref type="bibr" target="#b1">(Corlett and Penn, 2010)</ref>. The number of f s that are fixed in φ is given by its cardinality. φ is called an extension of φ, if f is fixed in φ such that δ(φ (f ), φ(f )) yields true ∀f ∈ V f which are already fixed in φ where δ is Kronecker delta. Decipherment is then the task of finding the φ for which the probability of the deciphered text is maximized.</p><formula xml:id="formula_0">ˆ φ = arg max φ p(φ(f 1 )...φ(f N ))<label>(1)</label></formula><p>where p(.) is the language model (LM). Find- ing this argmax is solved using a beam search al- gorithm <ref type="bibr" target="#b9">(Nuhn et al., 2013</ref>) which incrementally finds the most likely substitutions using the lan- guage model scores as the ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Neural Language Model</head><p>The advantage of a neural LM is that it can be used to score the entire candidate plaintext for a hypoth- esized partial decipherment. In this work, we use a state of the art byte (character) level neural LM us- ing a multiplicative LSTM ( <ref type="bibr" target="#b12">Radford et al., 2017)</ref>. Consider a sequence S = w 1 , w 2 , w 3 , ..., w N . The LM score of S is SCORE(S): P (S) = P (w 1 , w 2 , w 3 , ..., w N )</p><formula xml:id="formula_1">P (S) = N i=1 P (w i | w 1 , w 2 , ..., w i−1 )) SCORE(S) = − N i=1 log(P (w i | w &lt;i ))<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Beam Search</head><p>Algorithm 1 is the beam search algorithm ( <ref type="bibr" target="#b9">Nuhn et al., 2013</ref><ref type="bibr" target="#b10">Nuhn et al., , 2014</ref>) for solving substitution ci- phers. It monitors all partial hypotheses in lists H s and H t based on their quality. As the search progresses, the partial hypotheses are ex- tended, scored with SCORE and appended to H t . EXT LIMITS determines which extensions should be allowed and EXT ORDER picks the next cipher symbol for extension. The search continues after pruning: H s ← HISTOGRAM_PRUNE(H t ). We augment this algorithm by updating the SCORE function with a neural LM.</p><formula xml:id="formula_2">Algorithm 1 Beam Search for Decipherment 1: function (BEAM SEARCH (EXT ORDER, EXT LIM- ITS)) 2:</formula><p>initialize sets Hs, Ht 3:</p><formula xml:id="formula_3">CARDINALITY = 0 4:</formula><p>Hs.ADD((∅,0)) 5:</p><p>while</p><formula xml:id="formula_4">CARDINALITY &lt; |V f | do 6: f = EXT ORDER[CARDINALITY] 7:</formula><p>for all φ ∈ Hs do 8:</p><p>for all e ∈ Ve do 9:</p><formula xml:id="formula_5">φ' := φ ∪ {(e, f )} 10:</formula><p>if EXT LIMITS(φ') then 11:</p><p>Ht.ADD(φ',SCORE(φ')) 12:</p><p>HISTOGRAM PRUNE(Ht) 13: CARDINALITY = CARDINALITY + 1 14:</p><formula xml:id="formula_6">Hs = Ht 15:</formula><p>Ht.CLEAR() 16:</p><p>return WINNER(Hs)</p><p>3 Score Estimation (SCORE)</p><p>Score estimation evaluates the quality of the partial hypotheses φ. Using the example from <ref type="bibr" target="#b10">Nuhn et al. (2014)</ref>, consider the vo- cabularies V e = {a, b, c, d} and V f = {A, B, C, D}, extension order (B, A, C, D), and ciphertext $ ABDDCABCDADCABDC $. Let φ = {(a, A), (b, B))} be the partial hypothesis. Then SCORE(φ) scores this hypothesized partial deci- pherment (only A and B are converted to plain- text) using a pre-trained language model in the hy- pothesized plaintext language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>The initial rest cost estimator introduced by Nuhn et al. nuhnbeam computes the score of hypothe- ses only based on partially deciphered text that builds a shard of n adjacent solved symbols. As a heuristic, n-grams which still consist of unsolved cipher-symbols are assigned a trivial estimate of probability 1. An improved version of rest cost es- timation ( <ref type="bibr" target="#b10">Nuhn et al., 2014</ref>) consults lower order n-grams to score each position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global Rest Cost Estimation</head><p>The baseline scoring method greatly relies on local context, i.e. the estimation is strictly based on par- tial character sequences. Since this depends solely on the n-gram LM, the true conditional probabil- ity under Markov assumption is not modeled and, therefore, context dependency beyond the window of (n − 1) is ignored. Thus, attempting to utilize a higher amount of context can lower the probability of some tokens resulting in poor scores.</p><p>We address this issue with a new improved ver- sion of the rest cost estimator by supplement- ing the partial decipherment φ(f N 1 ) with predicted plaintext text symbols using our neural language model (NLM). Applying φ = {(a, A), (b, B))} to the ciphertext above, we get the following partial hypothesis:</p><formula xml:id="formula_7">φ(f N 1 ) = $a 1 b 2 ...a 6 b 7 .</formula><p>.a 10 ..a 13 b 14 ..$ We introduce a scoring function that is able to score the entire plaintext including the missing plaintext symbols. First, we sample 1 the plaintext symbols from the NLM at all locations depend- ing on the deciphered tokens from the partial hy- pothesis φ such that these tokens maintain their re- spective positions in the sequence, and at the same time are sampled from the neural LM to fit (prob- abilistically) in this context. Next, we determine the probability of the entire sequence including the scores of sampled plaintext as our rest cost esti- mate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NLM</head><p>In our running example, this would yield a score estimation of the partial decipherment, φ(f N 1 ) : pled plaintext symbols from the NLM. Since more terms participate in the rest cost estimation with global context, we use the plaintext LM to provide us with a better rest cost in the beam search.</p><formula xml:id="formula_8">φ(f N 1 ) = $ a 1 b 2 d 3 c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Frequency Matching Heuristic</head><p>Alignment by frequency similarity <ref type="bibr" target="#b15">(Yarowsky and Wicentowski, 2000</ref>) assumes that two forms be- long to the same lemma when their relative fre- quency fits the expected distribution. We use this heuristic to augment the score estimation (SCORE):</p><formula xml:id="formula_9">FMH(φ ) = log ν(f ) ν(e) f ∈ V f , e ∈ V e (3) ν(f )</formula><p>is the percentage relative frequency of the ci- phertext symbol f , while ν(e) is the percentage relative frequency of the plaintext token e in the plaintext language model. The closer this value to 0, the more likely it is that f is mapped to e.</p><p>Thus given a φ with the SCORE(φ), the exten- sion φ (Algo. 1) is scored as:</p><formula xml:id="formula_10">SCORE(φ ) = SCORE(φ) + NEW(φ ) − FMH(φ )<label>(4)</label></formula><p>where NEW is the score for symbols that have been newly fixed in φ while extending φ to φ . Our experimental evaluations show that the global rest cost estimator and the frequency matching heuris- tic contribute positively towards the accuracy of different ciphertexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head><p>We carry out 2 sets of experiments: one on let- ter based 1:1, and another on homophonic sub- stitution ciphers. We report Symbol Error Rate (SER) which is the fraction of characters in the deciphered text that are incorrect.</p><p>The character NLM uses a single layer multi- plicative LSTM (mLSTM) ( <ref type="bibr" target="#b12">Radford et al., 2017</ref>) with 4096 units. The model was trained for a sin- gle epoch on mini-batches of 128 subsequences of length 256 for a total of 1 million weight updates. States were initialized to zero at the beginning of each data shard and persisted across updates to simulate full-backprop and allow for the forward propagation of information outside of a given sub- sequence. In all the experiments we use a charac- ter NLM trained on English Gigaword corpus aug- mented with a short corpus of plaintext letters of about 2000 words authored by the Zodiac killer 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">1:1 Substitution Ciphers</head><p>In this experiment we use a synthetic 1:1 let- ter substitution cipher dataset following <ref type="bibr" target="#b13">Ravi and Knight (2008)</ref>    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I H A V E D E P O S I T E D I N T H E C O U N T Y O F B E D F O R D A B O U T F O U R M I L E S F R O M B U F O R D S I N A N E X C A V A T I O N O R V A U L T S I X F E E T B E L O W T H E S U R F A C E O F T H E G R O U N D T H E F O L L O W I N G A R T I C L E S B E L O N G I N G J O I N T L Y T O T H E P A</head><p>115 <ref type="formula" target="#formula_0">73 24 807 37 52 49 17 31 62 647 22 7 15 140 47 29 107 79 84 56 239 10 26 811</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">An Easy Cipher: Zodiac-408</head><p>Zodiac-408, a homophonic cipher, is commonly used to evaluate decipherment algorithms.  Our neural LM model with global rest cost es- timation and frequency matching heuristic with a beam size of 1M has SER of 1.2% compared to the beam search algorithm ( <ref type="bibr" target="#b9">Nuhn et al., 2013</ref>) with beam size of 10M with a 6-gram LM which gives an SER of 2%. The improved beam search ( <ref type="bibr" target="#b10">Nuhn et al., 2014</ref>) with an 8-gram LM, however, gets 52 out of 54 mappings correct on the Zodiac-408 ci- pher.</p><formula xml:id="formula_11">Beam SER (%) 1 SER (%) 2<label>10k</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">A Hard Cipher: Beale Pt 2</head><p>Part 2 of the Beale Cipher is a more challeng- ing homophonic cipher because of a much larger search space of solutions. <ref type="bibr">Nunh et al. (2014)</ref> were the first to automatically decipher this Beale Ci- pher.</p><p>With an error of 5% with beam size of 1M vs 5.4% with 8-gram LM and a pruning size of 10M, our system outperforms the state of the art ( <ref type="bibr" target="#b10">Nuhn et al., 2014</ref>) on this task.   </p><formula xml:id="formula_12">! 1 I L I K E K I L L I N G P E O P L E B E C A U S E I T I S S O M U C H F U N I T I S M O R E F U N T H A A N K I L L I N G W I L D G A M E I N T H E F O R T E S T B E C A U S E M A N I S T H E M O S T D A N G E R T U E A N A M A L O F A L L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Automatic decipherment for substitution ciphers started with dictionary attacks <ref type="bibr" target="#b4">(Hart, 1994;</ref><ref type="bibr" target="#b6">Jakobsen, 1995;</ref><ref type="bibr" target="#b11">Olson, 2007)</ref>. <ref type="bibr" target="#b13">Ravi and Knight (2008)</ref> frame the decipherment problem as an integer lin- ear programming (ILP) problem. <ref type="bibr" target="#b7">Knight et al. (2006)</ref> use an HMM-based EM algorithm for solv- ing a variety of decipherment problems. <ref type="bibr" target="#b14">Ravi and Knight (2011)</ref> extend the HMM-based EM ap- proach with a Bayesian approach, and report the first automatic decipherment of the Zodiac-408 ci- pher. <ref type="bibr" target="#b0">Berg-Kirkpatrick and Klein (2013)</ref> show that a large number of random restarts can help the EM approach. <ref type="bibr" target="#b1">Corlett and Penn (2010)</ref> presented an efficient A* search algorithm to solve letter substitution ciphers. <ref type="bibr" target="#b9">Nuhn et al. (2013)</ref> produce better results in faster time compared to ILP and EM-based decipherment methods by employing a higher order language model and an iterative beam search algorithm. <ref type="bibr" target="#b10">Nuhn et al. (2014)</ref> present var- ious improvements to the beam search algorithm in <ref type="bibr" target="#b9">Nuhn et al. (2013)</ref> including improved rest cost estimation and an optimized strategy for order- ing decipherment of the cipher symbols. <ref type="bibr" target="#b5">Hauer et al. (2014)</ref> propose a novel approach for solv- ing mono-alphabetic substitution ciphers which combines character-level and word-level language model. They formulate decipherment as a tree search problem, and use Monte Carlo Tree Search (MCTS) as an alternative to beam search. Their approach is the best for short ciphers. <ref type="bibr" target="#b3">Greydanus (2017)</ref> frames the decryption pro- cess as a sequence-to-sequence translation task and uses a deep LSTM-based model to learn the decryption algorithms for three polyalphabetic ci- phers including the Enigma cipher. However, this approach needs supervision compared to our approach which uses a pre-trained neural LM. <ref type="bibr" target="#b2">Gomez et al. (2018)</ref>  <ref type="figure">(CipherGAN)</ref> use a genera- tive adversarial network to learn the mapping be- tween the learned letter embedding distributions in the ciphertext and plaintext. They apply this approach to shift ciphers (including Vigenère ci- phers). Their approach cannot be extended to ho- mophonic ciphers and full message neural LMs as in our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper presents, to our knowledge, the first application of large pre-trained neural LMs to the decipherment problem. We modify the beam search algorithm for decipherment from <ref type="bibr" target="#b9">Nuhn et al. (2013;</ref> and extend it to use global scor- ing of the plaintext message using neural LMs. To enable full plaintext scoring we use the neural LM to sample plaintext characters which reduces the beam size required. For challenging ciphers such as Beale Pt 2 we obtain lower error rates with smaller beam sizes when compared to the state of the art in decipherment for such ciphers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Symbol error rates for decipherment of 1:1 substitution ciphers of different lengths. The beam size is 100k. Beam 6-gram model uses the beam search from Nunh et al. (2013).</figDesc><graphic url="image-2.png" coords="3,321.11,482.82,187.88,185.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: First few lines from part two of the Beale cipher. The letters have been capitalized.</figDesc><graphic url="image-4.png" coords="4,192.74,180.00,489.70,336.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: First 119 characters from deciphered Zodiac408 text. The letters have been capitalized.</figDesc><graphic url="image-3.png" coords="4,61.15,292.08,243.00,182.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>, Nuhn et al. (2013) and Hauer et al. (2014). The text is from English Wikipedia articles about history 3 , preprocessed by stripping the text of all images, tables, then lower-casing all characters, and removing all non-alphabetic and non-space characters. We create 50 cryptograms for each length 16, 32, 64, 128 and 256 using a random Caesar-cipher 1:1 substitution.</figDesc><table>Length Beam 
SER(%) 1 SER(%) 2 
64 
100 
4.14 
4.14 
1,000 
1.09 
1.04 
10,000 
0.08 
0.12 
100,000 
0.07 
0.07 
128 
100 
7.31 
7.29 
1,000 
1.68 
1.55 
10,000 
0.15 
0.09 
100,000 
0.01 
0.02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Symbol Error Rates (SER) based on Neural 
Language Model and beam size (Beam) for solving 
1:1 substitution ciphers of lengths 64 and 128, respec-
tively. SER 1 shows beam search with global scoring, 
and SER 2 shows beam search with global scoring with 
frequency matching heuristic. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Symbol Error Rates (SER) based on Neu-
ral Language Model and beam size (Beam) for deci-
phering Zodiac-408, respectively. SER 1 shows beam 
search with global scoring, and SER 2 shows beam 
search with global scoring with the frequency match-
ing heuristic. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Symbol Error Rates (SER) based on Neural 
Language Model and beam size (Beam) for decipher-
ing Part 2 of the Beale Cipher. SER 1 shows beam 
search with global scoring, and SER 2 shows beam 
search with global scoring with the frequency match-
ing heuristic. 

</table></figure>

			<note place="foot" n="1"> The char-level sampling is done incrementally from left to right to generate a sequence that contains the deciphered tokens from φ at the exact locations they occur in the above φ(f N 1 ). If the LM prediction contradicts the hypothesized decipherment we stop sampling and start from the next character.</note>

			<note place="foot" n="2"> https://en.wikisource.org/wiki/Zodiac Killer letters 3 http://en.wikipedia.org/wiki/History</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank the anonymous reviewers for their helpful remarks. The research was also partially supported by the Natural Sciences and Engineering Research Council of Canada grants NSERC RGPIN-2018-06437 and RGPAS-2018-522574 and a Department of National Defence (DND) and NSERC grant DGDND-2018-00025 to the third author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Decipherment with a million random restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="874" to="878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An exact A* method for deciphering letter-substitution ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Corlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Penn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1040" to="1047" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Osama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04883</idno>
		<title level="m">Unsupervised cipher cracking using discrete gans</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning the enigma with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Greydanus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07576</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">To decode short cryptograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="102" to="108" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Solving substitution ciphers with combined language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Hayward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2314" to="2325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fast method for cryptanalysis of substitution ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Jakobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cryptologia</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="265" to="274" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised analysis for decipherment problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishit</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the COLING/ACL on Main conference poster sessions</title>
		<meeting>the COLING/ACL on Main conference poster sessions</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="499" to="506" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">JaňJaň Cernock`Cernock`y, and Sanjeev Khudanpur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukáš</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Recurrent neural network based language model</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Beam search for solving substitution ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Nuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1568" to="1576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved decipherment of homophonic ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Nuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Schamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1764" to="1768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust dictionary attack of short simple substitution ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cryptologia</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="332" to="342" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning to generate reviews and discovering sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01444</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Attacking decipherment problems optimally with low-order ngram models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="812" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bayesian inference for zodiac and other homophonic ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujith</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="239" to="247" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Minimally supervised morphological analysis by multimodal alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wicentowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 38th Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="207" to="216" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
