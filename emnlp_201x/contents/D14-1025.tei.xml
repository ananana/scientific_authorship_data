<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fitting Sentence Level Translation Evaluation with Many Dense Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloš</forename><surname>Stanojevi´c</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Logic</orgName>
								<orgName type="department" key="dep2">Language and Computation</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 107</addrLine>
									<postCode>1098 XG</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanojevi´c</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Logic</orgName>
								<orgName type="department" key="dep2">Language and Computation</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 107</addrLine>
									<postCode>1098 XG</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima&amp;apos;an</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute for Logic</orgName>
								<orgName type="department" key="dep2">Language and Computation</orgName>
								<orgName type="institution">University of Amsterdam Science</orgName>
								<address>
									<addrLine>Park 107</addrLine>
									<postCode>1098 XG</postCode>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fitting Sentence Level Translation Evaluation with Many Dense Features</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="202" to="206"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Sentence level evaluation in MT has turned out far more difficult than corpus level evaluation. Existing sentence level metrics employ a limited set of features, most of which are rather sparse at the sentence level, and their intricate models are rarely trained for ranking. This paper presents a simple linear model exploiting 33 relatively dense features, some of which are novel while others are known but seldom used, and train it under the learning-to-rank framework. We evaluate our metric on the standard WMT12 data showing that it outperforms the strong baseline METEOR. We also analyze the contribution of individual features and the choice of training data, language-pair vs. target-language data, providing new insights into this task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Evaluating machine translation (MT) output at the sen- tence/ segment level has turned out far more challeng- ing than corpus/ system level. Yet, sentence level evaluation can be useful because it allows fast, fine- grained analysis of system performance on individual sentences.</p><p>It is instructive to contrast two widely used metrics, METEOR <ref type="bibr" target="#b8">(Michael Denkowski and Alon Lavie, 2014</ref>) and BLEU ( <ref type="bibr" target="#b11">Papineni et al., 2002</ref>), on sentence level evaluation. METEOR constantly shows better corre- lation with human ranking than BLEU ( <ref type="bibr" target="#b11">Papineni et al., 2002</ref>). Arguably, this shows that sentence level evaluation demands finer grained and trainable models over less sparse features. Ngrams, the core of BLEU, are sparse at the sentence level, and a mismatch for longer ngrams implies that BLEU falls back on shorter ngrams. In contrast, METEOR has a trainable model and incorporates a small, yet wider set of features that are less sparse than ngrams. We think that METEOR's features and its training approach only suggest that sen- tence level evaluation should be treated as a modelling challenge. This calls for questions such as what model, what features and what training objective are better suited for modelling sentence level evaluation.</p><p>We start out by explicitly formulating sentence level evaluation as the problem of ranking a set of compet- ing hypothesis. Given data consisting of human ranked system outputs, the problem then is to formulate an easy to train model for ranking. One particular exist- ing approach <ref type="bibr" target="#b15">(Ye et al., 2007</ref>) looks especially attrac- tive because we think it meshes well with a range of effective techniques for learning-to-rank (Li, 2011).</p><p>We deliberately select a linear modelling approach inspired by <ref type="bibr">RankSVM (Herbrich et al., 1999</ref>), which is easily trainable for ranking and allows analysis of the individual contributions of features. Besides presenting a new metric and a set of known, but also a set of novel features, we target three questions of interest to the MT community:</p><p>• What kind of features are more helpful for sen- tence level evaluation?</p><p>• How does a simple linear model trained for rank- ing compare to the well-developed metric ME- TEOR on sentence level evaluation?</p><p>• Should we train the model for each language pair separately or for a target language?</p><p>Our new metric dubbed BEER 1 outperforms ME- TEOR on WMT12 data showing the effectiveness of dense features in a learning-to-rank framework. The metric and the code are available as free software 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Our model is a linear combination of features trained for ranking similar to <ref type="bibr">RankSVM (Herbrich et al., 1999</ref>) or, to readers familiar with SMT system tuning, to PRO tuning ( <ref type="bibr" target="#b4">Hopkins and May, 2011)</ref>:</p><formula xml:id="formula_0">score(sys) = w · x sys</formula><p>where w represents a weight vector and x sys a vec- tor of feature values for system output sys. Look- ing at evaluation as a ranking problem, we con- trast (at least) two system translations good and bad for the same source sentence. Assuming that humanRank(good) &gt; humanRank(bad) as ranked <ref type="bibr">1</ref> BEER participated on WMT14 evaluation metrics task where it was the highest scoring sentence level evaluation metric on average over all language pairs <ref type="bibr" target="#b12">(Stanojevi´cStanojevi´c and Sima'an, 2014)</ref> 2 https://github.com/stanojevic/beer 202 by human judgement, we expect metric score(·) to ful- fill score(good) &gt; score(bad):</p><formula xml:id="formula_1">w · x good &gt; w · x bad ⇔ w · x good − w · x bad &gt; 0 ⇔ w · ( x good − x bad ) &gt; 0 ∧ w · ( x bad − x good ) &lt; 0</formula><p>The two feature vectors ( x good − x bad ) and ( x bad − x good ) can be considered as positive and negative in- stances for training our linear classifier. For training this model, we use Logistic Regression from the Weka toolkit ( <ref type="bibr" target="#b2">Hall et al., 2009</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head><p>Generally speaking we identify adequacy and fluency features. For both types we devise far less sparse fea- tures than word ngrams.</p><p>Adequacy features We use precision P , recall R and F1-score F as follows:</p><formula xml:id="formula_2">P f unc , R f unc , F f unc on matched function words P cont , R cont , F cont on matched content words P all , R all , F all</formula><p>on matched words of any type P char , R char , F char matching of the char ngrams By differentiating between function and non-function words, our metric weighs each kind of words accord- ing to importance for evaluation. Matching character ngrams, originally proposed in ( <ref type="bibr" target="#b14">Yang et al., 2013)</ref>, re- wards certain translations even if they did not get the morphology completely right. Existing metrics use stemmers for this, but using character ngrams is inde- pendent of the availability of a good quality stemmer. Higher-order character ngrams have less risk of sparse counts than word ngrams. In our experiments we used char ngrams for n up to 6, which makes the total num- ber of adequacy features 27.</p><p>Fluency features To evaluate word order we follow ( <ref type="bibr" target="#b5">Isozaki et al., 2010;</ref><ref type="bibr" target="#b0">Birch and Osborne, 2010</ref>) in rep- resenting reordering as a permutation π over [1.</p><p>.n] and then measuring the distance to the ideal monotone per- mutation 1, 2, · · · , n. We present a novel approach based on factorization into permutation trees (PETs) ( <ref type="bibr" target="#b16">Zhang and Gildea, 2007)</ref>, and contrast it with Kendall τ ( <ref type="bibr" target="#b0">Birch and Osborne, 2010;</ref><ref type="bibr" target="#b5">Isozaki et al., 2010)</ref>. PETs are factorizations of permutations, which allows for an abstract and less sparse view of word order as exempli- fied next. Kendall score was regularly shown to have high correlation with human judgment on distant lan- guage pairs ( <ref type="bibr" target="#b5">Isozaki et al., 2010;</ref><ref type="bibr" target="#b0">Birch and Osborne, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features based on PETs</head><p>We informally review PETs in order to exploit them for novel ordering fea- tures. We refer the reader to <ref type="bibr" target="#b16">(Zhang and Gildea, 2007)</ref> and (Maillette de Buy Wenniger and Sima'an, 2011) for a formal treatment of PETs and efficient factoriza- tion algorithms.</p><p>A PET of permutation π is a tree organization of π's unique, atomic building blocks, called operators. Ev- ery operator on a PET node is an atomic permutation (not factorizing any further), <ref type="bibr">3</ref> and it stands for the per- mutation of the direct children of that node. <ref type="figure" target="#fig_0">Figure 1a</ref> shows an example PET that has one 4-branching node with operator 2, 4, 1, 3, two binary branching nodes of which one decorated with the inverted operator 2, 1 and another with the monotone 1, 2.</p><p>PETs have two important properties making them at- tractive for measuring order difference: firstly, order difference is measured on the operators -the atomic reordering building blocks of the permutation, and sec- ondly, the operators on higher level nodes capture hid- den ordering patterns that cannot be observed without factorization. Statistics over ordering patterns in PETs are far less sparse than word or character ngram statis- tics.</p><p>Intuitively, among the atomic permutations, the bi- nary monotone operator 1, 2 signifies no ordering dif- ference at all, whereas the binary inverted 2, 1 signi- fies the shortest unit of order difference. Operators of length four like 2, 4, 1, 3 (Wu, 1997) are presumably more complex than 2, 1, whereas operators longer than four signify even more complex order difference. Therefore, we devise possible branching feature func- tions over the operator length for the nodes in PETs:</p><p>• factor 2 -with two features: ∆ [ ] and ∆ &lt;&gt; (there are no nodes with factor 3 (Wu, 1997))</p><p>• factor 4 -feature ∆ =4</p><p>• factor bigger than 4 -feature ∆ &gt;4</p><p>Consider permutations 2, 1, 4, 3 and 4, 3, 2, 1, none of which has exactly matching ngrams beyond uni- grams. Their PETs are in <ref type="figure" target="#fig_0">Figures 1b and 1c</ref>. Intuitively, 2, 1, 4, 3 is somewhat less scrambled than 4, 3, 2, 1 because it has at least some position in correct order. These "abstract ngrams" pertaining to correct order- ing of full phrases could be counted using ∆ [ ] which would recognize that on top of the PET in 1b there is a binary monotone node, unlike the PET in <ref type="figure" target="#fig_0">Figure 1c</ref> which has no monotone nodes at all. Even though the set of operators that describe a per- mutation is unique for the given permutation, the ways in which operators are combined (the derivation tree) is not unique. For example, for the fully monotone The features on PETs that we described so far look at the operators independently (they treat a derivation as a set of operators) so differenct derivations do not influ- ence the score-whichever derviation we use we will get the same feature score. However, the number of derivations might say something about the goodness of the permutation. Similar property of permutations was found to be helpful earlier in <ref type="bibr">(Mylonakis and Sima'an, 2008)</ref> as an ITG prior for learning translation rule prob- abilities. Permutations like 3, 2, 1, 4 and 2, 4, 3, 1 have the same set of operators, but the former factorizes into more PETs than the latter because 4, 3 must group first before grouping it with 2 and then 1 in 2, 4, 3, 1. The "freedom to bracket" in different ways could be a signal of better grouping of words (even if they have inverted word order). Hence we exploit one more fea- ture:</p><note type="other">2, 4, 1, 3 2 2, 1 1, 2 5 6 4 1 3 (a) Complex PET 1, 2 2, 1 2 1 2, 1 4 3 (b) PET with inversions 2, 1 2, 1 2, 1 4 3 2 1 (c) Canonical fully inverted PET 2, 1 2, 1 4 2, 1 3 2 1 (d) Alternative fully inverted PET 2, 1 2, 1 4 3 2, 1 2 1 (e) Alternative fully inverted PET 2, 1 4 2, 1 2, 1 3 2 1 (f) Alternative fully inverted PET 2, 1 4 2, 1 3 2, 1 2 1 (g) Alternative</note><p>∆ count the ratio between the number of alternative PETs for the given permutation, to the number of PETs that could be built if permutation was per- fectly grouped (fully monotone or fully inverted).</p><p>Finding the number of PETs that could be built does not require building all PETs or encoding them in the chart. The number can be computed directly from the canonical left-branching PET. Since multiple different PETs appear only in cases when there is a sequence of more than one node that is either 1, 2 or 2, 1 (Zhang et al., <ref type="bibr">2008</ref>), we can use these sequences to predict the number of PETs that could be built. Let X represent a set of sequences of the canonical derivation. The num- ber of PETs is computed in the following way:</p><formula xml:id="formula_3">#P ET s = x∈X Cat(|x|)<label>(1)</label></formula><formula xml:id="formula_4">Cat(n) = 1 n + 1 2n n (2)</formula><p>where Cat(·) is a Catalan number. The proof for this formula is beyond the scope of this paper. The reader can consider the example of the PET in <ref type="figure" target="#fig_0">Figure 1c</ref>. That derivation has one sequence of monotone operators of length 3. So the number of PETs that could be built is Cat(3) = 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We use human judgments from the WMT tasks: WMT13 is used for training whereas WMT12 for test- ing. The baseline is METEOR's latest version <ref type="bibr" target="#b8">(Michael Denkowski and Alon Lavie, 2014</ref>), one of the best met- rics on sentence level. To avoid contaminating the re- sults with differences with METEOR due to resources, we use the same alignment, tokenization and lower- casing (-norm in METEOR) algorithms, and the same tables of function words, synonyms, paraphrases and stemmers.</p><p>Kendall τ correlation is borrowed from WMT12 ( <ref type="bibr" target="#b1">Callison-Burch et al., 2012)</ref>:</p><formula xml:id="formula_5">τ = #concordant − #discordant − #ties #concordant + #discordant + #ties</formula><p>#concordant represents the number of pairs or- dered in the same way by metric and by human, #discordant the number of opposite orderings and #ties the number of tied rankings by metric. Beside testing our full metric BEER, we perform ex- periments where we remove one kind of the following features at a time:</p><p>1. char n-gram features (P, R and F-score) 2. all word features (P, R and F-score for all, function and content words),</p><p>3. all function and content words features   <ref type="table">Table 1</ref> shows the results sorted by their average Kendall τ correlation with human judgment.</p><note type="other">-cs en-fr en-de en-es cs-en fr-en de-en es-en avg τ BEER without char</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>Given these experimental results, we are coming back to the questions we asked in the introduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">What kind of features are more helpful for</head><p>sentence level evaluation?</p><p>Fluency vs. Adequacy The fluency features play a smaller role than adequacy features. Apparently, many SMT systems participating in this task have rather sim- ilar reordering models, trained on similar data, which makes the fluency features not that discriminative rel- ative to adequacy features. Perhaps in a different ap- plication, for example MT system tuning, the reorder- ing features would be far more relevant because ignor- ing them would basically imply disregarding the im- portance of the reordering model in MT.</p><p>Character vs. Word features We observe that, pre- cision, recall and F-score on character ngrams are cru- cial. We think that this shows that less sparse features are important for sentence level evaluation. The sec- ond best features are word features. Without word features, BEER scores just below METEOR, which suggests that word boundaries play a role as well. In contrast, differentiating between function and content words does not seem to be important.</p><p>PETs vs. Kendall τ Despite the smaller role for reordering features we can make a few observations. Firstly, while PETs and Kendall seem to have simi- lar effect on English-Foreign cases, in all four cases of Foreign-English PETs give better scores. We hypoth- esize that the quality of the permutations (induced be- tween system output and reference) is better for English than for the other target languages. Discarding PET features has far larger impact than discarding Kendall. Most interestingly, for de-en it makes the difference in outperforming METEOR. In many cases discarding Kendall τ improves the BEER score, likely because it conflicts with the PET features that are found more ef- fective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Is a linear model sufficient?</head><p>A further insight, from our perspective, is that F-score features constitute a crucial set of features, even when the corresponding precision and recall features are in- cluded. Because our model merely allows for linear in- terpolation, whereas F-score is a non-linear function of precision and recall, we think this suggests that a non- linear interpolation of precision and recall is useful. <ref type="bibr">4</ref> By formulating the evaluation as a ranking problem it is relatively easy to "upgrade" for using non-linear mod- els while using the same (or larger) set of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Train for the language pair or only for the target language?</head><p>All our models were trained for each language pair. This is not the case with many other metrics which train their models for each target language instead of language pair. We contrast these two settings in <ref type="table" target="#tab_1">Table  2</ref>. Training for each language pair separately does not give significant improvement over training for the tar- get language only. A possible reason could be that by training for the target language we have more training data (in this case four times more).  The results across individual language pairs are mostly consistent with the averages with a few exceptions. BEER outperforms METEOR in five out of eight lan- guage pairs, ties at one (the difference is only 0.001 on es-en) and loses in two (en-fr and cs-en). In some cases BEER is better than METEOR by a large margin (see, e.g., en-cs, en-de).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work we show that combining less sparse fea- tures at the sentence level into a linear model that is trained on ranking we can obtain state-of-the-art re- sults. The analysis of the results shows that features on character ngrams are crucial, besides the standard word level features. The reordering features, while rather important, are less effective within this WMT task, al- beit the more abstract PET features have larger impact than the often used Kendall. Good performance of F- score features leads to the conclusion that linear models might not be sufficient for modeling human sentence level ranking and to learn the right relation between precision and recall it could be worthwhile exploring non-linear models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of PETs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Train for cs-en fr-en de-en es-en avg τ target lang 0.199 0.257 0.273 0.248 0.244 lang pair 0.198 0.263 0.283 0.245 0.247</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Kendall τ scores on WMT12 for different 
training data 

5.4 BEER vs. METEOR 

</table></figure>

			<note place="foot" n="3"> For example 2, 4, 1, 3 is atomic whereas 4, 3, 2, 1 is not. The former does not contain any contiguous sub-ranges of integers whereas the latter contains sub-range {2, 3, 4} in reverse order 4, 3, 2, which factorizes into two binary inverting nodes cf. Fig. 1c.</note>

			<note place="foot" n="4">. all F-scores (all words, function words, content words, char ngrams)</note>

			<note place="foot" n="4"> Interestingly, METEOR tunes β in F β. 205</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported by STW grant nr. 12271 and NWO VICI grant nr. 277-89-002. We also thank TAUS and the other DatAptor project User Board members.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LRscore for Evaluating Lexical and Reordering Quality in MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR</title>
		<meeting>the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="327" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Findings of the 2012 Workshop on Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Workshop on Statistical Machine Translation</title>
		<meeting>the Seventh Workshop on Statistical Machine Translation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="10" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The WEKA Data Mining Software: An Update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explor. Newsl</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Support Vector Learning for Ordinal Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tuning as Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-05" />
			<biblScope unit="page" from="1352" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic Evaluation of Translation Quality for Distant Language Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideki</forename><surname>Isozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhito</forename><surname>Sudoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajime</forename><surname>Tsukada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="944" to="952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to Rank for Information Retrieval and Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies. Morgan</title>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical Translation Equivalence over Word Alignments</title>
	</analytic>
	<monogr>
		<title level="m">ILLC Prepublication Series</title>
		<editor>Gideon Maillette de Buy Wenniger and Khalil Sima&apos;an</editor>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2011" to="2049" />
		</imprint>
		<respStmt>
			<orgName>University of Amsterdam</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meteor Universal: Language Specific Translation Evaluation for Any Target Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Workshop on Statistical Machine Translation</title>
		<meeting>the ACL 2014 Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Markos Mylonakis and Khalil Sima&apos;an</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Phrase Translation Probabilities with ITG Priors and Smoothing as Learning Objective</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="630" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BLEU: A Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">BEER: BEtter Evaluation as Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloš</forename><surname>Stanojevi´cstanojevi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, Maryland, USA, June</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="414" to="419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stochastic inversion transduction grammars and bilingual parsing of parallel corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="403" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fusion of Word and Letter Based Metrics for Automatic MT Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junguo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI&apos;13</title>
		<meeting>the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI&apos;13</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2204" to="2210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sentence Level Machine Translation Evaluation As a Ranking Problem: One Step Aside from BLEU</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation, StatMT &apos;07</title>
		<meeting>the Second Workshop on Statistical Machine Translation, StatMT &apos;07<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="240" to="247" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Factorization of synchronous context-free grammars in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL Workshop on Syntax and Structure in Statistical Translation</title>
		<imprint>
			<publisher>SSST</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting Synchronous Grammar Rules From Word-Level Alignments in Linear Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08)</title>
		<meeting>the 22nd International Conference on Computational Linguistics (COLING-08)<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1081" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
