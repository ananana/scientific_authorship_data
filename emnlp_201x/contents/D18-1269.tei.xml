<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">XNLI: Evaluating Cross-lingual Sentence Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
							<email>adinawilliams,bowman@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI</orgName>
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">XNLI: Evaluating Cross-lingual Sentence Representations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2475" to="2485"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>2475</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic , there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Contemporary natural language processing sys- tems typically rely on annotated data to learn how to perform a task (e.g., classification, sequence tagging, natural language inference). Most com- monly the available training data is in a single lan- guage (e.g., English or Chinese) and the resulting system can perform the task only in the training language. In practice, however, systems used in major international products need to handle inputs in many languages. In these settings, it is nearly impossible to annotate data in all languages that a system might encounter during operation.</p><p>A scalable way to build multilingual systems is through cross-lingual language understanding (XLU), in which a system is trained primarily on data in one language and evaluated on data in others. While XLU shows promising results for tasks such as cross-lingual document classification ( <ref type="bibr" target="#b26">Klementiev et al., 2012;</ref><ref type="bibr" target="#b42">Schwenk and Li, 2018)</ref>, there are very few, if any, XLU benchmarks for more difficult language understanding tasks like natural language inference. Large-scale natural language inference (NLI), also known as recog- nizing textual entailment (RTE), has emerged as a practical test bed for work on sentence understand- ing. In NLI, a system is tasked with reading two sentences and determining whether one entails the other, contradicts it, or neither (neutral). Re- cent crowdsourced annotation efforts have yielded datasets for NLI in English ( <ref type="bibr" target="#b6">Bowman et al., 2015;</ref><ref type="bibr">Williams et al., 2017</ref>) with nearly a million exam- ples, and these have been widely used to evaluate neural network architectures and training strate- gies ( <ref type="bibr">Rocktäschel et al., 2016;</ref><ref type="bibr" target="#b16">Gong et al., 2018;</ref><ref type="bibr" target="#b36">Peters et al., 2018;</ref><ref type="bibr" target="#b51">Wang et al., 2018)</ref>, as well as to train effective, reusable sentence representations ( <ref type="bibr" target="#b12">Conneau et al., 2017;</ref><ref type="bibr" target="#b47">Subramanian et al., 2018;</ref><ref type="bibr" target="#b7">Cer et al., 2018)</ref>.</p><p>In this work, we introduce a benchmark that we call the Cross-lingual Natural Language In- ference corpus, or XNLI, by extending these NLI corpora to 15 languages. XNLI consists of 7500 human-annotated development and test examples in NLI three-way classification format in English, French, Spanish, German, Greek, Bulgarian, Rus- sian, Turkish, Arabic, Vietnamese, Thai, Chi- nese, Hindi, Swahili and Urdu, making a total of 112,500 annotated pairs. These languages span several language families, and with the inclusion of Swahili and Urdu, include two lower-resource languages as well.</p><p>Because of its focus on development and test  We evaluate several approaches to cross-lingual learning of natural language inference that lever- age parallel data from publicly available corpora at training time. We show that parallel data can help align sentence encoders in multiple languages such that a classifier trained with English NLI data can correctly classify pairs of sentences in other languages. While outperformed by our machine translation baselines, we show that this alignment mechanism gives very competitive results.</p><p>A second practical use of XNLI is the eval- uation of pretrained general-purpose language- universal sentence encoders. We hope that this benchmark will help the research community build multilingual text embedding spaces. Such embed- dings spaces will facilitate the creation of multi- lingual systems that can transfer across languages with little or no extra supervision.</p><p>The paper is organized as follows: We next sur- vey the related literature on cross-lingual language understanding. We then describe our data collec- tion methods and the resulting corpus in Section 3. We describe our baselines in Section 4, and finally present and discuss results in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Multilingual Word Embeddings Much of the work on multilinguality in language understand- ing has been at the word level. Several approaches have been proposed to learn cross-lingual word representations, i.e., word representations where translations are close in the embedding space. Many of these methods require some form of supervision (typically in the form of a small bi- lingual lexicon) to align two sets of source and tar- get embeddings to the same space ( <ref type="bibr" target="#b32">Mikolov et al., 2013a;</ref><ref type="bibr" target="#b27">Kociský et al., 2014;</ref><ref type="bibr" target="#b15">Faruqui and Dyer, 2014;</ref><ref type="bibr" target="#b1">Ammar et al., 2016)</ref>. More recent stud- ies have showed that cross-lingual word embed- dings can be generated with no supervision what- soever ( <ref type="bibr" target="#b4">Artetxe et al., 2017;</ref>.</p><p>Sentence Representation Learning Many ap- proaches have been proposed to extend word em- beddings to sentence or paragraph representa- tions ( <ref type="bibr" target="#b30">Le and Mikolov, 2014;</ref><ref type="bibr" target="#b53">Wieting et al., 2016;</ref><ref type="bibr" target="#b3">Arora et al., 2017</ref>). The most straightforward way to generate sentence embeddings is to con- sider an average or weighted average of word representations, usually referred to as continu- ous bag-of-words (CBOW). Although naïve, this method often provides a strong baseline. More so- phisticated approaches-such as the unsupervised SkipThought model of <ref type="bibr" target="#b25">Kiros et al. (2015)</ref> that extends the skip-gram model of <ref type="bibr" target="#b33">Mikolov et al. (2013b)</ref> to the sentence level-have been pro-posed to capture syntactic and semantic depend- encies inside sentence representations. While these fixed-size sentence embedding methods have been outperformed by their supervised counter- parts ( <ref type="bibr" target="#b12">Conneau et al., 2017;</ref><ref type="bibr" target="#b47">Subramanian et al., 2018)</ref>, some recent developments have shown that pretrained language models can also transfer very well, either when the hidden states of the model are used as contextualized word vectors ( <ref type="bibr" target="#b36">Peters et al., 2018)</ref>, or when the full model is fine- tuned on transfer tasks ( <ref type="bibr" target="#b39">Radford et al.;</ref><ref type="bibr" target="#b22">Howard and Ruder, 2018)</ref>.</p><p>Multilingual Sentence Representations There has been some effort on developing multilingual sentence embeddings. For example, <ref type="bibr" target="#b9">Chandar et al. (2013)</ref> train bilingual autoencoders with the objec- tive of minimizing reconstruction error between two languages.  and <ref type="bibr">EspañaBonet et al. (2017)</ref> jointly train a sequence-to- sequence MT system on multiple languages to learn a shared multilingual sentence embedding space. <ref type="bibr" target="#b27">Hermann and Blunsom (2014)</ref> propose a compositional vector model involving unigrams and bigrams to learn document level representa- tions. <ref type="bibr" target="#b37">Pham et al. (2015)</ref> directly train embedding representations for sentences with no attempt at compositionality. <ref type="bibr" target="#b58">Zhou et al. (2016)</ref> learn bilin- gual document representations by minimizing the Euclidean distance between document representa- tions and their translations.</p><p>Cross-lingual Evaluation Benchmarks The lack of evaluation benchmark has hindered the development of such multilingual representations. Most previous approaches use the Reuters cross- lingual document classification corpus <ref type="bibr" target="#b26">Klementiev et al. (2012)</ref> for evaluation. However, the clas- sification in this corpus is done at document level, and, as there are many ways to aggregate sen- tence embeddings, the comparison between differ- ent sentence embeddings is difficult. Moreover, the distribution of classes in the Reuters corpus is highly unbalanced, and the dataset does not pro- vide a development set in the target language, fur- ther complicating experimental comparisons.</p><p>In addition to the Reuters corpus, <ref type="bibr" target="#b8">Cer et al. (2017)</ref> propose sentence-level multilingual train- ing and evaluation datasets for semantic textual similarity in four languages. There have also been efforts to build multilingual RTE datasets, either through translating English data ), or annotating sentences from a parallel cor- pora ). More recently, <ref type="bibr" target="#b0">Agic and Schluter (2017)</ref> provide a corpus, that is very com- plementary to our work, of human translations for 1332 pairs of the SNLI data into Arabic, French, Russian, and Spanish. Among all these bench- marks, XNLI is the first large-scale corpus for evaluating sentence-level representations on that many languages.</p><p>In practice, cross-lingual sentence understand- ing goes beyond translation. For instance, <ref type="bibr" target="#b34">Mohammad et al. (2016)</ref> analyze the differences in human sentiment annotations of Arabic sentences and their English translations, and conclude that most of them come from cultural differences. Sim- ilarly, <ref type="bibr" target="#b1">Smith et al. (2016)</ref> show that most of the degradation in performance when applying a clas- sification model trained in English to Spanish data translated to English is due to cultural differences. One of the limitations of the XNLI corpus is that it does not capture these differences, since it was obtained by translation. We see the XNLI evalua- tion as a necessary step for multilingual NLP be- fore tackling the even more complex problem of domain-adaptation that occurs when handling this the change in style from one language to another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The XNLI Corpus</head><p>Because the test portion of the Multi-Genre NLI data is private, the Cross-lingual NLI Corpus (XNLI) is based on new English NLI data. To col- lect the core English portion, we follow precisely the same crowdsourcing-based procedure used for the existing Multi-Genre NLI corpus, and collect and validate 750 new examples from each of the ten text sources used in that corpus for a total of 7500 examples. With that portion in place, we create the full XNLI corpus by employing profes- sional translators to translate it into our ten target languages. This section describes this process and the resulting corpus.</p><p>Translating, rather than generating new hypoth- esis sentences in each language separately, has multiple advantages. First, it ensures that the data distributions are maximally similar across lan- guages. As speakers of different languages may have slightly different intuitions about how to fill in the supplied prompt, this allows us to avoid adding this unwanted degree of freedom. Second, it allows us to use the same trusted pool of work- ers as was used prior NLI crowdsourcing efforts, without the need for training a new pool of work- ers in each language. Third, for any premise, this process allows us to have a corresponding hypoth- esis in any language.</p><p>This translation approach carries with it the risk that the semantic relations between the two sen- tences in each pair might not be reliably preserved in translation, as <ref type="bibr" target="#b34">Mohammad et al. (2016)</ref> ob- served for sentiment. We investigate this poten- tial issue in our corpus and find that, while it does occur, it only concerns a negligible number of sen- tences (see Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>The English Corpus Our collection procedure for the English portion of the XNLI corpus fol- lows the same procedure as the MultiNLI corpus. We sample 250 sentences from each of the ten sources that were used in that corpus, ensuring that none of those selected sentences overlap with the distributed corpus. Nine of the ten text sources are drawn from the second release of the Open American National Corpus 1 : Face-To-Face, Tele- phone, Government, 9/11, Letters, Oxford Uni- versity Press (OUP), Slate, Verbatim, and Gov- ernment. The tenth, Fiction, is drawn from the novel Captain Blood <ref type="bibr" target="#b41">(Sabatini, 1922)</ref>. We refer the reader to <ref type="bibr">Williams et al. (2017)</ref> for more de- tails on each genre.</p><p>Given these sentences, we ask the same MultiNLI worker pool from a crowdsourcing platform to produce three hypotheses for each premise, one for each possible label.</p><p>We present premise sentences to workers using the same templates as were used in MultiNLI. We also follow that work in pursuing a second valida- tion phase of data collection in which each pair of sentences is relabeled by four other workers. For each validated sentence pair, we assign a gold la- bel representing a majority vote between the initial label assigned to the pair by the original annotator, and the four additional labels assigned by valida- tion annotators. We obtained a three-vote consen- sus for 93% of the data. In our experiments, we kept the 7% additional ones, but we mark these ones with a special label '-'.</p><p>Translating the Corpus Finally, we hire trans- lators to translate the resulting sentences into 15 languages using the One Hour Translation plat- form. We translate the premises and hypotheses separately, to ensure that no context is added to the hypothesis that was not there originally, and sim- ply copy the labels from the English source text. Some examples are shown in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Resulting Corpus</head><p>One main concern in studying the resulting corpus is to determine whether the gold label for some of the sentence pairs changes as a result of informa- tion added or removed in the translation process.</p><p>Investigating the data manually, we find an ex- ample in the Chinese translation where an entail- ment relation becomes a contradictory relation, while the entailment is preserved in other lan- guages. Specifically, the term upright which was used in English as entailment of standing, was translated into Chinese as sitting upright thus cre- ating a contradiction. However, the difficulty of finding such an example in the data suggests its rarity.</p><p>To quantify this observation, we recruit two bilingual annotators to re-annotate 100 examples each in both English and French following our standard validation procedure. The examples are drawn from two non-overlapping random subsets of the development data to prevent the annota- tors from seeing the source English text for any translated text they annotate. With no training or burn-in period, these annotators recover the En- glish consensus label 85% of the time on the orig- inal English data and 83% of the time on the trans- lated French, suggesting that the overall semantic relationship between the two languages has been preserved. As most sentences are relatively easy to translate, in particular the hypotheses generated by the workers, there seems to be little ambiguity added by the translator.</p><p>More broadly, we find that the resulting corpus has similar properties to the MultiNLI corpus. For all languages, on average, the premises are twice as long as the hypotheses (See <ref type="table" target="#tab_3">Table 2</ref>). The top hypothesis words indicative of the class label - scored using the mutual information between each word and class in the corpus -are similar across languages, and overlap those of the MultiNLI cor- pus ( <ref type="bibr" target="#b19">Gururangan et al., 2018)</ref>. For example, a translation of at least one of the words no, not or never is among the top two cues for contradiction in all languages.</p><p>As in the original MultiNLI corpus, we ex- pect that cues like these <ref type="bibr">('artifacts', in</ref>   rangan's terms, also observed by <ref type="bibr" target="#b38">Poliak et al., 2018;</ref><ref type="bibr" target="#b50">Tsuchiya, 2018</ref>) allow a baseline system to achieve better-than-random accuracy with access only to the premise sentences. We accept this as an unavoidable property of the NLI task over natural- istic sentence pairs, and see no reason to expect that this baseline would achieve better accuracy than the relatively poor 53% seen in <ref type="bibr" target="#b19">Gururangan et al. (2018)</ref>.</p><note type="other">Guru-en fr es de el bg ru tr ar vi th zh hi sw ur Premise 21.7</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cross-Lingual NLI</head><p>In this section we present results with XLU sys- tems that can serve as baselines for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Translation-Based Approaches</head><p>The most straightforward techniques for XLU rely on translation systems. There are two natural ways to use a translation system: TRANSLATE TRAIN, where the training data is translated into each tar- get language to provide data to train each clas- sifier, and TRANSLATE TEST, where a transla- tion system is used at test time to translate in- put sentences to the training language. These two methods provide strong baselines, but both present practical challenges. The former requires training and maintaining as many classifiers as there are languages, while the latter relies on computationally-intensive translation at test time. Both approaches are limited by the quality of the translation system, which itself varies with the quantity of available training data and the similar- ity of the language pair involved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multilingual Sentence Encoders</head><p>An alternative to translation is to rely on language- universal embeddings of text and build multilin- gual classifiers on top of these representations. If an encoder produces an embedding of an English sentence close to the embedding of its translation in another language, then a classifier learned on top of English sentence embeddings will be able to classify sentences from different languages with- out needing a translation system at inference time.</p><p>We evaluate two types of cross-lingual sen- tence encoders: (i) pretrained universal multilin- gual sentence embeddings based on the average of word embeddings (X-CBOW), (ii) bidirectional- LSTM (BiLSTM) <ref type="bibr" target="#b21">(Hochreiter and Schmidhuber, 1997</ref>) sentence encoders trained on the MultiNLI training data (X-BILSTM). The former evaluates transfer learning while the latter evaluates NLI- specific encoders trained on in-domain data. Both approaches use the same alignment loss for align- ing sentence embedding spaces from multiple lan- guages which is present below. We consider two ways of extracting feature vectors from the BiLSTM: either using the initial and final hid- den states ), or using the element-wise max over all states <ref type="bibr" target="#b10">(Collobert and Weston, 2008</ref>).</p><p>The first approach is commonly used as a strong baseline for monolingual sentence embeddings ( <ref type="bibr" target="#b3">Arora et al., 2017;</ref><ref type="bibr" target="#b11">Conneau and Kiela, 2018;</ref><ref type="bibr" target="#b17">Gouews et al., 2014</ref>). Concretely, we consider the English fastText word embedding space as be- ing fixed, and fine-tune embeddings in other lan- guages so that the average of the word vectors in a sentence is close to the average of the word vectors in its English translation. The second ap- proach consists in learning an English sentence en- coder on the MultiNLI training data along with an encoder on the target language, with the ob- jective that the representations of two translations are nearby in the embedding space. In both ap- proaches, an English encoder is fixed, and we train target language encoders to match the output of this encoder. This allows us to build sentence rep- resentations that belong to the same space. Joint training of encoders and parameter sharing are also promising directions to improve and simplify the alignment of sentence embedding spaces. We leave this for future work.</p><p>In all experiments, we consider encoders that output a vector of fixed size as a sentence repre- sentation. While previous work shows that perfor- mance on the NLI task can be improved by using cross-sentence attention between the premise and hypothesis ( <ref type="bibr">Rocktäschel et al., 2016;</ref><ref type="bibr" target="#b16">Gong et al., 2018)</ref>, we focus on methods with fixed-size sen- tence embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Aligning Word Embeddings</head><p>Multilingual word embeddings are an efficient way to transfer knowledge from one language to another. For instance, <ref type="bibr" target="#b57">Zhang et al. (2016)</ref> show that cross-lingual embeddings can be used to extend an English part-of-speech tagger to the cross-lingual setting, and <ref type="bibr" target="#b55">Xiao and Guo (2014)</ref> achieve similar results in dependency parsing. Cross-lingual embeddings also provide an ef- ficient mechanism to bootstrap neural machine translation (NMT) systems for low-resource lan- guage pairs, which is critical in the case of un- supervised machine translation ( <ref type="bibr" target="#b5">Artetxe et al., 2018)</ref>. In that case, the use cross-lingual embeddings directly helps the align- ment of sentence-level encoders. Cross-lingual embeddings can be generated efficiently using a very small amount of supervision. By using a small parallel dictionary with n = 5000 word pairs, it is possible to learn a linear mapping to minimize</p><formula xml:id="formula_0">W = argmin W ∈O d (R) W X − Y F = U V T ,</formula><p>where d is the dimension of the embeddings, and X and Y are two matrices of shape (d, n) that cor- respond to the aligned word embeddings that ap- pear in the parallel dictionary, O d (R) is the group of orthogonal matrices of dimension d, and U and V are obtained from the singular value decompo- sition (SVD) of Y X T : U ΣV T = SVD(Y X T ). <ref type="bibr" target="#b56">Xing et al. (2015)</ref> show that enforcing the ortho- gonality constraint on the linear mapping leads to better results on the word translation task.</p><p>In this paper, we use common-crawl word em- beddings ( <ref type="bibr" target="#b18">Grave et al., 2018)</ref> aligned with the MUSE library of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Universal Multilingual Sentence Embeddings</head><p>Most of the successful recent approaches for learn- ing universal sentence representations have re- lied on English ( <ref type="bibr" target="#b25">Kiros et al., 2015;</ref><ref type="bibr" target="#b3">Arora et al., 2017;</ref><ref type="bibr" target="#b12">Conneau et al., 2017;</ref><ref type="bibr" target="#b47">Subramanian et al., 2018;</ref><ref type="bibr" target="#b7">Cer et al., 2018)</ref>. While notable recent ap- proaches have considered building a shared sen- tence encoder for multiple languages using pub- licly available parallel corpora <ref type="bibr" target="#b23">(Johnson et al., 2016;</ref><ref type="bibr" target="#b14">España-Bonet et al., 2017)</ref>, the lack of a large-scale, sentence-level se- mantic evaluation has limited their adoption by the community. In particular, these works do not cover the scale of languages considered in XNLI, and are limited to high-resource languages. As a baseline for the evaluation of multilingual sen- tence representations in the 15 languages of XNLI, we consider state-of-the-art common-crawl em- beddings with a CBOW encoder. Our approach, dubbed X-CBOW, consists in fixing the English pretrained word embeddings, and fine-tuning the target (e.g., French) word embeddings so that the CBOW representations of two translations are close in embedding space. In that case, we con- sider our multilingual sentence embeddings as be- ing pretrained and only learn a classifier on top of them to evaluate their quality, similar to so-called "transfer" tasks in ( <ref type="bibr" target="#b25">Kiros et al., 2015;</ref><ref type="bibr" target="#b12">Conneau et al., 2017</ref>) but in the multilingual setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Aligning Sentence Embeddings</head><p>Training for similarity of source and target sen- tences in an embedding space is conceptually and computationally simpler than generating a trans- lation in the target language from a source sen- tence. We propose a method for training for cross- lingual similarity and evaluate approaches based on the simpler task of aligning sentence represen- tations. Under our objective, the embeddings of two parallel sentences need not be identical, but only close enough in the embedding space that the decision boundary of the English classifier cap- tures the similarity. We propose a simple alignment loss function to align the embedding spaces of two different lan- guages. Specifically, we train an English encoder on NLI, and train a target encoder by minimizing the loss:</p><formula xml:id="formula_1">Lalign(x, y) = sim(x, y) − λ(sim(xc, y) + sim(x, yc))</formula><p>where (x, y) corresponds to the source and tar- get sentence embeddings, (x c , y c ) is a contrastive term (i.e. negative sampling), λ controls the weight of the negative examples in the loss. For a similarity measure, we use the L2 norm with sim(x, y) = −−x−y 2 . We obtain similar results using the cosine similarity. A ranking loss <ref type="bibr" target="#b52">(Weston et al., 2011</ref>) of the form   <ref type="table">Table 3</ref>: BLEU scores of our translation models (XX-En) P@1 for multilingual word embeddings.</p><note type="other">fr es de el bg ru tr ar vi th zh hi sw ur XX-En</note><p>that pushes the sentence embeddings of a trans- lation pair to be closer than the ones of negative pairs leads to very poor results in this particular case. As opposed to L align , L rank does not encour- age the embeddings of sentence pairs to be close enough so that the shared classifier can understand that these sentences have the same meaning.</p><p>We use L align in the cross-lingual embed- dings baselines X-CBOW, X-BILSTM-LAST and X- BILSTM-MAX. For X-CBOW, the encoder is pre- trained (transfer-learning), while the English X- BiLSTMs are trained on NLI (in-domain). For the three methods, the English encoder is then fixed. Each of the 14 other languages have their own en- coders with same architecture. These encoders are trained to "copy" the English encoder using the L align loss and the parallel data described in sec- tion 5.2.</p><p>We only back-propagate through the target en- coder when optimizing L align such that all 14 en- coders live in the same English embedding space. In these experiments, we initialize lookup tables of the LSTMs with pretrained cross-lingual em- beddings discussed in Section 4.2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training details</head><p>We use internal translation systems to translate data between English and the 10 other languages. For TRANSLATE TEST (see <ref type="table" target="#tab_6">Table 4</ref>), we translate each test set into English, while for the TRANS- LATE TRAIN, we translate the English training data of MultiNLI 2 . To give an idea of the transla- tion quality, we give BLEU scores of the automatic translation from the foreign language into English of the XNLI test set in <ref type="table">Table 3</ref>.</p><p>We use pretrained 300D word embeddings and only consider the most 500,000 frequent words in the dictionary, which generally covers more than 98% of the words found in XNLI corpora. We set the number of hidden units of the BiLSTMs to 512, and use the Adam optimizer ( <ref type="bibr" target="#b24">Kingma and Ba, 2014</ref>) with default parameters. For the alignment loss, setting λ to 0.25 worked best in our experi- ments, and we found that the trade-off between the importance of the positive and the negative pairs was particularly important (see <ref type="table">Table 5</ref>). When fitting the target BiLSTM encoder to the English encoder, we fine-tune the lookup table associated to the target encoder, but keep the source word em- beddings fixed. The classifier is a feed-forward neural network with one hidden layer of 128 hid- den units, regularized with dropout ( <ref type="bibr" target="#b46">Srivastava et al., 2014</ref>) at a rate of 0.1. For X-BiLSTMs, we perform model selection on the XNLI valida- tion set in each target language. For X-CBOW, we keep a validation set of parallel sentences to eval- uate our alignment loss. The alignment loss re- quires a parallel dataset of sentences for each pair of languages, which we describe next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parallel Datasets</head><p>We use publicly available parallel datasets to learn the alignment between English and target en- coders. For French, Spanish, Russian, Arabic and Chinese, we use the United Nation corpora <ref type="bibr" target="#b59">(Ziemski et al., 2016)</ref>, for German, Greek and Bul- garian, the Europarl corpora ( <ref type="bibr" target="#b28">Koehn, 2005)</ref>, for Turkish, Vietnamese and Thai, the OpenSubtitles 2018 corpus <ref type="bibr" target="#b49">(Tiedemann, 2012)</ref>, and for Hindi, the IIT Bombay corpus ( <ref type="bibr" target="#b2">Anoop et al., 2018)</ref>. For all the above language pairs, we were able to gather more than 500,000 parallel sentences, and we set the maximum number of parallel sentences to 2 million. For the lower-resource languages Urdu and Swahili, the number of parallel sen- tences is an order of magnitude smaller than for the other languages we consider. For Urdu, we used the Bible and Quran transcriptions <ref type="bibr" target="#b49">(Tiedemann, 2012</ref>  only able to gather 42k sentences using the Global Voices corpus and the Tanzil Quran transcription corpus 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis</head><p>Comparing in-language performance in <ref type="table" target="#tab_6">Table 4</ref>, we observe that, when using BiLSTMs, results are consistently better when we take the dimension- wise maximum over all hidden states (BiLSTM- max) compared to taking the last hidden state (BiLSTM-last). Unsuprisingly, BiLSTM results are better than the pretrained CBOW approach for all languages. As in <ref type="bibr" target="#b6">Bowman et al. (2015)</ref>, we also observe the superiority of BiLSTM encoders over CBOW, even when fine-tuning the word em- beddings of the latter on the MultiNLI training set, thereby again confirming that the NLI task requires more than just word information. Both of these findings confirm previously published re- sults ( <ref type="bibr" target="#b12">Conneau et al., 2017</ref>). <ref type="table" target="#tab_6">Table 4</ref> shows that translation offers a strong baseline for XLU. Within translation, TRANS- LATE TEST appears to perform consistently better than TRANSLATE TRAIN for all languages. The best cross-lingual results in our evaluation are ob- tained by the TRANSLATE TEST approach for all cross-lingual directions. Within the translation approaches, as expected, we observe that cross- lingual performance depends on the quality of the translation system. In fact, translation-based results are very well-correlated with the BLEU scores for the translation systems; XNLI perfor- mance for three of the four languages with the best translation systems (comparing absolute BLEU, <ref type="table">Table 3</ref>) is above 70%. This performance is still about three points below the English NLI perfor- mance of 73.7%. This slight drop in performance may be related to translation error, changes in style, or artifacts introduced by the machine trans- lation systems that result in discrepancies between the training and test data.</p><p>For cross-lingual performance, we observe a healthy gap between the English results and the results obtained on other languages. For instance, for French, we obtain 67.7% accuracy when clas- sifying French pairs using our English classifier and multilingual sentence encoder. When using our alignment process, our method is competi- tive with the TRANSLATE TRAIN baseline, sug- gesting that it might be possible to encode similar- ity between languages directly in the embedding spaces generated by the encoders. However, these methods are still below the other machine trans- lation baseline TRANSLATE TEST, which signifi- cantly outperforms the multilingual sentence en- coder approach by up to 6% (Swahili). These pro- duction systems have been trained on much larger training data than the ones used for the alignment loss (section 5.2), which can partly explain the superiority of this method over the baseline. In- terestingly, the two points difference in accuracy between X-BiLSTM-last and X-BiLSTM-max is maintained across languages, which suggests that having a stronger encoder in English also posi- tively impacts the transfer results on other lan- guages.</p><p>In <ref type="table">Table 5</ref>, we report the validation accuracy using BiLSTM-max on three languages with dif- ferent training hyper-parameters. Fine-tuning the fr ru zh f t = 1, λ = 0.25 <ref type="bibr">[default]</ref> 68.9 66.4 67.9 f t = 1, λ = 0.0 (no negatives) 67.8 66.2 66.3 f t = 1, λ = 0.5 64.5 61.3 63.7 f t = 0, λ = 0.25 68.5 66.3 67.7 <ref type="table">Table 5</ref>: Validation accuracy using BiLSTM- max. Default setting corresponds to λ = 0.25 (importance of the negative terms) and uses fine- tuning of the target lookup table (f t =1).</p><p>embeddings does not significantly impact the re- sults, suggesting that the LSTM alone is ensuring alignment of parallel sentence embeddings. We also observe that the negative term is not critical to the performance of the model, but can lead to slight improvement in Chinese (up to 1.6%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>A typical problem in industrial applications is the lack of supervised data for languages other than English, and particularly for low-resource languages. Since annotating data in every lan- guage is not a realistic approach, there has been a growing interest in cross-lingual understanding and low-resource transfer in multilingual scenar- ios. In this work, we extend the development and test sets of the Multi-Genre Natural Language In- ference Corpus to 15 languages, including low- resource languages such as Swahili and Urdu. Our dataset, dubbed XNLI, is designed to address the lack of standardized evaluation protocols in cross- lingual understanding, and will hopefully help the community make further strides in this area. We present several approaches based on cross-lingual sentence encoders and machine translation sys- tems. While machine translation baselines ob- tained the best results in our experiments, these ap- proaches rely on computationally-intensive trans- lation models either at training or at test time. We found that cross-lingual encoder baselines provide an encouraging and efficient alternative, and that further work is required to match the performance of translation based methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Lrank(x, y) = max(0, α − sim(x, y) + s(x, yc)) + max(0, α − sim(x, y) + s(xc, y))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Examples (premise and hypothesis) from various languages and genres from the XNLI corpus. 

data, this corpus is designed to evaluate cross-
lingual sentence understanding, where models 
have to be trained in one language and tested in 
different ones. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : Average number of tokens per sentence in the XNLI corpus for each language.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Cross-lingual natural language inference (XNLI) test accuracy for the 15 languages. 

</table></figure>

			<note place="foot" n="1"> http://www.anc.org/</note>

			<note place="foot" n="2"> To allow replication of results, we share the MT translations of XNLI training and test sets.</note>

			<note place="foot" n="3"> http://opus.nlpl.eu/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This project has benefited from financial support to Samuel R. Bowman by Google, Tencent Hold-ings, and Samsung Research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Baselines and test data for cross-lingual inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</author>
		<idno>abs/1704.05347</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Massively multilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1602.01925" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The iit bombay englishhindi parallel corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunchukuttan</forename><surname>Anoop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehta</forename><surname>Pratik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhattacharyya</forename><surname>Pushpak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning bilingual word embeddings with (almost) no bilingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gorka</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Universal sentence encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Yi</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhomni</forename><surname>St John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Tar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11175</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semeval2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><forename type="middle">T</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iñigo</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Specia</surname></persName>
		</author>
		<idno>abs/1708.00055</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Balaraman Ravindran, Vikas Raykar, and Amrita Saha</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarath</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khapra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, Workshop Track</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Multilingual deep learning</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Senteval: An evaluation toolkit for universal sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno>abs/1803.05449</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jegou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An empirical analysis of nmt-derived interlingual embeddings and their use in parallel sentence identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>España-Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ádám</forename><forename type="middle">Csaba</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="1340" to="1348" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving vector space word representations using monolingual correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Natural language inference over interaction space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bilbowa: Fast bilingual distributed representations without word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gouews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning word vectors for 157 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>LREC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno>abs/1803.02324</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multilingual models for compositional distributed semantics</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<editor>Karl Moritz Hermann and Phil Blunsom</editor>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="58" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Finetuned language models for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Google&apos;s multilingual neural machine translation system: enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corrado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04558</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhattarai</surname></persName>
		</author>
		<title level="m">ducing crosslingual distributed representations of words. In Coling</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning bilingual word representations by marginalizing alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kociský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="224" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT summit</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised machine translation using monolingual corpora only</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Using bilingual parallel corpora for crosslingual textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL, HLT &apos;11</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1336" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">How translation alters sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Salameh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kiritchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="130" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Divide and conquer: Crowdsourcing the creation of cross-lingual textual entailment corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning distributed representations for multilingual text sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Vector Space Modeling for NLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hypothesis only baselines in natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparajita</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM</title>
		<meeting>*SEM</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Improving language understanding by generative pre-training</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Kočisk`y, and Phil Blunsom. 2016. Reasoning about entailment with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočisk</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Captain Blood. Houghton Mifflin Company</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Sabatini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A corpus for multilingual document classification in eight languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3548" to="3551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning joint multilingual sentence representations with neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Giorgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Solanki</surname></persName>
		</author>
		<editor>Johannes C. Eichstaedt, H. Andrew Schwartz, Muhammad Abdul-Mageed, Anneke Buffone, and</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Does &apos;well-being&apos; translate on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2042" to="2047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning general purpose distributed sentence representations via large scale multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher J</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in opus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC, Istanbul, Turkey. European Language Resources Association (ELRA)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Performance impact caused by hidden bias of training data for recognizing textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Tsuchiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amapreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Distributed word representation learning for cross-lingual dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="119" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Normalized word embedding and orthogonal transform for bilingual word translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiye</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Ten pairs to tagmultilingual pos tagging via coarse mapping between embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gaddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cross-lingual sentiment classification with bilingual document representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinjie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Ziemski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
		<title level="m">The united nations parallel corpus v1. 0. In LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
