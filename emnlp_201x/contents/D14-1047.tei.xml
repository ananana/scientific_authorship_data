<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Nothing like Good Old Frequency: Studying Context Filters for Distributional Thesauri</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muntsa</forename><surname>Padró</surname></persName>
							<email>muntsa.padro@inf.ufrgs.br, marco.idiart@gmail.com, carlos.ramisch@lif.univ-mrs.fr, avillavicencio@inf.ufrgs.br</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="laboratory">LIF UMR 7279</orgName>
								<orgName type="institution" key="instit1">Federal University of Rio Grande do Sul (Brazil) ♥ Institute of Physics</orgName>
								<orgName type="institution" key="instit2">Federal University of Rio Grande do Sul (Brazil) ♦ Aix Marseille Université</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>13288</postCode>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Idiart</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="laboratory">LIF UMR 7279</orgName>
								<orgName type="institution" key="instit1">Federal University of Rio Grande do Sul (Brazil) ♥ Institute of Physics</orgName>
								<orgName type="institution" key="instit2">Federal University of Rio Grande do Sul (Brazil) ♦ Aix Marseille Université</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>13288</postCode>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Ramisch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="laboratory">LIF UMR 7279</orgName>
								<orgName type="institution" key="instit1">Federal University of Rio Grande do Sul (Brazil) ♥ Institute of Physics</orgName>
								<orgName type="institution" key="instit2">Federal University of Rio Grande do Sul (Brazil) ♦ Aix Marseille Université</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>13288</postCode>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Villavicencio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Informatics</orgName>
								<orgName type="laboratory">LIF UMR 7279</orgName>
								<orgName type="institution" key="instit1">Federal University of Rio Grande do Sul (Brazil) ♥ Institute of Physics</orgName>
								<orgName type="institution" key="instit2">Federal University of Rio Grande do Sul (Brazil) ♦ Aix Marseille Université</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>13288</postCode>
									<settlement>Marseille</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Nothing like Good Old Frequency: Studying Context Filters for Distributional Thesauri</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="419" to="424"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Much attention has been given to the impact of informativeness and similarity measures on distributional thesauri. We investigate the effects of context filters on thesaurus quality and propose the use of cooccurrence frequency as a simple and inexpensive criterion. For evaluation , we measure thesaurus agreement with WordNet and performance in answering TOEFL-like questions. Results illustrate the sensitivity of distributional the-sauri to filters.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large-scale distributional thesauri created auto- matically from corpora <ref type="bibr" target="#b13">(Grefenstette, 1994;</ref><ref type="bibr" target="#b15">Lin, 1998;</ref><ref type="bibr" target="#b21">Weeds et al., 2004;</ref><ref type="bibr" target="#b10">Ferret, 2012)</ref> are an inexpensive and fast alternative for representing semantic relatedness between words, when man- ually constructed resources like WordNet <ref type="bibr">(Fellbaum, 1998</ref>) are unavailable or lack coverage. To construct a distributional thesaurus, the (colloca- tional or syntactic) contexts in which a target word occurs are used as the basis for calculating its sim- ilarity with other words. That is, two words are similar if they share a large proportion of contexts.</p><p>Much attention has been devoted to refin- ing thesaurus quality, improving informativeness and similarity measures <ref type="bibr" target="#b15">(Lin, 1998;</ref><ref type="bibr" target="#b5">Curran and Moens, 2002;</ref><ref type="bibr" target="#b9">Ferret, 2010</ref>), identifying and de- moting bad neighbors <ref type="bibr" target="#b11">(Ferret, 2013)</ref>, or using more relevant contexts ( <ref type="bibr" target="#b3">Broda et al., 2009;</ref><ref type="bibr" target="#b1">Biemann and Riedl, 2013)</ref>. For the latter in particular, as words vary in their collocational tendencies, it is difficult to determine how informative a given context is. To remove uninformative and noisy contexts, filters have often been applied like point- wise mutual information (PMI), lexicographer's mutual information (LMI) ( <ref type="bibr" target="#b1">Biemann and Riedl, 2013)</ref>, t-score ( <ref type="bibr" target="#b18">Piasecki et al., 2007</ref>) and z-score ( <ref type="bibr" target="#b3">Broda et al., 2009</ref>). However, the selection of a measure and of a threshold value for these filters is generally empirically determined. We argue that these filtering parameters have a great influence on the quality of the generated thesauri.</p><p>The goal of this paper is to quantify the im- pact of context filters on distributional thesauri. We experiment with different filter methods and measures to assess context significance. We pro- pose the use of simple cooccurrence frequency as a filter and show that it leads to better results than more expensive measures such as LMI or PMI. Thus we propose a cheap and effective way of fil- tering contexts while maintaining quality. This paper is organized as follows: in §2 we discuss evaluation of distributional thesauri. The methodology adopted in the work and the results are discussed in §3 and §4. We finish with some conclusions and discussion of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In a nutshell, the standard approach to build a dis- tributional thesaurus consists of: (i) the extraction of contexts for the target words from corpora, (ii) the application of an informativeness measure to represent these contexts and (iii) the application of a similarity measure to compare sets of contexts. The contexts in which a target word appears can be extracted in terms of a window of cooccurring (content) words surrounding the target ( <ref type="bibr" target="#b12">Freitag et al., 2005;</ref><ref type="bibr" target="#b10">Ferret, 2012;</ref><ref type="bibr" target="#b6">Erk and Pado, 2010)</ref> or in terms of the syntactic dependencies in which the target appears <ref type="bibr" target="#b15">(Lin, 1998;</ref><ref type="bibr" target="#b17">McCarthy et al., 2003;</ref><ref type="bibr" target="#b21">Weeds et al., 2004</ref>). The informativeness of each context is calculated using measures like PMI, and t-test while the similarity between contexts is cal- culated using measures like <ref type="bibr" target="#b15">Lin's (1998)</ref>, cosine, Jensen-Shannon divergence, Dice or Jaccard.</p><p>Evaluation of the quality of distributional the- sauri is a well know problem in the area <ref type="bibr" target="#b15">(Lin, 1998;</ref><ref type="bibr" target="#b5">Curran and Moens, 2002</ref>). For instance, for intrinsic evaluation, the agreement between the- sauri has been examined, looking at the average similarity of a word in the thesauri <ref type="bibr" target="#b15">(Lin, 1998)</ref>, and at the overlap and rank agreement between the thesauri for target words like nouns ( <ref type="bibr" target="#b21">Weeds et al., 2004</ref>). Although much attention has been given to the evaluation of various informativeness and sim- ilarity measures, a careful assessment of the ef- fects of filtering on the resulting thesauri is also needed. For instance, <ref type="bibr" target="#b1">Biemann and Riedl (2013)</ref> found that filtering a subset of contexts based on LMI increased the similarity of a thesaurus with WordNet. In this work, we compare the impact of using different types of filters in terms of thesaurus agreement with WordNet, focusing on a distribu- tional thesaurus of English verbs. We also propose a frequency-based saliency measure to rank and filter contexts and compare it with PMI and LMI.</p><p>Extrinsic evaluation of distributional thesauri has been carried out for tasks such as En- glish lexical substitution <ref type="bibr" target="#b16">(McCarthy and Navigli, 2009)</ref>, phrasal verb compositionality detection ( <ref type="bibr" target="#b17">McCarthy et al., 2003</ref>) and the WordNet-based synonymy test (WBST) ( <ref type="bibr" target="#b12">Freitag et al., 2005</ref>). For comparative purposes in this work we adopt the latter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>We focus on thesauri of English verbs constructed from the BNC (Burnard, 2007) <ref type="bibr">1</ref> . Contexts are ex- tracted from syntactic dependencies generated by RASP ( <ref type="bibr" target="#b2">Briscoe et al., 2006</ref>), using nouns (heads of NPs) which have subject and direct object rela- tions with the target verb. Thus, each target verb is represented by a set of triples containing (i) the verb itself, (ii) a context noun and (iii) a syntac- tic relation (object, subject). The thesauri were constructed using Lin's (1998) method. Lin's ver- sion of the distributional hypothesis states that two words (verbs v 1 and v 2 in our case) are similar if they share a large proportion of contexts weighted by their information content, assessed with PMI ( <ref type="bibr" target="#b0">Bansal et al., 2012;</ref><ref type="bibr" target="#b19">Turney, 2013)</ref>.</p><p>In the literature, little attention is paid to context filters. To investigate their impact, we compare two kinds of filters, and before calculating similar- ity using Lin's measure, we apply them to remove potentially noisy triples:</p><p>• Threshold (th): we remove triples that oc- cur less than a threshold th. Threshold values vary from 1 to 50 counts per triple.</p><p>• Relevance (p): we keep only the top p most relevant contexts for each verb, were rele- vance is defined according to the following measures: (a) frequency, (b) PMI, and (c) LMI ( <ref type="bibr" target="#b1">Biemann and Riedl, 2013)</ref>. Values of p vary between 10 and 1000.</p><p>In this work, we want to answer two ques- tions: (a) Do more selective filters improve intrin- sic evaluation of thesaurus? and (b) Do they also help in extrinsic evaluation?</p><p>For intrinsic evaluation, we determine agree- ment between a distributional thesaurus and Word- Net as the path similarities for the first k distri- butional neighbors of a verb. A single score is obtained by averaging the similarities of all verbs with their k first neighbors. The higher this score is, the closer the neighbors are to the target in WordNet, and the better the thesaurus. Several values of k were tested and the results showed ex- actly the same curve shapes for all values, with WordNet similarity decreasing linearly with k. For the remainder of the paper we adopt k = 10, as it is widely used in the literature.</p><p>For extrinsic evaluation, we use the WBST set for verbs <ref type="bibr" target="#b12">(Freitag et al., 2005</ref>) with 7,398 ques- tions and an average polysemy of 10.4. The task consists of choosing the most suitable synonym for a word among a set of four options. The the- saurus is used to rank the candidate answers by similarity scores, and select the first one as the correct synonym. As discussed by <ref type="bibr" target="#b12">Freitag et al. (2005)</ref>, the upper bound reached by English na- tive speakers is 88.4% accuracy, and simple lower bounds are 25% (random choice) and 34.5% (al- ways choosing the most frequent option). <ref type="figure" target="#fig_0">Figure 1</ref> shows average WordNet similarities for thesauri built filtering by frequency threshold th and by p most frequent contexts.   When using a threshold filter <ref type="figure" target="#fig_0">(Figure 1 left)</ref>, high values lead to better performance for mid- and low-frequency verbs. This is because, for high th values, there are few low and mid-frequency verbs left, since a verb that occurs less has less chances to be seen often in the same context. The similarity for verbs with no contexts over the fre- quency threshold cannot be assessed and as a con- sequence those verbs are not included in the fi- nal thesaurus. As <ref type="figure" target="#fig_2">Figure 2</ref> shows, the number of verbs decreases much faster for low and mid frequency verbs when th increases. 3 For exam- ple, for th = 50, there are only 7 remaining low- frequency verbs in the thesaurus and these tend to be idiosyncratic multiword expressions. One example is wreak, and the only triple contain- ing this verb that appeared more than 50 times is wreak havoc (71 occurrences). The neighbors of this verb are cause and play, which yield a good similarity score in WordNet. Therefore, although higher thresholds result in higher similarities for low and mid-frequency verbs, this comes at a cost, as the number of verbs included in the thesaurus decreases considerably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>(||v|| ≥ 500), mid-frequency (150 ≤ ||v|| &lt; 500) and low- frequency (||v|| &lt; 150).</p><p>3 For p most salient contexts, the number of verbs does not vary and is the same shown in <ref type="figure" target="#fig_2">Figure 2</ref> for th = 1 (no filter).  As expected, the best performance is obtained for high-frequency verbs and no filter, since it re- sults in more context information per verb. In- creasing th decreases similarity due to the removal of some of these contexts. In average, higher th values lead to better overall similarity among the frequency ranges (from 0.148 with th = 1 to 0.164 with th = 50). The higher the threshold, the more high-frequency verbs will prevail in the thesauri, for which the WordNet path similarities are higher.</p><p>On the other hand, when adopting a relevance  <ref type="figure">Figure 3</ref>: WBST task scores filtering by frequency threshold th (left) and p most frequent contexts (right).</p><p>filter of keeping the p most relevant contexts for each verb <ref type="figure" target="#fig_0">(Figure 1 right)</ref>, we obtain similar re- sults, but more stable thesauri. The number of verbs remains constant, since we keep a fixed number of contexts for each verb and verbs are not removed when the threshold is modified. Word- Net similarity increases as more contexts are taken into account, for all frequency ranges. There is a maximum around p = 200, though larger values do not lead to a drastic drop in quality. This sug- gests that the noise introduced by low-frequency contexts is compensated by the increase of infor- mativeness for other contexts. An ideal balance is reached by the lowest possible p that maintains high WordNet similarity, since the lower the p the faster the thesaurus construction.</p><p>In terms of saliency measure, when keeping only the p most relevant contexts, sorting them with PMI leads to much worse results than LMI or frequency, as PMI gives too much weight to infrequent combinations. This is consistent with results of <ref type="bibr" target="#b1">Biemann and Riedl (2013)</ref>. Regarding LMI versus frequency, the results using the latter are slightly better (or with no significant differ- ence, depending on the frequency range). The ad- vantage of using frequency instead of LMI is that it makes the process simpler and faster while lead- ing to equal or better performance in all frequency ranges. Therefore for the extrinsic evaluation us- ing WBST task, we use frequency to select the p most relevant contexts and then compute Lin's similarity using only those contexts. <ref type="figure">Figure 3</ref> shows the performance of the thesauri in the WBST task in terms of precision, recall and F1. <ref type="bibr">4</ref> For precision, the best filter is to remove con- 4 Filters based on LMI and PMI were also tested with the texts occurring less than th times, but, this also leads to poor recall, since many verbs are left out of the thesauri and their WSBT questions cannot be answered. On the other hand, keeping the most relevant p contexts leads to more stable results and when p is high (right plot), they are similar to those shown in the left plot of <ref type="figure">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Discussion</head><p>The answer to our questions in Section 3 is yes, more selective filters improve intrinsic and extrin- sic thesaurus quality. The use of both filtering methods results in thesauri in which the neighbors of target verbs are closer in WordNet and get better scores in TOEFL-like tests. However, the fact that filtering contexts with frequency under th removes verbs in the final thesaurus is a drawback, as high- lighted in the extrinsic evaluation on the WBST task.</p><p>Furthermore, we demonstrated that competitive results can be obtained keeping only the p most relevant contexts per verb. On the one hand, this method leads to much more stable thesauri, with the same verbs for all values of p. On the other hand, it is important to highlight that the best re- sults to assess the relevance of the contexts are ob- tained using frequency while more sophisticated filters such as LMI do not improve thesaurus qual- ity. Although an LMI filter is relatively fast com- pared to dimensionality reduction techniques such as singular value decomposition <ref type="bibr" target="#b14">(Landauer and Dumais, 1997)</ref>, it is still considerably more expen- sive than a simple frequency filter.</p><p>In short, our experiments indicate that a reason- same results as intrinsic evaluation: sorting contexts by fre- quency leads to better results. able trade-off between noise, coverage and com- putational efficiency is obtained for p = 200 most frequent contexts, as confirmed by intrinsic and extrinsic evaluation. Frequency threshold th is not recommended: it degrades recall because the contexts for many verbs are not frequent enough. This result is useful for extracting distributional thesauri from very large corpora like the UKWaC ( <ref type="bibr" target="#b8">Ferraresi et al., 2008)</ref> by proposing an alterna- tive that minimizes the required computational re- sources while efficiently removing a significant amount of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper we addressed the impact of filters on the quality of distributional thesauri, evaluat- ing a set of standard thesauri and different filtering methods. The results suggest that the use of fil- ters and their parameters greatly affect the thesauri generated. We show that it is better to use a filter that selects the most relevant contexts for a verb than to simply remove rare contexts. Furthermore, the best performance was obtained with the sim- plest method: frequency was found to be a simple and inexpensive measure of context salience. This is especially important when dealing with large amounts of data, since computing LMI for all con- texts would be computationally costly. With our proposal to keep just the p most frequent contexts per verb, a great deal of contexts are cheaply re- moved and thus the computational power required for assessing similarity is drastically reduced. As future work, we plan to use these filters to build thesauri from larger corpora. We would like to generalize our findings to other syntactic con- figurations (e.g. noun-adjective) as well as to other similarity and informativeness measures. For in- stance, ongoing experiments indicate that the same parameters apply when Lin's similarity is replaced by cosine. Finally, we would like to compare the proposed heuristics with more sophisticated filter- ing strategies like singular value decomposition <ref type="bibr" target="#b14">(Landauer and Dumais, 1997</ref>) and non-negative matrix factorization (Van de Cruys, 2009).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: WordNet scores for verb frequency ranges, filtering by frequency threshold th (left) and p most frequent contexts (right). Filter All verbs Frequency range Low Mid High No filter0.1480.1010.1440.198 Filter low freq. contexts th = 50 0.164 th = 50 0.202 th = 50 0.154 th = 1 0.200 Keep p contexts (freq.) p = 200 0.158 p = 500 0.138 p = 200 0.149 p = 200 0.206 Keep p contexts (PMI) p = 1000 0.139 p = 1000 0.101 p = 1000 0.136 p = 1000 0.181 Keep p contexts (LMI) p = 200 0.155 p = 100 0.112 p = 200 0.147 p = 200 0.208</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Number</head><label></label><figDesc>of verbs th Number of verbs in WordNet Filtering triples with frequency under th all verbs high frequent verbs mid frequent verbs low frequent verbs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Number of verbs per frequency ranges when filtering by context frequency threshold th</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 sumWordNet path Similarity for different frequency ranges, k=10 Filtering triples with frequency under th allWordNet path Similarity for different frequency ranges, k=10 Keeping p most frequent triples per verb</head><label>1</label><figDesc>- marizes the parametrization leading to the best WordNet similarity for each kind of filter. In all cases we show the results obtained for different frequency ranges 2 as well as the results when av- eraging over all verbs.</figDesc><table>0 

0.05 

0.1 

0.15 

0.2 

0.25 

1 
10 

WN similarity 

th 

verbs 
high frequent verbs 
mid frequent verbs 
low frequent verbs 

0 

0.05 

0.1 

0.15 

0.2 

0.25 

10 
100 
1000 

WN similarity 

p 

all verbs 
high frequent verbs 
mid frequent verbs 
low frequent verbs 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Best scores obtained for each filter for all verbs and frequency ranges. Scores are given in terms of WordNet path. Confidence interval is arround ± 0.002 in all cases.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>th WBST task: P, R and F1 Filtering triples with frequency under th PrecisionWBST task: P, R and F1 Keeping p most frequent triples per verb</head><label></label><figDesc></figDesc><table>0 

0.2 

0.4 

0.6 

0.8 

1 

1 
10 

P, R, F1 

Recall 
F1 
0 

0.2 

0.4 

0.6 

0.8 

1 

10 
100 
1000 

P, R, F1 

p 

Precision 
Recall 
F1 

</table></figure>

			<note place="foot" n="1"> Even though larger corpora are available, we use a traditional carefully constructed corpus with representative samples of written English to control the quality of the thesaurus.</note>

			<note place="foot" n="2"> In order to study the influence of verb frequency on the results, we divide the verbs in three groups: high-frequency</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised translation sense clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="773" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Text: Now in 2D! a framework for lexical expansion with contextual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Modelling</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The second release of the RASP system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the COLING/ACL 2006 Interactive Presentation Sessions</title>
		<editor>James Curran</editor>
		<meeting>of the COLING/ACL 2006 Interactive Presentation Sessions<address><addrLine>Sidney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="77" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rank-based transformation in measuring semantic relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartosz</forename><surname>Broda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Piasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Canadian Conference on Artificial Intelligence: Advances in Artificial Intelligence, Canadian AI &apos;09</title>
		<meeting>the 22nd Canadian Conference on Artificial Intelligence: Advances in Artificial Intelligence, Canadian AI &apos;09<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="187" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">User Reference Guide for the British National Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lou</forename><surname>Burnard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-02" />
		</imprint>
		<respStmt>
			<orgName>Oxford University Computing Services</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improvements in automatic thesaurus extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">R</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc.of the ACL 2002 Workshop on Unsupervised Lexical Acquisition</title>
		<meeting>.of the ACL 2002 Workshop on Unsupervised Lexical Acquisition<address><addrLine>Philadelphia, Pennsylvania, USA. ACL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exemplar-based models for word meaning in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Pado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL 2010 Conference Short Papers</title>
		<meeting>of the ACL 2010 Conference Short Papers<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database (Language, Speech, and Communication)</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998-05" />
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">423</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Introducing and evaluating UKWaC, a very large web-derived corpus of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Web as Corpus Workshop</title>
		<meeting>the 4th Web as Corpus Workshop</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>WAC-4</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Testing semantic similarity measures for extracting synonyms from a corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Seventh LREC (LREC 2010)</title>
		<meeting>of the Seventh LREC (LREC 2010)<address><addrLine>Valetta, Malta, May. ELRA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3338" to="3343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Combining bootstrapping and feature selection for improving a distributional thesaurus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECAI</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identifying bad semantic neighbors for improving distributional thesauri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 51st ACL</title>
		<meeting>of the 51st ACL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="561" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">New experiments in distributional representations of synonymy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayne</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Byrnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edmond</forename><surname>Chow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadik</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Rohwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Ninth CoNLL (CoNLL-2005)</title>
		<editor>Ido Dagan and Dan Gildea</editor>
		<meeting>of the Ninth CoNLL (CoNLL-2005)<address><addrLine>MI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
		<title level="m">Explorations in Automatic Thesaurus Discovery</title>
		<meeting><address><addrLine>Norwell, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A solution to platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="page" from="211" to="240" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic retrieval and clustering of similar words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 36th ACL and 17th COLING</title>
		<meeting>of the 36th ACL and 17th COLING<address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="768" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The english lexical substitution task. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="139" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting a continuum of compositionality in phrasal verbs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL Workshop on MWEs: Analysis, Acquisition and Treatment (MWE 2003)</title>
		<editor>Francis Bond, Anna Korhonen, Diana McCarthy, and Aline Villavicencio</editor>
		<meeting>of the ACL Workshop on MWEs: Analysis, Acquisition and Treatment (MWE 2003)<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic selection of heterogeneous syntactic features in semantic similarity of polish nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Piasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Szpakowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartosz</forename><surname>Broda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on Text, speech and dialogue, TSD&apos;07</title>
		<meeting>the 10th international conference on Text, speech and dialogue, TSD&apos;07<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="99" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Distributional semantics beyond words: Supervised learning of analogy and paraphrase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="353" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A non-negative tensor factorization model for selectional preference induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Geometrical Models of Natural Language Semantics</title>
		<meeting>the Workshop on Geometrical Models of Natural Language Semantics<address><addrLine>Athens, Greece, March</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Characterising measures of lexical distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 20th COLING</title>
		<meeting>of the 20th COLING<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08" />
			<biblScope unit="page" from="1015" to="1021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
