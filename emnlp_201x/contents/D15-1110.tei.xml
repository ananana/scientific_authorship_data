<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:03+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint prediction in MST-style discourse parsing for argumentation mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
							<email>peldszus@uni-potsdam.de</email>
							<affiliation key="aff0">
								<orgName type="department">Applied Computational Linguistics</orgName>
								<orgName type="institution" key="instit1">UFS Cognitive Science University of Potsdam</orgName>
								<orgName type="institution" key="instit2">UFS Cognitive Science University of Potsdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
							<email>stede@uni-potsdam.de</email>
							<affiliation key="aff0">
								<orgName type="department">Applied Computational Linguistics</orgName>
								<orgName type="institution" key="instit1">UFS Cognitive Science University of Potsdam</orgName>
								<orgName type="institution" key="instit2">UFS Cognitive Science University of Potsdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Joint prediction in MST-style discourse parsing for argumentation mining</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We introduce a new approach to argumen-tation mining that we applied to a parallel German/English corpus of short texts annotated with argumentation structure. We focus on structure prediction, which we break into a number of subtasks: relation identification, central claim identification, role classification, and function classification. Our new model jointly predicts different aspects of the structure by combining the different subtask predictions in the edge weights of an evidence graph; we then apply a standard MST decoding algorithm. This model not only outperforms two reasonable baselines and two data-driven models of global argument structure for the difficult subtask of relation identification, but also improves the results for central claim identification and function classification and it compares favorably to a complex mstparser pipeline.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Argumentation mining is a task that has drawn increased interest in the last years. In its full- fledged version, it seeks to automatically recog- nize the structure of argumentation in a text by identifying and connecting the central claim of the text, supporting premises, possible objections, and counter-objections to these objections. <ref type="bibr">1</ref> A variety of applications can profit from ac- cess to the argumentative structure of text, includ- ing the retrieval of relevant court decisions from legal databases ( <ref type="bibr" target="#b15">Palau and Moens, 2011</ref>), auto- matic document summarization systems <ref type="bibr" target="#b24">(Teufel and Moens, 2002</ref>), the analysis of scientific papers in biomedical text mining <ref type="bibr" target="#b25">(Teufel, 2010</ref>; Liakata <ref type="bibr">1</ref> A comprehensive overview of the research field is given in <ref type="bibr" target="#b18">(Peldszus and Stede, 2013).</ref> et al., 2012), or essay scoring. Importantly, argu- ment analysis can also be an extension of opinion mining applications.</p><p>To make argumentation structures available for these applications, their robust automatic recogni- tion is required, a task that is very challenging: argumentative strategies and styles vary across text genres and languages; classifying arguments might require domain knowledge; furthermore, ar- gumentation can often rely on implicitly conveyed messages.</p><p>The full-fledged task can be decomposed into several subtasks:</p><p>• Segmentation: splitting the text into elemen- tary discourse units (EDUs as used in gen- eral kinds of discourse parsing, typically sen- tences or clauses)</p><p>• Identification of argumentative discourse units (ADUs): discarding argumentatively ir- relevant EDUs, joining adjacent EDUs to form larger ADUs</p><p>• ADU type classification: determining the type of argumentative unit; different schemes have been proposed, involving stance, evi- dence types, rhetorical status, argumentative function</p><p>• Relation identification: building a connected tree-or graph-structure to represent argumen- tative relations between the ADUs</p><p>• Relation type classification: determining the type of argumentative relation (e.g. support- ing versus attacking relations or more fine- grained types)</p><p>In this paper, we address the last three subtasks: Given a text segmented into relevant ADUs, iden- tify the argumentation structure. We will work with a bilingual corpus of short texts that have been generated in a text production experiment.</p><p>The next section describes related work. In sec- tion 3, we present the dataset used in our experi- ments. Section 4 gives a more detailed description of the task. The baselines and the models are pre- sented in section 5. We then report the result of our experiments in section 6 and close with some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In our discussion of related work, we focus on the three subtasks addressed in this paper:</p><p>ADU type classification: One typical clas- sification task concerns the properties of a seg- ment in the argumentation structure: Burstein and Marcu (2003) trained classifiers for identifying thesis and conclusion statements in student es- says, using additional automatic discourse parse features and cue words, resulting in an average F- score of 53% for thesis and 80% for conclusion segments. For legal texts, Palau and Moens (2011) demonstrated in their influential work how to clas- sify the segment of a text into premises and con- clusions, obtaining an F-score of 68% and 74% for the two classes. More recently, <ref type="bibr" target="#b21">Stab and Gurevych (2014)</ref> classified segments in student essays into the classes major claim (of the text), claim (of the paragraph), premise and irrelevant. The macro av- erage F-score for all classes is 73%, the F-score for the claim of the paragraph 54% and for the major claim 63%.</p><p>Besides structural segment-wise classification tasks, there is also work on more semantic tasks: The rhetorical status of a segment is classified in the argumentative zoning approaches ( <ref type="bibr" target="#b24">Teufel and Moens, 2002;</ref><ref type="bibr" target="#b23">Teufel and Kan, 2011;</ref><ref type="bibr" target="#b10">Liakata et al., 2012)</ref>, where certain coarse-grained patterns of ar- gumentation in scholarly papers can be captured. <ref type="bibr" target="#b16">Park and Cardie (2014)</ref> focus on supporting seg- ments and classify which type of evidence is pre- sented in it. Finally, stance classification (Hasan and Ng, 2013) might be of interest to identify pos- sible objections, although it is typically applied on full comments and not on single segments.</p><p>Relation identification: Much less prior work can be found for the process of building argumen- tation structures. Palau and Moens (2011) used a hand-written context-free grammar to predict ar- gumentation trees on legal documents, achieving an accuracy of 60%. Only recently, data-driven approaches have been applied. <ref type="bibr" target="#b9">Lawrence et al. (2014)</ref> construct tree structures on philosophical texts using unsupervised methods based on topical distance between the segments. The relations in the tree are neither labeled not directed. Unfortu- nately, the method was evaluated on only a few an- notated items, which is why we cannot comment on the results. Finally, <ref type="bibr" target="#b21">Stab and Gurevych (2014)</ref> present a supervised data-driven approach for re- lation identification. They predict attachment for support-graphs spanning over paragraphs of En- glish essays and obtain a macro F1 score of 72%, and an F1 score of 52% for positive attachment. No decoding is used to optimize global predictions per text.</p><p>Relation type classification: The only study on explicitly classifying argumentative relations we are aware of is <ref type="bibr" target="#b5">(Feng and Hirst, 2011</ref>). They classify pairs of premise and conclusion from newswire text into a set of five frequently used argumentation schemes in the sense of <ref type="bibr" target="#b26">Walton et al. (2008)</ref>. In one-against-others classification, the system yields best average accuracies of over 90% for two schemes, while for the other three schemes the results are between 63% and 70%.</p><p>To the best of our knowledge, no data-driven model of argumentation structure has been pro- posed yet that would optimize argumentation structure globally for the complete input text, as it is done in other discourse parsing tasks, e.g. in <ref type="bibr" target="#b14">(Muller et al., 2012</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>Texts: We use the arg-microtext corpus (Peldszus and Stede, to appear), a freely available 2 parallel corpus of 112 short texts with 576 ADUs. The texts are authentic discussions of controversial is- sues. They were originally written in German and have been professionally translated to English, preserving the segmentation and if possible the us- age of discourse markers. The texts have been col- lected in a controlled text generation experiment, with the result that all of them fulfill the follow- Scheme:</p><p>The argumentation structure of every text has been annotated according to a scheme ( <ref type="bibr" target="#b18">Peldszus and Stede, 2013</ref>) based on Free- man's theory of argumentation structures (Free- <ref type="bibr">[e1]</ref> Of course there are a number of programmes in public broadcasting that are not worth the licencing fee,</p><p>[e2] and others, such as "Musikantenstadl" and soap operas, are only interesting to certain audiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1</head><p>[e3] Nevertheless, everybody should contribute to the funding of the public broadcasters in equal measure,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>[e4] for we need general and independent media.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>[e5] After all we want to get our view of the world neither through the lens of the government nor through that of rich media entrepreneurs. man, 1991; Freeman, 2011), that has been proven to yield reliable structures in annotation experi- ments <ref type="bibr" target="#b20">(Peldszus, 2014</ref>). The argumentation struc- ture of a text is defined as a graph with the text seg- ments as nodes. Each node is associated with one argumentative role: the proponent who presents and defends the central claim, or the opponent who critically questions the proponent's claims. Edges between the nodes represent argumentative rela- tions, and each edge is of one specific argumen- tative function: support or attack. The scheme al- lows to discriminate between "rebutting" attacks, targeting another node and thereby challenging its acceptability, and "undercutting" attacks, target- ing an edge and thereby challenging the accept- ability of the inference from the source to the tar- get node. It can also represent linked support, where multiple premises jointly support a claim.</p><p>Transformation: The annotated graph struc- tures can be quite complex, especially when they involve undercutting relations and linked support. For the purpose of this study, we thus reduce the graphs to a simpler tree-like representation. All re- lations pointing to edges are rewritten to point to the source node of the original target edge, which enables the use of standard graph algorithms (like MST). Also, this is a loss-less mapping, given that every segment has only one outgoing arc (as gen- erally done in argumentation models). Further- more, the set of relation types is reduced to the simple binary distinction between support and at- tack. We think this is a reasonable simplification that facilitates comparisons with slightly differ- ent approaches/datasets (we are not aware of any dataset that makes use of the full granularity pro- posed in our scheme).</p><p>An example text from the corpus in its reduced form is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. Text boxes are EDUs, each of which constitutes also an ADU. Proponent ADUs are round nodes, opponent ADUs are box nodes. Supporting relations have a normal arrow- head, while attacking relations have a circle arrow- head.</p><p>All statistics on the annotated argumentation structures apply equally for the German and the English version of the parallel corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task</head><p>Identifying the structure of argumentation accord- ing to our scheme involves choosing one segment as the central claim of the text, deciding how the other segments are related to the central claim and to each other, identifying the argumentative role of each segment, and finally the argumentative func- tion of each relation.</p><p>Our prior experiments on automating the recog- nition of argumentation structure approached the problem as a segment-wise classification task <ref type="bibr" target="#b20">(Peldszus, 2014)</ref>. Formulating the task this way was successful for the recognition of argumenta- tive role and function of a segment. For the au- tomation of the structure building however, the segment-wise classification of attachment with only a small context window around the target seg- ment proved to be a very hard task. This is due to the long-distance dependencies frequently found in argumentation graphs. For example, 46% of the relations marked in the corpus used for this study involve non-adjacent segments. For longer texts this number might increase further: Stab and Gurevych (2014) report a rate of 63% of non- adjacent relations in their corpus.</p><p>In this study we therefore frame the task of at- tachment classification as a binary decision, where the classifier, when given a pair of a source and a target segment, chooses whether or not to estab- lish a relation from the source to the target. Since these relations can hold not only between adjacent but between arbitrary segments of the text, all pos- sible combinations of segments are required to be tested. Consequently, the class distribution is very skewed.</p><p>• attachment (at): Is there an argumentative connection between the source and the target segment? In the corpus, a relation has been annotated for 464 segment pairs, no relation has been annotated for the combinatorially remaining 2000 pairs of segments.</p><p>In this paper we first address only the task of at- tachment classification, and then the prediction of the full graph, involving all other levels:</p><p>• central claim (cc): Is the current segment the central claim of the text? In our data 112 of the 576 segments are central claims.</p><p>• role (ro): Does the current segment present a claim of the proponent or the opponent? In our data 451 of the 576 segments are pro- ponent segments and 125 are opponent seg- ments.</p><p>• function (fu): Has the current segment a sup- porting or an attacking function? In our data, 290 segments are supports, 174 are attacks and 112 are the central claim and thus have no own function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Models</head><p>We compare two heuristic baseline models and different data-driven models that we developed, each of them trained and evaluated separately on both language versions of the corpus. All models are evaluated on the basis of 10 iterations of 5x3- fold nested cross validation (CV). The outer 5-fold CV is for evaluation only, i.e. to ensure that the model is trained only on training data and tested only on test data. If a model requires hyperpa- rameters to be tuned or multiple passes, then this is achieved via one (or multiple) inner 3-fold CV over the training data only. The folding is strati- fied, randomly distributing the texts of the corpus while aiming to reproduce the overall label distri- bution in both training and test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Baseline: attach to first</head><p>In the English-speaking school of essay writing and debating, there is the tendency to state the cen- tral claim of a text or a paragraph in the very first sentence, followed by supporting arguments. It is therefore a reasonable baseline to assume that all segments attach to the first segment. In our cor- pus, the first segment is the central claim in 50 of the 112 texts (44.6%).</p><p>This baseline (BL-first) will not be able to cap- ture serial argumentation, where one more general argument is supported or attacked by a more spe- cific one. However, it will cover convergent argu- mentation, where separate arguments are put for- ward in favor of the central claim (given that it is expressed in the first segment). It will always pro- duce flat trees. In our corpus, 176 of the 464 rela- tions (37.9%) attach to the first segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline: attach to preceding</head><p>A typically very strong baseline in discourse pars- ing is attaching to the immediately preceding seg- ment ( <ref type="bibr" target="#b14">Muller et al., 2012</ref>). Possibly, this holds more for corpora with relations often or always being adjacent, as in rhetorical structure trees. Since argumentation structures often exhibit non- adjacent relations (see above), this heuristic might be easier to beat in our scenario.</p><p>This baseline (BL-preced.) will always pro- duce chain trees and thus cover serial argumen- tation, but not convergent argumentation. In our corpus, 210 of all 464 relations (45.3%) attach to the preceding segment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Learned attachment without decoding</head><p>We train a linear log-loss model (simple) us- ing stochastic gradient descent (SGD) learning, with elastic net regularization, the learning rate set to optimal decrease and class weight adjusted according to class distribution ( <ref type="bibr" target="#b17">Pedregosa et al., 2011</ref>). The following hyper parameters are tuned in the inner CV: the regularization parameter al- pha, the elastic net mixing parameter and the num- ber of iterations. We optimize macro averaged F1- score.</p><p>For each text segment, we extract binary fea- tures for lemma, pos-tags, lemma-and pos-tag- based dependency-parse triples and the main verb morphology <ref type="bibr" target="#b1">(Bohnet, 2010)</ref>, and discourse con- nectives <ref type="bibr" target="#b22">(Stede, 2002</ref>), furthermore simple statis- tics like relative segment position, segment length and punctuation count. For each pair of text seg- ments, we extract relative distance between the segments and their linear order (is the source be- fore or after the target). The feature vector for each pair then contains both the pair features and the segment features for source and target segment and their adjacent segments. <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Learned attachment with MST decoding</head><p>The simple model just described might be able to learn which segment pairs actually attach, i.e., correspond to some argumentative relation in the corpus. However it is not guaranteed to yield predictions that can be combined to a tree struc- <ref type="bibr" target="#b3">, 1965;</ref><ref type="bibr" target="#b4">Edmonds, 1967)</ref> to determine the minimum spanning tree, i.e., the subgraph connecting all nodes with minimal total edge cost (in our case highest total edge probabil- ity). This resulting tree then represents the best global attachment structure for a text given the predicted probabilities.</p><note type="other">ture again. A more appropriate model would en- force global constraints on its predictions. In the simple+MST model, this is achieved by a mini- mum spanning tree (MST) decoding, which has first been applied for syntactic dependency parsing (McDonald et al., 2005a; McDonald et al., 2005b) and later for discourse parsing (Baldridge et al., 2007; Muller et al., 2012). First, we build a fully- connected directed graph, with one node for each text segment. The weight of each edge is the at- tachment probability predicted by the learned clas- sifier for the corresponding pair of source and tar- get segment. We then apply the Chu-Liu-Edmonds algorithm (Chu and Liu</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Joint prediction with MST decoding</head><p>All models presented in the previous subsections have in common that they do not rely on other fea- tures of the argumentation graph. However, it is fair to assume that knowledge about the argumen- tative role and function of a segment or its like- liness to be the central claim might improve the attachment classification. Consequently, our next model considers not only the predicted probability of attachment for a segment pair, but also the pre- dicted probabilities of argumentative role, func- tion and of being the central claim for each seg- ment. The predictions of all levels are combined in one evidence graph.</p><p>Additional segment-wise base classifiers: We train base classifiers for the role, function and cen- tral claim level using the same learning regime as described in Section 5.3. Contrary to the attach- ment classification, the items are not segment pairs but single segments. We thus extract all segment- based features as described above for the target segment and its adjacent segments. segments, and distance measures between pairs of segments in terms of word-overlap, td-idf and LDA distributions.</p><p>Combining segment and segment-pair pre- dictions: Our goal in this model is to combine the predicted probabilities of all levels in one edge score, so that the MST decoding can be applied as before. <ref type="figure">Figure 2</ref> depicts the situation before and after the combination, first with separate predic- tion for segments and segment pairs and then with the combined edge scores.</p><p>The evidence graph is constructed as follows: First, we build a fully connected multigraph over all segments with as many edges per segment-pair as there are edge types. In our scenario there are two edge types, supporting and attacking edges. Then we translate the segment-wise predictions into level-specific edge scores.</p><p>The edge-score for the central claim level cc i,j is equal to the probability of the edge's source not being the central claim, which is capturing the in- tuition that central claims are unlikely to have out- going edges:</p><formula xml:id="formula_0">cci,j = p(cci = no)<label>(1)</label></formula><p>The edge-score for the argumentative function level fu i,j is equal to the probability of the source being the corresponding segment for the edge type:</p><p>fui,j = p(fui = sup) for sup. edges p(fui = att) for att. edges</p><p>The edge-score for the argumentative role level ro i,j is also determined by the edge type. Attack- ing edges involve a role switch (proponent or op- ponent would not attack their own claims), while supporting edges preserve the role (proponent or opponent will only support their own claims):</p><formula xml:id="formula_2">roi,j =        p(roi = pro) × p(roj = pro)+ p(roi = opp) × p(roj = opp) for sup. edges p(roi = pro) × p(roj = opp)+ p(roi = opp) × p(roj = pro) for att. edges<label>(3)</label></formula><p>Finally, of course the edge-score for the attach- ment level at i,j is equal to the probability of at- tachment between the segment pair:</p><formula xml:id="formula_3">ati,j = p(ati,j = yes)<label>(4)</label></formula><p>The combined score of an edge w i,j is then de- fined as the weighted sum of the level-specific edge score: <ref type="figure">Figure 2</ref>: An example evidence graph before (left) and after (right) the predicted probabilities of the different levels have been combined in a single edge score.</p><formula xml:id="formula_4">wi,j = φ1roi,j + φ2fui,j + φ3cci,j + φ4ati,j φn<label>(5)</label></formula><p>In our implementation, the combined evidence graphs can be constructed without a weighting, and then be instantiated with a specific weighting to yield the combined edge scores w i,j .</p><p>Procedure: As before, we first tune the hyper- parameters in the inner CV, train the model on the whole training data and predict probabilities on all items of the test set. Also, we predict all items in the training data "as unseen" in a second inner CV using the best hyperparameters. This procedure is executed for every level. Using the predictions of all four levels, we then build the evidence graphs for training and test set.</p><p>Finding the right weighting: We evaluate two versions of the evidence graph model. The first version (EG equal) gives equal weight to each level-specific edge score. The second version (EG best) optimizes the weighting of the base classi- fiers with a simple evolutionary search on all evi- dence graphs of the training set, i.e. it searches for a weighting that maximizes the average level eval- uation score of the decoded argumentation struc- tures in the training set. Finally, all evidence graphs of the test set are instantiated with the se- lected weighting (the equal one or the optimized one) and evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Comparison: MST parser</head><p>Finally, we compare our models to the well-known mstparser <ref type="bibr">4</ref> , which was also used in the discourse parsing experiments of <ref type="bibr" target="#b0">Baldridge et al. (2007)</ref>. The mstparser applies 1-best MIRA structured learning, a learning regime that we expect to be superior over the simple training in the previous models. In all experiments in this paper, we use 10 iterations for training, the non-projective 1-best MST decoding, and no second order features. The <ref type="bibr">4</ref> http://sourceforge.net/projects/mstparser/ base mstparser model (MP) evaluated here uses the same features as above, as well as its own features extracted from the dependency structure. Second, we evaluate a pre-classification scenario (MP+p), where the predictions of the base classi- fiers trained in the above models for central claim, role and function are added as additional features. We expect this to improve the central claim iden- tification as well as the edge labeling.</p><p>For the full task involving all levels, we com- bine the mstparser with an external edge labeler, as the internal edge labeler is reported to be weak. In this setting (MP+r), we replace the edge la- bels predicted by the mstparser with the pre- dictions of the base classifier for argumentative function. Furthermore, the combination of pre- classification, mstparser and external relation la- beler (MP+p+r) is evaluated. Finally, we evaluate a scenario (MP+p+r) where the mstparser has ac- cess only to its own features and to those of the pre-classification, but not to the features described in Section 5.3, and the external relation labeller is used. In this scenario, the mstparser exclusively serves as a meta-model on the base classifier's pre- dictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>All results are reported as average and standard deviation over the 50 folds resulting from 10 iter- ations of (the outer) 5-fold cross validation. We use the following metrics: macro averaged F1, F1 for positive attachment, and Cohen's Kappa κ. For significance testing, we apply the Wilcoxon signed-rank test on the macro averaged F1 scores and assume a significance level of α=0.01.  <ref type="table">Table 2</ref>: Number and percentage of valid trees for the "simple" attachment model languages, since they rely only on the annotated structure of the parallel corpus. Here, attach-to- first is the lower bound, attach-to-preceding is a more competitive baseline, as we had hypothe- sized in section 5.2. The learned classifier (simple) beats both base- lines in both languages, although the improvement is much smaller for English than for German. In general, the classifier lacks precision compared to recall: It predicts too many edges. As a result, the graph constructed from the predicted edges for one text very often does not form a tree. In <ref type="table">Table 2</ref>, we give a summary of how often tree constraints are fulfilled, showing that without decoding, valid trees can only be predicted for 15.4% of the texts in German and for 10.7% of the texts in English. The most frequently violated constraint is "out de- gree", stating that every node in the graph should have at most one outgoing edge. Note that all other models, the baselines as well as the MST decoding models, are guaranteed to predict tree structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Attachment task</head><p>The simple+MST model yields slightly lower F1-scores for positive attachment than without de- coding, trading off a loss of 10 points in recall of the over-optimistic base classifier against a gain of 5 in precision. However, the output graphs are constrained to be trees now, which is rewarded by a slight increase in the summarizing metrics macro F1 and κ.</p><p>The evidence graph models (EG equal &amp; EG best) clearly outperform the simple and sim- ple+MST model, indicating that the attachment classification can benefit from jointly predicting the four different levels. Note, that the EG model with equal weighting scores slightly better than the one with optimized weighting for German but not for English. However, this difference is not signif- icant (p&gt;0.5) for both languages, which indicates that the search for an optimal weighting is not nec- essary for the attachment task.</p><p>The overall best result is achieved by the mst- parser model. We attribute this to the superior structured learning regime. The improvement of MP over EP equal and best is significant in both languages (p&lt;0.008). Using pre-classification fur- ther improves the results, although difference is neither significant for German (p=0.4) nor for En- glish (p=0.016).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Full task</head><p>Until now, we only focused on the attachment task. In this subsection we will present results on the impact of joint prediction for all levels.</p><p>The results in <ref type="table">Table 3</ref> show significant improve- ments of the EG models over the base-classifiers on the central claim, the function and the attach- ment levels (p&lt;0.0001). This demonstrates the positive impact of jointly predicting all levels. The EG models achieve the best scores in central claim identification and function classification, and the second best result in role identification. The dif- ferences between EG equal and EG best are not significant on any level, which again indicates that  <ref type="table">Table 3</ref>: Results for the full task: for German (above) and English (below), best values highlighted.</p><note type="other">simple EG equal EG best MP MP+p MP+r MP+p+r</note><p>we can dispense with the extra step of optimizing the weighting and use the simple equal weighting. These result are consistent across both languages.</p><p>The pure labeled mstparser model (MP) per- forms worse than the base classifiers on all lev- els except for the attachment task. Adding pre- classification yields significant improvements on all levels but role identification. Using the ex- ternal relation labeler drastically improves func- tion classification and indirectly also role identifi- cation. The combined model (MP+p+r) yields best results for all mstparser models, but is still sig- nificantly outperformed by EG equal in all tasks except attachment classification. There, the mst- parser models achieve best results, the improve- ment of MP+p+r over EG equal is significant for English (p&lt;0.0001) and for German (p=0.001). Interestingly, the meta-model (MP+p+r) which has access to its own features and to those of the pre-classification, but not to the features described in Section 5.3, performs nearly as good as or equal to the combined model (MP+p+r).</p><p>The only level not benefiting from any MST model in comparison with the base classifier is the role classification: In the final MST, the role of each segment is only implicitly represented, and can be determined by following the series of the role-switches of each argumentative function from the segment to the root. The loss of accuracy for predicting the argumentative role is much smaller for German than for English, probably due to the better attachment classification in the first place.</p><p>Finally, note that the EG best model gives the highest total score when summed over all levels, followed by EG equal and then MP+p+r.</p><p>Projecting further improvements: We have shown that joint prediction of all levels in the ev- idence graph models helps to improve the clas- sification on single levels. To measure exactly how much a level contributes to the predictions of other levels, we simulate better base classifiers and study their impact. To achieve this, we artificially improved the classification of one target level by overwriting a percentage of its predictions with ground truth. The overwritten predictions where drawn randomly, corresponding to the label dis- tribution of the target level. E.g. for a 20% im- provement on the argumentative function level, the predictions of 20% of the true "attack"-items were set to attack and the predictions of 20% of the true "support"-items were set to support, irrespective of whether the classifier already chose the correct label.</p><p>The results of the simulations are presented in <ref type="figure" target="#fig_2">Figure 3</ref> for English only, due to space constraints. The results for German exhibit the same trends. The figure plots the κ-score on the y-axis against the percentage of improvement on the x-axis. Ar- tificially improved levels are drawn as a dashed line. As the first plot shows, function classifica- tion is greatly improved by a better role classifica- tion (due to the logical connection between them), whereas the other levels are unaffected. In con- trast, all levels would benefit from a better function classification, most importantly even the attach- ment classification. Potential improvements in the central claim identification mostly affect function classification (as these classification tasks partly overlap: central claims will not be assigned a func- tion they cannot have). Finally, a combined im- provement on the logically coupled task of role and function identification, would even more help the attachment classification. It might thus be use- ful to work on a better joint role and function clas- sifier in near future.</p><p>Evidence combination: As pointed out by one reviewer, combining the evidence in an edge score as a weighted sum, see (5), instead of a product of probabilities might be inadequate and could result in a model that optimizes the highest scored but not the most probable structure. We compared the EG equal against an EG model with a product of probability. The model scores are nearly identical and do not show a significant difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Summary and Outlook</head><p>We introduced a new approach to argumenta- tion mining that we applied to a parallel Ger- man/English corpus of 112 short texts. For the purposes of automatic mining, the original more fine-grained annotation in the corpus was reduced to a slightly simplified scheme consisting of sup- port and attack relations among argumentative dis- course units. We did not address the segmenta- tion step here but focused on structure prediction, which we broke into a number of subtasks. Our new evidence graph model jointly predicts differ- ent aspects of the structure by combining the dif- ferent subtask predictions in the edge weights of an evidence graph; we then apply a standard MST decoding algorithm. This model not only out- performs two reasonable baselines and two sim- ple models for the difficult subtask of attach- ment/relation identification, but also improves the results for central claim identification and relation classification, and it compares favorably to a 3- pass mstparser pipeline.</p><p>To the best of our knowledge, this is the first data-driven model of argumentation structure that optimizes argumentation structure globally for the complete sequence of input segments. Further- more, it is the first model jointly tackling segment type classification, relation identification and rela- tion type classification.</p><p>Although a direct comparison with results from related work on other corpora is not possible, we can draw indirect comparisons. The first learned model without decoding (simple) is similar to the one presented by <ref type="bibr" target="#b21">Stab and Gurevych (2014)</ref>. Since it is outperformed by our joint MST decoding model on our data, we assume similar gains could be accomplished on their student essay dataset. Our next step is to apply the method to other corpora and to more complex text, where the iden- tification of non-participating segments (which are irrelevant for the argumentation) needs to be ac- counted for. Furthermore, we plan to investigate structured models that not only jointly predict but jointly learn the different aspects of the argumen- tation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>946</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>ing criteria: (i) The length of each text is about 5 ADUs (henceforth: segments). (ii) One segment explicitly states the central claim. (iii) Each seg- ment is argumentatively relevant. (iv) At least one objection to the central claim is considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example text and its reduced argumentation structure: Text segments, proponent (round) and opponent (box) nodes, supporting (arrow-head) and attacking (circle-head) relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Simulations of the effect of better base classifiers in the EG equal model for English: dashed levels artificially improved, x = number of predictions overwritten with ground truth; y = average κ score in 10 iterations of 5fold CV.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 shows the results in the attachment task. The rule-based baseline scores are equal for both</head><label>1</label><figDesc></figDesc><table>BL-first 

BL-preced. simple 
simple+MST EG equal 
EG best 
MP 
MP+p 

F1 macro .618±.041 .662±.025 
.679±.025 .688±.032 
.712±.026 .710±.028 .724±.030 .728±.033 
attach F1 .380±.067 .452±.039 
.504±.038 .494±.053 
.533±.042 .530±.044 .553±.048 .559±.053 
κ 
.236±.081 .325±.050 
.365±.048 .377±.064 
.424±.052 .421±.055 .449±.060 .456±.066 

trees 
100% 
100% 
15.4% 
100% 
100% 
100% 
100% 
100% 

BL-first 
BL-preced. simple 
simple+MST EG equal 
EG best 
MP 
MP+p 

F1 macro .618±.041 .662±.025 
.663±.030 .674±.036 
.692±.034 .693±.031 .707±.035 .720±.034 
attach F1 .380±.067 .452±.039 
.478±.049 .470±.058 
.501±.056 .502±.052 .524±.056 .546±.056 
κ 
.236±.081 .325±.050 
.333±.059 .347±.071 
.384±.068 .386±.063 .414±.070 .440±.069 

trees 
100% 
100% 
11.6% 
100% 
100% 
100% 
100% 
100% 

Table 1: Results for the attachment task: for German (above) and English (below), best values high-
lighted. 

German 
English 

total graphs 1120 100.0% 1120 100.0% 

rooted 
1091 
97.4% 1088 
97.1% 
cycle free 
1059 
94.6% 
995 
88.8% 
full span 
908 
81.1% 
864 
77.1% 
out degree 
298 
26.6% 
283 
25.3% 

trees 
173 
15.4% 
120 
10.7% 

</table></figure>

			<note place="foot" n="2"> https://github.com/peldszus/arg-microtexts</note>

			<note place="foot" n="3"> We experimented with several features, some of which were dismissed from the final evaluation runs due to lacking impact: sentiment values and the presence of negation for</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the anonymous reviewers for their thoughtful comments. We want to thankŽeljko thankˇthankŽeljko Agi´cAgi´c, Stergos Afantenos and Christoph Teichmann for fruitful discussions and Wladimir Sidorenko for feedback on an earlier version of the paper. The first author was supported by a grant from Cusanuswerk.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Annotation for and robust parsing of discourse structure on unrestricted texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zeitschrift für Sprachwissenschaft</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="213" to="239" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Very high accuracy and fast dependency parsing is not a contradiction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A machine learning approach for identification thesis and conclusion statements in student essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><surname>Burstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and the Humanities</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="455" to="467" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the shortest arborescence of a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Sinica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1396" to="1400" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Edmonds</surname></persName>
		</author>
		<title level="m">Optimum Branchings. Journal of Research of the National Bureau of Standards</title>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classifying arguments by scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="987" to="996" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Dialectics and the Macrostructure of Argument. Foris</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Argument Structure: Representation and Theory. Argumentation Library (18)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stance classification of ideological debates: Data, models, features, and constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazi</forename><surname>Saidul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Joint Conference on Natural Language Processing</title>
		<meeting>the Sixth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1348" to="1356" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining arguments from 19th century philosophical texts using topic based modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Mcalister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ravenscroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic recognition of conceptualization zones in scientific articles and two life science applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyamasree</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Dobnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">R</forename><surname>Batchelor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietrich</forename><surname>Rebholzschuhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="991" to="1000" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Online large-margin training of dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd</title>
		<meeting>the 43rd</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting><address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="91" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005-01" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Constrained decoding for text-level discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="page" from="1883" to="1900" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Identifying appropriate support for propositions in online user comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From argument diagrams to automatic argument mining: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Cognitive Informatics and Natural Intelligence (IJCINI)</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An annotated corpus of argumentative microtexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First European Conference on Argumentation: Argumentation and Reasoned Action</title>
		<meeting>the First European Conference on Argumentation: Argumentation and Reasoned Action<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards segment-based recognition of argumentation structure in short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, U.S.</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Identifying argumentative discourse structures in persuasive essays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DiMLex: A Lexical Approach to Discourse Markers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Stede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Orso</title>
		<editor>Vittorio Di Tomaso Alessandro Lenci</editor>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Exploring the Lexicon-Theory and Computation</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust argumentative zoning for sensemaking in scholarly documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Language Technologies for Digital Libraries</title>
		<editor>Raffaella Bernadi, Sally Chambers, Björn Gottfried, Frédérique Segond, and Ilya Zaihrayeu</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">6699</biblScope>
			<biblScope unit="page" from="154" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Summarizing scientific articles: Experiments with relevance and rhetorical status</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="409" to="445" />
			<date type="published" when="2002-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Structure of Scientific Articles: Applications to Citation Indexing and Summarization. CSLI Studies in Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>CSLI Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Macagno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Argumentation Schemes. Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
