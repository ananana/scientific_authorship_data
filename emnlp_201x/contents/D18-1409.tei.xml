<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BANDITSUM: Extractive Summarization as a Contextual Bandit</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Dong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Shen</surname></persName>
							<email>yi-kang.shen @umontreal.ca</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Crawford</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herke</forename><surname>Van Hoof</surname></persName>
							<email>h.c.vanhoof @uva.nl</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><forename type="middle">C K</forename><surname>Cheung</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Mila/McGill University</orgName>
								<orgName type="institution" key="instit1">McGill University</orgName>
								<orgName type="institution" key="instit2">Mila/University of Montréal</orgName>
								<address>
									<settlement>Mila</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Mila/McGill University jcheung</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">BANDITSUM: Extractive Summarization as a Contextual Bandit</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3739" to="3748"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3739</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this work, we propose a novel method for training neural networks to perform single-document extractive summarization without heuristically-generated extractive labels. We call our approach BANDITSUM as it treats ex-tractive summarization as a contextual bandit (CB) problem, where the model receives a document to summarize (the context), and chooses a sequence of sentences to include in the summary (the action). A policy gradient reinforcement learning algorithm is used to train the model to select sequences of sentences that maximize ROUGE score. We perform a series of experiments demonstrating that BANDITSUM is able to achieve ROUGE scores that are better than or comparable to the state-of-the-art for extractive summariza-tion, and converges using significantly fewer update steps than competing approaches. In addition, we show empirically that BANDIT-SUM performs significantly better than competing approaches when good summary sentences appear late in the source document.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Single-document summarization methods can be divided into two categories: extractive and ab- stractive. Extractive summarization systems form summaries by selecting and copying text snippets from the document, while abstractive methods aim to generate concise summaries with paraphrasing. This work is primarily concerned with extractive * Equal contribution. summarization. Though abstractive summariza- tion methods have made strides in recent years, ex- tractive techniques are still very attractive as they are simpler, faster, and more reliably yield seman- tically and grammatically correct sentences.</p><p>Many extractive summarizers work by selecting sentences from the input document <ref type="bibr" target="#b14">(Luhn, 1958;</ref><ref type="bibr" target="#b15">Mihalcea and Tarau, 2004;</ref><ref type="bibr" target="#b31">Wong et al., 2008;</ref><ref type="bibr" target="#b8">Kågebäck et al., 2014;</ref><ref type="bibr" target="#b35">Yin and Pei, 2015;</ref><ref type="bibr" target="#b1">Cao et al., 2015;</ref><ref type="bibr" target="#b34">Yasunaga et al., 2017</ref>). Furthermore, a growing trend is to frame this sentence selection process as a sequential binary labeling problem, where binary inclusion/exclusion labels are cho- sen for sentences one at a time, starting from the beginning of the document, and decisions about later sentences may be conditioned on decisions about earlier sentences. Recurrent neural networks may be trained with stochastic gradient ascent to maximize the likelihood of a set of ground-truth binary label sequences <ref type="bibr" target="#b3">(Cheng and Lapata, 2016;</ref><ref type="bibr" target="#b17">Nallapati et al., 2017</ref>). However, this approach has two well-recognized disadvantages. First, it suf- fers from exposure bias, a form of mismatch be- tween training and testing data distributions which can hurt performance ( <ref type="bibr" target="#b22">Ranzato et al., 2015;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2017;</ref><ref type="bibr" target="#b20">Paulus et al., 2018)</ref>. Second, extractive labels must be generated by a heuris- tic, as summarization datasets do not generally in- clude ground-truth extractive labels; the ultimate performance of models trained on such labels is thus fundamentally limited by the quality of the heuristic.</p><p>An alternative to maximum likelihood training is to use reinforcement learning to train the model to directly maximize a measure of summary qual- ity, such as the ROUGE score between the gener- ated summary and a ground-truth abstractive sum- mary ( <ref type="bibr" target="#b32">Wu and Hu, 2018)</ref>. This approach has be- come popular because it avoids exposure bias, and directly optimizes a measure of summary quality. However, it also has a number of downsides. For one, the search space is quite large: for a docu- ment of length T , there are 2 T possible extrac- tive summaries. This makes the exploration prob- lem faced by the reinforcement learning algorithm during training very difficult. Another issue is that due to the sequential nature of selection, the model is inherently biased in favor of selecting earlier sentences over later ones, a phenomenon which we demonstrate empirically in Section 7.</p><p>The first issue can be resolved to a degree using either a cumbersome maximum likelihood-based pre-training step (using heuristically-generated la- bels) (Wu and Hu, 2018), or placing a hard upper limit on the number of sentences selected. The second issue is more problematic, as it is inherent to the sequential binary labeling setting.</p><p>In the current work, we introduce BANDITSUM, a novel method for training neural network-based extractive summarizers with reinforcement learn- ing. This method does away with the sequential binary labeling setting, instead formulating extrac- tive summarization as a contextual bandit. This move greatly reduces the size of the space that must be explored, removes the need to perform su- pervised pre-training, and prevents systematically privileging earlier sentences over later ones. Al- though the strong performance of Lead-3 indicates that good sentences often occur early in the source article, we show in Sections 6 and 7 that the con- textual bandit setting greatly improves model per- formance when good sentences occur late without sacrificing performance when good sentences oc- cur early.</p><p>Under this reformulation, BANDITSUM takes the document as input and outputs an affinity for each of the sentences therein. An affinity is a real number in <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> which quantifies the model's propensity for including a sentence in the sum- mary. These affinities are then used in a process of repeated sampling-without-replacement which does not privilege earlier sentences over later ones. BANDITSUM is free to process the document as a whole before yielding affinities, which permits affinities for different sentences in the document to depend on one another in arbitrary ways. In our technical section, we show how to apply policy gradient reinforcement learning methods to this setting.</p><p>The contributions of our work are as follows:</p><p>• We propose a theoretically grounded method, based on the contextual bandit formalism, for training neural network-based extrac- tive summarizers with reinforcement learn- ing. Based on this training method, we pro- pose the BANDITSUM system for extractive summarization.</p><p>• We perform experiments demonstrating that BANDITSUM obtains state-of-the-art perfor- mance on a number of datasets and requires significantly fewer update steps than compet- ing approaches.</p><p>• We perform human evaluations showing that in the eyes of human judges, summaries cre- ated by BANDITSUM are less redundant and of higher overall quality than summaries cre- ated by competing approaches.</p><p>• We provide evidence, in the form of experi- ments in which models are trained on subsets of the data, that the improved performance of BANDITSUM over competitors stems in part from better handling of summary-worthy sentences that come near the end of the doc- ument (see Section 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Extractive summarization has been widely studied in the past. Recently, neural network-based meth- ods have been gaining popularity over classical methods <ref type="bibr" target="#b14">(Luhn, 1958;</ref><ref type="bibr" target="#b6">Gong and Liu, 2001;</ref><ref type="bibr" target="#b5">Conroy and O'leary, 2001;</ref><ref type="bibr" target="#b15">Mihalcea and Tarau, 2004;</ref><ref type="bibr" target="#b31">Wong et al., 2008</ref>), as they have demonstrated stronger performance on large corpora. Central to the neural network-based models is the encoder- decoder structure. These models typically use ei- ther a convolution neural network ( <ref type="bibr" target="#b9">Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b11">Kim, 2014;</ref><ref type="bibr" target="#b35">Yin and Pei, 2015;</ref><ref type="bibr" target="#b1">Cao et al., 2015</ref>), a recurrent neural network ( <ref type="bibr" target="#b4">Chung et al., 2014;</ref><ref type="bibr" target="#b3">Cheng and Lapata, 2016;</ref><ref type="bibr" target="#b17">Nallapati et al., 2017)</ref>, or a combination of the two ( <ref type="bibr" target="#b19">Narayan et al., 2018;</ref><ref type="bibr" target="#b32">Wu and Hu, 2018)</ref> to create sentence and document representations, using word embed- dings ( <ref type="bibr" target="#b16">Mikolov et al., 2013;</ref><ref type="bibr" target="#b21">Pennington et al., 2014</ref>) to represent words at the input level. These vectors are then fed into a decoder network to gen- erate the output summary. The use of reinforcement learning (RL) in extractive summarization was first explored by <ref type="bibr" target="#b25">Ryang and Abekawa (2012)</ref>, who proposed to use the TD(λ) algorithm to learn a value function for sentence selection. <ref type="bibr" target="#b24">Rioux et al. (2014)</ref> im- proved this framework by replacing the learning agent with another TD(λ) algorithm. However, the performance of their methods was limited by the use of shallow function approximators, which required performing a fresh round of reinforce- ment learning for every new document to be sum- marized. The more recent work of <ref type="bibr" target="#b20">Paulus et al. (2018)</ref> and <ref type="bibr" target="#b32">Wu and Hu (2018)</ref> use reinforcement learning in a sequential labeling setting to train ab- stractive and extractive summarizers, respectively, while Chen and Bansal (2018) combines both ap- proaches, applying abstractive summarization to a set of sentences extracted by a pointer network ( <ref type="bibr" target="#b29">Vinyals et al., 2015</ref>) trained via REINFORCE. However, pre-training with a maximum likelihood objective is required in all of these models.</p><p>The two works most similar to ours are <ref type="bibr" target="#b33">Yao et al. (2018)</ref> and <ref type="bibr" target="#b19">Narayan et al. (2018)</ref>. <ref type="bibr" target="#b33">Yao et al. (2018)</ref> recently proposed an extractive sum- marization approach based on deep Q learning, a type of reinforcement learning. However, their approach is extremely computationally intensive (a minimum of 10 days before convergence), and was unable to achieve ROUGE scores bet- ter than the best maximum likelihood-based ap- proach. <ref type="bibr" target="#b19">Narayan et al. (2018)</ref> uses a cascade of filters in order to arrive at a set of candidate extrac- tive summaries, which we can regard as an approx- imation of the true action space. They then use an approximation of a policy gradient method to train their neural network to select summaries from this approximated action space. In contrast, BANDIT- SUM samples directly from the true action space, and uses exact policy gradient parameter updates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Extractive Summarization as a Contextual Bandit</head><p>Our approach formulates extractive summariza- tion as a contextual bandit which we then train an agent to solve using policy gradient reinforcement learning. A bandit is a decision-making formal- ization in which an agent repeatedly chooses one of several actions, and receives a reward based on this choice. The agent's goal is to quickly learn which action yields the most favorable distribu- tion over rewards, and choose that action as often as possible. In a contextual bandit, at each trial, a context is sampled and shown to the agent, af- ter which the agent selects an action and receives a reward; importantly, the rewards yielded by the actions may depend on the sampled context. The agent must quickly learn which actions are favor- able in which contexts. Contextual bandits are a subset of Markov Decision Processes in which ev- ery episode has length one. Extractive summarization may be regarded as a contextual bandit as follows. Each document is a context, and each ordered subset of a document's sentences is a different action. Formally, assume that each context is a document d consisting of sentences s = (s 1 , . . . , s N d ), and that each action is a length-M sequence of unique sentence indices i = (i 1 , . . . , i M ) where i t ∈ {1, . . . , N d }, i t = i t for t = t , and M is an integer hyper-parameter. For each i, the extractive summary induced by i is given by (s i 1 , . . . , s i M ). An action i taken in context d is given a reward R(i, a), where a is the gold-standard abstractive summary that is paired with document d, and R is a scalar reward function quantifying the degree of match between a and the summary induced by i.</p><p>A policy for extractive summarization is a neu- ral network p θ (·|d), parameterized by a vector θ, which, for each input document d, yields a proba- bility distribution over index sequences. Our goal is to find parameters θ which cause p θ (·|d) to as- sign high probability to index sequences that in- duce extractive summaries that a human reader would judge to be of high-quality. We achieve this by maximizing the following objective func- tion with respect to parameters θ:</p><formula xml:id="formula_0">J(θ) = E [R(i, a)]<label>(1)</label></formula><p>where the expectation is taken over documents d paired with gold-standard abstractive summaries a, as well as over index sequences i generated ac- cording to p θ (·|d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Policy Gradient Reinforcement Learning</head><p>Ideally, we would like to maximize (1) using gra- dient ascent. However, the required gradient can- not be obtained using usual techniques (e.g. sim- ple backpropagation) because i must be discretely sampled in order to compute R(i, a).</p><p>Fortunately, we can use the likelihood ratio gra- dient estimator from reinforcement learning and stochastic optimization <ref type="bibr" target="#b30">(Williams, 1992;</ref><ref type="bibr" target="#b28">Sutton et al., 2000</ref>), which tells us that the gradient of this function can be computed as:</p><formula xml:id="formula_1">θ J(θ) = E [ θ log p θ (i|d)R(i, a)]<label>(2)</label></formula><p>where the expectation is taken over the same vari- ables as (1).</p><p>Since we typically do not know the exact docu- ment distribution and thus cannot evaluate the ex- pected value in (2), we instead estimate it by sam- pling. We found that we obtained the best perfor- mance when, for each update, we first sample one document/summary pair (d, a), then sample B in- dex sequences i 1 , . . . , i B from p θ (·|d), and finally take the empirical average:</p><formula xml:id="formula_2">θ J(θ) ≈ 1 B B b=1 θ log p θ (i b |d)R(i b , a) (3)</formula><p>This overall learning algorithm can be regarded as an instance of the REINFORCE policy gradient al- gorithm (Williams, 1992).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Structure of p θ (·|d)</head><p>There are many possible choices for the structure of p θ (·|d); we opt for one that avoids privileging early sentences over later ones. We first decom- pose p θ (·|d) into two parts: π θ , a deterministic function which contains all the network's param- eters, and µ, a probability distribution parameter- ized by the output of π θ . Concretely:</p><formula xml:id="formula_3">p θ (·|d) = µ(·|π θ (d))<label>(4)</label></formula><p>Given an input document d, π θ outputs a real- valued vector of sentence affinities whose length is equal to the number of sentences in the docu- ment (i.e. π θ (d) ∈ R N d ) and whose elements fall in the range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. The t-th entry π(d) t may be roughly interpreted as the network's propensity to include sentence s t in the summary of d. Given sentence affinities π θ (d), µ imple- ments a process of repeated sampling-without- replacement. This proceeds by repeatedly nor- malizing the set of affinities corresponding to sen- tences that have not yet been selected, thereby ob- taining a probability distribution over unselected sentences, and sampling from that distribution to obtain a new sentence to include. This normalize- and-sample step is repeated M times, yielding M unique sentences to include in the summary.</p><p>At each step of sampling-without-replacement, we also include a small probability of sampling uniformly from all remaining sentences. This is used to achieve adequate exploration during train- ing, and is similar to the -greedy technique from reinforcement learning.</p><p>Under this sampling scheme, we have the fol- lowing expression for p θ (i|d):</p><formula xml:id="formula_4">M j=1 N d − j + 1 + (1 − )π(d) i j z(d) − j−1 k=1 π(d) i k<label>(5)</label></formula><p>where</p><formula xml:id="formula_5">z(d) = t π(d) t .</formula><p>For index sequences that have length different from M , or that con- tain duplicate indices, we have p θ (i|d) = 0. Using this expression, it is straightforward to use automatic differentiation software to compute θ log p θ (i|d), which is required for the gradient estimate in (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baseline for Variance Reduction</head><p>Our sample-based gradient estimate can have high variance, which can slow the learning. One po- tential cause of this high variance can be seen by inspecting (3), and noting that it basically acts to change the probability of a sampled index se- quence to an extent determined by the reward R(i, a). However, since ROUGE scores are al- ways positive, the probability of every sampled index sequence is increased, whereas intuitively, we would prefer to decrease the probability of se- quences that receive a comparatively low reward, even if it is positive. This can be remedied by the introduction of a so-called baseline which is sub- tracted from all rewards.</p><p>Using a baseline r, our sample-based estimate of θ J(θ) becomes:</p><formula xml:id="formula_6">1 B B i=1 θ log p θ (i b |d)(R(i b , a) − r)<label>(6)</label></formula><p>It can be shown that the introduction of r does not bias the gradient estimator and can significantly reduce its variance if chosen appropriately ( <ref type="bibr" target="#b28">Sutton et al., 2000</ref>). There are several possibilities for the baseline, including the long-term average reward and the average reward across different samples for one document-summary pair. We choose an approach known as self-critical reinforcement learning, in which the test-time performance of the current model is used as the baseline ( <ref type="bibr" target="#b22">Ranzato et al., 2015;</ref><ref type="bibr" target="#b23">Rennie et al., 2017;</ref><ref type="bibr" target="#b20">Paulus et al., 2018)</ref>. More concretely, after sampling the document-summary pair (d, a), we greedily generate an index se- quence using the current parameters θ:</p><formula xml:id="formula_7">i greedy = arg max i p θ (i|d)<label>(7)</label></formula><p>and calculate the baseline for the current update as r = R(i greedy , a). This baseline has the intu- itively satisfying property of only increasing the probability of a sampled label sequence when the summary it induces is better than what would be obtained by greedy decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Reward Function</head><p>A final consideration is a concrete choice for the reward function R(i, a). Throughout this work we use:</p><formula xml:id="formula_8">R(i, a) = 1 3 (ROUGE-1 f (i, a) + ROUGE-2 f (i, a) + ROUGE-L f (i, a)).<label>(8)</label></formula><p>The above reward function optimizes the average of all the ROUGE variants <ref type="bibr" target="#b13">(Lin, 2004</ref>) while bal- ancing precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>In this section, we discuss the concrete instan- tiations of the neural network π θ that we use in our experiments. We break π θ up into two components: a document encoder f θ1 , which outputs a sequence of sentence feature vectors (h 1 , . . . , h N d ) and a decoder g θ2 which yields sen- tence affinities:</p><formula xml:id="formula_9">h 1 , . . . , h N d = f θ1 (d) (9) π θ (d) = g θ2 (h 1 , . . . , h N d )<label>(10)</label></formula><p>Encoder. Features for each sentence in isolation are first obtained by applying a word-level Bidi- rectional Recurrent Neural Network (BiRNN) to the embeddings for the words in the sentence, and averaging the hidden states over words. A sepa- rate sentence-level BiRNN is then used to obtain a representations h i for each sentence in the context of the document. Decoder. A multi-layer perceptron is used to map from the representation h t of each sentence through a final sigmoid unit to yield sentence affinities π θ (d).</p><p>The use of a bidirectional recurrent network in the encoder is crucial, as it allows the network to process the document as a whole, yielding repre- sentations for each sentence that take all other sen- tences into account. This procedure is necessary to deal with some aspects of summary quality such as redundancy (avoiding the inclusion of multiple sentences with similar meaning), which requires the affinities for different sentences to depend on one another. For example, to avoid redundancy, if the affinity for some sentence is high, then sen- tences which express similar meaning should have low affinities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we discuss the setup of our exper- iments. We first discuss the corpora that we used and our evaluation methodology. We then discuss the baseline methods against which we compared, and conclude with a detailed overview of the set- tings of the model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Corpora</head><p>Three datasets are used for our experiments: the CNN, the Daily Mail, and combined CNN/Daily Mail ( <ref type="bibr" target="#b7">Hermann et al., 2015;</ref><ref type="bibr" target="#b18">Nallapati et al., 2016)</ref>. We use the standard split of <ref type="bibr" target="#b7">Hermann et al. (2015)</ref> for training, validating, and testing and the same setting without anonymization on the three cor- pus as <ref type="bibr" target="#b27">See et al. (2017</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation</head><p>The models are evaluated based on ROUGE <ref type="bibr" target="#b13">(Lin, 2004</ref>). We obtain our ROUGE scores using the standard pyrouge package 1 for the test set eval- uation and a faster python implementation of the ROUGE metric 2 for training and evaluating on the validation set. We report the F1 scores of ROUGE- 1, ROUGE-2, and ROUGE-L, which compute the uniform, bigram, and longest common subse- quence overlapping with the reference summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baselines</head><p>We compare BANDITSUM with other extractive methods including: the Lead-3 model, Sum- maRuNNer ( <ref type="bibr" target="#b17">Nallapati et al., 2017</ref>), Refresh <ref type="bibr" target="#b19">(Narayan et al., 2018)</ref>, RNES ( <ref type="bibr" target="#b32">Wu and Hu, 2018)</ref>, <ref type="bibr">DQN (Yao et al., 2018)</ref>, and NN-SE ( <ref type="bibr" target="#b3">Cheng and Lapata, 2016</ref>). The Lead-3 model simply pro- duces the leading three sentences of the document as the summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Model Settings</head><p>We use 100-dimensional Glove embeddings <ref type="bibr" target="#b21">(Pennington et al., 2014</ref>) as our embedding initializa- tion. We do not limit the sentence length, nor the maximum number of sentences per document. We use one-layer BiLSTM for word-level RNN, and two-layers BiLSTM for sentence-level RNN. The hidden state dimension is 200 for each direction on all LSTMs. For the decoder, we use a feed- forward network with one hidden layer of dimen- sion 100.</p><p>During training, we use Adam ( <ref type="bibr" target="#b12">Kingma and Ba, 2015)</ref> as the optimizer with the learning rate of 5e −5 , beta parameters (0, 0.999), and a weight de- cay of 1e −6 , to maximize the objective function defined in equation <ref type="formula" target="#formula_0">(1)</ref>. We employ gradient clip- ping of 1 to regularize our model. At each iter- ation, we sample B = 20 times to estimate the gradient defined in equation 3. For our system, the reported performance is obtained within two epochs of training <ref type="bibr">3</ref> .</p><p>At the test time, we pick sentences sorted by the predicted probabilities until the length limit is reached. The full-length ROUGE F1 score is used as the evaluation metric. For M , the number of sentences selected per summary, we use a value of 3, based on our validation results as well as on the settings described in <ref type="bibr" target="#b17">Nallapati et al. (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiment Results</head><p>In this section, we present quantitative results from the ROUGE evaluation and qualitative re- sults based on human evaluation. In addition, we demonstrate the stability of our RL model by com- paring the validation curve of BANDITSUM with SummaRuNNer ( <ref type="bibr" target="#b17">Nallapati et al., 2017</ref>) trained with a maximum likelihood objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Rouge Evaluation</head><p>We present the results of comparing BANDITSUM to several baseline algorithms <ref type="bibr">4</ref>    Mail corpus in <ref type="table" target="#tab_2">Tables 1 and 2</ref>. Compared to other extractive summarization systems, BANDITSUM achieves performance that is significantly better than two RL-based approaches, Refresh (Narayan et al., 2018) and DQN ( <ref type="bibr" target="#b33">Yao et al., 2018)</ref>, as well as SummaRuNNer, the state-of-the-art maximum liklihood-based extractive summarizer ( <ref type="bibr" target="#b17">Nallapati et al., 2017)</ref>. BANDITSUM performs a little bet- ter than RNES ( <ref type="bibr" target="#b32">Wu and Hu, 2018</ref>) in terms of ROUGE-1 and slightly worse in terms of ROUGE- 2. However, RNES requires pre-training with the maximum likelihood objective on heuristically- generated extractive labels; in contrast, BANDIT- SUM is very light-weight and converges signifi- cantly faster. We discuss the advantage of fram- ing the extractive summarization based on the con- textual bandit (BANDITSUM) over the sequential binary labeling setting (RNES) in the discussion Section 7.</p><p>We also noticed that different choices for the policy gradient baseline (see Section 3.3) in BAN- DITSUM affect learning speed, but do not signif- icantly affect asymptotic performance. Models trained with an average reward baseline learned most quickly, while models trained with three different baselines (greedy, average reward in a the test set provided by <ref type="bibr" target="#b19">Narayan et al. (2018)</ref>. Since their Lead score is a combination of Lead-3 for CNN and Lead- 4 for Daily Mail, we recompute the Lead-3 scores for both CNN and Daily Mail with the preprocessing steps used in <ref type="bibr" target="#b27">See et al. (2017)</ref>. Additionally, our results are not directly comparable to results based on the anonymized dataset used by <ref type="bibr" target="#b17">Nallapati et al. (2017).</ref> batch, average global reward) all perform roughly the same after training for one epoch. Models trained without a baseline were found to under- perform other baseline choices by about 2 points of ROUGE score on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Human Evaluation</head><p>We also conduct a qualitative evaluation to un- derstand the effects of the improvements intro- duced in BANDITSUM on human judgments of the generated summaries. To assess the effect of training with RL rather than maximum like- lihood, in the first set of human evaluations we compare BANDITSUM with the state-of-the-art maximum likelihood-based model SummaRuN- Ner. To evaluate the importance of using an exact, rather than approximate, policy gradient to opti- mize ROUGE scores, we perform another human evaluation comparing BANDITSUM and Refresh, an RL-based method that uses the an approxima- tion of the policy gradient.</p><p>We follow a human evaluation protocol similar to the one used in <ref type="bibr" target="#b32">Wu and Hu (2018)</ref>. Given a set of N documents, we ask K volunteers to evalu- ate the summaries extracted by both systems. For each document, a reference summary, and a pair of randomly ordered extractive summaries (one gen- erated by each of the two models) is presented to the volunteers. They are asked to compare and rank the extracted summaries along three dimen- sions: overall, coverage, and non-redundancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Overall   To compare with SummaRuNNer, we randomly sample 57 documents from the test set of Daily- Mail and ask 5 volunteers to evaluate the extracted summaries. While comparing with Refresh, we use the 20 documents (10 CNN and 10 Daily- Mail) provided by <ref type="bibr" target="#b19">Narayan et al. (2018)</ref> to 4 vol- unteers. <ref type="table" target="#tab_5">Tables 3 and 4</ref> show the results of hu- man evaluation in these two settings. BANDIT- SUM is shown to be better than Refresh and Sum- maRuNNer in terms of overall quality and non- redundancy. These results indicate that the use of the true policy gradient, rather than the approxi- mation used by Refresh, improves overall quality. It is interesting to observe that, even though BAN- DITSUM does not have an explicit redundancy avoidance mechanism, it actually outperforms the other systems on non-redundancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Learning Curve</head><p>Reinforcement learning methods are known for sometimes being unstable during training. How- ever, this seems to be less of a problem for BAN- DITSUM, perhaps because it is formulated as a contextual bandit rather than a sequential label- ing problem. We show this by comparing the val- idation curves generated by BANDITSUM and the state-of-the-art maximum likelihood-based model -SummaRuNNer ( <ref type="bibr" target="#b17">Nallapati et al., 2017)</ref>  <ref type="figure" target="#fig_0">(Fig- ure 1</ref>). From <ref type="figure" target="#fig_0">Figure 1</ref>, we observe that BANDITSUM converges significantly more quickly to good re- sults than SummaRuNNer. Moreover, there is less variance in the performance of BANDITSUM.</p><p>One possible reason is that extractive summariza- tion does not have well-defined supervised labels. There exists a mismatch between the provided la- bels and human-generated abstractive summaries. Hence, the gradient, computed from the maximum likelihood loss function, is not optimizing the eval- uation metric of interest. Another important mes- sage is that both models are still far from the es- timated upper bound 5 , which shows that there is still significant room for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Run Time</head><p>On CNN/Daily mail dataset, our model's time- per-epoch is about 25.5 hours on a TITAN Xp. We trained the model for 3 epochs, which took about 76 hours in total. For comparison, DQN took about 10 days to train on a GTX 1080 ( <ref type="bibr" target="#b33">Yao et al., 2018)</ref>. Refresh took about 12 hours on a sin- gle GPU to train <ref type="bibr" target="#b19">(Narayan et al., 2018)</ref>. Note that this figure does not take into account the signifi- cant time required by Refresh for pre-computing ROUGE scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion: Contextual Bandit Setting Vs. Sequential Full RL Labeling</head><p>We conjecture that the contextual bandit (CB) set- ting is a more suitable framework for modeling extractive summarization than the sequential bi- nary labeling setting, especially in the cases when good summary sentences appear later in the doc- ument. The intuition behind this is that models based on the sequential labeling setting are af- fected by the order of the decisions, which bi- ases towards selecting sentences that appear ear- lier in the document. By contrast, our CB-based RL model has more flexibility and freedom to explore the search space, as it samples the sen- tences without replacement based on the affin- ity scores. Note that although we do not explic- itly make the selection decisions in a sequential fashion, the sequential information about depen- dencies between sentences is implicitly embedded in the affinity scores, which are produced by bi- directional RNNs.</p><p>We provide empirical evidence for this conjec- ture by comparing BANDITSUM to the sequential RL model proposed by <ref type="bibr" target="#b32">Wu and Hu (2018)</ref>  <ref type="figure" target="#fig_1">(Fig- ure 2</ref>) on two subsets of the data: one with good summary sentences appearing early in the article, while the other contains articles where good sum- mary sentences appear late. Specifically, we con- struct two evaluation datasets by selecting the first 50 documents (D early , i.e., best summary occurs early) and the last 50 documents (D late , i.e., best summary occurs late) from a sample of 1000 doc- uments that is ordered by the average extractive label index idx. Given an article with n sentences indexed from 1, . . . , n and a greedy extractive la- bels set with three sentences (i, j, k) 6 , the aver- age index for the extractive label is computed by idx= (i + j + k)/3n. Given these two subsets of the data, three differ- ent models (BANDITSUM, RNES and RNES3) are trained and evaluated on each of the two datasets without extractive labels. Since the original se- quential RL model (RNES) is unstable without supervised pre-training, we propose the RNES3 model that is limited to select no more then three sentences. Starting with random initializations without supervised pre-training, we train each model ten times for 100 epochs and plot the learn- ing curve of the average ROUGE-F1 score com- puted based on the trained model in <ref type="figure" target="#fig_1">Figure 2</ref>. We can clearly see that BANDITSUM finds a better so-lution more quickly than RNES and RNES3 on both datasets. Moreover, it displays a significantly speed-up in the exploration and finds the best solu- tion when good summary sentences appeared later in the document (D late ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work, we presented a contextual ban- dit learning framework, BANDITSUM , for ex- tractive summarization, based on neural networks and reinforcement learning algorithms. BANDIT- SUM does not require sentence-level extractive la- bels and optimizes ROUGE scores between sum- maries generated by the model and abstractive ref- erence summaries. Empirical results show that our method performs better than or comparable to state-of-the-art extractive summarization mod- els which must be pre-trained on extractive la- bels, and converges using significantly fewer up- date steps than competing approaches. In future work, we will explore the direction of adding an extra coherence reward ( <ref type="bibr" target="#b32">Wu and Hu, 2018)</ref> to im- prove the quality of extracted summaries in terms of sentence discourse relation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Average of ROUGE-1,2,L F1 scores on the Daily Mail validation set within one epoch of training on the Daily Mail training set. The x-axis (multiply by 2,000) indicates the number of data example the algorithms have seen. The supervised labels in SummaRuNNer are used to estimate the upper bound.</figDesc><graphic url="image-1.png" coords="7,307.28,444.08,226.78,170.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model comparisons of the average value for ROUGE-1,2,L F1 scores (f ) on D early and D late. For each model, the results were obtained by averaging f across ten trials with 100 epochs in each trail. D early and D late consist of 50 articles each, such that the good summary sentences appear early and late in the article, respectively. We observe a significant advantage of BANDITSUM compared to RNES and RNES3 (based on the sequential binary labeling setting) on D late .</figDesc><graphic url="image-2.png" coords="8,307.28,250.25,226.77,170.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>on the CNN/Daily</head><label></label><figDesc></figDesc><table>Model 
ROUGE 
1 
2 
L 
Lead(Narayan et al., 2018) 39.6 17.7 36.2 
Lead-3(ours) 
40.0 17.5 36.2 
SummaRuNNer 
39.6 16.2 35.3 
DQN 
39.4 16.1 35.6 
Refresh 
40.0 18.2 36.6 
RNES w/o coherence 
41.3 18.9 37.6 
BANDITSUM 
41.5 18.7 37.6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Performance comparison of different ex-
tractive summarization models on the combined 
CNN/Daily Mail test set using full-length F1. 

Model 
CNN 
Daily Mail 
1 
2 
L 
1 
2 
L 
Lead-3 
28.8 11.0 25.5 41.2 18.2 37.3 
NN-SE 
28.4 10.0 25.0 36.2 15.2 32.9 
Refresh 
30.4 11.7 26.9 41.0 18.8 37.7 
BANDITSUM 30.7 11.6 27.4 42.1 18.9 38.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>The full-length ROUGE F1 scores of various extractive models on the CNN and the Daily Mail test set separately.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Average rank of human evaluation based on 
5 participants who expressed 57 pairwise preferences 
between the summaries generated by SummaRuNNer 
and BANDITSUM. The model with the lower score is 
better. 

Model 
Overall 
Coverage 
Non-
Redundancy 
Refresh 
1.53 
1.34 
1.55 
BANDITSUM 1.50 
1.58 
1.30 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Average rank of manual evaluation with 4 
participants who expressed 20 pairwise preferences be-
tween the summaries generated by Refresh and our sys-
tem. The model with the lower score is better. 

</table></figure>

			<note place="foot" n="1"> https://pypi.python.org/pypi/pyrouge/ 0.1.3 2 We use the modified version based on https:// github.com/pltrdy/rouge</note>

			<note place="foot" n="3"> Our code can be found at https://github.com/ yuedongP/summarization_RL 4 Due to different pre-processing methods and different numbers of selected sentences, several papers report different Lead scores (Narayan et al., 2018; See et al., 2017). We use</note>

			<note place="foot" n="5"> The supervised labels for the upper bound estimation are obtained using the heuristic described in Nallapati et al. (2017).</note>

			<note place="foot" n="6"> For each document, a length-3 extractive summary with near-optimal ROUGE score is selected following the heuristic proposed by Nallapati et al. (2017).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research was supported in part by Natural Sciences and Engineering Research Council of Canada (NSERC). The authors would like to thank Compute Canada for providing the computational resources.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An actor-critic algorithm for sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philemon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning summary prior representation for extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqiang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fast abstractive summarization with reinforce-selected sentence rewriting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2014 Workshop on Deep Learning</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Text summarization via hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianne P O&amp;apos;</forename><surname>Conroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="406" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generic text summarization using relevance measure and latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="19" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Extractive summarization using continuous vector space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Kågebäck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olof</forename><surname>Mogren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Tahmasebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devdatt</forename><surname>Dubhashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Continuous Vector Space Models and their Compositionality (CVSC) at EACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="31" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd</title>
		<meeting>the 52nd</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference for Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out: Proceedings of the ACL-04 Workshop</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The automatic creation of literature abstracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Peter Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="165" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">TextRank: Bringing order into text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR) Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SummaRuNNer: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st AAAI Conference on Artificial Intelligence</title>
		<meeting>the 31st AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Abstractive text summarization using sequence-tosequence rnns and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ranking sentences for extractive summarization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A deep reinforced model for abstractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06732</idno>
		<title level="m">Sequence level training with recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-critical sequence training for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Steven J Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youssef</forename><surname>Marcheret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerret</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhava</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7008" to="7024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fear the reaper: A system for automatic multidocument summarization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cody</forename><surname>Rioux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yllias</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="681" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Framework of automatic text summarization using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonggi</forename><surname>Ryang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Abekawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012</title>
		<meeting>the 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Natural Language Processing and Computational Natural Language Learning (EMNLP)</title>
		<imprint>
			<biblScope unit="page" from="256" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointergenerator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Policy gradient methods for reinforcement learning with function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Richard S Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Satinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1057" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reinforcement Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Extractive summarization using supervised and semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 22nd International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="985" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to extract coherent summary via deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for extractive document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">284</biblScope>
			<biblScope unit="page" from="52" to="62" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph-based neural multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitijh</forename><surname>Meelu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishnan</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 21st Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="452" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Optimizing sentence modeling and selection for document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulong</forename><surname>Pei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1383" to="1389" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
