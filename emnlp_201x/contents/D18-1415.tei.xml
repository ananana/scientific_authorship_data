<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Teacher-Student Framework for Maintainable Dialog Manager</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weikang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Mobvoi AI Lab</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei-Yuh</forename><surname>Hwang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Mobvoi AI Lab</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqing</forename><surname>Zong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">CAS</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">CAS Center for Excellence in Brain Science and Intelligence Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Mobvoi AI Lab</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Teacher-Student Framework for Maintainable Dialog Manager</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="3803" to="3812"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Reinforcement learning (RL) is an attractive solution for task-oriented dialog systems. However, extending RL-based systems to handle new intents and slots requires a system redesign. The high maintenance cost makes it difficult to apply RL methods to practical systems on a large scale. To address this issue, we propose a practical teacher-student framework to extend RL-based dialog systems without retraining from scratch. Specifically, the &quot;student&quot; is an extended dialog manager based on a new ontology, and the &quot;teacher&quot; is existing resources used for guiding the learning process of the &quot;student&quot;. By specifying constraints held in the new dialog manager, we transfer knowledge of the &quot;teacher&quot; to the &quot;student&quot; without additional resources. Experiments show that the performance of the extended system is comparable to the system trained from scratch. More importantly, the proposed framework makes no assumption about the unsupported intents and slots, which makes it possible to improve RL-based systems incrementally.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the flourish development of virtual personal assistants (e.g., Amazon Alexa and Google Assis- tant), task-oriented dialog systems, which can help users accomplish tasks naturally, have been a focal point in both academic and industry research. In the early work, the task-oriented dialog system is merely a set of hand-crafted mapping rules defined by experts. This is referred to as a rule-based system. Although rule-based systems often have acceptable performance, they are inconvenient and difficult to be optimized. Recently, reinforcement learning approaches have been applied to optimize dialog systems through interaction with a user simulator or employed real users online <ref type="bibr" target="#b7">(Gaši´Gaši´c et al., 2011;</ref><ref type="bibr" target="#b28">Su et al., 2016a;</ref><ref type="bibr">Li et al., 2016, Figure 1</ref>: An example of a task-oriented dialog after the system comes online. The user is confused because the "confirm" intent has not been considered in the deployed system. Dialog rules should be embedded in a new system to handle such situations. 2017b). It has been proven that RL-based dialog systems can abandon hand-crafted dialog manager and achieve more robust performance than rule- based systems <ref type="bibr" target="#b32">(Young et al., 2013)</ref>.</p><p>Typically, the first step of building RL-based dialog systems is defining a user model 1 and necessary system actions to complete a specific task (e.g., seek restaurants information or book hotels). Based on such ontology, developers can extract dialog features and train the dialog man- ager model in an interaction environment. Such systems work well if real users are consistent with the predefined user model. However, as shown in <ref type="figure">Fig. 1</ref>, the unanticipated actions 2 of real users will lead to a poor user experience.</p><p>In this situation, the original system should be extended to support new user actions based on user feedback. However, adding new intents or slots will change the predefined ontology. As a consequence, developers need to extract additional dialog features based on new ontology. Besides, new system actions may be added to deal with new user actions. The network architecture of the new system and the original one will be different. The new system can not inherit the parameters from the old one directly. It will make the original dialog manager model invalid. Therefore, developers have to retrain the new system by interacting with users from scratch. Though there are many methods to train a RL-based dialog manager ef- ficiently ( <ref type="bibr" target="#b28">Su et al., 2016a</ref><ref type="bibr" target="#b27">Su et al., , 2017</ref><ref type="bibr" target="#b16">Lipton et al., 2017;</ref><ref type="bibr" target="#b3">Chen et al., 2017)</ref>, the unmaintainable RL-based dialog systems will still be put on the shelf in real-world applications <ref type="bibr" target="#b21">(Paek and Pieraccini, 2008;</ref><ref type="bibr" target="#b20">Paek, 2006</ref>).</p><p>To alleviate this problem, we propose a teacher- student framework to maintain the RL-based dia- log manager without training from scratch. The idea is to transfer the knowledge of existing re- sources to a new dialog manager.</p><p>Specifically, after the system is deployed, if developers find some intents and slots missing before, they can define a few simple dialog rules to handle such situations. For example, under the condition shown in <ref type="figure">Fig. 1</ref>, a reasonable s- trategy is to inform the user of the location of this restaurant. Then we encode information of such hand-crafted logic rules into the new dialog manager model. Meanwhile, user logs and dialog policy of the original system can guide the new system to complete tasks like the original one. Under the guidance of the "teacher" (logic rules, user logs, and original policy), we can reforge an extended dialog manager (the "student") without a new interaction environment.</p><p>We conduct a series of experiments with simu- lated and real users on restaurant domain. The ex- tensive experiments demonstrate that our method can overcome the problem brought by the unpre- dictable user behavior after deployment. Owing to reuse of existing resources, our framework saves time in designing new interaction environments and retraining RL-based systems from scratch. More importantly, our method does not make any assumptions about the unsupported intents and slots. So the system can be incrementally extended once developers find new intents and slots that are not taken into account before. As far as we know, we are the first to discuss the maintainability of deep reinforcement learning based dialog systems systematically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Dialog Manager The dialog manager of task- oriented dialog systems, which consists of a s- tate tracker and a dialog policy module, controls the dialog flow. Recently, deep reinforcement learning ( <ref type="bibr" target="#b18">Mnih et al., 2013</ref><ref type="bibr" target="#b19">Mnih et al., , 2015</ref>) has been ap- plied to optimize the dialog manager in an "end- to-end" way, including deep Q-Network ( <ref type="bibr" target="#b16">Lipton et al., 2017;</ref><ref type="bibr" target="#b15">Li et al., 2017b;</ref><ref type="bibr" target="#b22">Peng et al., 2017;</ref><ref type="bibr" target="#b35">Zhao and Eskenazi, 2016)</ref> and policy gradient methods ( <ref type="bibr" target="#b30">Williams et al., 2017;</ref><ref type="bibr" target="#b29">Su et al., 2016b;</ref><ref type="bibr" target="#b6">Dhingra et al., 2017)</ref>. RL methods have shown great potential in building a robust dialog system automatically. However, RL-based approaches are rarely used in real-world applications because of the maintainability problem <ref type="bibr" target="#b21">(Paek and Pieraccini, 2008;</ref><ref type="bibr" target="#b20">Paek, 2006</ref>). To extend the domain of dialog systems, <ref type="bibr" target="#b8">Gašic et al. (2014)</ref> explicitly defined kernel functions between the belief states that come from different domains. However, defining an appropriate kernel function is non- trivial when the ontology has changed drastically. <ref type="bibr" target="#b25">Shah et al. (2016)</ref> proposed to integrate turn- level feedback with a task-level reward signal to learn how to handle new user intents. This approach alleviates the problem that arises from the difference between training and deployment phases. But it still fails when the developers have not considered all user actions in advance. <ref type="bibr" target="#b16">Lipton et al. (2017)</ref> proposed to use BBQ-Networks to extend the domain. However, similar to <ref type="bibr" target="#b25">Shah et al. (2016)</ref>, the BBQ-Networks have reserved a few bits in the feature vector for new intents and slots. And system actions for handling new user actions have been considered in the original system design. This assumption is not practical enough. Compared to the existing domain exten- sion methods, our work addresses a more practical problem: new intents and slots are unknown to the original system. If we need to extend the dialog system, we should design a new network architecture to represent new user actions and take new system actions into account. Knowledge Distillation Our proposed framework is inspired by recent work in knowledge distilla- tion ( <ref type="bibr">Bucilu et al., 2006</ref>; <ref type="bibr" target="#b0">Ba and Caruana, 2014;</ref><ref type="bibr" target="#b12">Li et al., 2014</ref>). Knowledge distillation means training a compact model to mimic a larger teach- er model by approximating the function learned by the teacher. <ref type="bibr" target="#b10">Hinton et al. (2015)</ref>   a large highly regularized model into a smaller model. The knowledge which can be transferred has not been restricted to models. <ref type="bibr" target="#b26">Stewart and Ermon (2017)</ref> proposed to distill the physics and domain knowledge to train neural networks with- out labeled data. <ref type="bibr" target="#b11">Hu et al. (2016)</ref> enabled a neural network to learn simultaneously from labeled in- stances as well as logic rules. <ref type="bibr" target="#b34">Zhang et al. (2017)</ref> integrated multiple prior knowledge sources into neural machine translation using posterior regu- larization. Our experiments are based on such insights. Through defining appropriate regular- ization terms, we can distill different knowledge (e.g., trained model or prior knowledge) to a new designed model, alleviating the need for new la- beled data or expensive interaction environments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RL-based Dialog Manager</head><p>Before going to the details of our method, we provide some background on the RL-based dialog manager in this section. <ref type="figure" target="#fig_0">Fig. 2</ref> shows an overview of such dialog manager. We describe each of the parts briefly below. Feature Extraction At the t-th turn of a dialog, the user input u t is parsed into domain specific intents and slots to form a semantic frame a u t by a language understanding (LU) module. o u t and o s t−1 are the one-hot representations of such semantic frames for the current user input and the last system output respectively. Alternatively, o u the vocabulary size is relatively large in real-world applications. It will yield slow convergence in the absence of a LU module. Based on the slot-value pair output with the highest probability, a query is sent to a database to retrieve user requested information. o db t is the one-hot representation of the database result. As a result, the observable information x t is the concatenation of o u t , o s t−1 and o db t . State Representation Based on the extracted fea- ture vector x t and previous internal state s t−1 , recurrent neural networks (RNNs) are used to infer the latent representation of dialog state s t at step t. Current state s t can be interpreted as the summary of dialog history h t up to current step. Dialog Policy Next, the dialog state representation s t is fed into a policy network. The output π(a|h t ; θ) of the policy network is a probability distribution over a predefined system action set A s . Lastly, the system samples an action a s t ∈ A s based on π(a|h t ; θ) and receives a new observa- tion x t+1 with an assigned reward r t . The policy parameters θ can be learned by maximizing the expected discounted cumulative rewards:</p><formula xml:id="formula_0">J (θ) = E T −t k=0 γ k r t+k (1)</formula><p>where T is the maximal step, and γ is the discount factor. Usually the parameters θ can be iteratively updated by policy gradient (Williams, 1992) ap- proach. The policy gradient can be empirically estimated as:</p><formula xml:id="formula_1">θ J (θ) ≈ 1 N N i=1 T t=1 θ log π(a s i,t |hi,t; θ)(Gi,t −b) (2)</formula><p>where N is the number of sampled episodes in a batch, G i,t = T −t k=0 γ k r i,t+k is the sum of discounted reward at step t in the episode i, and b is a baseline to estimate the average reward of current policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Notations and Problem Definition</head><p>Let A u and A s denote the supported user and system action sets in the original system design respectively. u t denotes the user input in the t-th turn. The LU module converts u t into a domain specific intent and associated slots to form a user action a u t ∈ A u . The system will return an action a s t ∈ A s according to the dialog manager π(θ). Note that not all user actions are taken into account at the beginning of system design. After deployment, the developers can find that some user actions A u new cannot be handled by the original system based on the human-machine interaction logs D. Generally speaking, A u new consists of new intents and slots. Our goal is to extend the original system to support the new user action set A u = A u ∪A u new . The extended dialog manager and new system action set are denoted as π(θ ) and A s respectively. To handle new user actions, more system actions may be added to the new system. It means that A s is a subset of A s . <ref type="figure" target="#fig_1">Fig. 3</ref> shows two kinds of strategies to extend the original system. The first strategy requires a new interaction environment. However, building a user simulator or hiring real users once the system needs to be extended is costly and impractical in real-world applications. By contrast, our method enhances the reuse of existing resources. The basic idea is to use the existing user logs, original dialog policy model and logic rules ("teacher") to guide the learning process of a new dialog manager ("student"). Without an expensive in- teraction environment, the developers can main- tain RL-based dialog systems as efficiently and straightforwardly as in rule-based systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Distill Knowledge from the Original System</head><p>Although the ontology of the new system is dif- ferent from the original one, the extended dialog manager can still reuse dialog policy of the ill- considered system circuitously. Given user logs D and the original dialog manager π(θ), we define a loss L(θ ; D, θ) to minimize the difference be- tween new dialog manager π(θ ) and the old one:</p><formula xml:id="formula_2">L(θ ; D, θ) = d∈D |d| t=1 KL( π(a|ht; θ) || π(a|ht; θ ) )<label>(3)</label></formula><p>where π(a|h t ; θ) and π(a|h t ; θ ) are the policy distributions over A s and A s given the same dialog history h t . |d| means turns of a specific dialog d ∈ D. To deal with unsupported user actions, A s will be a subset of A s . As a result, the KL term in equation (3) can be defined as follows:</p><formula xml:id="formula_3">KL( π(a|ht; θ) || π(a|ht; θ ) ) = |As| k=1 π(a k |ht; θ) logπ(a k |ht; θ) − logπ(a k |ht; θ )<label>(4)</label></formula><p>As the original policy parameters θ are fixed, the loss function in equation <ref type="formula" target="#formula_2">(3)</ref> can be rewritten as:</p><formula xml:id="formula_4">L(θ ; D, θ) = − d∈D |d| t=1 |As| k=1 π(a k |ht; θ)logπ(a k |ht; θ )<label>(5)</label></formula><p>This objective will transfer knowledge of the origi- nal system to the "student" at the turn level. Under the guidance of the original system, the extended system will be equipped with the primary strategy to complete a task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Distill Knowledge from Logic Rules</head><p>It's easy for the developers to give logic rules on the system responses to handle new user actions.</p><p>For example, if users ask to confirm a slot, the system should inform the value of that slot im- mediately. Note that these system actions which handle new user actions may not exist in the old model. It means the architecture of the new system is different from the old one.</p><p>We define a set of logic constraints</p><formula xml:id="formula_5">R = {(h l , a l )} L l=1 ,</formula><note type="other">where h l ∈ H R indicates the dialog context condition in the l-th rule, and a l ∈ A s is the corresponding system action. The number of logic rules L is equal to the number of new user actions. These rules can be seen as triggers: if dialog context h t in current turn t meets the context condition h l defined in logic rules, then the system should execute a l . In our work, we use the output of the LU module to judge whether the current dialog context meets the condition defined by logic rules. An alternative method is simple rules matching. To distill the knowledge of rules to a new system, we define a loss function L(θ ; D, R) to embed such constraints in the new system:</note><formula xml:id="formula_6">L(θ ; D, R) = − d∈D |d| t=1 h l ∈H R 1{ht = h l } × |A s | k=1 1{a k = a l } log π(a k |ht; θ )<label>(6)</label></formula><p>Where 1{·} is the indicate function. Equation <ref type="formula" target="#formula_6">(6)</ref> suggests the new dialog manager π(θ ) will be penalized if it violates the instructions defined by the dialog rules. Note that, for simplicity, we assume these rules are absolutely correct and mutually exclusive. Although this hypothesis may lead to a non-optimal dialog system, these rules define reasonable system actions to corresponding dialog contexts. It implies that the new system can be further refined by reinforcement learning once a new interaction environment is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Extension of Dialog Manager</head><p>In the absence of a new training environment, learning is made possible by exploiting structure that holds in the new dialog manager. On one hand, we expect the new system can complete tasks like the original one. On the other hand, it should satisfy the constraints defined by dialog rules. So, the learning objective of new dialog manager π(θ ) can be defined as follows:</p><formula xml:id="formula_7">L(θ ; D, θ, R) = L(θ ; D, R) if ht ∈ HR ; L(θ ; D, θ) else<label>(7)</label></formula><p>When the dialog context h t in the t-th turn satis- fies a condition defined in H R , we distill knowl- edge of rules into the new system. Otherwise, we distill knowledge of the original system into the new one. Instead of retraining from scratch, de- velopers can extend RL-based systems by reusing existing resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>To evaluate our method, we conduct experiments on a dialog system extension task of restaurant domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Domain</head><p>The dialog system provides restaurant information in Beijing. The database we use includes 2988 restaurants. This domain consists of 8 slots (name, area, price range, cuisine, rating, number of comments, address and phone number) in which the first four slots (inform slots) can be used for searching the desirable restaurant and all of these slots (request slots) can be asked by users. In each dialog, the user has a goal containing a set of slots, indicating the constraints and requests from users. For example, an inform slot, such as "inform(cuisine=Sichuan cuisine)", indicates the user finding a Sichuan restaurant, and a request slot, such as "request(area)", indicates the user asking for information from the system ( <ref type="bibr" target="#b14">Li et al., 2016</ref><ref type="bibr" target="#b15">Li et al., , 2017b</ref><ref type="bibr" target="#b22">Peng et al., 2017</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Measurements</head><p>A main advantage of our approach is that the unconsidered user actions can be handled in the extended system. In addition to traditional mea- surements (e.g., success rate, average turns and average reward), we define an objective measure- ment called "Satis." (user satisfaction) to verify this feature in the simulated evaluation. "Satis." indicates the rate at which the system takes rea- sonable actions in unsupported dialog situations. It can be calculated as follows:</p><formula xml:id="formula_8">Satis. = d∈D |d| t=1 L l=1 1{ht = h l }1{a s t = a l } d∈D |d| t=1 L l=1 1{ht = h l }<label>(8)</label></formula><p>where h t and a s t are the dialog history and system action in the t-th turn, h l and a l are dialog context condition and corresponding system ac- tion defined in the l-th rules. Intuitively, an unreasonable system reply will frustrate users and low "Satis." indicates a poor user experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sim1</head><p>Sim2  Although "Satis." is obtained based on our hand- crafted dialog rules, it approximately measures the subjective experience of real users after system deployment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">User Simulator</head><p>Training RL-based dialog systems requires a large number of interactions with users. It's common to use a user simulator to train RL-based dialog systems in an online fashion <ref type="bibr" target="#b23">(Pietquin and Dutoit, 2006;</ref><ref type="bibr" target="#b24">Scheffler and Young, 2002;</ref><ref type="bibr" target="#b14">Li et al., 2016)</ref>. As a consequence, we construct an agenda-based user simulator, which we refer to as Sim1, to train the original RL-based system. The user action set of Sim1 is denoted as A u , which includes such in- tents 4 : "hello", "bye", "inform", "deny", "negate", "affirm", "request", "reqalts" and "null". The slots of Sim1 are shown in section 6.1. In each turn, the user action consists of a intent and slots and we append the value of slots according to the user goal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Implementation of the Original System</head><p>For the original RL-based dialog system, a feature vector x t of size 191 is extracted. This vector is the concatenation of encodings of LU results, the previous system reply, database results and the current turn number. The LU module is imple- mented with an SVM 5 for intent detection and a CRF 6 for slot filling. The language generation module is implemented by a rule-based method. The hidden dialog state representation is inferred <ref type="bibr">4</ref> A detail explanation of these intents is in DSTC2 <ref type="bibr" target="#b9">(Henderson et al., 2013)</ref>. <ref type="bibr">5</ref> We use the publicly available SVM tool at http://scikit- learn.org. <ref type="bibr">6</ref> We use the publicly available CRF tool at https://pypi.python.org/pypi/sklearn-crfsuite.</p><p>by a GRU ( <ref type="bibr" target="#b5">Chung et al., 2014</ref>). We set the hidden states of the GRU to be 120. The policy network is implemented as a Multilayer Perceptron (MLP) with one hidden layer. The size of the hidden layer is 80. The output dimension of policy network is 15, which corresponds to the number of system actions. To encourage shorter interaction, we set a small per-turn negative reward R turn = −1. The maximal turn is set to be 40. If the user goal is satisfied, the policy will be encouraged by a large positive reward R succ = 10; otherwise the policy will be penalized by a negative reward R f ail = −10. Discounted factor γ = 0.9. The baseline b of current policy is estimated on sampled episodes in a batch. The batch size N is set to be 32. Adadelta <ref type="bibr" target="#b33">(Zeiler, 2012)</ref> method is used to update model parameters. The original system S 1 is trained by interacting with Sim1. After about 2400 interactions, the performance of S 1 starts to converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Simulated Evaluation</head><p>To evaluate our approach, we design another user simulator, which we denote as Sim2, to simulate the unpredictable real customers. The user action set of Sim2 is denoted as A u . The difference between A u and A u is reflected on the domain specific intents <ref type="bibr">7</ref> . Specifically, in addition to the intents of Sim1, A u includes the "confirm" intent. The difference in user action sets will result in different interaction strategies between Sim1 and Sim2. To verify whether a recommended restau- rant meets his (her) constraints, Sim1 can only request what the value of a specific slot is, but Sim2 can request or confirm.</p><p>After obtaining the original system S 1 , we de- ploy it to interact with Sim1 and Sim2 respectively, under different LU error rates ( <ref type="bibr" target="#b13">Li et al., 2017a</ref>). In each condition, we simulate 3200 episodes to obtain the performance.  details of the test performance. <ref type="table" target="#tab_2">Table 2</ref> shows the statistics of turns when S 1 interacts with Sim2.</p><p>As shown in <ref type="table" target="#tab_3">Table 1</ref>, S 1 achieves higher dialog success rate and rewards when testing with Sim1.</p><p>When interacting with Sim2, nearly half of the responses to unsupported user actions are not reasonable. Notice even though Sim2 contains new user actions, some of the new actions might be appropriately handled by S 1 . It may be due to the robustness of our RL-based system. But it's far from being desired. The unpredictable real user behavior in the deployment stage will lead to a poor user experience in real-world applications. It proves the importance of a maintainable system.</p><p>To maintain the original system, we define a few simple logic rules to handle unsupported user actions: if users confirm the value of a slot in current turn, the system should inform users of that value. These rules 8 are intuitive and reasonable to handle queries such as "Is this restaurant located in Zhongguancun?". There are four slots 9 that can be used for confirmation, so we define four logic rules in all. Due to the change in ontology, we add a new status in dialog features to represent the "confirm" intent of users. It leads to a change in the model architecture of extended dialog manager. Then we distill knowledge of the S 1 and logic rules into the extended system. No additional data is used to obtain the extended system.</p><p>For comparison, we retrain another new sys- tem (contrast system) from scratch by interacting <ref type="bibr">8</ref> In the practical dialog system, we can inject more complex logic rules and take dialog history into account. These rules are not limited to question/answer mapping. <ref type="bibr">9</ref> They are "name", "area", "price range" and "cuisine".</p><p>with Sim2. After about 2600 interactions with Sim2, the performance of contrast system starts to converge. Note that in order to build the contrast system, the developers need to redesign a new user simulator or hire real users. It's expensive and impractical in industrial applications. Then we simulate 3200 interactions with Sim2 to obtain its performance. <ref type="figure" target="#fig_2">Fig. 4</ref> illustrates the performance of different systems. As can be seen, the extended system performs better than the original system in terms of dialog success rate and "Satis.". This is to a large degree attributed to the consideration of new user actions. <ref type="figure" target="#fig_2">Fig. 4(a)</ref> shows that the contrast system achieves higher dialog success rate than the extended sys- tem. But the gap is negligible. However, the contrast system is trained from scratch under a new interaction environment and the extended system is trained by transferring knowledge of the original system and logic rules. To train the contrast system, about 2600 episodes are sampled by interacting with a new interaction environment. But no additional data is used to train the extended system.</p><p>In <ref type="figure" target="#fig_2">Fig. 4(b)</ref>, the "Satis." of the extended system is slightly higher than the contrast system. This is due to the fact that the extended system learns how to deal with new user actions from logic rules but the contrast system obtains dialog policy by exploring the environment. As a result, the contrast system learns a more flexible dialog policy than the extended system 10 . However, the "Satis." has a bias to the suboptimal rules,   rather than the optimal policy gained from the environment. It suggests the extended system can be further refined by reinforcement learning once a new interaction environment is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Human Evaluation</head><p>In any case, the developers can't guarantee all user actions are considered. Fortunately, our method makes no assumptions about the new user actions and new dialog model architecture. As a result, the system can be extended over multiple iterations.</p><p>To evaluate this characteristic, we deploy the extended system 11 in section 6.5 to interact with real human users. Users are given a goal sam- pled from our corpus for reference. To elicit more complex situations, they are encouraged to interact with our system by new intents and slots related to the restaurant domain. At the end of each dialog, they are asked to give a subjective rating on the scale from 1 to 5 based on the naturalness of the system (1 is the worst, 5 is the best.). After filtering dialog sessions unrelated to our task, we collect 315 episodes in total. <ref type="table" target="#tab_5">Table 3</ref> shows the details of the user logs. As shown in <ref type="table" target="#tab_5">Table 3</ref>, after deployment, there are a few slots <ref type="bibr">11</ref> The extended system in the simulated evaluation will be the original system in our human evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original System</head><p>Extended System and intents unseen before. For example, users may ask for the discount information or take a taxi to the restaurant. To represent the new intents and slots, the dimension of extracted dialog features is extended to 236. Meanwhile, the number of system actions is extended to 29 to handle new user actions. To deal with the newfound user actions, we define 14 rules in total. <ref type="table" target="#tab_6">Table 4</ref> shows the details of new defined logic rules. Then we distill the knowledge of the original system and logic rules into a new system. <ref type="figure" target="#fig_3">Fig. 5</ref> shows the comparison in user ratings. The extended system significantly gets a higher subjective rating than the original one. It proves that the extended system can give reasonable responses in unseen dialog situations. <ref type="table">Table 5</ref> shows sample dialogs from the original system and extended system with real users. We can see that the extended system is much more coherent since it takes new user actions into ac- count. It inspires us that a complicated RL-based dialog system can start from a simple one and be improved incrementally based on our framework. This design pattern will be much more efficient if the interaction environment is hard to access.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we present a practical solution to maintain RL-based dialog systems without retrain- ing from scratch. By reusing existing resources, developers can extend the RL-based dialog man- ager to deal with unpredictable user actions after deployment. Furthermore, our method holds no constraints on the architecture of the new system and retains the key benefit of data-driven methods. It means the new system can be maintained it- eratively and further refined by RL once a new interaction environment is available. The sim-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original System</head><p>Extended System User: I want to find a Sichuan restaurant.</p><p>User: I want to find a Sichuan restaurant in System: Where do you want to go?</p><p>Zhongguancun area. User: Zhongguancun area.</p><p>System: "Hot Charge" is a nice Sichuan restaurant in System: "Hot Charge" is a nice Sichuan restaurant in in Zhongguancun area. Zhongguancun area.</p><p>User: What's the discount of this restaurant? User: Can you tell me the discount?</p><p>System: This restaurant is offering 10% off. System: The average cost is 42 CNY.</p><p>User: Is there a waiting line? User: Tell me the discount! System: Currently there are 5 parties waiting in line. System: "Hot Charge" is a nice Sichuan restaurant in User: Can you book a table for me? Zhongguancun area.</p><p>System: Ok. User: Bye.</p><p>User: Thanks. System: Bye.</p><p>System: You are welcome. Subjective Rating = 2 Subjective Rating = 5 <ref type="table">Table 5</ref>: Sample dialogs of the original and extended systems in the human evaluation. The original system will collapse when encountering unseen slots and intents. After extension, the new system can handle more user actions.</p><p>ulation and human experiments show our pro- posed framework guarantees the maintainability and scalability in RL-based systems, which are necessary for any industrial application.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An overview of the RL-based dialog manager used in our work 3. In the last turn, the system inquires "Where do you want to go?". In current turn, the user input is "Find a restaurant in Beihai.".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Two kinds of strategies to extend the original system. (a) means redesigning and retraining a new system in an expensive interaction environment from scratch and (b) means transferring knowledge from existing resources to a new system. The network in red indicates the old system based on the original ontology. The networks in gray and purple represent the initialized and trained dialog manager models based on a new ontology respectively. On account of the change in ontology, the extended system has a different network architecture. The dash lines in (a) and (b) show the ability of a new model derives from various sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Performance of different systems under simulation. The original, extended and contrast systems are shown in red, blue and purple bars. We test these systems by interacting with Sim2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Distribution of user ratings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 t s  t s ( | ; )</head><label></label><figDesc>introduced knowledge distillation to transfer knowledge from</figDesc><table>Policy Net 

RNN dialog state 

Inform(area=Beihai) 
Request(area) 
10 

Germy 

Victorian 

Godear 
Holiday 

Do Eat 

Database 

Query: Select * 
where 
area=Beihai 

encoding 
encoding 
encoding 

Request(price) 

sample 

s 
t 

a 

u 
t 

a 

1 

s 
t 

a  

u 
t 

o 

1 

s 
t 

o  

db 
t 

o 

t 

x 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>LU Error Rate Succ. Turn Reward Satis. Succ. Turn Reward Satis.</figDesc><table>0.00 
0.962 13.6 
3.94 
-
0.901 13.2 
2.95 
0.57 
0.05 
0.937 13.7 
3.41 
-
0.877 14.4 
2.41 
0.48 
0.10 
0.910 14.3 
2.65 
-
0.841 13.9 
1.41 
0.47 
0.20 
0.845 15.2 
0.58 
-
0.784 14.7 
0.01 
0.47 

Table 1: Performance of the original system when interacting with different user simulators. LU error means 
simulating slot errors and intent errors in different rates. Succ.: success rate, Turn: average turns, Reward: average 
reward. 

LU Error Rate 
0.00 
0.05 
0.10 
0.20 

Total 
25857 26166 27077 28385 
New User Actions 
1853 
1859 
1998 
1912 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Statistics of turns when S 1 interacts with Sim2.</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 shows the</head><label>1</label><figDesc></figDesc><table>0.00 
0.05 
0.01 
0.2 

LU Error Rate 

0.6 

0.7 

0.8 

0.9 

1.0 

Success Rate 

Original System 
Extended System 
Contrast System 

(a) Dialog success rate of different systems. 

0.00 
0.05 
0.01 
0.2 

LU Error Rate 

0.4 

0.5 

0.6 

0.7 

0.8 

0.9 

1.0 

Satis. 

Original System 
Extended System 
Contrast System 

(b) Satis. of different systems. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Details of the real user logs. Users are 
encouraged to interact with the original system by 
unsupported intents and slots. We find there are 14 user 
actions unseen before. 

Dialog Condition 
System Action 

takeTaxi 
API call 
bookTable 
API call 
inform unseen slots 
recommend a restaurant 
request unseen slots 
offer information of slots 
confirm unseen slots offer information of slots 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Different types of rules for new user actions. Left column shows the dialog context condition; Right column shows the corresponding system action. We define 14 rules in all to handle newfound intents and slots shown in Table 3.</figDesc><table></table></figure>

			<note place="foot" n="1"> The user model defines what users can do in a dialog system, including domain specific intents and slots. 2 User actions consist of intents and slots.</note>

			<note place="foot">t can be a simple n-grams representation of u t. But 3 Similar dialog model architectures can be found in recent work (Liu and Lane, 2017; Williams et al., 2017; Su et al., 2016b). But designing a dialog model architecture is not our main purpose. We focus on endowing RL-based dialog systems with maintainability and scalability. The dialog model used in our work can be replaced with the similar architectures in the related work.</note>

			<note place="foot" n="7"> A more complex situation is shown in the human evaluation.</note>

			<note place="foot" n="10"> Table 6 in the Appendix shows sample dialogs from the extended system and contrast system.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgments</head><p>The research work described in this paper has been supported by the National Key Research and Development Program of China under Grant No. 2017YFB1002103 and also supported by the Natural Science Foundation of China under Grant No. 61333018.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Do deep nets really need to be deep?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2654" to="2662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Bucilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Alexandru Niculescu-Mizil. 2006. Model compression</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="535" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Affordable on-line dialogue policy learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2190" to="2199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Agent-aware dropout dqn for safe and efficient on-line dialogue policy learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2444" to="2454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards end-to-end reinforcement learning of dialogue agents for information access</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="484" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On-line policy optimisation of spoken dialogue systems via live interaction with human subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurčíček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incremental on-line adaptation of pomdp-based dialogue managers to extended domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gašic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongho</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pirros</forename><surname>Tsiakoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Breslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings on InterSpeech</title>
		<meeting>on InterSpeech</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Dialog state tracking challenge 2 &amp; 3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Harnessing deep neural networks with logic rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2410" to="2420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning small-size dnn with outputdistribution-based criteria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Ting</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Investigation of language understanding impact for reinforcement learning based dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07055</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A user simulator for task-completion dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Zachary C Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.05688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">End-to-end task-completion neural dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01008</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bbq-networks: Efficient exploration in deep reinforcement learning for task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05715</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.06136</idno>
		<title level="m">Iterative policy learning in end-to-end trainable task-oriented neural dialog models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Humanlevel control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Reinforcement learning for spoken dialogue systems: Comparing strengths and weaknesses for practical deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Dialogon-Dialog Workshop</title>
		<meeting>Dialogon-Dialog Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Automating spoken dialogue management design using machine learning: An industry perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="716" to="729" />
		</imprint>
	</monogr>
	<note>Speech communication</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Composite task-completion dialogue policy learning via hierarchical deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2231" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A probabilistic framework for dialog simulation and optimal strategy learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Dutoit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="589" to="599" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Scheffler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international conference on Human Language Technology Research</title>
		<meeting>the second international conference on Human Language Technology Research</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="12" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive reinforcement learning for taskoriented dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pararth</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2016 Deep Learning for Action and Interaction Workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Labelfree supervision of neural networks with physics and domain knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2576" to="2582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Sample-efficient actor-critic reinforcement learning with supervised data for dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawel</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Online active reward learning for policy optimisation in spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina M Rojas</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2431" to="2441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Rojasbarahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsunghsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02689</idno>
		<title level="m">Continuously learning neural dialogue management</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hybrid code networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavosh</forename><surname>Jason D Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="665" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pomdp-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthew D Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Prior knowledge integration for neural machine translation using posterior regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1514" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
