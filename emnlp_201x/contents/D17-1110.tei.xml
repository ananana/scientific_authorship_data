<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:28+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PACRR: A Position-Aware Neural IR Model for Relevance Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MPI for Informatics Saarbrücken Graduate School of Computer Science</orgName>
								<orgName type="laboratory">MPI for Informatics Klaus Berberich htw saar MPI for Informatics Gerard de Melo Rutgers University New Brunswick</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MPI for Informatics Saarbrücken Graduate School of Computer Science</orgName>
								<orgName type="laboratory">MPI for Informatics Klaus Berberich htw saar MPI for Informatics Gerard de Melo Rutgers University New Brunswick</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PACRR: A Position-Aware Neural IR Model for Relevance Matching</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1049" to="1058"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In order to adopt deep learning for information retrieval, models are needed that can capture all relevant information required to assess the relevance of a document to a given user query. While previous works have successfully captured unigram term matches, how to fully employ position-dependent information such as proximity and term dependencies has been insufficiently explored. In this work, we propose a novel neural IR model named PACRR aiming at better modeling position-dependent interactions between a query and a document. Extensive experiments on six years&apos; TREC Web Track data confirm that the proposed model yields better results under multiple benchmarks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Despite the widespread use of deep neural mod- els across a range of linguistic tasks, to what extent such models can improve information re- trieval (IR) and which components a deep neural model for IR should include remain open ques- tions. In ad-hoc IR, the goal is to produce a rank- ing of relevant documents given an open-domain ("ad hoc") query and a document collection. A ranking model thus aims at evaluating the inter- actions between different documents and a query, assigning higher scores to documents that better match the query. Learning to rank models, like the recent IRGAN model ( <ref type="bibr" target="#b21">Wang et al., 2017)</ref>, rely on handcrafted features to encode query docu- ment interactions, e.g., the relevance scores from unsupervised ranking models. Neural IR mod- els differ in that they extract interactions directly based on the queries and documents. Many early neural IR models can be categorized as seman- tic matching models, as they embed both queries and documents into a low-dimensional space, and then assess their similarity based on such dense representations. Examples in this regard include DSSM ( <ref type="bibr" target="#b7">Huang et al., 2013</ref>) and DESM ( <ref type="bibr" target="#b15">Mitra et al., 2016)</ref>. The notion of relevance is inher- ently asymmetric, however, making it different from well-studied semantic matching tasks such as semantic relatedness and paraphrase detection. In- stead, relevance matching models such as Match- Pyramid ( <ref type="bibr" target="#b17">Pang et al., 2016</ref>), DRMM ( ) and the recent K-NRM ( <ref type="bibr" target="#b22">Xiong et al., 2017)</ref> resemble traditional IR retrieval measures in that they directly consider the relevance of documents' contents with respect to the query. The DUET model ( <ref type="bibr" target="#b14">Mitra et al., 2017</ref>) is a hybrid approach that combines signals from a local model for rel- evance matching and a distributed model for se- mantic matching. The two classes of models are fairly distinct. In this work, we focus on relevance matching models.</p><p>Given that relevance matching approaches mir- ror ideas from traditional retrieval models, the decades of research on ad-hoc IR can guide us with regard to the specific kinds of relevance sig- nals a model ought to capture. Unigram matches are the most obvious signals to be modeled, as a counterpart to the term frequencies that appear in almost all traditional retrieval models. Be- yond this, positional information, including where query terms occur and how they depend on each other, can also be exploited, as demonstrated in retrieval models that are aware of term proxim- ity ( <ref type="bibr" target="#b19">Tao and Zhai, 2007)</ref> and term dependen- cies ( <ref type="bibr" target="#b9">Huston and Croft, 2014;</ref><ref type="bibr" target="#b12">Metzler and Croft, 2005</ref>). Query coverage is another factor that can be used to ensure that, for queries with mul- tiple terms, top-ranked documents contain mul- tiple query terms rather than emphasizing only one query term. For example, given the query "dog adoption requirements", unigram matching signals correspond to the occurrences of the in- dividual terms "dog", "adoption", or "require- ments". When considering positional informa- tion, text passages with "dog adoption" or "re- quirements for dog adoption" are highlighted, dis- tinguishing them from text that only includes in- dividual terms. Query coverage, meanwhile, fur- ther emphasizes that matching signals for "dog", "adoption", and "requirements" should all be in- cluded in a document.</p><p>Similarity signals from unigram matches are taken as input by DRMM (  after being summarized as histograms, whereas K-NRM ( <ref type="bibr" target="#b22">Xiong et al., 2017</ref>) directly digests a query-document similarity matrix and summarizes it with multiple kernel functions. As for posi- tional information, both the MatchPyramid ( <ref type="bibr" target="#b17">Pang et al., 2016</ref>) and local DUET ( <ref type="bibr" target="#b14">Mitra et al., 2017</ref>) models account for it by incorporating convolu- tional layers based on similarity matrices between queries and documents. Although this leads to more complex models, both have difficulty in sig- nificantly outperforming the DRMM model ( <ref type="bibr" target="#b14">Mitra et al., 2017)</ref>. This indicates that it is non-trivial to go beyond unigrams by utilizing positional information in deep neural IR models. Intuitively, unlike in standard sequence- based models, the interactions between a query and a document are sequential along the query axis as well as along the document axis, making the problem multi-dimensional in nature. In addi- tion, this makes it non-trivial to combine match- ing signals from different parts of the documents and over different query terms. In fact, we argue that both MatchPyramid and local DUET mod- els fail to fully account for one or more of the aforementioned factors. For example, as a pio- neering work, MatchPyramid is mainly motivated by models developed in computer vision, result- ing in its disregard of certain IR-specific consider- ations in the design of components, such as pool- ing sizes that ignore the query and document di- mensions. Meanwhile, local DUET's CNN filters match entire documents against individual query terms, neglecting proximity and possible depen- dencies among different query terms.</p><p>We conjecture that a suitable combination of convolutional kernels and recurrent layers can lead to a model that better accounts for these factors. In particular, we present a novel re-ranking model called PACRR (Position-Aware Convolutional- Recurrent Relevance Matching). Our approach first produces similarity matrices that record the semantic similarity between each query term and each individual term occurring in a document. These matrices are then fed through a series of convolutional, max-k-pooling, and recurrent lay- ers so as to capture interactions corresponding to, for instance, bigram and trigram matches, and fi- nally to aggregate the signals in order to produce global relevance assessments. In our model, the convolutional layers are designed to capture both unigram matching and positional information over text windows with different lengths; k-max pool- ing layers are along the query dimension, preserv- ing matching signals over different query terms; the recurrent layer combines signals from differ- ent query terms to produce a query-document rel- evance score. Organization. The rest of this paper unfolds as follows. Section 2 describes our approach for computing similarity matrices and the architecture of our deep learning model. The setup and results of our extensive experimental evaluation can be found in Section 3, before concluding in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The PACRR Model</head><p>We now describe our proposed PACRR approach, which consists of two main parts: a relevance matching component that converts each query- document pair into a similarity matrix sim |q|×|d| and a deep architecture that takes a given query- document similarity matrix as input and produces a query-document relevance score rel (q, d). Note that in principle the proposed model can be trained end-to-end by backpropagating through the word embeddings, as in ( <ref type="bibr" target="#b22">Xiong et al., 2017)</ref>. In this work, however, we focus on highlighting the building blocks aiming at capturing positional in- formation, and freeze the word embedding layer to achieve better efficiency. The pipeline is summa- rized in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance Matching</head><p>We first encode the query-document relevance matching via query-document similarity matri- ces sim |q|×|d| that encodes the similarity be- tween terms from a query q and a document d, where sim ij corresponds to the similarity be- tween the i-th term from q and the j-th term from d. When using cosine similarity, we have  <ref type="figure">Figure 1</ref>: The pipeline of PACRR. Each query q and document d is first converted into a query-document similarity matrix sim |q|×|d| . Thereafter, a distillation method (firstk is displayed) transforms the raw similarity matrix into unified dimensions, namely, sim lq×l d . Here, l g − 1 convolutional layers (CNN) are applied to the distilled similarity matrices. As l g = 3 is shown, layers with kernel size 2 and 3 are applied. Next, max pooling is applied, leading to l g matrices C 1 · · · C lg . Following this, n s -max pooling captures the strongest n s signals over each query term and n-gram size, and the case for n s = 2 is shown here. Finally, the similarity signals from different n-gram sizes are concatenated, the query terms' normalized IDFs are added, and a recurrent layer combines these signals for each query term into a query-document relevance score rel (q, d).</p><formula xml:id="formula_0">sim ∈ [−1, 1] |q|×|d| .</formula><p>As suggested in ( <ref type="bibr" target="#b8">Hui et al., 2017)</ref>, query-document similarity matrices pre- serve a rich signal that can be used to perform relevance matching beyond unigram matches. In particular, n-gram matching corresponds to con- secutive document terms that are highly similar to at least one of the query terms. Query coverage is reflected in the number of rows in sim that include at least one cell with high similarity. The similar- ity between a query term q and document term d is calculated by taking the cosine similarity using the pre-trained 1 word2vec ( <ref type="bibr" target="#b13">Mikolov et al., 2013)</ref>. The subsequent processing in PACRR's convo- lutional layers requires that each query-document similarity matrix have the same dimensionality. Given that the lengths of queries and documents vary, we first transform the raw similarity matri- ces sim |q|×|d| into sim lq×l d matrices with uniform l q and l d as the number of rows and columns. We unify the query dimension l q by zero padding it to the maximum query length. With regard to the document dimension l d , we describe two strate- gies: firstk and kwindow.</p><p>PACRR-firstk. Akin to ( <ref type="bibr" target="#b14">Mitra et al., 2017)</ref>, the firstk distillation method simply keeps the first k columns in the matrix, which correspond to the first k terms in the document. If k &gt; |d|, the re- maining columns are zero padded. PACRR-kwindow. As suggested in ( , relevance matching is local. Document terms that have a low query similarity relative to a document's other terms cannot contribute sub- stantially to the document's relevance score. Rele- vance matching can be extracted in terms of pieces of text that include relevant information. That is, one can segment documents according to rel- evance relative to the given query and retain only the text that is highly relevant to the given query. Given this observation, we prune query-document similarity cells with a low similarity score. In the case of unigrams, we simply choose the top l d terms with the highest similarity to query terms. In the case for text snippets beyond length n, we pro- duce a similarity matrix sim n lq×l d for each query- document pair and each n, because n consecutive terms must be co-considered later on. For each text snippet with length n in the document, kwin- dow calculates the maximum similarity between each term and the query terms, and then calculates the average similarity over each n-term window. It then selects the top k = l d /n windows by av- eraging similarity and discards all other terms in the document. The document dimension is zero padded if l d /n is not a multiple of k. When the convolutional layer later operates on a similarity matrix produced by kwindow, the model's stride is set to n (i.e., the sliding window moves ahead n terms at a time rather than one term at a time) since it can consider at most n consecutive terms that are present in the original document. This variant's output is a similarity matrix sim n lq×l d for each n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Retrieval Model</head><p>Given a query-document similarity matrix sim lq×l d as input, our deep architecture relies on convolutional layers to match every text snippet with length n in a query and in a document to produce similarity signals for different n. Subsequently, two consecutive max pooling layers extract the document's strongest similarity cues for each n. Finally, a recurrent layer ag- gregates these salient signals to predict a global query-document relevance score rel (q, d).</p><p>Convolutional relevance matching over local text snippets. The purpose of this step is to match text snippets with different length from a query and a document given their query-document sim- ilarity matrix as input. This is accomplished by applying multiple two-dimensional convolutional layers with different kernel sizes to the input simi- larity matrix. Each convolutional layer is responsi- ble for a specific n; by applying its kernel on n×n windows, it produces a similarity signal for each window. When the firstk method is used, each con- volutional layer receives the same similarity ma- trix sim lq×l d as input because firstk produces the same similarity matrix regardless of the n. When the kwindow method is used, each convolutional layer receives a similarity matrix sim n lq×l d corre- sponding to the convolutional layer with a n × n kernel. We use l g −1 different convolutional layers with kernel sizes 2 × 2, 3 × 3, . . . , l g × l g , corre- sponding to bi-gram, tri-gram, . . . , l g -gram match- ing, respectively, where the length of the longest text snippet to consider is governed by a hyper- parameter l g . The original similarity matrix cor- responds to unigram matching, while a convolu- tional layer with kernel size n×n is responsible for capturing matching signals on n-term text snip- pets. Each convolutional layer applies n f differ- ent filters to its input, where n f is another hyper- parameter. We use a stride of size (1, 1) for the firstk distillation method, meaning that the convo- lutional kernel advances one step at a time in both the query and document dimensions. For the kwin- dow distillation method, we use a stride of (1, n) to move the convolutional kernel one step at a time in the query dimension, but n steps at a time in the document dimension. This ensures that the con- volutional kernel only operates over consecutive terms that existed in the original document. Thus, we end up with l g − 1 matrices C n lq×l d ×n f , and the original similarity matrix is directly employed to handle the signals over unigrams.</p><p>Two max pooling layers. The purpose of this step is to capture the n s strongest similarity signals for each query term. Measuring the similarity signals separately for each query term allows the model to consider query term coverage, while capturing the n s strongest similarity signals for each query term allows the model to consider signals from different kinds of relevance matching patterns, e.g., n-gram matching and non-contiguous matching. In prac- tice, we use a small n s to prevent the model from being biased by document length; while each sim- ilarity matrix contains the same number of doc- ument term scores, longer documents have more opportunity to contain terms that are similar to query terms. To capture the strongest n s similar- ity signals for each query term, we first perform max pooling over the filter dimension n f to keep only the strongest signal from the n f different fil- ters, assuming that there only exists one particular true matching pattern in a given n × n window, which serves different purposes compared with other tasks, such as the sub-sampling in computer vision. We then perform k-max pooling <ref type="bibr" target="#b11">(Kalchbrenner et al., 2014</ref>) over the query dimension l q to keep the strongest n s similarity signals for each query term. Both pooling steps are performed on each of the l g − 1 matrices C i from the convolu- tional layer and on the original similarity matrix, which captures unigram matching, to produce the 3-dimensional tensor P lq×lg×ns . This tensor con- tains the n s strongest signals for each query term and for each n-gram size across all n f filters.</p><p>Recurrent layer for global relevance. Finally, our model transforms the query term similarity signals in P lq×lg×ns into a single document rele- vance score rel (q, d). It achieves this by applying a recurrent layer to P, taking a sequence of vectors as input and learning weights to transform them into the final relevance score. More precisely, akin to ( , the IDF of each query term q i is passed through a softmax layer for normal- ization. Thereafter, we split up the query term dimension to produce a matrix P lg×ns for each query term q i , subsequently forming the recurrent layer's input by flattening each matrix P lg×ns into a vector by concatenating the matrix's rows to- gether and appending query term q i 's normalized IDF onto the end of the vector. This sequence of vectors for each query term q i is passed into a Long Short-Term Memory (LSTM) recurrent layer <ref type="bibr" target="#b6">(Hochreiter and Schmidhuber, 1997</ref>) with an output dimensionality of one. That is, the LSTM's input is a sequence of query term vectors where each vector is composed of the query term's nor- malized IDF and the aforementioned salient sig- nals for the query term along different kernel sizes. The LSTM's output is then used as our document relevance score rel (q, d).</p><p>Training objective. Our model is trained on triples consisting of a query q, relevant document d + , and non-relevant document d − , minimizing a standard pairwise max margin loss as in Eq. 1.</p><formula xml:id="formula_1">L(q,d + ,d − ;Θ)=max (0,1−rel(q,d + )+rel(q,d − ))<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>In this section, we empirically evaluate PACRR models using manual relevance judgments from the standard TREC Web Track. We compare them against several state-of-the-art neural IR models <ref type="bibr">2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>We rely on the widely-used 2009-2014 TREC Web Track ad-hoc task benchmarks 3 . The benchmarks are based on the CLUEWEB09 and CLUEWEB12 datasets as document collections. In total, there are 300 queries and more than 100k judgments (qrels). Three years  of query-likelihood baselines <ref type="bibr">4</ref> provided by TREC 5 serve as baseline runs in the RERANKSIMPLE benchmark. In the RERANKALL setting, the search results from runs submitted by participants from each year are also considered: there are 71 (2009), 55 Training. At each step, we perform Stochastic Gradient Descent (SGD) with a mini-batch of 32 triples. For the purpose of choosing the triples, we consider all documents that are judged with a label more relevant than Rel 7 as highly relevant, and put the remaining relevant documents into a relevant group. To pick each triple, we sample a relevance group with probability proportional to the number of documents in the group within the training set, and then we randomly sample a docu- ment with the chosen label to serve as the positive document d + . If the chosen group is the highly relevant group, we randomly sample a document from the relevant group to serve as the negative document d − . If the chosen group is the relevant group, we randomly sample a non-relevant doc- ument as d − . This sampling procedure ensures that we differentiate between highly relevant doc- uments (i.e., those with a relevance label of HRel, Key or Nav) and relevant documents (i.e., those are labeled as Rel). The training continues until a given number of iterations is reached. The model is saved at every iteration. We use the model with the best ERR@20 on the validation set to make predictions. Proceeding in a round-robin manner, we report test results on one year by exploiting the respective remaining five years (250 queries) for training. From these 250 queries, we reserve 50 random queries as a held-out set for validation and hyper-parameter tuning, while the remaining 200 queries serve as the actual training set.</p><p>As mentioned, model parameters and training iterations are chosen by maximizing the ERR@20 on the validation set. The selected model is then used to make predictions on the test data. An ex- ample of this training procedure is shown in <ref type="figure" target="#fig_1">Fig- ure 2</ref>. There are four hyper-parameters that gov- ern the behavior of the proposed PACRR-kwindow and PACRR-firstk: the unified length of the doc- ument dimension l d , the k-max pooling size n s , the maximum n-gram size l g , and the number of filters used in convolutional layers n f . Due to limited computational resources, we determine the range of hyper-parameters to consider based on pi- lot experiments and domain insights. In partic- ular, we evaluate l d ∈ <ref type="bibr">[256,</ref><ref type="bibr">384,</ref><ref type="bibr">512,</ref><ref type="bibr">640,</ref><ref type="bibr">768]</ref>, n s ∈ [1, 2, 3, 4], and l g ∈ [2, 3, 4]. Due to the limited possible matching patterns given a small kernel size (e.g., l g = 3), n f is fixed to 32. For PACRR-firstk, we intuitively desire to retain as much information as possible from the input, and thus l d is always set to 768. DRMM (DRMM LCH×IDF ), DUET, Match- Pyramid and K-NRM are trained under the same settings using the hyperparameters described in their respective papers. In particular, as our fo- cus is on the deep relevance matching model as mentioned in Section 1, we only compare against DUET's local model, denoted as DUETL. In addi- tion, K-NRM is trained slightly different from the one described in ( <ref type="bibr" target="#b22">Xiong et al., 2017)</ref>, namely, with a frozen word embedding layer. This is to guar- antee its fair comparison with other models, given that most of the compared models can be enhanced by co-training the embedding layers, whereas the focus here is the strength coming from the model architecture. A fully connected middle layer with 30 neurons is added to compensate for the reduc- tion of trainable parameters in K-NRM, mirroring the size of DRMM's first fully connected layer.</p><p>All models are implemented with Keras <ref type="bibr" target="#b4">(Chollet et al., 2015</ref>) using Tensorflow as backend, and are trained on servers with multiple CPU cores. In particular, the training of PACRR takes 35 seconds per iteration on average, and in total at most 150 iterations are trained for each model variant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>RERANKSIMPLE. We first examine the proposed model by re-ranking the search results from the QL baseline on Web Track 2012-14. The results are summarized in <ref type="table">Table 1</ref>. It can be seen that DRMM can significantly improve QL on WT12 and WT14, whereas MatchPyramid fails on WT12 under ERR@20. While DUETL and K-NRM can consistently outperform QL, the two variants of PACRR are the only models that can achieve sig- nificant improvements at a 95% significance level on all years under both ERR@20 and nDCG@20. More remarkably, by solely re-ranking the search results from QL, PACRR-firstk can already rank within the top-3 participating systems on all three years as measured by both ERR and nDCG. The re-ranked search results from PACRR-kwindow also ranks within the top-5 based on nDCG@20. On average, both PACRR-kwindow and PACRR- firstk achieve 60% improvements over QL.</p><p>RERANKALL. In this part, we would like to fur- ther examine the performance of the proposed models in re-ranking different sets of search re- sults. Thus, we extend our analysis to re-rank search results from all submitted runs from six years of the TREC Web Track ad-hoc task. In particular, we only consider the judged documents from TREC, which loosely correspond to top-20 documents in each run. The tested models make predictions for individual documents, which are used to re-rank the documents within each sub- mitted run. Given that there are about 50 runs for each year, it is no longer feasible to list the scores for each re-ranked run. Instead, we summarize the results by comparing the performance of each run before and after re-ranking, and provide statistics over each year to compare the methods under con- sideration in <ref type="table" target="#tab_6">Table 2</ref>. In the top portion of <ref type="table" target="#tab_6">Table 2</ref>, we report the relative changes in metrics before and after re-ranking in terms of percentages ("av- erage ∆ measure score"). In the bottom portion, we report the percentage of systems whose results have increased after re-ranking. Note that these results assess two different aspects: the average ∆ measure score in <ref type="table" target="#tab_6">Table 2</ref>   <ref type="table">Table 1</ref>: ERR@20 and nDCG@20 on TREC Web Track 2012-14 when re-ranking search results from QL. The comparisons are conducted between two variants of PACRR and DRMM (D/d), DUETL (L/l), MatchPyramid (M/m) and K-NRM (K/k). All methods are compared against the QL (Q/q) baseline. The upper/lower-case characters in the brackets indicate a significant difference under two-tailed paired Student's t-tests at 95% or 90% confidence levels relative to the corresponding approach. In addition, the relative ranks among all runs within the respective years according to ERR@20 and nDCG@20 are also reported directly after the absolute scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures</head><p>Tested Methods wt09 wt10 wt11 wt12 wt13 wt14</p><p>average ∆ measure score over each year (%):</p><p>re-rank score−original score original score</p><formula xml:id="formula_2">ERR@20 PACRR-firstk 66% (DLK) 362% (dm) 43% (DLM K) 76% (DLM K) 37% (DLM K) 41% (DLM K) PACRR-kwindow 70% (DLmK) 393% (DlM ) 10% (LM K) 83% (DLM K) 21% (DLM ) 36% (DLM K) DUETL 80% (DM K) 316% 15% (DM K) 64% (M ) 26% (DM ) 19% (M K) DRMM 54% (LM K) 315% 11% (LM K) 61% (M ) 5% (LM K) 19% (M K) MatchPyramid 65% (DL) 313% 2% (DLK) 48% (DLK) 29% (DLK) 14% (DLK) K-NRM 59% (DL) 333% 31% (DLM ) 63% (M ) 25% (DM ) 32% (DLM ) nDCG@20 PACRR-firstk 69% (DLM K) 304% (LM ) 56% (DLM K) 100% (DLM K) 31% (DLM K) 31% (DLM ) PACRR-kwindow 63% (DmK) 345% (DLM K) 27% (DLM K) 113% (DLM K) 23% (DLK) 30% (DLM ) DUETL 62% (DM K) 237% (DK) 17% (DM K) 55% (DM K) 17% (DM K) 10% (DM K) DRMM 49% (LM K) 274% (LM k) 8% (LM K) 70% (LM K) 9% (LM K) 15% (LK) MatchPyramid 59% (DLk) 232% (DK) 1% (DLK) 37% (DLK) 21% (DLk) 14% (LK) K-NRM 52% (DLm) 288% (dLM ) 36% (DLM ) 85% (DLM ) 19% (DLm) 30% (DLM )</formula><p>% of runs that get better performance after re-ranking     PAIRACCURACY. The ranking of documents can be decomposed into rankings of document pairs as suggested in (Radinsky and Ailon, 2011). Specif- ically, a model's retrieval quality can be examined by checking across a range of individual document pairs, namely, how likely a model can assign a higher score for a more relevant document. Thus, it is possible for us to compare different models over the same set of complete judgments, remov- ing the issue of different initial runs. Moreover, although ranking is our ultimate target, a direct in- spection of pairwise prediction results can indicate which kinds of document pairs a model succeeds at or fails on. We first convert the graded judg- ments from TREC into ranked document pairs by comparing their labels. Document pairs are cre- ated among documents that have different labels. A prediction is counted as correct if it assigns a higher score to the document from the pair that is labeled with a higher degree of relevance. The judgments from TREC contain at most six rele- vance levels, and we merge and unify the original levels from the six years into four grades, namely, Nav, HRel, Rel and NRel. We compute the ac- curacy for each pair of labels. The statistics are summarized in <ref type="table">Table 3</ref>. The volume column lists the percentage of a given label combination out of all document pairs, and the # query column provides the number of queries for which the la- bel combination exists. In <ref type="table">Table 3</ref>, we observe that both PACRR models always perform better than all baselines on label combinations HRel vs. NRel, Rel vs. NRel and Nav vs. NRel, which in to- tal cover 90% of all document pairs. Meanwhile, apart from Nav-Rel, there is no significant differ- ence when distinguishing Nav from other types. K-NRM and DRMM perform better than the other two baseline models.</p><formula xml:id="formula_3">ERR@20 PACRR-firstk 94% 95% 97% 92% 87% 100% PACRR-kwindow 97% 100% 47% 96% 65% 76% DUETL 94% 95% 61% 86% 69% 59% DRMM 82% 95% 47% 86% 40% 66% MatchPyramid 85% 93% 40% 78% 81% 59% K-NRM 87% 95% 89% 82% 67% 86% nDCG@20 PACRR-firstk 94% 100% 100% 100% 92% 93% PACRR-kwindow 93% 100% 84% 100% 81% 86% DUETL 86% 93% 69% 92% 79% 59% DRMM 86% 100% 50% 88% 62% 55% MatchPyramid 76% 93% 39% 80% 81% 69% K-NRM 94% 100% 97% 96% 81% 93%</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discussion</head><p>Hyper-parameters. As mentioned, models are selected based on the ERR@20 over validation data. Hence, it is sufficient to use a reasonable and representative validation dataset, rather than handpicking a specific set of parameter settings. However, to gain a better understanding of the influence of different hyper-parameters, we ex- plore PACRR-kwindow's effectiveness when sev- eral hyper-parameters are varied. The results when re-ranking QL search results are given in <ref type="figure" target="#fig_3">Figure 3</ref>. The results are reported based on the models with the highest validation scores after fixing certain hyper-parameters. For example, the ERR@20 in the leftmost figure is obtained when fixing l d to the values shown. The crosses in <ref type="figure" target="#fig_3">Figure 3</ref> corre- spond to the models that were selected for use on the test data, based on their validation set scores. It can be seen that the selected models are not neces- sarily the best model on the test data, as evidenced by the differences between validation and test data results, but we consistently obtain scores within a reasonable margin. Owing to space constraints, we omit the plots for PACRR-firstk.</p><p>Choice between kwindow and firstk approaches. As mentioned, both PACRR-kwindow and PACRR- firstk serve to address the variable-length chal- Figure 3: The ERR@20 of re-ranked QL with PACRR-kwindow when applying different hyper- parameters: l d , n s and l g . The x-axis reflects the settings for hyper-parameters, and the y-axis is the ERR@20. Crosses correspond to the selected models.</p><p>lenge for documents and queries, and to make the training feasible and more efficient. In general, if both training and test documents are known to be short enough to fit in memory, then PACRR-firstk can be used directly. Otherwise, PACRR-kwindow is a reasonable choice to provide comparable re- sults. Alternatively, one can regard this choice as another hyper-parameter, and make a selection based on held-out validation data.</p><p>Accuracy in PAIRACCURACY. Beyond the ob- servations in Section 3.2, we further examine the methods' accuracy over binary judgments by merging the Nav, HRel and Rel labels. The accura- cies become 73.5%, 74.1% and 67.4% for PACRR- kwindow, PACRR-firstk, and DRMM, respectively. Note that the manual judgments that indicate a document as relevant or non-relevant relative to a given query contain disagreements <ref type="bibr" target="#b2">(Carterette et al., 2008;</ref><ref type="bibr" target="#b20">Voorhees, 2000</ref>) and errors <ref type="bibr" target="#b1">(Alonso and Mizzaro, 2012)</ref>. In particular, a 64% agree- ment (cf.  <ref type="bibr" target="#b1">Alonso and Mizzaro, 2012</ref>) observed a 77% agreement relative to judgments from TREC when collecting judgments via crowd- sourcing. Therefore, the more than 73% agree- ment achieved by both PACRR methods is close to the aforementioned agreement levels among dif- ferent human assessors. However, when distin- guishing Nav, HRel, and Rel, the tested models still fall significantly short of the human judges' agreement levels. These distinctions are impor- tant for a successful ranker, especially when mea- suring with graded metrics such as ERR@20 and nDCG@20. Hence, further research is needed for better discrimination among relevant documents with different degrees of relevance. In addition, as for the distinction between Nav documents and Rel or HRel documents, we argue that since Nav actually indicates that a document mainly satisfies a navigational intent, this makes such documents qualitatively different from Rel and HRel docu- ments. Specifically, a Nav is more relevant for a user with navigational intent, whereas for other users it may in some cases be less useful than a document that directly includes highly pertinent information content. Therefore, we hypothesize that further improvements can be obtained by in- troducing a classifier for user intents, e.g., naviga- tional pages, before employing neural IR models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we have demonstrated the impor- tance of preserving positional information for neu- ral IR models by incorporating domain insights into the proposed PACRR model. In particular, PACRR captures term dependencies and proximity through multiple convolutional layers with differ- ent sizes. Thereafter, following two max-pooling layers, it combines salient signals over different query terms with a recurrent layer. Extensive ex- periments show that PACRR substantially outper- forms four state-of-the-art neural IR models on TREC Web Track ad-hoc datasets and can dramat- ically improve search results when used as a re- ranking model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, including DRMM (Guo et al., 2016), DUET (Mitra et al., 2017), MatchPyramid (Pang et al., 2016), and K-NRM (Xiong et al., 2017). The comparisons are over three task settings: re- ranking search results from a simple initial ranker (RERANKSIMPLE); re-ranking all runs from the TREC Web Track (RERANKALL); and examining neural IR models' classification accuracy between document pairs (PAIRACCURACY).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The training loss, ERR@20 and nDCG@20 per iteration on validation data when training on Web Track 2010-14. The x-axis denotes the iterations. The y-axis indicates the ERR@20/nDCG@20 (left) and the loss (right). The best performance appears on 109th iteration with ERR@20=0.242. The lowest training loss (0.767) occurs after 118 iterations.</figDesc><graphic url="image-3.png" coords="5,318.19,62.81,196.43,147.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 :</head><label>2</label><figDesc>The average statistics when re-ranking all runs from the TREC Web Track 2009-14 based on ERR@20 and nDCG@20. The average differences of the scores for individual runs are reported in the top portion. The comparisons are conducted between two variants of PACRR and DRMM (D/d), DUETL (L/l), MatchPyramid (M/m) and K-NRM (K/k). The upper/lower-case characters in parentheses indicate a significant difference under two-tailed paired Student's t-tests at 95% or 90% confidence levels, respectively, relative to the corresponding approach. The percentage of runs that show improvements in terms of a measure is summarized in the bottom portion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 :</head><label>3</label><figDesc>Comparison among tested methods in terms of accuracy when comparing document pairs with different labels. The "volume" column indicates the percentage of occurrences of each label combination out of the total pairs. The "# Queries" column records the number of queries that include a particular label combination. The comparisons are conducted between two variants of PACRR and DRMM (D/d), DUETL (L/l), MatchPyramid (M/m) and K-NRM (K/k). The upper/lower-case characters in parentheses indicate a significant difference under two-tailed paired Student's t-tests at 95% or 90% confidence levels, respectively, relative to the corresponding approach. In the last row, the average accuracy among different kinds of label combinations is computed, weighted by their corresponding volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>í µí± í µí±í µí± |%|×|'|</head><label>í</label><figDesc></figDesc><table>í µí° ¶í µí±í µí± *×* ⋯ í µí° ¶í µí±í µí± , -×, -

í µí° ¶ , . ×, / ×0 1 

* 

⋯ í µí° ¶ , . ×, / ×0 1 

, -

í µí±í µí±í µí±¥ í µí±í µí±í µí±í µí±í µí±í µí±í µí± í µí±í µí±í µí±í µí±¡í µí±í µí±í µí± 
í µí± &gt; -í µí±í µí±í µí±¥ í µí±í µí±í µí±í µí±í µí±í µí±í µí± 

í µí± , . ×, -×0 @ 

í µí± í µí±í µí± , . ×, / 

í µí° ¶ , . ×, / ×A 

A 

í µí° ¶ , . ×, / ×A 

A 

⋯ í µí° ¶ , . ×, / ×A 

, -

í µí± í µí±í µí±í µí±¡í µí±í µí±í µí±¥(í µí°¼í µí°·í µí°¹ , . ×A ) 

í µí±
í µí±í µí±í µí±¢í µí±í µí±í µí±í µí±í µí±¡ í µí°¿í µí±í µí±¦í µí±í µí± 

í µí±
í µí±í µí±(í µí±, í µí±) 

í µí° ¶í µí±í µí±í µí±í µí±í µí±¡í µí±í µí±í µí±í µí±¡í µí±í µí±í µí± 

⋯ 

⋯ 

⋯ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>captures the degree to which a model can improve an initial run, while</figDesc><table>Measure 

Years 
PACRR-firstk 
Rank PACRR-kwindow Rank DUETL Rank DRMM Rank MatchPyramid Rank K-NRM Rank 
QL 
Rank 

ERR@20 

wt12 
0.318 (mQ) 
2 
0.313 (M Q) 
4 
0.281 (Q) 
10 
0.289 (Q) 
10 
0.227 
16 
0.258 (Q) 
12 
0.177 
26 
wt13 
0.166 (DKQ) 
3 
0.139 (Q) 
14 
0.147 (Q) 
12 
0.124 
25 
0.141 (q) 
13 
0.134 (q) 
14 
0.101 
38 
wt14 
0.221 (LM Q) 
2 
0.208 (Q) 
3 
0.179 (Q) 
12 
0.193 (Q) 
10 
0.176 (Q) 
12 
0.201 (Q) 
8 
0.131 
25 

nDCG@20 

wt12 0.243 (DLM Q) 
2 
0.250 (DLM Q) 
2 
0.186 (Q) 
11 
0.197 (Q) 
8 
0.164 (Q) 
16 
0.222 (Q) 
4 
0.106 
39 
wt13 
0.295 (DLkQ) 
3 
0.279 (DQ) 
4 
0.248 (q) 
11 
0.228 
20 
0.258 (Q) 
7 
0.251 (Q) 
11 
0.190 
36 
wt14 
0.339 (LM Q) 
1 
0.331 (LM Q) 
1 
0.267 (q) 
11 
0.300 (Q) 
6 
0.278 (Q) 
10 
0.324 (Q) 
2 
0.231 
23 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 2 (</head><label>2</label><figDesc></figDesc><table>b) therein) is observed over 
the inferred relative order among document pairs 
based on graded judgments from six trained 
judges (Carterette et al., 2008). When reproducing 
TREC judgments, Al-Maskari et al. (Al-Maskari 
et al., 2008) reported a 74% agreement (cf. Ta-
ble 1 therein) with the original judgments from 
TREC when a group of users re-judged 56 queries 
on the TREC-8 document collections. Meanwhile, 
Alonso and Mizzaro (</table></figure>

			<note place="foot" n="1"> https://code.google.com/archive/p/ word2vec/</note>

			<note place="foot" n="2"> We also attempted to include IRGAN (Wang et al., 2017) model as a baseline, but failed to obtain reasonable results when training on TREC data. 3 http://trec.nist.gov/tracks.html 4 Terrier (Ounis et al., 2006) version without filtering spam documents 5 https://github.com/trec-web/ trec-web-2014</note>

			<note place="foot" n="6"> http://trec.nist.gov/data/web/12/gdeval.pl 7 Judgments from TREC include junk pages (Junk), nonrelevance (NRel), relevance (Rel), high relevance (HRel), key pages (Key) and navigational pages (Nav).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Relevance judgments between trec and nontrec assessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azzah</forename><surname>Al-Maskari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 31st annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="683" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using crowdsourcing for trec relevance assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Mizzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">formation Processing &amp; Management</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1053" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Here or there: Preference Judgments for Relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Maxwell</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="16" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Expected reciprocal rank for graded relevance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metlzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Grinspan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM conference on Information and knowledge management, CIKM &apos;09</title>
		<meeting>the 18th ACM conference on Information and knowledge management, CIKM &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="621" to="630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;13</title>
		<meeting>the 22Nd ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Position-aware representations for relevance matching in neural information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion</title>
		<meeting>the 26th International Conference on World Wide Web Companion</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="799" to="800" />
		</imprint>
	</monogr>
	<note>ternational World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comparison of retrieval models using term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Huston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014-11-03" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaana</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.2188</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A markov random field model for term dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="472" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW 2017</title>
		<meeting>WWW 2017</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A dual embedding space model for document ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.01137</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Terrier: A high performance and scalable information retrieval platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the OSIR Workshop</title>
		<meeting>the OSIR Workshop</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A study of matchpyramid models on ad-hoc retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno>abs/1606.04648</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ranking from pairs and triplets: Information quality, evaluation methods and query complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM &apos;11</title>
		<meeting>the Fourth ACM International Conference on Web Search and Data Mining, WSDM &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An exploration of proximity measures in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="295" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Variations in relevance judgments and the measurement of retrieval effectiveness. Information processing &amp; management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="697" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Irgan: A minimax game for unifying generative and discriminative information retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benyou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dell</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10513</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06613</idno>
		<title level="m">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
