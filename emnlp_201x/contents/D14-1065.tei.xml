<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic-Based Multilingual Document Clustering via Tensor Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Romeo</surname></persName>
							<email>sromeo@dimes.unical.it</email>
							<affiliation key="aff0">
								<orgName type="department">DIMES</orgName>
								<orgName type="institution">University of Calabria Arcavacata di Rende</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Tagarelli</surname></persName>
							<email>tagarelli@dimes.unical.it</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">IRSTEA</orgName>
								<orgName type="institution" key="instit2">UMR TETIS Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Ienco</surname></persName>
							<email>dino.ienco@irstea.fr</email>
							<affiliation key="aff2">
								<orgName type="institution">LIRMM Montpellier</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic-Based Multilingual Document Clustering via Tensor Modeling</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="600" to="609"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A major challenge in document clustering research arises from the growing amount of text data written in different languages. Previous approaches depend on language-specific solutions (e.g., bilingual dictionaries, sequential machine translation) to evaluate document similarities, and the required transformations may alter the original document semantics. To cope with this issue we propose a new document clustering approach for multilingual corpora that (i) exploits a large-scale multilingual knowledge base, (ii) takes advantage of the multi-topic nature of the text documents, and (iii) employs a tensor-based model to deal with high dimensionality and sparseness. Results have shown the significance of our approach and its better performance w.r.t. classic document clustering approaches, in both a balanced and an unbalanced corpus evaluation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Document clustering research was initially focused on the development of general purpose strategies to group unstructured text data. Recent studies have started de- veloping new methodologies and algorithms that take into account both linguistic and topical characteristics, where the former include the size of the text and the type of language, and the latter focus on the commu- nicative function and targets of the documents.</p><p>A major challenge in document clustering research arises from the growing amount of text data that are written in different languages, also due to the increased popularity of a number of tools for collaboratively edit- ing through contributors across the world. Multilingual document clustering (MDC) aims to detect clusters in a collection of texts written in different languages. This can aid a variety of applications in cross-lingual infor- mation retrieval, including statistical machine transla- tion and corpora alignment.</p><p>Existing approaches to MDC can be divided in two broad categories, depending on whether a parallel cor- pus rather than a comparable corpus is used ( <ref type="bibr">Kumar et al., 2011c)</ref>. A parallel corpus is typically comprised of documents with their related translations ( <ref type="bibr" target="#b8">Kim et al., 2010</ref>). These translations are usually obtained through machine translation techniques based on a se- lected anchor language. Conversely, a comparable cor- pus is a collection of multilingual documents written over the same set of classes <ref type="bibr" target="#b20">(Ni et al., 2011;</ref><ref type="bibr" target="#b30">Yogatama and Tanaka-Ishii, 2009</ref>) without any restric- tion about translation or perfect correspondence be- tween documents. To mine this kind of corpus, external knowledge is employed to map concepts or terms from a language to another <ref type="bibr">(Kumar et al., 2011c;</ref><ref type="bibr">Kumar et al., 2011a)</ref>, which enables the extraction of cross- lingual document correlations. In this case, a major issue lies in the definition of a cross-lingual similarity measure that can fit the extracted cross-lingual correla- tions. Also, from a semi-supervised perspective, other works attempt to define must-link constraints to de- tect cross-lingual clusters <ref type="bibr" target="#b30">(Yogatama and Tanaka-Ishii, 2009</ref>). This implies that, for each different dataset, the set of constraints needs to be redefined; in general, the final results can be negatively affected by the quantity and the quality of involved constraints ( <ref type="bibr" target="#b5">Davidson et al., 2006</ref>).</p><p>To the best of our knowledge, existing clustering ap- proaches for comparable corpora are customized for a small set (two or three) of languages ( <ref type="bibr" target="#b16">Montalvo et al., 2007</ref>). Most of them are not generalizable to many languages as they employ bilingual dictionaries and the translation is performed sequentially considering only pairs of languages. Therefore, the order in which this process is done can seriously impact the results. Another common drawback concerns the way most of the recent approaches perform their analysis: the various languages are analyzed independently of each other (possibly by exploiting external knowledge like Wikipedia to enrich documents ( <ref type="bibr">Kumar et al., 2011c;</ref><ref type="bibr">Kumar et al., 2011a)</ref>), and then the language-specific results are merged. This two-step analysis however may fail in profitably exploiting cross-language infor- mation from the multilingual corpus.</p><p>Contributions. We address the problem of MDC by proposing a framework that features three key ele- ments, namely: (1) to model documents over a unified conceptual space, with the support of a large-scale mul- tilingual knowledge base; (2) to decompose the mul- tilingual documents into topically-cohesive segments; and (3) to describe the multilingual corpus under a multi-dimensional data structure.</p><p>The first key element prevents loss of information due to the translation of documents from different lan- guages to a target one. It enables a conceptual represen- tation of the documents in a language-independent way preserving the content semantics. <ref type="bibr">BabelNet (Navigli and Ponzetto, 2012a</ref>) is used as multilingual knowl- edge base. To the extent of our knowledge, this is the first work in MDC that exploits BabelNet.</p><p>The second key element, document segmentation, enables us to simplify the document representation according to their multi-topic nature. Previous re- search has demonstrated that a segment-based ap- proach can significantly improve document clustering performance <ref type="bibr" target="#b26">(Tagarelli and Karypis, 2013)</ref>. More- over, the conceptual representation of the document segments enables the grouping of linguistically dif- ferent (portions of) documents into topically coherent clusters.</p><p>The latter aspect is leveraged by the third key ele- ment of our proposal, which relies on a tensor-based model ( <ref type="bibr" target="#b9">Kolda and Bader, 2009)</ref> to effectively handle the high dimensionality and sparseness in text. Ten- sors are considered as a multi-linear generalization of matrix factorizations, since all dimensions or modes are retained thanks to multi-linear structures which can produce meaningful components. The applicability of tensor analysis has recently attracted growing atten- tion in information retrieval and data mining, including document clustering (e.g., ( <ref type="bibr" target="#b14">Liu et al., 2011;</ref><ref type="bibr" target="#b23">Romeo et al., 2013)</ref>) and cross-lingual information retrieval (e.g., <ref type="bibr" target="#b2">(Chew et al., 2007)</ref>).</p><p>The rest of the paper is organized as follows. Sec- tion 2 provides an overview of BabelNet and basic no- tions on tensors. We describe our proposal in Section 3. Data and experimental settings are described in Sec- tion 4, while results are presented in Section 5. We summarize our main findings in Section 6, finally Sec- tion 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">BabelNet</head><p>BabelNet ( <ref type="bibr">Navigli and Ponzetto, 2012a</ref>) is a multilin- gual semantic network obtained by linking Wikipedia with WordNet, that is, the largest multilingual Web en- cyclopedia and the most popular computational lex- icon. The linking of the two knowledge bases was performed through an automatic mapping of WordNet synsets and Wikipages, harvesting multilingual lexi- calization of the available concepts through human- generated translations provided by the Wikipedia inter- language links or through machine translation tech- niques. The result is an encyclopedic dictionary con- taining concepts and named entities lexicalized in 50 different languages.</p><p>Multilingual knowledge in BabelNet is represented as a labeled directed graph in which nodes are concepts or named entities and edges connect pairs of nodes through a semantic relation. Each edge is labeled with a relation type (is-a, part-of, etc.), while each node corre- sponds to a BabelNet synset, i.e., a set of lexicalizations of a concept in different languages.</p><p>BabelNet can be accessed and easily integrated into applications by means of a Java API provided by the toolkit described in <ref type="bibr">(Navigli and Ponzetto, 2012b</ref>). The toolkit also provides functionalities for graph- based WSD in a multilingual context. Given an in- put set of words, a semantic graph is built by looking for related synset paths and by merging all them in a unique graph. Once the semantic graph is built, the graph nodes can be scored with a variety of algorithms. Finally, this graph with scored nodes is used to rank the input word senses by a graph-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tensor model representation</head><p>A tensor is a multi-dimensional array T ∈ I1×I2×···×I M . The number of dimensions M , also known as ways or modes, is called order of the ten- sor, so that a tensor with order M is also said a M - way or M -order tensor. A higher-order tensor (i.e., a tensor with order three or higher) is denoted by bold- face calligraphic letters, e.g., T ; a matrix (2-way ten- sor) is denoted by boldface capital letters, e.g., U; a vector (1-way tensor) is denoted by boldface low- ercase letters, e.g., v. The generic entry (i 1 , i 2 , i 3 ) of a third-order tensor T is denoted by t i1i2i3 , with</p><formula xml:id="formula_0">i 1 ∈ [1..I 1 ], i 2 ∈ [1..I 2 ], i 3 ∈ [1..I 3 ].</formula><p>A one-dimensional fragment of tensor, defined by varying one index and keeping the others fixed, is a 1-way tensor called fiber. A third-order tensor has column, row and tube fibers. Analogously, a two- dimensional fragment of tensor, defined by varying two indices and keeping the rest fixed, is a 2-way tensor called slice. A third-order tensor has horizontal, lateral and frontal slices.</p><p>The mode-m matricization of a tensor T , denoted by T (m) , is obtained by arranging the mode-m fibers as columns of a matrix. A third-order tensor T ∈ I1×I2×I3 is all-orthogonal if i1i2 t i1i2α t i1i2β = i1i3 t i1αi3 t i1βi3 = i2i3 t αi2i3 t βi2i3 = 0 when- ever α = β. The mode-m product of a tensor T ∈ I1×I2×···×I M with a matrix U ∈ J×Im , denoted by</p><formula xml:id="formula_1">T × m U, is a tensor of dimension I 1 × . . . I m−1 × J × I m+1 × · · · × I M and can be expressed in terms of matrix product as Y = T × m U, whose mode-m matricization is Y (m) = UT (m) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Proposal</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multilingual Document Clustering framework</head><p>We are given a collection of multilingual documents</p><formula xml:id="formula_2">D = L l=1 D l , where each D l = {d li } N l i=1</formula><p>represents a subset of documents written in the same language, with N = L l=1 N l = |D|. Our framework can be applied to any multilingual document collection regardless of the languages, and can deal with balanced as well as <ref type="bibr">Algorithm 1 SeMDocT (Segment-based MultiLingual Document Clustering via Tensor Modeling)</ref> Input: A collection of multilingual documents D, the num- ber k of segment clusters, the number of tensorial com- ponents r. Output: A document clustering solution C over D.</p><p>1: Apply a text segmentation algorithm over each of the documents in D to produce a collection of document seg- ments S. /* Section 3.1.1 */ 2: Represent S in either a bag-of-words (BoW) or a bag-of- synsets (BoS) space. /* Section 3.1.2 */ 3: Apply any document clustering algorithm on S to obtain a segment clustering</p><formula xml:id="formula_3">C S = {C s i } k i=1</formula><p>. /* Section 3.1.2 */ 4: Represent C S in either a bag-of-words (BoW) or a bag- of-synsets (BoS) space. /* Section 3.1.3 */ 5: Model S as a third-order tensor T ∈ I 1 ×I 2 ×I 3 , with I1 = |D|, I2 = |F|, and I3 = k. /* Section 3.1.4 */ 6: Decompose the tensor using a Truncated HOSVD.</p><p>/* Section 3.1.4 */ 7: Apply a document clustering algorithm on the mode-1 factor matrix to obtain the final clusters of documents</p><formula xml:id="formula_4">C = {Ci} K i=1 . /* Section 3.1.5 */</formula><p>unbalanced corpora. Therefore, no restriction is given on both the number L of languages and the distribution of documents over the languages (i.e.,</p><formula xml:id="formula_5">N i N j , with i, j = 1..L, i = j).</formula><p>Real-world documents often span multiple topics. We assume that each document in D is relatively long to be comprised of smaller textual units, or segments, each of which can be considered cohesive w.r.t. a topic over the document. This represents a key aspect in our framework as it enables the use of a tensor model to conveniently address the multi-faceted nature of the documents.</p><p>Our overall framework, named SeMDocT (Segment- based MultiLingual Document Clustering via Tensor Modeling), is shown in Algorithm 1. In the following, we shall describe in details each of the steps involved in SeMDocT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Computing within-document segments</head><p>Text segmentation is concerned with the fragmentation of an input text into multi-paragraph, contiguous and disjoint blocks that represent subtopics. Regardless of the presence of logical structure clues in the document, linguistic criteria ( <ref type="bibr" target="#b1">Beeferman et al., 1999</ref>) and statis- tical similarity measures <ref type="bibr" target="#b7">(Hearst, 1997;</ref><ref type="bibr" target="#b3">Choi et al., 2001;</ref><ref type="bibr" target="#b4">Cristianini et al., 2001</ref>) have been mainly used to detect subtopic boundaries between segments. A com- mon assumption is that terms that discuss a subtopic tend to co-occur locally, and a switch to a new subtopic is detected by the ending of co-occurrence of a given set of terms and the beginning of the co-occurrence of another set of terms.</p><p>Our SeMDocT does not depend on a specific algo- rithmic choice to perform text segmentation; in this work, we refer to the classic TextTiling (Hearst, 1997), which is the exemplary similarity-block-based method for text segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Inducing document segment clusters</head><p>The result of the previous step is a collection of doc- ument segments, henceforth denoted as S. Each seg- ment in S is represented as a vector of feature oc- currences, where a feature can be either lexical or se- mantic. This corresponds to two alternative represen- tation models: the standard bag-of-words (henceforth BoW), whereby features correspond to lemmatized, non-stopword terms, and the obtained feature space results from the union of the vocabularies of the dif- ferent languages; and bag-of-synsets (henceforth BoS), whereby features correspond to BabelNet synsets. We shall devote Section 3.2 to a detailed description of our proposed BoS representation.</p><p>The segment collection S is given in input to a doc- ument clustering algorithm to produce a clustering of the segments</p><formula xml:id="formula_6">C S = {C s i } k i=1</formula><p>. The obtained clusters of segments can be disjoint or overlapping. Again, our SeMDocT is parametric to the clustering algorithm as well; here, we resort to a state-of-the-art clustering al- gorithm, namely Bisecting K-Means ( <ref type="bibr" target="#b25">Steinbach et al., 2000</ref>), which is widely known to produce high-quality (hard) clustering solutions in high-dimensional, large datasets ( <ref type="bibr" target="#b31">Zhao and Karypis, 2004</ref>). Note however that it requires as input the number of clusters. To cope with this issue, we adopt the method described in ( <ref type="bibr" target="#b24">Salvador and Chan, 2004</ref>), which explores how the within-cluster cohesion changes by varying the number of clusters. The number of clusters for which the slope of the plot changes drastically is chosen as a suitable value for the clustering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Segment-cluster based representation</head><p>Upon the segment clustering, each document is repre- sented by its segments assigned to possibly multiple segment clusters. Therefore, we derive a document- feature matrix for each of the k segment clusters. The features correspond either to the BoW or BoS model, according to the choice made for the segment represen- tation.</p><p>Let us denote with F the feature space for all seg- ments in S. Given a segment cluster C s , the cor- responding document-feature matrix is constructed as follows. The representation of each document d ∈ D w.r.t. C s is a vector of length |F| that results from the sum of the feature vectors of the d's segments belong- ing to C s . Moreover, in order to weight the appearance of a document in a cluster based on its segment-based portion covered in the cluster, the document vector of d w.r.t. C s is finally obtained by multiplying the sum of the segment-vectors by a scalar representing the portion of d's features that appear in the segments belonging to C s . The document-feature matrix of C s resulting from the previous step is finally normalized by column.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Tensor model and decomposition</head><p>The document-feature matrices corresponding to the k segment-clusters are used to form a third-order tensor. Our third-order tensor model is built by arranging as frontal slices the k segment-cluster matrices. The resulting tensor will be of the form T ∈ I1×I2×I3 , with I 1 = |D|, I 2 = |F|, and I 3 = k. The proposed tensor model is sketched in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>The resulting tensor is decomposed through a Trun- cated Higher Order SVD (T-HOSVD) ( <ref type="bibr" target="#b13">Lathauwer et al., 2000</ref>) in order to obtain a low-dimensional rep- resentation of the segment-cluster-based representation of the document collection. The T-HOSVD can be con- sidered as an extension of the Truncated Singular Value Decomposition (T-SVD) to the case of three or more dimensions. For a third-order tensor T ∈ I1×I2×I3 the T-HOSVD is expressed as</p><formula xml:id="formula_7">T ≈ X × 1 U (1) × 2 U (2) × 3 U (3) where U (m) = [u (m) 1 u (m) 2 . . . u (m)</formula><p>rm ] ∈ Im×rm (m = 1, 2, 3) are orthogonal matrices, r m I m , and the core tensor X ∈ r1×r2×r3 is an all-orthogonal and ordered tensor. T-HOSVD can be computed in two steps:</p><p>1. For m ∈ {1, 2, 3}, compute the unfolded ma- trices T (m) from T and related standard SVD:</p><formula xml:id="formula_8">T (m) = U (m) S (m) V (m) . The orthogonal matrix U (m)</formula><p>contains the leading left singular vectors of T (m) .</p><p>2. Compute the core tensor X using the inversion formula:</p><formula xml:id="formula_9">X = T × 1 U (1) T × 2 U (2) T × 3 U (3) T .</formula><p>Note that, since T-HOSVD is computed by means of 3 standard matrix T-SVDs, its computational cost can be reduced by using fast and efficient SVD algorithms. Moreover, the ability of T-HOSVD in effectively cap- turing the variation in each of the modes independently from the other ones, is particularly important to alle- viate the problem of concentration of distances, thus making T-HOSVD well-suited to clustering purposes. In this work, in order to obtain a final clustering so- lution of the documents, we will consider the mode-1 factor matrix U (1) of the T-HOSVD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.5">Document clustering</head><p>The mode-1 factor matrix is provided in input to a clus- tering method to obtain a final organization of the doc- uments into K clusters, i.e., C = {C i } K i=1 . Note that there is no principled relation between the number K of final document clusters and k. However, K is expected to reflect the number of topics of interest for the docu- ment collection. Also, possibly but not necessarily, the same clustering algorithm used for the segment cluster- ing step (i.e., Bisecting K-Means) can be employed for this step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bag-of-synset representation</head><p>In the BoS model, our objective is to represent the doc- ument segments in a conceptual feature space instead of the traditional term space. Since we deal with mul- tilingual documents, this task clearly relies on the mul- tilingual lexical knowledge base functionalities of Ba- belNet. Conceptual features will hence correspond to BabelNet synsets.</p><p>The segment collection S is subject to a two-step processing phase. In the first step, each segment is broken down into a set of lemmatized and POS-tagged sentences, in which each word is replaced with re- lated lemma and associated POS-tag. Let us denote with w, P OS(w) a lemma and associated POS-tag occurring in any sentence sen of the segment. In the second step, a WSD method is applied to each pair w, P OS(w) to detect the most appropriate Babel- Net synset σ w for w, P OS(w) contextually to sen. The WSD algorithm is carried out in such a way that all words from all languages are disambiguated over the same concept inventory, producing a language- independent feature space for the whole multilingual corpus. Each segment is finally modeled as a |BS|- dimensional vector of BabelNet synset frequencies, be- ing BS the set of retrieved BabelNet synsets.</p><p>As previously discussed in Section 2.1, BabelNet provides WSD algorithms for multilingual corpora. More specifically, the authors in ( <ref type="bibr">Navigli and Ponzetto, 2012b</ref>) suggest to use the Degree algorithm <ref type="bibr" target="#b17">(Navigli and Lapata, 2010)</ref>, as it showed to yield highly com- petitive performance in a multilingual context as well. Note that the Degree algorithm, given a semantic graph for the input context, simply selects the sense of the tar- get word with the highest vertex degree. Clearly, other graph-based methods for (unsupervised) WSD, partic- ularly PageRank-style methods (e.g., <ref type="bibr" target="#b15">(Mihalcea et al., 2004;</ref><ref type="bibr" target="#b29">Yeh et al., 2009;</ref><ref type="bibr" target="#b27">Tsatsaronis et al., 2010)</ref>), can be plugged in to address the multilingual WSD task based on BabelNet. An investi- gation of the performance of existing WSD algorithms for a multilingual context is however out of the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Methodology</head><p>In order to evaluate our proposal we need a multilin- gual comparable document collection with annotated <ref type="table" target="#tab_0">C15 -PERFORMANCE  850  850  850  C18 -OWNERSHIP CHANGES  850  850  850  E11 -ECONOMIC PERFORMANCE  850  850  850  E12 -MONETARY/ECONOMIC  850  850  850  M11 -EQUITY MARKETS  850  850  850  M13 -MONEY MARKETS  850  850  850  Total  5 100  5 100  5 100  Unbalanced Corpus  C15 -PERFORMANCE  850  850  0  C18 -OWNERSHIP CHANGES  850  850  0  E11 -ECONOMIC PERFORMANCE  0  850  850  E12 -MONETARY/ECONOMIC  850  0  850  M11 -EQUITY MARKETS  0  850  850  M13 -MONEY MARKETS  850  0  850  Total  3 400  3 400</ref> 3 400   <ref type="bibr">1</ref> In the following, we present the corpus characteristics and competing methods used in our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RCV2 Topics English French Italian Balanced Corpus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data preparation</head><p>We consider a subset of the RCV2 corpus correspond- ing to three languages: English, French and Italian. It covers six different topics, i.e., different labels of the RCV2 TOPICS field. Topics are chosen accord- ing with their coverage in the different languages. The language-specific documents were lemmatized and POS-tagged through the Freeling library <ref type="bibr" target="#b21">(Padró and Stanilovsky, 2012</ref>) in order to obtain a suitable rep- resentation for the WSD process.</p><p>To assess the robustness of our proposal, we de- sign two different scenarios. The first (Balanced Cor- pus) is characterized by a completely balanced dataset. Each language covers all topics and for each pair lan- guage/topic the same number of documents is selected. The second scenario corresponds to an Unbalanced Corpus. Starting from the balanced corpus, we re- moved for each topic all the documents belonging to one language. In this way, we obtained a corpus in which each topic is covered by only two of the three languages.</p><p>Main characteristics of both evaluation corpora are reported in <ref type="table" target="#tab_0">Table 1 and Table 2</ref>   As our proposal explicitly models document seg- ments, we also report statistics, considering both topics and languages, related to the average number of seg- ments per document <ref type="table" target="#tab_3">(Table 3)</ref>, and the average length of segments per document <ref type="table" target="#tab_4">(Table 4)</ref>. The latter statistic is computed separately for BoW and BoS representa- tions. We made this distinction because a term cannot have a mapping to a synset, or it can be mapped to more than one synset in the BoS space during the WSD pro- cess (Section 3.2).</p><p>Looking at the average number of segments per doc- ument in <ref type="table" target="#tab_3">Table 3</ref>, it can be noted that English docu- ments contain, for all topics, a larger number of seg- ments. This means that English documents are gener- ally richer than the ones in the other languages. Ital- ian language corresponds to the smallest documents, each of them containing between 2 and 3.2 segments on average. A sharper difference appears in the MONE- TARY/ECONOMIC topic for which English documents contain 5.2 segments, while the Italian ones are com- posed, on average, by only 2 segments. <ref type="table" target="#tab_4">Table 4</ref> shows the average length of segments per document for both space representations. Generally, segments in the BoS representation are smaller than the corresponding segments in the BoW space. More in de- tail, if we consider the ratio between the segment length in BoS and the one in BoW, this ratio is around 2/3 for the English language, while for both French and Ital- ian it varies between 1/4 and 1/3. This disequilibrium is induced by the multilingual concept coverage of Ba- belNet, as stated by its authors <ref type="bibr">(Navigli and Ponzetto, 2012a)</ref>, <ref type="bibr">(Navigli and Ponzetto, 2012b</ref>). In particular, the WSD process tightly depends from the concept cov- erage supplied from the language-specific knowledge base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Competing methods and settings</head><p>We compare our SeMDocT with two standard ap- proaches, namely Bisecting K-Means ( <ref type="bibr" target="#b25">Steinbach et al., 2000</ref>), and Latent Semantic Analysis (LSA)-based doc- ument clustering (for short, LSA). Given a number K of desired clusters, Bisecting K-Means produces a K- way clustering solution by performing a sequence of K-1 repeated bisections based on standard K-Means algorithm. This process continues until the number K of clusters is found. LSA performs a decomposition of the document collection matrix through Singular Value Decomposition in order to extract a more concise and descriptive representation of the documents. After this step, Bisecting K-Means is applied over the new docu- ment space to get the final document clustering.</p><p>All the three methods, SeMDocT, Bisecting K- Means and LSA are coupled with either BoS or BoW representation models. The comparison between BoS and BoW representations allows us to evaluate the presumed benefits that can be derived by exploiting synsets instead of terms for the multilingual document clustering task.</p><p>Both SeMDocT and LSA require the number of com- ponents as input; as concerns specifically SeMDocT, we varied r 1 (cf. Section 3.1.4) from 2 to 30, with in- crements of 2. To determine the number of segment clusters k, we employed an automatic way as discussed in Section 3.1.2. By varying k from 2 to 40, for Bal- anced Corpus and Unbalanced Corpus, respectively, the values of k obtained were 22 and 23 under BoS, and 25 and 11 under BoW.</p><p>As concerns the step of text segmentation, TextTiling requires the setting of some interdependent parameters, particularly the size of the text unit to be compared and the number of words in a token sequence. We used the setting suggested in <ref type="bibr" target="#b7">(Hearst, 1997)</ref> and also confirmed in <ref type="bibr" target="#b26">(Tagarelli and Karypis, 2013)</ref>, i.e., 10 for the text unit size and 20 for the token-sequence size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Assessment criteria</head><p>Performance of the different methods are evaluated us- ing two standard clustering validation criteria, namely F-Measure and Rand Index.</p><p>Given a document collection D, let Γ = {Γ j } H j=1</p><p>and C = {C i } K i=1 denote a reference classification and a clustering solution for D, respectively. The lo- cal precision and the local recall of a cluster C i w.r.t. a class Γ j are defined as P ij = |C i ∩ Γ j |/|C i | and R ij = |C i ∩ Γ j |/|Γ j |, respectively. F-Measure (FM) is computed as follows ( <ref type="bibr" target="#b25">Steinbach et al., 2000)</ref>:</p><formula xml:id="formula_10">F = H j=1 |Γ j | |D| max i=1...K {F ij } where F ij = 2P ij R ij /(P ij + R ij ).</formula><p>Rand Index (RI) <ref type="bibr" target="#b22">(Rand, 1971)</ref> measures the percent- age of decisions that are correct, penalizing false pos- itive and false negative decisions during clustering. It takes into account the following quantities: TP, i.e., the number of pairs of documents that are in the same clus- ter in C and in the same class in Γ; TN, i.e., the number of pairs of documents that are in different clusters in C and in different classes in Γ; FN, i.e., the number of pairs of documents that are in different clusters in C and in the same class in Γ; and FP, i.e., the number of pairs of documents that are in the same cluster in C and in different classes in Γ. Rand Index is hence defined as:</p><formula xml:id="formula_11">RI = T P + T N T P + T N + F P + F N</formula><p>Note that for each method, results were averaged over 30 runs and the number of final document clusters K was set equal to the number of topics in the docu- ment collection (i.e., 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We present here our main experimental results. We first provide a comparative evaluation of our SeMDocT with the competing methods, on both balanced and unbal- anced corpus evaluation cases. Then we provide a per language analysis focusing on SeMDocT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation with competing methods</head><p>Evaluation on balanced corpus. <ref type="figure" target="#fig_1">Figure 2</ref> shows FM and RI results obtained by the various methods coupled with the two document representations on the Balanced Corpus. Several remarks stand out. First, the BoS space positively influences the performance of all the employed approaches. This is particularly evident for Bisecting K-Means and LSA that clearly benefit from this kind of representation. The former almost doubles its performance in terms of FM and significantly im- proves its result w.r.t. RI. LSA shows improvements in both cases. SeMDocT-BoS generally outperforms all the competitors for both FM and RI when the num- ber of components is greater than 16. Note that, under the BoW model, SeMDocT-BoW still outperforms the other methods.</p><p>Evaluation on unbalanced corpus. <ref type="figure" target="#fig_2">Figure 3</ref> reports results for the Unbalanced Corpus. Also in this eval- uation, the best performances for all the methods are reached using the BoS representation.  competitors, while in terms of RI the differences in per- formance are 0.012 and 0.019 for LSA-BoS and Bisect- ing K-Means-BoS, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Per language evaluation of SeMDocT-BoS</head><p>Starting from the clustering solutions produced by SeMDocT-BoS in both balanced and unbalanced cases, for each language we extracted a language-specific pro- jection of the clustering. After that, we computed the clustering validation criteria according to language spe- cific solutions to quantify how well the clustering result fits each specific language. The results of this experi- ment are reported in <ref type="figure" target="#fig_3">Fig. 4</ref> and <ref type="figure" target="#fig_4">Fig. 5</ref>    ments written in French and in Italian.</p><p>We gained an insight into the above discussed perfor- mance behaviors by computing some additional statis- tics that we report in <ref type="table" target="#tab_8">Table 5</ref>: for each language and each dataset, the size of the term and synset dictionar- ies and the average number of synsets per lemma (β) we retrieved through BabelNet according to the related corpus. More in detail, β is the ratio between the BoS and the BoW dictionaries. This quantity roughly eval- uates how many synsets are produced per term during the multilingual WSD process (Section 3.2). As we can observe, this value is always smaller than one, which means that not all the terms have a corresponding map- ping to a synset. The β ratio can explain the discrep- ancy in (language-specific) performances in the two scenarios. In particular, the difference in the β statis- tic between English and the other languages is more evident for the Unbalanced Corpus (i.e., 0.23 between English and French), while it is lower for the Balanced Corpus (around 0.1). The relatively large gap in β be- tween the first and the second language (respectively, English and French) for the Unbalanced Corpus re- duces the relative gap between the second and the third languages (respectively, French and Italian) while this trend is less marked for the Balanced Corpus as β range is narrower. In summary, we can state that our frame- work works well if BabelNet knowledge base provides a good coverage of the terms in the analyzed language. Experimental evidence shows that, if this condition is met, SeMDocT-BoS provides better clustering results w.r.t. the competing approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Runtime of tensor decomposition</head><p>As previously discussed, T-HOSVD of a third-order tensor can be computed through three standard SVDs. Furthermore, for clustering purposes, we considered only the mode-1 factor matrix of the decomposition.  To compute the SVD, we used the svds() function of MATLAB R2012b, which is based on an iterative algo- rithm. <ref type="bibr">2</ref> Experiments were carried out on an Intel Core I7-3610QM platform with 16GB DDR RAM. <ref type="figure">Figure 6</ref> shows the execution time of the SVD over the mode-1 matricization of our tensor for the Balanced Corpus, by varying the number of components, for both BoW and BoS representation models. As it can be ob- served, in both cases the runtime is linear in the number of components. However, the SVD computation in the BoS setting is one order of magnitude faster than time performance in the BoW setting. This is mainly due to a large difference in size between the feature spaces of BoW and BoS (cf. <ref type="table" target="#tab_1">Table 2</ref>), since the selected num- ber of segment clusters (k) was nearly the same (25 for BoW, and 22 for BoS). Therefore, by providing a more compact feature space, BoS clearly allows for a much less expensive SVD computation for our tensor decom- position.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of Words Bag of Synsets</head><p>Figure 6: Time performance of SVD over the mode-1 matricization of the Balanced Corpus tensor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Our work paves the way for the use of a multilingual knowledge base to deal with the multilingual document clustering task. Here we sum up our main findings.</p><p>SeMDocT vs. LSA. LSA achieved its best results for a number of components generally smaller than the one for which SeMDocT obtained its maximum. This is due to the initial information that the two methods summarize. LSA tries to capture the variation of the initial document-term (alternatively, document-synset) matrix representing the texts in a lower space, whereas SeMDocT does the same starting from a richer repre- sentation of the documents (i.e., a third-order tensor model). For this reason, SeMDocT tends to employ relatively more components in order to summarize the documents content; however, a number of components between 16 and 30 is generally enough to ensure good performance of SeMDocT. Moreover, in most cases, the highest performance results by SeMDocT are better than the highest performances of LSA.</p><p>BoS vs. BoW. Our results have highlighted the better quality in multilingual clustering supplied by synsets compared with the one provided by terms. BoS produces a smaller representation space over which documents are projected, but it is enough rich to well capture the documents content. In particular, BoS ben- efits from the WSD process that is able to discriminate the same term w.r.t. the context in which it appears.</p><p>BabelNet. BabelNet is a recent project that supports many different languages. As the intention of the au- thors is to enrich this resource, in the future our frame- work will benefit of this fact. Moreover, our framework can deal with documents written in many different lan- guages as they are represented through the same space; the only constraint is related to the available language support in BabelNet. On the other hand, we point out that any other multilingual knowledge base and WSD tools can in principle be integrated in our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we proposed a new approach for multi- lingual document clustering. Our key idea lies in the combination of a tensor-based model with a bag-of- synsets description, which enables a common space to project multilingual document collections. We evalu- ated our approach w.r.t. standard document clustering methods, using both term and synset representations. Results have shown the benefits deriving from the use of a multilingual knowledge base in the analysis of comparable corpora, and also shown the significance of our approach in both a balanced and an unbalanced corpus evaluation. Our tensor-based representation of topically-segmented multilingual documents can also be applied to cross-lingual information retrieval or mul- tilingual document categorization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The third-order tensor model for the representation of a multilingual document collection based on segment clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Average F-Measure (a) and Rand Index (b) on the Balanced Corpus using BoW and BoS document representation and varying the number of components for both SeMDocT and LSA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Average F-Measure (a) and Rand Index (b) on the Unbalanced Corpus using BoW and BoS document representation and varying the number of components for both SeMDocT and LSA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average F-Measure (a) and Rand Index (b) for language specific solutions on the Balanced Corpus obtained by SeMDocT-BoS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Average F-Measure (a) and Rand Index (b) for language specific solutions on the Unbalanced Corpus obtained by SeMDocT-BoS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Number of documents for each topic and lan-
guage. 

Statistics Balanced Corpus Unbalanced Corpus 
# of docs 
15 300 
10 200 
# of terms 
58 825 
44 535 
# of synsets 
16 395 
14 339 
BoW Density 
1.5E-3 
2.0E-3 
BoS Density 
2.6E-3 
3.1E-3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Main characteristics of the corpora. 

topics. For this reason, we used Reuters Corpus Volume 
2 (RCV2), a multilingual corpus containing news arti-
cles in thirteen language. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>. In the latter table, we report the number of documents, number of terms, number of synsets and the dataset density for both representations. To quantify the density of each cor- 1 http://trec.nist.gov/data/reuters/reuters.html</figDesc><table>RCV2 Topics English French Italian 
C15 -PERFORMANCE 
3.41 
3.67 
3.27 
C18 -OWNERSHIP CHANGES 
3.20 
3.32 
2.40 
E11 -ECONOMIC PERFORMANCE 
4.89 
3.17 
2.07 
E12 -MONETARY/ECONOMIC 
5.22 
3.69 
2.05 
M11 -EQUITY MARKETS 
4.29 
2.94 
2.15 
M13 -MONEY MARKETS 
3.31 
3.12 
2.10 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Average number of document segments, for each topic and language.</head><label>3</label><figDesc></figDesc><table>English 
French 
Italian 
RCV2 
avg BoS 
avg BoW 
avg BoS 
avg BoW 
avg BoS 
avg BoW 
Topics seg. leng. seg. leng. seg. leng. seg. leng. seg. leng. seg. leng. 
C15 
21.76 
36.32 
11.54 
34.92 
10.58 
37.75 
C18 
20.94 
36.87 
10.94 
35.62 
11.24 
41.20 
E11 
22.90 
37.24 
11.47 
34.73 
11.96 
38.60 
E12 
22.70 
37.70 
11.50 
37.44 
12.59 
43.63 
M11 
22.04 
36.83 
10.91 
32.76 
11.57 
42.39 
M13 
22.22 
36.97 
11.34 
34.75 
11.72 
39.36 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc>Average length of document segment in the BoW and BoS spaces, for each topic and language. pus/representation combination, we counted the non- zero entries of the induced document-synset matrix (al- ternatively, document-term matrix) and we divided this value by the size of such matrix. This number pro- vides an estimate about the density/sparseness of each dataset. Lower values indicate more sparse data. We can note that BoS model yields more dense datasets for both Balanced Corpus and Unbalanced Corpus.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 : Statistics by language.</head><label>5</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="2"> http://www.mathworks.it/it/help/matlab/ref/svds.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Personalizing PageRank for Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>of the International Conference of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Statistical Models for Text Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Beeferman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="177" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cross-language information retrieval using PARAFAC2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><forename type="middle">W</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abdelali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Latent Semantic Analysis for Text Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Freddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanna</forename><surname>Wiemer-Hastings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of the International Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="109" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent Semantic Kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huma</forename><surname>Lodhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Measuring constraint-set utility for partitional clustering algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiri</forename><surname>Wagstaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sugato</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</title>
		<meeting>of the European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="115" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Parameter-less co-clustering for star-structured heterogeneous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Ienco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Céline</forename><surname>Robardet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruggero</forename><forename type="middle">G</forename><surname>Pensa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosa</forename><surname>Meo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="254" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">TextTiling: Segmenting Text into Multi-Paragraph Subtopic Passages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="64" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-view clustering of multilingual documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Min</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massih-Reza</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM SIGIR International Conference on Research and Development in Information Retrieval (SIGIR)</title>
		<meeting>of the ACM SIGIR International Conference on Research and Development in Information Retrieval (SIGIR)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="821" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tensor Decompositions and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A language-independent approach to identify the named entities in under-resourced languages and clustering multilingual documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Kiran</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S K</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference of the CrossLanguage Evaluation Forum (CLEF)</title>
		<meeting>of the International Conference of the CrossLanguage Evaluation Forum (CLEF)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effectively mining Wikipedia for clustering multilingual documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Kiran</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S K</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Applications of Natural Language to Information Systems (NLDB)</title>
		<meeting>of the International Conference on Applications of Natural Language to Information Systems (NLDB)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="254" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multilingual document clustering using Wikipedia as external knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Kiran</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S K</forename><surname>Santosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Information Retrieval Facility Conference (IRFC)</title>
		<meeting>of the Information Retrieval Facility Conference (IRFC)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Multilinear Singular Value Decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><forename type="middle">De</forename><surname>Lieven De Lathauwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joos</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1253" to="1278" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hybrid clustering of multi-view data via Tucker-2 model and its application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Glänzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><forename type="middle">De</forename><surname>Moor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="819" to="839" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">PageRank on Semantic Networks, with Application to Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Figa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>of the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multilingual news clustering: Feature translation vs. identification of cognate named entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soto</forename><surname>Montalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Martínez-Unanue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantza</forename><surname>Casillas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Víctor</forename><surname>Fresno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="2305" to="2311" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An Experimental Study of Graph Connectivity for Unsupervised Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="678" to="692" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multilingual WSD with Just a Few Lines of Code: The BabelNet API</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the System Demonstrations of the Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>of the System Demonstrations of the Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross lingual text classification by mining multilingual topics from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochuan</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Tao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACM International Conference on Web Search and Web Data Mining (WSDM)</title>
		<meeting>of the ACM International Conference on Web Search and Web Data Mining (WSDM)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FreeLing 3.0: Towards Wider Multilinguality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Stanilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Language Resources and Evaluation Conference (LREC)</title>
		<meeting>of the Language Resources and Evaluation Conference (LREC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">M</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Tensor-based Clustering Approach for Multiple Document Classifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Romeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Tagarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Gullo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Greco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Pattern Recognition Applications and Methods (ICPRAM)</title>
		<meeting>of the International Conference on Pattern Recognition Applications and Methods (ICPRAM)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="200" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Determining the Number of Clusters/Segments in Hierarchical Clustering/Segmentation Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Tools with Artificial Intelligence (ICTAI)</title>
		<meeting>of the International Conference on Tools with Artificial Intelligence (ICTAI)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="576" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Comparison of Document Clustering Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the KDD Workshop on Text Mining</title>
		<meeting>of the KDD Workshop on Text Mining</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A segment-based approach to clustering multi-topic documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Tagarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="563" to="595" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SemanticRank: Ranking Keywords and Sentences Using Semantic Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iraklis</forename><surname>Varlamis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kjetil</forename><surname>Nørvåg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Computational Linguistics (COLING)</title>
		<meeting>of the International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1074" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A Latent Semantic Indexing-based Approach to Multilingual Document Clustering. Decision Support Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Ping</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Min</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="606" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">WikiWalk: Random walks on Wikipedia for Semantic Relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL Workshop on Graph-based Methods for Natural Language Processing</title>
		<meeting>of the ACL Workshop on Graph-based Methods for Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multilingual spectral clustering using document similarity propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumiko</forename><surname>Tanaka-Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>of the International Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="871" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Empirical and Theoretical Comparison of Selected Criterion Functions for Document Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="311" to="331" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
