<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How agents see things: On visual representations in an emergent language game</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Bouchacourt</surname></persName>
							<email>dianeb@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Facebook AI Research</orgName>
								<orgName type="department" key="dep2">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
							<email>mbaroni@fb.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Facebook AI Research</orgName>
								<orgName type="department" key="dep2">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">How agents see things: On visual representations in an emergent language game</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="981" to="985"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>981</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>There is growing interest in the language developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents&apos; symbol usage, rather than on their representation of visual input. In this paper, we consider the referential games of Lazaridou et al. (2017), and investigate the representations the agents develop during their evolving interaction. We find that the agents establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we are interested in developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has recently been a revival of interests in language emergence simulations involving agents interacting in visually-grounded games. Unlike earlier work (e.g., <ref type="bibr">Briscoe, 2002;</ref><ref type="bibr" target="#b2">Cangelosi and Parisi, 2002;</ref><ref type="bibr">Steels, 2012</ref>), many recent simula- tions consider realistic visual input, for example, by playing referential games with real-life pictures (e.g., <ref type="bibr" target="#b8">Jorge et al., 2016;</ref><ref type="bibr" target="#b10">Lazaridou et al., 2017;</ref><ref type="bibr" target="#b6">Havrylov and Titov, 2017;</ref><ref type="bibr" target="#b11">Lee et al., 2018;</ref><ref type="bibr" target="#b4">Evtimova et al., 2018)</ref>. This setup allows us to ad- dress the exciting issue of whether the needs of goal-directed communication will lead agents to associate visually-grounded conceptual represen- tations to discrete symbols, developing natural- language-like word meanings. However, while most studies present some analysis of the agents' symbol usage, they pay little or no attention to the representation of the visual input that the agents develop as part of their evolving interaction.</p><p>We study here agent representations following the model and setup of <ref type="bibr" target="#b10">Lazaridou et al. (2017)</ref>. This is an ideal starting point, since it involves an extremely simple signaling game <ref type="bibr" target="#b12">(Lewis, 1969)</ref>, that is however played with naturalistic images, thus allowing us to focus on the question of how the agents represent these images, and whether such representations meet our expectations for natural word meanings. In their first game, Lazari- dou's Sender and Receiver are exposed to the same pair of images, one of them being randomly marked as the "target". The Sender always sees the target in the left position, and it must pick one discrete symbol from a fixed vocabulary to send to the Receiver. The Receiver sees the im- ages in random order, together with the sent sym- bol, and it tries to guess which image is the tar- get. In case of success, both players get a pay- off of 1. Since an analysis of vocabulary usage brings inconclusive evidence that the agents are using the symbols to represent natural concepts (such as beaver or bayonet), Lazaridou and col- leagues next modify the game, by presenting to the Sender and the Receiver different images for each of the two concepts (e.g., the Sender must now signal that the target is a beaver, while see- ing a different beaver from the one shown to the Receiver). This setup should encourage concept- level thinking, since the two agents should not be able to communicate about low-level percep- tual characteristics of images they do not share. Lazaridou and colleagues present preliminary evi- dence suggesting that, indeed, agents are now de- veloping conceptual symbol meanings. We repli- cate Lazaridou's games, and we find that, in both, the agents develop successfully aligned represen- tations that, however, are not capturing conceptual properties at all. In what is perhaps our most strik- ing result, agents trained in either version of the game succeed at communicating about pseudo- images generated from random noise <ref type="figure" target="#fig_1">(Fig. 2)</ref>. We conclude that, if we want interactive agents to develop a vocabulary of words denoting natural meanings, more attention must be paid to the way in which they are representing their perceptual in- put.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental setup</head><p>Architecture We re-implement Lazaridou's Sender and Receiver architectures (using their better-behaved "informed" Sender). Both agents are feed-forward networks. The Sender takes image representations as input, it projects them into its own representational space, compares them, and finally outputs a probability distribution over vocabulary symbols, from which a single discrete symbol is then sampled. We report here results obtained with an output vocabulary of 100 symbols, but the same patterns were observed using a range of sizes from 2 to 1, 000. The Receiver takes as input the target and distractor input image representations in random order, as well as the symbol produced by the sender (as a vocabulary-sized one-hot vector). It embeds the images and the symbol into its own representa- tional space, where it performs a symbol-to-image comparison, producing a probability distribution over the two images, one of which is selected by sampling from this distribution. If the Receiver selected the target image, a reward of 1 is assigned to both agents. The whole architecture is jointly trained by letting the agents play, and updating their parameters with Reinforce <ref type="bibr" target="#b16">(Williams, 1992)</ref>. See <ref type="bibr" target="#b10">Lazaridou et al. (2017)</ref> for details.</p><p>Data Following <ref type="bibr" target="#b10">Lazaridou et al. (2017)</ref>, for each of the 463 concepts they used, we randomly sam- ple 100 images from ImageNet ( <ref type="bibr" target="#b3">Deng et al., 2009</ref>). We construct 50, 000 mini-batches of 32 image pairs during training and 1, 024 pairs for valida- tion. We construct a held-out test set in the same way by sampling 10 images per concept from Ima- geNet (for 2 concepts, we were not able to assem- ble enough further images), for a total of 4, 610. We compute RSA scores (see below) on the cross- product of these images. We also use the held- out set to construct mini-batches of images pairs to compute test performance. Following Lazari- dou, the images are passed through a pre-trained VGG ConvNet ( <ref type="bibr" target="#b13">Simonyan and Zisserman, 2015)</ref>. The input vector fed to the agents is the second-to- last 4096-D fully connected layer 1 .</p><p>Games We re-implement both Lazaridou's same-image game, where Sender and Receiver are shown the same two images (always of differ- ent concepts), and their different-image game, where the Receiver sees different images than the Sender's. We repeat all experiments using 100 random initialization seeds. As we faithfully reproduced the setup of <ref type="bibr" target="#b10">Lazaridou et al. (2017)</ref>, we refer the reader there for hyper-parameters and training details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>We first asked in which way playing the game af- fects the way agents "see" the input data, that is, in which way their image embeddings differ from the input image representations, and from each other. Concerning Sender and Receiver, a reason- able expectation is that successful communication implies a convergence of representations. How should these representations relate to the input? Recall that input representations are from one of the top layers of a state-of-the-art ConvNet trained on ImageNet concept categorization, and the top layers of such networks are known to capture high- level concept semantics <ref type="bibr" target="#b17">(Zeiler and Fergus, 2014</ref>). The game image pairs are always sampled from different concepts. So, it would make sense for the agents to simply learn to carry through the simi- larity structure of the input space, in order to com- municate about distinct concepts. Consequently, we predicted that, as training proceeds, Sender and Receiver representations will become closer to each other, and to the input ones.</p><p>In order to compare the similarity structure of input, Sender and Receiver spaces, we borrow representational similarity analysis (RSA) from computational neuroscience ( <ref type="bibr" target="#b9">Kriegeskorte et al., 2008)</ref>. Given two sets r 1 and r 2 of representa- tions of the same item collection (e.g., r 1 is the collection of input images mapped in Sender em- bedding space and r 2 is the same collection rep- resented by Receiver), we first compute s 1 as all possible pairwise (cosine) similarities between the representations in r 1 , and s 2 as those in r 2 . We then compute the (Spearman) correlation between the similarity vectors s 1 and s 2 . This latter value, which we will call RSA score, measures the global agreement between s 1 and s 2 , relative to the cho- sen input collection. If N is the number of items in the collection that we compute representations for, both similarity vectors s 1 and s 2 are of length N (N − 1). Therefore, it is not necessary for rep- resentations r 1 and r 2 to belong to the same space (for example, in our case, input and agent vectors have different dimensionality). <ref type="figure" target="#fig_0">Figure 1</ref> shows RSA and mean validation re- ward (MVR) development curves for the cross- validated best seed in the same-image game. At the beginning of training, the RSA scores are non- zeros, which is expected as the two agents archi- tectures are similar and randomly initialized the same way. They are also somewhat correlated with the input, which we attribute to the fact that untrained neural networks can already extract rel- evant image features <ref type="bibr" target="#b7">(Jarrett et al., 2009</ref>). As training converges, Sender and Receiver similar- ity spaces also converge. However, contrary to our prediction, the agent similarity spaces are not strongly correlated with the input visual space. We note that, during the first few hundred games, the Sender (green curve) aligns with the input, but the Receiver (blue curve) does not. Therefore, it seems that, in order to establish communica- tion, the two agents have to drift from the input. Indeed, when communication is successfully es- tablished at the end of training, 2 the two agents have a RSA score of ρ S/R = 0.98. However ei- ther agent's score with the input is a much lower ρ S/I = ρ R/I = 0.33. 3 On the contrary, when the agents fail to establish communication, by the end of training their RSA score is just ρ S/R = 0.39, but they stay closer to the input (ρ S/I = 0.58 and ρ R/I = 0.42). <ref type="bibr">4</ref> The drift of the agents from input similarity could be attributed to the characteristics of the game they are playing. Since they are only asked to distinguish between pictures of different con- cepts, they have no incentive to keep different instances of a concept distinct (if the agents are never asked to distinguish one dog from another, they might eventually become unable to tell dogs apart). That is, we might be assisting to the in- ception of a form of categorical perception <ref type="bibr" target="#b5">(Goldstone and Hendrickson, 2010)</ref>, whereby the agents lose sensitivity to within-category differences. If this is the case, we should observe that same- concept image similarity is higher in Sender (or Receiver) space with respect to input space. How- ever, this turns out not to be the case. To the con- trary, average pairwise same-concept similarity is consistently lower in Sender space than in the in- put (mean z-normalized same-concept similarity in input space is at 1.94 vs. 0.57 in Sender space, averaged across successful seeds). A similar effect is observed by looking at higher-class (mammal, furniture, etc.) similarities: images from the same classes become less similar in Sender space (0.61 z-normalized within-class input similarity vs. 0.30 in Sender space). This suggests that the agents are becoming less proficient at capturing the sim- ilarity among instances of the same concept or of the same class. The same conclusion is qualita- tively supported by the pairs of images that un- derwent the largest shift between input and Sender space. For example, for two test images of avoca- dos which have an input similarity of 0.82 (and are reasonably similar to the human eye), the Sender similarity is at the low value of −0.27 (Receiver similarity is −0.59). Contrarily, for an image of a cabin in a field and an image of a telephone that have an intuitively correct very low input similar- ity of 0.02, the Sender similarity for these images is 0.94 (Receiver similarity is 0.95).</p><p>Lazaridou et al. (2017) designed their second game to encourage more general, concept-like ref- erents. Unfortunately, we replicate the anomalies above in the different-image setup, although to a less marked extent. When successful communica- tion is established at the end of training, the agents have ρ S/R = 0.90. But again, the agents' repre- sentation do not align with the input space: their scores with the input are at lower values of ρ S/I =  0.40 and ρ R/I = 0.37. <ref type="bibr">5</ref> In case of communication failure, by the end of training their RSA score is at the lower value of ρ S/R = 0.74, and their val- ues with respect to the input are ρ S/I = 0.36 and ρ R/I = 0.34. 6 Again, same-concept images drift apart in agent space, although now to a lesser ex- tent (1.94 z-normalized mean similarity in input space vs. 1.07 in Sender space). More encourag- ingly, we don't find the same pattern for within- class mean similarities (0.61 input space vs. 0.75 Sender space). We must conjecture that the agents are compar- ing low-level properties of the image pairs, inde- pendently of the game they play. As an extreme way to test this, we look at how agents trained to play the two games behave when tested with in- put pairs that are just random noise vectors drawn from a standard Normal distribution. <ref type="bibr">7</ref> If the agents are indeed indifferent to the objects represented by images, the radical shift in the nature of the input to the game should not affect them much.</p><p>Results are shown in <ref type="table" target="#tab_1">Table 1</ref>. We confirm that the same-image game is the easiest, and we ob- serve that agents trained in one game perform rea- sonably well on the other. More importantly, no matter which game they are trained on, the agents perform very well on noise input! This confirms our hypothesis that the Sender and Receiver are able to communicate about input data that contain no conceptual content at all, which in turn suggests that they haven't extracted any concept-level in- formation (e.g., features that would allow them to recognize instances of the dog or chair category) during training. To get a sense of the sort of noise pairs agents succeed to communicate about, Finally, we draw 1, 000 noise pairs (z 1 , z 2 ), and present each to the Sender with either z 1 or z 2 as target. We then compare, pair by pair, whether the highest probability symbol changes when the target is swapped. We average across 10 random runs using the best cross-validated seed. In both versions of the game, for more than 99% of the pairs, the symbol with highest probability changes when the target is swapped. This suggests that the agents perform a relative comparison of the two inputs, rather than an absolute one, in line with the general conclusion that they are not using the vocabulary to denote stable conceptual properties of the objects depicted in the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Existing literature in game theory already showed that convergence towards successful communi- cation is ensured under specific conditions (see <ref type="bibr" target="#b14">Skyrms (2010)</ref> and references therein). How- ever, the important contribution of <ref type="bibr" target="#b10">Lazaridou et al. (2017)</ref> is to play a signaling game with real-life images instead of artificial symbols. This raises new empirical questions that are not answered by the general mathematical results, such as: When the agents do succeed at communicating, what are the input features they rely upon? Do the internal representations they develop relate to the concep- tual properties of the input? Our study suggests that the agents' representations are not capturing general conceptual properties of different objects, but they are rather specifically tuned to success- fully distinguish images based on inscrutable low- level relational properties.</p><p>Interestingly, our conclusions can be aligned with findings in psycholinguistic experimental lit- erature on dialogue. In order to achieve communi- cation, the agents develop a form of ''conceptual pact" <ref type="bibr" target="#b0">(Brennan and Clark, 1996)</ref>: Their internal representations align while at the same time drift- ing away from human-level properties of the input. The agents agree on a shared use of the vocabu- lary, that does not correspond to concepts in the input data.</p><p>In future work, we would like to encourage the development of more natural word meanings by enforcing the agent representations to stay more faithful to the perceptual input they receive. Mov- ing ahead, it is fundamental to design setups where agents would have stronger reasons to develop human-like communication strategies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: RSA scores of the two agents (ρ S/R ), and of each agent with the input (ρ S/I and ρ R/I ), during the first 10, 000 training games. S refers to Sender, R to Receiver, I to input. Values remain stable until end of training. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Noise vectors agents trained on the sameimage game successfully communicate about.</figDesc><graphic url="image-1.png" coords="4,307.28,62.81,106.95,106.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Percentage average rewards on the same-
image, different-image and noise test sets for 
agents trained in the same-and different-image 
games (chance level at 50%). For each game, 
values are averaged on 10 test runs consisting of 
1, 000 games of mini-batches of 32 image pairs, 
using the cross-validated best seed. 

</table></figure>

			<note place="foot" n="1"> We found very similar results with the top 1000-D softmax layer.</note>

			<note place="foot" n="2"> We consider training successful if MVR ≥ 80%. 3 Values averaged over the 96 successful seeds.</note>

			<note place="foot" n="4"> Values averaged over the 4 failing seeds.</note>

			<note place="foot" n="5"> Values averaged over the 19 successful seeds. 6 Values averaged over the 81 failing seeds. 7 As during training inputs are divided by their norm, we also normalize each noise vector, so multiple noise variances would have no effect.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Angeliki Lazaridou, Douwe Kiela and Calvin Lee for their useful discussions and in-sights. We also thank Francisco Massa for his help on setting up the experiments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Conceptual pacts and lexical choice in conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1482" to="1493" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Linguistic evolution through language acquisition</title>
		<editor>Ted Briscoe</editor>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Simulating the evolution of language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelo</forename><surname>Cangelosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domenico</forename><surname>Parisi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lia-Ji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR<address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emergent communication in a multi-modal, multi-step referential game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrina</forename><surname>Evtimova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Drozdov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<ptr target="https://openreview.net/group?id=ICLR.cc/2018/Conference" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Conference Track</title>
		<meeting>ICLR Conference Track<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Categorical perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Goldstone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hendrickson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="78" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
<note type="report_type">Wiley Interdisciplinary Reviews</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Emergence of language with multi-agent games: Learning to communicate with sequences of symbols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serhii</forename><surname>Havrylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2149" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What is the best multistage architecture for object recognition?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Marc&amp;apos;aurelio Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Computer Vision</title>
		<meeting>the 12th International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2146" to="2153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to play Guess Who? and inventing a grounded language as a consequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilio</forename><surname>Jorge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Kågebäck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emil</forename><surname>Gustavsson</surname></persName>
		</author>
		<ptr target="https://sites.google.com/site/deeprlnips2016/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS Deep Reinforcement Learning Workshop</title>
		<meeting>the NIPS Deep Reinforcement Learning Workshop<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Representational similarity analysis: Connecting the branches of systems neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Kriegeskorte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bandettini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Systems Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-agent cooperation and the emergence of (natural) language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Peysakhovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<ptr target="https://openreview.net/group?id=ICLR.cc/2017/conference" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Conference Track</title>
		<meeting>ICLR Conference Track<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Emergent translation in multi-agent communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<ptr target="https://openreview.net/group?id=ICLR.cc/2018/Conference" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Conference Track</title>
		<meeting>ICLR Conference Track<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Convention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Harvard University Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.iclr.cc/doku.php?id=iclr2015:main" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Conference Track</title>
		<meeting>ICLR Conference Track<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Signals: Evolution, learning, and information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Skyrms</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<title level="m">Experiments in Cultural Language Evolution. John Benjamins</title>
		<editor>Luc Steels</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Simple statistical gradientfollowing algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECCV</title>
		<meeting>ECCV<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
	<note>Part 1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
