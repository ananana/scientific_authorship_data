<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IRT-based Aggregation Model of Crowdsourced Pairwise Comparisons for Evaluating Machine Translations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Otani</surname></persName>
							<email>otani.naoki.65v@st.kyoto-u.ac.jp nakazawa@pa.jst.jp {dk,kuro}@i.kyoto-u.ac.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Japan Science and Technology Agency</orgName>
								<address>
									<addrLine>Kawaguchi-shi</addrLine>
									<settlement>Saitama</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Informatics</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<addrLine>Yoshida-honmachi, Sakyo-ku</addrLine>
									<settlement>Kyoto</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">IRT-based Aggregation Model of Crowdsourced Pairwise Comparisons for Evaluating Machine Translations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="511" to="520"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Recent work on machine translation has used crowdsourcing to reduce costs of manual evaluations. However, crowdsourced judgments are often biased and inaccurate. In this paper , we present a statistical model that aggregates many manual pairwise comparisons to robustly measure a machine translation system&apos;s performance. Our method applies graded response model from item response theory (IRT), which was originally developed for academic tests. We conducted experiments on a public dataset from the Workshop on Statistical Machine Translation 2013, and found that our approach resulted in highly in-terpretable estimates and was less affected by noisy judges than previously proposed methods .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Manual evaluation is a primary means of interpret- ing the performance of machine translation (MT) systems and evaluating the accuracy of automatic evaluation metrics. It is also essential for natural lan- guage processing tasks such as summarization and dialogue systems, where (1) the number of correct outputs is unlimited, and (2) na¨ıvena¨ıve text matching cannot judge the correctness, that is, an evaluator must consider syntactic and semantic information.</p><p>Recent work has used crowdsourcing to reduce costs of manual evaluations. However, the judg- ments of crowd workers are often noisy and unre- liable because they are not experts.</p><p>To maintain quality, evaluation tasks imple- mented using crowdsourcing should be simple.</p><p>Thus, many previous studies focused on pairwise comparisons instead of absolute evaluations. The same task is given to multiple workers, and their re- sponses are aggregated to obtain a reliable answer.</p><p>We must, therefore, develop methods that ro- bustly estimate the MT performance based on many pairwise comparisons.</p><p>Some aggregation methods have been proposed for MT competitions hosted by the Workshop on Statistical Machine Translation (WMT) ( <ref type="bibr" target="#b1">Bojar et al., 2013;</ref><ref type="bibr" target="#b11">Hopkins and May, 2013;</ref><ref type="bibr" target="#b15">Sakaguchi et al., 2014)</ref>, where a ranking of the submitted systems is produced by aggregating many manual judgments of pairwise comparisons of system outputs.</p><p>However, existing methods do not consider the following important issues.</p><p>Interpretability of the estimates: For the purpose of evaluation, their results must be interpretable so that we could use the results to improve MT systems and the next MT evaluation campaigns. Existing methods, however, only yield system-level scores.</p><p>Judge sensitivity: Some judges can examine the quality of translations with consistent standards, but others cannot ( <ref type="bibr" target="#b8">Graham et al., 2015)</ref>. Sensitivities to the translation quality and judges' own standards are important factors.</p><p>Evaluation of a newly submitted system: Pre- vious approaches considered all pairwise combina- tions of systems and must compare a newly sub- mitted system with all the submitted systems. This made it difficult to allow participants to submit their systems after starting the evaluation step.</p><p>To address these issues, we use a model from item response theory (IRT). This theory was origi- nally developed for psychometrics, and has applica- tions to academic tests. IRT models are highly in- terpretable and are supported by theoretical and em- pirical studies. For example, we can estimate the informativeness of a question in a test based on the responses of examinees. We focused on aggregating many pairwise com- parisons with a baseline translation so that we could use the analogy of standard academic tests. <ref type="figure" target="#fig_0">Figure 1</ref> shows our problem setting. Each system of inter- est yields translations, and the translations are com- pared with a baseline translation by multiple human judges. Each judge produces a preference judgment.</p><p>The pairwise comparisons correspond to ques- tions in academic tests, a judge's sensitivity to the translation quality is mapped to discrimination of questions, and the relative difficulty of winning the pairwise comparison is mapped to the difficulty of questions. MT systems correspond to students that take academic tests, and IRT models can be naturally applied to estimate the latent performance (ability) of MT systems (students).</p><p>Additionally, our approach, fixing baseline trans- lations, can easily evaluate a newly submitted sys- tem. We only need to compare the new system with the baseline instead of testing all pairwise combina- tions of the submitted systems.</p><p>Our contributions are summarized as follows. 1</p><p>1. We propose an IRT-based aggregation model of pairwise comparisons with highly interpretable parameters.</p><p>2. We simulated noisy judges on the WMT13 dataset and demonstrated that our model is less affected by the noisy judges than previously proposed methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The WMT shared tasks have collected many manual judgments of segment-level pairwise comparisons and used them to produce system-level rankings for MT tasks. Various methods has been proposed to ag- gregate the judgments to produce reliable rankings. Each system yields translations. Judges compare them with a baseline translation and report their preferences. Our goal is to aggregate the judgments to determine the performance of each system.</p><p>Frequency based approaches were used to pro- duce the WMT13 official rankings ( <ref type="bibr" target="#b1">Bojar et al., 2013)</ref>, considering statistical significance of the re- sults <ref type="bibr">(Koehn, 2012)</ref>.</p><p>Hopkins and May (2013) noted that we should consider the relative matchup difficulty, and pro- posed a statistical aggregation model. Their model assumes that the quality of each system can be rep- resented by a Gaussian distribution. <ref type="bibr" target="#b15">Sakaguchi et al. (2014</ref><ref type="bibr">) applied TrueSkill (Herbrich et al., 2006</ref>) to reduce the number of compar- isons to reach the final estimate based on an active learning strategy. The same model was recently used for grammatical error correction ( <ref type="bibr" target="#b9">Grundkiewicz et al., 2015;</ref><ref type="bibr" target="#b13">Napoles et al., 2015)</ref>.</p><p>These methods acquire the final system-level scores, whereas our model also estimates segment specific and judge specific parameters.</p><p>The Bradley-Terry (BT) model was the result of a seminal study on aggregating pairwise compar- isons <ref type="bibr" target="#b4">(Bradley and Terry, 1952;</ref><ref type="bibr" target="#b5">Chen et al., 2013;</ref><ref type="bibr" target="#b6">Dras, 2015)</ref>. Recently, <ref type="bibr" target="#b5">Chen et al. (2013)</ref> explic- itly incorporated the quality of judges into the BT model, and applied it to quality control in crowd- sourcing.</p><p>The previously mentioned methods focused on pairwise comparisons of all combination of the MT systems, and thus, the number of comparisons in- creases rapidly as the number of systems increases.</p><p>Our approach, however, only uses comparisons with a fixed baseline. This approach enables to apply IRT models for academic tests and makes it easy to eval- uate a newly submitted system.</p><p>The work most relevant to our model is the IRT- based crowdsourcing model proposed by <ref type="bibr" target="#b0">Baba and Kashima (2013)</ref>. Their goal was to estimate the true quality of artifacts such as design works based on ratings assigned by reviewers. They also applied a graded response model to incorporate the authors' latent abilities and the reviewers' biases.</p><p>Yet their setting differs from ours in that they fo- cused on the quality of the artifacts, whereas we are interested in the authors. Additionally, their model maps task difficulty and review bias to a difficulty parameter in IRT. However, we naturally extended the model so that standard analysis approaches can be applied to maintain interpretability.</p><p>Some studies have focused on absolute evalua- tions ( <ref type="bibr" target="#b7">Goto et al., 2014;</ref><ref type="bibr" target="#b8">Graham et al., 2015)</ref>. <ref type="bibr" target="#b8">Graham et al. (2015)</ref> gathered continuous scale evalu- ations in terms of adequacy and fluency for many segments, and filtered out noisy judgments based on their consistency. The proposed pipeline results in very accurate evaluations, but 40-50% of all the judgments were filtered out due to inconsistencies. This explains the difficulties of developing absolute evaluation methods in crowdsourcing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Setting</head><p>We first describe the problem setting, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Assume that there are a group of systems I in- dexed by i, a set of segments J indexed by j, and a set of judges K indexed by k.</p><p>Before a manual evaluation, we fix an arbitrary baseline system and use it to translate the segments J . Then, each system i ∈ I produces a transla- tion on segment j ∈ J . One of the judges k ∈ K compares it with the baseline translation. The judge produces a preference judgment.</p><p>Let u i,j,k be the observed judgment that judge k assigns to a translation by system i on segment j, that is, and let c ∈ {1, 2, 3} be the judgment label.</p><formula xml:id="formula_0">u i,j,k =      1 (preference for baseline) 2 (no preference) 3 (preference for system i) , -BUFOUUQFSGPSNBODFFPGGTZTUFNT (</formula><p>Each system i has its own latent performance θ i ∈ R. Our goal is to estimate θ by using the observed judgments U = {u i,j,k } i∈I,j∈J ,k∈K .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Generative Judgment Model</head><p>We describe a statistical model for pairwise compar- isons based on an IRT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Modified Graded Response Model</head><p>Based on the graded response model (GRM) pro- posed by <ref type="bibr" target="#b16">Samejima (1968)</ref>, we define a generative model of judgments. GRM deals with responses on ordered categories including ratings such as A+, A, B+ and B, and partial credits in tests. In our prob- lem setting, judgments can be seen as partial credits. When a system beats a baseline translation, the sys- tem receives c = 3 credit. In the case of a tie, the system receives c = 2 credit. The system receives c = 1 credit when it lose to the baseline.</p><p>Let P * jkc (θ i ) be the probability that judge k as- signs judgment π &gt; c to a comparison on segment j between system i and a baseline.</p><formula xml:id="formula_1">P * jkc (θ i ) = 1 1 + exp(−a k (θ i − b jc )) ,</formula><p>where P * jk0 (θ i ) = 1, P * jk3 (θ i ) = 0. Parameters a and b are called discrimination and difficulty parameters, respectively. a represents the discriminablity or sen- sitivity of the judge, and b represents a segment- specific difficulty parameter. The discrimination pa- rameter (a) is positive, and the difficulty parameter (b) satisfies b 1 &lt; b 2 , where b 1 corresponds to the dif- ficulty of not losing to the baseline (c &gt; 1), and b 2 corresponds to the difficulty of beating the baseline (c &gt; 2).</p><p>The generative probability of judgment u i,j,k is defined as the difference in the probabilities defined above, that is,</p><formula xml:id="formula_2">P jkc (θ i ) = P(u i,j,k = c|θ i , b j , a k ) = P * jkc−1 (θ i ) − P * jkc (θ i ) .</formula><p>This function is called item characteristic curve (ICC). <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the ICC in the GRM. The horizontal axis represents the latent performance of systems, and the vertical axis represents the genera- tive probability of the judgments. This figure shows, for example, that the probability of the system with θ = 0 beating the baseline is 0.3, whereas the system with θ = 1.0 is much more likely to win. The dis- crimination parameter controls slope of the curves. If a is small, the probability drops a little when θ decreased.</p><p>The model described above is different from the original GRM, which assumed that the values of a are independent from question to question, and that each a belongs to exactly one question. However, in our problem setting, the judges evaluate multiple segments, and discrimination parameter a is inde- pendent from segment j. This modification means that the GRM can capture the judge's sensitivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Priors</head><p>We assign prior distributions to the parameters to obtain estimates stably. We assume Gaussian dis- tributions on θ and b, that is, θ ∼ N (0, τ 2 ) and b c ∼ N (µ bc , σ 2 bc ) (c = 1, 2). The discrimination parameter is positive, so we assume a log Gaussian distribution on a, i.e., log(a) ∼ N (µ a , σ 2 a ). Note that τ, µ, and σ are hyper parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Parameter Estimation</head><p>We find the values of the parameters to maximize the log likelihood based on obtained judgments U :</p><formula xml:id="formula_3">L(θ, ξ) = logP(U, θ, ξ) .</formula><p>We denote the parameters a = {a k } k∈K and b = {b j1 , b j2 } j∈J to be ξ in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Marginal Likelihood Maximization of Judge Sensitivity and Matchup Difficulty</head><p>Estimates are known to be inaccurate when all the parameters are optimized at once, so we first esti- mate the parameters ξ to maximize the marginal log likelihood w.r.t. the system performance θ.</p><formula xml:id="formula_4">mL(ξ) = logP(U, ξ) = i∈I log ∞ −∞ P(θ)P(U i |θ, ξ)dθ + logP(ξ),</formula><p>where U i is the set of judgments given to system i The equation above can be approximated using Gauss-Hermite quadrature, i.e.,</p><formula xml:id="formula_5">mL(ξ) ≈ i∈I log T t=1 1 √ π w t P(U i |τ x t , ξ) + logP(ξ) w t = 2 T −1 T ! √ π T 2 (H(x t )) 2 H(x t ) = 2x t − d dx t T −1 · 1 ,</formula><p>where a practically good approximation is obtained by taking T ≈ 20. <ref type="bibr">2</ref> We solve the optimization problem using the gra- dient descent methods to maximize the approxi- mated marginal likelihood. The inequality con- straints on the parameters are handled by adding log barrier functions to the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Maximum A Posteriori (MAP) Estimation of System Performance</head><p>Given the estimates of ξ, we estimate the system per- formance θ = {θ i } i∈I by using MAP estimation. We maximize the objective function,</p><formula xml:id="formula_6">L(θ) = logP(U, θ; ξ) = i∈I logP(θ i ) + i∈I logP(U i |θ i ; ξ) .</formula><p>The estimates of θ are obtained using the gradient descent method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discussion</head><p>So far we have assumed that the estimate is based on batch learning. However, it is known that active learning can reduce the costs (i.e., the total number of comparisons) ( <ref type="bibr" target="#b15">Sakaguchi et al., 2014)</ref>.</p><p>To extend our model to the active learning frame- work, one approach is to optimize the objective function online and actively select the next system to be compared based on criteria such as the uncer- tainty of the system's performance. We can apply stochastic gradient descent to the online optimiza- tion, which updates the estimates of the parame- ters using the gradients calculated based on a single comparison. This modification was left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We conducted experiments on the WMT13 man- ual evaluation dataset for 10 language pairs. 3 For details of the evaluation data, see the overview of WMT13 ( <ref type="bibr" target="#b1">Bojar et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Setup</head><p>Models: Our method (GRM) was initialized using a = 1.7, b = (−0.5, 0.5), and a θ value derived by summing up the judgments for each system and scaling θ to fit the prior distribution. For the hyper parameters, we set τ = √ 2, µ a = log(1.7), σ a = 1.0, µ b = (−0.5, 0.5), σ b = 2.0.</p><p>To compare with our method, we trained Ex- pectedWins (EW) ( <ref type="bibr" target="#b1">Bojar et al., 2013)</ref>, the model by <ref type="bibr" target="#b11">Hopkins and May (2013)</ref>, (HM) and the two- stage crowdsourcing model proposed by <ref type="bibr">Baba and Kashima (2013) (TSt)</ref>. We also trained TrueSkill (TS) ( <ref type="bibr" target="#b15">Sakaguchi et al., 2014)</ref>, which was used to produce the gold score on this experiment.</p><p>We followed <ref type="bibr" target="#b15">Sakaguchi et al. (2014)</ref>, who also used the WMT13 datasets in their experiments, and initialized the HM and TS parameters. For TSt, we followed <ref type="bibr" target="#b0">Baba and Kashima (2013)</ref>.</p><p>Pairwise comparisons: The WMT dataset con- tains five-way partial rankings, so we converted the five-way partial rankings into pairwise comparisons. For example, given a five-way partial ranking A &gt; B &gt; C &gt; D &gt; E, we obtain ten pairwise compar- isons A &gt; B, A &gt; C, A &gt; D, · · · , and D &gt; E. We randomly sampled 800, 1,600, 3,200 and 6,400 pair- wise comparisons from the whole dataset.</p><p>The training data differs between the models. For GRM and TSt, we first sampled five-way rankings that contained a baseline translation for each base- line system and obtained pairwise comparisons. For EW and HM, we first converted five-way rankings into pairwise comparisons and selected them at ran- dom. <ref type="bibr">4</ref> TS first receives all the pairwise compar- isons and selects the training data based on the active learning strategy, whereas we sampled the compar- isons before running the other methods.</p><p>Gold scores: We followed the official evaluation procedure of the WMT14-15 ( <ref type="bibr" target="#b2">Bojar et al., 2014;</ref><ref type="bibr" target="#b3">Bojar et al., 2015</ref>) and made gold scores with TS. We produced 1,000 bootstrap-resampled datasets over all of the available comparisons. We then ran TS and collected the system scores. The gold score is the mean of the scores.</p><p>Evaluation metrics: We evaluated the models us- ing the Pearson correlation coefficient and the nor- malized discounted cumulative gain (nDCG), com- paring the estimated scores and gold scores. We used nDCG because we are often interested in ranks and scores, especially in MT competitions such as the WMT translation task. 5 These metrics were also used for experiments in <ref type="bibr" target="#b0">Baba and Kashima (2013)</ref>. <ref type="figure" target="#fig_2">Figure 3</ref> shows the correlation and nDCG between the estimated system performance and the gold scores for the WMT13 Spanish-English task. For the GRM and TSt, the baselines used in the eval- uation are shown in parentheses in the labels. The other language pairs showed similar tendencies. The complete results for all language pairs can be found in the supplementary data files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>Note that the main contribution of our method is not to perform better than other methods in terms of correlation and nDCG to the gold scores, but to re- sult in highly interpretable and robust estimates dis- cussed later.</p><p>TS resulted in the highest correlation and nDCG. It is reasonable because the gold scores themselves were produced by TS, and because it estimates the parameters using active learning, unlike the other models.</p><p>The GRM with the best baseline system (DCU) achieved almost the same scores as the TS, in terms of correlation and nDCG. Although the TSt with the best baseline resulted in accurate estimates in terms of correlation, it did not in terms of nDCG. With the worst baselines, the GRM and TSt both failed to replicate the gold scores, but the GRM was sur- prisingly accurate in terms of nDCG (even in the worst case). This implies that the GRM can effec- tively predict the top ranked systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Baseline Selection</head><p>It is likely that single pairwise comparisons do not work well if the baseline is very strong or weak. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, the baseline system influences the final result. When we used SHEF-WPROA as baseline, the estimated system performance was not accurate. This is because SHEF-WPROA loses 69.4% of the pairwise comparisons and fails to dis- criminate between the other systems. In contrast, DCU loses 34.5% and win 34.8% of the compar- isons and discriminate the other systems success- fully. Thus, when we used DCU as baseline, the best correlation and nDCG were achieved. Therefore, we must determine the appropriate baseline system be- fore the comparisons.</p><p>One possible solution is to consider the system-  <ref type="table">Table 1</ref>: Correlation and nDCG between the estimated system performance and gold scores for the WMT13 Spanish-English task, based on noisy judges. The val- ues were averaged over all the datasets. The GRM scores were averaged over all baselines. The differences from the GRM are reported for the HM and EW. level scores yielded by automatic evaluation metrics such as BLEU and METEOR. <ref type="figure">Figure 4</ref> shows that we obtained relatively good results when we used a system whose system-level BLEU score and ME- TEOR score 6 were close to the mean of all the sys- tems. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Analysis of Judge Sensitivity</head><p>To investigate the robustness of the GRM, we sim- ulated "noisy" judges. We selected a subset of   <ref type="figure">Figure 4</ref>: Relationship between system-level BLEU/METEOR scores (horizontal) and correlation/nDCG scores (vertical). The mean BLEU/METEOR was set to zero, and the best score was set to zero for each language pair.</p><p>judges and randomly changed their decisions based on a uniform distribution. The percentage of noisy judges varied between 10% and 50% (in increments of 10%).</p><p>We trained HM and EW on the simulated datasets. We excluded TS because it assumes that we can ac- tively request more comparisons from judges when their decisions are ambiguous.</p><p>As shown in <ref type="table">Table 1</ref>, the accuracy of the GRM was less affected by the noisy judges than HM and EW. This is because our model estimates judge- specific sensitivities and automatically reduces the influence of the noisy judges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Analysis of the Interpretability of the Estimated Matchup Difficulty</head><p>Our model is a natural extension of the GRM Same- jima (1968), so we can apply standard analyses for IRT models. Item information is one of the standard analysis methods and corresponds to sensitivity to a latent parameter of interest. Based on the item infor- mation, we can find which segment was difficult to be translated better than a baseline translation.</p><p>The item information is calculated using the esti- mated parameters ξ <ref type="bibr" target="#b16">(Samejima, 1968)</ref>, that is,</p><formula xml:id="formula_7">I j (θ) = −E ∂ 2 L(θ; ξ) ∂θ 2 = 3 c=1 − ∂ 2 logP jkc (θ) ∂θ 2 P jkc = 3 c=1 [P * jkc−1 (θ) − P * jkc (θ)] 2 P * jkc−1 (θ) − P * jkc (θ) ,</formula><p>where P * = ∂P * /∂θ. Because the item information is only determined Segment 1858: Difficult to beat the baseline translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Hasta 2007 los dos telescopios Keck situados en el volcán hawaiano de Mauna Kea eran considerados los más grandes del mundo. Reference Until 2007, the two Keck telescopes at the Hawaiian volcano, Mauna Kea, were the largest in the world. DCU <ref type="bibr">[baseline]</ref> Until 2007, the two Keck telescopes located on the Hawaiian volcano Mauna of KEA were considered the largest in the world. Segment 1818: Easy to beat the baseline translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ONLINE-B</head><p>Source Dependiendo de las tonalidades, algunas imágenes de galaxias espirales se convierten en verdaderas obras de arte.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference</head><p>Depending on the colouring, photographs of spiral galaxies can become genuine works of art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCU[baseline]</head><p>Depending on the drink, some images of galaxias galaxies become true works of art.</p><p>ONLINE-B 0.24 Depending on the shades, some images of spiral galaxies become true works of art. UEDIN 0.12 (Same as ONLINE-B) LIMSI-NCODE-SOUL 0.10 Depending on the color, some images of galaxies spirals become real works of art. CU-ZEMAN -0.10 Depending on the tonalidades, some images of spirals galaxies become true works of art. JHU -0.12 Depending on the tonalidades, some images of galaxies spirals become true works of art. SHEF-WPROA -0.92 Depending on the tonalidades, some images of galaxies spirals become real artwork. by segments and is independent of the judges, we set a k = 1 (k ∈ K). <ref type="figure" target="#fig_4">Figure 5</ref> gives two examples of the item infor- mation. The horizontal axis corresponds to the sys- tem performance θ, and the vertical axis represents the informativeness of a segment. This figure in- dicates that segment 1858 (red line) can effectively discriminate systems with θ ≈ 0.13, whereas seg- ment 1818 (blue dashed line) is sensitive to those with θ ≈ −0.11. This means that systems with low θ tend to lose to a baseline translation on segment 1858, and the segment does not tell meaningful in- formation on performance of the systems. However, they sometimes beat a baseline translation on seg- ment 1818, and the segment can measure their per- formance accurately. <ref type="table" target="#tab_2">Table 2</ref> shows translations for segments 1858 and 1818. We found that the baseline translation on seg- ment 1818 was relatively good, whereas the baseline translation on segment 1858 contained wrong words such as "drink" and "galaxias". Consequently, sys- tems with low θ tended to lose to the baseline on segment 1858 due to their wrong translation (see the translation of "hawaiano de Mauna Kea"). In con- trast, some of the low-ranked systems beat the base- line on segment 1818, and the segment contributed to discriminate them.</p><p>The item information is used to design academic tests that can effectively capture students' abilities. It could analogously be used to preselect segments to be translated based on the item information in the MT evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have addressed the task of manual judgment ag- gregation for MT evaluations. Our motivation was three folded: (1) to incorporate a judge's sensitivity to robustly measure a system's performance, (2) to maintain highly interpretable estimates, and (3) to handle with a newly submitted system.</p><p>To tackle these problems, we focused on pairwise comparisons with a fixed baseline translation so that we could apply the GRM model in IRT by using the analogy of standard academic tests. Unlike testing all pairwise combinations of systems, fixing base- line translations makes it easy to evaluate a newly submitted system. We demonstrated that our model gave robust and highly interpretable estimates on the WMT13 datasets.</p><p>In the future work, we will incorporate active learning to the proposed method so that we could reduce the total number of comparisons to obtain fi- nal results. Although we evaluated the correlation between the estimated system performance scores and the WMT official scores, other evaluation pro- cedures might also be considered. For example, <ref type="bibr" target="#b11">Hopkins and May (2013)</ref> considered model perplex- ity and <ref type="bibr" target="#b15">Sakaguchi et al. (2014)</ref> compared accuracy. However, we cannot directly compare other meth- ods to our method in terms of perplexity or accuracy because our method focuses on comparisons with a baseline translation, whereas they do not. It will be required to investigate correlation between the esti- mates and expert decisions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of manual pairwise comparison. Each system yields translations. Judges compare them with a baseline translation and report their preferences. Our goal is to aggregate the judgments to determine the performance of each system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: ICC of graded response model for (b 1 , b 2 ) = (−0.5, 0.5) and a = 1.7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Correlation and nDCG comparing the estimated system performance and gold scores with the number of comparisons for the WMT13 Spanish-English task. The baseline system is shown in parenthesis for TSt and GRM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>DTFO</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Item information for the WMT13 SpanishEnglish task. The DCU was used as a baseline. We used the averaged estimates of b on 100 sampled datasets with 6,400 comparisons to calculate the item information for all segments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(θ =) 0.24 Until 2007 the two Keck telescopes located on the Hawaiian volcano Mauna Kea were considered the largest in the world. UEDIN 0.12 Until 2007, the two Keck telescopes located on the Hawaiian volcano of Mauna Kea were considered the largest in the world. LIMSI-NCODE-SOUL 0.10 Until 2007 the two Keck telescopes in the Hawaiian Mauna Kea volcano were consid- ered the largest in the world. CU-ZEMAN -0.10 Until 2007, the two Keck telescope located in the volcano Mauna Kea hawaiano of were regarded as the world's largest. JHU -0.12 Until 2007, the two Telescope Keck located in the Kea volcano hawaiano of Mauna were considered the world's largest. SHEF-WPROA -0.92 Until 2007 the two telescope Keck located volcano hawaiano of Mauna KEA were re- garded larger of world.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Translation examples for the WMT13 Spanish-English task. The reference is a correct translation given 
by the WMT organizers and was shown to human judges. Estimates of θ (averaged over 100 sampled datasets with 
6,400 comparisons) are also reported in the table. 

</table></figure>

			<note place="foot" n="1"> We also show that our method accurately replicated the WMT13 official system scores using a few comparisons. However, this is not the main focus of this paper.</note>

			<note place="foot" n="2"> In this study, we set T = 21 to include x = 0.</note>

			<note place="foot" n="3"> http://statmt.org/wmt13/results.html</note>

			<note place="foot" n="4"> We also applied the sampling procedure of GRM and TSt to EW and HM, but it made their estimation inaccurate. 5 We did not use Spearman&apos;s rank correlation coefficient because it does not consider a margin between ranks.</note>

			<note place="foot" n="6"> BLEU and METEOR scores were given by the WMT13 organizers. 7 The system-level scores can be found in the WMT13 Metrics Task dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Yukino Baba and Hisashi Kashima for providing an implementation of their method. We are also thankful for the useful com-ments from the anonymous reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Statistical quality estimation for general crowdsourcing tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukino</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisashi</forename><surname>Kashima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="554" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Findings of the 2013 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation (WMT)<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1" to="44" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Findings of the 2014 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saintamand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation (WMT)<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation (WMT)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>Findings of the 2015 workshop on statistical machine translation</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rank analysis of incomplete block designs: I. the method of paired comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milton</forename><forename type="middle">E</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="324" to="345" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pairwise ranking aggregation in a crowdsourced setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">N</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth ACM International Conference on Web Search and Data Mining (WSDM)</title>
		<meeting>the Sixth ACM International Conference on Web Search and Data Mining (WSDM)<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013-02" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evaluating human pairwise preference judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="345" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Crowdsourcing for evaluating machine translation quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Goto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toru</forename><surname>Ishida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC)<address><addrLine>Reykjavik, Iceland, May</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Can machine translation systems be evaluated by the crowd alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Human evaluation of grammatical error correction systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Gillian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">TrueSkill TM : A bayesian skill rating system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20 (NIPS)</title>
		<meeting><address><addrLine>Vancouver, British Columbia, Canada, Demeber</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Models of translation competitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st</title>
		<meeting>the 51st</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simulating human judgment in machine translation evaluation campaigns</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Workshop on Spoken Language Translation (IWSLT)</title>
		<meeting>International Workshop on Spoken Language Translation (IWSLT)<address><addrLine>Sofia, Bulgaria; Hongkong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-08" />
			<biblScope unit="page" from="179" to="184" />
		</imprint>
	</monogr>
<note type="report_type">Philipp Koehn</note>
	<note>Annual Meeting of the Association for Computational Linguistics (ACL). International Speech Communication Association</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ground truth for grammatical error correction metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd</title>
		<meeting>the 53rd</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="588" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient elicitation of annotations for human evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation (WMT)</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation (WMT)<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Estimation of latent ability using a response pattern of graded scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumiko</forename><surname>Samejima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ETS Research Bulletin Series</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">169</biblScope>
			<date type="published" when="1968-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
