<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speech segmentation with a neural encoder model of working memory</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
							<email>melsner0@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cory</forename><surname>Shain</surname></persName>
							<email>shain.3@osu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Linguistics</orgName>
								<orgName type="institution">The Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Speech segmentation with a neural encoder model of working memory</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1070" to="1080"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present the first unsupervised LSTM speech segmenter as a cognitive model of the acquisition of words from unseg-mented input. Cognitive biases toward phonological and syntactic predictability in speech are rooted in the limitations of human memory (Baddeley et al., 1998); compressed representations are easier to acquire and retain in memory. To model the biases introduced by these memory limitations, our system uses an LSTM-based encoder-decoder with a small number of hidden units, then searches for a segmentation that minimizes autoencod-ing loss. Linguistically meaningful segments (e.g. words) should share regular patterns of features that facilitate de-coder performance in comparison to random segmentations, and we show that our learner discovers these patterns when trained on either phoneme sequences or raw acoustics. To our knowledge, ours is the first fully unsupervised system to be able to segment both symbolic and acoustic representations of speech.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes a new cognitive model of the acquisition of word-like units from unsegmented input. The model is intended to describe the pro- cess by which pre-linguistic infants learn their ear- liest words, a stage they pass through during the first year of life <ref type="bibr" target="#b28">(Jusczyk and Aslin, 1995;</ref><ref type="bibr" target="#b4">Bergelson and Swingley, 2012)</ref>. Our model is based on the standard memory model of <ref type="bibr" target="#b3">Baddeley and Hitch (1974)</ref> in which the listener encodes lexical items into phonological working memory, but rep- resents the entire sentence as a higher-level syn- tactic structure without phonological detail. Our model implements this architecture using encoder- decoder LSTMs with limited memory capacity, then searches for word segmentations which make it easy to remember the sentence. <ref type="bibr">1</ref> Word learning has been extensively studied in previous research, both with transcribed symbolic input and acoustics. Why attempt yet another ap- proach? Our model has three main advantages. First, as a cognitive model, it relates the kinds of learning biases used in previous work to the wider literature on working memory. Second, its sequence-to-sequence neural architecture allows it to handle either one-hot symbolic input or dense vectors of acoustic features. In contrast, existing models are typically designed for "clean" sym- bolic input, then retrofitted with additional mech- anisms to cope with acoustics. Finally, neural net- works have been impressively successful in super- vised language processing domains, yet are still underused in unsupervised learning. Even sys- tems which do use neural nets to model lexical ac- quisition generally require an auxiliary model for clustering the embeddings, which can make their learning objectives difficult to understand. Our system uses the well-understood autoencoder ob- jective to perform the segmentation task without requiring auxiliary clustering, and thus suggests a new direction for neural unsupervised learning.</p><p>In an experiment conducted on the widely used Brent corpus <ref type="bibr" target="#b8">(Brent, 1999)</ref>, our system achieves performance close to that of <ref type="bibr" target="#b20">Fleck (2008)</ref>, al- though subsequent systems outperform ours by a wider margin. We show that memory limitations do indeed drive the performance of the system, with smaller LSTM hidden states outperforming larger ones in the development set.</p><p>In a follow-up experiment designed to ex-plore the flexibility of our model, we deploy the segmenter on acoustic input: the English por- tion of the Zerospeech 2015 challenge <ref type="bibr" target="#b51">(Versteegh et al., 2015)</ref>. Our model outperforms the win- ning model from that challenge <ref type="bibr">(Räsänen et al., 2015</ref>), although we underperform more recent un- supervised acoustic segmentation systems <ref type="bibr" target="#b30">(Kamper et al., 2016;</ref><ref type="bibr">Räsänen et al., under review)</ref>. To our knowledge, our system is the first un- supervised LSTM speech segmenter, as well as the first unsupervised speech segmenter to succeed on both symbolic and acoustic representations of speech. Our results are of note for several reasons. First, they provide modeling support for the claim that memory limitations encourage lexical acquisi- tion. Second, they show that a general strategy of searching for maximally compressible represen- tations can realistically guide lexical acquisition without explicit reference to perceptual biases (c.f. e.g. <ref type="bibr">Räsänen et al., 2015)</ref>, regardless of input rep- resentation. And third, they demonstrate the bene- fits of our adaptation of neural sequence modeling to unsupervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivations</head><p>We begin with a short overview of previous ap- proaches to the word learning problem, then ex- plain each of our main contributions in detail. Many cognitive models of the word learning prob- lem draw on Brent (1999), which used a sim- ple unigram model of the lexicon to discover re- peated patterns in phonemically transcribed input. Brent's model laid the groundwork for later gen- erative models with more sophisticated prior dis- tributions over word frequencies, co-occurrence statistics and phonological shapes , among others). Other model- ing architectures for segmentation have focused on detecting phonological boundaries between words using transitional probabilities <ref type="bibr" target="#b12">(Christiansen et al., 1998</ref>, among others) or inducing words procedu- rally by "subtracting" known word forms from ut- terances <ref type="bibr" target="#b35">(Lignos, 2011)</ref>.</p><p>All these modeling architectures are designed to work with phonemically transcribed input, and require some degree of retrofitting to work with more realistic inputs. In the Bayesian framework, this typically takes the form of a transducer which probabilistically transforms "underlying" lexical items to "surface" acoustics ( <ref type="bibr" target="#b34">Lee et al., 2015)</ref> or discrete symbols <ref type="bibr" target="#b18">(Elsner et al., 2013)</ref>; the same framework is used for morphological segmenta- tion in <ref type="bibr" target="#b14">Cotterell et al. (2015)</ref>. For transition- based models, the input must be transformed into discrete symbols from which segment-to-segment probabilities can be extracted; this transforma- tion requires an externally trained preprocessor (a phone recognizer). Transition-based models are fairly robust to variation in the symbols <ref type="bibr" target="#b43">(Rytting, 2007;</ref><ref type="bibr" target="#b44">Rytting et al., 2010;</ref><ref type="bibr" target="#b15">Daland and Pierrehumbert, 2011;</ref><ref type="bibr" target="#b20">Fleck, 2008)</ref> and can be relatively suc- cessful in this framework. Extensions using neural nets <ref type="bibr" target="#b12">(Christiansen et al., 1998;</ref><ref type="bibr" target="#b44">Rytting et al., 2010)</ref> are discussed in more detail below (subsec. 2.3). Lignos (2011) requires the most complex prepro- cessing of the input (segmentation into syllables, with marked lexical stresses); adapting it to noisy input is an open problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Working memory and learning biases</head><p>Cognitive models of word segmentation rely on two kinds of learning biases to structure their in- ferred lexicons: predictability within words (of- ten expressed as a prior over phonological forms), and Zipfian unigram and bigram frequencies of words (a prior over word distributions). These biases control the entropy of utterances, making it easy for adult listeners to remember what they hear and reconstruct any missing parts from con- text ( <ref type="bibr" target="#b40">Piantadosi et al., 2012</ref>). The biases corre- spond to different components in a standard model of working memory <ref type="bibr" target="#b1">(Baddeley, 2007;</ref><ref type="bibr" target="#b3">Baddeley and Hitch, 1974)</ref>. In this model, listeners can store the last few items they heard in a phonolog- ical loop, from which words are transferred into episodic memory which represents them at a syn- tactic/semantic level. <ref type="bibr" target="#b2">Baddeley et al. (1998)</ref> claim that the phonologi- cal loop functions in word learning as well as pro- cessing by proficient listeners, aiding in the ac- quisition of unfamiliar words. They summarize a number of studies showing that the vocabulary size of typically developing infants correlates with their ability to remember a sequence of phono- logically plausible non-words, a test of phonolog- ical loop capacity. Children with Specific Lan- guage Impairment, meanwhile, remember non- words poorly, a deficit which may contribute to their atypically small vocabularies. <ref type="bibr" target="#b2">Baddeley et al. (1998)</ref> argue that the ability to remember an unfa- miliar phonological form in the short term is es- sential if it is to be transferred to long-term mem-ory as a datapoint for lexical learning. This ac- count of word learning is one of a growing number which attempt to unify acquisition and speech pro- cessing in terms of the same real-time, resource- constrained mechanisms <ref type="bibr" target="#b0">(Apfelbaum and McMurray, 2016</ref>).</p><p>In our model, memorization itself can be viewed as the objective for early word learning. The model attempts to reconstruct its input from mem- ory; chunks that are easy to reconstruct (and that make the context reconstructible) are good can- didate words. The working memory model ac- counts for the two types of bias normally found in Bayesian segmenters. Phonological predictabil- ity due to consistent word shapes <ref type="bibr" target="#b6">(Börschinger and Johnson, 2014;</ref>) re- duces the load on the phonological loop. Pre- dictability between words reduces the load on syn- tactic memory. The two memory systems draw on different cognitive resources, which correspond to different parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Input representations</head><p>As stated above, traditional segmentation models operate on phonemic transcriptions and must be adapted to cope with phonetic or acoustic input. For models which infer an explicit lexicon (i.e., those which do not simply count segment transi- tions), this takes the form of a mapping between the data and the space of "underlying" latent word forms.</p><p>Learning such a mapping can be problematic. Traditional generative learning models use para- metric distributions over the data-for acoustics, <ref type="bibr">Gaussians (Vallabha et al., 2007;</ref><ref type="bibr" target="#b19">Feldman et al., 2009)</ref> or Gaussian-HMMs ( <ref type="bibr" target="#b33">Lee and Glass, 2012;</ref><ref type="bibr" target="#b34">Lee et al., 2015)</ref>. But these are a notoriously poor fit to real speech sounds <ref type="bibr" target="#b21">(Glass, 2003)</ref>.</p><p>An example of an alternative approach to rep- resentation learning from acoustics is <ref type="bibr">Räsänen et al. (2015)</ref>. They exploit known acoustic indi- cators of syllable boundaries to infer syllable seg- ments, cluster those segments using expectation- maximization (EM), and then identify multisyl- labic words by searching for recurring cluster n- grams. As a result, their system is constrained to propose word boundaries only at proposed syl- lable boundaries regardless of the representations acquired downstream. Furthermore, EM is known to find non-optimal solutions for many problems in natural language <ref type="bibr" target="#b26">(Johnson, 2007)</ref>. To the ex- tent that this inhibits their system's ability to ex- ploit information in the acoustic feature space, it might lead to misidentification of recurrent sylla- ble n-grams and consequently to segmentation er- ror.</p><p>Latent underlying representations can also cause search problems, since the model must ex- plore all the possible underlying forms which might map to some utterance on the surface. In a probabilistic system capable of mapping every word to every possible realization, this quickly be- comes intractable. Many systems use dynamic programming ( <ref type="bibr" target="#b38">Mochihashi et al., 2009;</ref><ref type="bibr" target="#b39">Neubig et al., 2010)</ref>, sometimes with pruning <ref type="bibr" target="#b50">(Van Gael et al., 2008)</ref>. But these algorithms require Markov models with small context windows, and in any case can still be slow and prone to search errors.</p><p>Neural nets, on the other hand, learn a non- linear mapping between input and output. This allows them to model speech more flexibly, out- competing Gaussian/HMMs for supervised speech recognition ( <ref type="bibr" target="#b23">Graves et al., 2013;</ref><ref type="bibr" target="#b24">Hinton et al., 2012)</ref>. Recurrent neural nets also produce hidden representations differently than HMMs. Rather than use dynamic programming to search a latent space, they produce a single vector deterministi- cally at each timestep. Models such as LSTMs <ref type="bibr" target="#b25">(Hochreiter and Schmidhuber, 1997</ref>) can learn long-distance sequential dependencies in their in- put without making inference more expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Neural unsupervised learning</head><p>A few previous papers have used neural networks for word segmentation. <ref type="bibr" target="#b12">Christiansen et al. (1998)</ref>, drawing on older work with Simple Recurrent Networks <ref type="bibr" target="#b17">(Elman, 1990)</ref>, trains a recurrent net- work as a language model. Word boundaries are extracted at points where the network predicts an upcoming utterance boundary; that is, utterance boundaries are used as distant supervision for the locations of word boundaries. While effective, this system uses symbolic rather than acoustic input. Moreover, it may have trouble with word endings which do not end utterances, such as the endings of function words; experiments show that infants learn detailed representations of function words by 13 months <ref type="bibr" target="#b45">(Shi et al., 2006</ref>) and use known words as "anchors" for segmentation within utterances ( <ref type="bibr" target="#b7">Bortfeld et al., 2005</ref>).</p><p>Rytting (2007) adapts the Christiansen model to variable input by using the posterior probabil-ity distribution from a phone recognizer as its fea- ture representation. This system was run on natu- ral data; results for word boundary detection were significantly above chance, though still much less accurate than results for symbolic input. The use of utterance boundaries as distant supervision may create problems for this system similar to those pointed out for Christiansen above. Moreover, the use of an SRN rather than an LSTM means that the system is essentially phonotatic; it makes its deci- sions based on the previous one or two phones, without the capacity to remember whole lexical items.</p><p>Recent work ( <ref type="bibr" target="#b30">Kamper et al., 2016)</ref> has at- tempted to harness the flexibility of neural fea- ture extractors within the generative model frame- work. This model has a hybrid architecture con- sisting of a neural feature extractor, the Correspon- dence Autoencoder, pretrained using distant su- pervision ( <ref type="bibr" target="#b29">Kamper et al., 2015)</ref>, and a Bayesian clustering/segmentation model. The system repre- sents each word by neurally encoding its frames, then downsampling to obtain a fixed-dimensional word vector; the clustering model assumes that these vectors can be modeled with Gaussian clus- ters. The advantage of this approach is its ability to exploit the known strengths of both Bayesian and neural learning systems. The disadvantage is its indirectness: there is no end-to-end objective to be optimized, and the system's lexical learning does not inform its phonetic representations.</p><p>Even outside the domain of segmentation, neu- ral networks have been most successful for super- vised problems, and are not widely used for un- supervised learning of discrete structures (trees, clusters, segment boundaries). While some re- searchers have proposed information-theoretic ob- jectives for learning clusters <ref type="bibr" target="#b32">(Klapper-Rybicka et al., 2001</ref>), the most widely used unsupervised objective is the one used here: autoencoding. Yet autoencoders are rarely used to learn discrete hidden structures. One exception, <ref type="bibr" target="#b46">Socher et al. (2011)</ref>, uses autencoders to find a latent tree struc- ture for sentiment analysis by greedily merging adjacent nodes so as to minimize the reconstruc- tion error. <ref type="bibr" target="#b13">Chung et al. (2017)</ref> describe a model similar to our own which performs a segmentation task using autoencoders. Both models use multiscale autoencoding to learn a sequence model with un- known segment boundaries. The main difference is the different technique used to deal with the discontinuities caused by switching discrete seg- ment boundary variables. However, they evaluate their model on downstream tasks (notably, char- acter language modeling) without evaluating the segmentations directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Model</head><p>The model uses a basic encoder-decoder archi- tecture now typical in machine translation ( <ref type="bibr" target="#b10">Cho et al., 2014</ref>) and image captioning ( <ref type="bibr" target="#b53">Vinyals et al., 2015)</ref>. In a typical encoder-decoder, the input is fed into an LSTM sequence model <ref type="bibr" target="#b25">(Hochreiter and Schmidhuber, 1997</ref>) which represents it as a la- tent numeric embedding. This embedding is then fed into another sequence model, which uses it to generate an output sequence. Our two-level model performs this process in stages, first encoding ev- ery word, character-by-character, and then encod- ing the word sequence, vector-by-vector. In an au- toencoder, the objective is to make input and out- put match; thus, the decoder performs the encod- ing stages in reverse. We provide the final encoder hidden state as input to each decoder unit. To force the system's learned embeddings to be robust to noise caused by mishearing or misremembering, we use dropout ( <ref type="bibr" target="#b47">Srivastava et al., 2014</ref>) at the in- put (deleting individual timesteps) and at the word encoding layer (deleting entire words). This archi- tecture is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>The encoder-decoder does not predict segment boundaries directly, but gives an objective func- tion (reconstruction loss) which can be used to guide segmentation. Because the segment bound- ary decisions are hard (there are no "partial" boundaries), the loss function is not differentiable as a function of the boundary indicators. We use sampling to estimate the gradient, as in previous work <ref type="bibr" target="#b37">(Mnih et al., 2014;</ref><ref type="bibr" target="#b54">Xu et al., 2015</ref>). Our sampling system works as follows: we begin with a proposal distribution P seg over sequences of seg- ment boundaries for the current utterance x. We sample m sequences of boundaries, B 1:m from P seg . Each boundary sequence splits the utterance into words. We use the autoencoder network to encode and decode the words, and obtain the loss (the cross-entropy of the reconstructed input) for each sequence, L 1:m .</p><p>We can use the cross-entropy to estimate the posterior probability of the data given a breakpoint sequence (Eq. 1), assuming a uniform prior over break positions. We then treat each breakpoint t in the utterance independently: for each one, we use the losses and the proposal probabilities to com- pute an importance weight w t i for sample i and po- sition t (Eq. 2), then compute the expected prob- ability of a boundary at that position by summing over the weighted samples (Eq. 3). Essentially, a breakpoint will be more likely if it appeared in samples with low reconstruction loss, especially if it is not encouraged by the current proposal.</p><formula xml:id="formula_0">P (x|B i ) = P (B i |x)P (B i ) P (x) ≈ exp(L i ) j exp(L j )<label>(1)</label></formula><formula xml:id="formula_1">w t i = P (x|B i ) P t seg (B t i )<label>(2)</label></formula><formula xml:id="formula_2">E[B(t)] ≈ 1 i w t i i w t i B t i<label>(3)</label></formula><p>We initialize by making random breakpoint pro- posals (with probability .1 at each position). The random proposal does not search the space of seg- mentation boundaries particularly efficiently, so we train a better proposal using another LSTM. This LSTM simply reads the input from left to right and predicts a binary output (segment or not) at each timestep. We update the proposal LSTM by using the sampling-derived P seg as a training target after each batch. Thus, the proposal learns to predict segment boundaries that are likely to re- sult in low reconstruction loss for the main net- work. To force the system to explore the space, we smooth the learned proposal by interpolating it with a uniform distribution:</p><formula xml:id="formula_3">P seg = .9×P LST M + .1 × 1 2 .</formula><p>We control the memory capacity of the system using four tunable parameters: the number of hid- den states at the phonological level (H p ) and at the utterance level (H u ) and the dropout probabil- ity of mishearing a phonological segment (D p ) or a word (D u ). We discuss parameter tuning results below.</p><p>The system also has several other parameters which were not tuned against the evaluation met- ric. For convenience in GPU training, we treat all sequences as fixed length, either clipping them or padding with a dummy symbol. This requires us to set a maximum length for each word (in charac- ters), and each utterance (in words and characters); we set these parameters to ensure 99% coverage of the input (for the Brent corpus, 7, 10, and 30 respectively).</p><p>Clipping creates the possibility of pathological outcomes where the system deliberately creates extremely long words, exploiting the fact that the excess characters will be discarded and will not have to be predicted in the output. We penalize this by subtracting 50 for each deleted character. Fi- nally, we find that, despite pre-training, the system may settle into an initial state where the phono- logical network simply embeds the characters and the utterance network learns a character LM. To avoid this, we subtract 10 from the objective for each one-symbol word. These parameters were tuned only lightly; we increased the values until the problematic behavior (segmentation of the en- tire utterance as one word, or each character as a word) ceased.</p><p>We implemented the network in Keras <ref type="bibr" target="#b11">(Chollet, 2015)</ref>, using Adam ( <ref type="bibr" target="#b31">Kingma and Ba, 2014</ref>) with default settings for optimization. We use mini- batches of 128 and take 100 samples of potential segment boundaries per sequence. We perform 10 iterations of pretraining with random boundaries, 10 iterations of boundary induction with random proposals, and 70 iterations of full training with the learned LSTM proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Brent Corpus</head><p>The Brent corpus <ref type="bibr" target="#b8">(Brent, 1999</ref>) is a standard benchmark dataset for segmentation, consisting of 9790 utterances from <ref type="bibr" target="#b5">Bernstein-Ratner (1987)</ref>, translated into phonemic transcription using the CMU dictionary. The standard metrics for seg- mentation are F-score for word boundary detec- tion (treating each boundary in isolation) and F- score for word token segmentation (a word is cor- rect only if both its boundaries are correct and no spurious boundaries intervene). Although early work on Brent used all 9790 utterances for both development and test, we use the first 8000 utter- ances for parameter tuning. Thus, we present re- sults for the whole corpus (for comparison with previous work) and clean test results for the last 1790.</p><p>We tune the four parameters of our system, H p , H u , D p and D u , using a grid search (see <ref type="figure">Fig- ure 2)</ref>. Each subplot shows a particular dropout setting, D p /D u ; the cells within represent set- tings of H p (rows) and H u (columns), where darker cells have higher boundary F-score. Exces- sive noise decreases scores, especially high word dropout (right side of the plot). For low levels of dropout, the best systems tend to have small numbers of hidden units (dark regions in the lower left); for larger dropout, more hidden units can be useful. For instance, compare the top left subplot, with 0 dropout and good performance with H p = 20, H u = 100, to subplot 3,3, with optimal per- formance at H p = 80, H u = 200. In other words, limiting the system's memory resources is indeed the key to its performance. The best score occurs at H p = 80, H u = 400, D p = 0.5, D u = 0.25 with a dev boundary F-score of 83%. We used these parameters for our final evaluation, along with 100 hidden units in the proposal network.</p><p>To further demonstrate that limited memory can bias the network to learn a low-entropy lexi- con, we perform a separate experiment using the phonological encoder/decoder alone. We create  networks with varying H p (setting D p to 0); for each network size, we train one net on real words from the gold segmentation of Brent, and another on length-matched pseudowords sampled by ran- domly segmenting the Brent corpus. <ref type="figure">Figure 3</ref> shows the reconstruction error rates as a function of H p . The gap between the green and orange lines shows the difference in reconstruction error obtained by using real words rather than pseu- dowords. For the smallest H p , neither network does a good job; for the largest, both networks learn the sequences perfectly. For values in be- tween, however, the lines are relatively far apart, showing that the real words are easier for the net- work to remember.</p><note type="other">Du 0.25 Du 0.5 Du 0.</note><p>Our results for Brent, along with selected com- parisons, are shown in <ref type="table">Table 1</ref>. <ref type="bibr">2</ref> Our system per-System Bd P Bd R Bd F Wd <ref type="table" target="#tab_0">F  Goldwater 09  90  74  87  74  Johnson 09  - - - 88  Berg- Kirkpatrick  10   - - -</ref>  forms at the lower end of the reported range for Brent segmenters, scoring 83% for boundary de- tection and 72% for word detection (comparable to <ref type="bibr" target="#b20">(Fleck, 2008)</ref>  <ref type="bibr" target="#b52">Vihman et al., 2004;</ref><ref type="bibr" target="#b48">Swingley, 2005)</ref>. But this does not im- ply that they learn every word they hear, or that they can use their word knowledge to segment ev- ery utterance correctly. Thus, while our result is not state-of-the-art, it is good enough to conform with the reported infant results and suggest that our neural architecture is a promising direction. Learning curves for segmentation on the Brent corpus are shown in <ref type="figure" target="#fig_3">Figure 4</ref>. The first 10 it- erations show a gradual increase in segmentation performance using the random proposal. Perfor- mance increases sharply with the activation of the learned proposal, then climbs slowly over time. Precision initially exceeds recall (that is, the sys- tem proposes too few boundaries) but recall climbs over time as the system exploits known words as "anchors" to discover new ones, a pattern consis- tent with the infant data ( <ref type="bibr" target="#b7">Bortfeld et al., 2005</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Zerospeech 2015 acoustic segmentation</head><p>We began by claiming that an advantage of our model was its flexible architecture that permits dense acoustic features as input (rather than sym- bolic phone labels) with little modification. In this section, we present preliminary results from respective publications, except for , which are corrected numbers published with their software release. Not all systems report all metrics. a follow-up experiment in which we tested this claim by deploying our system as an acoustic seg- menter on the English portion of the Zerospeech 2015 challenge dataset ( <ref type="bibr" target="#b51">Versteegh et al., 2015)</ref>. We preprocess the raw acoustic data by extract- ing 25ms 13-dimensional mel frequency cepstral coefficients with first and second order deltas at a step size of 10ms. We then train the network on the resulting sequences of 39-dimensional frames.</p><p>Given that the goal of the experiment was to test the existing architecture on a novel task, we intentionally conducted this experiment with min- imal parameter tuning or architectural modifica- tion. However, we made several key changes in response to the unique challenges presented by acoustic input.</p><p>First, since we are now reconstructing dense vectors of acoustic features, we use mean squared error (MSE) instead of categorical cross-entropy as the autoencoder loss function. We consequently rescale our clipping penalty from 50 to 1, a coeffi- cient which seemed more in balance with the vari- ation in decoder loss produced by MSE. We also increase our one-letter penalty from 10 to 50, mod- eling our strong prior assumption that a 1-frame segment will never correspond to a word.</p><p>Second, in contrast to the phoneme sequences in the Brent corpus discussed above, utterance boundaries are not observed in acoustic input. The input to the two-level autoencoder must be divided into sequences of utterances, so we imposed utter- ance boundaries by iteratively consuming the next discovered word in the time series up to the maxi-  mum utterance length (in frames). The aforemen- tioned clipping penalties punish the system for ut- terances that contain too many words, preventing it from optimizing its autoencoder loss by seg- menting everywhere. Third, for our initial proposal distribution we use the speech region segmentation provided by the Zerospeech challenge, consisting of speech in- tervals identified through automatic voice activ- ity detection (VAD), rather than using the uniform initialization described above for symbolic mode. We interpolate the initial distribution with a uni- form prior as described above.</p><p>Fourth, we discovered in practice that the as- sumption of independence between samples made by the importance scoring scheme as implemented for symbolic mode was distortionary in acoustic mode, such that the "best" segmentation discov- ered through sampling often contained many times more segments than any of its component sam- ples. <ref type="bibr">3</ref> To prevent this from happening, we simply used 1-best rather than importance sampling for acoustic segmentation.</p><p>We trained the system for 80 iterations using pa- rameters H p = 20, H u = 400, D p = 0, D u = 0.25 and 1500 hidden units in the proposal LSTM. In the auto-encoder network, we limited frames per utterance, words per utterance, and frames per word to 400, 16, and 100, respectively. Results are presented in <ref type="table" target="#tab_3">Table 2</ref>, along with a compari- son to results from other systems. <ref type="bibr" target="#b36">Lyzinski et al. (2015)</ref> and <ref type="bibr">Räsänen et al. (2015)</ref> were entrants in the Zerospeech 2015 challenge, in which <ref type="bibr">Räsänen et al. (2015)</ref> performed best in the word bound-ary detection measure. As shown in the table, our system beats both of these competitors' boundary detection scores, with a word detection score com- parable to that of <ref type="bibr">Räsänen et al. (2015)</ref>. How- ever, since the challenge concluded, Räsänen et al. (under review) have modified their system and improved their segmentation score, <ref type="bibr">4 and Kamper et al. (2016)</ref> have established a new state of the art for this task. While our system currently re- mains far from these newer benchmarks, we ex- pect that with systematic parameter tuning and in- vestigation into appropriate sampling procedures for acoustic input, we might be able to improve substantially on the results presented here. We be- lieve that the results of this preliminary investiga- tion into the acoustic domain are promising, and that they bear out our claims about the flexibility of our general architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and future directions</head><p>This work presented a new unsupervised LSTM architecture for discovering meaningful segments in representations of continuous speech. Mem- ory limitations in the autoencoder part of the net- work apply pressure to discover compressed rep- resentations much as human memory limitations have been argued to guide lexical acquisition. By varying the size of the LSTM's hidden state, we showed that word segmentation performance on the Brent corpus is driven by memory limitations, with performance improving (up to a point) as we constrain the system's memory capacity. And by successfully deploying our system on both sym- bolic (character) and acoustic representations of speech, we demonstrated that our approach is flex- ible enough to adapt to either representation of the speech stimulus.</p><p>In the future we hope to pursue a number of lines of inquiry. We plan to conduct more de- tailed parameter tuning in the acoustic domain and to segment the Xitsonga dataset supplied with the Zerospeech 2015 challenge. We also intend to introduce additional layers into the autoencoder network so as to allow for joint acquisition of phone-like, morph-like, and/or word-like units in the acoustic signal; this may benefit from the al- ternate model structure of <ref type="bibr" target="#b13">Chung et al. (2017)</ref>. And we plan to explore clustering techniques that would allow our system to discover categories in addition to probable segmentation points.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of the model: top two panels show the encoder/decoder, bottom panels show computation of breakpoints and resulting loss. Horizontal arrows represent LSTMs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Tuning results on Brent development. Cell axes represent H u and H p , darker cells have higher scores (best 83%, worst 60%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Boundary precision, recall, and F1 score by iteration on the entire Brent dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>88</head><label>88</label><figDesc></figDesc><table>Fleck 08 
95 
74 
83 
71 
Ours (all) 
81 
85 
83 
72 
Ours (test) 
81 
86 
83 
72 

Table 1: Selected segmentation results on Brent. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Selected word segmentation results on the 
the Zerospeech 2015 English corpus. 

</table></figure>

			<note place="foot" n="1"> The system is available from https://github. com/melsner/neural-segmentation.</note>

			<note place="foot" n="2"> Comparison system scores are those reported in their</note>

			<note place="foot" n="3"> We believe this is driven by training batches in which multiple samples receive similar scores but have fairly nonoverlapping segmentations. In this case, the output segmentation can contain something close to the union of the best samples&apos; segmentation points, leading to oversegmentation. This effect is likely exaggerated in acoustic mode as compared to symbolic mode because acoustic word segments are generally much longer (in frames) than their corresponding symbolic word segments (in characters).</note>

			<note place="foot" n="4"> The new results are not yet published. Those reported above are copied from the results summary in Kamper et al. (2016).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank members of the Clippers discussion group (especially Joo-Kyung Kim, Eric Fosler-Lussier and Wei Xu) and three anonymous review-ers. Computations for this project were run on a Titan-X GPU donated by the NVIDIA Hardware Grant program and on the Ohio Supercomputer <ref type="bibr">(1987)</ref>. Funding was provided by NSF #1422987.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning during processing: Word learning doesn&apos;t wait for word recognition to finish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Apfelbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcmurray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Working memory, thought and action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Baddeley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The phonological loop as a language learning device</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Gathercole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costanza</forename><surname>Papagno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Hitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="47" to="89" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">At 69 months, human infants know the meanings of many common nouns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elika</forename><surname>Bergelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Swingley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3253" to="3258" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The phonology of parentchild speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Bernstein-Ratner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Children&apos;s Language</title>
		<editor>K. Nelson and A. van Kleeck</editor>
		<meeting><address><addrLine>Erlbaum, Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring the role of stress in Bayesian word segmentation using adaptor grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Börschinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="93" to="104" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mommy and me</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><surname>Bortfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberta</forename><forename type="middle">Michnick</forename><surname>Golinkoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Rathbun</surname></persName>
		</author>
		<idno type="doi">10.1111/j.0956-7976.2005.01531.x</idno>
		<ptr target="https://doi.org/10.1111/j.0956-7976.2005.01531.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="298" to="304" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An efficient, probabilistically sound algorithm for segmentation and word discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="71" to="105" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ohio Supercomputer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Center</surname></persName>
		</author>
		<ptr target="http://osc.edu/ark:/19495/f5s1ph73" />
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1179" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning to segment speech using multiple cues: A connectionist model. Language and Cognitive Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Seidenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="221" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hierarchical multiscale recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling word forms using latent underlying morphs and phonology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="433" to="447" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning diphone-based segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Daland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">B</forename><surname>Pierrehumbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="155" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<idno type="doi">10.1111/j.1551-6709.2010.01160.x</idno>
		<ptr target="https://doi.org/10.1111/j.1551-6709.2010.01160.x" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeffrey L Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A joint learning model of word segmentation, lexical acquisition, and phonetic variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="42" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning phonetic categories by learning a lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naomi</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Morgan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual Conference of the Cognitive Science Society</title>
		<meeting>the 31st Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lexicalized phonotactic word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><forename type="middle">M</forename><surname>Fleck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT. Association for Computational Linguistics</title>
		<meeting>ACL-08: HLT. Association for Computational Linguistics<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="130" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A probabilistic framework for segment-based speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="137" to="152" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Bayesian framework for word segmentation: Exploring the effects of context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="54" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Abdel-Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel</forename><surname>Rahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Why doesn&apos;t EM find good HMM POS-taggers?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>In EMNLP</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving nonparametric Bayesian inference: Experiments on unsupervised word segmentation with adaptor grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Infants&apos; detection of the sound patterns of words in fluent speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jusczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richard N Aslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised neural network based feature extraction using weak top-down constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Kamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5818" to="5822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A segmental framework for fullyunsupervised large-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Kamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06950</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>CoRR abs/1412.6980</idno>
		<ptr target="http://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unsupervised learning in LSTM recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magdalena</forename><surname>Klapper-Rybicka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="684" to="691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A nonparametric Bayesian approach to acoustic model discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P12-1005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="40" to="49" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised lexicon discovery from acoustic input</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J O&amp;apos;</forename><surname>Timothy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="389" to="403" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Modeling infant word segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Lignos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifteenth conference on computational natural language learning</title>
		<meeting>the fifteenth conference on computational natural language learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An evaluation of graph clustering methods for unsupervised term discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vince</forename><surname>Lyzinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Sell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Jansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bayesian unsupervised word segmentation with nested Pitman-Yor language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daichi</forename><surname>Mochihashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P/P09/P09-1012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Association for Computational Linguistics</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Association for Computational Linguistics<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="100" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning a language model from continuous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masato</forename><surname>Mimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Annual Conference of the International Speech Communication Association</title>
		<meeting><address><addrLine>Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Makuhari</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1053" to="1056" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The communicative function of ambiguity in language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harry</forename><surname>Steven T Piantadosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Tily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="280" to="291" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised word discovery from speech using automatic segmentation into syllable-like units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Okko Räsänen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech 2015</title>
		<meeting>Interspeech 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3204" to="3208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">under review. Pre-linguistic rhythmic segmentation of speech into syllabic units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Okko Räsänen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Preserving Subsegmental Variation in Modeling Word Segmentation (Or, the Raising of Baby Mondegreen)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Rytting</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>The Ohio State University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Segmenting words from natural speech: subsegmental variation in segmental cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Rytting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Fosler-Lussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Child Language</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="513" to="543" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Recognition and representation of function words in english-learning infants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">F</forename><surname>Werker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Cutler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infancy</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="198" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Semi-supervised recursive autoencoders for predicting sentiment distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Statistical clustering and the contents of the infant vocabulary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Swingley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="86" to="132" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised learning of vowel categories from infant-directed speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Vallabha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">F</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeaki</forename><surname>Werker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="13273" to="13278" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Beam sampling for the infinite Hidden Markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Van Gael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunus</forename><surname>Saatci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="doi">10.1145/1390156.1390293</idno>
		<ptr target="https://doi.org/10.1145/1390156.1390293" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine learning</title>
		<meeting>the 25th International Conference on Machine learning<address><addrLine>New York, NY, USA, ICML &apos;08</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1088" to="1095" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The zero resource speech challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Versteegh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Rolandthiollì Ere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><forename type="middle">Nga</forename><surname>Schatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aren</forename><surname>Anguerra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dupoux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The role of accentual pattern in early lexical representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satsuki</forename><surname>Marilyn M Vihman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rory</forename><forename type="middle">A</forename><surname>Nakai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Depaolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hallé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="336" to="353" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML. JMLR</title>
		<meeting>ICML. JMLR<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
