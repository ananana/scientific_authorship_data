<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Show Me Your Evidence-an Automatic Method for Context Dependent Evidence Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research -Haifa</orgName>
								<address>
									<addrLine>Mount Carmel</addrLine>
									<postCode>31905</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lena</forename><surname>Dankin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research -Haifa</orgName>
								<address>
									<addrLine>Mount Carmel</addrLine>
									<postCode>31905</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Alzate</surname></persName>
							<email>carlos.alzate@ie.ibm.com mikhapra@in.ibm.com</email>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research -Ireland</orgName>
								<address>
									<addrLine>Damastown Industrial Estate, Dublin 15</addrLine>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitesh</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">IBM Research -Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research -Haifa</orgName>
								<address>
									<addrLine>Mount Carmel</addrLine>
									<postCode>31905</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research -Haifa</orgName>
								<address>
									<addrLine>Mount Carmel</addrLine>
									<postCode>31905</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Show Me Your Evidence-an Automatic Method for Context Dependent Evidence Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Engaging in a debate with oneself or others to take decisions is an integral part of our day-today life. A debate on a topic (say, use of performance enhancing drugs) typically proceeds by one party making an assertion/claim (say, PEDs are bad for health) and then providing an evidence to support the claim (say, a 2006 study shows that PEDs have psychiatric side effects). In this work, we propose the task of automatically detecting such evidences from unstructured text that support a given claim. This task has many practical applications in decision support and persuasion enhancement in a wide range of domains. We first introduce an extensive benchmark data set tailored for this task, which allows training statistical models and assessing their performance. Then, we suggest a system architecture based on supervised learning to address the evidence detection task. Finally, promising experimental results are reported.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years there has been a growing interest in the area of argumentation mining ( <ref type="bibr" target="#b12">Green et al., 2014;</ref><ref type="bibr" target="#b5">Cardie et al., 2015;</ref><ref type="bibr" target="#b33">Wells, 2014)</ref>. Part of this awak- ening is the The Debater TM project 1 whose goal is to develop technologies that will assist humans to de- bate and reason, e.g., by automatically suggesting argu- ments relevant to an examined topic. The minimal def- inition of such an argument <ref type="bibr" target="#b32">(Walton, 2009</ref>) is a set of statements, made up of three parts -a claim (aka con- clusion, proposition), a set of evidence (aka premises), and an inference from the evidence to the claim. Need- less to say, evidence plays a critical role in a persuasive argument.</p><p>In most debate related skills, such as natural lan- guage understanding and generation, humans currently have an inherent advantage over a machine. However, in the ability to provide high quality and diverse evi- dence, machines have a very promising potential, being able to swiftly process large quantities of information. Nonetheless, since most of the relevant information is represented by unstructured text, successfully exploit- ing these resources requires the ability to identify evi- dence in free text. This is exactly the focus of our work. Specifically, we formally define the task of evidence detection, introduce an architecture for attacking this problem, and demonstrate its performance over dedi- cated manually labeled data.</p><p>Before defining the task formally, we introduce three concepts which will be used throughout this paper. These concepts were earlier defined in ( ) and we use the same definitions here. Topic: a short phrase that frames the discussion. Claim: a gen- eral, concise statement that directly supports or con- tests the topic. Context Dependent Evidence (CDE): a text segment that directly supports a claim in the con- text of the topic. The first three rows of <ref type="table">Table 1</ref> show examples of a topic, a claim and CDE.</p><p>For the purpose of this work, we assume that we are given a concrete topic, a relevant claim, and po- tentially relevant documents, provided either manually or by automatic methods <ref type="bibr" target="#b6">(Cartright et al., 2011;</ref>. Our task, which we term Context Depen- dent Evidence Detection (CDED), is to automatically pinpoint CDE within these documents. We further re- quire that a detected CDE is reasonably well phrased, and easily understandable in the given context, so that it can be instantly and naturally used to support the claim in a discussion. <ref type="table">Table 1</ref> gives examples of valid CDE (V) and non-valid CDE (X) according to the definition mentioned above.</p><p>It is well recognized that one can support a claim us- ing different types of evidence ( <ref type="bibr" target="#b26">Rieke and Sillars, 2001;</ref><ref type="bibr" target="#b29">Seech, 2008)</ref>. Furthermore, for different use cases, dif- ferent evidence types could be more suitable. Corre- spondingly, we develop a classification approach that is able to identify and distinguish between three com- mon evidence types ( <ref type="bibr" target="#b25">Rieke and Sillars, 1984;</ref><ref type="bibr" target="#b29">Seech, 2008</ref>):</p><p>• Study Results of a quantitative analysis of data, given as numbers, or as conclusions. <ref type="table">(Table 1 S1</ref>);</p><p>Topic: Use of performance enhancing drugs (PEDs) in professional sports Claim A: PEDs can be harmful to athletes health S1: A 2006 study examined 320 athletes for psychiatric side effects induced by anabolic steroid use. The study found a higher incidence of mood disorders in these athletes compared to a control group.  <ref type="table">Table 1</ref>: Examples for defined concepts. The V/X in- dicates if the candidate is a CDE to the claim above it, according to our definition.</p><p>• Expert Testimony by a person / group / commit- tee / organization with some known expertise / au- thority on the topic. <ref type="table">(Table 1 S2</ref>, S7);</p><p>• Anecdotal A description of an episode(s), cen- tered on individual(s) or clearly located in place and/or in time. <ref type="table">(Table 1 S3</ref>);</p><p>Examining the valid and non-valid CDEs in <ref type="table">Table  1</ref> it should be clear that the distinction between them is often quite subtle. For example, it is possible that a piece of text has the characteristics of a certain evi- dence type, but does not support the claim (see S4 in <ref type="table">Table 1</ref>). It is also possible that a piece of text supports the claim, but is irrelevant in the context of the topic (see S5 in <ref type="table">Table 1</ref>). It could also be the case that a piece of text entails the claim, but adds no new information to support it (see S6 in <ref type="table">Table 1)</ref>.</p><p>We present here a pipeline architecture, relying on supervised learning, to handle the different aspects of CDED which shows promising results over a variety of topics. We demonstrate that the proposed solution and features can generalize well, namely that models learned over different topics can perform reasonably well on an entirely new topic. On average, for a signif- icant fraction of claims the proposed system succeeds to propose relevant CDE amongst its top 4 predictions, and properly determines the evidence type. Further- more we show that we are able to automatically pin- point claims for which the performance of the system are of even greater quality, enabling the user to obtain higher precision for these claims.</p><p>We believe that the ability to automatically provide evidence for given claims will have many practical uses, helping layman and professionals in different do- mains, to reach decisions and prepare for discussions, from a lawyer presenting a case in court, to a politician considering a new policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>CDED is related to several other information retrieval and NLP tasks. Probably the closest of which is the relatively unexplored task of Evidence Retrieval (ER) <ref type="bibr" target="#b6">(Cartright et al., 2011;</ref><ref type="bibr" target="#b2">Bellot et al., 2013)</ref>. However, while ER focus is on identifying whole documents, in CDED the goal is to pinpoint a typically much shorter text segment which can be used directly to support a claim. Furthermore, ER is typically performed for fac- tual assertions, while in CDED one may want to con- sider a wider range of claim types ( <ref type="bibr" target="#b26">Rieke and Sillars, 2001</ref>), cf. claim B in <ref type="table">Table 1</ref>.</p><p>Another important line of related work is the Textual Entailment (TE) framework <ref type="bibr" target="#b7">(Dagan et al., 2009;</ref><ref type="bibr" target="#b11">Glickman et al., 2005)</ref>. A text fragment, T, is said to entail a textual hypothesis H if the truth of H can be most likely inferred from T. While TE can be an important com- ponent in a CDED approach, and perhaps vice versa, the tasks are quite different. Namely, the goal of TE is detecting semantic inference while the goal of CDED is to provide evidence which can enhance the persua- sion of a claim. For example, common instances of TE are rephrases or summarizations of a sentence, how- ever they cannot serve to support a claim within a dis- cussion, as they merely repeat it (Table 1, S6). On the other hand, an anecdotal story may have strong emo- tional impact that will effectively support a claim dur- ing a discussion, although the truth of the claim cannot be inferred from such evidence. Furthermore, similar to ER, TE focuses only on factual assertions, while we focus on a wider range of claims ( <ref type="bibr" target="#b26">Rieke and Sillars, 2001</ref>), cf. claim B in <ref type="table">Table 1</ref>.</p><p>Question answering (QA) ( <ref type="bibr" target="#b8">Dang et al., 2007</ref>) also has some similar aspects to the proposed task, although aiming at a very different goal, which is to provide an explicit -typically unique and concise -answer, to a question.</p><p>The proposed CDED task should be seen as an- other contribution in the emerging field of argumen- tation mining, with several important distinct charac- teristics. Previous works suggested extracting full ar-  <ref type="table">Table 2</ref>: 'Topics' indicate the number of topics included for each CDE type. This determines the number of claims considered for each type. The next columns indicate the number of articles in which at least one CDE was found; the total number of CDE detected for each type; the average percent of claims for which at least one CDE was found; and for these claims, the average number of CDE found. Note that the total number of CDE is not a simple sum of the CDE per type, as CDE can be assigned with more than one type. Standard deviations of distribution across topics are given in parenthesis where relevant.</p><p>guments <ref type="bibr" target="#b20">(Mochales Palau and Moens, 2009)</ref>, analyz- ing argument structure <ref type="bibr" target="#b23">(Peldszus, 2014)</ref>, and identi- fying relations between arguments (Cabrio and Vil- lata, 2012; <ref type="bibr" target="#b10">Ghosh et al., 2014</ref>). Other works focused on specific domains such as evidence-based legal doc- uments <ref type="bibr" target="#b21">(Mochales Palau and Moens, 2011;</ref><ref type="bibr" target="#b1">Ashley and Walker, 2013)</ref>, online debates ( <ref type="bibr" target="#b4">Cabrio and Villata, 2012;</ref><ref type="bibr">Boltuži´Boltuži´c andŠnajderandˇandŠnajder, 2014)</ref>, and product re- views ( <ref type="bibr" target="#b31">Villalba and Saint-Dizier, 2012;</ref><ref type="bibr" target="#b34">Yessenalina et al., 2010</ref>). In addition, some works based on machine- learning techniques, used the same topic in training and testing <ref type="bibr" target="#b28">(Rosenfeld and Kraus, 2015;</ref><ref type="bibr">Boltuži´Boltuži´c andŠnajder andˇandŠnajder, 2014</ref>), relying on features from the topic itself in identifying arguments. In contrast, here, we focus on detecting an essential constituent of an argument - the evidence -rather then detecting whole arguments, or detecting other argument parts like claims ( <ref type="bibr" target="#b15">Lippi and Torroni, 2015</ref>). In addition, we do not limit ourselves to a particular domain, nor assume that the topic of the discussion is known in advance. Fi- nally, we aim to pinpoint evidence in a clearly defined context, given by the pre-specified claim. Thus, the de- veloped system should not only find pieces of text that have general evidence characteristics but further iden- tify which of these candidates can be used to support a specific claim. Hence, as we demonstrate in our re- sults, an essential part of a CDED system should be dedicated to model and assess the semantic relation of a candidate evidence to the given claim and topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>Since CDED is a new and rather complicated task, it is beneficial to examine and understand the nature of the data before moving on to developing a working solu- tion. We therefore start by explaining the manual data annotation process, and several important observations over the resulting data.</p><p>To train and assess the classifiers in our system we rely on data collected by the procedure described in ( ). Briefly, given a topic and a cor- responding relevant claim, extracted from a Wikipedia article by human annotators, the annotators were asked to mark corresponding evidence -text segments sup- porting the claim. To limit the amount of time anno- tators spend on these tasks, labeling was restricted to the article in which the claim was found. The task was split into two stages. First, in the detection stage, five annotators read the article, and mark all CDE candi- dates they locate. Next, in the confirmation stage all the candidates suggested by the annotators are presented to another set of five annotators, which confirm or reject each candidate, and determine the type(s) of accepted candidates. Candidates which were confirmed by the majority of the annotators are considered CDE, and are assigned the type(s) suggested by at least three annota- tors.</p><p>A total of 547 Wikipedia articles associated with 58 different topics were annotated through this procedure. The topics were selected at random from Debatabase 3 covering a wide variety of domains, from atheism to the role of wind power in future energy supply. Out of these topics, 39 were selected at random for train- ing and testing the classifiers included in the system. We refer to these data as the train and test data. The remaining 19 topics were used for tuning various fea- ture parameters, and developing auxiliary classifiers, as described in Section 5. We refer to these data as the held-out data.</p><p>In the 39 topics comprising the train and test data, a total of 3, 057 distinct CDE were found in 274 articles (See <ref type="table">Table 2</ref>). The data is highly unbalanced towards non CDE sentences. For example, for type Study, only 31% of the claims had at least one CDE. Of these 31% claims, on average, a claim was associated with 2.17 CDEs. Further, on average these 2.17 CDEs together span 1.5 sentences, whereas an average article in our data consists of 150 sentences. In other words, even for claims with at least one CDE of type Study, on average only 2% of the sentences in the claim's article are part of such Study CDE.</p><p>In general, CDE in the examined data varied in length from less than a sentence to more than a para- graph. However, 90% of these CDE were composed of segments of up to three sentences within the same para- graph. Furthermore, in 95% of the cases, CDEs were comprised of full sentences. Examining CDEs that start or end mid-sentence, reveals that in most cases the CDE is more concise in these boundaries, but is still a valid CDE when extending the boundaries to include the full sentence. We therefore decided not to address this issue here, and we extend all CDE boundaries to full sentences.</p><p>Apparently CDE of type Study and type Expert are far more common in Wikipedia compared to Anecdotal CDE. We expect this distribution to change in other less scientifically inclined corpora. Finally, the variance between different topics was substantial, as depicted in <ref type="table">Table 2</ref> (refer to the stan- dard deviations mentioned in parenthesis). For exam- ple, the percentage of claims with Expert CDE varies from 10% in the topic banning gambling to 95% in the topic US responsibility for the Mexican drug wars. This observed variability obviously adds to the diffi- culty and complexity of the task.</p><p>In the experiments reported in this paper, out of the 39 topics in the train and test data, we exclude from the evaluation of each type, topics that had less than three CDE of that type. This leaves a total of 30, 37, and 22 topics for types Expert, Study, and Anecdotal, respectively.</p><p>The current work is the first to report results over these CDE data, which are more than 4 times larger compared to the data released in ( ). These data are now freely available for research pur- poses 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System Architecture</head><p>The input to our system is a topic, a set of related arti- cles and a set of relevant claims detected within these articles. Given this input, our system provides the user with a ranked list of candidate CDEs, originating from the text in the claim's article, for an automatically se- lected subset of the input claims.</p><p>In general, we observe that a text segment should satisfy three criteria to be considered CDE of a specific type. It must be coherent; it must have characteristics of the relevant Evidence type; and finally, of course, it should support the claim.</p><p>In addition to these observations, we note that a pri- ori, we do not expect all claims to be supported by all CDE types <ref type="bibr" target="#b22">(Park and Cardie, 2014</ref>). For example, opinion claims like claim B in <ref type="table">Table 1</ref> are expected to be less supported by Study evidence compared to fac- tual claims, like claim A in <ref type="table">Table 1</ref>. Moreover, as ev- ident from Table 2, many claims do not have any as- sociated CDE in the same article. Thus, the system performance may naturally improve if it will propose candidate CDE of a particular type, only to an auto- matically identified subset of the input claims.</p><p>Based on these observations, we are led to suggest an architecture which approaches CDED via a pipeline of modular components. Each of these components relies upon the results of its precedents, and is specifically designed to address a single aspect of those mentioned above. The resulting architecture is depicted in <ref type="figure" target="#fig_0">Figure  1</ref>. Briefly, in the proposed architecture, the first two components are context-free, i.e., focused on the gen- eral characteristics of a candidate, still not taking into account the context of the claim, nor the topic. The third component is context-dependent, considering the relation of the candidate to the claim and topic. Finally, the fourth component aims to identify a subset of the claims for which CDE will be proposed.</p><p>We consider all text segments composed of one, two or three consecutive sentences, included within the same paragraph as candidates (see Section 5 for more details). Given a set of such candidate CDEs -or sim- ply, candidates -the first component, termed the co- herence component, estimates the coherence of each candidate. For example, consider CDE S1 in <ref type="table">Table  1</ref>. A candidate which includes only the second sen- tence is incoherent, as it includes critical unresolved anaphora, that cannot be understood without the pre- vious sentence. In parallel, the second component, termed the evidence characteristics component, esti- mates the extent to which the candidate's statistical sig- nature matches that of the examined evidence type. For example, if no quantitative analysis of data is reported, the candidate typically cannot be considered Study evi- dence, regardless of the claim and topic. Next, we only retain candidates for which the average score of the first two components was relatively high, aiming to further focus our attention on the most promising candidates.</p><p>The retained candidates are then considered by the context-dependent component which aims to determine if the examined candidate indeed supports the provided claim in the context of the topic. Thus, this component ranks all retained candidates with respect to each claim. Finally, the claim selection component aims to rank all input claims, according to the probability that CDEs are indeed found amongst top-ranking candidate for the claim.</p><p>Dividing the overall task into sub-tasks has several benefits. First, it allows training each component over its most suitable data, in which the signal of the relevant features is easier to capture. For example, many of the features for the context-dependent component aim to determine the semantic relatedness between the claim and a candidate. If one would have tried to tackle the entire CDED task simultaneously, the training data for this component would have been masked by many can- didates that are highly related to the claim, although are not CDE -e.g., definitions of some aspects of the claim. These candidates would have blurred the sig- nal that should be captured by the semantic relatedness features, as they represent candidates with negative la- bels that are nonetheless semantically related to the claim. By separating the tasks, we allow the context- dependent component to avoid this inherent difficulty, and train over much cleaner data.</p><p>Second, our pipeline allows efficient handling of the CDED task in terms of run time. Semantic relatedness features are often relatively complex and demanding in terms of run time. The significant filtering done af- ter the context-free stage, reduces the number of candi- dates for which we have to calculate these features.</p><p>Finally, we note that some of the modular compo- nents we develop as part of the pipeline might be of interest by themselves. For example, context-free evi- dence detection might be useful in cases in which the claim and topic are not defined ( <ref type="bibr" target="#b15">Lippi and Torroni, 2015)</ref>. Naturally, we expect that different evidence types will have different characteristics. For example, num- bers are expected to be more common in CDE of type Study compared to CDE of type Expert. Anecdotal CDE is perhaps expected to be less semantically related to the corresponding claim, as it may have a more asso- ciative relation to the claim, compared to CDE of types Study or type Expert. Correspondingly, all components are developed, trained, and assessed, independently for each CDE type.</p><p>In summary, the full flow of our system upon receiv- ing a new topic with associated articles and claims, is as follows:</p><p>1. All articles are split into sentences, and all con- secutive segments up to three sentences within a paragraph are generated as candidates.</p><p>2. Each candidate is assigned a score by the two components in the context-free stage and their scores are averaged. <ref type="bibr">5</ref> 3. A dynamic programming algorithm selects a com- plete coverage of the article by non-overlapping candidates with the maximal average context-free score. The rest of the candidates are discarded.</p><p>4. The remaining candidates across all articles are sorted and only the top 15% of these candidates are retained. <ref type="bibr">6</ref> 5. For each claim, the context-dependent component ranks all retained candidates within the claim's ar- ticle with respect to the claim.</p><p>6. The claim selection component considers all claims and the candidates ranked with respect to each claim and assigns a score per claim. If the claim-score is below a pre-computed threshold, no candidate CDE will be presented for that claim.</p><p>All components are based on a Logistic Regression (LR) classifier, and the class probability is used as the candidate score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Technical approach</head><p>In this section, we provide more technical details for each of the components in our architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Coherence component</head><p>This component aims to score a candidate according to its coherence. For example, a candidate with an unresolved anaphora, or one that breaks a quotation in the middle, is expected to receive a relatively low score. As mentioned, this component considers all text segments composed of 1-3 consecutive sentences in- cluded within the same paragraph. This decision is based on the observation that such segments cover 90% of CDE in the labeled data. Reaching a full cover- age requires examining segments up to 25 sentences, which would vastly increase run time, for a relatively small gain. Thus, for example, for a single paragraph with five sentences, our system will examine a total of 5 + 4 + 3 = 12 candidates. For an article including 30 such paragraphs, a total of 360 candidates will be con- sidered. During training, segments that conform to a labeled CDE were considered positive examples, while segments that overlap a labeled CDE, but either include additional sentence(s), or exclude part of the CDE sen- tences were considered negative examples.</p><p>Dominant features for this classifier included: presence of incomplete quotes; presence of con- trast related conjunctive adverbs -e.g., however, nevertheless; segment length; and presence of un- resolved co-references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evidence characteristics component</head><p>This component aims to estimate to what extent a can- didate represents evidence of a certain type. The train and test data for this component consisted of all text segments composed of 1-3 consecutive sentences, in- cluded within the same paragraph. Positive examples are all labeled CDE of the corresponding evidence type. Negative examples are all candidates that do not over- lap labeled CDE of the relevant type, including CDE of other types.</p><p>The dominant features for the classifier used in this component relied on the following mechanisms:</p><p>• Lexicons -including external lexicons (the Har- vard IV-4 dictionary) and manually and automat- ically compiled in-house lexicons. Specifically, for each evidence type, we manually compiled a lexicon of words characterizing this type by look- ing at examples from the held-out data. This re- sulted with high-precision / low-recall lexicons. For example, for type Expert we used a lexi- con of words describing persons and organizations that may have some relevant expertise, such as: economist, philosopher, court. In addi- tion, we used the held-out data to automatically learn wider lexicons of words that are significantly associated with each type. All the in-house lexi- cons are described in detail in the supplementary material.</p><p>• Named Entity Recognition (NER). We used the Stanford NER ( <ref type="bibr" target="#b9">Finkel et al., 2005</ref>) to extract named entities such as person and organization, and an in-house NER <ref type="bibr" target="#b13">(Lally et al., 2012</ref>) to extract more fine grained categories such as "educational organization" and "leader".</p><p>• Patterns. We used regular expressions to repre- sent features like: does that candidate contain a quote; does it contain a citation; does it contain numeric quantitative results. In addition, we gen- erated complex regular expressions which com- bine the above lexicons with NER results to cap- ture patterns indicative of different types. For ex- ample, the pattern [Person/organization, 0 to 10 wildcard words, an opinion verb -such as believe, conclude, etc.] was highly indicative of Expert ev- idence (cf. <ref type="table">Table 1 S7</ref>).</p><p>• Subjectivity classifier. We manually labeled 1, 750 sentences, selected at random from articles in the held-out data, as either subjective or objec- tive. Next, each sentence was represented by a concatenation of two feature vectors -(i) a bag- of-words representation, limited to a handcrafted subjectivity lexicon containing 100 words; (ii) a bag-of-patterns representation based on patterns observed as frequent in the subjective sentences, detected by a modification of the SPM algorithm <ref type="bibr" target="#b30">(Srikant and Agrawal, 1996</ref>). An LR classifier was then trained over the labeled sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Context-dependent component</head><p>The goal of this component is to estimate whether a candidate can be used to support a claim while dis- cussing the given topic. The training data for this com- ponent are [topic / claim / CDE] triplets. Triplets in which the CDE and claim were linked in the labeled data -namely, the CDE was identified as evidence for the claim -were considered as positive examples. Neg- ative examples were generated by combining claims and CDEs detected in the same topic and article, but that were not linked in our labeled data. The features for the classifier used in this component can be conceptually divided into four types: (i) Seman- tic relatedness between the candidate and the claim (ii) Semantic relatedness between text related to the candi- date and the claim (iii) Relative location of the can- didate with respect to the claim and (iv) sentiment- agreement between the candidate and the claim.</p><p>In general, we rely on two methods to assess the se- mantic relatedness between two texts. The first is based on the cosine similarity between TF-IDF vectors repre- senting each text. Before constructing the TF-IDF vec- tors each text is augmented with acronym expansions, and lexical relations (including antonym, derivationally related and pertainym) from WordNet <ref type="bibr" target="#b19">(Miller, 1995)</ref>. The second, relies on the average cosine similarity be- tween the Word2Vec ( <ref type="bibr" target="#b18">Mikolov et al., 2013</ref>) representa- tion of all pairs of words in the two texts, where in each pair one word is taken from the first text and the other word from the second.</p><p>For each of these two methods, we consider the se- mantic relatedness between the claim and: Specified slots in the candidate as detected by an in-house slot grammar parser <ref type="bibr" target="#b17">(McCord, 1990;</ref>; The entire candidate text; The header/sub-header of the section/subsection containing the candidate; Titles of citations referred to from the candidate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Claim selection component</head><p>The goal of this component is to rank all claims accord- ing to the probability that the claim's article includes CDE of the relevant type, associated with the claim. The training data consisted of all claims, where pos- itive examples included claims for which at least one CDE of the relevant type existed in the labeled data and negative examples included all remaining claims.</p><p>A thresholding mechanism on the component score is used to determine the claims for which candidates will be presented. This threshold was selected by opti- mizing the F1 score over the set of held-out topics.</p><p>The features used by this component exploited three types of information:</p><p>• Claim properties: We used the held-out data to generate two types of lexicons. The first lexicon is generated separately per evidence type. It in- cludes claim words that were found to be signifi- cantly associated with positive examples, namely with claims for which CDE were found. For example, for type Study, this lexicon included words such as lead, result, development and significant. The second lexicon aimed to characterize words that are significantly associ- ated with factual claims vs. non-factual claims, with the expectation that certain evidence types might be more/less common for each of these two claim categories. For this, 550 randomly selected claims were annotated as factual/non- factual. Words identified as characterizing factual claims included increase, important, and relate, while words like natural, freedom, and right were found dominant for non-factual claims.</p><p>• Claim's relevance to topic and article: We ex- pect that when an article's main topic is highly re- lated to the claim, it will more likely include CDE for that claim. Similarly we expect that for claims at the heart of the topic, CDE is more likely to be provided. These properties are assessed by mea- suring the semantic relatedness between (i) the claim and the content of the claim's article and (ii) the claim and topic.</p><p>• Properties of claim's article : Specifically, we mainly consider the scores provided by the context-dependent component to all candidates examined in the claim's article. If the observed scores are relatively high/low, we expect the arti- cle to be more/less likely to include evidence of the considered type. Various statistics of these scores, such as the maximum score and the stan- dard deviation are used as features aiming to cap- ture this intuition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation</head><p>We evaluated our approach using the Leave-One-Out schema: for every topic, we trained the classifiers using the claims and associated CDE in all other topics and then applied the resulting models to the left out topic. In general, we consider a candidate as true-positive if it includes all sentences included in the CDE and no ad- ditional sentences. However, for our analysis it is also interesting to separate between (i) errors in selecting the segment boundaries and (ii) errors of down the line components that are affected by these errors. Thus, we also include the overlap measure where we consider a candidate as true-positive if at least one sentence within it overlaps a sentence in a labeled CDE.</p><p>Our final assessment measure is the mean recipro- cal rank (MRR), that is the inverse of the rank of the first CDE detected for a particular claim, averaged over all claims selected by the claim selection component. This is motivated by the observation that in most prac- tical use cases, it is usually more important to be able to support many claims, than to provide all the CDE avail- able for a single claim. We define the MRR of a claim with no CDE (errors of the claim selection component) to be 0.</p><p>Finally, we report the macro-averaged results over the different topics, that is all topics have the same weight regardless the amount of labeled claims and la- beled CDE detected for them. The rational behind this is that we wish to ensure that our system does rea- sonably well across all topics examined. We note that micro-averaging gave overall similar results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison to Baselines</head><p>To assess the necessity and contribution of the differ- ent components we compare our full pipeline to partial pipelines, where some of the component are disabled or replaced by simple baselines. These baselines are described below.</p><p>First, we consider the No Context-Free Stage (NCFS) baseline which aims to assess the contribution of the context-free stage by skipping this stage, and passing all candidates directly to the context-dependent component.</p><p>Next, we consider the Basic Claim Selection (BCS) baseline which replaces the claim selection component. It ranks claims according to the top score of the candi- date CDE for the claim. A threshold was selected on top of the training data, such that the average percent- age of claims passing the threshold is equal to the av- erage percentage of claims with CDEs in the labeled data.</p><p>Since, to the best of our knowledge, this is the first work to address CDED, there is no prior-art to com- pare our results to. However, to ensure that this task is indeed empirically different from related tasks, and demands a specialized pipeline to handle, we compare with two baselines that are often used in related tasks.</p><p>The BM25 basline handles CDED as an IR task, where the claim represents the query, and all CDE can- didates represent the documents in a standard IR set- ting. After pre-processing, which includes tokeniza- tion, stop word removal, and stemming (Porter, 1997) we use BM25 ( <ref type="bibr" target="#b27">Robertson et al., 1996</ref>) to rank all rel- evant candidates according to their similarity to the query, namely to the input claim.</p><p>The W2V baseline handles CDED as a purely se- mantic relatedness task using state of the art seman- tic relatedness measure of Word2Vec ( <ref type="bibr" target="#b18">Mikolov et al., 2013</ref>). Thus, we use the average cosine similarity be- tween the Word2Vec representations of all words in a given candidate to all words in the claim, to rank all relevant candidates with respect to each claim.  <ref type="table">Table 3</ref>: Macro-averaged MRR for each CDE type. Only claims with CDE in the labeled data were considered in these results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>We start by assessing the proposed pipeline prior to the claim selection component. <ref type="table">Table 3</ref> reports the MRR following the context-dependent component when fil- tering out claims for which no CDE were found in the labeled data. Impact of context free stage: Comparing the pipeline performance to the baseline using only the context de- pendent component (NCFS baseline), the results in- dicate the necessity of the context-free stage in our pipeline. That is, assessing the coherence of candi- dates, as well as their evidence characteristics, seems to be essential to properly address CDED. In particu- lar, the fact that the gain is observed both in the MRR measure and in the MRR-overlap measure suggests that both the context-free components are valuable. Impact of context dependent stage: Comparing the NCFS basline to W2V and BM25 baselines shows that for type Study, the context-dependent component alone still has an advantage over a single semantic related- ness feature. Observing feature weights learned by the LR classifier, we estimate that much of this advantage is due to also taking into consideration semantic relat- edness of the claim to texts related to the candidate, namely the header of the section containing the candi- date and titles of citations referred to from the candi- date. For types Expert and Anecdotal the performance of the context-dependent component are similar to those of the W2V baseline. For type Expert, this suggests that most of the signal in the context-dependent com- ponent comes from semantic relatedness between the claim and candidate CDE. Results for type Anecdotal are significantly lower. This was somewhat expected, given the smaller size of Anecdotal data available to train our classifiers ( <ref type="table">Table 2</ref>). The declined perfor- mance of the W2V and BM25 baselines for this type, further suggests that the semantic relatedness of CDE and claims for this type are less direct. Impact of detecting segment boundaries: Compar- ing the overlap MRR measure to the exact MRR high- lights that identifying the correct segment boundaries is still a challenge, and once we improve this aspect, we can expect a significant improvement in the results. Impact of claim selection component: We next turn to assess the contribution of the claim selection compo- nent.   <ref type="figure" target="#fig_1">Figure 2</ref>). Admittedly, for Anecdo- tal CDE the performance of claim selection are poor. For this component the small sample size for Anecdo- tal CDE was even more acute -there were only 151 claims with CDE of type Anecdotal -thus few positive examples to train this component.</p><p>Recall that the claim selection component's thresh- old was tuned over the held-out data to optimize the F1 measure with respect to claims with/without CDE. However, for some applications one may favor higher precision at the expense of providing candidate CDEs for less claims. <ref type="figure" target="#fig_1">Figure 2</ref> shows that indeed, for type Study, considering more strict thresholds of the claim selection component monotonically improves the sys- tem's overall precision, as reflected by the improved MRR. Similar results were obtained for type Expert.  <ref type="table" target="#tab_3">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Examples of System Performance</head><p>To provide some intuition for the results of our sys- tem, <ref type="table">Table 5</ref> shows the 4 top ranking candidate CDE According to econometric studies, negative side ef- fects of aid can include an unbalanced appreciation of the recipient's currency, increasing corruption, and adverse political effects such as postponements of necessary economic and democratic reforms. X Many econometric studies in recent years have sup- ported the view that development aid has no effect on the speed with which countries develop. V An inquiry into aid effectiveness by the UK All Party Parliamentary Group (APPG) for Debt, Aid and Trade featured evidence from Rosalind Eyben, a Fellow at the Institute of Development Studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X</head><p>A very large part of the spend money on develop- ment aid is simply wasted uselessly. According to Gerbert van der Aa, for the Netherlands, only 33% of the development aid is successful, another 33% fails and of the remaining 33% the effect is unclear. This means that for example for the Netherlands, 1.33 to 2.66 billion is lost as it spends 4 billion in total of development aid. V <ref type="table">Table 5</ref>: Top ranking candidates for the claim aid is ineffective in the context of the topic trade vs. aid of type Study for the claim aid is ineffective in the con- text of the topic trade vs. aid. Among these, 2 were indeed labeled as CDE. The other two exemplify com- mon errors of our system. Candidate 1 can be used to support a highly related claim such as aid has nega- tive side effects, but does not directly support the claim under consideration. Candidate 3 mentions a relevant study, but does not present its results, hence cannot be used to support the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We have provided the definitions for the CDED task, and described a system architecture that addresses the issues at the heart of the task. We assessed the perfor- mance of the proposed approach over a novel bench- mark dataset, demonstrating the validity of our archi- tecture, and the necessity of all its components. There are still many open issues to address and di- rections in which to expand the task and labeled data which we hope to address in future work.</p><p>In this paper we define CDE only in the context of supporting a claim. However, in many scenarios pro- viding counter evidence can also be very useful. As evidence supporting and contesting a claim share many semantic and syntactic features, we believe that detect- ing both cases simultaneously might be easier to ac- complish, although to enhance the practical use of such a solution, one may need to develop an additional com- ponent, determining the polarity of the detected CDE.</p><p>Another natural direction to pursue is expanding the documents which are considered for CDED beyond the article containing the claim. These can include ad- ditional Wikipedia articles and other resources such as newspaper archives, scientific literature, blogs, etc. This poses additional challenges in gathering labeled data, as it will require a mechanism to decide which documents to label per claim and will probably increase the number of documents to be labeled. Expanding to additional corpora will probably require development of additional features, to capture signals unique to each corpus. For example, in newspaper archives, the iden- tity of the author might prove an important feature.</p><p>Finally, in this work we used manually identified claims and articles. Combining a CDED solution with recent works in the field of argumentation mining <ref type="bibr" target="#b6">(Cartright et al., 2011;</ref><ref type="bibr" target="#b15">Lippi and Torroni, 2015)</ref>, may give rise to a new generation of methods, that will be able to automatically construct relevant ar- guments on demand, for a variety of topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic description of the CDED system proposed in this work.</figDesc><graphic url="image-1.png" coords="4,82.77,62.81,432.02,118.23" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: MRR and average fraction of passed claims as function of the claim selection threshold for type Study. Arrow indicates threshold used to obtain the results in Table 4.</figDesc><graphic url="image-2.png" coords="8,307.28,564.71,216.00,83.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>441</head><label>441</label><figDesc></figDesc><table>Topics Claims 

Articles with 
CDE 
CDE 
avg. % of 
claims with 
CDE 

avg. # CDE per 
claim 

Study 
30 
1587 
136 
1018 
31 (22) 
2.2 (0.9) 
Expert 
37 
1702 
214 
1896 
46 (22) 
1.9 (0.8) 
Anecdotal 22 
1137 
70 
382 
17 (11) 
2.0 (1.6) 
Total 
39 
1734 
274 
3057 
60 (17) 
2.9 (3.7) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 compares</head><label>4</label><figDesc>the final MRR results -at the end of the pipeline -for claims selected by the claim selection component, vs. claims selected by the BCS</figDesc><table>Type 
Pipeline BCS All claims 
Study 
0.25 
0.16 
0.12 
Expert 
0.34 
0.23 
0.20 
Anecdotal 0.04 
0.05 
0.03 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Macro-averaged MRR over: 1) claims se-
lected by the claim selection component, 2) claims se-
lected by basic claim selection, and 3) all claims. 

baseline. Additionally, to demonstrate the value of 
claim selection in general, we add results when consid-
ering all claims. For types Expert and Study the claim 
selection component shows a clear advantage over the 
baselines. Furthermore, the improved performance is 
achieved when passing a higher percentage of claims 
than the BCS baseline (34% vs 31% for Study and 52% 
vs 46% for Expert, </table></figure>

			<note place="foot" n="1"> http://researcher.ibm.com/researcher/ view_group.php?id=5443</note>

			<note place="foot" n="2"> Note ibuprofen is considered a PED</note>

			<note place="foot" n="3"> http://idebate.org/debatabase</note>

			<note place="foot" n="4"> https://www.research.ibm.com/haifa/ dept/vst/mlta_data.shtml</note>

			<note place="foot" n="5"> With additional training data, we might be able to learn a more sophisticated function to combine both scores. 6 This percentage was determined according to performance on the held-out data set. We have also experimented with methods where the threshold is score-based rather than percentage-based, which gave similar results.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Oren Tsur, Vikas C. Raykar, Matan Orbach and Ido Dagan for many helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A benchmark dataset for automatic detection of claims and evidence in the context of controversial topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoly</forename><surname>Polnarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Lavee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="64" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Toward constructing evidence-based legal arguments using legal decision documents and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vern</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Law, ICAIL &apos;13</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Law, ICAIL &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="176" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overview of inex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sairam</forename><surname>Gurajada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marijn</forename><surname>Koolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arunav</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronique</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Preminger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schenkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Trappett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuyue</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF Lab Reports</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Back up your stance: Recognizing arguments in online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Boltuži´boltuži´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaň</forename><surname>Snajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Combining textual entailment and argumentation theory for supporting online debates interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Villata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="208" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Georgios Petasis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Argumentation Mining</title>
		<editor>Manfred Stede, Marilyn Walker, and Janyce Wiebe</editor>
		<meeting>the Second Workshop on Argumentation Mining<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evidence finding using a collection of books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc-Allen</forename><surname>Cartright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><forename type="middle">A</forename><surname>Feild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th ACM Workshop on Online Books, Complementary Social Media and Crowdsourcing, BooksOnline &apos;11</title>
		<meeting>the 4th ACM Workshop on Online Books, Complementary Social Media and Crowdsourcing, BooksOnline &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recognizing textual entailment: Rational, evaluation and approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">04</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Overview of the trec 2007 question answering track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Analyzing argumentative discourse units in online interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debanjan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Wacholder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Aakhus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mitsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A probabilistic classification approach for lexical textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Koppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<editor>Manuela M. Veloso and Subbarao Kambhampati</editor>
		<imprint>
			<publisher>AAAI Press / The MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1050" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Litman</surname></persName>
		</author>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<editor>Chris Reed, and Vern Walker</editor>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Question analysis: How watson reads a clue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><surname>Boguraev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Patwardhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Fodor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Context dependent claim detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
			<biblScope unit="page" from="1489" to="1500" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Contextindependent claim detection for argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Torroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty Fourth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty Fourth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep parsing in watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><forename type="middle">K</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Dev</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="278" />
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Slot grammar: A system for simpler construction of practical natural language grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural Language and Logic: Proc. of the International Scientific Symposium</title>
		<editor>R. Studer</editor>
		<meeting><address><addrLine>Hamburg, FRG; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="118" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COMMUNICATIONS OF THE ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Argumentation mining: the detection, classification and structure of arguments in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Conference on Artificial Intelligence and Law</title>
		<meeting>the Twelfth International Conference on Artificial Intelligence and Law</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="98" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Argumentation mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><forename type="middle">Mochales</forename><surname>Palau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Law</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Identifying appropriate support for propositions in online user comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards segment-based recognition of argumentation structure in short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Peldszus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="88" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Readings in information retrieval. chapter An Algorithm for Suffix Stripping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<biblScope unit="page" from="313" to="316" />
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Argumentation and the decision making process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><forename type="middle">O</forename><surname>Rieke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sillars</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Harper Collins</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Argumentation and Critical Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><forename type="middle">O</forename><surname>Rieke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sillars</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Longman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Okapi at trec-3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Gatford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="109" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Providing arguments in discussions based on the prediction of human argumentative behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarit</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)</title>
		<meeting>the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Writing Philosophy Papers. Cengage Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Seech</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Mining sequential patterns: Generalizations and performance improvements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishnan</forename><surname>Srikant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Extending Database Technology: Advances in Database Technology, EDBT &apos;96</title>
		<meeting>the 5th International Conference on Extending Database Technology: Advances in Database Technology, EDBT &apos;96<address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Some facets of argument mining for opinion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Paz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garcia</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Saint-Dizier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Models of Argument-Proceedings of COMMA 2012</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09-10" />
			<biblScope unit="page" from="23" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Argumentation theory: A very short introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Walton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Argumentation in Artificial Intelligence</title>
		<editor>Guillermo Simari and Iyad Rahwan</editor>
		<meeting><address><addrLine>US</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Argument mining: Was ist das?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Workshop on Computational Models of Natural Argument, CMNA14</title>
		<meeting>the 14th International Workshop on Computational Models of Natural Argument, CMNA14</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatically generating annotator rationales to improve sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ainur</forename><surname>Yessenalina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers, ACLShort &apos;10</title>
		<meeting>the ACL 2010 Conference Short Papers, ACLShort &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="336" to="341" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
