<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial Training for Multi-task and Multi-lingual Joint Modeling of Utterance Intent Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Masumura</surname></persName>
							<email>ryou.masumura.ba@hco.ntt.co.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
								<address>
									<addrLine>1-1, Yokosuka-shi</addrLine>
									<postCode>239-0847</postCode>
									<settlement>Hikarinooka, Kanagawa</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Shinohara</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
								<address>
									<addrLine>1-1, Yokosuka-shi</addrLine>
									<postCode>239-0847</postCode>
									<settlement>Hikarinooka, Kanagawa</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
								<address>
									<addrLine>1-1, Yokosuka-shi</addrLine>
									<postCode>239-0847</postCode>
									<settlement>Hikarinooka, Kanagawa</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Aono</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">NTT Media Intelligence Laboratories</orgName>
								<orgName type="institution" key="instit2">NTT Corporation</orgName>
								<address>
									<addrLine>1-1, Yokosuka-shi</addrLine>
									<postCode>239-0847</postCode>
									<settlement>Hikarinooka, Kanagawa</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adversarial Training for Multi-task and Multi-lingual Joint Modeling of Utterance Intent Classification</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="633" to="639"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>633</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper proposes an adversarial training method for the multi-task and multilingual joint modeling needed for utterance intent classification. In joint modeling, common knowledge can be efficiently utilized among multiple tasks or multiple languages. This is achieved by introducing both language-specific networks shared among different tasks and task-specific networks shared among different languages. However, the shared networks are often specialized in majority tasks or languages, so performance degradation must be expected for some minor data sets. In order to improve the invariance of shared networks, the proposed method introduces both language-specific task adversarial networks and task-specific language adversarial networks; both are leveraged for purging the task or language dependencies of the shared networks. The effectiveness of the adver-sarial training proposal is demonstrated using Japanese and English data sets for three different utterance intent classification tasks.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In natural language processing fields, full neural network based methods are suitable for joint mod- eling as they can simultaneously utilize multiple task data sets or multiple language data sets to improve the performance achieved for individual tasks or languages <ref type="bibr" target="#b2">(Collobert and Weston, 2008)</ref>. It is known that joint modeling can address the data scarcity problem.</p><p>Key natural language processing technologies for spoken dialogue systems include utterance in- tent classification, which is needed to detect in- tent labels such as dialogue act ( <ref type="bibr" target="#b20">Stolcke et al., 2000;</ref><ref type="bibr" target="#b8">Khanpour et al., 2016)</ref>, domain ( <ref type="bibr" target="#b22">Xu and Sarikaya, 2014)</ref>, and question type ( <ref type="bibr" target="#b21">Wu et al., 2005</ref>) from input utterances <ref type="bibr">Stolcke, 2015a,b, 2016)</ref>. One problem is that the train- ing data are often limited or unbalanced among different tasks or different languages. Therefore, our motivation is to leverage both multi-task joint modeling and multi-lingual joint modeling to en- hance utterance intent classification.</p><p>The multi-task and multi-lingual joint modeling can be composed by introducing both task-specific networks, which are shared among different lan- guages, and language-specific networks, which are shared among different tasks ( <ref type="bibr" target="#b14">Masumura et al., 2018;</ref><ref type="bibr" target="#b9">Lin et al., 2018</ref>). Although joint model- ing is mainly intended to improve classification performance in resource-poor tasks or languages, its classification performance is degraded in some minor data sets. This is because the language- specific networks often depend on majority tasks, while the task-specific networks often depend on majority languages. What are needed are task- specific networks that are invariant to languages, and language-specific networks that are invariant to tasks.</p><p>In order to explicitly improve the invariance of language and task-specific networks, this paper in- troduces adversarial training ( <ref type="bibr" target="#b6">Goodfellow et al., 2014</ref>). Our idea is to train language-specific net- works so as to be insensitive to the target task, while training task-specific networks to be in- sensitive to language. To this end, we intro- duce multiple domain adversarial networks ( <ref type="bibr">Ganin et al., 2016</ref>), language-specific task adversarial networks, and task-specific language adversarial networks, into a state-of-the-art fully neural net- work based joint modeling; we adopt the bidi- rectional long short-term memory recurrent neural networks (BLSTM-RNNs) with attention mecha- nism ( <ref type="bibr" target="#b28">Zhou et al., 2016)</ref>. To the best of our knowledge, this paper is the first study to employ adversarial training for multi-input and multi-output joint modeling.</p><p>Experiments on Japanese and English data sets demonstrate the effectiveness of the adversarial training proposal. To support spoken dialogue sys- tems, three different utterance intent classification tasks are examined: dialogue act, topic type, and question type classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Joint Modeling: In natural language processing research, joint modeling is usually split into multi- task joint modeling and multi-lingual joint mod- eling. Multi-task joint modeling has been shown to effectively improve individual tasks <ref type="bibr" target="#b2">(Collobert and Weston, 2008;</ref><ref type="bibr">Liu et al., 2016a,b;</ref><ref type="bibr" target="#b27">Zhang and Weng, 2016;</ref><ref type="bibr" target="#b13">Liu et al., 2016c</ref>). In addition, multi-lingual joint modeling is achieved by learn- ing common semantic representations among dif- ferent languages ( <ref type="bibr" target="#b7">Guo et al., 2016;</ref><ref type="bibr" target="#b3">Duong et al., 2016;</ref><ref type="bibr" target="#b26">Zhang et al., , 2017b</ref>). In addition, a few work have examined multi-task and multi- lingual joint modeling ( <ref type="bibr" target="#b14">Masumura et al., 2018;</ref><ref type="bibr" target="#b9">Lin et al., 2018)</ref>. Different from the previous work, our novelty is to introduce adversarial training for multi-task and multi-lingual joint modeling. Adversarial Training: The concept of adversar- ial training was first proposed by <ref type="bibr" target="#b6">Goodfellow et al. (2014)</ref>, and many studies in the machine learning field have focused on adversarial training. Adver- sarial training has been well utilized in text classi- fication ( <ref type="bibr">Ganin et al., 2016;</ref><ref type="bibr" target="#b1">Chen et al., 2016;</ref><ref type="bibr" target="#b12">Liu et al., 2017;</ref><ref type="bibr" target="#b15">Miyato et al., 2017;</ref><ref type="bibr" target="#b0">Chen and Cardie, 2018)</ref>. Most natural language processing papers adopted either the language invariant approach <ref type="bibr" target="#b1">(Chen et al., 2016;</ref><ref type="bibr" target="#b25">Zhang et al., 2017a</ref>) or the task invariant approach ( <ref type="bibr">Ganin et al., 2016;</ref><ref type="bibr" target="#b12">Liu et al., 2017;</ref><ref type="bibr" target="#b0">Chen and Cardie, 2018)</ref>. This paper aims to fully utilize both task adversarial training and language adversarial training. To this end, we si- multaneously introduce language-specific task ad- versarial networks and task-specific language ad- versarial networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>This section details our adversarial training method for multi-task and multi-lingual joint mod- eling of utterance intent classification.</p><p>In the j-th task utterance intent classification for the i-th language input utterance, intent la-</p><formula xml:id="formula_0">bel l (j) ∈ {1, · · · , K (j) } is estimated from in- put utterance W (i) = {w (i) 1 , · · · , w (i)</formula><p>T } where i ∈ {1, · · · , I} and j ∈ {1, · · · , J}. Utter- ance intent classification is followed by estima- tion of the probabilities of each intent label given input utterance, P (l (j) |W (i) , Θ (i,j) ) where Θ (i,j) is the trainable model parameter for the com- bination of the i-th language and the j-th task. In multi-task and multi-lingual joint modeling, {Θ <ref type="bibr">(1,</ref><ref type="bibr">1)</ref> , · · · , Θ (I,J) } are jointly trained from I language and J task data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Main Joint Network</head><p>The proposed method is founded on a fully neu- ral network that employs I language-specific net- works, J task-specific networks, and J classifica- tion networks as well as <ref type="bibr" target="#b14">Masumura et al. (2018)</ref>.</p><p>The language-specific network can be shared between multiple tasks, where words in the in- put utterance are converted into language-specific hidden representations. Each word in the i-th lan- guage input utterance W (i) is first converted into a continuous representation. Next, each word rep- resentation is converted into a hidden representa- tion that uses BLSTM-RNNs to take neighboring word context information into account. The t-th language-specific hidden representation for the i- th language is given by:</p><formula xml:id="formula_1">w (i) t = EMBED(w (i) t ; θ (i) h ),<label>(1)</label></formula><formula xml:id="formula_2">h (i) t = BLSTM({w (i) 1 , · · · , w (i) T }, t; θ (i) h ),<label>(2)</label></formula><p>where EMBED() is a linear transformational func- tion for word embedding, BLSTM() is a function of the BLSTM-RNN layer, and θ</p><formula xml:id="formula_3">(i)</formula><p>h is the trainable parameter for the i-th language-specific network.</p><p>In addition, task-specific networks can be shared between multiple languages, where the language-specific hidden representations are con- verted into task-specific hidden representations. The t-th language-specific hidden representation for the j-th task is given by:</p><formula xml:id="formula_4">u (j) t = BLSTM({h (i) 1 , · · · , h (i) T }, t; θ (j) u ),<label>(3)</label></formula><p>where θ</p><formula xml:id="formula_5">(j)</formula><p>u is the trainable parameter for the j-th task-specific network.</p><p>In classification networks for each task, the task-specific hidden representations are summa- rized as sentence representation s (j) by using a self-attention mechanism that can consider the importance of individual hidden representations ( <ref type="bibr" target="#b28">Zhou et al., 2016;</ref><ref type="bibr" target="#b19">Sawada et al., 2017)</ref>. Next, predicted probabilities of the j-th task intent labels, o (j) ∈ R K (j) , are given by:</p><formula xml:id="formula_6">s (j) = ATTENSUM({h (i) 1 , · · · , h (i) T }; θ (j) o ), (4) o (j) = SOFTMAX(s (j) ; θ (j) o ),<label>(5)</label></formula><p>where ATTENSUM() is a weighted sum function with self-attention, SOFTMAX() is a transforma- tional function with softmax activation, and θ</p><formula xml:id="formula_7">(j) o</formula><p>is the trainable parameter for the j-th classifica- tion network. In the main joint networks of the proposal, Θ (i,j) corresponds to {θ</p><formula xml:id="formula_8">(i) h , θ (j) u ,θ (j) o }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Adversarial Networks</head><p>The proposed method combines a language- specific task adversarial network with a task- specific language adversarial network. The task adversarial network is used for training the language-specific networks to be insensitive to tar- get task labels, and the language adversarial net- work is used for training the task-specific net- works to be insensitive to target language labels. In order to efficiently use stochastic gradient de- scent based training for optimizing the adversarial networks, we use gradient reversal layers, which allow the input vectors during forward propaga- tion, and sign inversion of the gradients during back propagation, to be utilized ( <ref type="bibr">Ganin et al., 2016)</ref>.</p><p>The i-th language-specific task adversarial net- work estimates task labels from the i-th language- specific hidden representations. The predicted probabilities of task labels, x (i) ∈ R J , are given by:</p><formula xml:id="formula_9">˜ h (i) ˜ h (i) = ATTENSUM({ ˜ h (i) 1 , · · · , ˜ h (i) T }; θ (i) x ), (7) x (i) = SOFTMAX( ˜ h (i) , θ (i) x ),<label>(8)</label></formula><p>where GRL() represents the gradient reversal layer, and θ</p><formula xml:id="formula_10">(i)</formula><p>x is the trainable parameter. The j-th task- specific language adversarial network estimates language labels from the j-th task-specific hid- den representations. The predicted probabilities of language labels, y (j) ∈ R I , are given by:</p><formula xml:id="formula_11">˜ u (j) t = GRL(u (j) t ),<label>(9)</label></formula><formula xml:id="formula_12">˜ u (j) = ATTENSUM({ ˜ u (j) 1 , · · · , ˜ u (j) T }; θ (j) y ), (10) y (j) = SOFTMAX( ˜ u (j) , θ (j) y ),<label>(11)</label></formula><p>where θ y is the trainable parameter. The red components are language-specific net- works, the orange components are task-specific networks, and the purple components are classi- fication networks. In addition, green components are language-specific task adversarial networks, and blue components are task-specific language adversarial networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>Our adversarial training proposal jointly optimizes all parameters in both the main joint networks and the adversarial networks by using all training data sets {D <ref type="bibr">(1,</ref><ref type="bibr">1)</ref> , · · · , D (I,J) } where D (i,j) represents the sets of the input utterances and the reference. The cross-entropy loss functions of each network are defined as:</p><formula xml:id="formula_13">L o = − I i=1 J j=1 |D (i,j) | n=1 K (j) k=1ô k=1ˆk=1ô (j) n,k log o (j) n,k , (12) L x = − I i=1 J j=1 |D (i,j) | n=1 J j =1ˆx =1ˆ =1ˆx (i) n,j log x (i)</formula><p>n,j , (13)</p><formula xml:id="formula_14">L y = − I i=1 J j=1 |D (i,j) | n=1 I i =1ˆy =1ˆ =1ˆy (j) n,i log y (j) n,i , (14)</formula><p>where L o , L x , and L y are the cross entropy loss terms for the classification networks, the task ad- versarial networks, and the language adversarial networks. ˆ o</p><formula xml:id="formula_15">(j) n,k , ˆ x (i)</formula><p>n,j , andˆyandˆ andˆy</p><formula xml:id="formula_16">(j)</formula><p>n,i are the reference probabilities, and o n,k , x n,j , and y n,i are the es- timated probabilities of the k-th label in the j-th task classification network, the j -th task in the i- th language-specific task adversarial network, and  the i -th language in the j-th task-specific lan- guage adversarial network for W n , respectively. Due to use of gradient reversal layers, individ- ual parameters are gradually updated as follows:</p><formula xml:id="formula_17">θ (j) o ← θ (j) o − ∂L o ∂θ (j) o ,<label>(15)</label></formula><formula xml:id="formula_18">θ (j) y ← θ (j) y − β ∂L y ∂θ (j) y ,<label>(16)</label></formula><formula xml:id="formula_19">θ (j) u ← θ (j) u − ( ∂L o ∂θ (j) u − β ∂L y ∂θ (j) u ),<label>(17)</label></formula><formula xml:id="formula_20">θ (i) x ← θ (i) x − α ∂L x ∂θ (i) x ,<label>(18)</label></formula><formula xml:id="formula_21">θ (i) h ← θ (i) h − ( ∂L o ∂θ (i) h − α ∂L x ∂θ (i) h − β ∂L y ∂θ (i) h ),<label>(19)</label></formula><p>where α and β are hyper parameters of the param- eter update, and is the learning rate. Note that adversarial training is suppressed by setting α and β to 0.0. In training, we prepared optimizers for individual data sets. The individual learning rates fall when the validation loss of the target classifi- cation network increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Our experiments employed Japanese and English data sets created for three different utterance in- tent classification tasks. The tasks, dialogue act (DA) classification, topic type (TT) classification, and question type (QT) classification, are intended to support spoken dialogue systems. For example, the task of English DA classification is to obtain a DA label from an input utterance. We used natural language texts as the input utterances and individ- ual label sets were unified between Japanese and English. Data sets employed in experiments were corpora that were made for constructing spoken dialogue systems ( <ref type="bibr" target="#b14">Masumura et al., 2018</ref>  validation (Valid), and test (Test) sets. <ref type="table" target="#tab_3">Table 1</ref> shows the number of utterances in individual data sets where #labels represents the number of labels. <ref type="table" target="#tab_1">Table 2</ref> shows English utterances and label exam- ples for individual tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setups</head><p>We examined single-task and mono-lingual mod- eling, multi-task joint modeling, multi-lingual join modeling, and multi-task and multi-lingual joint modeling with or without adversarial training. We unified network configurations as follows. Word representation size was set to 128, BLSTM- RNN unit size was set to 400, and sentence rep- resentation was set to 400. Dropout was used for EMBED() and BLSTM(), and the dropout rate was set to 0.5. Words that appeared only once in the training data sets were treated as unknown words. We used mini-batch stochastic gradient descent, in which initial learning rate was set to 0.1. We opti- mized hyper-parameters of adversarial training (α and β) for the validation sets by varying them from 0.001 to 1.0. Other hyper parameters were also op- timized for the validation sets. <ref type="table" target="#tab_5">Table 3</ref> shows the results in terms of utterance classification accuracy. For each setup, we con- structed five models by varying the initial param- eters and evaluated the average accuracy. Line (1) shows baseline results: single-task and mono- lingual modeling. Lines <ref type="formula" target="#formula_2">(2)</ref> and <ref type="formula" target="#formula_4">(3)</ref> show results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Joint modeling</head><p>Adversarial Training Japanese English Multi-task Multi-lingual <ref type="table" target="#tab_3">Task-invariant Language-invariant  DA  TT  QT  DA  TT  QT  (1).  - - - - 66.6</ref>   with only performing multi-task joint modeling, and lines <ref type="formula">(4)</ref> and <ref type="formula" target="#formula_6">(5)</ref> show results with only per- forming multi-lingual joint modeling. Note that lines <ref type="formula" target="#formula_4">(3)</ref> and <ref type="formula" target="#formula_6">(5)</ref> show the results achieved with ad- versarial training. Line (6) shows multi-task and multi-lingual joint modeling results: adversarial training was suppressed by setting both α and β to 0.0. Lines <ref type="formula">(7)</ref>- <ref type="formula" target="#formula_11">(9)</ref> shows the results achieved with adversarial training. Note that setting with bold values achieved the highest performance in our evaluation.</p><p>First, in lines (2) and (4), the classification per- formance deteriorated in some cases, while per- formance improvements were achieved in other cases. On the other hand, in lines (3) and (5), clas- sification performance in each data sets was im- proved by introducing adversarial training. This indicates that adversarial training was effective in improving the performance of joint modeling.</p><p>Next, line (6) shows that, relative to line 1, multi-task and multi-lingual joint modeling can improve the classification performance for Japanese TT, Japanese QT, and English TT, but classification performance was degraded for En- glish DA and English QT. This indicates that it is difficult to simultaneously improve the clas- sification performance for all data sets because joint modeling often depends on majority tasks or majority languages. In addition, lines <ref type="formula">(7)</ref> and <ref type="bibr">(8)</ref> show the introduction of either task adver- sarial networks or language adversarial networks yielded better performance than line (6) for all data sets. This indicates that adversarial train- ing was effective in improving the performance of multi-task and multi-lingual joint modeling. The best results were achieved by using both language-specific task adversarial networks and task-specific language adversarial networks, line (9). These results confirm that task adversarial networks and language adversarial networks well complement each other. Of particular benefit, the proposed method demonstrated greater classifica- tion performance improvements when the number of training utterances per label was small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have proposed an adversarial training method for the multi-task and multi-lingual joint modeling needed to enhance utterance intent classification. Our adversarial training proposal utilizes both task adversarial networks and language adversarial net- works for improving task-invariance in language- specific networks and language-invariance in task- specific networks. Experiments showed that the adversarial training proposal could well realize the benefits of joint modeling in all data sets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Proposed network structure for two tasks and two languages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Task Utterance Label DA Hello, how are you today? GREETING I am so sorry to hear of your son's accident. SYMPATHY/AGREE Lets go to school an hour early today. PROPOSAL TT What is the highest mountain in the world? MOUNTAIN Who is president of the united states? PERSON What is the name of the most recent Star Wars movie? MOVIE QT Do you like egg salad? TRUE/FALSE How do you correct a hook in a golf swing? EXPLANATION:METHOD Why is blood red? EXPLANATION:CAUSE</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Examples of English data sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Number of utterances in individual data sets.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Experimental results: utterance classification accuracy (%) for individual test sets. 

</table></figure>

			<note place="foot">t = GRL(h (i) t ), (6)</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Multinomial adversarial networks for multi-domain text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05694</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Adversarial deep averaging networks for cross-lingual sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01614</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning crosslingual word embeddings without bilingual corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Duong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1285" to="1295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Information Processing Systems (NIPS)</title>
		<meeting>Advances in Neural Information essing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A representation learning framework for multi-source transfer parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2734" to="2740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dialogue act classification in domain-independent conversations using a deep recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Khanpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishitha</forename><surname>Guntakandla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodney</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Linguistics (COLING)</title>
		<meeting>International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2012" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A multi-lingual multi-task architecture for low-resource sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="799" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep multi-task learning with shared memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>Conference on Empirical Methods in Natural Language essing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="118" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent neural network for text classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2873" to="2879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial multi-task learning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Implicit discourse relation classification via multi-task neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2750" to="2756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-task and multi-lingual joint learning of neural lexical utterance classification based on partially-shared modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Masumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomohiro</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichiro</forename><surname>Higashinaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokazu</forename><surname>Masataki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushi</forename><surname>Aono</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Linguistics</title>
		<meeting>International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3586" to="3596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adversarial training methods for semisupervised text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representation (ICLR)</title>
		<meeting>International Conference on Learning Representation (ICLR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A comparative study of neural network models for lexical intent classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Automatic Speech Recognition and Understanding Workshop (ASRU)</title>
		<meeting>Automatic Speech Recognition and Understanding Workshop (ASRU)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="368" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Recurrent neural network and LSTM models for lexical utterance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</title>
		<meeting>Annual Conference of the International Speech Communication Association (INTERSPEECH)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="135" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparative study of recurrent neural network models for lexical domain classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>International Conference on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="6075" to="6079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parallel hierarchical attention networks with shared memory reader for multi-stream conversational document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naoki</forename><surname>Sawada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Masumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiromitsu</forename><surname>Nishizaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Conference of the International Speech Communication Association (INTERSPEECH)</title>
		<meeting>Annual Conference of the International Speech Communication Association (INTERSPEECH)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3311" to="3315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dialogue act modeling for automatic tagging and recognition of conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Ries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Coccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Martion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><surname>Van Ess-Dykema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Metter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="339" to="373" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Domain-specific FAQ retrieval using independent aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Hsien</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jui-Feng</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Jun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Asian Language Information Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contextual domain classification in spoken language understanding systems using recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<meeting>International Conference on Acoustics, Speech and Signal essing (ICASSP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="136" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inducing bilingual lexica from non-parallel data with earth mover&apos;s distance regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computational Linguistics (COLING)</title>
		<meeting>International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3188" to="3198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adversarial training for unsupervised bilingual lexicon induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1959" to="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bilingual lexicon induction from non-parallel data with minimum supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3379" to="3384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A joint model of intent determination and slot filling for spoken language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2993" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attentionbased bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
