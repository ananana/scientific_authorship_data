<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural versus Phrase-Based Machine Translation Quality: a Case Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><forename type="middle">Bentivogli</forename><surname>Fbk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam The Netherlands Mauro Cettolo FBK</orgName>
								<address>
									<country>Trento Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trento</forename><surname>Italy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam The Netherlands Mauro Cettolo FBK</orgName>
								<address>
									<country>Trento Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam The Netherlands Mauro Cettolo FBK</orgName>
								<address>
									<country>Trento Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><forename type="middle">Federico</forename><surname>Fbk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam The Netherlands Mauro Cettolo FBK</orgName>
								<address>
									<country>Trento Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trento</forename><surname>Italy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam The Netherlands Mauro Cettolo FBK</orgName>
								<address>
									<country>Trento Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural versus Phrase-Based Machine Translation Quality: a Case Study</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="257" to="267"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Within the field of Statistical Machine Translation (SMT), the neural approach (NMT) has recently emerged as the first technology able to challenge the long-standing dominance of phrase-based approaches (PBMT). In particular , at the IWSLT 2015 evaluation campaign, NMT outperformed well established state-of-the-art PBMT systems on English-German, a language pair known to be particularly hard because of morphology and syntactic differences. To understand in what respects NMT provides better translation quality than PBMT, we perform a detailed analysis of neural vs. phrase-based SMT outputs, leveraging high quality post-edits performed by professional translators on the IWSLT data. For the first time, our analysis provides useful insights on what linguistic phenomena are best modeled by neural models-such as the reordering of verbs-while pointing out other aspects that remain to be improved.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The wave of neural models has eventually reached the field of Statistical Machine Translation (SMT). After a period in which Neural MT (NMT) was too computationally costly and resource demanding to compete with state-of-the-art Phrase-Based MT (PBMT) 1 , the situation changed in 2015. For the first time, in the latest edition of IWSLT 2 (Cettolo et al., 2015), the system described in ) overtook a variety of PBMT approaches with a large margin (+5.3 BLEU points) on a diffi- cult language pair like English-German -anticipat- ing what, most likely, will be the new NMT era.</p><p>This impressive improvement follows the dis- tance reduction previously observed in the WMT 2015 shared translation task ( <ref type="bibr" target="#b5">Bojar et al., 2015</ref>). Just few months earlier, the NMT systems de- scribed in <ref type="bibr" target="#b21">(Jean et al., 2015b</ref>) ranked on par with the best phrase-based models on a couple of lan- guage pairs. Such rapid progress stems from the im- provement of the recurrent neural network encoder- decoder model, originally proposed in <ref type="bibr" target="#b35">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b9">Cho et al., 2014b)</ref>, with the use of the at- tention mechanism ( <ref type="bibr" target="#b0">Bahdanau et al., 2015)</ref>. This evolution has several implications. On one side, NMT represents a simplification with respect to pre- vious paradigms. From a management point of view, similar to PBMT, it allows for a more efficient use of human and data resources with respect to rule- based MT. From the architectural point of view, a large recurrent network trained for end-to-end trans- lation is considerably simpler than traditional MT systems that integrate multiple components and pro- cessing steps. On the other side, the NMT pro- cess is less transparent than previous paradigms. In- deed, it represents a further step in the evolution from rule-based approaches that explicitly manipu- late knowledge, to the statistical/data-driven frame- work, still comprehensible in its inner workings, to a sub-symbolic framework in which the translation process is totally opaque to the analysis.</p><p>What do we know about the strengths of NMT and the weaknesses of PBMT? What are the linguis- tic phenomena that deep learning translation models can handle with such greater effectiveness? To an- swer these questions and go beyond poorly informa- tive BLEU scores, we perform the very first compar- ative analysis of the two paradigms in order to shed light on the factors that differentiate them and deter- mine their large quality differences.</p><p>We build on evaluation data available for the IWSLT 2015 MT English-German task, and com- pare the results of the first four top-ranked partic- ipants. We choose to focus on one language pair and one task because of the following advantages: (i) three state-of-the art PBMT systems compared against the NMT system on the same data and in the very same period (that of the evaluation cam- paign); (ii) a challenging language pair in terms of morphology and word order differences; (iii) avail- ability of MT outputs' post-editing done by pro- fessional translators, which is very costly and thus rarely available. In general, post-edits have the ad- vantage of allowing for informative and detailed analyses since they directly point to translation er- rors. In this specific framework, the high quality data created by professional translators guarantees reliable evaluations. For all these reasons we present our study as a solid contribution to the better under- standing of this new paradigm shift in MT.</p><p>After reviewing previous work (Section 2), we in- troduce the analyzed data and the systems that pro- duced them (Section 3). We then present three in- creasingly fine levels of MT quality analysis. We first investigate how MT systems' quality varies with specific characteristics of the input, i.e. sentence length and type of content of each talk (Section 4). Then, we focus on differences among MT systems with respect to morphology, lexical, and word or- der errors (Section 5). Finally, based on the finding that word reordering is the strongest aspect of NMT compared to the other systems, we carry out a fine- grained analysis of word order errors (Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Previous Work</head><p>To date, NMT systems have only been evaluated by BLEU in single-reference setups ( <ref type="bibr" target="#b0">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b35">Sutskever et al., 2014;</ref><ref type="bibr" target="#b20">Jean et al., 2015a;</ref><ref type="bibr" target="#b16">Gülçehre et al., 2015)</ref>. Ad- ditionally, the Montreal NMT system submitted to <ref type="bibr">WMT 2015</ref><ref type="bibr" target="#b21">(Jean et al., 2015b</ref>) was part of a man- ual evaluation experiment where a large number of non-professional annotators were asked to rank the outputs of multiple MT systems ( <ref type="bibr" target="#b5">Bojar et al., 2015)</ref>. Results for the Montreal system were very positive -ranked first in English-German, third in German- English, English-Czech and Czech-English -which confirmed and strengthened the BLEU results pub- lished so far. Unfortunately neither BLEU nor man- ual ranking judgements tell us which translation as- pects are better modeled by different MT frame- works. To this end, a detailed and systematic error analysis of NMT vs. PBMT output is required.</p><p>Translation error analysis, as a way to identify systems' weaknesses and define priorities for their improvement, has received a fair amount of atten- tion in the MT community. In this work we opt for the automatic detection and classification of transla- tion errors based on manual post-edits of the MT output. We believe this choice provides an opti- mal trade-off between fully manual error analysis <ref type="bibr" target="#b11">(Farrús Cabeceran et al., 2010;</ref><ref type="bibr" target="#b29">Popovi´cPopovi´c et al., 2013;</ref><ref type="bibr">Daems et al., 2014;</ref><ref type="bibr" target="#b27">Neubig et al., 2015)</ref>, which is very costly and complex, and fully automatic error analysis <ref type="bibr" target="#b28">(Popovi´cPopovi´c and Ney, 2011;</ref><ref type="bibr" target="#b19">Irvine et al., 2013)</ref>, which is noisy and biased towards one or few arbitrary reference translations.</p><p>Existing tools for translation error detection are either based on Word Error Rate (WER) and Position-independent word Error Rate (PER) ) or on output-reference alignment <ref type="bibr" target="#b38">(Zeman et al., 2011</ref>). Regarding error classifi- cation, Hjerson (Popovi´cPopovi´c, 2011) detects five main types of word-level errors as defined in <ref type="bibr" target="#b37">(Vilar et al., 2006</ref>): morphological, reordering, missing words, extra words, and lexical choice errors. We follow a similar but simpler error classification (morpho- logical, lexical, and word order errors), but detect the errors differently using TER as this is the most natural choice in our evaluation framework based on post-edits (see also Section 3.4). <ref type="bibr" target="#b19">Irvine et al. (2013)</ref> propose another word-level error analysis technique specifically focused on lexical choice and aimed at understanding the effects of domain differences on MT. Their error classification is strictly related to model coverage and insensitive to word order dif- ferences. The technique requires access to the sys-tem's phrase table and is thus not applicable to NMT, which does not rely on a fixed inventory of transla- tion units extracted from the parallel data.</p><p>Previous error analyses based on manually post- edited translations were presented in <ref type="bibr" target="#b6">(Bojar, 2011;</ref><ref type="bibr" target="#b23">Koponen, 2012;</ref><ref type="bibr" target="#b29">Popovi´cPopovi´c et al., 2013</ref>). We are the first to conduct this kind of study on the output of a neural MT system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setting</head><p>We perform a number of analyses on data and re- sults of the IWSLT 2015 MT En-De task, which consists in translating manual transcripts of English TED talks into German. Evaluation data are pub- licly available through the WIT 3 repository (Cettolo et al., 2012). <ref type="bibr">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Data</head><p>TED Talks 4 are a collection of rather short speeches (max 18 minutes each, roughly equivalent to 2,500 words) covering a wide variety of topics. All talks have captions, which are translated into many lan- guages by volunteers worldwide. Besides represent- ing a popular benchmark for spoken language tech- nology, TED Talks embed interesting research chal- lenges. Translating TED Talks implies dealing with spoken rather than written language, which is hence expected to be structurally less complex, formal and fluent <ref type="bibr" target="#b31">(Ruiz and Federico, 2014)</ref>. Moreover, as hu- man translations of the talks are required to follow the structure and rhythm of the English captions, a lower amount of rephrasing and reordering is ex- pected than in the translation of written documents.</p><p>As regards the English-German language pair, the two languages are interesting since, while belonging to the same language family, they have marked dif- ferences in levels of inflection, morphological varia- tion, and word order, especially long-range reorder- ing of verbs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Data</head><p>Five systems participated in the MT En-De task and were manually evaluated on a representative subset of the official 2015 test set. The Human Evaluation (HE) set includes the first half of each of the 12 test</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Approach Data PBSY Combination: Phrase+Syntax-based 175M/ (Huck and GHKM string-to-tree; hierarchical + 3.1B Birch, 2015) sparse lexicalized reordering models HPB Hierarchical Phrase-based 166M/ (Jehl et al., source pre-ordering (dependency tree 854M 2015) -based); re-scoring with neural LM SPB Standard Phrase-based 117M/ ( <ref type="bibr">Ha et al.,</ref> source pre-ordering (POS-and tree-2.4B 2015) based); re-scoring with neural LMs NMT Recurrent neural network (LSTM) 120M/ (Luong &amp; Man-attention-based; source reversing; - ning, 2015) rare words handling <ref type="table">Table 1</ref>: MT systems' overview. Data column: size of paral- lel/monolingual training data for each system in terms of En- glish and German tokens.</p><p>talks, for a total of 600 sentences and around 10K words. Five professional translators were asked to post-edit the MT output by applying the minimal ed- its required to transform it into a fluent sentence with the same meaning as the source sentence. Data were prepared so that all translators equally post-edited the five MT outputs, i.e. 120 sentences for each eval- uated system.</p><p>The resulting evaluation data consist of five new reference translations for each of the sentences in the HE set. Each one of these references represents the targeted translation of the system output from which it was derived, but the other four additional translations can also be used to evaluate each MT system. We will see in the next sections how we ex- ploited the available post-edits in the more suitable way depending on the kind of analysis carried out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">MT Systems</head><p>Our analysis focuses on the first four top-ranking systems, which include NMT (  and three different phrase-based approaches: standard phrase-based ( <ref type="bibr">Ha et al., 2015)</ref>, hierarchi- cal ( <ref type="bibr" target="#b22">Jehl et al., 2015</ref>) and a combination of phrase- based and syntax-based <ref type="bibr" target="#b18">(Huck and Birch, 2015)</ref>. Ta- ble 1 presents an overview of each system, as well as figures about the training data used. <ref type="bibr">5</ref> The phrase+syntax-based (PBSY) system com- bines the outputs of a string-to-tree decoder, trained with the GHKM algorithm, with those of two stan-dard phrase-based systems featuring, among others, adapted phrase tables and language models enriched with morphological information, hierarchical lexi- calized reordering models and different variations of the operational sequence model.</p><p>The hierarchical phrase-based MT (HPB) system leverages thousands of lexicalised features, data- driven source pre-ordering (dependency tree-based), word-based and class-based language models, and n-best re-scoring models based on syntactic and neu- ral language models.</p><p>The standard phrase-based MT (SPB) system fea- tures an adapted phrase-table combining in-domain and out-domain data, discriminative word lexicon models, multiple language models (word-, POS-and class-based), data-driven source pre-ordering (POS- and constituency syntax-based), n-best re-scoring models based on neural lexicons and neural lan- guage models.</p><p>Finally, the neural MT (NMT) system is an en- semble of 8 long short-term memory (LSTM) net- works of 4 layers featuring 1,000-dimension word embeddings, attention mechanism, source revers- ing, 50K source and target vocabularies, and out-of- vocabulary word handling. Training with TED data was performed on top of models trained with large out-domain parallel data.</p><p>With respect to the use of training data, it is worth noticing that NMT is the only system not employ- ing monolingual data in addition to parallel data. Moreover, NMT and SPB were trained with smaller amounts of parallel data with respect to PBSY and HPB (see <ref type="table">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Translation Edit Rate Measures</head><p>The Translation Edit Rate (TER) ( <ref type="bibr" target="#b33">Snover et al., 2006</ref>) naturally fits our evaluation framework, where it traces the edits done by post-editors. Also, TER shift operations are reliable indicators of re- ordering errors, in which we are particularly inter- ested. We exploit the available post-edits in two dif- ferent ways: (i) for Human-targeted TER (HTER) we compute TER between the machine translation and its manually post-edited version (targeted ref- erence), (ii) for Multi-reference TER (mTER), we compute TER against the closest translation among all available post-edits (i.e. targeted and additional references) for each sentence.  Throughout sections 4 and 5, we mark a score achieved by NMT with the symbol * if this is bet- ter than the score of its best competitor at statistical significance level 0.01. Significance tests for HTER and mTER are computed by bootstrap re-sampling, while differences among proportions are assessed via one-tailed z-score tests. We can see that NMT clearly outperforms all other approaches both in terms of BLEU and TER scores. Focusing on mTER results, the gain obtained by NMT over the second best system (PBSY) amounts to 26%. It is also worth noticing that mTER is con- siderably lower than HTER for each system. This re- duction shows that exploiting all the available post- edits as references for TER is a viable way to control and overcome post-editors variability, thus ensuring a more reliable and informative evaluation about the real overall performance of MT systems. For this reason, the two following analyses rely on mTER. In particular, we investigate how specific character- istics of input documents affect the system's overall translation quality, focusing on (i) sentence length and (ii) the different talks composing the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Overall Translation Quality</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Translation quality by sentence length</head><p>Long sentences are known to be difficult to trans- late by the NMT approach.  significant differences. As a general tendency, the performance of all approaches worsens as sentence length increases. However, for sentences longer than 35 words we see that NMT quality degrades more markedly than in PBMT systems. Considering the percentage decrease with respect to the preceding length bin <ref type="bibr">(26)</ref><ref type="bibr">(27)</ref><ref type="bibr">(28)</ref><ref type="bibr">(29)</ref><ref type="bibr">(30)</ref><ref type="bibr">(31)</ref><ref type="bibr">(32)</ref><ref type="bibr">(33)</ref><ref type="bibr">(34)</ref><ref type="bibr">(35)</ref>, we see that the %∆ for NMT (-15.4) is much larger than the average %∆ for the three PBMT systems (-7.9). Hence, this still seems an issue to be addressed for further improving NMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Translation quality by talk</head><p>As we saw in Section 3.1, the TED dataset is very heterogeneous since it consists of talks covering dif- ferent topics and given by speakers with different styles. It is therefore interesting to evaluate trans- lation quality also at the talk level. <ref type="figure" target="#fig_2">Figure 2</ref> plots the mTER scores for each of the twelve talks included in the HE set, sorted in ascend- ing order of NMT scores. In all talks, the NMT sys- tem outperforms the PBMT systems in a statistically significant way.</p><p>We analysed different factors which could impact translation quality in order to understand if they cor- relate with such performance differences. We stud- ied three features which are typically considered as indicators of complexity (see <ref type="bibr" target="#b15">(François and Fairon, 2012</ref>) for an overview), namely (i) the length of the talk, (ii) its average sentence length, and (iii) the type-token ratio 6 (TTR) which -measuring lexical diversity -reflects the size of a speaker's vocabulary and the variety of subject matter in a text.</p><p>For the first two features we did not find any cor- relation; on the contrary, we found a moderate Pear- son correlation (R=0.7332) between TTR and the mTER gains of NMT over its closest competitor in each talk. This result suggests that NMT is able to cope with lexical diversity better than any other con- sidered approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis of Translation Errors</head><p>We now turn to analyze which types of linguistic er- rors characterize NMT vs. PBMT. In the literature, various error taxonomies covering different levels of granularity have been developed <ref type="bibr" target="#b14">(Flanagan, 1994;</ref><ref type="bibr" target="#b37">Vilar et al., 2006;</ref><ref type="bibr" target="#b11">Farrús Cabeceran et al., 2010;</ref><ref type="bibr" target="#b34">Stymne and Ahrenberg, 2012;</ref><ref type="bibr" target="#b24">Lommel et al., 2014</ref>). We focus on three error categories, namely (i) mor- phology errors, (ii) lexical errors, and (iii) word or- der errors. As for lexical errors, a number of existing taxonomies further distinguish among translation er- rors due to missing words, extra words, or incor- rect lexical choice. However, given the proven dif- ficulty of disambiguating between these three sub- classes <ref type="bibr" target="#b28">(Popovi´cPopovi´c and Ney, 2011;</ref><ref type="bibr" target="#b13">Fishel et al., 2012)</ref>, we prefer to rely on a more coarse-grained linguistic error classification where lexical errors include all of them <ref type="bibr" target="#b11">(Farrús Cabeceran et al., 2010</ref>).</p><p>For error analysis we rely on HTER results under the assumption that, since the targeted translation is generated by post-editing the given MT output, this method is particularly informative to spot MT er- rors. We are aware that translator subjectivity is still an issue (see Section 4), however in this more fine- grained analysis we prefer to focus on what a hu- man implicitly annotated as a translation error. This particularly holds in our specific evaluation frame- work, where the goal is not to measure the absolute number of errors made by each system, but to com- pare systems with each other. Moreover, the post- edits collected for each MT output within IWSLT allow for a fair and reliable comparison since sys- tems were equally post-edited by all translators (see Section 3.2), making all analyses uniformly affected by such variability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Morphology errors</head><p>A morphology error occurs when a generated word form is wrong but its corresponding base form (lemma) is correct. Thus, we assess the ability of systems to deal with morphology by comparing the HTER score computed on the surface forms (i.e. morphologically inflected words) with the HTER score obtained on the corresponding lemmas. The additional matches counted on lemmas with respect to word forms indicate morphology errors. Thus, the closer the two HTER scores, the more accurate the system in handling morphology.</p><p>To carry out this analysis, the lemmatized (and POS tagged) version of both MT outputs and cor- responding post-edits was produced with the Ger- man parser ParZu ( <ref type="bibr" target="#b32">Sennrich et al., 2013)</ref>. Then, the HTER-based evaluation was slightly adapted in or- der to be better suited to an accurate detection of morphology errors. First, punctuation was removed since -not being subject to morphological inflection -it could smooth the results. Second, shift errors were not considered. A word form or a lemma that matches a corresponding word or lemma in the post- edit, but is in the wrong position with respect to it, is counted as a shift error in TER. Instead -when focusing on morphology -exact matches are not er- rors, regardless their position in the text. 7 <ref type="bibr">7</ref> Note that the TER score calculated by setting to 0 the cost of shifts approximates the Position-independent Error Rate ( <ref type="bibr" target="#b36">Tillmann et al., 1997</ref>   <ref type="table" target="#tab_4">Table 3</ref> presents HTER scores on word forms and lemmas, as well as their percentage difference which gives an indication of morphology errors. We can see that NMT generates translations which are mor- phologically more correct than the other systems. In particular, the %∆ for NMT (-13.7) is lower than that of the second best system (PBSY, -16.9) by 3.2% absolute points, leading to a percentage gain of around 19%. We can thus say that NMT makes at least 19% less morphology errors than any other PBMT system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Lexical errors</head><p>Another important feature of MT systems is their ability to choose lexically appropriate words. In or- der to compare systems under this aspect, we con- sider HTER results at the lemma level as a way to abstract from morphology errors and focus only on actual lexical choice problems. The evaluation on the lemmatised version of the data performed to identify morphology errors fits this purpose, since its driving assumptions (i.e. punctuation can be ex- cluded and lemmas in the wrong order are not errors) hold for lexical errors too.</p><p>The lemma column of <ref type="table" target="#tab_4">Table 3</ref> shows that NMT outperforms the other systems. More precisely, the NMT score (18.7) is better than the second best (PBSY, 22.5) by 3.8% absolute points. This corre- sponds to a relative gain of about 17%, meaning that NMT makes at least 17% less lexical errors than any PBMT system. Similarly to what observed for mor- phology errors, this can be considered a remarkable improvement over the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Word order errors</head><p>To analyse reordering errors, we start by focusing on shift operations identified by the HTER metrics. The first three columns of  (ii) the number of shifts required to align each sys- tem output to the corresponding post-edit; and (iii) the corresponding percentage of shift errors. Notice that the shift error percentages are incorporated in the HTER scores reported in <ref type="table" target="#tab_1">Table 2</ref>. We can see in <ref type="table" target="#tab_5">Table 4</ref> that shift errors in NMT translations are definitely less than in the other systems. The error reduction of NMT with respect to the second best system (PBSY) is about 50% <ref type="bibr">(173 vs. 354)</ref>.</p><p>It should be recalled that these numbers only re- fer to shifts detected by HTER, that is (groups of) words of the MT output and corresponding post-edit that are identical but occurring in different positions. Words that had to be moved and modified at the same time (for instance replaced by a synonym or a morphological variant) are not counted in HTER shift figures, but are detected as substitution, inser- tion or deletion operations. To ensure that our re- ordering evaluation is not biased towards the align- ment between the MT output and the post-edit per- formed by HTER, we run an additional assessment using KRS -Kendall Reordering Score ( <ref type="bibr" target="#b1">Birch et al., 2010</ref>) -which measures the similarity between the source-reference reorderings and the source-MT output reorderings. 8 Being based on bilingual word alignment via the source sentence, KRS detects re- ordering errors also when post-edit and MT words are not identical. Also unlike TER, KRS is sensitive to the distance between the position of a word in the MT output and that in the reference.</p><p>Looking at the last column of <ref type="table" target="#tab_5">Table 4</ref>, we can say that our observations on HTER are confirmed by the KRS results: the reorderings performed by NMT are much more accurate than those performed by any PBMT system. <ref type="bibr">9</ref> Moreover, according to the approx-imate randomization test, KRS differences are statis- tically significant between NMT and all other sys- tems, but not among the three PBMT systems.</p><p>Given the concordant results of our two quanti- tative analyses, we conclude that one of the ma- jor strengths of the NMT approach is its ability to place German words in the right position even when this requires considerable reordering. This outcome calls for a deeper investigation, which is carried out in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Fine-grained Word Order Error Analysis</head><p>We have observed that word reordering is a very strong aspect of NMT compared to PBMT, accord- ing to both HTER and KRS. To better understand this finding, we investigate whether reordering er- rors concentrate on specific linguistic constructions across our systems. Using the POS tagging and dependency parsing of the post-edits produced by ParZu, we classify the shift operations detected by HTER and count how often a word with a given POS label was misplaced by each of the systems (alone or as part of a shifted block). For each word class, we also compute the percentage order error reduction of NMT with respect to the PBMT system that has highest reordering accuracy overall, that is PBSY. Results are presented in <ref type="table" target="#tab_8">Table 5</ref>, ranked by NMT- vs-PBSY gain. Punctuation is omitted as well as word classes that were shifted less than 10 times by all systems. Examples of salient word order error types are presented in <ref type="table" target="#tab_10">Table 6</ref>. The upper part of <ref type="table" target="#tab_8">Table 5</ref> shows that verbs are by far the most often misplaced word category in all PBMT systems -an issue already known to affect standard phrase-based SMT between German and English ( <ref type="bibr" target="#b3">Bisazza and Federico, 2013)</ref>. Reordering is particularly difficult when translating into German, since the position of verbs in this language varies according to the clause type (e.g. main vs. subor- dinate). Our results show that even syntax-informed PBMT does not solve this issue. Using syntax at decoding time, as done by one of the systems com- bined within PBSY, appears to be a better strategy reports a difference of 5 KRS points between the translations of a PBMT system and those produced by four human translators tested against each other, in a Chinese-English experiment. <ref type="table" target="#tab_1">NMT-NMT PBSY HPB SPB  vs-PBSY   V   -70%  35  116 133 155   PRO   -57%  22  51  53</ref>   than using it for source pre-ordering, as done by the HPB and SPB systems. However this only results in a moderate reduction of verb reordering errors (- 12% and -25% vs. HPB and SPB respectively). On the contrary, NMT reduces verb order errors by an impressive -70% with respect to PBSY (-74% and -77% vs. HPB and SPB respectively) despite being trained on raw parallel data without any syntactic annotation, nor explicit modeling of word reorder- ing. This result shows that the recurrent neural lan- guage model at the core of the NMT architecture is very successful at generating well-formed sentences even in languages with less predictable word order, like German (see examples in <ref type="table" target="#tab_10">Table 6</ref>(a,b)). NMT, though, gains notably less on nouns (-47%), which is the second most often misplaced word category in PBSY. More insight on this is provided by the lower part of the table, where reordering errors are divided by their dependency label as well as POS tag. Here we see that order errors on nouns are notably reduced by NMT when they act as syntac- tic objects (-65% obja:N) but less when they act as preposition complements (-36% pn:N) or subjects (- 33% subj:N).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head><p>The smallest NMT-vs-PBSY gains are observed on prepositions (-18% PREP), negation particles (-17% PTKNEG) and articles (-4% ART). Manual inspection of a data sample reveals that misplaced prepositions are often part of misplaced preposi- tional phrases acting, for instance, as temporal or instrumental adjuncts (e.g. 'in my life', 'with this video'). In these cases, the original MT output is overall understandable and grammatical, but does not conform to the order of German semantic argu- ments that is consistently preferred by post-editors (see example in <ref type="table" target="#tab_10">Table 6</ref>(c)). Articles, due to their commonness, are often misaligned by HTER and marked as shift errors instead of being marked as two unrelated substitutions. Finally, negation parti- cles account for less than 1% of the target tokens but play a key role in determining the sentence meaning. Looking closely at some error examples, we found that the correct placement of the German particle nicht was determined by the focus of negation in the source sentence, which is difficult to detect in En- glish. For instance in <ref type="table" target="#tab_10">Table 6</ref>(d) two interpretations are possible ('that did not work' or 'that worked, but not for systematic reasons'), each resulting in a dif- ferent, but equally grammatical, location of nicht. In fact, negation-focus detection calls for a deep un- derstanding of the sentence semantics, often requir- ing extra-sentential context ( <ref type="bibr" target="#b4">Blanco and Moldovan, 2011)</ref>. When faced with this kind of translation de- cisions, NMT performs as poorly as its competitors.</p><p>In summary, our fine-grained analysis confirms that NMT concentrates its word order improvements on important linguistic constituents and, specifically in English-German, is very close to solving the infa- mous problem of long-range verb reordering which so many PBMT approaches have only poorly man- aged to handle. On the other hand, NMT still strug- gles with more subtle translation decisions depend- ing, for instance, on the semantic ordering of adjunct prepositional phrases or on the focus of negation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Auxiliary-main verb construction [aux:V]:</head><p>SRC in this experiment , individuals were shown hundreds of hours of YouTube videos HPB in diesem Experiment , Individuen gezeigt wurden Hunderte von Stunden YouTube-Videos %   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We analysed the output of four state-of-the-art MT systems that participated in the English-to-German task of the IWSLT 2015 evaluation campaign. Our selected runs were produced by three phrase-based MT systems and a neural MT system. The analysis leveraged high quality post-edits of the MT outputs, which allowed us to profile systems with respect to reliable measures of post-editing effort and transla- tion error types.</p><p>The outcomes of the analysis confirm that NMT has significantly pushed ahead the state of the art, especially in a language pair involving rich morphol- ogy prediction and significant word reordering. To summarize our findings: (i) NMT generates outputs that considerably lower the overall post-edit effort with respect to the best PBMT system (-26%); (ii) NMT outperforms PBMT systems on all sentence lengths, although its performance degrades faster with the input length than its competitors; (iii) NMT seems to have an edge especially on lexically rich texts; (iv) NMT output contains less morphology er- rors (-19%), less lexical errors (-17%), and substan- tially less word order errors (-50%) than its closest competitor for each error type; (v) concerning word order, NMT shows an impressive improvement in the placement of verbs (-70% errors).</p><p>While NMT proved superior to PBMT with re- spect to all error types that were investigated, our analysis also pointed out some aspects of NMT that deserve further work, such as the handling of long sentences and the reordering of particular linguistic constituents requiring a deep semantic understand- ing of text. Machine translation is definitely not a solved problem, but the time is finally ripe to tackle its most intricate aspects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Following previous work (Cho et al., 2014a; Pouget-Abadie et al., 2014; Bah- danau et al., 2015; Luong et al., 2015), we investi- gate how sentence length affects overall translation quality. Figure 1 plots mTER scores against source sentence length. NMT clearly outperforms every PBMT system in any length bin, with statistically</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: mTER scores on bins of sentences of different length. Points represent the average mTER of the MT outputs for the sentences in each given bin.</figDesc><graphic url="image-1.png" coords="5,72.00,57.83,226.80,170.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: mTER scores per talk, sorted in ascending order of NMT scores.</figDesc><graphic url="image-2.png" coords="5,313.20,57.82,226.80,159.14" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Prepositional phrase [pp:PREP det:ART pn:N] acting as temporal adjunct: SRC so like many of us , I 've lived in a few closets in my life SPB so wie viele von uns , ich habe in ein paar Schränke in meinem Leben gelebt % (c) PE so habe ich wie viele von uns während meines Lebens in einigen Verstecken gelebt NMT wie viele von uns habe ich in ein paar Schränke in meinem Leben gelebt % PE wie viele von uns habe ich in meinem Leben in ein paar Schränken gelebt Negation particle [adv:PTKNEG]: SRC but I eventually came to the conclusion that that just did not work for systematic reasons HPB aber ich kam schlielich zu dem Schluss , dass nur aus systematischen Gründen nicht funktionieren ! (d) PE aber ich kam schlielich zu dem Schluss , dass es einfach aus systematischen Gründen nicht funktioniert NMT aber letztendlich kam ich zu dem Schluss , dass das einfach nicht aus systematischen Gründen funktionierte % PE ich musste aber einsehen , dass das aus systematischen Gründen nicht funktioniert</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Overall results on the HE Set: BLEU, computed</head><label>2</label><figDesc></figDesc><table>against the original reference translation, and TER, computed 

with respect to the targeted post-edit (HTER) and multiple post-

edits (mTER). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 presents</head><label>2</label><figDesc>overall system results according to HTER and mTER, as well as BLEU computed against the original TED Talks reference translation.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>HTER ignoring shift operations computed on words 

and corresponding lemmas, and their % difference. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 show, respectively: (i) the number of words generated by each system</head><label>4</label><figDesc></figDesc><table>system #words #shifts %shifts KRS 
PBSY 11,517 
354 
3.1 
84.6 
HPB 
11,417 
415 
3.6 
84.3 
SPB 
11,420 
398 
3.5 
84.5 
NMT 
11,284 
173 
1.5  *  
88.3  *  

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 : Word reordering evaluation in terms of shift opera-</head><label>4</label><figDesc></figDesc><table>tions in HTER calculation and of KRS. For each system, the 

number of generated words, the number of shift errors and their 

corresponding percentages are reported. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Main POS tags and dependency labels of words oc-

curring in shifted blocks detected by HTER. NMT-vs-PBSY 

denotes the reduction of reordering errors in NMT vs. PBSY 

system. Only word classes that were shifted 10 or more times 

in at least one system output are shown. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>(a) PE in diesem Experiment wurden Individuen Hunderte von Stunden Youtube-Videos gezeigt NMT in diesem Experiment wurden Individuen hunderte Stunden YouTube Videos gezeigt ! PE in diesem Experiment wurden Individuen hunderte Stunden YouTube Videos gezeigt</head><label></label><figDesc></figDesc><table>Verb in subordinate (adjunct) clause [neb:V]: 
SRC ... when coaches and managers and owners look at this information streaming ... 

PBSY ... wenn Trainer und Manager und Eigentümer betrachten diese Information Streaming ... 

% 

(b) PE 
... wenn Trainer und Manager und Eigentümer dieses Informations-Streaming betrachten ... 

NMT ... wenn Trainer und Manager und Besitzer sich diese Informationen anschauen ... 

! 

PE 

... wenn Trainer und Manager und Besitzer sich diese Informationen anschauen ... 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc>MT output and post-edit examples showing common types of reordering errors.</figDesc><table></table></figure>

			<note place="foot" n="1"> We use the generic term phrase-based MT to cover standard phrase-based, hierarchical and syntax-based SMT approaches. 2 International Workshop on Spoken Language Translation (http://workshop2015.iwslt.org/)</note>

			<note place="foot" n="3"> wit3.fbk.eu 4 http://www.ted.com/</note>

			<note place="foot" n="5"> Detailed information about training data was kindly made available by participating teams.</note>

			<note place="foot" n="6"> The type-token-ratio of a text is calculated dividing the number of word types (vocabulary) by the total number of word tokens (occurrences).</note>

			<note place="foot" n="8"> To compute the word alignments required by KRS, we used the FastAlign tool (Dyer et al., 2013). 9 To put our results into perspective, note that Birch (2011)</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR<address><addrLine>San Diego, US-CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metrics for MT evaluation: evaluating reordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Reordering Metrics for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>School of Informatics, University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Efficient solutions for word reordering in German-English phrase-based statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WMT</title>
		<meeting>of WMT<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic representation of negation using focus detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-HLT</title>
		<meeting>of ACL-HLT<address><addrLine>Portland, US-OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<title level="m">Findings of the 2015 workshop on statistical machine translation</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Proc. of WMT</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Analyzing error types in EnglishCzech machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistic</title>
		<imprint>
			<biblScope unit="issue">95</biblScope>
			<biblScope unit="page" from="63" to="76" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">WIT 3 : Web Inventory of Transcribed and Translated Talks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Girardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello ; Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roldano</forename><surname>Cattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWSLT</title>
		<meeting>of IWSLT<address><addrLine>Trento, Italy. Mauro Cettolo; Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
	<note>Proc. of EAMT</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the properties of neural machine translation: encoder-decoder approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SSST-8</title>
		<meeting>of SSST-8<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP<address><addrLine>Doha, Qatar; Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Proc. of LREC</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A simple, fast, and effective reparameterization of IBM model 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Chahuneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NACL-HLT</title>
		<meeting>of NACL-HLT<address><addrLine>Atlanta, USGA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistic-based evaluation criteria to identify statistical machine translation errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><forename type="middle">Ruiz</forename><surname>Mireia Farrús Cabeceran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bernardo Mariño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Adrián Rodríguez</forename><surname>Acebal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fonollosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EAMT</title>
		<meeting>of EAMT<address><addrLine>Saint-Raphaël, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Assessing the impact of translation errors on machine translation quality with mixedeffects models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Terra: a collection of translation error-annotated corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Error classification for MT evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Flanagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA</title>
		<meeting>of AMTA<address><addrLine>Columbia, US-MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An &quot;AI readability&quot; formula for French as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>François</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cédrick</forename><surname>Fairon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-CoNLL</title>
		<meeting>of EMNLP-CoNLL<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On using monolingual corpora in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huei-Chi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1503.03535</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mohammed Mediani, and Alex Waibel. 2015. The KIT translation systems for IWSLT 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Le</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunah</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWSLT</title>
		<meeting>of IWSLT<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Edinburgh machine translation systems for IWSLT 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWSLT</title>
		<meeting>of IWSLT<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Measuring machine translation errors in new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Munteanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="429" to="440" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL-IJCNLP</title>
		<meeting>of ACL-IJCNLP<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Montreal neural machine translation systems for WMT15</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WMT</title>
		<meeting>of WMT<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Heidelberg university EnglishGerman translation system for IWSLT 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Jehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Simianer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWSLT</title>
		<meeting>of IWSLT<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Comparing human perceptions of post-editing effort with post-editing operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maarit Koponen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WMT</title>
		<meeting>of WMT<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using a new analytic measure for the annotation and analysis of MT errors on real data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arle</forename><surname>Lommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Burchardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EAMT</title>
		<meeting>of EAMT<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Eleftherios Avramidis, and Hans Uszkoreit</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Stanford neural machine translation systems for spoken language domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWSLT</title>
		<meeting>of IWSLT<address><addrLine>Da Nang, Vietnam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="Por" to=" tugal" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural Reranking Improves Subjective Quality of Machine Translation: NAIST at WAT2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of WAT2015</title>
		<meeting>of WAT2015<address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards automatic error analysis of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="657" to="688" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hjerson: an open source tool for automatic error classification of machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popovi´cpopovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleftherios</forename><surname>Avramidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Burchardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Hunsicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Schmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cindy</forename><surname>Tscherwinka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT Summit</title>
		<meeting>of MT Summit<address><addrLine>Nice, France. Maja Popovi´cPopovi´c</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
	<note>Learning from human judgments of machine translation output</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Overcoming the curse of sentence length for neural machine translation using automatic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SSST-8</title>
		<meeting>of SSST-8<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Complexity of spoken versus written language for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EAMT</title>
		<meeting>of EAMT<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploiting synergies between open resources for German dependency parsing, POS-tagging, and morphological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Volk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerold</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RANLP</title>
		<meeting>of RANLP<address><addrLine>Hissar, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of AMTA</title>
		<meeting>of AMTA<address><addrLine>Boston, US-MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the practice of error analysis for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Stymne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Ahrenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Accelerated DP based search for statistical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sawaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Eurospeech</title>
		<meeting>of Eurospeech<address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Error analysis of statistical machine translation output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Fernando D&amp;apos;haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Addicter: what is wrong with my translations? The Prague Bulletin of Mathematical Linguistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fishel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Berka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="79" to="88" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
