<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Emotion Distribution Learning from Texts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">MOE Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Engineering Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">MOE Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Engineering Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">MOE Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Engineering Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">MOE Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Engineering Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">MOE Key Laboratory of Computer Network and Information Integration</orgName>
								<orgName type="institution">Engineering Southeast University</orgName>
								<address>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Emotion Distribution Learning from Texts</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="638" to="647"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The advent of social media and its prosperity enable users to share their opinions and views. Understanding users&apos; emotional states might provide the potential to create new business opportunities. Automatically identifying user-s&apos; emotional states from their texts and classifying emotions into finite categories such as joy, anger, disgust, etc., can be considered as a text classification problem. However , it introduces a challenging learning scenario where multiple emotions with different intensities are often found in a single sentence. Moreover, some emotions co-occur more often while other emotions rarely co-exist. In this paper, we propose a novel approach based on emotion distribution learning in order to address the aforementioned issues. The key idea is to learn a mapping function from sentences to their emotion distributions describing multiple emotions and their respective intensities. Moreover, the relations of emotions are captured based on the Plutchik&apos;s wheel of emotions and are subsequently incorporated into the learning algorithm in order to improve the accuracy of emotion detection. Experimental results show that the proposed approach can effectively deal with the emotion distribution detection problem and perform remarkably better than both the state-of-the-art emotion detection method and multi-label learning methods.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The advent of social media and its prosperity enable the creation of massive online user-generated con- *</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corresponding author</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence</head><p>Trains crash near Thai resort town Emotions anger disgust fear joy sadness surprise 2 0 62 0 90 10 tent including opinions and product reviews. Ana- lyzing such user-generated content allows the detec- tion of users' emotional states, which might be po- tentially useful for downstream applications such as brand watching, product recommendation, and de- tection of health-related issues, etc. Based on the way emotions are represented, computational mod- els for emotion analysis can be categorized into di- mensional models and categorical models <ref type="bibr" target="#b5">(Calvo and D'Mello, 2010)</ref>. Dimensional approaches <ref type="bibr" target="#b22">(Russell, 2003</ref>) emphasize the fundamental dimension- s of valence and arousal in understanding emotion- al experience, which have long been studied by e- motion theorists. Categorical models ( <ref type="bibr" target="#b10">Gupta et al., 2013)</ref> involve the use of a categorical representa- tion, in which emotions are represented by a num- ber of labels. For example, Ekman's basic emotion set <ref type="bibr" target="#b7">(Ekman, 1992)</ref> consists of anger, disgust, fear, happiness, sadness and surprise. An example of a sentence and the annotated emotions can be found in <ref type="table" target="#tab_0">Table 1</ref>. Considering each basic emotion as class label for the sentence, emotion detection can be treated as a classification problem. There is a large body of pri- or work on emotion classification (Mishne and de <ref type="bibr" target="#b14">Rijke, 2006</ref>; <ref type="bibr" target="#b13">Lin and He, 2009;</ref><ref type="bibr" target="#b20">Quan et al., 2015</ref>; <ref type="bibr" target="#b26">Wang and Pal, 2015)</ref>. By choosing the strongest e- motion as the emotion label for the sentence, most of classification approaches are based on single-label learning. However, as shown in <ref type="table" target="#tab_0">Table 1</ref>, a sentence might contain multiple emotions with varying inten- sities. Although, some lexicon-based approach such as ( <ref type="bibr" target="#b26">Wang and Pal, 2015)</ref> can output multiple emo- tions with intensities using non-negative matrix fac- torization. It can only guarantee convergence to a local minimum, which is prohibitive on the large, realistically-sized emotion detection problem.</p><p>Machine learning methods such as multi-label learning (MLL) can be employed to identify mul- tiple emotions for each sentence <ref type="bibr" target="#b28">(Zhang and Zhou, 2014)</ref>. MLL usually selects a threshold, then label- s emotions with scores higher than the threshold as relevant and the others as irrelevant. However, these methods are not able to learn the intensity of each emotion. To address this problem, a new machine learning paradigm called Label Distribution Learn- ing (LDL) <ref type="bibr" target="#b9">(Geng, 2016)</ref> was proposed in recently years. Similarly, in this paper, we propose an e- motion distribution learning (EDL) algorithm. Dif- ferent from the previous approaches, EDL assumes that each sentence contains a mixture of basic e- motions with different intensities. Using categori- cal model, we can label each sentence with an emo- tion vector where each element corresponds to one basic emotion and the value of each element indi- cates the intensity of the emotion. We require that each vector element has a value between 0 and 1 and they sum up to 1. By doing so, the emotion vectors can be considered as emotion distributions and the proposed EDL algorithm aims to learn the mapping from sentences to their corresponding e- motion distributions by minimizing the differences between the true distributions and the predicted dis- tributions. Both the single-label learning and ML- L can be considered as special cases of EDL in e- motion detection. Moreover, as some emotions co- occur more often while others rarely co-exist, the relations between basic emotions are captured ac- cording to the Plutchik's wheel of emotions theo- ry <ref type="bibr" target="#b16">(Plutchik, 1980)</ref> and are incorporated in the learn- ing framework as constraints in order to improve the accuracy of emotion detection.</p><p>Our work makes the following contributions:</p><p>• We propose a novel approach based on emo- tion distribution learning to identify multiple emotions with their intensities from texts. To the best of our knowledge, it is the first attempt to identify both emotions and intensities in the distribution learning framework.</p><p>• The relations between basic emotions are in- corporated into the learning framework as con- straints to improve the emotion detection accu- racy. To avoid the incorporation of noisy in- formation from the training data, the relation constraint is set based on the Plutchik's wheel of emotions theory.</p><p>• Experimental results show that the proposed approach can effectively deal with the emotion distribution detection problem and perform re- markably better than the state-of-the-art multi- label learning methods and emotion detection method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In general, emotion classification can be approached by two types of methods, lexicon-based or corpus- based. Lexicon-based approaches rely on emotion lexicons consisting of words and their correspond- ing emotion labels for detecting emotions from tex- t. For example, WordNetAffect ( <ref type="bibr" target="#b24">Strapparava and Valitutti, 2004</ref>) was constructed by extending Word- net, a lexical database of English terms, with infor- mation on affective terms. EmoSenticNet assigns six WordNetAffect emotion labels to SenticNet con- cepts ( <ref type="bibr" target="#b18">Poria et al., 2013)</ref>, which can be thought of as an expansion of WordNetAffect emotion label- s to a larger vocabulary. Many approaches were proposed based on emotion lexicons. For example, (Aman and Szpakowicz, 2007) classified emotional and non-emotional sentences using the constructed emotion lexicon. (Choudhury et al., 2012) employed a classifier to detect human affective states in social media. ( <ref type="bibr" target="#b26">Wang and Pal, 2015)</ref> proposed a model with several constraints based on an emotion lexicon for emotion classification.</p><p>Corpus-based methods aim to train supervised classifiers from annotated training data where each sentence or document is labelled with an emotion class. (Mishne and de <ref type="bibr" target="#b14">Rijke, 2006</ref>) constructed models to predict the levels of various moods ac- cording to the language used by bloggers at a giv-en time. <ref type="bibr" target="#b2">(Aman and Szpakowicz, 2007</ref>) described an emotion annotation task of identifying emotion category, emotion intensity and the words/phrases that indicate emotions in text. Emotion classifica- tion was conducted using trained support vector ma- chines. <ref type="bibr" target="#b0">(Agrawal and An, 2012)</ref> proposed an un- supervised context-based approach to detect emo- tions from text at the sentence level. They comput- ed an emotion vector for each potential affect bear- ing word based on the semantic relatedness between words and various emotion concepts. The scores are then tuned using the syntactic dependencies with- in the sentence structure. ( <ref type="bibr" target="#b3">Bao et al., 2009</ref>) pro- posed an emotion topic model by augmenting laten- t Dirichlet allocation with an intermediate emotion layer. ( <ref type="bibr" target="#b20">Quan et al., 2015)</ref> proposed a logistic regres- sion model for social emotion detection. Intermedi- ate hidden variables were also introduced to model the latent structure of input text corpora.</p><p>Our work is partly inspired by <ref type="bibr" target="#b20">(Quan et al., 2015</ref>). However, our proposed approach differs from <ref type="bibr" target="#b20">(Quan et al., 2015</ref>) in two aspects: 1) by introducing the emotion distribution learning framework, many dif- ferent criteria can be used to measure the distance between the true distribution and the predicted dis- tribution, such as squared X 2 , Euclidean, Jeffery's divergence apart from Kullback-Leibler divergence employed in logistic regression model. 2) the re- lations between basic emotions are captured based on the Plutchik's wheel of emotions theory to avoid the incorporation of any noisy information from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Emotion Distribution Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Setting</head><p>As have discussed in section 1, one sentence might contain one or more emotions, and each emotion has its own intensity. We use d y x to indicate the intensi- ty of emotion y for sentence x, where x ∈ X and y ∈ Y. The emotion intensity is normalized to make d y x ∈ [0, 1] and ∑ y d y x = 1 to constitute the emotion distribution.</p><p>Note that d y x denotes the proportion that y accounts for in a full emotion distribution of x. It is differ- ent from the probability of y being a correct emo- tion label for x. Probability distribution implies that only one emotion label is correct for each sentence, while emotion distribution allows multiple emotions in one sentence. The goal of EDL is to learn a map- ping from sentences X = R m to the distributions over a finite set of labels Y = {y 1 , y 2 , ...y c }. Each label represents one of the basic emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning</head><p>Given a training set P = {(x 1 , E 1 ), (x 2 , E 2 ), ..., (x n , E n )}, where x i ∈ X is a sentence and E i = {d</p><formula xml:id="formula_0">y 1 x i , d y 2 x i , ..., d y c</formula><p>x i } is the emotion distribution asso- ciated with x i . The goal of EDL is to learn a con- ditional probability mass function p(y|x) from P , where x ∈ X and y ∈ Y. Assuming that p(y|x) is a parametric model p(y|x; θ), where θ are mod- el parameters, many different criteria can be used to measure the distance between two distribution- s, such as Squared X 2 , Euclidean, Jeffery's diver- gence, Kullback-Leibler (K-L) divergence and so on. Here we use Divergence defined by</p><formula xml:id="formula_1">D J (Q a ||Q b ) = 2 ∑ j (Q j a − Q j b ) 2 (Q j a + Q j b ) 2</formula><p>, where Q j a and Q j b are the j-th element of the t- wo distributions Q a and Q b , respectively. Diver- gence is balanced, which makes</p><formula xml:id="formula_2">D J (Q a ||Q b ) equal to D J (Q b ||Q a ).</formula><p>The formula above calculates the sum of all the distances between emotion intensities in the same position.</p><p>Then the optimal model parameters θ * is deter- mined by</p><formula xml:id="formula_3">θ * = arg min θ    ∑ i D J (E i ||ˆE||ˆ ||ˆE i ) + ξ 1 n ∑ k,r |θ k,r | 1 + ξ 2 n ∑ u ∑ j,k ω jk ∥θ u,j − θ u,k ∥ 2 2    = arg min θ    2 ∑ i,j (d y j x i − p(y j |x i , θ)) 2 (d y j x i + p(y j |x i , θ)) 2 + ξ 1 n ∑ k,r |θ k,r | 1 + ξ 2 n ∑ u ∑ j,k ω jk ∥θ u,j − θ u,k ∥ 2 2   <label>(1)</label></formula><p>, where E i is the ground truth emotion distribution of the i-th sentence and thê E i is the predicted one by p(y|x i ; θ). The second term is a regularizer to make the predicted emotion distribution sparse, and the third term considers the relationship between d- ifferent emotions. As mentioned in section 1, some emotions often co-occur such as joy and love, and some rarely co-exist such as joy and anger. There- fore, the third term is employed to incorporate such prior knowledge. The weight ω jk models the rela- tionship between the j-th emotion and the k-th emo- tion in the distribution. In this paper, we capture the relationships between different emotions based on Plutchik's wheel of emotions <ref type="bibr" target="#b16">(Plutchik, 1980)</ref> which is produced in psychology view. Plutchik's wheel of emotions includes several typical emotions and its eight sectors indicate eight primary emotion dimensions arranged as four pairs of opposites. We re-produce a wheel of eight emotions' relationship- s according to Plutchik's theory, which is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. In the emotion wheel, emotions sat at opposite end have an opposite relationship, while emotion- s next to each other are more closely related. We quantify the relations between each pair of emotions based on the angle between them in wheel of emo- tions <ref type="bibr" target="#b17">(Plutchik, 2001</ref>). For example, emotion pairs with 180 degrees are opposite to each other, which are described by −1, while emotion pairs with 90 degrees are described by 0, meaning no relation- ship between them. Emotion pairs with 45 degrees have the relationship value of 0.5, while emotion pairs with 135 degrees have the relationship value of −0.5. <ref type="figure" target="#fig_2">Figure 2</ref> shows the gray-scale image of the pair-wise relationships of emotions presented in <ref type="figure" target="#fig_0">Fig- ure 1</ref>. In each cell, the darker the color is, the more similar the two emotions are.</p><p>As for p(y|x; θ), similar to (Geng, 2016), we as- sume it takes a maximum entropy model, i.e.,</p><formula xml:id="formula_4">p(y k |x i ; θ) = 1 Z i exp( ∑ r θ kr x r i )<label>(2)</label></formula><p>, where</p><formula xml:id="formula_5">Z i = ∑ k exp( ∑</formula><note type="other">r θ kr x r i ) is the normaliza- tion factor, x r i is the r-th feature of x i , and θ kr is an element in θ. Substituting Equation 2 into Equa- tion 1 yields the target function,</note><formula xml:id="formula_6">T (θ) = 2 ∑ i,j ( 1 − 4Z i d y j x i exp ( ∑ r θ jr x r i ) (Z i d y j x i + exp ( ∑ r θ jr x r i )) 2 ) + ξ 1 n ∑ k,r |θ k,r | 1 + ξ 2 n ∑ u ∑ j,k ω jk ∥θ u,j − θ u,k ∥ 2 2 .<label>(3)</label></formula><p>The </p><formula xml:id="formula_7">T ′ (θ (l+1) ) ≈ T ′ (θ (l) ) + ∇T ′ (θ (l+1) ) T ∆ + 1 2 ∆ T H(θ (l) )∆,<label>(4)</label></formula><p>where</p><formula xml:id="formula_8">∆ = θ (l+1) −θ (l) is the update step, ∇T ′ (θ (l) )</formula><p>and h(θ (l) ) are the gradient and Hessian matrix of</p><formula xml:id="formula_9">T ′ (θ (l) ) at θ (l)</formula><p>, respectively. The minimizer of E- quation 4 is</p><formula xml:id="formula_10">∆ l = −H −1 (θ (l) )∇T ′ (θ (l) ).<label>(5)</label></formula><p>The line search Newton method uses ∆ (l) as the search direction p (l) = ∆ (l) and updates model pa- rameters by</p><formula xml:id="formula_11">θ (l+1) = θ (l) + α (l) p (l) ,<label>(6)</label></formula><p>where the step length α (l) is obtained from a line search procedure to satisfy the strong Wolfe condi- tions ( <ref type="bibr" target="#b15">Nocedal and Wright, 2006</ref>):</p><formula xml:id="formula_12">T ′ (θ (l) +α (l) p (l) ) ≤ T ′ (θ (l) )+c 1 α (l) ∇T ′ (θ (l) ) T p (l) |∇T ′ (θ (l) + α (l) p (l) | ≤ c 2 |∇T ′ (θ (l) ) T p (l) |,</formula><note type="other">where 0 &lt; c 1 &lt; c 2 &lt; 1. The idea of BFGS is to avoid explicit calculation of H −1 (θ (l) ) by approxi- mating it with an iteratively updated matrix B, i.e.</note><formula xml:id="formula_13">B (L+1) = (I − ρ (l) s (l) (u (l) ) T ) × B (l) ×(I − ρ (l) u (l) (s (l) ) T ) +ρ (l) s (l) (s (l) ) T</formula><p>where As for the optimization of the target function T (θ), the computation of BFGS is mainly related to the first-order gradient of T ′ (θ), which can be achieved by</p><formula xml:id="formula_14">s (l) = θ (l+1) − θ (l) , u (l) = ∇T ′ (θ (l+1) ) − ∇T ′ (θ (l) ),</formula><formula xml:id="formula_15">ρ (l) = 1 s (l) u (l) .</formula><formula xml:id="formula_16">∂T (θ) ∂θ jr = 4d y j x i p ij (1 − p ij )(d y j x i − p ij ) (d y j x i + p ij ) 3 +ξ 1 ∑ k,r sgn(θ k,r ) + 1 n ξ 2 ∑ k ω jk (θ j − 2θ k ),<label>(7)</label></formula><p>where p ij = 1 Z i exp( ∑ r θ jr x r i ). Thus it performs more efficiently than the standard line search New- ton method.</p><p>In order to compare with the MLL methods, la- bels in the predicted distribution need to be divid- ed into two sets, i.e, the relevant and irrelevant set- s. For this purpose, an extra virtual label y 0 is added into the label set, i.e., the extended label set Y ′ = Y ∪ {y 0 }={y 0 , y 1 , y 2 ...y c }. Using the new ex- tended label set in the training process, the optimal parameter vector θ * is learned. As y 0 is the label that distinguishes the relevant and irrelevant emo- tions directly, it is initialized as the threshold used in MLL. Given a sentence x ′ , its emotion distribution is predicted by p(y|x ′ ; θ * ). The intensity value of y 0 splits the predicted distribution into two sets. The emotions with the intensity value higher than y 0 's are regarded as the relevant emotions, and the rest emotions are regarded as irrelevant ones. Therefore, EDL in fact implements the function of MLL with- out the need of setting the threshold manually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>We evaluate the proposed approach on the Ren- CECps corpus <ref type="bibr" target="#b19">(Quan and Ren, 2010)</ref>. It contains 35, 096 sentences selected from blogs in Chinese. Each sentence is annotated with 8 basic emotion- s, such as anger, anxiety, expect, hate, joy, love, sorrow and surprise, together with their emotion s- cores. Higher score represents higher emotion inten- sity. We use AS i (j) to represent the score of emo- tion j in sentence i. Given a sentence x i , the inten- sity of emotion j is calculated by d y j x i = 1. For each sentence, features are extracted using re- cursive auto-encoders (RAEs) <ref type="bibr" target="#b23">(Socher et al., 2011</ref>). RAEs are neural networks that represent meanings of fixed-size inputs in the reduced dimensional s- pace. For example, each word in a sentence is repre- sented using a vector w ∈ R d , and the RAE method reduces the entire sentence to a single vector of size R d . Sentences are sequences of words that can be represented by a binary tree structure. The words are the leaves of the tree and their combined grouping is used to get a notion of the meaning of the sentence.</p><formula xml:id="formula_17">x i = AS i (j) ∑ k AS i (k) .</formula><p>The internal nodes of the tree correspond to the com- bined meaning of the nodes underneath them. Each internal node is also represented in the same manner as individual words in the form of a vectorˆwvectorˆ vectorˆw ∈ R d . These internal nodes are the hidden representations of the neural network. In the RAE model, the vocab- ulary is stored in an embedding matrix V ∈ R d × D where D is the cardinality of the vocabulary. Typi- cally, each word w ∈ V is initialized independently following a Gaussian distribution w i <ref type="figure" target="#fig_2">∼ N (0, γ 2 )</ref>. In our experiment, we set the dimension of each sen- tence representation to 100.</p><p>We build a gray-scale image shown in <ref type="figure" target="#fig_3">Figure 3</ref> by computing the correlation coefficient of the emo- tions from the Ren-CECps corpus. It can be ob- served that <ref type="figure" target="#fig_3">Figure 3</ref> is quite similar to <ref type="figure" target="#fig_2">Figure 2</ref>, which shows that our proposed way in capturing the relations between emotions is inline with what have been revealed by the emotion annotations in the Ren-CECps corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Results</head><p>As the output of EDL is a distribution, a natural choice of criteria is the averaged similarity or dis- tance between the actual emotion distribution and the predicted distribution. There are many metric- s that can be applied to measure the distance be- tween two distributions. In this paper six of them are used to evaluate the results of EDL, i.e, Euclidean, Sϕrensen, Squared X 2 , KL divergence, Intersection and Fidelity, as suggested in <ref type="bibr" target="#b8">(Geng and Ji, 2013)</ref>. </p><formula xml:id="formula_18">Name Formula Distance Euclidean Euclidean(P, Q) = √ ∑ c j=1 (P j − Q j ) 2 Sϕrensen Sϕrensen(P, Q) = ∑ c j=1 |Pj −Qj | ∑ c j=1 (Pj +Qj ) Squared X 2 SquaredX 2 (P, Q) = ∑ c j=1 (Pj −Qj ) 2 Pj +Qj Kullback-Leibler (KL) K-L(P, Q) = ∑ c j=1 P j ln Pj Qj Similarity Intersection Intersection(P, Q) = ∑ c j=1 min(P j , Q j ) Fidelity F idelity(P, Q) = ∑ c j=1 √ P j Q j</formula><formula xml:id="formula_19">∑ P i=1 |h(x i )△Y i | One error one-error(f) = 1 P ∑ P i=1 [arg max y∈Y f(x i , y)] / ∈ Y i Coverage Coverage(f) = 1 P ∑ P i=1 max y∈Yi rank f (x i , y) − 1 Ranking Loss rloss(f) = 1 P ∑ P i=1 1 |Yi|| ¯ Yi| · |R|, W here R = (y ′ , y ′′ )|f(x i , y ′ ) ≤ f(x i , y ′′ ), (y ′ , y ′′ ) ∈ Y i × ¯ Y i Average Precision Average(f) = 1 P ∑ P i=1 1 |Yi| ∑ y∈Yi |Pi| rankf (xi,y)</formula><p>, where The formulae of the six criteria are summarized in <ref type="table" target="#tab_5">Table 4</ref>.2. Note that the virtual label y 0 is removed before evaluation.</p><formula xml:id="formula_20">P i = y ′ |rank f (x i , y ′ ) ≤ rank f (x i , y), (y) ′ ∈ Y i</formula><p>As EDL can output both the relevant emotions and their respective emotion intensities, MLL can be seen as a special case of EDL that it only outputs emotion labels but not their intensities. Several e- valuation criteria typically used in MLL can also be used to measure EDL's ability of distinguishing rel- evant emotions from irrelevant ones, including ham- ming loss, one error, coverage, ranking loss, and av- erage precision as suggested by <ref type="bibr" target="#b28">(Zhang and Zhou, 2014)</ref>, which are summarized in <ref type="table" target="#tab_5">Table 4</ref>.2. Ham- ming loss evaluates how many times an emotion la- bel is misclassified. One-error evaluates the fraction of sentences whose top-ranked emotion is not in the relevant emotion set. Coverage evaluates how many steps are needed to move down the ranked emotion list so as to cover all the relevant emotions of the example. Ranking loss evaluates the fraction of re- versely ordered emotion pairs. Average precision evaluates the average fraction of the relevant emo- tions ranked higher than a particular emotion y ∈ Y.</p><p>For each algorithm, ten-fold cross validation is conducted. EDL is first compared with four existing Label Distribution Learning (LDL) methods (Geng,</p><note type="other">Algorithm Evaluation Criterion Euclidean(</note><formula xml:id="formula_21">↓) Sϕrensen(↓) Squared X 2 (↓) K-L(↓) Intersection(↑) Fidelity(↑) EDL 0.2361±0.0057 0.2346±0.0061 0.1780±0.0037 0.2067±0.0046 0.7654±0.0046 0.9523±0.0019</formula><p>AA-KNN (Geng, 2016) 0.2948±0.0101• 0.2941±0.0123• 0.2688±0.0102• 0.3163±0.0087• 0.7059±0.0078• 0.9258±0.0090• PT-Bayes <ref type="bibr" target="#b9">(Geng, 2016)</ref> 0.3295±0.0125• 0.3288±0.0158• 0.2826±0.0115• 0.3263±0.0238• 0.6711±0.0241• 0.9238±0.0060• PT-SVM <ref type="bibr" target="#b9">(Geng, 2016)</ref> 0.3614±0.0869• 0.3625±0.0145• 0.3415±0.0089• 0.4073±0.0209• 0.6375±0.0099• 0.9069±0.0073• AA-BP <ref type="bibr" target="#b9">(Geng, 2016)</ref> 0     <ref type="table" target="#tab_5">Table 4</ref>.2. For all the mea- sures, "↓" indicates "the smaller the better", while "↑" indicates "the larger the better". The best perfor- mance on each measure is highlighted by boldface. The two-tailed t-tests with 5% significance level are performed to see whether the differences between EDL and the baselines are statistically significan- t. We use • to indicate significance difference. As the state-of-the-art emotion detection method pro- posed in ( <ref type="bibr" target="#b26">Wang and Pal, 2015)</ref> can output the e- motion distributions based on a dimensional reduc- tion method, we present its experimental results on the Ren-CECps corpus in the last row of <ref type="table" target="#tab_5">Table 4</ref>.2. It can be observed that EDL performs significant- ly better than all the baseline LDL methods and the state-of-the-art emotion detection approach on al- l criteria considered here.</p><p>Since EDL can be seen as an extension of MLL, EDL is compared with 7 widely used MLL methods using the virtual label Maximum a posteriori (MAP) principle is used to determine which emotion set is related to the giv- en sentence. CC (classifier chains method) over- comes the limitations of BR and performs better but requires more computations. ECC (ensemble clas- sifier chains) applies classifier chains in an ensem- ble framework and obtains high predictive perfor- mances. MLLOC (Multi-label LOcal Correlation) tries to exploit emotion correlations in the expres- sion data locally. The global discrimination fitting and local correlation sensitivity are incorporated in- to a unified framework, and solution for the opti- mization are developed. Rank-SVM provides a way of controlling the complexity of the overall learning system while having a small empirical error. The architectures of Rank-SVM is based on linear mod- els of Support Vector Machines (SVM) <ref type="bibr" target="#b4">(Boser et al., 1992)</ref>. LIFT constructs features specific to each e- motion by conducting clustering analysis on its pos- itive or negative instances, and then performs train- ing and testing by querying the clustering result- s (Zhang, 2011). BP-MLL is derived from the fa- mous backpropagation algorithm through employ- ing a novel error function capturing the character- istics of multi-label learning, i.e., the emotions be- longing to a sentence should be ranked higher than those not belonging to that sentence ( <ref type="bibr" target="#b27">Zhang and Zhou, 2006</ref>).</p><p>The virtual label y 0 used in EDL and the thresh- old value used in MLL are all set to 2.5. Besides, the ε, ξ 1 and ξ 2 are set as 0.25, 0.0001, 0.1 respectively. For the MLL methods, the value of k is set to 8 in ML-KNN, ratio is 0.02 and µ is 2 in ML-RBF. Lin- ear kernel is used in LIFT. Rank-SVM uses the RBF kernel with the width σ equals to 1. The evaluation results of the proposed approach in comparison to all MLL baselines are presented in <ref type="table" target="#tab_5">Table 4</ref>.2. EDL performs best on all evaluation measures. It verifies the advantage of EDL owing to the consideration of varying intensity of the basic emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Further Analysis</head><p>To fully understand the emotion detection results, we use word cloud <ref type="bibr" target="#b11">(Harris, 2011)</ref> to output the top 30 frequent words in the testing data for the emotion love and anxiety based on the annotation as shown in the left part of <ref type="figure">Figure 4</ref>. We also output the top 30 frequent words for the two emotions based on the prediction generated by EDL as shown in <ref type="figure">Figure 4</ref> 's right part. It can be observed that most words based on prediction indeed express their associated emotions. For example, word "like" delivers the e- motion of love (right part of <ref type="figure">Figure 4</ref>(a)) and word "problem" tells anxiety (right part of <ref type="figure">Figure 4(b)</ref>). Moreover, the annotation and the prediction share 20 out of the top 30 most frequent words for the emo- tion love such as "friend", "joy", "happiness", etc as shown in the middle of <ref type="figure">Figure 4</ref>(a) and 19 out of 30 for the emotion of anxiety (the middle of <ref type="figure">Figure 4(b)</ref>. It demonstrates that EDL can learn emotions from text precisely.</p><p>To investigate the emotion distributions generated by EDL, a sentence from the Ren-CECps corpus to- gether with the emotion distribution output by EDL is illustrated in <ref type="figure" target="#fig_7">Figure 5</ref>. The ground truth emotion distribution is obtained by normalizing the scores and the virtual label y 0 . As can be seen, the curve of the predicted emotion distribution is very similar as the ground truth distribution, which demonstrates that EDL can learn the varying intensities of all the basic emotions well.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper, we have proposed a novel approach based on EDL to identify multiple emotions with their intensities from texts. Moreover, the relations between basic emotions is incorporated in the learn- ing framework as constraints to improve the learning accuracy. Experimental results show that the pro- posed approach can effectively deal with the emo- tion distribution detection problem and perform re- markably better than the state-of-the-art multi-label learning methods and the emotion detection method. In future work, we will investigate the efficiency of the proposed approach in other datasets and explore other methods in capturing the inter-relations of e- motions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Plutchik's wheel of emotions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>minimization of the function T (θ) can be effec- tively solved by the limited-memory quasi-Newton method (L-BFGS). The basic idea of L-BFGS is to avoid explicit calculation of the inverse Hessian ma- trix used in the Newton method. L-BFGS approxi- mates the inverse Hessian matrix with an iteratively updated matrix instead of actually storing the ful- l matrix. Here we follow the idea of an effective quasi-Newton method BFGS. Consider the second- order Taylor series of T ′ (θ) = −T (θ) at the current estimate of the parameter vector θ (l) :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Gray-scale image of the pair-wise relationships of emotions shown in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Gray-scale image of the pair-wise relations of the emotions in the Ren-CECps corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>2016), i.e., PT-Bayes, PT-SVM, AA-KNN, AA-BP. k in AA-KNN is set to 8. Linear kernel is used in PT-SVM. The number of hidden-layer neurons for AA-BP is set to 60. The evaluation results of our proposed approach in comparison to the LDL base- lines are presented in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>y 0 , namely ML-KNN (Zhang and Zhou, 2014), ECC (Read et al., 2011), MLLOC (Huang and Zhou, 2012), LIFT (Zhang, 2011), ML- RBF (Zhang, 2009), Rank-SVM (Zhang and Zhou, 2014), BP-MLL (Zhang and Zhou, 2006). Among the compared algorithms, ML-kNN is derived from the traditional k-nearest neighbor (kNN) algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Relevant emotions Irrelevant emotions @@@@@@@@@@@@@@@@@ Dreams die one by one, but life should go on and we have to eat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: A sentence with the emotion distribution predicted by EDL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>An example of a sentence containing emotions select-

ed from SemEval 2007 Task#14, Affective Text, where each of 

the six emotions are indicated using a score of [0, 100]. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Evaluation criteria for the Label Distribution Learning 

(LDL) methods. 

Name 
Formula 

Hamming Loss 
hloss(h) = 1 

P 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Evaluation criteria for the MLL methods.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Experimental results in comparison with the LDL methods and the emotion detection approach. 

Algorithm 
Evaluation Criterion 
Average Precision(↑) 
Coverage(↓) 
Hamming Loss(↓) 
One Error(↓) 
Ranking Loss(↓) 

EDL 
0.6419±0.0235 
2.1412±0.0235 
0.1772±0.0568 
0.5239±0.0945 
0.2513±0.0560 

ML-KNN (Zhang and Zhou, 2014) 
0.5917±0.0742• 
2.448±0.0981• 
0.2459±0.0781• 0.5339±0.0954• 0.2908±0.0431• 
LIFT (Zhang, 2011) 
0.5979±0.0891• 
2.4267±0.0492• 0.1779±0.0597• 0.5131±0.0666• 0.2854±0.0427• 
Rank-SVM (Zhang and Zhou, 2014) 
0.5738±0.0892• 
2.5861±0.0777• 0.2485±0.0458• 0.5603±0.0921• 0.3055±0.0579• 
MLLOC (Huang and Zhou, 2012) 
0.4135±0.0568• 
3.6994±0.0764• 0.1850±0.0659• 0.6971±0.0924• 0.4742±0.0734• 
BP-MLL (Zhang and Zhou, 2006) 
0.4791±0.0999• 
3.3773±0.0681• 0.2108±0.0986• 0.6316±0.0988• 0.4293±0.0956• 
ECC (Read et al., 2011) 
0.5121±0.0892• 
2.7767±0.0876• 0.1812±0.0945• 0.6969±0.0598• 0.3281±0.0659• 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc>Experimental results in comparison with the MLL methods.</figDesc><table></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised emotion detection from text using semantic and syntactic relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameeta</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aijun</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012</title>
		<meeting>the 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology</title>
		<imprint>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying expressions of emotion in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saima</forename><surname>Aman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">4629</biblScope>
			<biblScope unit="page" from="196" to="205" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Joint emotion-topic modeling for social affective text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingyi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth IEEE International Conference on Data Mining</title>
		<meeting>the Ninth IEEE International Conference on Data Mining</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="699" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Annual Workshop on Computational Learning Theory</title>
		<meeting>the Fifth Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Affect detection: An interdisciplinary review of models, methods, and their applications. Affective Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>D&amp;apos;mello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="18" to="37" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Happy, nervous or surprised? classification of human affective states in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Munmun De Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Counts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the Sixth International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="435" to="438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An argument for basic emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogition and emotion</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="169" to="200" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongzi</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th IEEE International Conference on Data Mining Workshops</title>
		<meeting>the 13th IEEE International Conference on Data Mining Workshops</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="377" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1734" to="1748" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Emotion detection in email customer care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narendra</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mazin</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><forename type="middle">Di</forename><surname>Fabbrizio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="489" to="505" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Word clouds considered harmful</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Nieman Journalism Lab</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-label learning by exploiting label correlations locally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 26th AAAI Conference on Artificial Intelligence<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="949" to="955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09</title>
		<meeting>the 18th ACM Conference on Information and Knowledge Management, CIKM &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="375" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Capturing global mood levels using blog posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maarten De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Symposium on Computational Approaches to Analysing Weblogs (AAAI-CAAW)</title>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Numerical optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A general psychoevolutionary theory of emotion. Theories of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Plutchik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An argument for basic emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Plutchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Scientist</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="344" to="350" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Enhanced senticnet with affective labels for concept-based opinion mining. Intelligent Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentence emotion analysis and recognition based on emotion words using ren-cecps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqin</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuji</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent discriminative models for social emotion detection with emotional dependency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Wenyin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Classifier chains for multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Read</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="359" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Core affect and the psychological construction of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="172" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Semisupervised recursive autoencoders for predicting sentiment distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Valitutti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wordnet-affect: an affective extension of wordnet</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Language Resources and Evaluation</title>
		<meeting>the 4th International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<biblScope unit="page" from="1083" to="1086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detecting emotions in social media: A constrained optimization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="996" to="1002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multilabel neural networks with applications to functional genomics and text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A review on multi-label learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1819" to="1837" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ml-rbf: Rbf neural networks for multi-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Lift: Multi-label learning with label-specific features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Ling</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Joint Conference on Artificial Intelligence</title>
		<meeting>the 22nd International Joint Conference on Artificial Intelligence<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1609" to="1614" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
