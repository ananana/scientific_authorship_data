<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:14+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning To Split and Rephrase From Wikipedia Edit History</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Alex</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning To Split and Rephrase From Wikipedia Edit History</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="732" to="737"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>732</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Split and rephrase is the task of breaking down a sentence into shorter ones that together convey the same meaning. We extract a rich new dataset for this task by mining Wikipedia&apos;s edit history: WikiSplit contains one million naturally occurring sentence rewrites, providing sixty times more distinct split examples and a ninety times larger vocabulary than the WebSplit corpus introduced by Narayan et al. (2017) as a benchmark for this task. Incorporating WikiSplit as training data produces a model with qualitatively better predictions that score 32 BLEU points above the prior best result on the WebSplit benchmark.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A complex sentence can typically be rewritten into multiple simpler ones that together retain the same meaning. Performing this split-and-rephrase task is one of the main operations in text sim- plification, alongside paraphrasing and dropping less salient content <ref type="bibr" target="#b12">(Siddharthan, 2006;</ref><ref type="bibr" target="#b22">Zhu et al., 2010;</ref><ref type="bibr">Woodsend and Lapata, 2011, i.a.)</ref>. The area of automatic text simplification has received a lot of attention <ref type="bibr" target="#b13">(Siddharthan, 2014;</ref><ref type="bibr" target="#b11">Shardlow, 2014</ref>), yet still holds many open challenges ( <ref type="bibr" target="#b17">Xu et al., 2015)</ref>. Splitting sentences in this way could also benefit systems where predictive quality degrades with sentence length, as observed in, e.g., rela- tion extraction ( <ref type="bibr" target="#b21">Zhang et al., 2017</ref>) and translation ( <ref type="bibr" target="#b7">Koehn and Knowles, 2017)</ref>. And the schema-free nature of the task may allow for future supervision in the form of crowd-sourced rather than expen- sive expert annotation ( <ref type="bibr" target="#b5">He et al., 2015)</ref>.  introduce the WebSplit corpus for the split-and-rephrase task and report results for several models on it. <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref> improve WebSplit by reducing over- lap in the data splits, and demonstrate that neural * Both authors contributed equally.</p><p>A classic leaf symptom is water-soaked lesions be- tween the veins which appear as angular leaf-spots where the lesion edge and vein meet.</p><p>A classic leaf symptom is the appearance of angular, water-soaked lesions between the veins. The angular appearance results where the lesion edge and vein meet.</p><p>Figure 1: A split-and-rephrase example extracted from a Wikipedia edit, where the top sentence had been edited into two new sentences by removing some words (yellow) and adding others (blue).</p><p>encoder-decoder models ( <ref type="bibr" target="#b1">Bahdanau et al., 2014</ref>) perform poorly, even when enhanced with a copy mechanism ( <ref type="bibr" target="#b4">Gu et al., 2016;</ref><ref type="bibr" target="#b10">See et al., 2017)</ref>.</p><p>One limitation of the WebSplit examples them- selves is that they contain fairly unnatural linguis- tic expression using a small vocabulary. We in- troduce new training data mined from Wikipedia edit histories that have some noise, but which have a rich and varied vocabulary over naturally ex- pressed sentences and their extracted splits. <ref type="figure">Fig- ure 1</ref> gives an example of how a Wikipedia editor rewrote a single sentence into two simpler ones. We create WikiSplit, a set of one million such ex- amples mined from English Wikipedia, and show that models trained with this resource produce dra- matically better output for split and rephrase.</p><p>Our primary contributions are:</p><p>• A scalable, language agnostic method for extracting split-and-rephrase rewrites from Wikipedia edits.</p><p>• Public release of the English WikiSplit dataset, containing one million rewrites:</p><p>http://goo.gl/language/wiki-split</p><p>• By incorporating WikiSplit into training, we more than double (30.5 to 62.4) the BLEU score obtained on WebSplit by <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correct</head><p>Street Rod is the first in a series of two games released for the PC and Commodore 64 in 1989. Street Rod is the first in a series of two games. It was released for the PC and Commodore 64 in 1989.</p><p>He played all 60 minutes in the game and rushed for 114 yards, more yardage than all the Four Horsemen combined.</p><p>He played all 60 minutes in the game. He rushed for 114 yards, more yardage than all the Four Horsemen combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unsupported</head><p>When the police see Torco's injuries, they send Ace to a clinic to be euthanized, but he escapes and the clinic worker covers up his incompetence.</p><p>When the police see Torco's injuries to his neck, they believe it is a result of Ace biting him. They send Ace to a clinic to be euthanized, but he escapes and the clinic worker covers up his incompetence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Missing</head><p>The avenue was extended to Gyldenløvesgade by Copenhagen Municipality in 1927-28 and its name was changed to Rosenørns Allé after Ernst Emil Rosenørn (1810-1894) .</p><p>The avenue was extended to Gyldenløvesgade by Copenhagen Municipality in 1927-28. The street was named after Ernst Emil Rosenørn (1810-1894) . <ref type="table">Table 1</ref>: Examples of correct and noisy sentence splits extracted from Wikipedia edits. Noise from unsupported or missing statements is visualized with the same coloring as in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The WikiSplit Corpus</head><p>WebSplit provides a basis for measuring progress on splitting and rephrasing sentences. However, its small size, inherent repetitiveness, and syn- thetic nature limit its broader applicability. In par- ticular, we see it as a viable benchmark for eval- uating models, but not for training them. To that end, we introduce the WikiSplit corpus and detail its construction next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mining Wikipedia Edits</head><p>Wikipedia maintains snapshots of entire docu- ments at different timestamps, which makes it possible to reconstruct edit histories for docu- ments. This has been exploited for many NLP tasks, including sentence compression <ref type="bibr" target="#b18">(Yamangil and Nelken, 2008</ref>), text simplification ( <ref type="bibr" target="#b20">Yatskar et al., 2010;</ref><ref type="bibr" target="#b16">Woodsend and Lapata, 2011;</ref><ref type="bibr" target="#b14">Tonelli et al., 2016</ref>) and modeling semantic edit intentions ( <ref type="bibr" target="#b19">Yang et al., 2017)</ref>. To construct the WikiSplit corpus, we identify edits that involve sentences being split. A list of sentences for each snapshot is obtained by strip- ping HTML tags and Wikipedia markup and run- ning a sentence break detector <ref type="bibr" target="#b3">(Gillick, 2009)</ref>. Temporally adjacent snapshots of a Wikipedia page are then compared to check for sentences that have undergone a split like that shown in <ref type="figure">Figure 1</ref>. We search for splits in both temporal directions.</p><p>Given all candidate examples extracted this way, we use a high-precision heuristic to retain only high quality splits. To extract a full sentence C and its candidate split into S = (S 1 , S 2 ), we  require that C and S 1 have the same trigram pre- fix, C and S 2 have the same trigram suffix, and S 1 and S 2 have different trigram suffixes. To filter out misaligned pairs, we use BLEU scores <ref type="bibr" target="#b9">(Papineni et al., 2002</ref>) to ensure similarity between the original and the split versions. Specifically, we discard pairs where BLEU(C, S 1 ) or BLEU(C, S 2 ) is less than δ (an em- pirically chosen threshold). If multiple candi- dates remain for a given sentence C, we retain arg max S (BLEU(C, S 1 ) + BLEU(C, S 2 )). <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Corpus Statistics and Quality</head><p>Our extraction heuristic is imperfect, so we man- ually assess corpus quality using the same catego- rization schema proposed by <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref>; see <ref type="table">Table 1</ref> for examples of cor- rect, unsupported and missing sentences in splits extracted from Wikipedia. We do this for 100 randomly selected examples using three different  <ref type="table">Table 3</ref>: Training corpus statistics in terms of com- plex sentences (C), simple sentences (S =∪ i S i ) and to- kens (t, appearing across unique complex sentences). WikiSplit provides much greater diversity and scale.</p><p>thresholds of δ. As shown in <ref type="table" target="#tab_1">Table 2</ref>, δ=0.2 pro- vides the best trade-off between quality and size. Out of the 100 complex sentences in the sam- ple, only 4 contained information that was not completely covered by the simple sentences. In our corpus, every complex sentence is split into two simpler sentences, so the sample contains 200 simple sentences. Out of these we found 168 (84%) to be correct, while 35 (18%) contained un- supported facts. Thus, for the overall sample of 100 split-and-rephrase examples, 68% are perfect while 32% contain some noise (either unsupported facts or missing information). We stress that our main goal is to use data extracted this way as train- ing data and accept that its use for evaluation is an imperfect signal with some inherent noise and bias (by construction).</p><p>After extraction and filtering, we obtain over one million examples of sentence splits from around 18 million English documents. We ran- domly reserved 5000 examples each for tun- ing, validation and testing, producing 989,944 unique complex training sentences, compared to the 16,938 of WebSplit (cf. <ref type="table">Table 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Comparison to WebSplit</head><p>Narayan et al. (2017) derived the WebSplit corpus by matching up sentences in the WebNLG cor- pus (  according to partitions of their underlying meaning representations (RDF triples). The WebNLG corpus itself was created by having crowd workers write sentential realiza- tions of one or more RDF triples. The resulting language is often unnatural, for example, "Akeem Dent once played for the Houston Texans team which is based in Houston in Texas." <ref type="bibr">2</ref> Repetition arises because the same sentence fragment may appear in many different examples. This is to be expected given that WebSplit's small vocabulary of 7k words must account for the 344k tokens that make up the distinct complex sen- tences themselves. <ref type="bibr">3</ref> This is compounded in that each sentence con- tains a named entity by construction. In contrast, our large new WikiSplit dataset offers more natu- ral and diverse text (see examples in <ref type="table">Table 1</ref>), hav- ing a vocabulary of 633k items covering the 33m tokens in its distinct complex sentences.</p><p>The task represented by our WikiSplit dataset is a priori both harder and easier than that of the WebSplit dataset -harder because of the greater diversity and sparsity, but potentially easier due to the uniform use of a single split.</p><p>Of the two datasets, WebSplit is better suited for evaluation: its construction method guaran- tees cleaner data than is achieved by our extrac- tion heuristic, and it provides multiple reference decompositions for each complex sentence, which tends to improve the correlation of automatic met- rics with human judgment in related text genera- tion tasks ( <ref type="bibr" target="#b15">Toutanova et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In order to understand how WikiSplit can inform the split-and-rephrase task, we vary the composi- tion of the training set when training a fixed model architecture. We compare three training config- urations: WEBSPLIT only, WIKISPLIT only, and BOTH, which is simply their concatenation.</p><p>Text-to-text training instances are defined as all the unique pairs of (C, S), where C is a complex sentence and S is its simplification into multiple simple sentences ( <ref type="bibr" target="#b0">Aharoni and Goldberg, 2018)</ref>. For training, we delimit the simple sentences with a special symbol. We depart from the prior work by only using a subset of the WebSplit training set: we take a fixed sub-sample such that each distinct C is paired with a single S, randomly selected from the multiple possibili- ties in the dataset. This scheme produced superior performance in preliminary experiments.</p><p>As a quality measure, we report multi-reference corpus-level BLEU 4 ( <ref type="bibr" target="#b9">Papineni et al., 2002</ref>), but ↓train/eval→ WebSplit 1.  include sentence-level BLEU (sBLEU) for direct comparison to past work. <ref type="bibr">5</ref> We also report length- based statistics to quantify splitting. We use the same sequence-to-sequence archi- tecture that produced the top result for Aharoni and Goldberg (2018), "Copy512", which is a one- layer, bi-directional LSTM (cell size 512) with attention ( <ref type="bibr" target="#b1">Bahdanau et al., 2014</ref>) and a copying mechanism ( <ref type="bibr" target="#b10">See et al., 2017</ref>) that dynamically interpolates the standard word distribution with a distribution over the words in the input sen- tence. Training details are as described in the Ap- pendix of <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref> using the OpenNMT-py framework ( <ref type="bibr" target="#b6">Klein et al., 2017)</ref>. <ref type="bibr">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Results</head><p>We compare to the SOURCE baseline, which is the previously reported method of taking the un- modified input sentence as prediction, and we add SPLITHALF, the natural baseline of deterministi- cally splitting a complex sentence into two equal- length token sequences and appending a period to the first one. <ref type="table" target="#tab_4">Table 4</ref> compares our three training configu- rations on the validation sets of both WebSplit and WikiSplit. The WEBSPLIT model scores 35.3 BLEU on the WebSplit validation set but fails to generalize beyond its narrow domain, as evidenced by reaching only 4.2 BLEU on the WikiSplit validation set.</p><p>The example predictions in <ref type="table" target="#tab_7">Table 7</ref> illustrate how this model tends to drop content ("Alfred Warden", "mouth", "Hamburg"), hallucinate com- mon elements from its training set ("food", "ingre- dient", "publisher") and generally fails to produce coherent sentences.  <ref type="table">Table 5</ref>: Results on the WebSplit v1.0 test set when varying the training data while holding model ar- chitecture fixed: corpus-level BLEU, sentence-level BLEU (to match past work), simple sentences per com- plex sentence, and tokens per simple sentence (micro- average). AG18 is the previous best model by <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref>, which used the full WebSplit training set, whereas we downsampled it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BLEU sBLEU #S/C #T/S</head><p>In contrast, the WIKISPLIT model achieves 59.4 BLEU on the WebSplit validation set, without observing any in-domain data. It also outperforms the two deterministic baselines on both validation sets by a non-trivial BLEU margin. This indi- cates that the WikiSplit training data enable better generalization than when using WebSplit by itself. Reintroducing the downsampled, in-domain train- ing data (BOTH) further improves performance on the WebSplit evaluation.</p><p>These gains in BLEU from using WikiSplit carry over to the blind manual evaluation we per- formed on a random sample of model predictions on the WebSplit validation set. As shown in Ta- ble 6, the BOTH model produced the most accurate output (95% correct simple sentences), with the lowest incidence of missed or unsupported state- ments. Our manual evaluation includes the cor- responding outputs from Aharoni and Goldberg (2018) (AG18), which were 22% accurate.</p><p>The examples in <ref type="table" target="#tab_7">Table 7</ref> demonstrate that the WIKISPLIT and BOTH models produce much more coherent output which faithfully rephrases the input. In Example 1, the combined model (BOTH) produces three fluent sentences, overcom- ing the strong bias toward two-sentence output in- herent in the majority of its training examples.</p><p>We relate our approach to prior work on Web- Split v1.0 by reporting scores on its test set in Ta- ble 5. Our best performance in BLEU is again obtained by combining the proposed WikiSplit dataset with the downsampled WebSplit, yielding a 32 point improvement over the prior best result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training</head><p>Unsupported <ref type="table" target="#tab_1">Missing Repeated  Correct  AG18  82  45  12  26/119 (22%)  WEBSPLIT  58  47  13  32/100 (32%)  WIKISPLIT  8  5  0  91/100 (91%)  BOTH  4  4  0</ref> 95/100 (95%)   <ref type="bibr" target="#b0">Aharoni and Goldberg (2018)</ref>, while the other outputs are from our models trained on the corresponding data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Outlook</head><p>Our results demonstrate a large, positive impact on the split-and-rephrase task when training on large, diverse data that contains some noise. This sug- gests that future improvements may come from finding other such sources of data as much as from modeling. The new WikiSplit dataset is intended as training data, but for further progress on the split-and-rephrase task, we ideally need evaluation data also derived from naturally occurring sen- tences, and an evaluation metric that is more sen- sitive to the particularities of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgments</head><p>Thanks go to Kristina Toutanova and the anony- mous reviewers for helpful feedback on an earlier draft, and to Roee Aharoni for supplying his sys- tem's outputs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Quality vs corpus size trade-off when setting 
the similarity threshold. The counts are for a random 
sample of 100 split-and-rephrase examples extracted 
using our method (i.e., 200 simple sentences). Keys: 
Unsupported; Missing 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Corpus-level BLEU scores on the validation 
sets for the same model architecture trained on different 
data. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Manual evaluation results, as counts over the simple sentences predicted by each model for a random 
sample of 50 inputs from WebSplit 1.0 validation set. 

Example 1 from WebSplit validation set 

Input 
Alan Bean , born in Wheeler , Texas , was a crew member of Apollo 12 where Alfred 
Worden served as the backup pilot . 
AG18 
Alan Bean is a member of the crew of Apollo 12 which was operated by backup 
pilot . Alan Shepard was born in Texas . 
WEBSPLIT Alan Bean served as a crew member of Apollo 12 . Alan Bean was born in Wheeler . 
WIKISPLIT Alan Bean , born in Wheeler , Texas . He was a crew member of Apollo 12 where 
Alfred Worden served as the backup pilot . 
BOTH 
Alan Bean was born in Wheeler , Texas . Alan Bean was a crew member of 
Apollo 12 . Alfred Worden served as the backup pilot . 

Example 2 from WikiSplit validation set 

Input 
He is a short , dark grayish -green monster with a beak -like mouth and a cap 
made out of the upper part of a creature 's skull . 
WEBSPLIT He is a food found in grayish . grayish monster is an ingredient in grayish . 
WIKISPLIT He is a short , dark grayish -green monster with a beak -like mouth . A cap made 
out of the upper part of a creature 's skull . 
BOTH 
He is a short , dark grayish -green monster with a beak -like mouth . His cap is 
made out of the upper part of a creature 's skull . 

Example 3 from WikiSplit validation set 

Input 
Der beglückte Florindo is an opera composed by Handel in Hamburg in 1708 as 
part of a double opera , the other part being Die verwandelte Daphne . 
WEBSPLIT Handel opera is the publisher of the opera opera . Handel is the capital of 1708 . 
WIKISPLIT Der beglückte Florindo is an opera composed by Handel in Hamburg in 1708 . It 
was part of a double opera , the other part being Die verwandelte Daphne . 
BOTH 
Der beglückte Florindo is an opera composed by Handel in Hamburg in 1708 as part 
of a double opera . The other part being Die verwandelte Daphne . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Example model predictions for items from each validation set. AG18 gives the output of the Copy512-
model of </table></figure>

			<note place="foot" n="1"> We attempted to mitigate other noise inherent in Wikipedia by removing items that 1) repeated a token more than three times in a row; 2) contained a token longer than 25 characters; 3) were suggestive of profane vandalism.</note>

			<note place="foot" n="2"> Given RDF triple: {(H Txns, city, Texas), (Akeem Dent, formerTeam, H Txns), (H Txns, city, Houston)}.</note>

			<note place="foot" n="3"> We use WebSplit v1.0 throughout, which is the scaledup re-release by Narayan et al. (2017) at http://github. com/shashiongithub/Split-and-Rephrase, commit a9a288c. Preliminary experiments showed the same trends on the smaller v0.1 corpus, as resplit by Aharoni and Goldberg (2018). 4 Using NLTK v3.2.2, with case sensitive scoring.</note>

			<note place="foot" n="5"> Past work on WebSplit (Narayan et al., 2017; Aharoni and Goldberg, 2018) reported macro-averaged sentence-level BLEU, calculated without smoothing precision values of zero. We found this ill-defined case occurred often for lowquality output. 6 github.com/OpenNMT/OpenNMT-py, 0ecec8b</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Split and Rephrase: Better Evaluation and a Stronger Baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roee</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Creating Training Corpora for NLG Micro-Planners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sentence Boundary Detection and the Problem with the U.S</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Incorporating Copying Mechanism in Sequence-to-Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Question-Answer Driven Semantic Role Labeling: Using Natural Language to Annotate Natural Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">OpenNMT: Open-Source Toolkit for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>System Demonstrations</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Six Challenges for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the First Workshop on Neural Machine Translation</title>
		<meeting>of the First Workshop on Neural Machine Translation</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Split and Rephrase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bleu: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Get To The Point: Summarization with Pointer-Generator Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Survey of Automated Text Simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Shardlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="70" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Syntactic Simplification and Text Cohesion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="109" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey of research on text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="259" to="298" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SIMPITIKI: a Simplification corpus for Italian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Tonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><surname>Palmero Aprosio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Saltori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CLiC-it</title>
		<meeting>of CLiC-it</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Dataset and Evaluation Metrics for Abstractive Compression of Sentences and Short Paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><forename type="middle">M</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saleema</forename><surname>Amershi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Problems in Current Text Simplification Research: New Data Can Help</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="283" to="297" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining Wikipedia Revision Histories for Improving Sentence Compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elif</forename><surname>Yamangil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rani</forename><surname>Nelken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identifying Semantic Edit Intentions from Revisions in Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Halfaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Kraut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescumizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Positionaware Attention and Supervised Data Improve Slot Filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Monolingual Tree-based Translation Model for Sentence Simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhemin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delphine</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Coling</title>
		<meeting>of Coling</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
