<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwini</forename><surname>Pokle</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marynel Vázquez</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Soto</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Católica de Chile</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2657" to="2666"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose an end-to-end deep learning model for translating free-form natural language instructions to a high-level plan for behavioral robot navigation. The proposed model uses attention mechanisms to connect information from user instructions with a topo-logical representation of the environment. To evaluate this model, we collected a new dataset for the translation problem containing 11,051 pairs of user instructions and navigation plans. Our results show that the proposed model outperforms baseline approaches on the new dataset. Overall, our work suggests that a topological map of the environment can serve as a relevant knowledge base for translating natural language instructions into a sequence of navigation behaviors.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Enabling robots to follow navigation instructions in natural language can facilitate human-robot in- teraction across a variety of applications. For in- stance, within the service robotics domain, robots can follow navigation instructions to help with mobile manipulation <ref type="bibr" target="#b26">(Tellex et al., 2011</ref>) and de- livery tasks ( <ref type="bibr" target="#b27">Veloso et al., 2015)</ref>.</p><p>Interpreting navigation instructions in natural language is difficult due to the high variabil- ity in the way people describe routes <ref type="bibr" target="#b5">(Chen and Mooney, 2011</ref>). For example, there are a variety of ways to describe the route in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>:</p><p>-"Exit the room, turn right, follow the corri- dor until you pass a vase on your left, and enter the next room on your left"; or -"Turn right after you exit the room, and enter the room on the left right before the end of the corridor"; or -"Advance forward to the right after going out of the door. Enter the room which is in the middle of two vases on your left." * Both authors contributed equally to this work.</p><p>Each fragment of a sentence within these instruc- tions can be mapped to one or more than one navi- gation behaviors. For instance, assume that a robot counts with a number of primitive, navigation be- haviors, such as "enter the room on the left (or on right)" , "follow the corridor", "cross the inter- section", etc. Then, the fragment "advance for- ward" in a navigation instruction could be inter- preted as a "follow the corridor" behavior, or as a sequence of "follow the corridor" interspersed with "cross the intersection" behaviors depend- ing on the topology of the environment. Resolving such ambiguities often requires reasoning about "common-sense" concepts, as well as interpreting spatial information and landmarks, e.g., in sen- tences such as "the room on the left right before the end of the corridor" and "the room which is in the middle of two vases".</p><p>In this work, we pose the problem of inter- preting navigation instructions as finding a map- ping (or grounding) of the commands into an ex- ecutable navigation plan. While the plan is typ- ically modeled as a formal specification of low- level motions <ref type="bibr" target="#b5">(Chen and Mooney, 2011</ref>) or a grammar ( <ref type="bibr" target="#b1">Artzi and Zettlemoyer, 2013;</ref><ref type="bibr" target="#b16">Matuszek et al., 2010)</ref>, we focus specifically on translating instructions to a high-level navigation plan based on a topological representation of the environ- ment. This representation is a behavioral navi- gation graph, as recently proposed by <ref type="bibr" target="#b23">(Sepúlveda et al., 2018)</ref>, designed to take advantage of the se- mantic structure typical of human environments. The nodes of the graph correspond to semanti- cally meaningful locations for the navigation task, such as kitchens or entrances to rooms in corri- dors. The edges are parameterized, visuo-motor behaviors that allow a robot to navigate between neighboring nodes, as illustrated in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. Un- der this framework, complex navigation routes can be achieved by sequencing behaviors without an explicit metric representation of the world. , and the problem setting of interest (c). The red part of (b) corresponds to the representation of the route highlighted in blue in (a). The codes "oo-left", "oo-right", "cf", "left-io", and "right-io" correspond to the behaviors "go out and turn left", "go out and turn right", "follow the corridor", "enter the room on left", and "enter office on right", respectively.</p><p>We formulate the problem of following instruc- tions under the framework of <ref type="bibr" target="#b23">(Sepúlveda et al., 2018)</ref> as finding a path in the behavioral naviga- tion graph that follows the desired route, given a known starting location. The edges (behaviors) along this path serve to reach the -sometimes im- plicit -destination requested by the user. As in ( <ref type="bibr" target="#b32">Zang et al., 2018)</ref>, our focus is on the problem of interpreting navigation directions. We assume that a robot can realize valid navigation plans accord- ing to the graph.</p><p>We contribute a new end-to-end model for fol- lowing directions in natural language under the be- havioral navigation framework. Inspired by the information retrieval and question answering lit- erature ( <ref type="bibr" target="#b14">Lewis and Jones, 1996;</ref><ref type="bibr" target="#b22">Seo et al., 2017;</ref><ref type="bibr" target="#b31">Xiong et al., 2016;</ref><ref type="bibr" target="#b20">Palangi et al., 2016)</ref>, we pro- pose to leverage the behavioral graph as a knowl- edge base to facilitate the interpretation of naviga- tion commands. More specifically, the proposed model takes as input user directions in text form, the behavioral graph of the environment encoded as node; edge; node triplets, and the initial location of the robot in the graph. The model then predicts a set of behaviors to reach the desired des- tination according to the instructions and the map <ref type="figure" target="#fig_0">(Fig. 1(c)</ref>). Our main insight is that using atten- tion mechanisms to correlate navigation instruc- tions with the topological map of the environment can facilitate predicting correct navigation plans.</p><p>This work also contributes a new dataset of 11, 050 pairs of free-form natural language in- structions and high-level navigation plans. This dataset was collected through Mechanical Turk using 100 simulated environments with a corre- sponding topological map and, to the best of our knowledge, it is the first of its kind for behavioral navigation. The dataset opens up opportunities to explore data-driven methods for grounding navi- gation commands into high-level motion plans.</p><p>We conduct extensive experiments to study the generalization capabilities of the proposed model for following natural language instructions. We in- vestigate both generalization to new instructions in known and in new environments. We conclude this paper by discussing the benefits of the pro- posed approach as well as opportunities for future research based on our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>This section reviews relevant prior work on fol- lowing navigation instructions. Readers interested in an in-depth review of methods to interpret spa- tial natural language for robotics are encouraged to refer to ( <ref type="bibr" target="#b12">Landsiedel et al., 2017)</ref>.</p><p>Typical approaches to follow navigation com- mands deal with the complexity of natural lan- guage by manually parsing commands, constrain- ing language descriptions, or using statistical ma- chine translation methods. While manually pars- ing commands is often impractical, the first type of approaches are foundational: they showed that it is possible to leverage the compositionality of semantic units to interpret spatial language <ref type="bibr" target="#b4">(Bugmann et al., 2004;</ref><ref type="bibr" target="#b13">Levit and Roy, 2007)</ref>.</p><p>Constraining language descriptions can reduce the size of the input space to facilitate the inter- pretation of user commands. For example, <ref type="bibr" target="#b25">(Talbot et al., 2016</ref>) explored using structured, sym- bolic language phrases for navigation. As in this earlier work, we are also interested in navigation with a topological map of the environment. How- ever, we do not process symbolic phrases. Our aim is to translate free-form natural language instruc-tions to a navigation plan using information from a high-level representation of the environment. This translation problem requires dealing with missing actions in navigation instructions and actions with preconditions, such as "at the end of the corridor, turn right" ( <ref type="bibr" target="#b15">MacMahon et al., 2006</ref>).</p><p>Statistical machine translation <ref type="bibr" target="#b10">(Koehn, 2009)</ref> is at the core of recent approaches to enable robots to follow navigation instructions. These meth- ods aim to automatically discover translation rules from a corpus of data, and often leverage the fact that navigation directions are composed of sequen- tial commands. For instance, ( <ref type="bibr" target="#b30">Wong and Mooney, 2006;</ref><ref type="bibr" target="#b16">Matuszek et al., 2010;</ref><ref type="bibr" target="#b5">Chen and Mooney, 2011</ref>) used statistical machine translation to map instructions to a formal language defined by a grammar. Likewise, ( <ref type="bibr" target="#b11">Kollar et al., 2010;</ref><ref type="bibr" target="#b26">Tellex et al., 2011</ref>) mapped commands to spatial descrip- tion clauses based on the hierarchical structure of language in the navigation problem. Our ap- proach to machine translation builds on insights from these prior efforts. In particular, we focus on end-to-end learning for statistical machine trans- lation due to the recent success of Neural Net- works in Natural Language Processing <ref type="bibr" target="#b9">(Goodfellow et al., 2016</ref>).</p><p>Our work is inspired by methods that reduce the task of interpreting user commands to a sequential prediction problem ( <ref type="bibr" target="#b24">Shimizu and Haas, 2009;</ref><ref type="bibr" target="#b17">Mei et al., 2016;</ref><ref type="bibr" target="#b0">Anderson et al., 2018</ref>). Similar to <ref type="bibr">Mei et al. and Anderson et al.,</ref> we use a sequence-to- sequence model to enable a mobile agent to follow routes. But instead leveraging visual information to output low-level navigation commands, we fo- cus on using a topological map of the environment to output a high-level navigation plan. This plan is a sequence of behaviors that can be executed by a robot to reach a desired destination <ref type="bibr" target="#b23">(Sepúlveda et al., 2018;</ref><ref type="bibr" target="#b32">Zang et al., 2018</ref>).</p><p>We explore machine translation from the per- spective of automatic question answering. Follow- ing ( <ref type="bibr" target="#b22">Seo et al., 2017;</ref><ref type="bibr" target="#b31">Xiong et al., 2016)</ref>, our ap- proach uses attention mechanisms to learn align- ments between different input modalities. In our case, the inputs to our model are navigation in- structions, a topological environment map, and the start location of the robot <ref type="figure" target="#fig_0">(Fig. 1(c)</ref>). Our results show that the map can serve as an effective source of contextual information for the translation task. Additionally, it is possible to leverage this kind of information in an end-to-end fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Our goal is to translate navigation instructions in text form into a sequence of behaviors that a robot can execute to reach a desired destination from a known start location. We frame this problem un- der a behavioral approach to indoor autonomous navigation <ref type="bibr" target="#b23">(Sepúlveda et al., 2018)</ref> and assume that prior knowledge about the environment is available for the translation task. This prior knowl- edge is a topological map, in the form of a behav- ioral navigation graph ( <ref type="figure" target="#fig_0">Fig. 1(b)</ref>). The nodes of the graph correspond to semantically-meaningful locations for the navigation task, and its directed edges are visuo-motor behaviors that a robot can use to move between nodes. This formulation takes advantage of the rich semantic structure be- hind man-made environments, resulting in a com- pact route representation for robot navigation. <ref type="figure" target="#fig_0">Fig. 1</ref>(c) provides a schematic view of the prob- lem setting. The inputs are: (1) a navigation graph m, (2) the starting node s of the robot in m, and (3) a set of free-form navigation instructions I in natural language. The instructions describe a path in the graph to reach from s to a -potentially im- plicit -destination node g. Using this informa- tion, the objective is to predict a suitable sequence of robot behaviors b 1 , . . . , b T to navigate from s to g according to I. From a supervised learning perspective, the goal is then to estimate: argmax</p><formula xml:id="formula_0">b 1 ,...,b T P (b 1 , . . . , b T |m, s, I)<label>(1)</label></formula><p>based on a dataset of input-target pairs</p><formula xml:id="formula_1">{(x i , y i ) | 0 ≤ i ≤ N }, where x i = (m, s, I) i and y i = (b 1 , . . . , b T ) i , respectively.</formula><p>The sequen- tial execution of the behaviors b 1 , . . . , b T should replicate the route intended by the instructions I. We assume no prior linguistic knowledge. Thus, translation approaches have to cope with the semantics and syntax of the language by discover- ing corresponding patterns in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Behavioral Graph: A Knowledge Base For Navigation</head><p>We view the behavioral graph m as a knowledge base that encodes a set of navigational rules as triplets p i ; b l <ref type="bibr">[attr]</ref>; p j , where p i and p j are ad- jacent nodes in the graph, and the edge b l is an executable behavior to navigate from p i to p j . In general, each behaviors includes a list of relevant navigational attributes attr that the robot might encounter when moving between nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavior Description oo&lt;d&gt;</head><p>Go out of the current place and turn &lt;d&gt; io&lt;d&gt; Turn &lt;d&gt; and enter the place straight ahead oio Exit current place and enter straight ahead &lt;d&gt;t Turn &lt;d&gt; at the intersection cf Follow (or go straight down) the corridor sp Go straight at a T intersection ch&lt;d&gt;</p><p>Cross the hall and turn &lt;d&gt; We consider 7 types of semantic locations, 11 types of behaviors, and 20 different types of land- marks. A location in the navigation graph can be a room, a lab, an office, a kitchen, a hall, a corri- dor, or a bathroom. These places are labeled with unique tags, such as "room-1" or "lab-2", except for bathrooms and kitchens which people do not typically refer to by unique names when describ- ing navigation routes. <ref type="table" target="#tab_0">Table 1</ref> lists the navigation behaviors that we consider in this work. These behaviors can be de- scribed in reference to visual landmarks or objects, such as paintings, book shelfs, tables, etc. As in <ref type="figure" target="#fig_0">Fig. 1</ref>, maps might contain multiple landmarks of the same type. Please see the supplementary ma- terial (Appendix A) for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach</head><p>We leverage recent advances in deep learning to translate natural language instructions to a sequence of navigation behaviors in an end-to- end fashion. Our proposed model builds on the sequence-to-sequence translation model of <ref type="bibr" target="#b2">(Bahdanau et al., 2015)</ref>, which computes a soft- alignment between a source sequence (natural lan- guage instructions in our case) and the correspond- ing target sequence (navigation behaviors).</p><p>As one of our main contributions, we augment the neural machine translation approach of Bah- danau et al. to take as input not only natural lan- guage instructions, but also the corresponding be- havioral navigation graph m of the environment where navigation should take place. Specifically, at each step, the graph m operates as a knowl- edge base that the model can access to obtain in- formation about path connectivity, facilitating the grounding of navigation commands. <ref type="figure" target="#fig_1">Figure 2</ref> shows the structure of the proposed model for interpreting navigation instructions. The model consists of six layers:</p><p>Embed layer: The model first encodes each word and symbol in the input sequences I and m into fixed-length representations. The instruc- tions I are embedded into a 100-dimensional pre- trained GloVe vector ( <ref type="bibr" target="#b21">Pennington et al., 2014</ref>). Each of the triplet components, p i , b l <ref type="bibr">[attr]</ref>, and p j of the graph m, are one-hot encoded into vectors of dimensionality 2N + E, where N and E are the number of nodes and edges in m, respectively.</p><p>Encoder layer: The model then uses two bidi- rectional Gated Recurrent Units (GRUs) ( <ref type="bibr" target="#b7">Cho et al., 2014</ref>) to independently process the infor- mation from I and m, and incorporate contextual cues from the surrounding embeddings in each se-</p><note type="other">quence. The outputs of the encoder layer are the matrix ¯ I ∈ R T ×2H for the navigational commands and the matrix ¯ G ∈ R L×2H for the behavioral graph, where H is the hidden size of each GRU, T is the number of words in the instruction I, and L is the number of triplets in the graph m.</note><p>Attention layer: Matrices ¯ I and ¯ G generated by the encoder layer are combined using an at- tention mechanism. We use one-way attention because the graph contains information about the whole environment, while the instruction has (po- tentially incomplete) local information about the route of interest. The use of attention provides our model with a two-step strategy to interpret commands. This resembles the way people find paths on a map: first, relevant parts on the map are selected according to their affinity to each of the words in the input instruction (attention layer); second, the selected parts are connected to assem- ble a valid path (decoder layer). More formally, let ¯ G i (i ∈ <ref type="bibr">[1, L]</ref>) be the i-th row of ¯ G, and ¯ I j (j ∈ <ref type="bibr">[1, T ]</ref>) the j-th row of ¯ I. We use each en- coded triplet ¯ G i in ¯ G to calculate its associated attention distribution a i ∈ R T over all the atomic instructions ¯ I j :</p><formula xml:id="formula_2">e i = [ ¯ G i W ¯ I 1 , . . . , ¯ G i W ¯ I T ] (2) a i = sof tmax(e i )<label>(3)</label></formula><p>where the matrix W ∈ R 2H×2H serves to com- bine the different sources of information ¯ G and ¯ I. Each component a ij of the attention distributions a i quantifies the affinity between the i-th triplet in ¯ G and the j-th word in the corresponding input I.</p><p>The model then uses each attention distribution a i to obtain a weighted sum of the encodings of the words in ¯ I, according to their relevance to the corresponding triplet ¯ G i . This results in L atten- tion vectors R i ∈ R 2H , R i = T j=1 a ij I j . The final step in the attention layer concate- nates each R i with ¯ G i to generate the outputs  <ref type="bibr">et al., 2017)</ref>, we include the encoded triplet ¯ G i in the output tensor F i of this layer to prevent early sum- maries of relevant map information.</p><formula xml:id="formula_3">F i = [R i ; ¯ G i ], i ∈ [1, L]. Following (Seo</formula><p>FC layer: The model reduces the dimension- ality of each individual vector F i from 4H to H with a fully-connected (FC) layer. The resulting L vectors are output to the next layer as columns of a context matrix C ∈ R H×L .</p><p>Decoder layer: After the FC layer, the model predicts likelihoods over the sequence of behav- iors that correspond to the input instructions with a GRU network. Without loss of generality, con- sider the t-th recurrent cell in the GRU network. This cell takes two inputs: a hidden state vector h t−1 from the prior cell, and a one-hot embedding of the previous behavior b t−1 that was predicted by the model. Based on these inputs, the GRU cell outputs a new hidden state h t to compute likeli- hoods for the next behavior. These likelihoods are estimated by combining the output state h t with relevant information from the context C:</p><formula xml:id="formula_4">ˆ d ts = v a tanh(W 1 h t + W 2 C s )<label>(4)</label></formula><formula xml:id="formula_5">d t = sof tmax( ˆ d t1 , . . . , ˆ d tL )<label>(5)</label></formula><p>where W 1 , W 2 , and v a are trainable parameters. The attention vector d t ∈ R L in Eq. (5) quanti- fies the affinity of h t with respect to each of the columns C s of C, where s ∈ [1, L]. The attention vector also helps to estimate a dynamic contextual vector S t = L s=1 d ts C s that the t-th GRU cell uses to compute logits for the next behavior:</p><formula xml:id="formula_6">o t = W 3 [S t ; h t ]<label>(6)</label></formula><p>with W 3 trainable parameters. Note that o t in- cludes a value for each of the pre-defined behav- iors in the graph m, as well as for a special "stop" symbol to identify the end of the output sequence.</p><p>Output layer: The final layer of the model searches for a valid sequence of robot behaviors based on the robot's initial node, the connectivity of the graph m, and the output logits from the pre- vious decoder layer. Again, without loss of gen- erality, consider the t-th behavior b t that is finally predicted by the model. The search for this behav- ior is implemented as: b t = argmax(sof tmax(o t + mask(m, n t )))</p><p>with mask(m, n t ) a masking function that takes as input the graph m and the node n t that the robot reaches after following the sequence of behaviors b 1 , . . . , b t−1 previously predicted by the model. The mask function returns a vector of the same dimensionality as the logits o t , but with zeros for the valid behaviors after the last location n t and for the special stop symbol, and − inf for any in- valid predictions according to the connectivity of the behavioral navigation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Dataset</head><p>We created a new dataset for the problem of fol- lowing navigation instructions under the behav- ioral navigation framework of <ref type="bibr" target="#b23">(Sepúlveda et al., 2018)</ref>. <ref type="bibr">1</ref> This dataset was created using Amazon Mechanical Turk and 100 maps of simulated in- door environments, each with 6 to 65 rooms. To the best of our knowledge, this is the first bench-  <ref type="table" target="#tab_0">Single # Double Total  Training  4062  2002  8066  Test-Repeated  944  34  1012  Test-New  962  0  962   Table 2</ref>: Dataset statistics. "# Single" indicates the number of navigation plans with a single natural language instruction. "# Double" is the number of plans with two different instruc- tions. The total number of plans is (# Single) × 2(# Double).</p><p>mark for comparing translation models in the con- text of behavioral robot navigation. As shown in <ref type="table">Table 2</ref>, the dataset consists of 8066 pairs of free-form natural language instruc- tions and navigation plans for training. This train- ing data was collected from 88 unique simulated environments, totaling 6064 distinct navigation plans (2002 plans have two different navigation instructions each; the rest has one). The dataset contains two test set variants:</p><p>1) Test-Repeated: Contains 1012 pairs of instruc- tions and navigation plans. These routes are not part of the training set; however, they are collected using environments that are part of the training set.</p><p>2) Test-New: Contains 962 pairs of instructions and navigation plans. This test set is more chal- lenging than the Test-Repeated dataset because it contains new routes on 12 new indoor environ- ments not included in the training set.</p><p>While the dataset was collected with simulated en- vironments, no structure was imposed on the nav- igation instructions while crowd-sourcing data. Thus, many instructions in our dataset are am- biguous. Moreover, the order of the behaviors in the instructions is not always the same. For in- stance, a person said "turn right and advance" to describe part of a route, while another person said "go straight after turning right" in a similar sit- uation. The high variability present in the natu- ral language descriptions of our dataset makes the problem of decoding instructions into behaviors not trivial. See Appendix A of the supplementary material for additional details on our data collec- tion effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>This section describes our evaluation of the pro- posed approach for interpreting navigation com- mands in natural language. We provide both quan- titative and qualitative results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation Metrics</head><p>While computing evaluation metrics, we only con- sider the behaviors present in the route because they are sufficient to recover the high-level navi- gation plan from the graph. Our metrics treat each behavior as a single token. For example, the sam- ple plan "R-1 oor C-1 cf C-1 lt C-0 cf C-0 iol O-3" is considered to have 5 tokens, each correspond- ing to one of its behaviors ("oor", "cf", "lt", "cf", "iol"). In this plan, "R-1","C-1", "C-0", and "O- 3" are symbols for locations (nodes) in the graph.</p><p>We compare the performance of translation ap- proaches based on four metrics:</p><p>-Exact Match (EM). As in ( <ref type="bibr" target="#b24">Shimizu and Haas, 2009)</ref>, EM is 1 if a predicted plan matches exactly the ground truth; otherwise it is 0.</p><p>-F1 score (F1). The harmonic average of the pre- cision and recall over all the test set ( <ref type="bibr" target="#b6">Chinchor and Sundheim, 1993)</ref>.</p><p>-Edit Distance (ED). The minimum number of insertions, deletions or swap operations required to transform a predicted sequence of behaviors into the ground truth sequence <ref type="bibr" target="#b19">(Navarro, 2001</ref>).</p><p>-Goal Match (GM). GM is 1 if a predicted plan reaches the ground truth destination (even if the full sequence of behaviors does not match exactly the ground truth). Otherwise, GM is 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Models Used in the Evaluation</head><p>We compare the proposed approach for translat- ing natural language instructions into a navigation plan against alternative deep-learning models:</p><p>Baseline model. The baseline approach is based on ( <ref type="bibr" target="#b24">Shimizu and Haas, 2009</ref>). It divides the task of interpreting commands for behavioral naviga- tion into two steps: path generation, and path ver- ification. For path generation, this baseline uses a standard sequence-to-sequence model augmented with an attention mechanism, similar to ( <ref type="bibr" target="#b2">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b32">Zang et al., 2018</ref>). For path verification, the baseline uses depth-first search to find a route in the graph that matches the sequence of predicted behaviors. If no route matches per- fectly, the baseline changes up to three behaviors in the predicted sequence to try to turn it into a valid path.</p><p>Ablation model. To test the impact of using the behavioral graphs as an extra input to our trans- lation model, we implemented a version of our approach that only takes natural language instruc- tions as input. In this ablation model, the output of the bidirectional GRU that encodes the input in- struction I is directly fed to the decoder layer. This model does not have the attention and FC layers described in Sec. 4, nor uses the masking function in the output layer.</p><p>Ablation with mask model. This model is the same as the previous Ablation model, but with the masking function in the output layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Implementation Details</head><p>We pre-processed the inputs to the various models that are considered in our experiment. In partic- ular, we lowercased, tokenized, spell-checked and lemmatized the input instructions in text-form us- ing WordNet <ref type="bibr" target="#b18">(Miller, 1995)</ref>. We also truncated the graphs to a maximum of 300 triplets, and the navi- gational instructions to a maximum of 150 words. Only 6.4% (5.4%) of the unique graphs in the training (validation) set had more than 300 triplets, and less than 0.15% of the natural language in- structions in these sets had more than 150 tokens.</p><p>The dimensionality of the hidden state of the GRU networks was set to 128 in all the experi- ments. In general, we used 12.5% of the train- ing set as validation for choosing models' hyper- parameters. In particular, we used dropout after the encoder and the fully-connected layers of the proposed model to reduce overfitting. Best perfor- mance was achieved with a dropout rate of 0.5 and batch size equal to 256. We also used scheduled sampling ( ) at training time for all models except the baseline.</p><p>We input the triplets from the graph to our pro- posed model in alphabetical order, and consider a modification where the triplets that surround the start location of the robot are provided first in the input graph sequence. We hypothesized that such rearrangement would help identify the starting lo- cation (node) of the robot in the graph. In turn, this could facilitate the prediction of correct output se- quences. In the remaining of the paper, we refer to models that were provided a rearranged graph, beginning with the starting location of the robot, as models with "Ordered Triplets". <ref type="table" target="#tab_2">Table 3</ref> shows the performance of the models con- sidered in our evaluation on both test sets. The next two sections discuss the results in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Quantitative Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">Performance in the Test-Repeated Set</head><p>First, we can observe that the final model "Ours with Mask and Ordered Triplets" outperforms the Baseline and Ablation models on all metrics in previously seen environments. The difference in performance is particularly evident for the Exact Match and Goal Match metrics, with our model in- creasing accuracy by 35% and 25% in comparison to the Baseline and Ablation models, respectively. These results suggest that providing the behavioral navigation graph to the model and allowing it to process this information as a knowledge base in an end-to-end fashion is beneficial.</p><p>We can also observe from <ref type="table" target="#tab_2">Table 3</ref> that the mask- ing function of Eq. <ref type="formula" target="#formula_7">(7)</ref> tends to increase perfor- mance in the Test-Repeated Set by constraining the output sequence to a valid set of navigation be- haviors. For the Ablation model, using the mask- ing function leads to about 10% increase in EM and GM accuracy. For the proposed model (with or without reordering the graph triplets), the in- crease in accuracy is around 4%. Note that the impact of the masking function is less evident in terms of the F1 score because this metric considers if a predicted behavior exists in the ground truth navigation plan, irrespective of its specific posi- tion in the output sequence.</p><p>The results in the last four rows of <ref type="table" target="#tab_2">Table 3</ref> sug- gest that ordering the graph triplets can facilitate predicting correct navigation plans in previously seen environments. Providing the triplets that sur- round the starting location of the robot first to the model leads to a boost of 4% in EM and GM per- formance. The rearrangement of the graph triplets also helps to reduce ED and increase F1.</p><p>Lastly, it is worth noting that our proposed model (last row of <ref type="table" target="#tab_2">Table 3</ref>) outperforms all other models in previously seen environments. In partic- ular, we obtain over 4% increase in EM and GM between our model and the next best two models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">Performance in the Test-New Set</head><p>The previous section evaluated model perfor- mance on new instructions (and corresponding navigation plans) for environments that were pre- viously seen at training time. Here, we examine whether the trained models succeed on environ- ments that are completely new.</p><p>The evaluation on the Test-New Set helps un- derstand the generalization capabilities of the models under consideration. This experiment is more challenging than the one in the previous sec-  tion, as can be seen in performance drops in <ref type="table" target="#tab_2">Ta- ble 3</ref> for the new environments. Nonetheless, the insights from the previous section still hold: mask- ing in the output layer and reordering the graph triplets tend to increase performance. Even though the results in <ref type="table" target="#tab_2">Table 3</ref> suggest that there is room for future work on decoding natural language instructions, our model still outperforms the baselines by a clear margin in new environ- ments. For instance, the difference between our model and the second best model in the Test-New set is about 3% EM and GM. Note that the average number of actions in the ground truth output se- quences is 7.07 for the Test-New set. Our model's predictions are just 1.22 edits off on average from the correct navigation plans.</p><formula xml:id="formula_8">Model Test-Repeated Set Test-New Set EM ↑ F1 ↑ ED ↓ GM ↑ EM ↑ F1↑ ED ↓ GM ↑</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Qualitative Evaluation</head><p>This section discusses qualitative results to better understand how the proposed model uses the nav- igation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.1">Attention Visualization</head><p>We analyze the evolution of the attention weights d t in Eq. (5) to assess if the decoder layer of the proposed model is attending to the correct parts of the behavioral graph when making predictions. <ref type="figure" target="#fig_3">Fig 3(b)</ref> shows an example of the resulting atten- tion map for the case of a correct prediction. In the <ref type="figure">Figure,</ref> the attention map is depicted as a scaled and normalized 2D array of color codes. Each col- umn in the array shows the attention distribution d t used to generate the predicted output at step t. Consequently, each row in the array represents a triplet in the corresponding behavioral graph. This graph consists of 72 triplets for <ref type="figure" target="#fig_3">Fig 3(b)</ref>.</p><p>We observe a locality effect associated to the attention coefficients corresponding to high val- ues (bright areas) in each column of <ref type="figure" target="#fig_3">Fig 3(b)</ref>. This suggests that the decoder is paying atten- tion to graph triplets associated to particular neigh- borhoods of the environment in each prediction step. We include additional attention visualiza- tions in the supplementary Appendix, including cases where the dynamics of the attention distri- bution are harder to interpret.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.2">Experiments with Sub-Optimal Paths</head><p>All the routes in our dataset are the shortest paths from a start location to a given destination. Thus, we collected a few additional natural lan- guage instructions to check if our model was able to follow navigation instructions describing sub- optimal paths. One such example is shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, where the blue route (shortest path) and the red route (alternative path) are described by:</p><p>-Blue route: "Go out the office and make a left. Turn right at the corner and go down the hall. Make a right at the next corner and enter the kitchen in front of table."</p><p>-Red route: "Exit the room 0 and turn right, go to the end of the corridor and turn left, go straight to the end of the corridor and turn left again. After passing bookshelf on your left and table on your right, Enter the kitchen on your right."</p><p>For both routes, the proposed model was able to predict the correct sequence of navigation be- haviors. This result suggests that the model is in- deed using the input instructions and is not just ap- proximating shortest paths in the behavioral graph. Other examples on the prediction of sub-obtimal paths are described in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This work introduced behavioral navigation through free-form natural language instructions as a challenging and a novel task that falls at the intersection of natural language processing and robotics. This problem has a range of interesting cross-domain applications, including information retrieval.</p><p>We proposed an end-to-end system to trans- late user instructions to a high-level navigation plan. Our model utilized an attention mechanism to merge relevant information from the navigation instructions with a behavioral graph of the envi- ronment. The model then used a decoder to predict a sequence of navigation behaviors that matched the input commands.</p><p>As part of this effort, we contributed a new dataset of 11,051 pairs of user instructions and navigation plans from 100 different environments. Our model achieved the best performance in this dataset in comparison to a two-step baseline ap- proach for interpreting navigation instructions, and a sequence-to-sequence model that does not consider the behavioral graph. Our quantitative and qualitative results suggest that attention mech- anisms can help leverage the behavioral graph as a relevant knowledge base to facilitate the trans- lation of free-form navigation instructions. Over- all, our approach demonstrated practical form of learning for a complex and useful task.</p><p>In future work, we are interested in investigat- ing mechanisms to improve generalization to new environments. For example, pointer and graph networks ( <ref type="bibr" target="#b8">Defferrard et al., 2016</ref>) are a promising direction to help supervise translation models and predict motion behaviors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Map of an environment (a), its (partial) behavioral navigation graph (b), and the problem setting of interest (c). The</figDesc><graphic url="image-1.png" coords="2,72.00,62.81,453.54,129.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Model overview. The model contains six layers, takes the input of behavioral graph representation, free-form instruction, and the start location (yellow block marked as START in the decoder layer) and outputs a sequence of behaviors.</figDesc><graphic url="image-2.png" coords="5,140.03,62.81,317.49,183.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visualization of the attention weights of the decoder layer. The color-coded and numbered regions on the map (left) correspond to the triplets that are highlighted with the corresponding color in the attention map (right).</figDesc><graphic url="image-3.png" coords="8,307.28,196.11,218.27,106.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of two different navigation paths between the same pair of start and goal locations.</figDesc><graphic url="image-4.png" coords="9,93.83,62.81,174.61,174.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Behaviors (edges) of the navigation graphs consid-

ered in this work. The direction &lt;d&gt; can be left or right. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Performance of different models on the test datasets. EM and GM report percentages, and ED corresponds to average 

edit distance. The symbol ↑ indicates that higher results are better in the corresponding column; ↓ indicates that lower is better. 

</table></figure>

			<note place="foot" n="1"> The dataset is publicly available through the website: follow-nav-directions.stanford.edu.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The Toyota Research Institute (TRI) provided funds to assist with this research, but this paper solely reflects the opinions and conclusions of its authors and not TRI or any other Toyota entity. This work is also partially funded by Fondecyt grant 1181739, Conicyt, Chile. The authors would also like to thank Gabriel Sepúlveda for his assis-tance with parts of this project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visionand-language navigation: Interpreting visuallygrounded navigation instructions in real environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Sünderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Van Den Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Corpus-based robotics: A route instruction example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Bugmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislao</forename><surname>Lauria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theocharis</forename><surname>Kyriacou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Intelligent Autonomous Systems (IAS)</title>
		<meeting>Intelligent Autonomous Systems (IAS)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to interpret natural language navigation instructions from observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="859" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Muc-5 evaluation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Chinchor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beth</forename><surname>Sundheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th conference on Message understanding</title>
		<meeting>the 5th conference on Message understanding</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="69" to="78" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Gülehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno>abs/1606.09375</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Toward understanding natural language directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE International Conference on HumanRobot Interaction (HRI)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A review of spatial reasoning and interaction for real-world robotics. Advanced Robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Landsiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Wollherr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="222" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interpretation of spatial language in a map navigation task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Levit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deb</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="667" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language processing for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen Spärck Jones</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="101" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Walk the talk: Connecting language, knowledge, and action in route instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Macmahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Stankiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kuipers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Following directions using statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matuszek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Koscher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE International Conference on HumanRobot Interaction (HRI)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Listen, attend, and walk: Neural mapping of navigational instructions to action sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2772" to="2778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM computing surveys (CSUR)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="31" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Palangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinying</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabab</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Speech, and Language Processing</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A deep learning based behavioral approach to indoor autonomous navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sepúlveda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ICRA</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning to follow navigational route instructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuyuki</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">R</forename><surname>Haas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conferences on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Find my office: Navigating real space from semantic descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Obadiah</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feras</forename><surname>Dayoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Wyeth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5782" to="5787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding natural language commands for robotic navigation and mobile manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Tellex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Dickerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashis</forename><forename type="middle">Gopal</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><forename type="middle">J</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">National Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cobots: Robust symbiotic autonomous mobile service robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manuela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydeep</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Coltin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conferences on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">4423</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<editor>C. Cortes, N. D</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnett</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning for semantic parsing with statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="439" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic memory networks for visual and textual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2397" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Behavioral indoor navigation with natural language directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marynel</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE International Conference on HumanRobot Interaction (HRI)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="283" to="284" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
