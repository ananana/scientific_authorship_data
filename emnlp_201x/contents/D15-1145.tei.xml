<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph-Based Collective Lexical Selection for Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Su</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Soochow University</orgName>
								<address>
									<settlement>Suzhou</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Yao</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<settlement>Xiamen</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graph-Based Collective Lexical Selection for Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Lexical selection is of great importance to statistical machine translation. In this paper, we propose a graph-based framework for collective lexical selection. The framework is established on a translation graph that captures not only local associations between source-side content words and their target translations but also target-side global dependencies in terms of relat-edness among target items. We also introduce a random walk style algorithm to collectively identify translations of source-side content words that are strongly related in translation graph. We validate the effectiveness of our lexical selection framework on Chinese-English translation. Experiment results with large-scale training data show that our approach significantly improves lexical selection.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Lexical selection, which selects appropriate trans- lations for lexical items on the source side, is a cru- cial task in statistical machine translation (SMT). The task is closely related to two factors: 1) asso- ciations of selected translations with lexical items on the source side, including corresponding source items and their neighboring words, and 2) depen- dencies 1 between selected target translations and other items on the target side.</p><p>As translation rules and widely-used n-gram language models can only capture local associ- ations and dependencies, we have witnessed in-creasing efforts that attempt to incorporate non- local associations/dependencies into lexical selec- tion. Efforts using source-side associations mainly focus on the exploitation of either sentence-level context <ref type="bibr" target="#b2">(Chan et al., 2007;</ref><ref type="bibr" target="#b1">Carpuat and Wu, 2007;</ref><ref type="bibr" target="#b11">Hasan et al., 2008;</ref><ref type="bibr" target="#b19">Mauser et al., 2009;</ref><ref type="bibr" target="#b24">Shen et al., 2009)</ref> or the utilization of document-level context <ref type="bibr" target="#b28">(Xiao et al., 2011;</ref><ref type="bibr" target="#b27">Ture et al., 2012;</ref><ref type="bibr" target="#b29">Xiao et al., 2012;</ref><ref type="bibr" target="#b32">Xiong et al., 2013)</ref>. In contrast, target-side dependencies attract little attention, although they have an important im- pact on the accuracy of lexical selection. The most common practice is to use language mod- els to estimate the strength of target-side depen- dencies ( <ref type="bibr" target="#b15">Koehn et al., 2003;</ref><ref type="bibr" target="#b23">Shen et al., 2008;</ref><ref type="bibr" target="#b31">Xiong et al., 2011</ref>). However, conventional n- gram language models are not good at capturing long-distance dependencies. Consider the exam- ple shown in <ref type="figure">Figure 1</ref>. As the translations of pol- ysemous words "w` entí", "chíyˇchíyˇou" and "l` ıchˇangıchˇang" are far from each other, our baseline can only correctly translate "l` ıchˇangıchˇang" as "stance". It in- appropriately translates the other two words as "problem" and null, respectively, even with the support of an n-gram language model. If we could model long-distance dependencies among target translations of source words "w` entí"(issue), "chíyˇchíyˇou"(hold) and "l` ıchˇangıchˇang"(stance), these trans- lation errors could be avoided.</p><p>In order to model target-side global dependen- cies, we propose a novel graph-based collective lexical selection framework for SMT. Specifically,</p><p>• First, we propose a translation graph to model not only local associations between source- side content words and their target trans- lations but also global relatedness among target-side items. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Src: 对于/P 这/DT 问题/NN ，/PU 双方/PN 持有/VV 相同/VA 的/DEG 立场/NN</head><p>duìyú zhè wèntí , shuāngfāng chíyŏu xiāngtóng de lìchăng <ref type="figure">Figure 1</ref>: A Chinese-English translation example to illustrate the importance of target-side long-distance dependencies for lex- ical selection. Dotted lines show long-distance dependencies of source content words. Three content words "w` entí", "chíyˇchíyˇou", "l` ıchˇangıchˇang", and their candidate translations with high translation probabilities are also presented. Src: A Chinese sentence with part-of-speech tags. Tran: system output. Ref: reference translation.</p><p>• Second, we introduce a collective lexical se- lection algorithm, which can jointly identify translations of all source-side content words in the translation graph.</p><p>• Finally, we incorporate confidence scores of candidate translations in the translation graph, which are derived by the collective se- lection algorithm, into SMT to improve lexi- cal selection.</p><p>We validate the effectiveness of our graph- based lexical selection framework on a hierarchi- cal phrase-based system <ref type="bibr" target="#b3">(Chiang, 2007)</ref>. Exper- iment results on the NIST Chinese-English test sets show that our approach significantly improves translation quality.</p><p>We begin in Section 2 with the construction of translation graph for each translated sentence. Then, we propose a graph-based collective lexical selection framework for SMT in Section 3. Ex- periment results are reported in Section 4. We summarize and compare related work in Section 5. Finally, Section 6 presents conclusions and di- rections for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Translation Graph</head><p>Formally, a translation graph is a weighted graph G=(N, E). In the node set N , each node repre- sents either a source word or a target translation that contains one or multiple target words. In the edge set E, an edge linking a source word to a tar- get translation is referred to as a source-target as- sociation edge, and an edge connecting two target translations is called as a target-target relatedness edge. In Section 2.1 and 2.2, we will answer the following two questions on the translation graph:</p><p>• Which source words and their translations should be included in the translation graph?</p><p>• How can we measure the strength of the above two types of relations in the graph with edge weights?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Nodes</head><p>For a source sentence, the most ideal translation graph is a graph that includes all source words and their candidate translations. However, this ideal graph has two problems: intensive compu- tation for graph inference and difficulty in mod- eling dependencies between function and content words. In order to get around these two issues, we only consider lexical selection for source content words 2 .</p><p>We first identify source-side content word pairs using statistical metrics, and then keep word pairs with a high relatedness strength in the translation graph. To be specific, we use pointwise mutual in- formation (PMI) <ref type="bibr" target="#b4">(Church and Hanks, 1990</ref>) and co-occurrence frequency to measure the related- ness strength of two source-side words s and s within a window d s . Content word pairs will be kept when their co-occurrence frequencies are more than cf times in our training corpus and PMI values are larger than pmi . In this process, we remove noisy word pairs using the following heuristic rules: (1) As an adjective only has rela- tions with its head nouns or dependent adverbs, we remove all word pairs where an adjective is paired with words other than its head nouns or dependent adverbs; (2) We apply a similar con- straint to adverbs too, since the same thing hap- pens to an adverb and its head verb or head ad-  <ref type="figure">Figure 1</ref>. Relatedness scores on edges are shown for two group of translations {"problem", null, "stance"} (green) and {"issue", "hold", "position"} (blue), which are estimated with PMI. Note that the null node does not have any relations with other nodes. Besides, two translation combinations {"problem", null, "stance"} (green) and {"issue", "hold", "position"} (blue) have different strengths of relatedness.</p><p>jective. For example, in the Chinese sentence in <ref type="figure">Figure 1</ref>, the adjective "xi¯ angtóng" is only related to the noun "l` ıchˇangıchˇang" although it also frequently co-occur with "w` entí".</p><p>After identifying source-side content word pairs, we collect all target translations of these content words from extracted bilingual rules ac- cording to word alignments. These content words and target translations are used to build a transla- tion graph, where each node represents a source- side content word or a candidate target transla- tion. Note that there may be hundreds of differ- ent translations for a source word. For simplicity, we only consider target translations from transla- tion options that are adopted by the decoder after rule filtering. Let's revisit the example in <ref type="figure" target="#fig_1">Figure 2</ref>, we include the following target translations in the translation graph: "problem", "question", "issue", "hold", null, "possess", "stance" and "position".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Edges and Weights</head><p>In this section, we introduce how we calculate weights for two kinds of edges in a translation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Source-Target Association Edge</head><p>Connecting a source-side content word and its candidate target translations, a source-target asso- ciation edge provides a way to propagate transla- tion association evidence from a source word to its candidate translations. Obviously, the stronger the association between a source word and its can- didate translation, the more evidence the corre- sponding edge will propagate. For each source- side content word, we obtain its candidate trans- lations via the kept word alignments. Following <ref type="bibr" target="#b30">Xiong et al. (2014)</ref>, we allow a target translation to be either a phrase of length up to 3 words or null when s is not aligned to any word in the cor- responding bilingual rule. We define the weight of the edge from a source-side content word s to its target translatioñ t as follows:</p><formula xml:id="formula_0">W eight(s → ˜ t) = T P (s, ˜ t) ˜ t ∈N (s) T P (s, ˜ t )<label>(1)</label></formula><p>where N (s) denotes the set of candidate target translations of s kept on the translation graph, and T P (s, ˜ t) measures the probability of s be- ing translated tõ t. It is very important to note that there is no evidence propagated from a target translation to a source word, as source-target asso- ciation edges only go from a source-side content word to its translations.</p><p>We compute T P (s, ˜ t) according to the principle of maximal likelihood as follows:</p><formula xml:id="formula_1">T P (s, ˜ t) = count(s, ˜ t) count(s)<label>(2)</label></formula><p>where count(s, ˜ t) indicates how often s is aligned tõ t in the training corpus. Using this method, we can compute the translation probabilities of the source-target association edges in <ref type="figure" target="#fig_1">Figure 2</ref> as follows: TP("w` entí", "issue")=0.31, TP("chíyˇchíyˇou", "hold")=0.22 and TP("l` ıchˇangıchˇang", "position")=0.47.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Target-Target Relatedness Edge</head><p>Connecting two target translations of different re- lated source content words, a target-target relat- edness edge enables translation graph to capture dependencies between translations of any two dif- ferent source words.</p><p>Computing the weight of a target-target related- ness edge is crucial for our method. Intuitively, the stronger co-occurrence strength two transla- tions have, the more evidence should be propa- gated between them. Therefore we calculate the weight of a target-target related edge based on the co-occurrence strength of two translations linked by the edge. Formally, given the translatioñ t of source-side content word s and the translatioñ t of source-side content word s , the weight of the edge from˜tfrom˜ from˜t tõ t is defined as follows:</p><formula xml:id="formula_2">W eight( ˜ t → ˜ t ) = RS( ˜ t, ˜ t ) ˜ t ∈N ( ˜ t) RS( ˜ t, ˜ t )<label>(3)</label></formula><p>where N ( ˜ t) denotes the set of candidate transla- tions that link tõ t, and RS( ˜ t, ˜ t ) measures the strength of relatedness betweeñ t and˜tand˜ and˜t which is calculated as the average word-level relatedness over all content words in these two translations˜ttranslations˜ translations˜t and˜tand˜ and˜t .</p><p>As for the word-level relatedness RS(t, t ) for a content word pair (t, t ), we estimate it with the following two approaches over collected co- occurring word pairs within a window of size d t : (1) RS(t, t ) is computed as a bigram conditional probability p lm (t |t) via the language model; (2) Following (Xiong et al., 2011) and ( ), we employ PMI to define RS(t, t ) as ln p(t,t ) p(t)p(t ) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Collective Lexical Selection Algorithm</head><p>Based on the translation graph, we propose a col- lective lexical selection algorithm to jointly iden- tify translations of all source words in the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Statement and Solution Method</head><p>As stated previously, the translation of a source- side content word s should be: 1) associated with s; 2) related to the translations of other source-side content words. Thus, in the translation graph, the translation of s should be a target-side node which has: 1) an association edge with the node of s; 2) many relatedness edges with other target-side nodes that represent translations of other source words. Let's revisit <ref type="figure" target="#fig_1">Figure 2</ref>. If we know that the trans- lation of "w` entí" is "issue", the relatedness be- tween ("issue", "hold") and between ("issue", "position") can provide evidences that "hold" and "position" are the correct translations of "chíyˇchíyˇou" and "l` ıchˇangıchˇang", respectively. On the other hand, the candidate translation "problem" is less related to "hold" and "position", which may suggest that it is not likely to be the correct translation of "w` entí", even if it has a strong source-target as- sociation relation with "w` entí". However, in the translation graph, the correct target translation of a source word depends on correct translations of other source words in the graph, and vice versa. So how do we find these correct translations?</p><p>We propose a Random Walk (Gobel and Jagers, 1974) style algorithm to solve this problem, aim- ing to use both local source-target associations and global target-target relatedness simultane- ously during translation. In our algorithm, we as- sign each node an evidence score in the transla- tion graph, which indicates either the importance of a source word (for a source word node) or the confidence of a target translation being a correct translation (for a target word node). Specifically, we perform collective inference on the translation graph as follows:</p><p>• First, we set initial evidence scores for nodes in the translation graph.</p><p>• Second, evidence scores are simultaneously updated by propagating evidences along edges in the translation graph.</p><p>In the following sub-section, we describe the two steps in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Details of Our Algorithm</head><p>Using the algorithm shown in Algorithm 1, we iteratively derive evidence scores for candidate translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Notations</head><p>For a translation graph with n nodes, we assign each node an index from 1 to n and use this index to represent the node. We also use the following two notations:</p><p>• The evidence vector V: an n-dimensional vector where the ith component V i is the ev- idence score contained in this node (if node i corresponds to a source word), or the evi- dence score from the related translations (if node i corresponds to a target translation). In particular, we use V (0) to denote the initial Algorithm 1 Collective Inference in Translation Graph.</p><p>Input: S: the set of source-side content words, and S(i) denotes the source word of node i; k: the number of source-side content words ; T: the set of all candidate target translations, and T (j) denotes the target translation of node j; l: the number of candidate target translations;</p><note type="other">λ: the reallocation weight; maxIter: the maximum iteration number; : the difference threshold; 1: for i = 1, 2..., k 2: for j = 1, 2..., l 3: if S(i) is linked to T(j) 4: M k+j,i ← Weight(S(i) → T(j)) 5: for j1 = 1, 2..., l 6: for j2 = 1, 2..., l 7: if T(j1) is linked to T(j2) 8: M k+j 2 ,k+j 1 → Weight(T(j1) → T(j2)) 9: for i = 1, 2..., k 10: V (0) i ← Importance(S(i)) 11: for j = 1, 2..., l 12: V (0) k+j ← 0 13: δ ← ∞ 14: r ← 1 15: while r ≤ maxIter &amp;&amp; δ &gt; do 16:</note><formula xml:id="formula_3">V (r) ← (1 − λ) × M × V (r−1) + λ × V (0) 17: δ ← V (r) − V (r−1) 2 18:</formula><p>r ← r + 1 19: end while 20: for i = 1, 2..., k 21:</p><p>for j = 1, 2..., l 22:</p><p>if S(i) is linked to T(j) 23:</p><formula xml:id="formula_4">LexiTable(S(i), T(j)) ← normalize(V (r) k+j ) Return: LexiTable;</formula><p>evidence vector, and V (r) to represent the ev- idence vector we obtain at the rth iteration.</p><p>• The evidence propagation matrix M: an n × n matrix where M ij is the evidence prop- agation ratio from node j to node i, and its value is the weight of the edge from node j to node i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Algorithm</head><p>In Algorithm 1, we jointly infer the evidence scores of all candidate translations in the follow- ing three steps.</p><p>In Step 1, we calculate the evidence propaga- tion matrix M according to the method described in Section 2.2 (equations <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_2">(3)</ref>) <ref type="figure">(Lines 1-8)</ref>.</p><p>In Step 2, we adopt different methods to set the value of V (0) according to the node type. If the node corresponds to a source word, we set the ini- tial value using its importance score in the trans- lation graph, as implemented in ( <ref type="bibr" target="#b10">Han et al. 2011</ref>) (Lines 9-10). We calculate the importance score of the source word s using tf.idf as follows:</p><formula xml:id="formula_5">Importance(s) = tf.idf (s) s ∈Nsrc tf.idf (s )<label>(4)</label></formula><p>where N src is the set of source words in the trans- lation graph. If the node corresponds to a target translation, its initial evidence score is 0 (Lines 11-12).</p><p>In Step 3, evidences are simultaneously rein- forced by propagating them among semantically related translations ( <ref type="bibr">Lines 13-19)</ref>. Specific to our algorithm, we update them by propagating evi- dences according to different types of relations in the evidence propagation matrix M. Formally, the recursive update of the evidence vector is defined as follows:</p><formula xml:id="formula_6">V (r) = M × V (r−1)<label>(5)</label></formula><p>where r is the number of iterations.</p><p>One problem with the above equation is that some nodes in the translation graph do not have evidence outgoing edges, such as translation nodes containing only function words or the null node. The evidence will disappear when passing through these nodes. To solve this problem, we propagate evidence in the form of reallocation: we reallocate a fraction of evidence to the initial evidence vector V (0) at each step. The new recursive update of the evidence vector is formulated as follows:</p><formula xml:id="formula_7">V (r) = (1 − λ) × M × V (r−1) + λ × V (0) (6)</formula><p>where λ ∈ (0, 1) is the fraction of the reallocated evidence. We keep updating the evidence vec- tor according to this equation (Line 16), until the maximal number of iteration maxIter is reached or the Euclidean distance (Line 17) between evi- dence vectors calculated in two consecutive itera- tions is less than a pre-defined threshold <ref type="bibr">(Line 15)</ref>.</p><p>In this way, we jointly infer the evidence scores of all candidate target translations in the transla- tion graph. <ref type="table">Table 1</ref> gives the evidence scores of the example in <ref type="figure" target="#fig_1">Figure 2</ref>. We can find that our sys- tem enhanced with target translation dependencies is able to select correct translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Integration of Derived Evidence Score</head><p>For each translated sentence, we may build multi- ple translation graphs. For each translation graph, scores of the source words scores of the target translations w` entí chíyˇchíyˇou l` ıchˇangıchˇang problem question issue hold null possess stance position</p><formula xml:id="formula_8">V (0) 0.2015 0.3989 0.3996 0 0 0 0 0 0 0 0 V (r) 0.0302 0.0598</formula><p>0.0599 0.0533 0.0774 0.1071 0.1218 0.0244 0.0604 0.1186 0.1486 <ref type="table">Table 1</ref>: The initial and final evidence scores of some source words and their target translations in <ref type="figure" target="#fig_1">Figure 2</ref>. Here we set the reallocation weight λ as 0.15. Note that the translations "issue", "hold" and "position" are given high evidence scores.</p><p>we infer evidence scores of translations repre- sented by graph nodes using the above-mentioned algorithm before decoding. Then, for each can- didate translation of a source-side content word, we normalize its evidence score over the cor- responding translation graph to form an addi- tional lexical translation probability (Lines 20- 23). For instance, the normalized evidence score of "chíyˇchíyˇou" translated into "hold" is calculated as 0.1218/(0.1218 + 0.0244 + 0.0604) ≈ 0.5895. In this way, for each bilingual rule with word align- ments, we will obtain a new lexical weight which can be used together with the original translation probabilities and lexical weight to improve lexical selection in SMT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Our bilingual training corpus is the combina- tion of the FBIS corpus and Hansards part of LDC2004T07 corpus (1M parallel sentences, 54.6K documents, with 25.2M Chinese words and 29M English words). We word-aligned them using GIZA++ <ref type="bibr" target="#b20">(Och and Ney, 2003</ref>) with the op- tion "grow-diag-final-and". We chose the NIST evaluation set of 2005 (MT05) as the development set, and the sets of MT06/MT08 as test sets. We used SRILM Toolkit <ref type="bibr" target="#b25">(Stolcke, 2002</ref>) to train one 5-gram language model on the Xinhua portion of Gigaword corpus.</p><p>To construct translation graphs, we first used the ZPar toolkit 3 and the Stanford toolkit 4 to prepro- cess (word segmentation, PoS tagging and so on) Chinese and English sentences, respectively. We used the Chinese part of our bilingual corpus and an additional Chinese LDC Xinhua news corpus (10.2M sentences with 279.9M words) as train- ing data to collect Chinese word pairs. We set window size d s =15, thresholds pmi =0, cf =5 to identify Chinese related word pairs in the NIST translated sentences. Averagely, these three sets contain 13.5, 10.3 and 9.5 content words used to build translation graphs per sentence, respec- tively. Using the English part of our bilingual cor- pus and the Xinhua portion of Gigaword corpus as training data, we set window size d t =20, and used the SRILM toolkit with Witten-Bell smooth- ing and PMI to calculate relatedness strengths for target-side translations. To avoid data sparseness, we build the graph using the surface forms of words while calculating the word relatedness at the lemma level. To achieve this, we converted each word into its corresponding lemma with the exception of adjectives and adverbs. In the proce- dure of collective lexical selection, the difference threshold was set as 10 −10 , and the maximal it- eration number maxIter 100.</p><p>We reimplemented the decoder of Hiero <ref type="bibr" target="#b3">(Chiang, 2007</ref>), a famous hierarchical phrase-based (HPB) system. HPB system is a formally syntax- based system and delivers good performance in various translation evaluations. During decod- ing, we set the ttable-limit as 20, the stack-size as 100. The translation quality is evaluated by case- insensitive BLEU-4 metric ( <ref type="bibr" target="#b22">Papineni et al., 2002</ref>). To alleviate the impact of the instability of MERT <ref type="bibr" target="#b21">(Och, 2003)</ref>, we ran it three times for each exper- iment and reported the average BLEU scores as suggested in <ref type="bibr" target="#b5">(Clark et al., 2011</ref>). Finally, we con- ducted paired bootstrap sampling <ref type="bibr" target="#b16">(Koehn, 2004)</ref> to test the significance in BLEU score differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Our Method vs Other Methods</head><p>In the first group of experiments, we investigated the effectiveness of our model by comparing it against the baseline as well as two additional mod- els: (1) lexicalized rule selection model (He et al., 2008) (LRSM), which employs local context to improve rule selection in the HPB system; (2) topic similarity model (Xiao et al., 2012) 5 (TSM), which explores document-level topic information for translation rule selection in the HPB system. Furthermore, we combined our model with the two models to see if we could obtain further im- provements. For this, we integrated the new lexi-  cal weight learned by our model as a new feature into the LRSM/TSM system. <ref type="table" target="#tab_1">Table 2</ref> reports the results. All models outper- form the baseline. Especially, our graph-based lexical selection model GM(PMI) achieves an av- erage BLEU score of 26.40 on the two test sets, which is higher than that of the baseline by 0.65 BLEU points. This improvement is statistically significant at p&lt;0.01. The BLEU score of our model is close to those of LRSM and TSM, which achieve an average BLEU score of 26.55 and 26.35 on the two test sets, respectively. As PMI is slightly better than LM in our model, we use PMI in experiments hereafter.</p><p>The combination of our model and LRSM is able to further improve translation quality in terms of BLEU. In this case, the average BLEU score of the improved system is 26.95, with 0.4 BLEU points higher than LRSM. When combining our model with TSM, we obtain an average BLEU score of 26.80, which is better than TSM by 0.45 BLEU points. The two improvements over LRSM and TSM are also statistically significant at p&lt;0.05. These experiment results suggest that exploring long-distance dependencies among tar- get translations is complementary to the previous lexical selection methods which focus on source- side context information.</p><p>In order to know how our approach improves the performance of the HPB system, we compared the best translations of the HPB system using dif- ferent models. We find that our approach really improves translation quality by utilizing target- side long-distance dependencies which are, on the contrary, ignored in previous methods.</p><p>For example, the source sentence "...</p><formula xml:id="formula_9">;â.Å c 9 Ú [n] • /«... ©|• í{ ³ å.</formula><p>.." is translated as follows:</p><p>• Ref: ... musharraf and some tribal leaders in the northern region of [pakistan] last septem- ber ... the remnant forces of the taliban ...</p><p>• Baseline: ... musharraf last september and [palestine] north of tribal leaders ... the rem- nants of the taliban ...</p><p>• LRSM: ... musharraf last september and some tribal chiefs of the northern region of <ref type="bibr">[palestine]</ref> ... the remnants of the taliban ...</p><p>• LRSM+GM(PMI): ... last september musharraf and some tribal chiefs of the northern region of <ref type="bibr">[pakistan]</ref> ... the remnants of the taliban ...</p><p>Here both the baseline and LRSM fail to ob- tain the right translation for the word "n" be- cause "palestine" has a higher probability than "pakistan" (0.0374 vs 0.0285). However, in our model, the long-distance dependencies between ("musharraf", "pakistan") and ("taliban", "pak- istan") help the decoder correctly choose the translation "pakistan" for "n".</p><p>In yet another example, the source sentence "{ F" Š Ø ¯K [AE] ¡ ‰1" is translated as follows:</p><p>• Ref: us hopes agreement on north korean nu- clear issue be fully implemented</p><p>• Baseline: us hoped that the dprk nuclear is- sue is the full implementation</p><p>• TSM: us hope that the full implementation of the nuclear issue</p><p>• TSM+GM(PMI): us hope that the dprk nuclear issue [agreement] to be fully implemented</p><p>Even with TSM, the HPB system did not trans- late " AE" at all because translation rules "X 1 AE ||| X 1 is" and "X 1 AE X 2 ‰ 1 ||| X 2 implementation of X 1 " are used to trans- late the source sentence by the baseline and TSM systems respectively. However, in the combined model TSM+GM(PMI), the differences in relat- edness scores between ("nuclear", "agreement"), ("issue", "agreement") and ("agreement", "im- plemented") encourage the enhanced system to se- lect right translation for this word. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Effect of Reallocation Weight λ.</head><p>In Eq. (6), the reallocation weight λ determines which part plays a more important role in our method. In order to investigate the effect of λ on our method, we tried different values for λ: from 0.1 to 0.5 with an increment of 0.05 each time. The experimental setup is the same as the previous experiments. <ref type="figure" target="#fig_2">Figure 3</ref> shows the aver- age BLEU scores on the two test sets. Our sys- tem performs well when λ ranges from 0.1 to 0.25.</p><p>The performance drops when λ is larger than 0.25. A small reallocation weight λ reduces the impact of initial evidences and local source-side associa- tions in the collective lexical selection algorithm, but increases the impact of global dependencies of target-side translation, which are normally not considered in previous lexical selection methods. This performance curve on the values of λ sug- gests that target-side global dependencies are im- portant for lexical selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The collective inference algorithm is partially in- spired by <ref type="bibr" target="#b10">Han et al. (2011)</ref> who propose a graph- based collective entity linking (EL) method to model global interdependences among different EL decisions. We successfully adapt this algo- rithm to lexical selection in SMT. Other related work mainly includes the following two strands.</p><p>(1) Lexical selection in SMT. In order to cap- ture source-side context for lexical selection, some researchers propose trigger-based lexicon models to capture long-distance dependencies <ref type="bibr" target="#b11">(Hasan et al., 2008;</ref><ref type="bibr" target="#b19">Mauser et al., 2009)</ref>, and many more re- searchers build classifiers with rich context infor- mation to select desirable translations during de- coding ( <ref type="bibr" target="#b2">Chan et al., 2007;</ref><ref type="bibr" target="#b1">Carpuat and Wu, 2007;</ref>. <ref type="bibr" target="#b24">Shen et al. (2009)</ref> introduce four new linguistic and contextual fea- tures for HPB system. We have also witnessed in- creasing efforts in the exploitation of document- level context information. <ref type="bibr" target="#b28">Xiao et al. (2011)</ref> impose a hard constraint to guarantee the trans- lation consistency in document-level translation. <ref type="bibr" target="#b27">Ture et al. (2012)</ref> soften this consistency con- straint by integrating three counting features into decoder. <ref type="bibr">Hardmeier et al. (2012</ref><ref type="bibr">Hardmeier et al. ( , 2013</ref>) introduce a document-wide phrase-based decoder and inte- grate a semantic language model that cross sen- tence boundaries into the decoder. Based on topic models, <ref type="bibr" target="#b29">Xiao et al. (2012)</ref> present a topic simi- larity model for HPB system, where each rule is assigned with a topic distribution. Also relevant is the work of <ref type="bibr" target="#b32">Xiong et al. (2013)</ref>, who use three different models to capture lexical cohesion for document-level machine translation. Compared with the above-mentioned studies, our method fo- cuses on the exploitation of global dependencies among target translations, which has attracted lit- tle attention before.</p><p>Different from exploring source-side context, other researchers pay attention to the utilization of target-side context information. The com- mon practice in SMT is to use an n-gram lan- guage model to capture local dependencies be- tween translations ( <ref type="bibr" target="#b15">Koehn et al., 2003;</ref><ref type="bibr" target="#b31">Xiong et al., 2011</ref>). Yet another approach exploring target- side context information is proposed by <ref type="bibr" target="#b23">Shen et al. (2008)</ref>, who use a dependency language model to capture long-distance relations on the target side. Moreover,  treat translation as an unconstrained target sentence generation task, using soft features to capture lexical and syntac- tic correspondences between the source and tar- get language. Recently, many researcher have proposed to use deep neural networks to model long-distance dependencies of arbitrary length for SMT ( <ref type="bibr" target="#b0">Auli et al., 2013;</ref><ref type="bibr" target="#b14">Kalchbrenner and Blunsom, 2013;</ref><ref type="bibr" target="#b7">Devlin et al., 2014;</ref><ref type="bibr" target="#b13">Hu et al., 2014;</ref><ref type="bibr" target="#b26">Sundermeyer et al., 2014</ref>). Our work is significantly different from these meth- ods. We use a graph representation to capture local and global context information, which, to the best of our knowledge, is the first attempt to explore graph-based representations for lexical selection. Furthermore, our model do not resort to any syn- tactic resources such as dependency parsers of the target language.</p><p>(2) Random walk for SMT. Because of the advantage of global consistency, random walk al-gorithm has been applied in SMT. For example, <ref type="bibr" target="#b6">Cui et al. (2013)</ref> develop an effective approach to optimize phrase scoring and corpus weighting jointly using graph-based random walk. <ref type="bibr" target="#b34">Zhu et al. (2013)</ref> apply a random walk method to dis- cover implicit relations between the phrases of dif- ferent languages. Aiming to better evaluate trans- lation quality at the document level, <ref type="bibr" target="#b9">Gong and Li (2013)</ref> run PageRank algorithm to assign weights to words in translation evaluation. Different from these studies, the key interest of our research lies in the lexical selection with random walk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>This paper has presented a novel graph-based collective lexical selection method for SMT. We build translation graphs to capture local source- side associations and global target-side dependen- cies, and propose a purely collective inference al- gorithm to jointly identify target translations of source-side content words in translation graphs. Our method capitalizes on capabilities of transla- tion graphs to represent both local and global rela- tions on the source/target side. Experiment results demonstrate the effectiveness of our method.</p><p>In the future, we plan to further improve our model by capturing semantic relatedness among source words. Additionally, we also want to jointly model different levels of context informa- tion in a unified framework for SMT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>wèntí</head><label></label><figDesc>= {problem, question, issue ...} chíyŏu = {hold, null, possess ...} lìchăng = {stance, position ...} Tran: For this problem , two sides of the same or similar stance . Ref: Both sides hold the same or similar position on this issue .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Translation graph of the example shown in Figure 1. Relatedness scores on edges are shown for two group of translations {"problem", null, "stance"} (green) and {"issue", "hold", "position"} (blue), which are estimated with PMI. Note that the null node does not have any relations with other nodes. Besides, two translation combinations {"problem", null, "stance"} (green) and {"issue", "hold", "position"} (blue) have different strengths of relatedness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experiment results on the test sets using different reallocation weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Experiment results on the test sets with λ=0.15. Avg 
= average BLEU scores, GM(LM) and GM(PMI) denote our 
model using the measure based on language model and PMI, 
respectively. 

</table></figure>

			<note place="foot" n="2"> In this work, we consider nouns, verbs, adjectives and adverbs as content words in the source/target language.</note>

			<note place="foot" n="3"> http://people.sutd.edu.sg/∼yue zhang/doc/index.html 4 http://nlp.stanford.edu/software</note>

			<note place="foot" n="5"> We used 30 topics following (Xiao et al., 2012).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors were supported by National Nat-ural Science Foundation of China <ref type="table">(Grant Nos 61303082</ref> </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Joint language and translation modeling with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2013</title>
		<meeting>of EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1044" to="1054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation using word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="61" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Word sense disambiguation improves statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="201" to="228" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word association norms, mutual information, and lexicography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">Ward</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Better hypothesis testing for statistical machine translation: Controlling for optimizer instability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="176" to="181" />
		</imprint>
	</monogr>
	<note>short papers</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bilingual data cleaning for smt using graph-based random walk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2013</title>
		<meeting>of ACL 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast and robust neural network joint models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabih</forename><surname>Zbib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2014</title>
		<meeting>of ACL 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1370" to="1380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Random walks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Jagers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and Their Applications</title>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="331" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Documentlevel automatic machine translation evaluation based on weighted lexical cohesion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengxian</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangyou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NLPCC</title>
		<meeting>of NLPCC</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collective entity linking in web text: A graph-based method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR 2011</title>
		<meeting>of SIGIR 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Triplet lexicon models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesús</forename><surname>Andrés-Ferrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improving statistical machine translation using lexicalized rule selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="321" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Minimum translation modeling with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuening</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="20" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Recurrent continuous translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2013</title>
		<meeting>of EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1700" to="1709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT 2003</title>
		<meeting>of NAACL-HLT 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="127" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical significance tests for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Maximum entropy based rule selection model for syntax-based statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="89" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Extracting opinion targets and opinionwords from online reviews with graph co-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="314" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extending statistical machine translation with discriminative and trigger-based lexicon models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arne</forename><surname>Mauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2009</title>
		<meeting>of EMNLP 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="19" to="51" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Joseph</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2003</title>
		<meeting>of ACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2002</title>
		<meeting>of ACL 2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new string-to-dependency machine translation algorithm with a target dependency language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="577" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective use of linguistic and contextual information for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Matsoukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2009</title>
		<meeting>of EMNLP 2009</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="72" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Srilm-an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICSLP 2002</title>
		<meeting>of ICSLP 2002</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Translation modeling with bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamer</forename><surname>Alkhouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern</forename><surname>Wuebker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="14" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Encouraging consistent translation choices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferhan Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douglasw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT 2012</title>
		<meeting>of NAACL-HLT 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Document-level consistency verification in machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of MT SUMMIT 2011</title>
		<meeting>of MT SUMMIT 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="131" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A topic similarity model for hierarchical phrase-based translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouxun</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2012</title>
		<meeting>of ACL 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="750" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A sense-based translation model for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1459" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Enhancing language models in statistical machine translation with backward n-grams and mutual information triggers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL 2011</title>
		<meeting>of ACL 2011</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1288" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Modeling lexical cohesion for document-level machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lü</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCAI 2013</title>
		<meeting>of IJCAI 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2183" to="2189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Syntactic smt using a discriminative text generation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="177" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Improving pivot-based statistical machine translation using random walk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoning</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Conghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP 2013</title>
		<meeting>of EMNLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="524" to="534" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
