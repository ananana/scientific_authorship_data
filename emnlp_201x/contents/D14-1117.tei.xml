<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Graph and Corpus Driven Segmentation and Answer Inference for Telegraphic Entity-seeking Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
							<email>mandarj90@in.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department">IIT Bombay</orgName>
								<orgName type="laboratory">IIT Bombay, Yahoo Labs</orgName>
								<orgName type="institution">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uma</forename><surname>Sawant</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">IIT Bombay</orgName>
								<orgName type="laboratory">IIT Bombay, Yahoo Labs</orgName>
								<orgName type="institution">IBM Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
							<email>soumen@cse.iitb.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">IIT Bombay</orgName>
								<orgName type="laboratory">IIT Bombay, Yahoo Labs</orgName>
								<orgName type="institution">IBM Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge Graph and Corpus Driven Segmentation and Answer Inference for Telegraphic Entity-seeking Queries</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1104" to="1114"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
					<note>* Work done as Masters student at IIT Bombay</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Much recent work focuses on formal interpretation of natural question utterances, with the goal of executing the resulting structured queries on knowledge graphs (KGs) such as Freebase. Here we address two limitations of this approach when applied to open-domain, entity-oriented Web queries. First, Web queries are rarely well-formed questions. They are &quot;telegraphic&quot;, with missing verbs, prepositions, clauses, case and phrase clues. Second, the KG is always incomplete, unable to directly answer many queries. We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment: a base entity e 1 , a relation type r, a target entity type t 2 , and contextual words s. The query seeks entity e 2 ∈ t 2 where r(e 1 , e 2) holds, further evidenced by schema-agnostic words s. Query segmentation is integrated with the KG and an unstructured corpus where mentions of entities have been linked to the KG. We do not trust the best or any specific query segmentation. Instead, evidence in favor of candidate e 2 s are aggre-gated across several segmentations. Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG, using over a thousand telegraphic queries adapted from TREC, INEX, and Web-Questions, show the efficacy of our approach. For one benchmark, MAP improves from 0.2-0.29 (competitive base-lines) to 0.42 (our system). NDCG@10 improves from 0.29-0.36 to 0.54.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A majority of Web queries mention an entity or type ( , as users increasingly ex- plore the Web of objects using Web search. To better support entity-oriented queries, commercial Web search engines are rapidly building up large catalogs of types, entities and relations, popu- larly called a "knowledge graph" (KG) <ref type="bibr" target="#b9">(Gallagher, 2012)</ref>. Despite these advances, robust, Web-scale, open-domain, entity-oriented search faces many challenges. Here, we focus on two.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">"Telegraphic" queries</head><p>First, the surface utterances of entity-oriented Web queries are dramatically different from TREC- or Watson-style factoid question answering (QA), where questions are grammatically well-formed. Web queries are usually "telegraphic": they are short, rarely use function words, punctuations or clausal structure, and use relatively flexible word orders. E.g., the natural utterance "on the bank of which river is the Hermitage Museum lo- cated" may be translated to the telegraphic Web query hermitage museum river bank. Even on well-formed question utterances, 50% of in- terpretation failures are contributed by parsing or structural matching failures ( <ref type="bibr" target="#b15">Kwiatkowski et al., 2013)</ref>. Telegraphic utterances will generally be even more challenging.</p><p>Consequently, whereas TREC-QA/NLP-style research has focused on parsing and precise in- terpretation of a well-formed query sentence to a strongly structured (typically graph-oriented) query language ( <ref type="bibr" target="#b13">Kasneci et al., 2008;</ref><ref type="bibr">Pound et al., 2012;</ref><ref type="bibr" target="#b25">Yahya et al., 2012;</ref><ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b15">Kwiatkowski et al., 2013)</ref>, the Web search and in- formation retrieval (IR) community has focused on telegraphic queries ( <ref type="bibr" target="#b10">Guo et al., 2009;</ref><ref type="bibr" target="#b22">Sarkas et al., 2010;</ref><ref type="bibr" target="#b17">Li et al., 2011;</ref><ref type="bibr" target="#b23">Sawant and Chakrabarti, 2013)</ref>. In terms of target schema richness, these efforts may appear more modest. The act of query 'interpre- tation' is mainly a segmentation of query tokens by purpose. In the example above, one may re- port segments "Hermitage Museum" (a located ar- tifact or named entity), and "river bank" (the target type). This is reminiscent of record segmentation in information extraction (IE). Over well-formed utterances, IE baselines are quite competitive ). But here, we are interested exclusively in telegraphic queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Incomplete knowledge graph</head><p>The second problem is that the KG is always work in progress <ref type="bibr" target="#b20">(Pereira, 2013)</ref>, and connec- tions found within nodes of the KG, between the KG and the query, or the KG and unstructured text, are often incomplete or erroneous. E.g., Wikipedia is considered tiny, and Freebase rather small, compared to what is needed to answer all but the "head" queries. Google's Freebase an- notations ( <ref type="bibr" target="#b8">Gabrilovich et al., 2013</ref>) on ClueWeb (ClueWeb09, 2009) number fewer than 15 per page to ensure precision. Fewer than 2% are to entities in Freebase but not in Wikipedia.</p><p>It may also be difficult to harness the KG for answering certain queries. E.g., answering the query fastest odi century batsman, the intent of which is to find the batsman holding the record for the fastest century in One Day International (ODI) cricket, may be too difficult for most KG-only sys- tems, but may be answered quite effectively by a system that also utilizes evidence from unstruc- tured text.</p><p>There is a clear need for a "pay-as-you-go" ar- chitecture that involves both the corpus and KG. A query easily served by a curated KG should give accurate results, but it is desirable to have a grace- ful interpolation supported by the corpus: e.g., if the relation r(e 1 , e 2 ) is not directly evidenced in the KG, but strongly hinted in the corpus, we still want to use this for ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Our contributions</head><p>Here, we make progress beyond the above frontier of prior work in the following significant ways. We present a new architecture for structural in- terpretation of a telegraphic query into these seg- ments (some may be empty):</p><p>• Mention/s e 1 of an entity e 1 , • Mention r of a relation type r, • Mention t 2 of a target type t 2 , and</p><p>• Other contextual matching words s (some- times called selectors),</p><p>with the simultaneous intent of finding and rank- ing entities e 2 ∈ t 2 , such that r(e 1 , e 2 ) is likely to hold, evidenced near the matching words in un- structured text. Given the short, telegraphic query utterances, we limit our scope to at most one relation mention, unlike the complex mapping of clauses in well- formed questions to twig and join style queries (e.g., "find an actor whose spouse was an Italian bookwriter"). On the other hand, we need to deal with the unhelpful input, as well as consolidate the KG with the corpus for ranking candidate e 2 s. Despite the modest specification, our query tem- plate is quite expressive, covering a wide range of entity-oriented queries <ref type="bibr" target="#b28">(Yih et al., 2014</ref>).</p><p>We present a novel discriminative graphical model to capture the entity ranking inference task, with query segmentation as a by-product. Ex- tensive experiments with over a thousand entity- seeking telegraphic queries using the ClueWeb09 corpus and a subset of Freebase show that we can accurately predict the segmentation and intent of telegraphic relational queries, and simultaneously rank candidate responses with high accuracy. We also present evidence that the KG and corpus have synergistic salutary effects on accuracy.</p><p>§2 explores related work in more detail. §3 gives some examples fitting our query template, explains why interpreting some of them is nontriv- ial, and sets up notation. §4 presents our core tech- nical contributions. §5 presents experiments. Data can be accessed at http://bit.ly/Spva49 and http://bit.ly/WSpxvr.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The NLP/QA community has traditionally as- sumed that question utterances are grammatically well-formed, from which precise clause structure, ground constants, variables, and connective rela- tions can be inferred via semantic parsing <ref type="bibr" target="#b13">(Kasneci et al., 2008;</ref><ref type="bibr">Pound et al., 2012;</ref><ref type="bibr" target="#b25">Yahya et al., 2012;</ref><ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b15">Kwiatkowski et al., 2013</ref>) and translated to lambda expressions <ref type="bibr" target="#b1">(Liang, 2013)</ref> or SPARQL style queries ( <ref type="bibr" target="#b13">Kasneci et al., 2008)</ref>, with elaborate schema knowledge. Such approaches are often correlated with the as- sumption that all usable knowledge has been cu- rated into a KG. The query is first translated to a structured form and then "executed" on the KG. A  large corpus may be used to build relation expres- sion models ), but not as supporting evidence for target entities. In contrast, the Web and IR community gener- ally assumes a free-form query that is often tele- graphic ( <ref type="bibr" target="#b10">Guo et al., 2009;</ref><ref type="bibr" target="#b22">Sarkas et al., 2010;</ref><ref type="bibr" target="#b17">Li et al., 2011</ref>). Queries being far more noisy, the goal of structure discovery is more modest, and of- ten takes the form of a segmentation of the query regarded as a token sequence, assigning a broad purpose ( ) to each segment, mapping them probabilistically to a relatively loose schema, and ranking responses in conjunction with segmentations <ref type="bibr" target="#b23">(Sawant and Chakrabarti, 2013)</ref>. To maintain quality in the face of noisy input, these approaches often additionally exploit clicks ( <ref type="bibr" target="#b17">Li et al., 2011</ref>) or a corpus that has been annotated with entity mentions <ref type="bibr" target="#b5">(Cheng and Chang, 2010;</ref><ref type="bibr" target="#b16">Li et al., 2010</ref>). The corpus provides contextual snippets for queries where the KG fails, preventing the systems from falling off the "struc- ture cliff" <ref type="bibr" target="#b20">(Pereira, 2013)</ref>.</p><p>Our work advances the capabilities of the lat- ter class of approaches, bringing them closer to the depth of the former, while handling telegraphic queries and retaining the advantage of corpus evi- dence over and above the KG. Very recently, ( ) have concluded that for current bench- marks, deep parsing and shallow information ex- traction give comparable interpretation accuracy. The very recent work of ( <ref type="bibr" target="#b28">Yih et al., 2014</ref>) is simi- lar in spirit to ours, but they do not unify segmen- tation and answer inference, along with corpus ev- idence, like we do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Notation and examples</head><p>We use e 1 , r, t 2 , e 2 to represent abstract nodes and edges (MIDs in case of Freebase) from the KG, and e 1 , r, t 2 to represent their textual mentions or hints, if any, in the query. s is a set of uninterpreted textual tokens in the query that are used to match and collect corpus contexts that lend evidence to candidate entities. <ref type="figure" target="#fig_0">Figure 1</ref> shows some telegraphic queries with possible segmentation into the above parts.</p><p>Consider another example: dave navarro first band.</p><p>'Band' is a hint for type /music/musical group, so it com- prises t 2 . Dave Navarro is an entity, with men- tion words 'dave navarro' comprising e 1 . r is made up of 'band', and represents the relation /music/group member/membership. Fi- nally, the word first cannot be mapped to any sim- ple KG artifact, so are relegated to s (which makes the corpus a critical part of answer inference). We use s and s interchangeably. Generally, there will be enough noise and uncer- tainty that the search system should try out several of the most promising segmentations as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The accuracy of any specific segmenta- tion is expected to be low in such adversarial set- tings. Therefore, support for an answer entity is aggregated over several segmentations. The ex- pectation is that by considering multiple interpre- tations, the system will choose the entity with best supporting evidence from corpus and knowledge base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>Telegraphic queries are usually short, so we enu- merate query token spans (with some restrictions, similar to beam search) to propose segmentations ( §4.1). Candidate response entities are lined up for each interpretation, and then scored in a global model along with query segmentations ( §4.2).</p><p>§4.3 describes how model parameters are trained.</p><p>1: input: query token sequence q 2: initialize segmentations I = ∅ 3: E 1 = (entity, mention) pairs from linker 4: for all (e 1 , e 1 ) ∈ E 1 do 5:</p><p>assign label E 1 to mention tokens e 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>for all contiguous span v ⊂ q \ e 1 do 7:</p><p>label each word w ∈ v as T 2 R 8:</p><p>label other words w ∈ q \ e 1 \ v as S 9:</p><p>add segments (E 1 , T 2 R, S) to I 10:</p><p>end for 11: end for 12: return candidate segmentations I <ref type="figure">Figure 2</ref>: Generating candidate query segmenta- tions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generating candidate query segmentations</head><p>Each query token can have four labels, E 1 , T 2 , R, S, corresponding to the mentions of the base entity, target type, connecting relation, and context words. We found that segments hinting at T 2 and R frequently overlapped (e.g., 'author' in the query zhivago author).</p><p>In our implementation, we simplified to three labels, E 1 , T 2 R, S, where tokens labeled T 2 R are involved with both t 2 and r, the proposed structured target type and connecting relation. Another reasonable assumption was that the base entity mention and type/relation mentions are contiguous token spans, whereas context words can be scattered in multiple segments. <ref type="figure">Figure 2</ref> shows how candidate segmentations are generated. For step 3, we use TagMe <ref type="bibr" target="#b7">(Ferragina and Scaiella, 2010)</ref>, an entity linker backed by an entity gazette derived from our KG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Graphical model</head><p>Based on the previous discussion, we assume that an entity-seeking query q is a sequence of tokens q 1 , q 2 , . . ., and this can be partitioned into different kinds of subsequences, corresponding to e 1 , r, t 2 and s, and denoted by a structured (vector) label- ing z = z 1 , z 2 , . . .. Given sequences q and z, we can separate out (possibly empty) token segments e 1 (q, z), t 2 (q, z), r(q, z), and s(q, z). A query segmentation z becomes plausible in conjunction with proposals for e 1 , r, t 2 and e 2 from the KG. The probability Pr(z, e 1 , r, t 2 , e 2 |q) is modeled as proportional to the product of sev- eral potentials <ref type="bibr" target="#b14">(Koller and Friedman, 2009</ref>) in a graphical model. In subsequent subsections, we will present the design of specific potentials.</p><p>• Ψ R (q, z, r) denotes the compatibility be- tween the relation hint segment r(q, z) and a proposed relation type r in the KG ( §4.2.1).</p><p>• Ψ T 2 (q, z, t 2 ) denotes the compatibility be- tween the type hint segment t 2 (q, z) and a proposed target entity type t 2 in the KG ( §4.2.2).</p><p>• Ψ E 1 ,R,E 2 ,S (q, z, e 1 , r, e 2 ) is a novel corpus- based evidence potential that measures how strongly e 1 and e 2 appear in corpus snippets in the proximity of words in s(q, z), and ap- parently related by relation type r ( §4.2.3).</p><p>• Ψ E 1 (q, z, e 1 ) denotes the compatibility be- tween the query segment e 1 (q, z) and entity e 1 that it purportedly mentions ( §4.2.4).</p><p>• Ψ S (q, z) denotes selector compatibility. Se- lectors are a fallback label, so this is pinned arbitrarily to 1; other potentials are balanced against this base value.</p><p>• Ψ E 1 ,R,E 2 (e 1 , r, e 2 ) is A if the relation r(e 1 , e 2 ) exists in the KG, and is B &gt; 0 oth- erwise, for tuned/learnt constants A &gt; B &gt; 0. Note that this is a soft constraint (B &gt; 0); if the KG is incomplete, the corpus may be able to supplement the required information.</p><p>• Ψ E 2 ,T 2 (e 2 , t 2 ) is 1 if e 2 belongs to t 2 and zero otherwise. In other words, candidate e 2 s must be proposed to be instances of the pro- posed t 2 -this is a hard constraint, but can be softened if desired, like Ψ E 1 ,R,E 2 . <ref type="figure">Figure 3</ref> shows the relevant variable states as circled nodes, and the potentials as square factor nodes. To rank candidate entities e 2 , we pin the node E 2 to each entity in turn. With E 2 pinned, we perform a MAP inference over all other hidden variables and note the score of e 2 as the product of the above potentials maximized over choices of all other variables: score(e 2 ) = max z,t 2 ,r,e 1 Ψ T 2 (q, z, t 2 )Ψ R (q, z, r)</p><formula xml:id="formula_0">Ψ E 1 (q, z, e 1 )Ψ S (q, z) Ψ E 2 ,T 2 (e 2 , t 2 )Ψ E 1 ,R,E 2 (e 1 , r, e 2 ) Ψ E 1 ,R,E 2 ,S (q, z, e 1 , r, e 2 ).<label>(1)</label></formula><p>We rank candidate e 2 s by decreasing score, which is estimated by max-product message-passing ( <ref type="bibr" target="#b14">Koller and Friedman, 2009</ref> Corpus-assisted entity-relation evidence potential</p><p>Figure 3: Graphical model for query segmentation and entity scoring. Factors/potentials are shown as squares. A candidate e 2 is observed and scored using equation <ref type="formula" target="#formula_0">(1)</ref>. Query q is also observed but not shown to reduce clutter; most potentials depend on it.</p><p>this case, we allow each of the entity, relation or target type nodes in the graphical to take the value ⊥ or 'null'. To support this, the value of the fac- tor between the query segmentation node Z and Ψ E1 (q, z, e 1 ), Ψ T 2 (q, z, t 2 ), and Ψ R (q, z, r)) are set to suitable low values. Next, we will describe the detailed design of some of the key potentials introduced above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Relation language model for Ψ R</head><p>Potential Ψ R (q, z, r) captures the compatibility between r(q, z) and the proposed relation r. E.g., if the query is steve jobs death rea- son, and r is (correctly chosen as) death rea- son, then the correct candidate r is /people/ deceased_person/cause_of_death. An incorrect r is /people/deceased_person/ place_of_death. An incorrect z may lead to r(q, z) being jobs death.</p><p>Using corpus: Considerable variation may exist in how r is represented textually in a query. The relation language model needs to build a bridge between the formal r and the textual r, so that (un)likely r's have (small) large potential. Many approaches ( <ref type="bibr" target="#b1">Berant et al., 2013;</ref><ref type="bibr" target="#b0">Berant and Liang, 2014;</ref><ref type="bibr" target="#b15">Kwiatkowski et al., 2013;</ref><ref type="bibr" target="#b28">Yih et al., 2014</ref>) to this problem have been intensely studied re- cently. Given our need to process billions of Web pages efficiently, we chose a pattern-based ap- proach ( <ref type="bibr" target="#b19">Nakashole et al., 2012</ref>): with each r, dis- cover the most strongly associated phrase patterns from a reference corpus, then mark these patterns into much larger payload corpus.</p><p>We started with the 2000 (out of approximately 14000) most frequent relation types in Freebase, and the ClueWeb09 corpus annotated with Free- base entities ( <ref type="bibr" target="#b8">Gabrilovich et al., 2013</ref>). For each triple instance of each relation type, we located all corpus sentences that mentioned both participat- ing entities. We made the crude assumption that if r(e 1 , e 2 ) holds and e 1 , e 2 co-occur in a sen- tence then this sentence is evidence of the rela- tionship. Each such sentence is parsed to obtain a dependency graph using the Malt Parser ( <ref type="bibr" target="#b11">Hall et al., 2014</ref>). Words in the path connecting the entities are joined together and added to a candi- date phrase dictionary, provided the path is at most three hops. (Inspection suggested that longer de- pendency paths mostly arise out of noisy sentences or botched parses.) 30% of the sentences were thus retained. Finally, we defined</p><formula xml:id="formula_1">Ψ R (q, z, r) = n(r, r(q, z)) p n(r, p ) ,<label>(2)</label></formula><p>where p ranges over all phrases that are known to hint at r, and n(r, p) denotes the number of sen- tences where the phrase p occurred in the depen- dency path between the entities participating in re- lation r.</p><p>Assuming entity co-occurrence implies evi- dence is admittedly simplistic. However, the pri- mary function of the relation model is to retrieve top-k relations that are compatible with the type/s of e 1 and the given relation hint. Moreover, the remaining noise is further mitigated by the collec- tive scoring in the graphical model. While we may miss relations if they are expressed in the query through obscure hints, allowing the relation to be ⊥ acts as a safety net.</p><p>Using Freebase relation names: As mentioned earlier, queries may express relations differently as compared to the corpus. A relation model based solely on corpus annotations may not be able to bridge that gap effectively, particularly so, because of sparsity of corpus annotations or the rarity of Freebase triples in ClueWeb. E.g., for the Freebase relation /people/person/profession, we found very few annotated sentences. One way to address this problem is to utilize relation type names in Freebase to map hints to relation types. Thus, in addition to the corpus-derived relation model, we also built a language model that used Freebase relation type names as lemmas. E.g., the word 'profession' would contribute to the relation type /people/person/profession.</p><p>Our relation models are admittedly simple. This is mainly because telegraphic queries may ex- press relations very differently from natural lan- guage text. As it is difficult to ensure precision of query interpretation stage, our models are geared towards recall. The system generates a large num- ber of interpretations and relies on signals from the corpus and KG to bring forth correct interpre- tations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Type language model for Ψ T 2</head><p>Similar to the relation language model, we need a type language model to measure compatibil- ity between t 2 and t 2 (q, z). Estimating the tar- get entity type, without over-generalizing or over- specifying it, has always been important for QA. E.g., when t 2 is 'city', a good type language model should prefer t 2 as /location/citytown over /location/location while avoiding /location/es_autonomous_city.</p><p>A catalog like Freebase suggests a straight- forward method to collect a type language model. Each type is described by one or more phrases through the link /common/topic/alias. We can collect these into a micro-'document' and use a standard Dirichlet-smoothed language model from IR <ref type="bibr" target="#b31">(Zhai, 2008)</ref>. In Freebase, an entity node (e.g., Einstein, /m/0jcx) may be linked to a type node (e.g. /base/scientist/ physicist) using an edge with label /type/ object/type.</p><p>But relation types provide additional clues to types of the endpoint entities. Freebase relation types have the form /x/y/z, where x is the domain of the relation, and y and z are string representations of the type of the entities partic- ipating in the relation. E.g., the (directed) re- lation type /location/country/capital connects from from /location/country to /location/citytown. Therefore, "capital" can be added to the set of descriptive phrases of entity type /location/citytown.</p><p>It is important to note that while we use Free- base link nomenclature for relation and type lan- guage models, our models are not incompati- ble with other catalogs. Indeed, most catalogs have established ways of deriving language mod- els that describe their various structures. For ex- ample, most YAGO types are derived from Word- Net synsets with associated phrasal descriptions (lemmas). YAGO relations also have readable names such as actedIn, isMarriedTo, etc. which can be used to estimate language models. DB- Pedia relations are mostly derived from (mean- ingfully) named attributes taken from infoboxes, hence they can be used directly. Furthermore, oth- ers ( <ref type="bibr" target="#b24">Wu and Weld, 2007)</ref> have shown how to asso- ciate language models with such relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Snippet scoring</head><p>The factor Ψ E 1 ,R,E 2 ,S (q, z, e 1 , r, e 2 ) should be large if many snippets contain a mention of e 1 and e 2 , relation r, and many high-signal words from s. Recall that we begin with a corpus annotated with entity mentions. Our corpus is not directly anno- tated with relation mentions. Therefore, we get from relations to documents via high-confidence phrases. Snippets are retrieved using a combined entity + word index, and scored for a given e 1 , r, e 2 , and selectors s(q, z). Given that relation phrases may be noisy and that their occurrence in the snippet may not nec- essarily mean that the given relation is being ex- pressed, we need a scoring function that is cog- nizant of the roles of relation phrases and enti- ties occurring in the snippets. In a basic ver- sion, e 1 , p, e 2 , s are used to probe a combined en- tity+word index to collect high scoring snippets, with the score being adapted from BM25. The sec- ond, refined scoring function used a RankSVM-style <ref type="bibr" target="#b12">(Joachims, 2002</ref>) optimization. </p><formula xml:id="formula_2">λ 2 + C e + ,e − ξ e + ,e − s.t. ∀e + , e − : λ · f (q, D e + , e + ) + ξ e + ,e − (3) ≥ λ · f (q, D e − , e − ) + 1.</formula><p>where e + and e − are positive and negative enti- ties for the query q and f (q, D e , e) represents the feature map for the set of snippets D e belonging to entity e. The assumption here is that all snip- pets containing e + are "positive" snippets for the query. f consolidates various signals like the num- ber of snippets where e occurs near query entity e 1 and a relation phrase, or the number of snippets with high proportion of query IDF, hinting that e is a positive entity for the given query. A partial list of features used for snippet scoring is given in <ref type="figure" target="#fig_2">Figure 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Query entity model</head><p>Potential Ψ E 1 (q, z, e 1 ) captures the compatibil- ity between e 1 (q, z) (i.e., the words that mention e 1 ) and the claimed entity e 1 mentioned in the query. We used the TagMe entity linker <ref type="bibr" target="#b7">(Ferragina and Scaiella, 2010)</ref> for annotating enti- ties in queries. TagMe annotates the query with Wikipedia entities, which we map to Freebase, and use the annotation confidence scores as the poten- tial Ψ E 1 (q, z, e 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discriminative parameter training with latent variables</head><p>We first set the potentials in (1) as explained in §4.2 (henceforth called 'Unoptimized'), and got encouraging accuracy. Then we rewrote each po- tential as</p><formula xml:id="formula_3">Ψ • (· · · ) = exp w • · φ • (· · · )<label>(4)</label></formula><p>or log</p><formula xml:id="formula_4">• Ψ • (· · · ) = • w • · φ • (· · · ),</formula><p>with w • being a weight vector for a specific poten- tial •, and φ • being a corresponding feature vector.</p><p>During inference, we seek to maximize max q,z,e 1 ,t 2 ,r w · φ(q, z, e 1 , t 2 , r, e 2 ),</p><p>for a fixed w, to find the score of each candidate entity e 2 . Here all w • and φ • have been collected into unified weight and feature vectors w, φ. Dur- ing training of w, we are given pairs of correct and incorrect answer entities e + 2 , e − 2 , and we wish to satisfy constraints of the form</p><formula xml:id="formula_6">max q,z,e 1 ,t 2 ,r w · φ(q, z, e 1 , t 2 , r, e + 2 ) + ξ (6) ≥ 1 + max q,z,e 1 ,t 2 ,r w · φ(q, z, e 1 , t 2 , r, e − 2 ),</formula><p>because collecting e + 2 , e − 2 pairs is less work than supervising with values of z, e 1 , t 2 , r, e 2 for each query. Similar distant supervision problems were posed via bundle method by <ref type="bibr" target="#b2">(Bergeron et al., 2008)</ref>, and ( <ref type="bibr" target="#b29">Yu and Joachims, 2009)</ref>, who used CCCP ( <ref type="bibr" target="#b30">Yuille and Rangarajan, 2006</ref>). These are equivalent in our setting. We use the CCCP style, and augment the objective with an additional en- tropy term as in <ref type="bibr" target="#b23">(Sawant and Chakrabarti, 2013)</ref>. We call this LVDT (latent variable discriminative training) in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Testbed</head><p>Corpus and knowledge graph: We used the ClueWeb09B (ClueWeb09, 2009) corpus contain- ing 50 million Web documents. This corpus was annotated by Google with Freebase enti- ties ( <ref type="bibr" target="#b8">Gabrilovich et al., 2013</ref>). The average page contains 15 entity annotations from Freebase. We used the Freebase KG and its links to Wikipedia.</p><p>Queries: We report on two sets of entity-seeking queries. A sample of about 800 well-formed queries from WebQuestions ( <ref type="bibr" target="#b1">Berant et al., 2013)</ref> were converted to telegraphic utterances (such as would be typed into commercial search engines) by volunteers familiar with Web search. We call this WQT (WebQuestions, telegraphic). Queries are accompanied by ground truth entities. The second data set, TREC-INEX, from <ref type="bibr" target="#b23">(Sawant and Chakrabarti, 2013</ref>) has about 700 queries sam- pled from TREC and INEX, available at http: //bit.ly/WSpxvr. These come with well- formed and telegraphic utterances, as well as ground truth entities.</p><p>There are some notable differences between these query sets. For WQT, queries were gener- ated by using Google's query suggestions inter- face. Volunteers were asked to find answers using single Freebase pages. Therefore, by construction, queries retained can be answered using the Free- base KG alone, with a simple r <ref type="figure" target="#fig_0">(e 1 , ?)</ref> form. In contrast, TREC-INEX queries provide a balanced mix of t 2 and r hints in the queries, and direct an- swers from triples is relatively less available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation details</head><p>On an average, the pseudocode in <ref type="figure">Figure 2</ref> generated 13 segmentations per query, with longer queries generating more segmentations than shorter ones.</p><p>We used an MG4J ( <ref type="bibr" target="#b3">Boldi and Vigna, 2005</ref>) based query processor, written in Java, over en- tity and word indices on ClueWeb09B. The in- dex supplies snippets with a specified maximum width, containing a mention of some entity and satisfying a WAND ( <ref type="bibr" target="#b4">Broder et al., 2003</ref>) predi- cate over words in s. In case of phrases in the query, the WAND threshold was computed by adding the IDF of constituent words. The index returned about 330,000 snippets on average for WAND threshold of 0.6.</p><p>We retained the top 200 candidate entities from the corpus; increasing this horizon did not give benefits. We also considered as candidates for e 2 those entities that are adjacent to e 1 in the KG via top-scoring r candidates. In order to gener- ate supporting snippets for an interpretation con- taining entity annotation e, we need to match e with Google's corpus annotations. However, re- lying solely on corpus annotations fails to retrieve many potential evidence snippets, because entity annotations are sparse. Therefore we probed the token index with the textual mention of e 1 in the query; this improved recall.</p><p>We also investigated the feasibility of our pro- posals for interactive search. There are three major processes involved in answering a query -gener- ating potential interpretations, collecting/scoring snippets, and inference (MAP for Unoptimized and wφ(·) for LVDT). For the WQT dataset, av- erage time per query for each stage was approx- imately -0.2, 16.6 and 1.3 seconds respectively. Our (Java) code did not optimize the bottleneck at all; only 10 hosts and no clever load balancing were used. We believe commercial search engines can cut this down to less than a second.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Research questions</head><p>In the rest of this section we will address these questions:</p><p>• For telegraphic queries, is our entity-relation- type-selector segmentation better than the type-selector segmentation of (Sawant and Chakrabarti, 2013)? • When semantic parsers <ref type="bibr" target="#b1">(Berant et al., 2013;</ref><ref type="bibr" target="#b15">Kwiatkowski et al., 2013</ref>) are subjected to telegraphic queries, how do they perform compared to our proposal? • Are the KG and corpus really complementary as regards their support of accurate ranking of candidate entities? • Is the prediction of r and t 2 from our ap- proach better than a greedy assignment based on local language models?</p><p>We also discuss anecdotes of successes and fail- ures of various systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Benefits of relation in addition to type</head><p>Figure 5 shows entity-ranking MAP, MRR, and NDCG@10 (n@10) for two data sets and vari- ous systems. "No interpretation" is an IR baseline without any KG. Type+selector is our implemen- tation of <ref type="bibr" target="#b23">(Sawant and Chakrabarti, 2013)</ref>. Unopti- mized and LVDT both beat "no interpretation" and "type+selector" by wide margins. (Boldface im- plies best performing formulation.) There are two notable differences between S&amp;C and our work. First, S&amp;C do not use the knowledge graph (KG) and rely on a noisy corpus. This means S&amp;C fails to answer queries whose answers are found only in KG. This can be seen from WQT results; they perform only slightly better than the baseline. Sec- ond, even for queries that can be answered through the corpus alone, S&amp;C miss out on two important signals that the query may provide -namely the query entity and the relation. Our framework not only provides a way to use a curated and high pre- cision knowledge graph but also attempts to pro- vide more reachability to corpus by the use of re- lational phrases. Figure 5: 'Entity-relation-type-selector' segmen- tation yields better accuracy than 'type-selector' segmentation.</p><p>objective makes matters worse. The bias in our unoptimized model circumvents training noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Comparison with semantic parsers</head><p>For TREC-INEX, both unoptimized and LVDT beat SEMPRE ( <ref type="bibr" target="#b1">Berant et al., 2013</ref>) convinc- ingly, whether it is trained with Free917 or Web- Questions ( <ref type="figure" target="#fig_3">Figure 6</ref>). SEMPRE's relatively poor performance, in this case, is explained by its complete reliance on the knowledge graph. As discussed previously, the TREC-INEX dataset contains a sizable proportion of queries that may be difficult to answer using a KG alone. When SEMPRE is compared with our systems with a telegraphic sample of Web- Questions (WQT), results are mixed. Our Unop- timized model still compares favorably to SEM- PRE, but with slimmer gains. As before, LVDT falls behind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Formulation map mrr n@10 SEMPRE(Free917  Our smaller gains over SEMPRE in case of WebQuestions is explained by how WebQuestions was assembled <ref type="bibr" target="#b1">(Berant et al., 2013)</ref>. Although Google's query suggestions gave an eclectic pool, only those queries survived that could be answered using a single Freebase page, which effectively re- duced the role of a corpus. In fact, a large frac- tion of WQT queries cannot be answered well us- ing the corpus alone, because FACC1 annotations are too sparse and rarely cover common nouns and phrases such as 'democracy' or 'drug overdose' which are needed for some WQT queries.</p><p>For WQT, our system also compares favorably with Jacana ( ). Given that they subject their input to natural langauge parsing, their relatively poor performance is not unsurprsing. <ref type="figure" target="#fig_4">Figure 7</ref> shows the synergy between the corpus and the KG. In all cases and for all metrics, using the corpus and KG together gives superior perfor- mance to using any of them alone. However, it is instructive that in case of TREC-INEX, corpus- only is better than KG-only, whereas this is re- versed for WQT, which also supports the above argument.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Complementary benefits of KG &amp; corpus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data</head><p>Formulation map mrr n@10  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Collective vs. greedy segmentation</head><p>To judge the quality of interpretations, we asked paid volunteers to annotate queries with an appro- priate relation and type, and compared them with the interpretations associated with top-ranked en- tities. Results in <ref type="figure">Figure 8</ref> indicate that in spite of noisy relation and type language models, our formulations produce high quality interpretations through collective inference. <ref type="figure">Figure 9</ref> demonstrates the benefit of collective inference over greedy segmentation followed by Type Relation Type/Rel Unoptimized <ref type="table">(top 1) 23  49  60  Unoptimized (top 5) 29  57  68  LVDT (top 1)  25  52  61  LVDT (top 5)</ref> 33 61 69</p><p>Figure 8: Fraction of queries (%) with correct in- terpretations of t 2 , r, and t 2 or r, on TREC-INEX. Figure 9: Collective vs. greedy segmentation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Discussion</head><p>Closer scrutiny revealed that collective infer- ence often overcame errors in earlier stages to produce a correct ranking over answer en- tities. E.g., for the query automobile com- pany makes spider the entity disambiguation stage fails to identify the car Alfa Romeo Spi- der (/m/08ys39). However, the interpretation stage recovers from the error and segments the query with Automobile (/m/0k4j) as the query entity e 1 , /organization/organization and /business/industry/companies as target type t 2 and relation r respectively (from the relation/type hint 'company'), and spider as se- lector to arrive at the correct answer Alfa Romeo (/m/09c50). The corpus features also play a cru- cial role for queries which may not be accurately represented with an appropriate logical formula. For the query meg ryan bookstore movie, the textual patterns for the relation ActedIn in con- junction with the selector word 'bookstore' cor- rectly identifies the answer entity You've Got Mail (/m/014zwb).</p><p>We also analyzed samples of queries where our system did not perform particularly well. We observed that one of the recurring themes of these queries was that their answer enti- ties had very little corpus support, and the type/relation hint mapped to too many or no candidate type/relations. For example, in the query south africa political system, the rel- evant type/relation hint 'political system' could not be mapped to /government/form_of_ government and /location/country/ form_of_government respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example queries and some potential segmentations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Sample features used for learning weights λ to score snippets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Comparison with semantic parsers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Synergy between KB and corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Comparison of various approaches for NDCG at rank 1 to 10, TREC-INEX dataset</figDesc><graphic url="image-1.png" coords="10,72.00,599.37,227.14,124.99" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and future work</head><p>We presented a technique to partition telegraphic entity-seeking queries into functional segments and to rank answer entities accordingly. While our results are favorable compared to strong prior art, further improvements may result from relax-ing our model to recognize multiple e 1 s and rs. It may also help to deploy more sophisticated para-phrasing models <ref type="bibr" target="#b0">(Berant and Liang, 2014</ref>) or word embeddings ( <ref type="bibr" target="#b28">Yih et al., 2014</ref>) for relation hints. It would also be interesting to supplement entity-linked corpora and curated KGs with extracted triples <ref type="bibr" target="#b6">(Fader et al., 2014</ref>). Another possibility is to apply the ideas presented here to well-formed questions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple instance ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jed</forename><surname>Zaretzki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Curt</forename><surname>Breneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
		<title level="m">TREC, number SP 500-266 in Special Publications. NIST</title>
		<editor>Ellen M. Voorhees and Lori P. Buckland</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>MG4J at TREC 2005</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient query evaluation using a two-level retrieval process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">Z</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Herscovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aya</forename><surname>Soffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Beyond pages: supporting efficient, scalable entity search with dual-inversion index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin Chen-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<ptr target="http://www.lemurproject.org/clueweb09.php/" />
	</analytic>
	<monogr>
		<title level="j">In EDBT. ACM. ClueWeb09</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">TAGME: on-the-fly annotation of short text fragments (by wikipedia entities). CoRR/arXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><surname>Scaiella</surname></persName>
		</author>
		<idno>abs/1006.3498</idno>
		<ptr target="http://arxiv.org/abs/1006.3498" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">FACC1: Freebase annotation of ClueWeb corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<ptr target="http://lemurproject.org/clueweb12/" />
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="2013" to="2019" />
		</imprint>
	</monogr>
	<note>Version 1 (Release date. Format version 1, Correction level 0</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">How Google and Microsoft taught search to &apos;understand&apos; the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gallagher</surname></persName>
		</author>
		<ptr target="http://goo.gl/NWs0zT" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Named entity recognition in query</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="267" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<ptr target="http://www.maltparser.org/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Optimizing search engines using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">NAGA: Searching and ranking knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Ifrim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<editor>ICDE. IEEE</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Conference</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1545" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">EntityEngine: Answering entity-relationship queries using shallow semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM, October. (demo)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised query segmentation using clickthrough for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Jun Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.4408</idno>
		<ptr target="http://arxiv.org/abs/1309.4408" />
	</analytic>
	<monogr>
		<title level="m">SIGIR Conference</title>
		<imprint>
			<publisher>ACM. Percy Liang</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
	<note>Lambda dependencybased compositional semantics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Active objects: Actions for entity-centric search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anitha</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Fuxman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PATTY: A taxonomy of relational patterns with semantic types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndapandula</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Conference</title>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1135" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mining entity types from query logs via user intent modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Conference</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="563" to="571" />
		</imprint>
	</monogr>
	<note>Meaning in the wild. Invited talk at EMNLP Conference</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Interpreting keyword queries over Web knowledge bases</title>
		<ptr target="http://hum.csse.unimelb.edu.au/emnlp2013/invited-talks.html" />
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<editor>Jeffrey Pound, Alexander K. Hudek, Ihab F. Ilyas, and Grant Weddell</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Structured annotations of Web queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Sarkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Stelios Paparizos, and Panayiotis Tsaparas</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>SIGMOD Conference</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning joint query interpretation and response ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uma</forename><surname>Sawant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Conference</title>
		<meeting><address><addrLine>Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatically semantifying Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="41" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Natural language questions for the Web of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shady</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Conference</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="379" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with Freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Conference. ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Freebase QA: Information extraction or semantic parsing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2014 Workshop on Semantic Parsing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic parsing for single-relation question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Wen-Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL Conference. ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning structural SVMs with latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Nam John</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1169" to="1176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The concave-convex procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="915" to="936" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Statistical language models for information retrieval: A critical review. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008-03" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="137" to="213" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
