<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:34+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting the Structure of Cooking Recipes</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jermsak</forename><surname>Jermsurawong</surname></persName>
							<email>{jermsak.jermsurawong,nizar.habash}@nyu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
						</author>
						<title level="a" type="main">Predicting the Structure of Cooking Recipes</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
					<note>Computational Approaches to Modeling Language Lab Computer Science New York University Abu Dhabi United Arab Emirates</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Cooking recipes exist in abundance; but due to their unstructured text format, they are hard to study quantitatively beyond treating them as simple bags of words. In this paper, we propose an ingredient-instruction dependency tree data structure to represent recipes. The proposed representation allows for more refined comparison of recipes and recipe-parts, and is a step towards semantic representation of recipes. Furthermore, we build a parser that maps recipes into the proposed representation. The parser&apos;s edge prediction accuracy of 93.5% improves over a strong baseline of 85.7% (54.5% error reduction).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cooking recipes are a specific genre of how-to in- structions which have been gaining interest in re- cent years as they may allow us to discover in- sights into culinary and cultural preferences. Most of the work studying recipes relies on simple in- gredient bag-of-word representations. While such representations may suffice for many purposes, they fail to capture much of the recipes' internal structure. A smaller number of efforts focus on se- mantic representations of cooking recipes with an eye toward more complex and deep understand- ing. Natural language processing (NLP) tech- niques have been used to interpret cooking instruc- tions; however, the results have not been as suc- cessful as other language genres due to the unique aspects of cooking recipes.</p><p>This paper makes two contributions. First, we propose an ingredient-instruction dependency tree representation of recipe structure. This represen- tation abstracts textual recipes more expressively than bag-of-word representations; and it allows for more nuanced comparisons of recipes. Second, we present a cooking recipe parser that maps text recipes into our proposed ingredient-instruction tree structures. The overall accuracy of predicting edges of our ingredient-instruction trees is 93.5%, beating a strong baseline of 85.7%, and achieving a relative error reduction of 54.5%.</p><p>We present next some related work (Section 2) followed by a discussion of the structure of recipes and our representation (Section 3). Section 4 de- tails the recipe parser design, implementation and evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been many efforts on the processing of cooking recipes using models that range from bags of words to complex semantic representations.</p><p>Among the approaches to studying recipes as ingredient bags of words, Ahn et al. (2011) con- structed a data-driven flavor network relating in- gredients together. <ref type="bibr" target="#b5">Jain et al. (2015</ref><ref type="bibr">) adopted Ahn et al. (2011</ref>'s framework to further analyze culi- nary practices of specific cultures. <ref type="bibr" target="#b10">Nedovic (2013)</ref> examined underlying ingredient groupings from their recipe co-occurrences, using topic modeling techniques (latent Dirichlet allocation), and fur- ther improvised novel ingredient combinations us- ing deep belief networks.</p><p>Among the structured representation ap- proaches, <ref type="bibr" target="#b12">Tasse and Smith (2008)</ref> proposed MILK (Minimal Instruction Language for the Kitchen), a formal language to describe actions required in directive cooking instructions. They used MILK in developing CURD (Carnegie Mellon University Recipe Database), a corpus of manually annotated recipes. <ref type="bibr" target="#b9">Mori et al. (2014)</ref> also manually annotated the procedural flow of Japanese cooking recipes using directed acyclic graphs (DAGs) where graph nodes correspond to food ingredients, cooking instruments, and actions. <ref type="bibr" target="#b12">Tasse and Smith (2008)</ref> had limited success in parsing into <ref type="bibr">MILK;</ref><ref type="bibr" target="#b9">and Mori et al. (2014)</ref> did not report on parsing experiments.</p><p>Other studies explored different machine learn- ing and NLP techniques to processing recipes.</p><formula xml:id="formula_0">Text Recipe SIMMR ingredients inst9 inst8 inst7 inst6 inst4 inst1 inst0 ing0 french bread inst3 inst2 ing1 ricotta ing2 cottage ing3 cream cheese ing4 sugar ing5 vanilla inst5 ing6</formula><p>egg ing7 milk 0 6 (2 inch thick) slices French bread 1 1/4 cup ricotta cheese 2 1/4 cup cottage cheese, whipped 3 2 tablespoons lowfat cream cheese 4 2 teaspoons white sugar 5 2 teaspoons vanilla extract 6 3 cups egg substitute 7 1/4 cup evaporated milk instructions 0 Cut a pocket in each slice of bread. 1 Open carefully 2 In a large bowl, combine the ricotta, cottage cheese and cream cheese. 3 Add the sugar and flavoring extract and beat until smooth. 4 Spread the mixture evenly into each bread pocket. 5 Beat together the egg substitutes and milk. 6 Dip the slices of bread in the egg mixture. 7 Heat a nonstick pan over medium-high heat. 8 Coat with cooking spray. 9 Cook the toast on each side for about 3 to 4 minutes per side until golden brown. Most recently, <ref type="bibr" target="#b0">Abend et al. (2015)</ref> proposed an edge-factored model to determine the likely tem- poral order of events based solely on the identity of their predicates and arguments. They demon- strated their approach on recipe text, under the simplifying assumption that such text is also tem- porally ordered.</p><p>In this paper, we present an ingredient- instruction dependency tree representation of recipe structure, which we call SIMMR (Simpli- fied Ingredient Merging Map in Recipes). The SIMMR representation captures the high-level flow of ingredients but without modeling the se- mantics in each individual instruction unlike other efforts ( <ref type="bibr" target="#b12">Tasse and Smith, 2008;</ref><ref type="bibr" target="#b8">Mori et al., 2012;</ref><ref type="bibr" target="#b9">Mori et al., 2014</ref>). We create a corpus in our rep- resentation by converting the recipes in the CURD corpus ( <ref type="bibr" target="#b12">Tasse and Smith, 2008</ref>) from MILK to SIMMR. We also develop a parser to generate SIMMR trees from input recipes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Recipe Representation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Recipes</head><p>The prototypical text recipe consists of two parts: an ingredient list that declares the food items to process, and a set of instructions that mostly de- scribe the transformations of the ingredients or the actions using the kitchen tools. The instructions relocate, process, combine, and separate ingredi- ents, as well as heat or cool utensils in the recipes. For the most part, the output produced from one instruction feeds as input into another instruction. The list of ingredients can be generalized as spe- cial fetch instructions whose output feeds as input to one of the cooking instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SIMMR</head><p>Our proposed representation is SIMMR: Simpli- fied Ingredient Merging Map in Recipes. SIMMR represents a recipe as a dependency tree whose leaves (terminal nodes) are the recipe ingredients, and whose internal nodes are the recipe instruc- tions. <ref type="figure" target="#fig_0">Figure 1</ref> exemplifies the SIMMR tree of a recipe for Surprise-inside French Toast. Indices for all ingredients and instructions are provided here to illustrate mapping between the different parts of the text recipe and its SIMMR tree. The subtree headed by inst2 indicates that ingredients #1, #2 and #3 (three cheeses) are inputs to instruc- tion #2, whose output is then an input to instruc-tion #3, together with ingredients #4 and #5 (sugar and vanilla). The SIMMR tree provides additional insights into the structure of recipes, suggesting in the case of this example, that multiple actions can take place in different orders without changing the recipe so long as the order of combinations is not changed. Some instructions simply transforms their input to produce their output, e.g. instruc- tions #1, #7, #8 and #9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">From MILK to SIMMR</head><p>We use MILK commands from the CMU CURD database ( <ref type="bibr" target="#b12">Tasse and Smith, 2008)</ref> to construct a database of SIMMR trees. The MILK lan- guage is a lot more expressive that SIMMR. For example, instruction #2 in <ref type="figure" target="#fig_0">Figure 1</ref> translates into create tool(t0, "large bowl"); combine(ing1, ing2, ing3, ing9, "cheeses", ""); and put(ing9, t0). These details of ingredient processing are ab- stracted away in SIMMR. To accomplish SIMMR instruction and ingredient linking, we process MILK instructions in order, tracing with MILK id numbers when each ingredient or its transformed or combined form at one instruction node is called for by a subsequent instruction node. The MILK intermediate names for instruction outputs (e.g., "cheeses" above) are not adopted in SIMMR. Ad- ditionally, food items that appear in instructions but are not part of the recipe ingredient list text are not included in SIMMR although MILK assigns ingredient ids to them. For example, instruction #8 mentions cooking spray, which is not on the in- gredient list. As a result inst8 looks like it has no ingredients coming into it other than the output of inst7.</p><p>We assume in SIMMR that at most one output is produced from each instruction. One MILK com- mand, separate, violates this assumption. For ex- ample, the instruction drain off the fat, and place the mixture into a slow cooker is MILK-tagged with a separate command to dispose fat, and re- tain the mixture. We ignore the separate command which occurs in 3% of all recipes (and 1.3% of the time involves disposing of a separated ingredient, such as draining off fat).</p><p>Instructions that do not interact with food, such as those calling for preheating the oven or lining the baking sheets, are considered to take the ingre- dient mixture of the cooking instruction immedi- ately prior and produce the same output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Recipe Parser</head><p>In this section, we present our SIMMR tree recipe parser. The input and output of the parser cor- respond to the left hand and right hand sides of <ref type="figure" target="#fig_0">Figure 1</ref>. We split the parsing process into two phases: first we link ingredients to instructions where the ingredients are first used; then we link instructions to other instructions, where the tar- get instruction uses the source instruction's output. We present the different challenges and solutions employed in each phase below and present evalu- ation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Data</head><p>We use a total of 260 recipes downloaded from CMU Recipe Database. MILK tags are used to construct the SIMMR trees as mentioned above. The dataset is randomly split (along recipe bound- aries) into training, development, and test sets with ratios of 50%, 20%, and 30%, respectively. The development set is used for tuning parameters. We report here on the test set only. We preprocess the data using standard NLP packages to tokenize, stem, and POS tag the words <ref type="bibr" target="#b3">(De Marneffe et al., 2006;</ref><ref type="bibr" target="#b2">Bird et al., 2009;</ref><ref type="bibr" target="#b4">De Smedt and Daelemans, 2012)</ref>. We further remove stop words and quantity measures. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Metrics</head><p>The evaluation metric is the accuracy of predict- ing edges in the SIMMR tree. This is compara- ble to the attachment score in dependency pars- ing. The overall accuracy of the task is computed at the edge level (counting all edges in the data set), and at the recipe level (average accuracy over all recipes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ingredient-Instruction Linking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Challenges</head><p>There are several characteristics of recipe text that do not reveal explicit linking of ingredients to in- structions that first use them. The ingredients are sometimes referred to by their qualifiers or onto- logical classes. For example, the ingredient 1 (15 oz) can sliced peaches, drained may be referred to in the instruction as canned fruit. In addition, Edge-level Recipe-level Accuracy Accuracy Baseline 84.3 84.8 SVMrank 95.3 95.8 <ref type="table">Table 1</ref>: Performance of different learning models for ingredient-instruction linking a number of ingredients are sometimes referred to as a group entity without specific mentions, e.g., Add the remaining ingredients, or mix together the dry ingredients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Baseline</head><p>For each instruction, in order, we compute all the maximum stemmed n-gram chunk matches against all ingredients. For each matching token chunk of the instruction, if it matches only one ingredient, we link the ingredient to the instruction and mark the ingredient as used. Otherwise, we compute the Levenshtein distance between the unstemmed sur- face text of both the ingredient candidate matches and the instruction token chunk, and take the high- est matching ingredient. Once an ingredient is used, it is no longer available for linking with sub- sequent instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Features and Linking</head><p>For each ingredient-instruction edge, we provide 1,136 features to classify whether the edge exists or not. The following are some of the most impor- tant features we use:</p><p>• The baseline decision for the ingredient- instruction edge.</p><p>• The number of distinct unigram matches.</p><p>• The largest match size.</p><p>• The sum of the relative frequency (in the list of instructions) of every word in the largest match (henceforth SRFM).</p><p>• The degree of similarity between SRFM and the instruction relative position (InstRP) in the instruction list. The intuition for this fea- ture is that if an ingredient is mentioned more often in the recipe, its first mention is likely to be in an earlier instruction. This feature is computed as (1 − |SRF M − InstRP |).</p><p>• The degree of similarity between the ingredi- ent relative position (IngRP) in the ingredient list and the InstRP. This feature captures an observation that earlier listed ingredients are used by earlier instructions. We compute the feature as (1 − |IngRP − InstRP |).</p><p>• To model the first word of each instruction (i.e., the directive verb such as heat or mix), we use a binary term vector whose vocab- ulary is constructed from all the instruction first words in the training data.</p><p>• We model the maximum ingredient- instruction word match using a binary term vector whose vocabulary covers non-directive recipe words (NDRW). We construct the NDRW vocabulary by taking the union of the set of words from the compiled food item list of Ahn et al. <ref type="formula">(2011)</ref> and the non-first words of the instructions in the training data.</p><p>• If there is a match, we model its surround- ing words using a similar binary term vector (NDRW vocabulary). If there is no match, the vector will be empty.</p><p>• We use a binary term vector (NDRW vocabu- lary also) to model the non-first words in the instruction.</p><p>We train using Linear SVMrank <ref type="bibr" target="#b6">(Joachims, 2006</ref>). <ref type="bibr">2</ref> The test set results are shown in <ref type="table">Table 1</ref>. Ranking edges using SVMrank and then picking the best one significantly outperforms the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Linking Errors</head><p>Among the linking errors, three patterns appear. First, stemming reduces the specificity of some of the terms, e.g., one prediction links baking powder to an action bake for 30 minutes. Second, our ap- proach does not handle negated mentions, e.g. the instruction mix together the dry ingredients, ex- cept the candies is incorrectly linked to ingredi- ent candy. Finally, the ingredients flour and butter are specifically part of many erroneous links be- cause they are often used in small quantities to fa- cilitate the cooking process such as board flouring and pan greasing. MILK does not always account for this trivial use of these ingredients and neither does SIMMR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Instruction-Instruction Linking</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Challenges</head><p>Although cooking instructions are written with an implied temporal order, they are not linked in a linear chain. Rather, the instructions describe dif- ferent cooking stages, where the output of apply-ing a number of instructions waits until other in- structions are finished to be used again, e.g., the output of instruction #1 in <ref type="figure" target="#fig_0">Figure 1</ref> waits until in- structions #2 and #3 are done. Sometimes stage switching is explicitly stated as in Set aside the flour mixture, and combine eggs and oil together; however, this is not the common case. Further- more, the waiting output of an earlier stage may be referred to collectively or using the main ingre- dient which makes linking harder, e.g., referring to the output of an instruction combining chicken, salt and pepper as chicken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Baseline</head><p>We link the instructions in a linear chain. In the training set, 89% of the instruction-instruction links are to the immediate neighbor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Features and Linking</head><p>For each possible instruction-instruction edge, we provide 1,573 features to classify if the edge exists or not. The features group into three categories.</p><p>First are words that suggest cooking stage switching, e.g., ingredient mixture words such as mixture, dough, and batter, or the simple men- tion of new containers and utensils. They are represented as binary features indicating whether the words appear in either or both instructions along the considered edge, as well as in imme- diate neighboring instructions. Logic operations <ref type="bibr">(and, or)</ref> are further applied to all pairs of these features. Another feature in this group is a binary verb conjugation feature that marks the presence of a past participle verb in the target instruction and a non-past-participle form of the same verb in the source instruction. The intuition here is that an instruction that asks to chop an ingredient would be followed later by an instruction containing the word chopped when referring to the ingredient.</p><p>The second group consists of features that en- code whether the n previous or future instructions has m linked ingredients, where n ranges from 1 to 3 and m ranges from 0 to 4.</p><p>Finally, the third group deals with term vec- tors describing the source and target instructions, as well as, the instructions' first words (the direc- tives). The term vector vocabularies used are the same as those discussed above in the ingredient- instruction linking section.</p><p>We additionally consider decoupling the fea- tures for the case of immediate neighboring in- structions from the further apart instructions. In the decoupled mode, we effectively double the number of features for each edge with nils used Edge-level Recipe-level Accuracy Accuracy Baseline 87.6 89.5 SVMrank 90.5 92.0 SVMrank -decoupled 91.3 92.4 <ref type="table">Table 2</ref>: Performance of different learning models for instruction-instruction linking to fill in the gaps. This allows us to learn different models for adjacent and apart instructions. The re- sults are in <ref type="table">Table 2</ref> and show that decoupling fea- tures in SVMrank is our best setting. Examining the weights learned for adjacent and long-distance edge features gives some interesting insights. One example is that the verb conjuga- tion feature has a higher weight for long-distance edges compared to adjacent edges. This is un- derstandable as most adjacent pairs of instructions would not exhibit this feature to express cooking progress: it is redundant to state, cook the pasta, and immediately refer to that pasta as the cooked pasta.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Linking Errors</head><p>As the distance between linked instructions in- creases, the likelihood of error also increases: while long-distance (i.e., non-adjacent) links con- stitute 12.3% of the reference, they are 91.7% of the errors. We expect that more training examples of long-distance linking can help address this is- sue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Overall Accuracy</head><p>The overall edge-level accuracy of constructing the full SIMMR tree is 93.5%, outperforming a baseline of 85.7%, and achieving error reduction of 54.5%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of a text recipe for Surprise-inside French Toast and its SIMMR representation. ing&lt;index&gt; and inst&lt;index&gt; refer to specific ingredients and instructions, respectively.</figDesc></figure>

			<note place="foot" n="1"> Since we start from the MILK representations, the set of ingredients and instructions are clearly identified in each recipe. However, we do not expect this to be the case when starting from raw text recipes, which need to be processed to segment the different ingredients and instructions. We do not attempt this step in this paper and leave it as future work.</note>

			<note place="foot" n="2"> We also experimented Linear SVM and Gaussian Kernel SVM (Pedregosa et al., 2011). We used the distance from the hyperplane to select the best edge among the set of edges connecting an ingredient. However, these techniques underperformed compared to SVMrank.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>We proposed a new ingredient-instruction depen-dency tree representation to capture the internal structure of cooking recipes, and built a parser for it. Our overall parsing accuracy is 93.5%, outper-forming a strong baseline of 85.7%.</p><p>We will make our SIMMR database, and our SIMMR parser publicly available. Further, we plan to build on SIMMR to get closer to the MILK representation. We also plan on parsing a large corpus of text recipes to provide structural features on a large scale that will allow us to discover new patterns of similarity across and within cuisines, as well as generate new recipes.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Lexical event ordering with an edge-factored model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Shay B Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Flavor network and the principles of food pairing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Yeol</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">E</forename><surname>Ahnert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Bagrow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert-László</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Natural language processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pattern for python. The Journal of Machine Learning Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom De</forename><surname>Smedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2063" to="2067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Bagler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03815</idno>
		<title level="m">Spices form the basis of food pairing in indian cuisine</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training linear svms in linear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><forename type="middle">Joachims</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 12th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="217" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Cooking with semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Malmaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Earl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A machine learning approach to recipe text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Yamakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichiro</forename><surname>Yoshino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 1st Cooking with Computer Workshop</title>
		<meeting>of the 1st Cooking with Computer Workshop</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="29" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Flow graph corpus from recipe texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinsuke</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokuni</forename><surname>Maeta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoko</forename><surname>Yamakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuro</forename><surname>Sasada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Nineth International Conference on Language Resources and Evaluation</title>
		<meeting>the Nineth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2370" to="2377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning recipe ingredient space using generative probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nedovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Cooking with Computers Workshop (CwC)</title>
		<meeting>Cooking with Computers Workshop (CwC)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Sour cream: Toward semantic processing of recipes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno>CMU-LTI-08-005</idno>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
