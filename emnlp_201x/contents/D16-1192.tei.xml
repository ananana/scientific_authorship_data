<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:55+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting the Relative Difficulty of Single Sentences With and Without Surrounding Context</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Schumacher</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">University of Oregon</orgName>
								<orgName type="institution" key="instit4">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">University of Oregon</orgName>
								<orgName type="institution" key="instit4">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwen</forename><surname>Frishkoff</surname></persName>
							<email>gfrishkoff@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">University of Oregon</orgName>
								<orgName type="institution" key="instit4">University of Michigan</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
							<email>kevynct@umich.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit3">University of Oregon</orgName>
								<orgName type="institution" key="instit4">University of Michigan</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting the Relative Difficulty of Single Sentences With and Without Surrounding Context</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1871" to="1881"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The problem of accurately predicting relative reading difficulty across a set of sentences arises in a number of important natural language applications, such as finding and curating effective usage examples for intelligent language tutoring systems. Yet while significant research has explored document-and passage-level reading difficulty, the special challenges involved in assessing aspects of readability for single sentences have received much less attention, particularly when considering the role of surrounding passages. We introduce and evaluate a novel approach for estimating the relative reading difficulty of a set of sentences, with and without surrounding context. Using different sets of lexical and grammatical features, we explore models for predicting pairwise relative difficulty using logistic regression, and examine rankings generated by aggregating pairwise difficulty labels using a Bayesian rating system to form a final ranking. We also compare rankings derived for sentences assessed with and without context , and find that contextual features can help predict differences in relative difficulty judgments across these two conditions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The reading difficulty, or readability, of a text is an estimate of linguistic complexity and is typically based on lexical and syntactic features, such as text length, word frequency, and grammatical complex- ity <ref type="bibr" target="#b3">(Collins-Thompson and Callan, 2004;</ref><ref type="bibr" target="#b29">Schwarm and Ostendorf, 2005;</ref><ref type="bibr" target="#b15">Kidwell et al., 2011;</ref><ref type="bibr" target="#b14">Kanungo and Orr, 2009)</ref>. Such estimates are often expressed as age-or grade-level measures and are useful for a range of educational and research applications. For example, instructors often wish to select stories or books that are appropriately matched to student grade level.</p><p>Many measures have been designed to calculate readability at the document level (e.g., for web pages, articles, or books) <ref type="bibr" target="#b3">(Collins-Thompson and Callan, 2004;</ref><ref type="bibr" target="#b29">Schwarm and Ostendorf, 2005</ref>), as well as the paragraph or passage level <ref type="bibr" target="#b15">(Kidwell et al., 2011;</ref><ref type="bibr" target="#b14">Kanungo and Orr, 2009)</ref>. However, much less work has attempted to characterize the readabil- ity of single sentences <ref type="bibr" target="#b24">(Pil√°n et al., 2014</ref>). This problem is challenging because single sentences provide less data than is typically required for re- liable estimates, particularly for measures that rely on aggregate statistics.</p><p>The absence of reliable single-sentence estimates points to a gap in natural language processing (NLP) research. Single sentences are used in a variety of experimental and NLP applications: for example, in studies of reading comprehension. Because read- ability estimates have been shown to predict a sub- stantial portion of variance in comprehension of dif- ferent texts, it would be useful to have measures of single-sentence readability. Thus, one aim of the current study was to estimate the relative readabil- ity of single sentences with a high degree of accu- racy. To our knowledge, general-purpose methods for computing such estimates for native language (L1) readers have not been developed, and thus our goal was to develop a method that would character- ize sentence-level difficulty for that group.</p><p>The second aim is to compare the readability of single sentences in isolation with the readability of these same sentences embedded in a larger context (e.g., paragraph, passage, or document). When a single sentence is extracted from a text, it is likely to contain linguistic elements, such as anaphora (e.g., "he" or "the man"), that are semantically or syn- tactically dependent on surrounding context. Not surprisingly, sentences that contain these contextual dependencies take more effort to comprehend: an anaphoric noun phrase, or NP (e.g., "he"), automati- cally triggers the need to resolve reference, typically by understanding the link between the anaphor and a full NP from a previous sentence (e.g., "John" or "The man that I introduced you to at the party last night" <ref type="bibr" target="#b23">(Perfetti and Frishkoff, 2008)</ref>. In general, studies have shown a link between reading com- prehension and the presence of such cross-sentence relationships in the text <ref type="bibr" target="#b21">(McNamara, 2001;</ref><ref type="bibr" target="#b19">Liederholm et al., 2000;</ref><ref type="bibr" target="#b35">Voss and Silfies, 1996)</ref>. This im- plies that the very notion of readability at the sen- tence level may depend on context as well as word- and sentence-level features. Therefore, it is impor- tant to compare readability estimates for single sen- tences that occur in isolation with those that occur within a larger passage, particularly if the target sen- tence contains coreferences, implied meanings, or other dependencies with its context.</p><p>To address these aims, the present study first con- ducted two crowdsourcing experiments. In the first, 'sentence-only' experiment, workers were asked to judge which of two "target" sentences they thought was more difficult. In the second, 'sentence-in- passage' experiment, another group of workers was presented with the same target sentences that were used in the first experiment. However, in the second experiment, target sentences were embedded in their original contexts.</p><p>Next, we analyzed these judgments of relative readability for each condition (sentence-only ver- sus sentence-in-passage) by developing models for predicting pairwise relative difficulty of sentences. These models used a rich representation of target sentences based on a combination of lexical, syntac- tic, and discourse features. Significant differences were found in readability judgments for sentences with and without their surrounding context. This demonstrates that discourse-level features (i.e., fea- tures related to coherence and cohesion) can affect the readability of single sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Recent approaches to estimating readability have used a variety of linguistic features and predic- tion models <ref type="bibr" target="#b4">(Collins-Thompson, 2014</ref>). The <ref type="bibr">Lexile Framework (Stenner, 1996)</ref> uses word frequency estimates in a large corpus as a proxy for lexi- cal difficulty, and sentence length as a grammati- cal feature. Methods based on statistical machine learning, such as the reading difficulty measures de- veloped by <ref type="bibr">Collins-Thompson and Callan (CollinsThompson and Callan, 2004)</ref> and <ref type="bibr" target="#b29">(Schwarm and Ostendorf, 2005</ref>) used a feature set based on language models. Later work <ref type="bibr" target="#b10">(Heilman et al., 2008</ref>) incorpo- rated grammatical features by parsing the sentences in a text, and creating subtrees of one-to three-level depth as separate features. Such features allow more detailed, direct analysis of the sentence structure it- self instead of traditional proxies for syntactic com- plexity likes sentence length. The linguistic features proposed in these works capture specific aspects of language difficulty applied at the document level, whereas our work investigates the effectiveness of these feature types for characterizing aspects of dif- ficulty at the sentence level.</p><p>Methods have been proposed to measure the read- ability of shorter portions of text (e.g. typically less than 100 words), including sentences. The approach most similar to ours is the prediction of relative sen- tence difficulty (with associated readability ranking) for the deaf introduced by <ref type="bibr" target="#b13">Inui et al. (2001)</ref>. That work focused on effective morphosyntactic features for that target population with an SVM binary clas- sifier, whereas our approach (1) is intended for a broader population of L1 learners and thus explores the effectiveness of adding a rich, lexically-derived feature set, (2) uses a logistic regression model to es- timate class probabilities and interprets the results of that model, compared to applying an SVM without interpretation to obtain a binary label, (3) examines differences in predicting sentence difficulty both in and out of passage context, and (4) creates and uses a new dataset based on a crowdsourced approach, us- ing hundreds of non-experts to gather thousands of pairwise preferences, compared to a questionnaire deployed to a small number of experts. In other do- mains, a model was proposed to predict the read- ability of short web summaries in <ref type="bibr" target="#b14">Kanungo and</ref><ref type="bibr">Orr 2009. In Kidwell et al. (2011)</ref>, , a set of Age of Acquisition estimates for individual words, repre- senting the lexical component of difficulty, was used to predict the grade levels of passages. Some ap- proaches have explored the classification of specific aspects of sentences, as opposed to reading difficulty classification. For example, <ref type="bibr" target="#b24">(Pil√°n et al., 2014</ref>) clas- sified individual sentences that would be understood by second-language learners. Another work <ref type="bibr" target="#b16">(Kilgarriff et al., 2008</ref>) identified sentences that would be good dictionary examples by looking for specific desirable features. <ref type="bibr" target="#b6">Davenport et al. 2014</ref> used a traditional method of readability (Flesch-Kincaid), within the larger context of exploring relationships between the difficulty of tweets in a geographic area and demographics. Research in text simplification has applied sentence-level models of difficulty as part of simplification-based optimization objectives. For example, Woodsend and Lapata (2011) use word and syllable count as proxy features for sentence dif- ficulty when implicitly comparing different simpli- fied variants of a sentence.</p><p>Other approaches have considered the relation- ship of reading difficulty to structures within in the whole text. These relationships can include the num- ber of coreferences present in a text. <ref type="bibr">Coh-Metrix (Graesser et al., 2011</ref>) measures text cohesiveness, accounting for both the reading difficulty of the text and other lexical and syntactic measures as well as a measure of prior knowledge needed for compre- hension, and the genre of the text. Coh-Metrix uses co-reference detection as a factor in the cohesive- ness of a text, typically at the document or passage level. Such cohesiveness factors account for the dif- ficulty of constructing the mental representation of texts with more complex internal structure. <ref type="bibr">TextEvaluator (Sheehan et al., 2013;</ref><ref type="bibr" target="#b31">Sheehan et al., 2014</ref>) is designed to help educators select materials for in- struction. The tool includes several components in its evaluation of text, including narrativity, style, and cohesion, beyond traditional difficulty and is again at the whole document level. This approach illus- trates that the difficulty of a text relies on the rela- tionships within it. This motivates the need to con- sider context when measuring difficulty.</p><p>Generating reading difficulty rankings of longer texts from pairwise preferences has been performed in other contexts. <ref type="bibr" target="#b34">Tanaka-Ishii et al. (2010)</ref> explored an approach for sorting texts by readability based on pairwise preferences. Later, <ref type="bibr" target="#b2">Chen et al. (2013)</ref> also proposed a model to obtain passage readability rank- ing by aggregating pairwise comparisons made by crowdworkers. In De <ref type="bibr" target="#b7">Clercq et al.(2014)</ref>, pairwise judgments of whole passages were obtained from crowdworkers and were found to give comparable results in aggregate to those obtained from experts. A pairwise ranking of text readability was created in <ref type="bibr" target="#b25">Pitler and Nenkova (2008)</ref> in which readability was defined by subjective questions asked to the reader after finishing the article, such as "How well-written is this article?". All of the above previous work was focused on ordering longer text passages, not single sentences as we do here.</p><p>Finally, research in the Machine Translation field has explored pairwise prediction of the best transla- tion between two sentence options. For example, in <ref type="bibr" target="#b32">Song and Cohn (2011)</ref>, a pairwise prediction model was built using n-gram precision and recall, as well as function, content, and word counts. However, un- like pairwise prediction of difficulty, the prediction is done with respect to a reference sentence, or set of reference sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Collection and Processing</head><p>We now describe methods used to create our dataset of sentences, to collect pairwise assessments of dif- ficulty, and to aggregate these pairwise preferences into a complete ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Set</head><p>The study sentences were drawn from a corpus com- bining the American National Corpus ( <ref type="bibr" target="#b27">Reppen et al., 2005</ref>), the New York Times Corpus <ref type="bibr" target="#b28">(Sandhaus, 2008)</ref>, and the North American News Text Corpus ( <ref type="bibr" target="#b20">McClosky et al., 2008)</ref>. The domain of these cor- pora is largely news text, but also includes other top- ics, such as travel guides and other non-fiction. In to- tal, this database contains 60,663,803 sentences that served as initial candidates. Sentences were filtered out that didn't include one of the 70 target words that the third author selected for a study on teach- ing vocabulary to 8-14 year-old students. Other sen- tences were removed based on length, keeping only sentences of between 6 and 20 words. Some sen- tences were removed due to the presence of one or more rare words. Finally, sentences were annotated with the surrounding document reading level, us-ing a lexical readability model <ref type="bibr" target="#b3">(Collins-Thompson and Callan, 2004</ref>).The data set gathered by <ref type="bibr">(CollinsThompson and Callan, 2004</ref>) was used in order to add to the amount of lower-level reading material in the collected corpora.</p><p>With these sentences, two crowdsourced tasks were prepared to gather pairwise assessments of sen- tence reading difficulty. In one task, the sentences were presented alone, outside of their original pas- sage context. In the other task, the same sentences were presented within their original passage context. The objective was to generate two sets of pairwise comparisons of the readability of a sentence. In to- tal, 120 sentence pairs were used for the first task and 120 passage pairs were used for the second. Each sentence was compared to five others, which created 300 comparisons in each task. The five sen- tences matched to each sentence were selected to en- sure that pairs with a range of document level differ- ences would be created. Within each type of pair, a random pair was selected.</p><p>There were several constraints when generating pairs for comparison. To allow for sentences to be taken from documents with a range of reading lev- els, sentences were selected evenly from documents at each reading level. From the twelve standard U.S. grade levels used in readability, each document was considered to be part of a bin consisting of two ad- jacent grade levels, such as grades 1 and 2, for ex- ample. Sentences were selected evenly from those bins.</p><p>Each sentence needed sufficient context to ensure there would be equivalent context for each item that would be compared, so only passages of sufficient size were included. To ensure passages were of similar length, only passages that had between 136 and 160 words were included. Contexts having at least two sentences before and after the sentence in question were strongly preferred. Each selected sentence was paired with one sentence from each of the other grade level bins. For example, a sen- tence from grade 1 would be paired with one sen- tence each from grade 3-4, 5-6, 7-8, 9-10, and 11- 12. Finally, each pair of sentences was presented in AB and BA order. For each pair, there were seven worker decisions. There were 296 unique workers for the sentence-only task, and 355 for the sentence- in-passage task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Crowdsourcing</head><p>Both of these tasks were carried out on the Crowd- flower platform. The workers were first given in- structions for each task, which included a descrip- tion of the general purpose of the task. In the sentence-only task, workers were asked to select which of the two sentences was more difficult. In the sentence-within-passage task, workers were sim- ilarly asked to decide which underlined sentence was more difficult. The instructions for the latter re- quested that the workers make their judgment only on the sentence, not on the whole context. In both tasks, there was an option for "I don't know or can't decide". The workers were asked to make their deci- sion based on the vocabulary and grammatical struc- ture of the sentences. Finally, examples for each task were provided with explanations for each answer.</p><p>For each task, at least 40 gold standard ques- tions were created from pairs of sentences that were judged to be sufficiently distinct from one another so that they could easily be answered correctly. For the sentence-in-passage task, several gold standard questions were written to verify that the instruc- tions were being followed, since it was possible that a worker might judge the sentences based on the quality of the passage alone. These gold examples consisted of an easier sentence in a difficult pas- sage compared with a difficult sentence within an easy passage. For each task, the worker saw three questions, including one gold standard question. A worker needed to maintain an 85% accuracy rating on gold standard questions to continue, and needed to spend at least 25 seconds per page, which con- tained 3 questions each.</p><p>A weighted disagreement rate was calculated for each worker. If a worker's response to a ques- tion differed from the most frequent answer to that question, the percentage of agreement was counted against the worker. If a worker, for the sentence- only task, had a disagreement rate (the weighted disagreement penalty divided by the total questions they answered) of 15% or higher, their contribution was removed from the data set (or 17% or higher for the sentence in passage task). The agreement for the sentence-in-passage task is lower than the sentence- only task (88.93% and 90.33% respectively), so the permitted disagreement level is higher for that task. This resulted in the removal of 5.7% and 4.5% of pairwise judgments, respectively. For each ques- tion, there was an optional text form to allow work- ers to submit feedback. The sentence-only task paid 11 cents per page, and the sentence-in-passage task paid 22 cents per page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ranking Generation</head><p>Each task resulted in 4,200 pairwise preference judgments, excluding gold-standard answers. To aggregate these pairwise preferences into an over- all ranking of sentences, we use a simple, publicly available approach evaluated by Chen et al. as be- ing competitive with their own Crowd-BT aggre- gation method: the Microsoft Trueskill algorithm ( <ref type="bibr" target="#b11">Herbrich et al., 2007)</ref>. Trueskill is a Bayesian skill rating system that generalized the well-known Elo rating system, in that it generates a ranking from pairwise decisions. As Trueskill's ranking algorithm depends on the order in which the samples are pro- cessed, we report the ranking as an average of 50 runs.</p><p>The judgments were not aggregated for each com- parison. Instead, each of the judgments was treated individually. This allows Trueskill to consider the degree of agreement between workers, since a sen- tence judgment that has high agreement reflects a larger difference in ranking than one that has lower agreement. Each sentence was considered a player, and the winner between two, A or B, was the sen- tence considered most difficult. If a worker chose "I don't know or can't tell", it was considered a draw. The prediction resulting in "I don't know or can't tell" is rare; 2.2% of decisions in the sentence only task resulted in a draw, and 2.0% for sentences within passages. After processing each of the judg- ments, a rating can be built of sentences, ranked from least difficult to most difficult. We can com- pare the resulting rankings for the sentence-only task and the sentence-in-passage task to see the effect of context on relative sentence difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Modeling Pairwise Relative Difficulty</head><p>Our first step in exploring relative difficulty order- ing for a set of sentences was to develop a model that could accurately predict relative difficulty for a single pair of sentences, corresponding to the pair- wise judgements of relative difficulty we gathered from the crowd. We did this for both the sentence- only and the sentence-in-passage tasks. In predict- ing a pairwise judgment for the sentence-only task, the model uses only the sentence texts. In the model for the sentence-in-passage task, the Stanford De- terministic Coreference Resolution System ( <ref type="bibr" target="#b26">Raghunathan et al., 2010</ref>) is used to find coreference chains within the passage. From these coreference chains, sentences with references to and from the target sen- tence can be identified. If any additional sentences are found, these are used in a separate feature set that is included in the model; for all possible fea- tures, they are calculated for the target sentence, and separately for the additional sentence set.</p><p>Prior to training the final model, feature selec- tion was done on random splits of the training data. Training data was used to fit a Random Forest Clas- sifier, and based on the resulting classifier, the most important variables were selected using sklearn's feature importance method. The top 2% of the fea- tures (or 1% for the sentence-in-passage with coref- erence, since the feature set size is doubled) were se- lected automatically. This resulted in a feature size of 40-50 features. We implemented our models us- ing scikit-learn ( <ref type="bibr" target="#b22">Pedregosa et al., 2011</ref>) in Python.</p><p>The resulting features were used to train a Logis- tic Regression model. While other prediction mod- els such as Support Vector Machines have been ap- plied to relative readability prediction <ref type="bibr" target="#b13">(Inui and Yamamoto, 2001</ref>), we chose Logistic Regression due to its ability to provide estimates of class prob- abilities (which may be important for reliability when deploying a system that recommends high- quality items for learners), its connection to the Rasch psychometric model used with reading as- sessments ( <ref type="bibr" target="#b8">Ehara et al., 2012)</ref>, and the interpretable nature of the resulting parameter weights. Since a given feature has a value for sentence A and B, if a feature was selected for only Sentence A or B, the feature for the other sentence was also added. We used the NLTK library ( <ref type="bibr" target="#b0">Bird et al., 2009</ref>) to tokenize the sentence for feature processing.</p><p>At the sentence level, the familiarity of the words is a significant factor to consider in any judgment of difficulty. The grammatical structure of a sentence is also important to consider: if the sentence uses a more familiar structure, it is likely to be consid- ered less difficult than a sentence with more unusual structure. We thus identified two groups of potential features: lexical and grammatical, described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lexical Features</head><p>For lexical features, based partly on the work of (Song and Cohn 2011) we included the percentage of non-stop words (using NLTK list), the total num- ber of words and the total number of characters as features. We included the percentage of words in the text found in the Revised Dale-Chall word list <ref type="bibr" target="#b5">(Dale and Chall, 2000</ref>) to capture the presence of more difficult words in the sentence.</p><p>Because sentences that contain rarer sequences of words are likely to be more difficult, and the likeli- hood of the sentence based on a large corpus should reflect this, we included the n-gram likelihood of each sentence, over each of 1-5 n-grams, as a fea- ture. The Microsoft WebLM service ( <ref type="bibr" target="#b36">Wang et al., 2010</ref>) was used to calculate the n-gram likelihood.</p><p>In the field of psycholinguistics, Age of Acquisi- tion (AoA) refers to the age at which a word is first learned by a child. A database of 51,715 words col- lected by <ref type="bibr" target="#b18">(Kuperman et al., 2012</ref>) provides a rich re- source for use in reading difficulty measures. With this dataset, we computed several additional fea- tures: the average, maximum, and standard devia- tion of the aggregated AoA for all words in a sen- tence that were present in the database. Since the data set also includes the number of syllables in each word, and as ( <ref type="bibr" target="#b17">Kincaid et al., 1975)</ref> proposes that words with more syllables are more difficult, we also included the average and maximum syllable count as potential features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Syntactic Features</head><p>We parsed each sentence in the data set using the BLLIP Parser <ref type="bibr" target="#b1">(Charniak and Johnson, 2005</ref>), which includes a pre-trained model built on the Wall Street Journal Corpus. This provided both a syntactic tree and part of speech tags for the sentence. As Part of Speech tagging is often used as a high-level linguis- tic feature, we computed percentages for each PoS tag present, since the percentages might vary be- tween difficult sentences and easier sentences. The percentage for each Part of Speech tag is defined as the number of times a certain tag occurred, divided by the total tags. The diversity of part of speech tags was used since this might vary between difficult and easier sentences.</p><p>Using the syntactic tree provided by the parser, we obtained the likelihood of the parse, and the like- lihood produced by the re-ranker, as syntactic fea- tures. If a sentence parse has a comparatively high likelihood, it is likely to be a more common struc- ture and thus more likely to be easier to read. The length and height of the parse were also included as features, since each of these could reflect the diffi- culty of the parse. Including the entire parse of the sentence would create too much sparsity since syn- tactic parses vary highly from sentence to sentence. Therefore, as was done in <ref type="figure">(Heilman et al., 2008)</ref>, subtrees of depth one to three were created from the syntactic parse, and were added as features. This creates a smaller feature set, and one that can poten- tially model specific grammatical structures that are associated with a specific level of difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pairwise Difficulty Prediction Results</head><p>The performance of the logistic regression models trained with different feature sets, for each task, is shown in <ref type="table">Table 1</ref>. We reported the mean and stan- dard deviation of the accuracy of each model over 200 randomly selected training and testing splits. Each test set consisted of 20% of the data, and con- tained 60 aggregate pairs, all of which are sentences (24 in total) that were not present in the training data. The test sets for the sentence-in-passage and sentence-only task contain the same sentence pairs, but the individual judgements are different.</p><p>For comparison, an oracle is included that repre- sents the accuracy a model would achieve if it made the optimal prediction for each aggregate pair. Due to disagreement within the crowd, the oracle cannot reach 100% accuracy. For example, for some pair A and B, if 10 workers selected A as the more diffi- cult sentence, and 4 workers selected B, the oracle's prediction for that pair would be that that A is more difficult. The judgments of the four workers that se- lected B would be counted as inaccurate, since the feature set is the same for the judgments with A and the judgments with B. Therefore, the oracle repre- sents the highest accuracy a model can achieve, con- sistent with the provided labels, using the features provided.</p><p>Examining the results in <ref type="table">Table 1</ref>, we find the best performing configuration, Model B, used all features as candidates. The exact number of features selected</p><note type="other">Sentence Only In Passage, With Coref In Passage, No Coref Model</note><p>Acc. S.D. p-value Acc. S.D. p-value Acc. S.D. p-value Oracle (A) 90.13% 2.71% - 87.81% 1.84% - 87.81% 1.84% - All Features (B) 84.69% 3.46% 0.01 ‚Üì 81.66% 3.17% 0.005 ‚Üì 81.91% 3.27% ‚Üê 0.04 AoA + Parse L. (C) 84.33% 3.13% 0.001 ‚Üì 81.27% 3.93% 0.001 ‚Üì 80.84% 3.61% ‚Üê 0.001</p><p>AoA (D) 79.62% 2.71% 0.001 ‚Üì 79.72% 2.86% 0.001 ‚Üì 78.99% 2.58% ‚Üê 0.001 Strat. Random 50.28% 1.68% - 50.31% 2.01% - 50.31% 2.01% -  To assess the contribution of different features to the model prediction, feature group importances are reported in <ref type="table" target="#tab_2">Table 2</ref>. As features for a given group are often highly correlated with each other, such as in Age of Acquisition, the importance is calculated for feature groups. Based on the method described for Model B, each feature group is removed from consideration in the model, and the resulting error rate from Model B is used to calculate an importance measure. The most important feature is normalized to have a value of 1.0, with the rest being relative to the difference in error rate from the original model, averaged across splits.</p><p>These prediction results show that relative reading difficulty can be predicted for sentence pairs with high accuracy, even with fairly simple feature sets. In particular, the results for AoA model D, which uses a small number of targeted features, are com- petitive with the best model B that relies on a much larger feature set. The addition of coreference fea- tures did result in small but significant changes in the <ref type="bibr">1</ref> The p-value for each accuracy measurement compares its significance, using a paired t-test, to the neighboring model in the direction of the arrow. For example, the sentence-only Model B is compared to sentence-only Model A.    accuracy of the sentence-in-passage task, although in one case the accuracy was reduced with corefer- ence features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Ranking Results</head><p>Using the pairwise aggregation method described in Sec. 3.3, we ranked sentences by relative dif- ficulty for both sentence-only and sentence-in- passage tasks. By observing how the overall rank or-  questions were used to build ranking. All correlations have p &lt; 0.0001 except those with an asterisk *, which have p &lt; 0.001.</p><p>dering of sentences changes across these conditions, we can identify differences in how workers judged the relative difficulty of sentences with and without context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Rank Differences</head><p>We report differences in ranking in terms of mean and standard deviation of the absolute difference in rank index of each sentence across the two rank- ings, along with Pearson's coefficient and Spear- man's rank order coefficients. Comparisons between the rankings for each task are shown in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>In comparing crowd-generated rankings for the sentence-only and sentence-in-passage task, the re- sults show a statistically significant aggregate dif- ference in how the crowd ranks sentence difficulty with and without the surrounding passage. While the correlation between the two rankings is high, and the average normalized change in rank posi- tion is 7.7%, multiple sentences exhibited a large change in ranking. For example, the sentence 'As a result, the police had little incentive to make con- cessions.' was ranked significantly easier when pre- sented out of context than when presented in context (rank change: -30 positions). For that example, the surrounding passage explained the complex political environment referred to indirectly in that sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Feature Correlation with Rank Differences</head><p>To examine why sentences may be ranked as more or less difficult, depending on the context, we exam- ined the correlation between a sentence's change in rank (Sentence-Only Ranking minus the Sentence- in-Passage ranking) and the normalized difference in feature values between the sentence representation and the remaining context representation. We found that percentage change in parser and reranker like- lihoods had the most significant correlation (-0.33) with ranking change, as shown in <ref type="table" target="#tab_4">Table 4</ref>.</p><p>To interpret this result, note that the parser and reranker likelihood represent the probability the parser and reranker models assign to the syntactic parse produced by the sentence. In other words, they are a measure of how likely it is that the sentence structure occurs, based on the model's training data. If the difficulty of the sentence-in-passage is ranked higher than the sentence alone, this correlates with the target sentence having a syntactic structure with higher likelihood than the average of the surround- ing sentence structures. This means that if a sen- tence that has a frequently-seen syntactic structure is in a passage with sentences that have less common structures, the sentence within the passage is more likely to be judged as more difficult. The reverse is also true: if a sentence that has a more unusual syn- tactic structure is in a passage with sentences with more familiar structures, the sentence without the surrounding passage is more likely to be ranked as more difficult.</p><p>We also examined the rank correlation of crowd- generated rankings with rankings produced by sort- ing sentences based on the value of individual fea- tures. In addition to the full rankings, we con- structed a ranking produced only by the gold stan- dard examples, denoted Gold Only and included this in the comparison. The gold standard questions con- sist of examples constructed by the authors to have a clear relative difficulty result. The rank correlations are shown in <ref type="table" target="#tab_6">Table 5</ref> for both tasks.</p><p>The reasons for discrepancies in relative diffi- culty assessment between the sentence-only and sentence-in-passage conditions require further ex- ploration. While the correlation between the per- centage change in probability of the parse and the difference in ranking is significant, it is not large. It does indicate that despite judges being explicitly Crowd Pearson Spearman Expert label 0.85 0.84 Document-based label 0.70 0.70 <ref type="table">Table 6</ref>: Correlation between sentence readability labels and crowd-generated ranking, for expert (sentence-level) and document-based labels (from document readability prediction). All correlations have p &lt; 0.0001.</p><p>told to only consider the sentence, the properties of the surrounding passage may indeed influence the perceived relative difficulty of the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Review of Data</head><p>The pairwise prediction results indicate that a large proportion of the crowdsourced pair orderings can be decided using vocabulary features, due to the strong performance of the Age of Acquisition fea- tures. To identify the relative importance of vocab- ulary and syntax in our data, we reviewed each pair and judged whether the sentence's syntax or vocab- ulary, or the combination of both, were needed to correctly predict the more difficult sentence. For many pairs, either syntax or vocabulary could be used to correctly predict the more difficult sentence since each factor indicated the same sentence was more difficult. We found that 19% of pairs had only a vocabulary distinction, and 65% of pairs could be judged correctly either by vocabulary or syntax. Therefore, 84% of pairs could be judged using vo- cabulary, which explains the high performance of the Age of Acquisition features. The level of a sentence's source document was used as a proxy for the sentence's grade level when building the pairs. To build a sentence-level gold standard for this dataset, we asked a teacher with a Master of Education with a Reading Specialist fo- cus and 30 years of experience in elementary and high school reading instruction, to identify the grade level of each sentence. This expert was asked to as- sign either a single grade level or a range of levels to each of the 120 sentences. From this, an expert rank- ing was created, using the midpoint of each expert- assigned range. The correlation between the expert sentence ranking and the crowd ranking can be seen in <ref type="table">Table 6</ref>, reinforcing the finding that crowdsourced judgments can provide an accurate ranking of diffi- culty <ref type="bibr" target="#b7">(De Clercq et al., 2014</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Using a rich sentence representation based on lex- ical and syntactic features leveraged from previous work on document-level readability, we introduced and evaluated several models for predicting the rel- ative reading difficulty of single sentences, with and without surrounding context. We found that while the best prediction performance was obtained by us- ing all feature classes, simpler representations based on lexical features such as Age of Acquisition norms were effective. The accuracy achieved by the best prediction model came within 6% of the oracle ac- curacy for both tasks.</p><p>Many of the features identified had a high correla- tion with the rankings produced by the crowd. This indicates that these features can be used to build a model of sentence difficulty. With the rankings built from crowdsourced judgments on sentence diffi- culty, small but significant differences were found in how sentences are ranked with and without the sur- rounding passages. This result suggests that prop- erties of the surrounding passage of a sentence can change the perceived difficulty of a sentence.</p><p>In future work, we plan to increase the number of sentences in our data set, so that additional more fine-grained features might be considered. For ex- ample, weights for lexical features could be more accurately estimated with more data. Our use of the crowd-based labels was intended to reduce noise in the ranking analysis, but we also intend to use the pairwise predictions produced by the logistic model as the input to the aggregation model, so that rank- ings can be obtained for previously unseen sentences in operational settings. Another goal is to obtain ab- solute difficulty labels for sentences by calibrating ordinal ranges based on the relative ranking. Finally, we are interested in the contribution of context in un- derstanding the meaning of an unknown word.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 :</head><label>1</label><figDesc>Mean and standard deviation of accuracy on 200 randomized samples of 20% held out data. 'With coref' indicates coreference features were used. The arrow indicates which immediately adjacent accuracy result is used for p-value comparison, e.g. Model B sentence-only is compared to model C sentence-only, and model B passage, no coref is compared to model B passage, with coref. varied depending on the task. However, the simplest model, the Age of Acquisition model (D) consisting of the average, standard deviation, and maximum AoA features (sentence-only: 6 features, sentence- in-passage: 12 features) performed well, achieving over 78% accuracy on all tasks, showing that most of the relative difficulty signal at the sentence level can be captured with a few lexical difficulty features. The Age of Acquisition + Parse Likelihood model (C) consists of all Age of Acquisition features, plus the likelihood of the parse (sentence-only: 10 fea- tures, sentence-in-passage: 20 features) 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Relative feature importance for Model B. Feature im-

portance is the increase in absolute error with a specific feature 
group removed, averaged across cross-validation folds used for 
Table 1, and normalized relative to the most informative fea-
ture. For Sentence in Passage, feature groups include corefer-
ence features. 

Value 
Avg. Abs. Diff 
9.3 
Avg. Abs. Std Dev 
7.7 
Pearson's correlation 
0.94* 
Spearman's correlation 
0.94* 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison of rankings generated with and without 

passage. Asterisk * indicates p &lt; 0.0001. 

% Diff 
Pearson p-val. 
Spearman p-val. 
Reranker -0.33 
0.0002 -0.29 
0.001 
Parser 
-0.33 
0.0002 -0.28 
0.002 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Correlation between difference in rank and percentage 

difference in features. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Sentence-Only and Sentence-In-Passage Ranking Correlation with Individual Features. Gold indicates only gold-standard 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their sug-gestions, and Ann Schumacher for serving as grade level annotator. This work was supported in part by Dept. of Education grant R305A140647 to the Uni-versity of Michigan. Any opinions, findings, conclu-sions or recommendations expressed in this material are the authors', and do not necessarily reflect those of the sponsors.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Natural language processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Coarse-tofine n-best parsing and maxent discriminative reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pairwise ranking aggregation in a crowdsourced setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM international conference on Web search and data mining</title>
		<meeting>the sixth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A language modeling approach to predicting reading difficulty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James P</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Computational assessment of text readability: a survey of current and future research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Applied Linguistics</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="97" to="135" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Dale</surname></persName>
		</author>
		<ptr target="http://opi.mt.gov/Pub/RTI/Forms/School/Choteau/The\%20Dale-Chall\%20Word\%20List.doc.Accessed" />
		<title level="m">Readability revisited: The new dale-chall readability formula</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="2016" to="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The readability of tweets and their geographic correlation with education</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deline</surname></persName>
		</author>
		<idno>abs/1401.6058</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Using the crowd for readability prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronique</forename><surname>Orph√©e De Clercq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martine</forename><forename type="middle">De</forename><surname>Van Oosten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieve</forename><surname>Cock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="293" to="325" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mining words in the minds of second language learners: Learner-specific word difficulty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yo</forename><surname>Ehara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidekazu</forename><surname>Oiwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2012, 24th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-08-15" />
			<biblScope unit="page" from="799" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Coh-metrix providing multilevel analyses of text characteristics. Educational Researcher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><forename type="middle">S</forename><surname>Arthur C Graesser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonna</forename><forename type="middle">M</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kulikowich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="223" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An analysis of statistical models and features for reading difficulty prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Innovative Use of NLP for Building Educational Applications, EANL &apos;08</title>
		<meeting>the Third Workshop on Innovative Use of NLP for Building Educational Applications, EANL &apos;08<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="71" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A bayesian skill rating system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trueskill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="569" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Corpusbased acquisition of sentence readability ranking models for deaf people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kentaro</forename><surname>Inui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satomi</forename><surname>Yamamoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Natural Language Processing Pacific Rim Symposium</title>
		<meeting>the Sixth Natural Language Processing Pacific Rim Symposium<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Hitotsubashi Memorial Hall</publisher>
			<date type="published" when="2001-11-27" />
			<biblScope unit="page" from="159" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting the readability of short web summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Kanungo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Orr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Second ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="202" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Statistical estimation of word acquisition with application to readability prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Kidwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Lebanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevyn</forename><surname>Collinsthompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">493</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gdex: Automatically finding good dictionary examples in a corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milos</forename><surname>Hus√°k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katy</forename><surname>Mcadam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Rundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavelrych√¨</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the XIII EURALEX International Congress</title>
		<meeting>the XIII EURALEX International Congress<address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-07" />
			<biblScope unit="page" from="425" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Peter</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert P Fishburne</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brad</forename><forename type="middle">S</forename><surname>Richard L Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>DTIC Document</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Age-of-acquisition ratings for 30,000 english words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kuperman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Stadthagen-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brysbaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="978" to="990" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Effects of causal text revisions on more-and less-skilled readers&apos; comprehension of easy and difficult texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tracy</forename><surname>Liederholm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><forename type="middle">Gaddy</forename><surname>Everson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Van Den Broek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maureen</forename><surname>Mischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Crittenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Samuels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Instruction</title>
		<imprint>
			<biblScope unit="page" from="525" to="556" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Bllip north american news text, complete. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reading both highcoherence and low-coherence texts: Effects of text sequence and prior knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Danielle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcnamara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Experimental Psychology/Revue canadienne de psychologie exp√©rimentale</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The neural bases of text and discourse processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Perfetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwen</forename><forename type="middle">A</forename><surname>Frishkoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of the Neuroscience of Language</title>
		<editor>B. Stemmer and H. A. Whitaker</editor>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rule-based and machine learning approaches for second language sentence-level readability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Ildik√≥ Pil√°n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Volodina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the Ninth Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Revisiting readability: A unified framework for predicting text quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;08<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="186" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A multipass sieve for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeyoung</forename><surname>Karthik Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Sudarshan Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="492" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">American national corpus (anc) second release. Linguistic Data Consortium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randi</forename><surname>Reppen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Suderman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Sandhaus</surname></persName>
		</author>
		<title level="m">The new york times annotated corpus. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">26752</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reading level assessment using support vector machines and statistical language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sarah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Schwarm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A two-stage approach for generating unbiased estimates of text complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kathleen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Sheehan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Flor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Napolitano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Natural Language Processing for Improving Textual Accessibility</title>
		<meeting>the Workshop on Natural Language Processing for Improving Textual Accessibility</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="49" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The textevaluator tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Kathleen M Sheehan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Kostin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Napolitano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Elementary School Journal</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="184" to="209" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Regression and ranking based optimisation for sentence level machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="123" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Measuring reading comprehension with the lexile framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackson</forename><surname>Stenner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sorting texts by readability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumiko</forename><surname>Tanaka-Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Tezuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Terada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="227" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning from history text: The interaction of knowledge and comprehension skill with text structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurie</forename><surname>Silfies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Instruction</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="68" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">An overview of microsoft web n-gram corpus and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Thrasher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evelyne</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences with quasi-synchronous grammar and integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="409" to="420" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
