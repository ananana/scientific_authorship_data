<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Don&apos;t Throw Those Morphological Analyzers Away Just Yet: Neural Morphological Disambiguation for Arabic</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><surname>Zalmout</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
						</author>
						<title level="a" type="main">Don&apos;t Throw Those Morphological Analyzers Away Just Yet: Neural Morphological Disambiguation for Arabic</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="704" to="713"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
					<note>Computational Approaches to Modeling Language Lab New York University Abu Dhabi United Arab Emirates</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper presents a model for Arabic morphological disambiguation based on Recurrent Neural Networks (RNN). We train Long Short-Term Memory (LSTM) cells in several configurations and embedding levels to model the various morphological features. Our experiments show that these models outperform state-of-the-art systems without explicit use of feature engineering. However, adding learning features from a morphological analyzer to model the space of possible analyses provides additional improvement. We make use of the resulting morphological models for scoring and ranking the analyses of the morphological analyzer for morphological disambiguation. The results show significant gains in accuracy across several evaluation metrics. Our system results in 4.4% absolute increase over the state-of-the-art in full morphological analysis accuracy (30.6% relative error reduction), and 10.6% (31.5% relative error reduction) for out-of-vocabulary words.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recurrent Neural Networks (RNN) in general, and Long Short-Term Memory (LSTM) cells in par- ticular, have been proven very successful for vari- ous Natural Language Processing (NLP) tasks, es- pecially those involving sequential data tagging. RNN models can produce near or above state- of-the-art performance with minimal language- specific feature engineering. These models have the capacity of capturing syntactic and seman- tic features through the lexical word-level embed- dings, and subword features through character- level embeddings.</p><p>Morphologically rich languages pose many challenges to NLP through their high degree of ambiguity and sparsity. These challenges are ex- acerbated for languages with limited resources. Morphological analyzers help reduce sparsity by providing several out-of-context morpheme-based analyses for words, but they usually introduce am- biguity by returning multiple analyses for the same surface form. Therefore, the model would require a further step of morphological disambiguation to choose the correct analysis in context.</p><p>Morphological modeling involves heavy use of sequential tagging, so using an LSTM-based model would be highly advantageous. LSTM models are also optimal for long-sequence tagging in particular, so such systems should be able to outperform other deep learning models with fixed window-based modeling. Morphological disam- biguation is a well studied problem in the litera- ture, but LSTM-based contributions are still rela- tively scarce. In this paper we use Bidirectional- LSTM (Bi-LSTM) models for morphological tag- ging and language modeling, and use the results of these models in ranking the analyses of the mor- phological analyzer. We incorporate various sub- word and morphological features at different lin- guistic depths in the tagger, along with both word- based and character-based embeddings.</p><p>Our results show significant accuracy gains for all the morphological features we study, and across several evaluation metrics. We compare our system against a strong baseline and a state- of-the-art-system. We achieve 4.4% absolute over the state-of-the-art in full morphological analysis accuracy (30.6% relative error reduction). When evaluated for the out-of-vocabulary (OOV) words alone, the system achieves 10.6% absolute in- crease (31.5% relative error reduction), and shows significant performance boost across all evaluation metrics. <ref type="bibr">704</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Linguistic Issues</head><p>What distinguishes morphologically rich lan- guages (MRL), like Arabic, from other languages is that their words include more morphemes (such as prefixes and suffixes) representing a number of morphological features, e.g., gender, number, per- son, mood, as well as attachable clitics. <ref type="table">Table 1</ref> shows the set of 16 Arabic morphological features we model As a result, MRLs tend to have more fully inflected words (types) than their poor coun- terparts. For instance when comparing Modern Standard Arabic (an MRL) with English (not an MRL), the total number of Arabic words in a large corpus is 20% less than the English parallel ver- sion of the corpus; however the the total number of unique Arabic types is twice that of English <ref type="bibr" target="#b10">(El Kholy and Habash, 2010</ref>  <ref type="table" target="#tab_2">Person  asp  Aspect  mod  Mood  vox  Voice  prc0  Proclitic 0, article proclitic  prc1  Proclitic 1, preposition proclitic  prc2  Proclitic 2, conjunction proclitic  prc3</ref> Proclitic 3, question proclitic enc0 Enclitic <ref type="table">Table 1</ref>: The morphological features we use in the various models. The first two groups are lexical features; and the last two groups are inflectional and clitic features respectively, in addition to the part-of-speech tag.</p><p>Furthermore, MRLs have a tendency towards a higher degree of ambiguity, stemming from dif- ferent interpretations of the same surface mor- phemes. In Modern Standard Arabic (MSA), this ambiguity is exacerbated by the language's diacritzation-optional orthography-leading a word to have about 12 analyses per word on average . These two issues, form rich- ness and form ambiguity, are at the heart of why MRLs are challenging to NLP. Richness of form increases model sparsity, and ambiguity makes disambiguation harder. <ref type="table" target="#tab_2">Table 2 shows an exam- ple of the various in-context and out-of-context   morphological analyses of the word    qymtha 1</ref> ('its value' among other readings). A potential solution is to build a morphological analyzer, also known as morphological dictionary, that encodes all the word inflections in the lan- guage. A good morphological dictionary should cover all the inflected forms of a word lemma (richness); and return all the possible analyses of a surface word (ambiguity). Finally, both rich- ness and ambiguity are more challenging when an MRL has limited data, and when the data is noisy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background and Related Work</head><p>Deep learning models have recently emerged as a viable approach for several morphological model- ing tasks in general. Neural approaches are par- ticularly appealing due to their generic modeling capabilities that can be scaled to multiple tasks, and for less reliance on specific feature engineer- ing. Notable contributions include the work of <ref type="bibr" target="#b4">Collobert et al. (2011)</ref>, where they present a learn- ing model that is applicable to several NLP tasks, like chunking, named entity recognition, and part- of-speech (POS) tagging, by deliberately avoid- ing task-specific feature engineering. They use a window-based deep neural network. The fixed window size, however, limits access to further parts of the sentence that might be relevant to the target word. Moreover, the analysis is applied on the surface word level only, without considering any subword features. Several other contributions utilize somewhat similar approaches, with vari- ous neural architectures ( <ref type="bibr" target="#b36">Wang et al., 2015;</ref><ref type="bibr" target="#b18">Huang et al., 2015)</ref>. Dos Santos and Zadrozny (2014), on the other hand, argue that subword information is useful for certain NLP tasks, like POS tagging. They propose a character-based embedding along with the word embeddings, to be able to capture internal morphemic structures. Character embed- dings, capturing subword features, are well stud- ied in other contributions too ( <ref type="bibr" target="#b22">Labeau et al., 2015;</ref><ref type="bibr" target="#b31">Rei et al., 2016;</ref><ref type="bibr" target="#b3">Belinkov and Glass, 2015)</ref>.</p><p>Morphological disambiguation, however, has wAšArt AlSHyf¯ h Alý An tAryx rsm AllwH¯ h lys mErwfA AlA An qymthA tqdr b 25 mlywn dwlAr .</p><p>The newspaper pointed out that the date of the painting is unknown, but its value is estimated at 25 million dollars.   Arabic morphological analysis and disambigua- tion have seen a considerable amount of work, spanning both MSA ( <ref type="bibr" target="#b13">Habash and Rambow, 2005;</ref><ref type="bibr" target="#b7">Diab et al., 2004;</ref><ref type="bibr" target="#b20">Khalifa et al., 2016;</ref><ref type="bibr" target="#b1">Abdelali et al., 2016)</ref>, and Dialectal Arabic ( <ref type="bibr" target="#b9">Duh and Kirchhoff, 2005;</ref><ref type="bibr" target="#b2">Al-Sabbagh and Girju, 2012;</ref>. The current state-of-the-art system is MADAMIRA ( <ref type="bibr" target="#b29">Pasha et al., 2014)</ref>; which uses SVMs to disambiguate among a target word's var- ious morphological analyses provided by a mor- phological dictionary.</p><p>Neural-based contributions for Arabic, how- ever, are also relatively scarce. Among the contri- butions that utilize morphological structures to en- hance the neural models in different NLP tasks, we note <ref type="bibr" target="#b12">Guzmán et al. (2016)</ref> for machine translation, and <ref type="bibr" target="#b0">Abandah et al. (2015)</ref> for diacritization. <ref type="bibr">Darwish et al. (2017)</ref> use Bi-LSTM models to train a POS tagger, and compare it against SVM-based models. The SVM models in their system out- perform the neural model, even with incorporat- ing pre-trained embeddings. <ref type="bibr" target="#b17">Heigold et al. (2016)</ref> developed character-based neural models for mor- phological tagging for 14 different languages, in- cluding Arabic, using the UD treebank. Most re- lated to our work though is by <ref type="bibr" target="#b34">Shen et al. (2016)</ref>, who applied their Bi-LSTM morphological disam- biguation model on MSA, but did not present any improvements over the state-of-the-art.</p><p>Occurring in parallel to our work, Inoue et al. (2017) used multi-task learning to model fine- grained POS tags, using the individual mor- phosyntactic features. They also use dictionary in- formation concatenated to the word embeddings, similar to the approach we use in this paper, and use the same dataset. Our approach provides slightly higher accuracy scores for the individual features, but the joint features score in their sys- tem is higher.</p><p>In this paper we study various architectures for neural based morphological tagging. We then use these architectures, along with neural language modeling systems, to train models for various Ara- bic morphological features. We utilize these mod- els for morphological disambiguation of the opti- mal analysis for each given word in context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach</head><p>The morphological disambiguation task involves choosing the correct morphological analysis from the set of potential analyses, obtained from the an-alyzer. Towards that end, we train several mod- els for the individual morphological features, and use their results to score and rank the different analyses and choose an optimal overall analysis. These features can be grouped into non-lexical features, where a tagger is used to obtain the rel- evant morphological tag, or morphological fea- ture tagging, and lexical features that need a lan- guage model <ref type="bibr" target="#b32">(Roth et al., 2008)</ref>, or neural lan- guage models. <ref type="table">Table 1</ref> shows the set of morpho- logical features we work with. The lexical fea- tures are handled with a language model, while the inflectional, clitic, and part-of-speech features are handled with a tagger.</p><p>We use Bi-LSTM-based taggers for the mor- phological feature tagging tasks, with various em- bedding levels and morphological features. We in- vestigate the different architectures and design op- tions in detail in Section 5. We then use the best design to build 14 different taggers, each specific to an individual feature. We also use LSTM-based neural language models for the lexical features. We discuss the neural language models in more detail in Section 6.</p><p>We then use the results for these various models to score the potential morphological analyses from the analyzer for each given word. These scores are used to rank the analyses and return the one with the highest result. The process of scoring is also tuned through tuning weights for the used features. The details of the ranking and disambiguation pro- cess are provided in Section 6.</p><p>Dataset: We use the Penn Arabic Treebank (PATB parts 1,2 and 3) ( <ref type="bibr" target="#b23">Maamouri et al., 2004</ref>) for all the experiments in this paper. We fol- low the data splits recommend by  for training, dev, and testing sets. We use Alif/Ya and Hamza normalization, and we remove all diacritics. The pre-trained word embeddings are trained using the LDC's Gigaword corpus for MSA (Parker et al., 2011). <ref type="table" target="#tab_4">Table 3</ref> shows the over- all data sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Size  Evaluation: We use accuracy as the evaluation metric for all experiments reported in the paper.</p><p>Baselines: We use the Maximum Likelihood Es- timation (MLE) baseline, calculated by count- ing the frequency scores for each given word/tag out of context, with backoff to the most fre- quent tag for unknown words. We also use the MADAMIRA (release-2.1) scores as another baseline, designated as the state-of-the-art sys- tem. Unless otherwise specified, MADAMIRA was configured in the ADD_PROP backoff mode, which adds a proper noun analysis to all words. We use this configuration to match the analyzer format we used in training the deep learning sys- tem, and to match the models in previous contri- butions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Neural Morphological Feature Tagging Architectures</head><p>The task of morphological tagging in general re- lies on the context for accurate analysis. Such tasks can be modeled as a sequential data tag- ging problem, with both word and subword em- beddings. While word embeddings are used to convey syntactic and semantic features, subword embeddings convey morphological features. We present our morphological tagging model in this section, and use the POS feature as a test case. We then generalize our findings for all the other features for the morphological disam- biguation process in Section 6. The POS tag set we use is the MADAMIRA tag set presented at ( <ref type="bibr" target="#b29">Pasha et al., 2014</ref>), and covered in detail at the MADAMIRA manual ( <ref type="bibr" target="#b30">Pasha et al., 2013)</ref>, com- prised of 34 tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Deep Learning Model</head><p>Given a sentence consisting of N words {w 1 , w 2 , ..., w N }, every word w i is converted into a vector</p><formula xml:id="formula_0">v i = [r wrd ; r morph ]</formula><p>which is composed of the word (or character se- quence) embedding vector r wrd , and the morpho- logical features embedding vector r morph . The morphological features vector can be constructed through various constructs, representing morpho- logical and/or subword units. We then use two LSTM layers to model the rele- vant context for both directions of the target word, where the input is represented by the v n vectors mentioned above:</p><formula xml:id="formula_1">− → c i = g(v i , − → c i−1 ) ← − c i = g(v i , ← − c i+1 )</formula><p>We join both sides, apply a non-linearity function, and softmax to get a probability distribution. We use two hidden layers of size 800. Each layer is composed of two LSTM layers for each direction, and a dropout wrapper with keep probability of 0.8, and peephole connections. We use Adam opti- mizer ( <ref type="bibr" target="#b21">Kingma and Ba, 2014</ref>) with a learning rate of 0.003, and cross-entropy cost function. We use Tensorflow as the development environment. (c) Potential POS tags from a morphological dictionary We use a high coverage morpholog- ical dictionary to obtain all possible POS tags of the target word. This requires advanced re- sources/annotations of the language. We include the set of potential tags in a vector representation and concatenate it with the word embedding. The vector representation of these features is made up of the sum of the one-hot vectors for each individual component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Word and Character Embeddings</head><p>Using character-level embeddings has recently been proven proficient for various NLP problems. In this paper we also study the effect of using word-level vs character-level embeddings on the overall morphological tagging problem, especially in light of the various subword and morphologi- cal features that we utilize. For word-level em- beddings, we pre-train the word vectors using Word2Vec ( <ref type="bibr" target="#b24">Mikolov et al., 2013</ref>) on the Gigaword corpus mentioned in Section 4 (and <ref type="table" target="#tab_4">Table 3</ref>), and the text of the training dataset. The embedding dimension for the words is 250. For the character- level embeddings, we concatenate the word em- beddings with the sequence of character embed- dings, initialized with their one-hot representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Accuracy MLE Baseline 92.5 MADAMIRA (no backoff) 95.9 MADAMIRA (with backoff) 97.0  <ref type="table">Table 5</ref>: Results for word embeddings (Word) and character-level embeddings (Char) for POS tag- ging. We don't provide character-level embed- dings results for the Fixed Character Affixes ap- proach, because such features would be redundant with the character embeddings themselves. <ref type="table" target="#tab_5">Table 4</ref> shows the baseline scores for the sys- tems, including the results for MADAMIRA with and without backoff. <ref type="table">Table 5</ref> shows the results for all systems. The results show clear improvement for all systems over the baseline and state-of-the- art without using subword. In fact, our system with no morphology outperforms MADAMIRA without using backoff. While our best result outperforms both MADAMIRA systems. Af- fixes (fixed length or lightstemmer) in general in- crease the accuracy across all systems. We no- tice, however, that the performance doesn't vary much between the fixed-width and lightstemmer affixes. This proves that the Bi-LSTM model is powerful enough to identify relevant features from a character-stream only, without the need for language-specific affixes. Using the morpholog- ical dictionary has the largest effect of improve- ment across all systems (among the three mor- phology features used): 0.8% over the next best approach (absolute score difference). We obtain the highest accuracy scores when incorporating both the morphological dictionary tags, and af- fixes, whether for the fixed-width or the lightstem- mer approaches. This system shows 20.0% er- ror reduction over MADAMIRA with backoff, and 41% error reduction without backoff.</p><p>The character-level embedding system shows a somewhat similar behavior in terms of relative per- formance. We do not provide the results for the Fixed Character Affixes approach here since the character embeddings would capture these fixed affixes within the overall embedding vector any- way. Hence, it will only provide redundant repre- sentation without any additional information.</p><p>We observe that the character-based system, without any additional features, outperforms the word-based system. This is expected, since the system has access to subword features, conveyed in the characters stream, that are not available for the word-based system. The same behavior per- sists with the lightstemmer, but the performance gap is smaller, since the word-based system is now provided with similar subword features that the character stream conveys. These subword features are somewhat redundant for the character-based system, so the performance is only slightly better.</p><p>Surprisingly, however, both systems perform exactly the same when using the morphological dictionary features. This indicates that the mor- phological features are powerful enough to convey and exceed the subword features that a character stream can convey.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">POS Tagging Error Analysis</head><p>We analyzed the resulting tag predictions against the gold tags by transforming the POS tag set space into four categories: nominals, verbs, par- ticles, and punctuation, and observed the resulting error patterns. We noticed that the errors' distri- bution across all developed systems is somewhat similar throughout the four different categories. Nominals dominate almost 80.0% of all errors, even though they constitute 61.5% only of the to- tal tokens. When introducing the morphological dictionary tags as features, all four categories in- crease in accuracy (except for the punctuation, be- ing tagged almost correctly at all systems). Verbs, however, have the highest accuracy increase, at 1.5%, relative to 1.0% for nominals and 0.8% for particles. This can be the result of verbs being the least common category in the dataset at 8.0% (vs 64.0%, 14.0%, and 12.0% for nominals, par- ticles, and punctuation, respectively). The nomi- nals set is also relatively bigger than the other cat- egories, which makes it internally confusable with errors within the nominals' options, like noun_adj or noun_num/noun_quant, among others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Morphological Disambiguation</head><p>In this section we apply the morphological feature tagging architecture we discussed earlier for POS tagging to the remaining morphological features. We use the results of these taggers, along with the language models for diac and lex, as the input to the scoring and ranking process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Morphological Tagging Models</head><p>Section 5 shows that the best performing neural ar- chitecture for POS tagging, as an example of mor- phological tagging in general, is using the embed- dings (either character-based or word-based) with the relevant morphological tags from the dictio- nary, along with fixed or lightstemmer affixes. The performance of both word and character embed- dings in this architecture was similar, so we opt for the word embeddings due to the excessive compu- tational overhead affiliated with training character- level embeddings.</p><p>We apply the same architecture for the 14 mor- phological, non-lexical, features we study in this paper. <ref type="table">Table 6</ref> shows the results for the differ- ent taggers, relative to the MLE and MADAMIRA baselines that we used in the previous section. All features show significant performance boost.</p><p>Notable features though include case and state, where good tagging requires a relatively wide analysis window surrounding the target word. These features have the biggest performance gap between the baselines and the Bi-LSTM approach among the various other features. This is mainly due to the fact that LSTM cells have the capabil- ity of maintaining a longer sequence memory than the other approaches, hence capturing more of the sentence structure when tagging, compared to tra- ditional window-based approaches. </p><note type="other">cas num gen vox mod stt asp per enc0 prc0 prc1 prc2 prc3</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLE</head><p>92.5 80.5 98.3 97.5 97.7 97.4 90.2 97.9 97.9 98.3 97.9 98.5 97.9 99.6 MADAMIRA 97.0 91.1 99.5 99.4 99.1 99.1 97.0 99.3 99.2 99.6 99.6 99.6 99.6 99.9 Bi-LSTM 97.6 94.5 99.6 99.5 99.2 99.4 97.9 99.4 99.4 99.7 99.7 99.8 99.7 99.9 Disambiguated Bi-LSTM 97.9 94.8 99.7 99.7 99.4 99.6 98.3 99.6 99.6 99.8 99.8 99.9 99.  <ref type="table">Table 6</ref>: Morphological tagging results. The absolute increase and error reduction are of the disam- biguated Bi-LSTM against MADAMIRA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Neural Language Models</head><p>In addition to the morphological taggers for the non-lexical features, we use neural language mod- els for the lemmatization and diacritization fea- tures. Lemmas and diacratized forms are lexi- cal in nature, and cannot be modeled directly us- ing a classifier. We use an LSTM-based neu- ral language model <ref type="bibr" target="#b11">(Enarvi and Kurimo, 2016)</ref>, with class-based input rather than words. Using a class-based approach speeds convergence dras- tically and improves the overall perplexity, espe- cially for the diac (diacritization) language model, which has a relatively large type count. We use the MKCLS tool (Och, 1999), through GIZA++ ( <ref type="bibr" target="#b27">Och and Ney, 2003)</ref>, to train the word classes. We use two hidden layers of size 500 and input layer of size 300, and use Nesterov Momen- tum as the optimization algorithm.</p><p>We encode the testing set in the HTK Standard Lattice Format (SLF), with a word mesh represen- tation for the various options of each word. <ref type="table">Table 7</ref> shows the accuracy results of the language models for lex and diac for both MADAMIRA (which uses SRILM <ref type="bibr" target="#b35">(Stolcke, 2002</ref>) for language modeling), and the LSTM model we use here. All models are trained on the same ATB training dataset used in the paper. The LSTM results outperform MADAMIRA's vastly, proving the superiority of neural language models. 3-gram model disambiguated 96.2 87.7</p><p>Our system (LSTM) 89.6 73.5</p><p>Our system disambiguated 96.9 91.7 <ref type="table">Table 7</ref>: The language model accuracy scores for both MADAMIRA and the LSTM models, for the lex and diac features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Disambiguation</head><p>We use a similar morphological disambiguation approach to the model proposed by <ref type="bibr" target="#b13">Habash and Rambow (2005)</ref> and <ref type="bibr" target="#b32">Roth et al. (2008)</ref>, where the resulting morphological features are matched and scored against the morphological analyzer op- tions, as a way to rank the different analyses, and tuned using feature weights. If the analysis and the predicted morphological tag for a feature of a given word match, the analysis score for that anal- ysis is incremented by the weight corresponding to that feature. The morphological analysis with the highest score is chosen as the disambiguated option. Any tie-breaking after the disambiguation is handled through random selection among the reduced op- tions 2 . For feature weight tuning we use the approach presented by <ref type="bibr" target="#b32">Roth et al. (2008)</ref>, us- ing the Downhill Simplex Method <ref type="bibr" target="#b25">(Nelder and Mead, 1965)</ref>. A tuning dataset of almost 2K lines (∼63K words) is randomly selected from the train- ing dataset. We retrain all the systems using the remaining training dataset, to be used in the tun- ing process. We finally use the resulting optimal weights in the original systems, trained on the full training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Evaluation</head><p>We use the following accuracy metrics to evalu- ate the disambiguation model, which <ref type="bibr" target="#b29">Pasha et al. (2014)</ref> also use in their evaluation:</p><p>• EVALFULL: The percentage of correctly an- alyzed words across all morphological fea- tures. This is the strictest possible metric.</p><p>• EVALDIAC: The percentage of words where the chosen analysis has the correct fully dia- critized form.  <ref type="table">Table 8</ref>: Accuracy results of the disambiguation system, evaluated using different metrics, for all words and out-of-vacbulary (OOV) words alone. OOV percentage of all words is 7.9%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evalustion Metric</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All Words Out-Of-Vocabulary Words MADAMIRA Our System Error Reduction MADAMIRA Our System Error Reduction</head><p>• EVALLEX: The percentage of words where the chosen analysis has the correct lemma.</p><p>• EVALPOS: The percentage of words where the chosen analysis has the correct part-of- speech.</p><p>• EVALATBTOK: The percentage of words that have a correct ATB tokenization. 3</p><p>Deep learning models, through word embed- dings, provide an advantage in terms of the anal- ysis of unseen words. So, in addition to calcu- lating the metrics for all the words in the testing set, we also calculate these metrics for the out-of- vocabulary (OOV) words alone. <ref type="table">Table 8</ref> shows the accuracy scores for MADAMIRA and our system. All evaluation met- rics indicate the performance boost of our sys- tem relative to MADAMIRA, with significant rel- ative error reduction. The same trend stands for the OOV words, with even higher absolute and relative error reduction scores, especially for EVALLEX, EVALPOS, and EVALATBTOK. This increase in OOV analysis accuracy is the re- sult of modeling the data on a semantic level, with the embeddings and neural networks, instead of pure lexical approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Discussion</head><p>We conducted additional data analysis over the test set comparing the performance of our system to MADAMIRA.</p><p>Comparative Error Patterns When consider- ing full analyses, we observe that our system still makes some errors in words where MADAMIRA is correct. However, the number of times our sys- tem is correct and MADAMIRA is not is over twice as the reverse (MADAMIRA is correct and our system is not). From a manual analysis of a sample of 500 words, we observe the majority of the instances where MADAMIRA was cor- rect and our system failed involved the case fea- tures. This is not surprising since case is one the features our system still struggles with al- though we have made major improvements be- yond MADAMIRA. <ref type="bibr" target="#b33">Shahrour et al. (2015)</ref> used syntax as an additional model to improve the anal- ysis of case. Our model still improves the accu- racy beyond theirs, but this highlights the value of using syntax in future work.</p><p>Minority Feature-Value Pairs While we show a lot of improvements across the board above in terms of accuracy, we also observe very large im- provements in the performance on some minority feature-value pairs. For example, among the val- ues of the case feature, the nominative (cas:n) and accusative (cas:a) appear about 7.0% and 11.0% of all words, respectively, of all the values of case. We improve the F-1 score from 70.4% in MADAMIRA to 84.1% in our system for (cas:n); and we similarly improve the F-1 score from 76.7% in MADAMIRA to 85.5% in our system for (cas:a). We also observe similar improvement in the mood feature, with the F-1 score for sub- junctive mood (occurring 0.55% of all words) in- creasing from 76.9% in MADAMIRA to 89.5%.</p><p>This great increase was not observed across all features. The F1-score of the passive voice feature-value pair (vox:p) occurring 0.6% of all words (and 7.0% of all verbs) only increased from 70.1% in MADAMIRA to 73.4% in our system. Voice in Arabic is harder to model than mood and case since some verbal constructions can be rather ambiguous even for human readers; for ex- ample, the noun phrase AlkAtb¯ h Alty nšrt mqAlthA has two readings 'the writer who published her article' (active voice) or 'the writer whose article was published' (passive voice). Case and mood are more likely to be de-terminable from the context using long and short- distance syntactic clues. In the example above the case of the noun mqAlthA 'her article' is de- pendent on the voice reading of the verb, which determines if the noun is the subject or object of the verb. For another example, the F1-score of the 2nd person feature-value pair (per:2) occurring 0.05% of all words (and 0.5% of all verbs) only in- creased from 29.7% in MADAMIRA to 31.7% in our system. The very low performance in the 2nd person makes sense, since the corpus we used is a news corpus where the 2nd person is hardly ever used. We would expect more training data to help such feature-value pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper we presented an LSTM-based mor- phological disambiguation system for Arabic. The system significantly outperforms a state-of-the-art system. Our experiments showed that enriching the input word embedding with additional mor- phological features increases the morphological tagging accuracy drastically, beyond the capabil- ities of even character-level embeddings. We also showed that using an LSTM based system pro- vides a significant performance boost for syntax based features, which often require wide context window for accurate tagging. Future directions include exploring additional deep learning architectures for morphological modeling and disambiguation, especially joint and sequence-to-sequence models. We also intend to further investigate the role of syntax features in morphological disambiguation, and explore addi- tional techniques for more accurate tagging. Fi- nally, we aim at applying our models to Ara- bic dialects and other languages. We expect that character-level embeddings will have a bigger role in scenarios with noisy input, such as non-standard spontaneous orthography used in social media.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>subword and Morphological Features Several features can be used to represent the r morph vec- tors mentioned before. These features are utilized to convey morphological information that are not represented at the word-level embeddings. We use various features with various linguistic depth: (a) Fixed-width affixes We represent the pre- fixes and suffixes through a fixed character length substring from the beginning and the end of every word. This requires no linguistic information. We use a subset of three characters on both ends. (b) Language-specific affixes (lightstemmer) We use regular expressions to maximally match affix patterns at the word's beginning and end. This requires basic linguistic knowledge of the tar- get language, but doesn't require any large-scale lexical resources or annotated corpora.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>) .</head><label>.</label><figDesc></figDesc><table>Feature 
Definition 
diac 
Diacratization 
lex 
Lemma 
pos 
Basic part-of-speech tags (34 tags) 
gen 
Gender 
num 
Number 
cas 
Case 
stt 
State 
per 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>An example highlighting Arabic's rich morphology and ambiguous orthography. The word 




qiymatahA 'its value' has a specific analysis in the context of the sentence shown at the top of the 

table; but it has many other analyses and diacritizations out of context. The correct analysis is bolded 
(4th from the bottom of the list). 

relatively fewer deep learning contributions. 
Yildiz et al. (2016) presented a disambiguation 
model for Turkish based on Convolutional Neural 
Networks (CNN). Their model creates a represen-
tation for the surface form of a word from the root 
along with a set of morphemic features. Then they 
train a model to predict the optimal analysis of a 
word given the annotations within a context win-
dow. Shen et al. (2016), on the other hand, use 
a character-based Bi-LSTM model for morpho-
logical disambiguation of morphologically com-
plex languages, without using a morphological an-
alyzer. The LSTM cells have the advantage of cap-
turing a longer sequence window than those of the 
fixed window and CNN approaches. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Dataset statistics</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Maximum Likelihood Estimation (MLE) 
and MADAMIRA baselines for POS tagging. 

Model 
Embedding 
Word Char 
No Morphology 
96.4 96.7 
Fixed Character Affixes 
96.6 
NA 
Lightstemmer 
96.7 96.8 
Morphological Dictionary 
97.5 97.5 
+ Fixed Character Affixes 97.6 
NA 
+ Lightstemmer 
97.6 97.6 

</table></figure>

			<note place="foot" n="1"> All Arabic transliterations are provided in the HabashSoudi-Buckwalter transliteration scheme (Habash et al., 2007).</note>

			<note place="foot" n="2"> This results in %0.02 variation range only in the EVALFULL end result.</note>

			<note place="foot" n="3"> ATB scheme tokenizes all clitics except the + Al &apos;the&apos; determiner.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The first author was sup-ported by the New York University Abu Dhabi Global PhD Student Fellowship program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Automatic diacritization of Arabic text using recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gheith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Abandah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balkees</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaa</forename><surname>Al-Shagoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuad</forename><surname>Arabiyat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Majid</forename><surname>Jamour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Al-Taee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Document Analysis and Recognition (IJDAR)</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="183" to="197" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Farasa: A fast and furious segmenter for Arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Abdelali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadir</forename><surname>Durrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A supervised pos tagger for written Arabic social networking corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rania</forename><surname>Al</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Sabbagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KONVENS 2012</title>
		<meeting>KONVENS 2012</meeting>
		<imprint>
			<publisher>OGAI</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="39" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Arabic diacritization with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2281" to="2285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Arabic POS tagging: Don&apos;t abandon feature engineering just yet</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Arabic Natural Language Processing Workshop</title>
		<editor>Kareem Darwish, Hamdy Mubarak, Ahmed Abdelali, and Mohamed Eldesouki</editor>
		<meeting>the Third Arabic Natural Language Processing Workshop<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1309.5652</idno>
		<title level="m">LDC Arabic treebanks and associated corpora: Data divisions manual</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Tagging of Arabic Text: From Raw Text to Base Phrase Chunks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kadri</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04)</title>
		<meeting>the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04)<address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="149" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning character-level representations for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dos</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1818" to="1826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">POS tagging of dialectal Arabic: a minimally supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, Semitic &apos;05</title>
		<meeting>the ACL Workshop on Computational Approaches to Semitic Languages, Semitic &apos;05<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Techniques for Arabic Morphological Detokenization and Orthographic Denormalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">El</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the seventh International Conference on Language Resources and Evaluation (LREC)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Theanolm-an extensible toolkit for neural network language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seppo</forename><surname>Enarvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</author>
		<idno>abs/1605.00942</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Machine translation evaluation for Arabic using morphologically-enriched embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramy</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the International Conference on Computational Linguistics</title>
		<meeting>COLING 2016, the International Conference on Computational Linguistics<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1398" to="1408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the ACL</title>
		<meeting>the 43rd Annual Meeting of the ACL<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="573" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Morphological analysis and disambiguation for dialectal Arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT<address><addrLine>Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="426" to="432" />
		</imprint>
	</monogr>
	<note>Ramy Eskander, and Nadi Tomeh. Atlanta</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On Arabic Transliteration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelhadi</forename><surname>Soudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Buckwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Arabic Computational Morphology: Knowledge-based and Empirical Methods</title>
		<editor>A. van den Bosch and A. Soudi</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Introduction to Arabic natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Habash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scaling character-based morphological tagging to fourteen languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Big Data (Big Data)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3895" to="3902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<title level="m">Bidirectional LSTM-CRF models for sequence tagging</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint prediction of morphosyntactic categories for fine-grained Arabic part-of-speech tagging exploiting tag dictionary information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Go</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st SIGNLL Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 21st SIGNLL Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Yamama: Yet another multi-dialect Arabic morphological analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><surname>Salam Khalifa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Zalmout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics (COLING): System Demonstrations</title>
		<meeting>the International Conference on Computational Linguistics (COLING): System Demonstrations<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="223" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Non-lexical neural architecture for fine-grained pos tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Labeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Löser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rue</forename><surname>John Von Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="232" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Maamouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Buckwalter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wigdan</forename><surname>Mekki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NEMLAR Conference on Arabic Language Resources and Tools</title>
		<meeting><address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="102" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simplex method for function minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Nelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="308" to="313" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">An efficient method for determining bilingual word classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on European Chapter of the Association for Computational Linguistics, EACL &apos;99</title>
		<meeting>the Ninth Conference on European Chapter of the Association for Computational Linguistics, EACL &apos;99<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="71" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A systematic comparison of various statistical alignment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Arabic Gigaword Fifth Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">LDC catalog number No. LDC2011T11</title>
		<imprint>
			<biblScope unit="page" from="1" to="58563" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arfath</forename><surname>Pasha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Al-Badrashiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">El</forename><surname>Kholy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramy</forename><surname>Eskander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Pooleery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arfath</forename><surname>Pasha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Al-Badrashiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Pooleery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<ptr target="http://www.nizarhabash.com/publications/MADAMIRA-UserManual.pdf" />
		<title level="m">MADAMIRA v1.0 User Manual</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Attending to characters in neural sequence labeling models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Gamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pyysalo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04361</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cynthia</forename><surname>Rudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2008: The Conference of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improving Arabic diacritization through syntactic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anas</forename><surname>Shahrour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salam</forename><surname>Khalifa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1309" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The role of context in neural morphological disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinlan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Clothiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Tagtow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="181" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SRILM-an Extensible Language Modeling Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Spoken Language Processing (ICSLP)</title>
		<meeting>the International Conference on Spoken Language Processing (ICSLP)<address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="901" to="904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Part-of-speech tagging with bidirectional long short-term memory recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno>abs/1510.06168</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A morphology-aware network for morphological disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eray</forename><surname>Yildiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Tirkaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bahadir Sahin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Tolga Eren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sonmez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2863" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
