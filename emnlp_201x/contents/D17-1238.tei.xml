<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Why We Need New Evaluation Metrics for NLG</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Dušek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><forename type="middle">Cercas</forename><surname>Curry</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical and Computer Sciences</orgName>
								<orgName type="institution">Heriot-Watt University</orgName>
								<address>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Why We Need New Evaluation Metrics for NLG</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2241" to="2252"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The majority of NLG evaluation relies on automatic metrics, such as BLEU. In this paper, we motivate the need for novel, system-and data-independent automatic evaluation methods: We investigate a wide range of metrics, including state-of-the-art word-based and novel grammar-based ones, and demonstrate that they only weakly reflect human judgements of system outputs as generated by data-driven, end-to-end NLG. We also show that metric performance is data-and system-specific. Nevertheless, our results also suggest that automatic metrics perform reliably at system-level and can support system development by finding cases where a system performs poorly.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic evaluation measures, such as BLEU <ref type="bibr" target="#b21">(Papineni et al., 2002</ref>), are used with increasing fre- quency to evaluate Natural Language Generation (NLG) systems: Up to 60% of NLG research published between 2012-2015 relies on automatic metrics ( <ref type="bibr" target="#b1">Gkatzia and Mahamood, 2015)</ref>. Auto- matic evaluation is popular because it is cheaper and faster to run than human evaluation, and it is needed for automatic benchmarking and tuning of algorithms. The use of such metrics is, however, only sensible if they are known to be sufficiently correlated with human preferences. This is rarely the case, as shown by various studies in NLG <ref type="bibr" target="#b27">(Stent et al., 2005;</ref><ref type="bibr">Belz and Reiter, 2006;</ref><ref type="bibr" target="#b22">Reiter and Belz, 2009)</ref>, as well as in related fields, such as dialogue systems ( , machine translation (MT) <ref type="bibr">(Callison-Burch et al., 2006</ref>), and image captioning <ref type="bibr">(Elliott and Keller, 2014;</ref><ref type="bibr" target="#b9">Kilickaya et al., 2017)</ref>. This paper follows on from the above previous work and presents another evalu- ation study into automatic metrics with the aim to firmly establish the need for new metrics. We consider this paper to be the most complete study to date, across metrics, systems, datasets and do- mains, focusing on recent advances in data-driven NLG. In contrast to previous work, we are the first to:</p><p>• Target end-to-end data-driven NLG, where we compare 3 different approaches. In contrast to NLG methods evaluated in previous work, our sys- tems can produce ungrammatical output by (a) generating word-by-word, and (b) learning from noisy data.</p><p>• Compare a large number of 21 automated met- rics, including novel grammar-based ones.</p><p>• Report results on two different domains and three different datasets, which allows us to draw more general conclusions.</p><p>• Conduct a detailed error analysis, which sug- gests that, while metrics can be reasonable indi- cators at the system-level, they are not reliable at the sentence-level.</p><p>• Make all associated code and data publicly avail- able, including detailed analysis results. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">End-to-End NLG Systems</head><p>In this paper, we focus on recent end-to-end, data- driven NLG methods, which jointly learn sentence planning and surface realisation from non-aligned data <ref type="bibr">(Dušek and Jurčíček, 2015;</ref><ref type="bibr" target="#b30">Wen et al., 2015;</ref><ref type="bibr" target="#b17">Mei et al., 2016;</ref><ref type="bibr" target="#b29">Wen et al., 2016;</ref><ref type="bibr" target="#b24">Sharma et al., 2016;</ref><ref type="bibr" target="#b19">Dušek and</ref><ref type="bibr">Jurčíček, 2016, Lampouras and</ref><ref type="bibr" target="#b10">Vlachos, 2016)</ref>. These approaches do not require costly semantic alignment between Meaning Rep- resentations (MR) and human references (also re- ferred to as "ground truth" or "targets"), but are  <ref type="table" target="#tab_0">Total  BAGEL SFREST SFHOTEL   LOLS   202  581  398 1,181   RNNLG   - 600  477 1,077  TGEN  202  - - 202  Total  404  1,181  875 2,460   Table 1</ref>: Number of NLG system outputs from dif- ferent datasets and systems used in this study.</p><p>based on parallel datasets, which can be collected in sufficient quality and quantity using effective crowdsourcing techniques, e.g. ( <ref type="bibr" target="#b20">Novikova et al., 2016)</ref>, and as such, enable rapid development of NLG components in new domains. In particular, we compare the performance of the following sys- tems:</p><p>• RNNLG: <ref type="bibr">2</ref> The system by <ref type="bibr" target="#b30">Wen et al. (2015)</ref> uses a Long Short-term Memory (LSTM) network to jointly address sentence planning and surface re- alisation. It augments each LSTM cell with a gate that conditions it on the input MR, which allows it to keep track of MR contents generated so far.</p><p>• TGEN: <ref type="bibr">3</ref> The system by <ref type="bibr">Dušek and Jurčíček (2015)</ref> learns to incrementally generate deep- syntax dependency trees of candidate sentence plans (i.e. which MR elements to mention and the overall sentence structure). Surface realisation is performed using a separate, domain-independent rule-based module.</p><p>• LOLS: <ref type="bibr">4</ref> The system by <ref type="bibr" target="#b10">Lampouras and Vlachos (2016)</ref> learns sentence planning and surface reali- sation using Locally Optimal Learning to Search (LOLS), an imitation learning framework which learns using BLEU and ROUGE as non-decomposable loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>We consider the following crowdsourced datasets, which target utterance generation for spoken dia- logue systems. <ref type="table">Table 1</ref> shows the number of sys- tem outputs for each dataset. Each data instance consists of one MR and one or more natural lan- guage references as produced by humans, such as the following example, taken from the BAGEL dataset: 5 2 https://github.com/shawnwun/RNNLG 3 https://github.com/UFAL-DSG/tgen 4 https://github.com/glampouras/JLOLS_ NLG 5 Note that we use lexicalised versions of SFHOTEL and SFREST and a partially lexicalised version of BAGEL, where proper names and place names are replaced by placeholders ("X"), in correspondence with the outputs generated by the MR: inform(name=X, area=X, pricerange=moderate, type=restaurant) Reference: "X is a moderately priced restaurant in X."</p><p>• SFHOTEL &amp; SFREST <ref type="bibr" target="#b30">(Wen et al., 2015</ref>) pro- vide information about hotels and restaurants in San Francisco. There are 8 system dialogue act types, such as inform, confirm, goodbye etc. Each domain contains 12 attributes, where some are common to both domains, such as name, type, pricerange, address, area, etc., and the others are domain-specific, e.g. food and kids-allowed for restaurants; hasinternet and dogs-allowed for ho- tels. For each domain, around 5K human refer- ences were collected with 2.3K unique human ut- terances for SFHOTEL and 1.6K for SFREST. The number of unique system outputs produced is 1181 for SFREST and 875 for SFHOTEL.</p><p>• BAGEL ( <ref type="bibr" target="#b16">Mairesse et al., 2010</ref>) provides informa- tion about restaurants in Cambridge. The dataset contains 202 aligned pairs of MRs and 2 corre- sponding references each. The domain is a subset of SFREST, including only the inform act and 8 at- tributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Word-based Metrics (WBMs)</head><p>NLG evaluation has borrowed a number of au- tomatic metrics from related fields, such as MT, summarisation or image captioning, which com- pare output texts generated by systems to ground- truth references produced by humans. We refer to this group as word-based metrics. In general, the higher these scores are, the better or more simi- lar to the human references the output is. <ref type="bibr">6</ref> The following order reflects the degree these metrics move from simple n-gram overlap to also consid- ering term frequency (TF-IDF) weighting and se- mantically similar words.</p><p>• Word-overlap Metrics (WOMs): We consider frequently used metrics, including TER (Snover • Semantic Similarity (SIM): We calculate the Se- mantic Text Similarity measure designed by <ref type="bibr" target="#b3">Han et al. (2013)</ref>. This measure is based on distri- butional similarity and Latent Semantic Analysis systems, as provided by the system authors. <ref type="bibr">6</ref> Except for TER whose scale is reversed.</p><p>(LSA) and is further complemented with semantic relations extracted from WordNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Grammar-based metrics (GBMs)</head><p>Grammar-based measures have been explored in related fields, such as MT ( <ref type="bibr">Giménez and M` arquez, 2008)</ref> or grammatical error correction ( <ref type="bibr" target="#b18">Napoles et al., 2016)</ref>, and, in contrast to WBMs, do not rely on ground-truth references. To our knowledge, we are the first to consider GBMs for sentence-level NLG evaluation. We focus on two important prop- erties of texts here -readability and grammatical- ity:</p><p>• Readability quantifies the difficulty with which a reader understands a text, as used for e.g. eval- uating summarisation ( <ref type="bibr" target="#b7">Kan et al., 2001</ref>) or text simplification <ref type="bibr">(Francois and Bernhard, 2014</ref>). We measure readability by the Flesch Reading Ease score (RE) <ref type="bibr">(Flesch, 1979)</ref>, which calculates a ra- tio between the number of characters per sentence, the number of words per sentence, and the num- ber of syllables per word. Higher RE score indi- cates a less complex utterance that is easier to read and understand. We also consider related mea- sures, such as characters per utterance (len) and per word (cpw), words per sentence (wps), syl- lables per sentence (sps) and per word (spw), as well as polysyllabic words per utterance (pol) and per word (ppw). The higher these scores, the more complex the utterance.</p><p>• Grammaticality: In contrast to previous NLG methods, our corpus-based end-to-end systems can produce ungrammatical output by (a) gener- ating word-by-word, and (b) learning from noisy data. As a first approximation of grammatical- ity, we measure the number of misspellings (msp) and the parsing score as returned by the Stanford parser (prs). The lower the msp, the more gram- matically correct an utterance is. The Stanford parser score is not designed to measure grammat- icality, however, it will generally prefer a gram- matical parse to a non-grammatical one. <ref type="bibr">7</ref> Thus, lower parser scores indicate less grammatically- correct utterances. In future work, we aim to use specifically designed grammar-scoring functions, e.g. ( <ref type="bibr" target="#b18">Napoles et al., 2016</ref>), once they become pub- licly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Human Data Collection</head><p>To collect human rankings, we presented the MR together with 2 utterances generated by differ- ent systems side-by-side to crowdworkers, which were asked to score each utterance on a 6-point Likert scale for:</p><p>• Informativeness: Does the utterance provide all the useful information from the meaning represen- tation?</p><p>• Naturalness: Could the utterance have been produced by a native speaker?</p><p>• Quality: How do you judge the overall quality of the utterance in terms of its grammatical cor- rectness and fluency?</p><p>Each system output (see <ref type="table">Table 1</ref>) was scored by 3 different crowdworkers. To reduce participants' bias, the order of appearance of utterances pro- duced by each system was randomised and crowd- workers were restricted to evaluate a maximum of 20 utterances. The crowdworkers were selected from English-speaking countries only, based on their IP addresses, and asked to confirm that En- glish was their native language.</p><p>To assess the reliability of ratings, we calculated the intra-class correlation coefficient (ICC), which measures inter-observer reliability on ordinal data for more than two raters <ref type="bibr" target="#b11">(Landis and Koch, 1977)</ref>. The overall ICC across all three datasets is 0.45 (p &lt; 0.001), which corresponds to a moderate agreement. In general, we find consistent differ- ences in inter-annotator agreement per system and dataset, with lower agreements for LOLS than for RNNLG and TGEN. Agreement is highest for the SFHOTEL dataset, followed by SFREST and BAGEL (details provided in supplementary material).  <ref type="table" target="#tab_0">Table 2</ref>: System performance per dataset (summarised over metrics), where "*" denotes p &lt; 0.05 for all the metrics and "(*)" shows significance on p &lt; 0.05 level for the majority of the metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">System Evaluation</head><p>terms of WBMs. We observe that human informa- tiveness ratings follow the same pattern as WBMs, while the average similarity score (SIM) seems to be related to human quality ratings. Looking at GBMs, we observe that they seem to be related to naturalness and quality ratings. Less complex utterances, as measured by read- ability (RE) and word length (cpw), have higher naturalness ratings. More complex utterances, as measured in terms of their length (len), number of words (wps), syllables (sps, spw) and polysyl- lables (pol, ppw), have lower quality evaluation. Utterances measured as more grammatical are on average evaluated higher in terms of naturalness.</p><p>These initial results suggest a relation between automatic metrics and human ratings at system level. However, average scores can be mislead- ing, as they do not identify worst-case scenarios. This leads us to inspect the correlation of human and automatic metrics for each MR-system output pair at utterance level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Relation of Human and Automatic Metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Human Correlation Analysis</head><p>We calculate the correlation between automatic metrics and human ratings using the Spearman coefficient (ρ). We split the data per dataset and system in order to make valid pairwise com- parisons. To handle outliers within human rat- ings, we use the median score of the three human raters. 8 Following <ref type="bibr" target="#b9">Kilickaya et al. (2017)</ref>, we use the Williams' test <ref type="bibr" target="#b31">(Williams, 1959)</ref> to determine significant differences between correlations. Ta- ble 3 summarises the utterance-level correlation results between automatic metrics and human rat- ings, listing the best (i.e. highest absolute ρ) re- sults for each type of metric (details provided in supplementary material). Our results suggest that:</p><p>• In sum, no metric produces an even moderate correlation with human ratings, independently of dataset, system, or aspect of human rating. This contrasts with our initially promising results on the system level (see Section 6) and will be further dis- cussed in Section 8. Note that similar inconsisten- cies between document-and sentence-level eval- uation results are observed in MT ( <ref type="bibr" target="#b26">Specia et al., 2010)</ref>.</p><p>• Similar to our results in Section 6, we find that WBMs show better correlations to human ratings of informativeness (which reflects content selec- tion), whereas GBMs show better correlations to quality and naturalness.</p><p>• Human ratings for informativeness, naturalness and quality are highly correlated with each other, with the highest correlation between the latter two (ρ = 0.81) reflecting that they both target surface realisation.</p><p>• All WBMs produce similar results (see <ref type="figure" target="#fig_2">Figure 1</ref> and 2): They are strongly correlated with each other, and most of them produce correlations with human ratings which are not significantly different from each other. GBMs, on the other hand, show greater diversity.</p><p>• Correlation results are system-and dataset- specific (details provided in supplementary mate- rial). We observe the highest correlation for TGEN on BAGEL <ref type="figure" target="#fig_2">(Figures 1 and 2</ref>) and LOLS on SFREST, whereas RNNLG often shows low correlation be- tween metrics and human ratings. This lets us conclude that WBMs and GBMs are sensitive to different systems and datasets.</p><p>• The highest positive correlation is observed be- tween the number of words (wps) and informative-</p><formula xml:id="formula_0">BAGEL SFHOTEL SFREST TGEN LOLS RNNLG LOLS RNNLG LOLS</formula><p>Best inform. 0.30* (BLEU-1) 0.20* (ROUGE) 0.09 (BLEU-1) 0.14* (LEPOR) 0.13* (SIM) 0.28* (LEPOR) WBM natural. -0.19* (TER) -0.19* (TER) 0.10* (METEOR) -0.20* (TER) 0.17* (ROUGE) 0.19* (METEOR) quality -0.16* (TER) 0.16* (METEOR) 0.10* (METEOR) -0.12* (TER) 0.09* (METEOR) 0.18* (LEPOR) Best inform. 0.33* (wps) 0.16* (ppw) -0.09 (ppw) 0.13* (cpw) 0.11* (len) 0.21* (len) GBM natural. -0.25* (len) -0.28* (wps) -0.17* (len) -0.18* (sps) -0.19* (wps) -0.21* (sps) quality -0.19* (cpw) 0.31* (prs) -0.16* (ppw) -0.17* (spw) 0.11* (prs) -0.16* (sps) <ref type="table">Table 3</ref>: Highest absolute Spearman correlation between metrics and human ratings, with "*" denoting p &lt; 0.05 (metric with the highest absolute value of ρ given in brackets).  ness for the TGEN system on BAGEL (ρ = 0.33, p &lt; 0.01, see <ref type="figure" target="#fig_2">Figure 1</ref>). However, the wps met- ric (amongst most others) is not robust across sys- tems and datasets: Its correlation on other datasets is very weak, (ρ ≤ .18) and its correlation with in- formativeness ratings of LOLS outputs is insignifi- cant.</p><p>• As a sanity check, we also measure a random score [0.0, 1.0] which proves to have a close-to- zero correlation with human ratings (highest ρ = 0.09).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Accuracy of Relative Rankings</head><p>We now evaluate a more coarse measure, namely the metrics' ability to predict relative human rat- ings. That is, we compute the score of each metric for two system output sentences corresponding to the same MR. The prediction of a metric is cor- rect if it orders the sentences in the same way as median human ratings (note that ties are allowed  <ref type="table">Table 4</ref> show that most metrics' performance is not significantly different from that of a random score (Wilcoxon signed rank test). While the random score fluc- tuates between 25.4-44.5% prediction accuracy, the metrics achieve an accuracy of between 30.6- 49.8%. Again, the performance of the metrics is dataset-specific: Metrics perform best on BAGEL data; for SFHOTEL, metrics show mixed perfor- mance while for SFREST, metrics perform worst.</p><p>informat  <ref type="table">Table 4</ref>: Metrics predicting relative human rating with significantly higher accuracy than a random baseline.</p><p>Discussion: Our data differs from the one used in previous work <ref type="bibr" target="#b28">(Vedantam et al., 2015;</ref><ref type="bibr" target="#b9">Kilickaya et al., 2017)</ref>, which uses explicit relative rank- ings ("Which output do you prefer?"), whereas we compare two Likert-scale ratings. As such, we have 3 possible outcomes (allowing ties). This way, we can account for equally valid system outputs, which is one of the main drawbacks of forced-choice approaches <ref type="bibr" target="#b5">(Hodosh and Hockenmaier, 2016</ref>). Our results are akin to previous work: <ref type="bibr" target="#b9">Kilickaya et al. (2017)</ref> report results be- tween 60-74% accuracy for binary classification on machine-machine data, which is comparable to our results for 3-way classification. Still, we observe a mismatch between the or- dinal human ratings and the continuous metrics. For example, humans might rate system A and system B both as a 6, whereas BLEU, for exam- ple, might assign 0.98 and 1.0 respectively, mean- ing that BLEU will declare system B as the win- ner. In order to account for this mismatch, we quantise our metric data to the same scale as the median scores from our human ratings. <ref type="bibr">9</ref> Applied to SFREST, where we previously got our worst re- 9 Note that this mismatch can also be accounted for by continuous rating scales, as suggested by <ref type="bibr">Belz and Kow (2011).</ref> sults, we can see an improvement for predicting informativeness, where all WBMs now perform significantly better than the random baseline (see <ref type="table">Table 4</ref>). In the future, we will investigate re- lated discriminative approaches, e.g. <ref type="bibr" target="#b5">(Hodosh and Hockenmaier, 2016;</ref><ref type="bibr" target="#b8">Kannan and Vinyals, 2017)</ref>, where the task is simplified to distinguishing cor- rect from incorrect output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Error Analysis</head><p>In this section, we attempt to uncover why auto- matic metrics perform so poorly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Scales</head><p>We first explore the hypothesis that metrics are good in distinguishing extreme cases, i.e. system outputs which are rated as clearly good or bad by the human judges, but do not perform well for ut- terances rated in the middle of the Likert scale, as suggested by <ref type="bibr" target="#b9">Kilickaya et al. (2017)</ref>. We 'bin' our data into three groups: bad, which comprises low ratings (≤2); good, comprising high ratings (≥5); and finally a group comprising average ratings.</p><p>We find that utterances with low human ratings of informativeness and naturalness correlate sig- nificantly better (p &lt; 0.05) with automatic metrics than those with average and good human ratings. For example, as shown in <ref type="figure" target="#fig_5">Figure 3</ref>, the correlation between WBMs and human ratings for utterances with low informativeness scores ranges between 0.3 ≤ ρ ≤ 0.5 (moderate correlation), while the highest correlation for utterances of average and high informativeness barely reaches ρ ≤ 0.2 (very weak correlation). The same pattern can be ob- served for correlations with quality and natural- ness ratings.</p><p>This discrepancy in correlation results between low and other user ratings, together with the fact that the majority of system outputs are rated "good" for informativeness (79%), naturalness (64%) and quality (58%), whereas low ratings do not exceed 7% in total, could explain why the overall correlations are low (Section 7) despite the observed trends in relationship between average system-level performance scores (Section 6). It also explains why the RNNLG system, which con- tains very few instances of low user ratings, shows poor correlation between human ratings and auto- matic metrics.</p><p>No. system MR system output human reference WOMs SIM humans 1 LOLS inform(name = the donatello, hasinternet = yes) well there is a hotel with in- ternet access called the do- natello the donatello has internet 1. <ref type="formula">4  5  6</ref> 2 LOLS inform nomatch(area = embarcadero, kidsallowed= yes, pricerange = expensive) i but i but i but i but i but i but i but i but i but i unfortunately i could not find any expensive restaurants in embarcadero that allow kids. sorry, there are no restau- rants allowing kids and serv- ing moroccan food</p><p>1.85 4 5 <ref type="table">Table 5</ref>: Example pairs of MRs and system outputs from our data, contrasting the average of word- overlap metrics (normalised in the 1-6 range) and semantic similarity (SIM) with human ratings (median of all measures). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Impact of Target Data</head><p>Characteristics of Data: In Section 7.1, we ob- served that datasets have a significant impact on how well automatic metrics reflect human ratings. A closer inspection shows that BAGEL data differs significantly from SFREST and SFHOTEL, both in terms of grammatical and MR properties. BAGEL has significantly shorter references both in terms of number of characters and words compared to the other two datasets. Although being shorter, the words in BAGEL references are significantly more often polysyllabic. Furthermore, BAGEL only con- sists of utterances generated from inform MRs, while SFREST and SFHOTEL also have less complex MR types, such as confirm, goodbye, etc. Utter- ances produced from inform MRs are significantly longer and have a significantly higher correlation with human ratings of informativeness and natu- ralness than non-inform utterance types. In other words, BAGEL is the most complex dataset to gen- erate from. Even though it is more complex, met- rics perform most reliably on BAGEL here (note that the correlation is still only weak). One possible explanation is that BAGEL only contains two human references per MR, whereas SFHOTEL and SFREST both contain 5.35 references per MR on average.</p><p>Having more references means that WBMs natu- rally will return higher scores ('anything goes'). This problem could possibly be solved by weight- ing multiple references according to their quality, as suggested by ( <ref type="bibr">Galley et al., 2015)</ref>, or following a reference-less approach ( <ref type="bibr" target="#b26">Specia et al., 2010)</ref>. Quality of Data: Our corpora contain crowd- sourced human references that have grammatical errors, e.g. "Fifth Floor does not allow childs" (SFREST reference). Corpus-based methods may pick up these errors, and word-based metrics will rate these system utterances as correct, whereas we can expect human judges to be sensitive to ungrammatical utterances. Note that the pars- ing score (while being a crude approximation of grammaticality) achieves one of our highest cor- relation results against human ratings, with |ρ| = .31. Grammatical errors raise questions about the quality of the training data, especially when be- ing crowdsourced. For example, <ref type="bibr">Belz and Reiter (2006)</ref> find that human experts assign low rank- ings to their original corpus text. Again, weighting (Galley et al., 2015) or reference-less approaches (Specia et al., 2010) might remedy this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Example-based Analysis</head><p>As shown in previous sections, word-based met- rics moderately agree with humans on bad quality output, but cannot distinguish output of good or medium quality. <ref type="table">Table 5</ref> provides examples from</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimension of human ratings Study</head><p>Sentence Planning Surface Realisation Domain this paper weak positive (ρ = 0.33, WPS) weak negative (ρ = 0. − 31, parser) NLG, restaurant/hotel search <ref type="bibr" target="#b22">(Reiter and Belz, 2009)</ref> none strong positive (Pearson's r = 0.96, NIST) NLG, weather forecast ( <ref type="bibr" target="#b27">Stent et al., 2005)</ref> weak positive (ρ = 0.47, LSA) negative (ρ = −0.56, NIST) paraphrasing of news (  weak positive (ρ = 0.35, BLEU-4) N/A dialogue/Twitter pairs <ref type="bibr">(Elliott and Keller, 2014)</ref> positive (ρ = 0.53, METEOR) N/A image caption ( <ref type="bibr" target="#b9">Kilickaya et al., 2017)</ref> positive (ρ = 0.64, SPICE) N/A image caption <ref type="bibr">(Cahill, 2009)</ref> N/A negative (ρ = −0.64, ROUGE) NLG, German news texts ( <ref type="bibr">Espinosa et al., 2010)</ref> weak positive (ρ = 0.43, TER) positive (ρ = 0.62, BLEU-4) NLG, news texts our three systems. <ref type="bibr">10</ref> Again, we observe differ- ent behaviour between WOMs and SIM scores. In Example 1, LOLS generates a grammatically cor- rect English sentence, which represents the mean- ing of the MR well, and, as a result, this utter- ance received high human ratings (median = 6) for informativeness, naturalness and quality. How- ever, WOMs rate this utterance low, i.e. scores of BLEU1-4, NIST, LEPOR, CIDEr, ROUGE and METEOR nor- malised into the 1-6 range all stay below 1.5. This is because the system-generated utterance has low overlap with the human/corpus references. Note that the SIM score is high (5), as it ignores human references and computes distributional semantic similarity between the MR and the system output. Examples 2 and 3 show outputs which receive low scores from both automatic metrics and humans. WOMs score these system outputs low due to lit- tle or no overlap with human references, whereas humans are sensitive to ungrammatical output and missing information (the former is partially cap- tured by GBMs). Examples 2 and 3 also illus- trate inconsistencies in human ratings since sys- tem output 2 is clearly worse than output 3 and both are rated by human with a median score of 1. Example 4 shows an output of the RNNLG system which is semantically very similar to the reference (SIM=4) and rated high by humans, but WOMs fail to capture this similarity. GBMs show more accu- rate results for this utterance, with mean of read- ability scores 4 and parsing score 3.5. <ref type="table" target="#tab_3">Table 6</ref> summarises results published by previous studies in related fields which investigate the re- lation between human scores and automatic met-rics. These studies mainly considered WBMs, while we are the first study to consider GBMs. Some studies ask users to provide separate ratings for surface realisation (e.g. asking about 'clarity' or 'fluency'), whereas other studies focus only on sentence planning (e.g. 'accuracy', 'adequacy', or 'correctness'). In general, correlations reported by previous work range from weak to strong. The re- sults confirm that metrics can be reliable indica- tors at system-level <ref type="bibr" target="#b22">(Reiter and Belz, 2009</ref>), while they perform less reliably at sentence-level ( <ref type="bibr" target="#b27">Stent et al., 2005</ref>). Also, the results show that the met- rics capture realization better than sentence plan- ning. There is a general trend showing that best- performing metrics tend to be the more complex ones, combining word-overlap, semantic similar- ity and term frequency weighting. Note, however, that the majority of previous works do not report whether any of the metric correlations are signifi- cantly different from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusions</head><p>This paper shows that state-of-the-art automatic evaluation metrics for NLG systems do not suf- ficiently reflect human ratings, which stresses the need for human evaluations. This result is opposed to the current trend of relying on automatic evalua- tion identified in ( <ref type="bibr" target="#b1">Gkatzia and Mahamood, 2015)</ref>. A detailed error analysis suggests that auto- matic metrics are particularly weak in distinguish- ing outputs of medium and good quality, which can be partially attributed to the fact that hu- man judgements and metrics are given on differ- ent scales. We also show that metric performance is data-and system-specific.</p><p>Nevertheless, our results also suggest that auto- matic metrics can be useful for error analysis by helping to find cases where the system is perform- ing poorly. In addition, we find reliable results on system-level, which suggests that metrics can be useful for system development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Future Directions</head><p>Word-based metrics make two strong assump- tions: They treat human-generated references as a gold standard, which is correct and complete. We argue that these assumptions are invalid for corpus-based NLG, especially when using crowd- sourced datasets. Grammar-based metrics, on the other hand, do not rely on human-generated ref- erences and are not influenced by their quality. However, these metrics can be easily manipulated with grammatically correct and easily readable output that is unrelated to the input. We have experimented with combining WBMs and GBMs using ensemble-based learning. However, while our model achieved high correlation with humans within a single domain, its cross-domain perfor- mance is insufficient.</p><p>Our paper clearly demonstrates the need for more advanced metrics, as used in related fields, including: assessing output quality within the di- alogue context, e.g. <ref type="bibr">(Dušek and Jurčíček, 2016)</ref>; extrinsic evaluation metrics, such as NLG's con- tribution to task success, e.g. ( <ref type="bibr" target="#b23">Rieser et al., 2014;</ref><ref type="bibr">Gkatzia et al., 2016;</ref><ref type="bibr" target="#b4">Hastie et al., 2016)</ref>; building discriminative models, e.g. <ref type="bibr" target="#b5">(Hodosh and Hockenmaier, 2016)</ref>, <ref type="bibr" target="#b8">(Kannan and Vinyals, 2017)</ref>; or reference-less quality prediction as used in MT, e.g. ( <ref type="bibr" target="#b26">Specia et al., 2010)</ref>. We see our paper as a first step towards reference-less evaluation for NLG by introducing grammar-based metrics. In current work <ref type="bibr" target="#b19">(Dušek et al., 2017)</ref>, we investigate a reference-less quality estimation approach based on recurrent neural networks, which predicts a quality score for a NLG system output by compar- ing it to the source meaning representation only.</p><p>Finally, note that the datasets considered in this study are fairly small (between 404 and 2.3k hu- man references per domain). To remedy this, sys- tems train on de-lexicalised versions <ref type="bibr" target="#b30">(Wen et al., 2015)</ref>, which bears the danger of ungrammatical lexicalisation ( <ref type="bibr" target="#b24">Sharma et al., 2016</ref>) and a possi- ble overlap between testing and training set <ref type="bibr" target="#b10">(Lampouras and Vlachos, 2016)</ref>. There are ongoing ef- forts to release larger and more diverse data sets, e.g. ( <ref type="bibr" target="#b20">Novikova et al., 2016</ref><ref type="bibr" target="#b19">Novikova et al., , 2017</ref>. <ref type="bibr">Ondřej Dušek and Filip Jurčíček. 2016</ref>. A context- aware natural language generator for dialogue systems.</p><p>In Proceedings of the 17th An- nual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics, Los Angeles, CA, USA, pages <ref type="bibr">185-190.</ref> arXiv:1608.07076. http://aclweb.org/anthology/W16-3622. <ref type="bibr">Dušek and Filip Jurčíček. 2016</ref>. Sequence- to-sequence generation for spoken dialogue via deep syntax trees and strings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ondřej</head><p>In Proceed- ings of the 54th Annual Meeting of the As- sociation for Computational Linguistics. Berlin, Germany, pages 45-51.</p><p>arXiv In Proceedings of the 54th Annual</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>et al., 2006), BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), NIST (Doddington, 2002), LEPOR (Han et al., 2012), CIDEr (Vedantam et al., 2015), and METEOR (Lavie and Agarwal, 2007).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Spearman correlation results for TGEN on BAGEL. Bordered area shows correlations between human ratings and automatic metrics, the rest shows correlations among the metrics. Blue colour of circles indicates positive correlation, while red indicates negative correlation. The size of circles denotes the correlation strength.</figDesc><graphic url="image-1.png" coords="5,72.90,195.50,449.02,200.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Williams test results: X represents a non-significant difference between correlations (p &lt; 0.05; top: WBMs, bottom: GBMs).</figDesc><graphic url="image-2.png" coords="5,72.00,485.67,222.24,136.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Correlation between automatic metrics (WBMs) and human ratings for utterances of bad informativeness (top), and average and good informativeness (bottom).</figDesc><graphic url="image-3.png" coords="7,113.10,264.83,136.06,148.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 2 summarises</head><label>2</label><figDesc></figDesc><table>the individual systems' over-
all corpus-level performance in terms of automatic 
and human scores (details are provided in the sup-
plementary material). 
All WOMs produce similar results, with SIM 
showing different results for the restaurant domain 
(BAGEL and SFREST). Most GBMs show the same 
trend (with different levels of statistical signifi-
cance), but RE is showing inverse results. System 
performance is dataset-specific: For WBMs, the 
LOLS system consistently produces better results 
on BAGEL compared to TGEN, while for SFREST 
and SFHOTEL, LOLS is outperformed by RNNLG in </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Best correlation results achieved by our and previous work. Dimensions targeted towards Sen-
tence Planning include 'accuracy', 'adequacy', 'correctness', 'informativeness'. Dimensions for Surface 
Realisation include 'clarity', 'fluency', 'naturalness'. 

</table></figure>

			<note place="foot" n="1"> Available for download at: https://github.com/ jeknov/EMNLP_17_submission</note>

			<note place="foot" n="7"> http://nlp.stanford.edu/software/ parser-faq.shtml</note>

			<note place="foot" n="8"> As an alternative to using the median human judgment for each item, a more effective way to use all the human judgments could be to use Hovy et al. (2013)&apos;s MACE tool for inferring the reliability of judges.</note>

			<note place="foot" n="10"> Please note that WBMs tend to match against the reference that is closest to the generated output. Therefore, we only include the closest match in Table 5 for simplicity.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research received funding from the EPSRC projects DILiGENt (EP/M005429/1) and MaDrI-gAL (EP/N017536/1). The Titan Xp used for this research was donated by the NVIDIA Corpora-tion.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>Anja Belz and Eric <ref type="bibr">Kow. 2011</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Short Papers)</title>
		<idno type="arXiv">arXiv:1606.03254</idno>
	</analytic>
	<monogr>
		<title level="j">of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="264" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A snapshot of NLG evaluation practices 2005-2014</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitra</forename><surname>Gkatzia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saad</forename><surname>Mahamood</surname></persName>
		</author>
		<idno type="doi">10.18653/v1/W15-4708</idno>
		<ptr target="https://doi.org/10.18653/v1/W15-4708" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th European Workshop on Natural Language Generation (ENLG)</title>
		<meeting>the 15th European Workshop on Natural Language Generation (ENLG)<address><addrLine>Brighton, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LEPOR: A robust evaluation metric for machine translation with augmented factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><forename type="middle">F</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidia</forename><forename type="middle">S</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C12-2044" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012: Posters. The COLING 2012 Organizing Committee</title>
		<meeting>COLING 2012: Posters. The COLING 2012 Organizing Committee<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">UMBC EBIQUITY-CORE: Semantic textual similarity systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lushan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhay</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/S13-1005" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Joint Conference on Lexical and Computational Semantics (*SEM)</title>
		<meeting>the Second Joint Conference on Lexical and Computational Semantics (*SEM)<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="44" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Why bother? Is evaluation of NLG in an end-to-end Spoken Dialogue System worth it?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heriberto</forename><surname>Cuayahuitl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Dethlefs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingkun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Dialogue Systems (IWSDS)</title>
		<meeting>the International Workshop on Spoken Dialogue Systems (IWSDS)<address><addrLine>Saariselkä, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Focused evaluation for image description with binary forcedchoice tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W16-3203" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Workshop on Vision and Language</title>
		<meeting>the 5th Workshop on Vision and Language<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="19" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning whom to trust with MACE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N13-1132" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACLHLT</title>
		<meeting>NAACLHLT<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1120" to="1130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Applying natural language generation to indicative summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<idno type="doi">10.3115/1117840.1117853</idno>
		<ptr target="https://doi.org/10.3115/1117840.1117853" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th European Workshop on Natural Language Generation. Association for Computational Linguistics</title>
		<meeting>the 8th European Workshop on Natural Language Generation. Association for Computational Linguistics<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adversarial evaluation of dialogue models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>CoRR abs/1701.08198</idno>
		<ptr target="https://arxiv.org/abs/1701.08198" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Re-evaluating automatic metrics for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Kilickaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aykut</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazli</forename><surname>Ikizler-Cinbis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erkut</forename><surname>Erdem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.07600</idno>
		<ptr target="https://arxiv.org/abs/1612.07600" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imitation learning for language generation from unaligned data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerasimos</forename><surname>Lampouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/C16-1105" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. The COLING 2016 Organizing Committee<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1101" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<idno type="doi">10.2307/2529310</idno>
		<ptr target="https://doi.org/10.2307/2529310" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhaya</forename><surname>Agarwal</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W07-0734" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on Statistical Machine Translation</title>
		<meeting>the Second Workshop on Statistical Machine Translation<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="228" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W04-1013" />
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out: Proceedings of the ACL04 workshop</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08023</idno>
		<ptr target="http://aclweb.org/anthology/D16-1230" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Phrase-based statistical language generation using graphical models and active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Jurčíček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P10-1157" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1552" to="1561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What to talk about and how? Selective generation using LSTMs with coarse-tofine alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Walter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00838</idno>
		<ptr target="http://aclweb.org/anthology/N16-1086" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2016</title>
		<meeting>NAACL-HLT 2016<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">There&apos;s no comparison: Reference-less evaluation metrics in grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02124</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2109" to="2115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The E2E dataset: New challenges for end-to-end generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Dušek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<idno>1706.09254</idno>
		<ptr target="https://arxiv.org/abs/1706.09254" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Saarbrücken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Crowd-sourcing NLG data: Pictures elicit better data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jekaterina</forename><surname>Novikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.00339</idno>
		<ptr target="http://aclweb.org/anthology/W16-2302" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Natural Language Generation Conference</title>
		<meeting>the 9th International Natural Language Generation Conference<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/P02-1040" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An investigation into the validity of some metrics for automatically evaluating natural language generation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
		<idno type="doi">10.1162/coli.2009.35.4.35405</idno>
		<ptr target="https://doi.org/10.1162/coli.2009.35.4.35405" />
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="529" to="558" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Natural language generation as incremental planning under uncertainty: Adaptive information presentation for statistical dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verena</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<idno type="doi">10.1109/TASL.2014.2315271</idno>
		<ptr target="https://doi.org/10.1109/TASL.2014.2315271" />
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="979" to="993" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Natural language generation in dialogue using lexicalized and delexicalized data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannes</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<idno>CoRR abs/1606.03632</idno>
		<ptr target="http://arxiv.org/abs/1606.03632" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
		<ptr target="http://mt-archive.info/AMTA-2006-Snover.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Conference of the Association for Machine Translation of the Americas</title>
		<meeting>the 7th Conference of the Association for Machine Translation of the Americas<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Machine translation evaluation versus quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhwaj</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<idno type="doi">10.1007/s10590-010-9077-2</idno>
		<ptr target="https://doi.org/10.1007/s10590-010-9077-2" />
	</analytic>
	<monogr>
		<title level="j">Machine translation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Evaluating evaluation methods for generation in the presence of variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Stent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Marge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Singhai</surname></persName>
		</author>
		<idno type="doi">10.1007/978-3-540-30586-638</idno>
		<ptr target="https://doi.org/10.1007/978-3-540-30586-638" />
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing: 6th International Conference, CICLing</title>
		<meeting><address><addrLine>Mexico City, Mexico; Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-02-13" />
			<biblScope unit="page" from="341" to="351" />
		</imprint>
	</monogr>
<note type="report_type">Proceedings</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">CIDEr: Consensusbased image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Ramakrishna Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parikh</surname></persName>
		</author>
		<idno type="doi">10.1109/CVPR.2015.7299087</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2015.7299087" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multidomain neural network language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">Maria</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">J</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01232</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="120" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semantically conditioned LSTM-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1711" to="1721" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Regression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">James</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
