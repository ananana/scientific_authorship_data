<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Language Modeling with Functional Head Constraint for Code Switching Speech Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center Department of Electronic and Computer Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Fung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center Department of Electronic and Computer Engineering</orgName>
								<orgName type="institution">The Hong Kong University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Language Modeling with Functional Head Constraint for Code Switching Speech Recognition</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="907" to="916"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper, we propose novel struc-tured language modeling methods for code mixing speech recognition by incorporating a well-known syntactic constraint for switching code, namely the Functional Head Constraint (FHC). Code mixing data is not abundantly available for training language models. Our proposed methods successfully alleviate this core problem for code mixing speech recognition by using bilingual data to train a struc-tured language model with syntactic constraint. Linguists and bilingual speakers found that code switch do not happen between the functional head and its complements. We propose to learn the code mixing language model from bilingual data with this constraint in a weighted finite state transducer (WFST) framework. The constrained code switch language model is obtained by first expanding the search network with a translation model, and then using parsing to restrict paths to those permissible under the constraint. We implement and compare two approaches-lattice parsing enables a sequential coupling whereas partial parsing enables a tight coupling between parsing and filtering. We tested our system on a lecture speech dataset with 16% embedded second language, and on a lunch conversation dataset with 20% embedded language. Our language models with lattice parsing and partial parsing reduce word error rates from a baseline mixed language model by 3.8% and 3.9% in terms of word error rate relatively on the average on the first and second tasks respectively. It outperforms the interpolated language model by 3.7% and 5.6% in terms of word error rate relatively, and outperforms the adapted language model by 2.6% and 4.6% relatively. Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust. We address the code switch data scarcity challenge by using bilingual data with syntactic structure.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In multilingual communities, it is common for people to mix two or more languages in their speech. A single sentence spoken by bilingual speakers often contains the main, matrix language and an embedded second language. This type of linguistic phenomenon is called "code switch- ing" by linguists. It is increasingly important for automatic speech recognition (ASR) systems to recognize code switching speech as they exist in scenarios such as meeting and interview speech, lecture speech, and conversational speech. Code switching is common among bilingual speakers of Spanish-English, Hindi-English, Chinese-English, and Arabic-English, among others. In China, lectures, meetings and conversations with techni- cal contents are frequently peppered with English terms even though the general population is not considered bilingual in Chinese and English. Un- like the thousands and tens of thousands of hours of monolingual data available to train, for exam- ple, voice search engines, transcribed code switch data necessary for training language models is hard to come by. Code switch language modeling is therefore an even harder problem than acoustic modeling.</p><p>One approach for code switch speech recogni- tion is to explicitly recognizing the code switch points by language identification first using pho- netic or acoustic information, before applying speech recognizers for the matrix and embed- ded languages <ref type="bibr" target="#b3">(Chan et. al, 2004;</ref><ref type="bibr" target="#b4">Shia et. al, 2004;</ref><ref type="bibr" target="#b5">Lyu and Lyu, 2008)</ref>. This approach is ex- tremely error-prone as language identification at each frame of the speech is necessary and any er- ror will be propagated in the second speech recog- nition stage leading to fatal and irrecoverable er- rors.</p><p>Meanwhile, there are two general approaches to solve the problem of lack of training data for lan- guage modeling. In a first approach, two language models are trained from both the matrix and em- bedded language separately and then interpolated together <ref type="bibr">(Vu et. al, 2012;</ref><ref type="bibr">Chan et. al, 2006</ref>). How- ever, an interpolated language model effectively allows code switch at all word boundaries without much of a constraint. Another approach is to adapt the matrix language language model with a small amount of code switch data <ref type="bibr" target="#b6">(Tsai et. al, 2010;</ref><ref type="bibr">Yeh et. al, 2010;</ref><ref type="bibr" target="#b8">Bhuvanagiri and Kopparapu, 2010;</ref><ref type="bibr" target="#b9">Cao et. al, 2010</ref>). The effectiveness of adapta- tion is also limited as positions of code switch- ing points are not generalizable from the limited data. Significant progress in speech recognition has been made by using deep neural networks for acoustic modeling and language model. However, improvement thus gained on code switch speech recognition remains very small. Again, we pro- pose that syntactic constraints of the code switch- ing phenomenon can help improve performance and model accuracy. Previous work of using part- of-speech tags <ref type="bibr" target="#b12">(Zhang et. al, 2008;</ref><ref type="bibr">Vu et al 2012)</ref> and our previous work using syntactic constraints ( <ref type="bibr" target="#b2">Li and</ref><ref type="bibr">Fung, 2012, 2013</ref>) have made progress in this area. Part-of-speech is relatively weak in predicting code switching points. It is generally accepted by linguists that code switching follows the so-called Functional Head Constraint, where words on the nodes of a syntactic sub tree must follow the language of that of the headword. If the headword is in the matrix language then none of its complements can switch to the embedded lan- guage.</p><p>In this work, we propose two ways to incorpo- rate the Functional Head Constraint into speech recognition and compare them. We suggest two approaches of introducing syntactic constraints into the speech recognition system. One is to ap- ply the knowledge sources in a sequential order. The acoustic model and a monolingual language model are used first to produce an intermediate lattice, then a second pass choose the best result using the syntactic constraints. Another approach uses tight coupling. We propose using structured language model <ref type="bibr" target="#b10">(Chelba and Jelinek, 2000</ref>) to build the syntactic structure incrementally.</p><p>Following our previous work, we suggest in- corporating the acoustic model, the monolingual language model and a translation model into a WFST framework. Using a translation model al- lows us to learn what happens when a language switches to another with context information. We will motivate and describe this WFST framework for code switching speech recognition in the next section. The Functional Head Constraint is de- scribed in Section 3. The proposed code switch language models and speech recognition coupling is described in Section 4. Experimental setup and results are presented in Section 5. Finally we con- clude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Code Switch Language Modeling in a WFST Framework</head><p>As code switch text data is scarce, we do not have enough data to train the language model for code switch speech recognition. We propose instead to incorporate language model trained in the matrix language with a translation model to obtain a code switch language model. We propose to integrate a bilingual acoustic model <ref type="bibr">(Li et. al, 2011</ref>) and the code switch language model in a weighted finite state transducer framework as follows. Suppose X denotes the observed code switch speech vector, w J 1 denotes a word sequence in the matrix language, the hypothesis transcript v I 1 is as follows:</p><formula xml:id="formula_0">ˆ v I 1 = arg max v I 1 P (v I 1 |X) = arg max v I 1 P (X|v I 1 )P (v I 1 ) = arg max v I 1 P (X|v I 1 ) w J 1 P (v I 1 |w J 1 )P (w J 1 ) ∼ = arg max v I 1 P (X|v I 1 )P (v I 1 |w J 1 )P (w J 1 ) (1)</formula><p>where P (X|v I 1 ) is the acoustic model and P (v I 1 ) is the language model in the mixed language.</p><p>Our code switch language model is obtained from a translation model P (v I 1 |w J 1 ) from the ma- trix language to the mixed language, and the lan- guage model in the matrix language P (w J 1 ). Instead of word-to-word translation, the trans- duction of the context dependent lexicon trans- fer is constrained by previous words. Assume the transduction depends on the previous n words:</p><formula xml:id="formula_1">P (v I 1 |w J 1 ) = I i=1 P (v i |v i−1 1 , w i 1 ) ∼ = I i=1 P (v i−1 i−n+1 |w i i−n+1 ) = I i=1 P (v i , w i |v i−1 i−n+1 , w i−1 i−n+1 ) P (w i |v i−1 i−n+1 , w i−1 i−n+1 ) = I i=1 P (v i , w i |v i−1 i−n+1 , w i−1 i−n+1 ) P (w i | v i v i−1 i−n+1 , w i−1 i−n+1 )<label>(2)</label></formula><p>There are C-level and H-level search networks in the WFST framework. The C-level search net- work is composed of the universal phone model P , the context model C, the lexicon L, and the grammar G</p><formula xml:id="formula_2">N = P • C • L • G<label>(3)</label></formula><p>The H-level search network is composed of the state model H, the phoneme model P , the context model C, the lexicon L, and the grammar G</p><formula xml:id="formula_3">N = H • P • C • L • G<label>(4)</label></formula><p>The C-level requires less memory then the H-level search network. We propose to use a weighted fi- nite state transducer framework incorporating the bilingual acoustic model P , the context model C, the lexicon L, and the code switching language models G CS into a C-level search network for mixed language speech recognition. The output of the recognition result is in the mixed language after projection π(G CS ).</p><formula xml:id="formula_4">N = P • C • L • π(G CS )<label>(5)</label></formula><p>The WFST implementation to obtain the code switch language model G CS is as follows:</p><formula xml:id="formula_5">G cs = T • G (6)</formula><p>where T is the translation model</p><formula xml:id="formula_6">P (˜ v L 1 |w J 1 ) = L l=1 P l (˜ v l |w l )<label>(7)</label></formula><p>P l (˜ v l |w l ) is the probability of w l translated intõ v l . In order to make use of the text data in the ma- trix language to recognize speech in the mixed lan- guage, the translation model P (v I 1 |w J 1 ) transduce the language model in the matrix language to the mixed language.</p><formula xml:id="formula_7">P (v I 1 |w J 1 ) = ˜ v L 1 ,c L 1 ,r K 1 , ˜ w K 1 P ( ˜ w K 1 |w J 1 ) ·P (r K 1 | ˜ w K 1 , w J 1 ) ·P (c L 1 , r K 1 , ˜ w K 1 , w J 1 ) ·P (˜ v K 1 |c L 1 , r K 1 , ˜ w K 1 , w J 1 ) ·P (v I 1 |˜v|˜v K 1 , r K 1 , ˜ w K 1 , w J 1 ) (8)</formula><p>where</p><formula xml:id="formula_8">P ( ˜ w K 1 |w J 1 ) is the word-to-phrase segmen- tation model, P (r K 1 | ˜ w K 1 , w J 1 ) is the phrasal re- ordering model, P (c L 1 , r K 1 , ˜ w K 1 , w J 1 ) is the chunk segmentation model, P (˜ v K 1 |c L 1 , r K 1 , ˜ w K 1 , w J 1 ) is the chunk-to-chunk transduction model, P (v I 1 |˜v|˜v K 1 , r K 1 , ˜ w K 1 , w J 1 ) is the chunk-to-word reconstruction model.</formula><p>The word-to-phrase segmentation model ex- tracts a table of phrases {˜v{˜v 1 , ˜ v 2 , ..., ˜ v K } for the transcript in the embedded language and { ˜ w 1 , ˜ w 2 , ..., ˜ w K } for the transcript in the ma- trix language based on word-to-word alignments trained in both directions with GIZA++ <ref type="bibr">(Och and Ney, 2003)</ref>. The chunk segmentation model per- forms the segmentation of a phrase sequence˜wsequence˜ sequence˜w K 1 into L phrases {c 1 , c 2 , ..., c L } using a segmenta- tion weighted finite-state transducer. Assumes that a chunk c l is code-switched to the embedded lan- guage independently by each chunk, the chunk- to-chunk transduction model is the probability of a chunk to be code switched to the embedded lan- guage trained on parallel data. The reconstruction model generates word sequence from chunk se- quences and operates in the opposite direction to the segmentation model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Functional Head Constraint</head><p>Many linguistics <ref type="bibr">(Abney 1986;</ref><ref type="bibr">Belazi et. al, 1994;</ref><ref type="bibr">Bhatt 1994)</ref> have discovered the so-called Func- tional Head Constraint in code switching. They have found that code switches between a func- tional head (a complementizer, a determiner, an inflection, etc.) and its complement (sentence, noun-phrase, verb-phrase) do not happen in natu- ral speech. In addition, the Functional Head Con- straint is language independent.</p><p>In this work, we propose to investigate and incorporate the Functional Head Constraint into code switching language modeling in a WFST framework. <ref type="figure" target="#fig_0">Figure 1</ref> shows one of the Functional Head Constraint examples. Functional heads are the roots of the sub trees and complements are part of the sub trees. Actual words are the leaf nodes. According to the Functional Head Constraint, the leave nodes of a sub tree must be in either the matrix language or embedded language, following the language of the functional head. For instance, the third word "東 西/something" is the head of the constituents "非常/very 重要的/important 東 西/something". These three constituent words cannot be switched. Thus, it is not permissible to code switch in the constituent. More precisely, the language of the constituent is constrained to be the same as the language of the headword. In the following sections, we describe the integration of the Functional Head Constraint and the language model.</p><p>We have found this constraint to be empirically sound as we look into our collected code mixing speech and language data. The only violation of the constraint comes from rare cases of borrowed words such as brand names with no translation in the local, matrix language. Borrowed words are used even by monolingual speakers so they are in general part of the matrix language lexicon and require little, if any, special treatment in speech recognition.</p><p>In the following sections, we describe the inte- gration of Functional Head Constraint and the lan- guage model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Code Switching Language Modeling with Functional Head Constraint</head><p>We propose two approaches of language model- ing with Functional Head Constraint: 1) lattice- parsing and sequential-coupling <ref type="bibr">(Chapplerler et. al, 1999</ref>); 2) partial-parsing and tight-coupling <ref type="bibr">(Chapplerler et. al, 1999</ref>). The two approaches will be described in the followed sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sequential-coupling by Lattice-based Parsing</head><p>In this first approach, the acoustic models, the code switch language model and the syntactic con- straint are incorporated in a sequential order to progressively constrain the search. The acoustic models and the matrix language model are used first to produce an intermediate output. The in- termediate output is a lattice in which word se- quences are compactly presented. Lattice-based parsing is used to expand the word lattice gener- ated from the first decoding step according to the Functional Head Constraint.</p><p>We have reasons to use word lattice instead of N-best hypothesis. The number of hypothesis of word lattice is larger than N-best hypothesis. Moreover, different kinds of errors correspond to the language model would be observed if N-best list is extracted after the first decoding step. The second pass run over the N-best list will prevent the language model with Functional Head Con- straint from correcting the errors. In order to ob- tain a computational feasible number of hypothe- ses without bias to the language model in the first decoding step, word lattice is used as the interme- diate output of the first decoding step.</p><p>A Probabilistic Context-Free Grammar (PCFG) parser is trained on Penn Treebank data. The PCFG parser is generalized to take the lattice gen- erated by the recognizer as the input. <ref type="figure" target="#fig_1">Figure 2</ref> il- lustrates a word lattice which is a compact repre- sentation of the hypothesis transcriptions of a an input sentence. All the nodes of the word-lattice are ordered by increasing depth.</p><p>A CYK table is obtained by associating the arcs with their start and end states in the lattice instead of their sentence position and initialized all the cells in the table corresponding to the arcs <ref type="bibr">(Chapplerler et. al, 1999</ref>). Each cell C k,j of the ta- ble is filled by a n-tuple of the non-terminal A, the length k and the starting position of the word sequence w j ...w j+k if there exists a PCFG rule A → w j ...w j+k , where A is a non-terminal which parse sequences of words w j ...w j+k . In order to allow all hypothesis transcriptions of word lattice to be taken into account, multiple word sequences of the same length and starting point are initialized in the same cell. <ref type="figure" target="#fig_1">Figure 2</ref> mapped the word lattice of the example to the table, where the starting node label of the arc is the column index and the length of the arc is the row index.</p><p>The sequential-coupling by lattice-parsing con- sists of the standard cell-filling and the self-filling steps. First, the cells C k,j and C i−k,j+k are com- bined to produce a new interpretation for cell C i,j . In order to handle the unary context-free produc- tion A → B and update the cells after the stan- dard cell-filling, a n-tuple of A, i and j is added for each n-tuple of the non-terminal B, the length i and the start j in the cell C i,j . The parse trees extracted are associated with the input lattice from the table starting from the non-terminal label of the top cell. After the parse tree is obtained, we re-     cursively enumerate all its subtrees. Each subtree is able to code-switch to the embedded language with a translation probability P l (˜ v l |w l ).</p><formula xml:id="formula_9">! ! ! ! ! ! ! ! ! "#$%&amp;'( )*(! ! "#+! ! ! ! ! ",-'.! ! "#$%&amp;'( )*(! "+&amp;$-( /#*0! "#+! "#*</formula><p>The lattice parsing operation consists of the an encoding of a given word sequence along with a parse tree (W, T ) and a sequence of elemen- tary model actions. In order to obtain a correct probability assignment P (W, T ) one simply as- sign proper conditional probabilities to each tran- sition in the weighted finite states.</p><p>The probability of a parse T of a word sequence W P (W, T ) can be calculated as the product of the probabilities of the subtrees.</p><formula xml:id="formula_10">P (W, T ) = n+1 k=1 [P (wk|W k−1 T k−1 ) (9)</formula><p>Where W k = w 0 ...w k is the first k words in the sentence, and (W k , T k ) is the word-and-parse k- prefix. The probability of the n-tuple of the non- terminal A, the length i and the starting position j is the probability of the subtree corresponding to A parsing throughout the sequence w j ...w j+i−1 . The probability of the partial parsing is the product of probabilities of the subtree parses it is made of. The probability of an n-tuple is the maximum over the probabilities of probable parsing path.</p><p>The N most probable parses are obtained during the lattice-parsing.</p><p>The probability of a sentence is computed by adding on the probability of each new context-free rule in the sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Tight-coupling by Incremental Parsing</head><p>To integrate the acoustic models, language model and the syntactic constraint in time synchronous decoding, an incremental operation is used in this approach. The final word-level probability as- signed by our model is calculated using the acous- tic models, the matrix language model, the struc- tured language model and the translation model. The structured language model uses probabilistic parameterization of a shift-reduce parse <ref type="bibr" target="#b10">(Chelba and Jelinek, 2000</ref>). The tight-coupled language model consists of three transducers, the word pre- dictor, the tagger and the constructor. As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, W k = w0...wk is the first k words of the sentence, T k contains only those binary sub- trees whose leaves are completely included in W k , excluding w 0 =&lt;s&gt;. Single words along with their POS tag can be regarded as root-only trees. The exposed head h k is a pair of the headword of the constituent W k and the non-terminal label. The exposed head of single words are pairs of the words and their POS tags.</p><p>Given the word-and-parse (k-1)-prefix W k−1 T k−1 , the new word w k is predicted by the word-predictor P (w k |W k−1 T k−1 ). Taking the word-and-parse k − 1-prefix and the next word as input, the tagger P (t k |w k , W k−1 T k−1 ) gives the POS tag t k of the word w k . Constructor P (p k i |W k T k ) assigns a non-terminal label to the constituent W k+1 . The headword of the newly built constituent is inherited from either the headword of the constituent W k or the next word w k+1 .</p><formula xml:id="formula_11">P (w k |W k−1 T k−1 ) = P (w k |[W k−1 T k−1 ]) = P (w k |h 0 , h −1 )<label>(10)</label></formula><formula xml:id="formula_12">P (t k |w k , W k−1 T k−1 ) = P (t k |w k , [W k−1 T k−1 ]) = P (t k |w k , h 0 .tag, h −1 .tag)<label>(11)</label></formula><formula xml:id="formula_13">P (p k i |W k T k ) = P (p k i |[W k T k ]) = P (p k i |h 0 , h 1 )<label>(12)</label></formula><p>The probability of a parse tree T P (W, T ) of a word sequence W and a complete parse T can be calculated as:</p><formula xml:id="formula_14">P (W, T ) = n+1 k=1 [P (w k |W k−1 T k−1 ) P (t k |W k−1 T k−1 , w k ) P (T k |W k−1 T k−1 , w k , t k )](13) P (T k k−1 |W k−1 T k−1 , w k , t k ) = N k i=1 P (p k |W k−1 T k−1 , w k , t k , p k 1 ...p k i−1 )<label>(14)</label></formula><p>Where w k is the word predicted by the word- predictor, t k is the POS tag of the word w k pre- dicted by the tagger, W k−1 T k−1 is the word-parse (k -1)-prefix, T k k−1 is the incremental parse struc- ture that generates T k = T k−1 ||T k k−1 when at- tached to T k−1 ; it is the parse structure built on top of T k−1 and the newly predicted word wk; the || notation stands for concatenation; N k−1 is the number of operations the constructor executes at position k of the input string before passing con- trol to the word-predictor (the N k th operation at position k is the null transition); N k is a function of T ; p k i denotes the i th constructor action carried out at position k in the word string.</p><p>The probability models of word-predictor, tag- ger and constructor are initialized from the Upenn Treebank with headword percolation and bina- rization. The headwords are percolated using a context-free approach based on rules of predict- ing the position of the headword of the constituent. The approach consists of three steps. First a parse tree is decomposed to phrase constituents. Then the headword position is identified and filled in with the actual word percolated up from the leaves of the tree recursively.</p><p>Instead of the UPenn Treebank-style, we use a more convenient binary branching tree. The parse trees are binarized using a rule-based approach.</p><p>The probability models of the word-predictor, tagger and constructor are trained in a maximiza- tion likelihood manner. The possible POS tag as- signments, binary branching parse, non-terminal labels and the head-word annotation for a given sentence are hidden. We re-estimate them using EM algorithm.</p><p>Instead of generating only the complete parse, all parses for all the subsequences of the sen- tence are produced. The headwords of the subtrees are code switched to the embedded language with a translation probability P l (˜ v l |w l ) as well as the leaves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Decoding by Translation</head><p>Using either lattice parsing or partial parsing, a two-pass decoding is needed to recognize code switch speech. A computationally feasible first pass generates an intermediate result so that the language model with Functional Head constraint can be used in the second pass. The first decoding pass composes of the transducer of the universal phoneme model P , the transducer C from context- dependent phones to context-independent phones, the lexicon transducer L which maps context- independent phone sequences to word strings and the transducer of the language model G. A T3 de- coder is used in the first pass.</p><formula xml:id="formula_15">ASR 1 = P • C • L • G<label>(15)</label></formula><p>Instead of N-best list, word lattice is used as the intermediate output of the first decoding step.</p><p>The language model G CS of the transducer in the second pass is improved from G by compos- ing with the translation model P l (˜ v l |w l ). Finally, the recognition transducer is optimized by deter- mination and minimization operations.</p><formula xml:id="formula_16">ASR 2 = P •C•min(det(L•min(det(π(G CS )))))<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>The bilingual acoustic model used for our mixed language ASR is trained from 160 hours of speech from GALE Phase 1 Chinese broadcast conver- sation, 40 hours of speech from GALE Phase 1 English broadcast conversation, and 3 hours of in-house nonnative English data. The acoustic features used in our experiments consist of 39 components (13MFCC, 13MFCC, 13 MFCC us- ing cepstral mean normalization), which are an- alyzed at a 10msec frame rate with a 25msec win- dow size. The acoustic models used throughout our paper are state-clustered crossword tri-phone HMMs with 16 Gaussian mixture output densi- ties per state. We use the phone set consists of 21 Mandarin standard initials, 37 Mandarin finals, 6 zero initials and 6 extended English phones. The pronunciation dictionary is obtained by modify- ing Mandarin and English dictionaries using the phone set. The acoustic models are reconstructed  <ref type="bibr">and Klein, 2007)</ref>.  <ref type="table" target="#tab_1">Table 1</ref> reports precision, recall and F-measure of code switching point in the recognition results of the baseline and our proposed language mod- els. Our proposed code switching language mod- els with functional head constraint improve both precision and recall of the code switching point detection on the code switching lecture speech and lunch conversation 4.48%. Our method by tight- coupling increases the F-measure by 9.38% rela- tively on the lecture speech and by 6.90% rela- tively on the lunch conversation compared to the baseline adapted language model. The <ref type="table" target="#tab_2">Table 2</ref> shows the word error rates (WERs) of experiments on the code switching lecture speech and <ref type="table" target="#tab_3">Table 3</ref> shows the WERs on the code switching lunch conversations. Our proposed code switching language model with Functional Head Constraints by sequential-coupling reduces the WERs in the baseline mixed language model by 3.72% relative on Test 1, and 5.85% on Test 2. Our method by tight-coupling also reduces WER by 2.51% relative compared to the baseline language model on Test 1, and by 4.57% on Test 2. We use the speech recognition scoring toolkit (SCTK) developed by the National Institute of Standards and Technology to compute the significance lev- els, which is based on two-proportion z-test com- paring the difference between the recognition re- sults of our proposed approach and the baseline. All the WER reductions are statistically signifi- cant. For our reference, we also compare the per- formance of using Functional Head Constraint to that of using inversion constraint in ( <ref type="bibr" target="#b2">Li and</ref><ref type="bibr">Fung, 2012, 2013)</ref> and found that the present model re- duces WER by 0.85% on Test 2 but gives no im- provement on Test 1. We hypothesize that since  Test 1 has mostly Chinese words, the proposed method is not as advantageous compared to our previous work. Another future direction is for us to improve the lattice parser as we believe it will lead to further improvement on the final result of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose using lattice parsing and partial parsing to incorporate a well-known syn- tactic constraint for code mixing speech, namely the Functional Head Constraint, into a continu- ous speech recognition system. Under the Func- tional Head Constraint, code switch cannot occur between the functional head and its complements. Since code mixing speech data is scarce, we pro- pose to instead learn the code mixing language model from bilingual data with this constraint. The constrained code switching language model is obtained by first expanding the search network with a translation model, and then using parsing to restrict paths to those permissible under the con- straint. Lattice parsing enables a sequential cou- pling of parsing then constraint filtering whereas partial parsing enables a tight coupling between parsing and filtering. A WFST-based decoder then combines a bilingual acoustic model and the proposed code-switch language model in an inte- grated approach. Lattice-based parsing and partial parsing are used to provide the syntactic structure of the matrix language. Matrix words at the leave nodes of the syntax tree are permitted to switch to the embedded language if the switch does not vio- late the Functional Head Constraint. This reduces the permissible search paths from those expanded by the bilingual language model. We tested our system on a lecture speech dataset with 16% em- bedded second language, and on a lunch conversa- tion dataset with 20% embedded second language. Our language models with lattice parsing and par- tial parsing reduce word error rates from a baseline mixed language model by 3.72% to 3.89% rela- tive in the first task, and by 5.85% to 5.97% in the second task. They are reduced from an inter- polated language model by 3.69% to 3.74%, and by 5.46% to 5.77% in the first and second task re- spectively. WER reductions from an adapted lan- guage model are 2.51% to 2.63%, and by 4.47% to 4.74% in the two tasks. The F-measure for code switch point detection is improved from 0.64 by the interpolated model to 0.68, and from 0.67 by the adapted model to 0.70 by our method. Our proposed approach avoids making early decisions on code-switch boundaries and is therefore more robust. Our approach also avoids the bottleneck of code switch data scarcity by using bilingual data with syntactic structure. Moreover, our method re- duces word error rates for both the matrix and the embedded language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A Functional Head Constraint example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example word lattice in the matrix language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The mapping of the example word lattice to the table.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: A word-and-parse example.</figDesc><graphic url="image-77.png" coords="7,76.71,73.48,427.09,80.08" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>For</head><label></label><figDesc>the language models, transcriptions of 18 hours of Data 1 are trained as a baseline mixed language model for the lecture speech domain. 250,000 sentences from Chinese speech confer- ence papers, power point slides and web data are used for training a baseline Chinese matrix language model for the lecture speech domain (LM 1). Transcriptions of 2 hours of Data 2 are used as the baseline mixed language model in the lunch conversation domain. 250,000 sentences of the GALE Phase 1 Chinese conversational speech transcriptions are used to train a Chinese ma- trix language model (LM 2). 250,000 of GALE Phase 1 English conversational speech transcrip- tion are used to train the English embedded lan- guage model (LM 3). To train the bilingual trans- lation model, the Chinese Gale Phase 1 conversa- tional speech transcriptions are used to generate a bilingual corpus using machine translation. For comparison, an interpolated language model for the lunch conversation domain is trained from in- terpolating LM 2 with LM 3. Also for comparison, an adapted language model for lecture speech is trained from LM 1 and transcriptions of 18 hours of Data 1. An adapted language mode l for conver- sation is trained from LM 2 and 2 hours of Data 2. The size of the vocabulary for recognition is 20k words. The perplexity of the baseline language model trained on the code switching speech tran- scription is 236 on the lecture speech and 279 on the conversation speech test sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Code switching point detection evaluation (Precision/Recall/F-measure)</head><label>1</label><figDesc></figDesc><table>Lecture speech Lunch conversation 
MixedLM 
0.61/0.64/0.64 
0.54/0.63/0.58 
InterpolatedLM 
0.62/0.66/0.64 
0.55/0.63/0.58 
AdaptedLM 
0.63/0.71/0.67 
0.54/0.63/0.58 
Sequential coupling 0.66/0.71/0.68 
0.55/0.70/0.61 
Tight coupling 
0.68/0.71/0.70 
0.56/0.70/0.62 

by decision tree tying. We also collected two 
speech databases with Chinese to English code 
switching -namely, 20 hours of lecture speech cor-
pus (Data 1) and 3 hours of lunch conversation 
corpus (Data 2). 18 hours of Data 1 is used for 
acoustic model adaptation and 1 hour of data are 
used as the test set (Test 1). 2 hours of Data 2 con-
taining 2389 utterances is used to adapt the acous-
tic model and 280 utterances are used as the test 
set (Test 2). To train the parser, we use Chinese 
Treebank Version 5.0 which consists of 500 thou-
sand words and use the standard data split (Petrov 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Our proposed system outperforms the baselines in terms of WER on the lecture speech</head><label>2</label><figDesc></figDesc><table>Matrix Embedded Overall 
MixedLM 
34.41% 
39.16% 
35.17% 
InterpolatedLM 
34.11% 
40.28% 
35.10% 
AdaptedLM 
35.11% 
38.41% 
34.73% 
Sequential coupling 33.17% 
36.84% 
33.76% 
Tight coupling 
33.14% 
36.65% 
33.70% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Our proposed system outperforms the baselines in terms of WER on the lunch conversation 
Matrix Embedded Overall 
MixedLM 
46.4% 
48.55% 
46.83% 
InterpolatedLM 
46.04% 
49.04% 
46.64% 
AdaptedLM 
46.64% 
48.39% 
46.20% 
Sequential coupling 43.24% 
46.27% 
43.89% 
Tight coupling 
42.97% 
46.03% 
43.58% 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is partially supported by grant number RGF 612211 of the Hong Kong Research Grants Council, by 1314159-0PAFT20F003 of the Ping An Research Institute and by 13140910 of the Huawei Noah's Ark Lab.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Discourse strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gumperz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The handbook of sociolinguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Coulmas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley-Blackwell</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A first speech recognition system for Mandarin-English code-switch conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Telaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Blaicher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Chng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2012</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detection of language boundary in code-switching utterances by bi-phone probabilities&quot; Chinese Spoken Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="293" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Language boundary detection and identification of mixed-language speech based on MAP estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Shia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Language identification on code-switching utterances using multiple cues&quot; Ninth Annual Conference of the International Speech Communication Association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lyu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A study on Hakka and mixed Hakka-Mandarin speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Spoken Language Processing (ISCSLP)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="199" to="204" />
		</imprint>
	</monogr>
	<note>7th International Symposium on</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An integrated framework for transcribing Mandarin-English code-mixed lectures with improved acoustic and language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Spoken Language Processing (ISCSLP), 2010 7th International Symposium on</title>
		<imprint>
			<biblScope unit="page" from="214" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An Approach to Mixed Language Automatic Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bhuvanagiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kopparapu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oriental COCOSDA</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantics-based language modeling for Cantonese-English code-mixing speech recognition Chinese Spoken Language Processing (ISCSLP)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ching</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Symposium on</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="246" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Structured language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Jelinek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="332" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language dependent universal phoneme posterior estimation for mixed language speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Imseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magimai-Doss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mandarin-English bilingual speech recognition for real world music retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combined acoustic and pronunciation modelling for non-native speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouselmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fohr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Illina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bilingual code-switching and syntactic theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Woolford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Inquiry</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="520" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">13 Code-switching and grammatical theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macswan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Handbook of Bilingualism and Multilingualism</title>
		<imprint>
			<publisher>Wiley-Blackwell</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">323</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A formal grammar for code-switching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poplack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sankoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Papers in Linguistics: International Journal of Human Communication</title>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="page" from="3" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Intelligent selection of language model training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2010 Conference Short Papers</title>
		<meeting>the ACL 2010 Conference Short Papers</meeting>
		<imprint>
			<biblScope unit="page" from="220" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heidi; Edward</forename><surname>Belazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rubin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Code switching and X-Bar theory: The functional head constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqueline</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toribio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguistic Inquiry</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="221" to="258" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Code-switching and the functional head constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><forename type="middle">M</forename><surname>Bhatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Janet Fuller et al. Proceedings of the Eleventh Eastern States Conference on Linguistics. Ithaca, NY: Department of Modern Languages and Linguistics</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Lattice parsing for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-C?</forename><surname>Chappelier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dric</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
