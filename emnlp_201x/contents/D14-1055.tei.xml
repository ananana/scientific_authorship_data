<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Positive Unlabeled Learning for Deceptive Reviews Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer School</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<addrLine>Wuhan 430072</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer School</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<addrLine>Wuhan 430072</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer School</orgName>
								<orgName type="institution">Wuhan University</orgName>
								<address>
									<addrLine>Wuhan 430072</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Positive Unlabeled Learning for Deceptive Reviews Detection</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="488" to="498"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Deceptive reviews detection has attracted significant attention from both business and research communities. However, due to the difficulty of human labeling needed for supervised learning, the problem remains to be highly challenging. This paper proposed a novel angle to the problem by modeling PU (positive unlabeled) learning. A semi-supervised model, called mixing population and individual property PU learning (MPIPUL), is proposed. Firstly, some reliable negative examples are identified from the unlabeled dataset. Secondly, some representative positive examples and negative examples are generated based on LDA (Latent Dirichlet Allocation). Thirdly, for the remaining un-labeled examples (we call them spy examples), which can not be explicitly identified as positive and negative, two similarity weights are assigned, by which the probability of a spy example belonging to the positive class and the negative class are displayed. Finally, spy examples and their similarity weights are incorporated into SVM (Support Vector Machine) to build an accurate classifier. Experiments on gold-standard dataset demonstrate the effectiveness of MPIPUL which outper-forms the state-of-the-art baselines.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Web has dramatically changed the way peo- ple express themselves and interact with others, people frequently write reviews on e-commerce sites, forums and blogs to achieve these purpos- es. For NLP (Natural Language Processing), these user-generated contents are of great value in that they contain abundant information related to peo- ple's opinions on certain topics. Currently, on- line reviews on products and services are used extensively by consumers and businesses to con- duct decisive purchase, product design and mar- keting strategies. Hence, sentiment analysis and opinion mining based on product reviews have become a popular topic of NLP ( <ref type="bibr" target="#b7">Pang and Lee, 2008;</ref><ref type="bibr" target="#b4">Liu, 2012)</ref>. However, since reviews infor- mation can guide people's purchase behavior, pos- itive reviews can result in huge economic benefit- s and fame for organizations or individuals. This leaves room for promoting the generation of re- view spams. Through observations and studies of the predecessors <ref type="bibr" target="#b18">(Jindal and Liu, 2008;</ref><ref type="bibr" target="#b17">Ott et al., 2011</ref>), review spams are divided into the following two classes:</p><p>• Deceptive Reviews: Those deliberately mis- lead readers by giving undeserving positive reviews to some target objects in order to pro- mote the objects, or by giving unjust nega- tive reviews to some target objects in order to damage their reputation.</p><p>• Disruptive Reviews: Those are non-reviews, which mainly include advertisements and other irrelevant reviews containing no opin- ion.</p><p>Disruptive reviews pose little threat to peo- ple, because human can easily identify and ignore them. In this paper, we focus on the more chal- lenging ones: deceptive reviews. Generally, de- ceptive reviews detection is deemed to be a classi- fication problem <ref type="bibr" target="#b17">(Ott et al., 2011;</ref><ref type="bibr" target="#b12">Li et al., 2011;</ref>). Based on the positive and neg- ative examples annotated by people, supervised learning is utilized to build a classifier, and then an unlabeled review can be predicted as deceptive re- view or truthful one. But the work from <ref type="bibr" target="#b17">Ott et al. (2011)</ref> shows that human cannot identify decep- tive reviews from their prior knowledge, which in- dicates that human-annotated review datasets must include some mislabeled examples. These exam- ples will disturb the generation ability of the clas- sifiers. So simple supervised learning is regarded as unsuitable for this task.</p><p>It is difficult to come by human labeling need- ed for supervised learning and evaluation, we can- not obtain the datasets containing deceptive re- views. However, we can get some truthful reviews with high confidence by heuristic rules and prior knowledge. Meanwhile, a lot of unlabeled reviews are available. The problem thus is this: based on some truthful reviews and a lot of unlabeled re- views, can we build an accurate classifier to iden- tify deceptive reviews. PU (positive unlabeled) learning can be utilized to deal with the above situation ( <ref type="bibr" target="#b5">Liu et al., 2002</ref>; <ref type="bibr" target="#b6">Liu et al., 2003)</ref>. Different from traditional super- vised learning, PU learning can still build an ac- curate classifier even without the negative training examples. Several PU learning techniques have been applied successfully in document classifica- tion with promising results <ref type="bibr" target="#b11">(Zhang, 2005;</ref><ref type="bibr" target="#b8">Elkan and Noto, 2008;</ref><ref type="bibr" target="#b24">Li et al., 2009;</ref><ref type="bibr">Xiao et al., 2011</ref>), while they have yet to be applied in detecting de- ceptive reviews. Here, we will study how to design PU learning to detect deceptive reviews.</p><p>An important challenge is how to deal with spy examples (easily mislabeled) of unlabeled re- views, which is not easily handled by the previous PU learning techniques. In this paper, we propose a novel approach, mixing population and individ- ual property PU learning (MPIPUL), by assigning similarity weights and incorporating weights into SVM learning phase. This paper makes the fol- lowing contributions:</p><p>• For the first time, PU learning is defined in the environment of identifying deceptive re- views.</p><p>• A novel PU learning is proposed based on L- DA and SVM.</p><p>• Experimental results demonstrate that our proposed method outperforms the curren- t baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deceptive Reviews Detection</head><p>Spam has historically been investigated in the con- texts of e-mail ( <ref type="bibr" target="#b15">Drucker et al., 1999;</ref><ref type="bibr">Gyongyi et al., 2004</ref>) and the Web ( <ref type="bibr" target="#b0">Ntoulas et al., 2006</ref>). In recent years, researchers have started to look at de- ceptive reviews. <ref type="bibr" target="#b18">Jindal and Liu (2008)</ref> found that opinion s- pam was widespread and different from e-mail and Web spam in essence <ref type="bibr" target="#b18">(Jindal and Liu, 2008)</ref>. They trained models using product review data, by defining features to distinguish duplicate opin- ion and non-duplicate based on the review tex- t, reviewers and product information. <ref type="bibr" target="#b13">Wu et al. (2010)</ref> proposed an alternative strategy of popu- larity rankings ( <ref type="bibr" target="#b13">Wu et al., 2010)</ref>.</p><p>Ott et al. (2011) developed the first dataset con- taining gold-standard deceptive reviews by crowd- sourcing <ref type="bibr" target="#b17">(Ott et al., 2011)</ref>, and presented three su- pervised learning methods to detect deceptive re- views by integrating knowledge from psycholin- guistics and computational linguistics. This gold- standard dataset will be used in the paper. <ref type="bibr" target="#b12">Li et al. (2011)</ref> manually built a review dataset from their crawled reviews <ref type="bibr" target="#b12">(Li et al., 2011)</ref>, and exploited semi-supervised co-training algorithm to identify deceptive reviews.  verified the connection be- tween the deceptive reviews and the abnormal dis- tributions <ref type="bibr">(Feng et al., 2012a</ref>). Later, they <ref type="bibr">(Feng et al., 2012b</ref>) demonstrated that features driven from CFG (Context Free Grammar) parsing trees con- sistently improve the detection performance. <ref type="bibr" target="#b3">Mukherjee et al. (2012)</ref> proposed detect- ing group spammers (a group of reviewers who work collaboratively to write deceptive reviews) in product reviews ( <ref type="bibr" target="#b3">Mukherjee et al., 2012</ref>). The pro- posed method first used frequent itemset mining to find a set of candidate groups. Then GSRank was presented which can consider relationships a- mong groups, individual reviewers and products they reviewed to detect spammer groups. Later, they also proposed exploiting observed reviewing behaviors to detect opinion spammers in an unsu- pervised Bayesian inference framework <ref type="bibr" target="#b1">(Mukherjee et al., 2013)</ref>.  assumed that there must be some difference on language structure and sen- timent polarity between deceptive reviews and truthful ones <ref type="bibr">(Ren et al., 2014a</ref>), then they de- fined the features related to the review text and used genetic algorithm for feature selection, fi- nally they combined two unsupervised clustering algorithm to identify deceptive reviews. Later, they <ref type="bibr">(Ren et al., 2014b</ref>) present a new approach, from the viewpoint of correcting the mislabeled examples, to find deceptive reviews. Firstly, they partition a dataset into several subsets.Then they construct a classifier set for each subset and s- elect the best one to evaluate the whole dataset. Meanwhile, error variables are defined to compute the probability that the examples have been mis- labeled. Finally, the mislabeled examples are cor- rected based on two threshold schemes, majority and non-objection.</p><p>Unlike previous studies, PU learning is imple- mented to identify deceptive reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Positive Unlabeled Learning</head><p>According to the use of the unlabeled data, PU learning can be divided into two classes.</p><p>One family of methods built the final classifier by using positive examples dataset and some ex- amples of the unlabeled dataset ( <ref type="bibr" target="#b5">Liu et al., 2002</ref>; <ref type="bibr" target="#b6">Liu et al., 2003)</ref>. The basic idea is to find a set of reliable negative examples from the unlabeled data firstly, and then to learn a classifier using EM (Expectation Maximization) or SVM. The perfor- mance is limited for neglecting the rest examples of unlabeled dataset.</p><p>Another family of methods learned the final classifier by using positive examples dataset and all examples of the unlabeled dataset. <ref type="bibr" target="#b24">Li et al. (Li et al., 2009</ref>) studied PU learning in the data stream environment, they proposed a PU learn- ing LELC (PU Learning by Extracting Likely positive and negative micro-Clusters) for docu- ment classification, they assume that the exam- ples close together shared the same labels. <ref type="bibr">Xiao et al. (Xiao et al., 2011</ref>) proposed a method, called SPUL (similarity-based PU learning), the local similarity-based and global similarity-based mechanisms are proposed to generate the similar- ity weights for the easily mislabeled examples, respectively. Experimental results show global SPUL generally performs better than local SPUL.</p><p>In this paper, a novel PU learning (MPIPUL) is proposed to identify deceptive reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminary</head><p>Before we introduce the proposed method, we briefly review SVM, which has proven to be an effective classification algorithm <ref type="bibr" target="#b22">(Vapnik, 1998)</ref>.</p><formula xml:id="formula_0">Let T = {(x (1) , y (1) ), (x (2) , y (2) ), . . . , (x (|T |) , y (|T |) )</formula><p>} be a training set, where x (i) ∈ R d and y (i) ∈ {+1, −1}. SVM aims to seek an optimal separating hyperplane w T x (i) + b = 0, the hyper- plane can be obtained by solving the following optimization problem:</p><formula xml:id="formula_1">min F (w, b, ϵ i ) = 1 2 ||w|| 2 + C |T | ∑ i=1 ϵ i s.t. y (i) (w T x (i) + b) ≥ 1 − ϵ i , i = 1, . . . , |T | ϵ i ≥ 0, i = 1, . . . , |T | (1)</formula><p>where w T represents the transpose of w, C is a parameter to balance the classification errors and ϵ i are variables to relax the margin constraints. The optimal classifier can be achieved by using the Lagrange function. For a test example x, if w T x+b &lt; 0, it is classified into the negative class; otherwise, it is positive.</p><p>In the following, SVM is extended to incorpo- rate the spy examples and their weights, such that the spy examples can contribute differently to the classifier construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Proposed Method</head><p>In this section, we will introduce the proposed ap- proach in details. In our PU learning (MPIPUL), truthful reviews are named positive examples, and deceptive reviews are called negative examples. P is defined as a set which contains all positive ex- amples. U is a set for all unlabeled examples. PU learning aims at building a classifier using P and U . MPIPUL adopts the following four steps:</p><p>• Step 1: Extract the reliable negative exam- ples;</p><p>• Step 2: Compute the representative positive and negative examples;</p><p>• Step 3: Generate the similarity weights for the spy examples;</p><p>• Step 4: Build the final SVM classifier;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extracting Reliable Negative Examples</head><p>Considering only positive and unlabeled examples are available in PU learning, some negative ex- amples need to be extracted firstly. These exam- ples will influence the performance of the follow- ing three steps. So high-quality negative examples must be guaranteed. Previous works solved the problem with the Spy technique ( <ref type="bibr" target="#b5">Liu et al., 2002</ref>) or the Rocchio technique ( <ref type="bibr" target="#b6">Liu et al., 2003)</ref>, we in- tegrate them in order to get reliable negative ex- amples. Let subsets N S 1 and N S 2 contain the corresponding reliable negative examples extract- ed by the two techniques, respectively. Examples are considered to be a reliable negative only if both techniques agree that they are negative. That is, N S = N S 1 ∩ N S 2 , where N S contains the reli- able negative examples. After reliable negative examples are extracted, there are still some unlabeled examples (we call spy examples) in set U , let subset U S = U − N S, which stores all the spy examples. It is crucial to determine how to deal with these spy examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Computing Representative Positive and Negative Examples</head><p>Generally, a classifier can be constructed to pre- dict deceptive reviews based on the positive ex- amples set P and the reliable negative examples set N S. But the classifier is not accurate enough for lacking of making full use of unlabeled dataset U . In order to utilize spy examples in subset U S, some representative positive and negative exam- ples are calculated firstly. Since the examples have different styles in sentiment polarity and topic dis- tribution, for every class, computing one repre- sentative example is not suitable. For the posi- tive class or the negative class, to ensure there is a big difference between the different representa- tive examples. This paper proposes clustering re- liable negative examples into several groups based on LDA (Latent Dirichlet Allocation) topic mod- el and K-means, and then multiple representative examples can be obtained. LDA topic model is known as a parametric Bayesian clustering model ( <ref type="bibr" target="#b10">Blei et al., 2003)</ref>, and assumes that each document can be represented as the distribution of several topics, each docu- ment is associated with common topics. LDA can well capture the relationship between internal doc- uments.</p><p>In our experiments based on LDA model, we can get the topic distribution for the reliable neg- ative examples, then some reliable negative exam- ples which are similar in topic distribution will be clustered into a group by K-means. Finally, these reliable negative examples can be clustered into n micro-clusters (N S 1 , N S 2 , . . . , N S n ). Here,</p><formula xml:id="formula_2">n = 30 * |N S|/(|U S| + |N S|)<label>(2)</label></formula><p>Here, according to the suggestion of previous work (Xiao et al., 2011), we examine the impact of the different parameter (from 10 to 60) on over- all performance, and select the best value 30.</p><p>Based on the modified Rocchio formula <ref type="bibr">(Buckley et al., 1999</ref>), n representative positive exam- ples (p k ) and n negative ones (n k ) can be obtained using the following formula:</p><formula xml:id="formula_3">p k = α 1 |P | |P | ∑ i=1 x (i) ∥ x (i) ∥ − β 1 |N S k | |N S k | ∑ i=1 x (i) ∥ x (i) ∥ n k = α 1 |N S k | |N S k | ∑ i=1 x (i) ∥ x (i) ∥ − β 1 |P | |P | ∑ i=1 x (i) ∥ x (i) ∥ k = 1, . . . , n<label>(3)</label></formula><p>According to previous works <ref type="bibr" target="#b9">(Buckley et al., 1994)</ref>, where the value of α and β are set to 16 and 4 respectively. The research from Buckley et al. demonstrate that this combination emphasizes occurrences in the relevant documents as opposed to non-relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Generating Similarity Weights</head><p>For a spy example x, since we do not know which class it should belong to, enforcing x to the posi- tive class or the negative class will lead to some mislabeled examples, which disturbs the perfor- mance of final classifier. We represent a spy ex- ample x using the following probability model:</p><formula xml:id="formula_4">{x, (p + (x), p − (x))}, p + (x) + p − (x) = 1<label>(4)</label></formula><p>Where p + (x) and p − (x) are similarity weight- s which represent the probability of x belonging to the positive class and the negative class, re- spectively. For example, {x, (1, 0)} means that x is positive, while {x, (0, 1)} indicates that x is i- dentified to be negative. For {x, (p + (x), p − (x))}, where 0 &lt; p + (x) &lt; 1 and 0 &lt; p − (x) &lt; 1, it implies that the probability of x belonging to the positive class and the negative class are both con- sidered.</p><p>In this section, similarity weights are decided by mixing global information (population property) and local information (individual property). Then all spy examples and their similarity weights are incorporated into a SVM-based learning model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Population Property</head><p>Population property means that the examples in each micro-cluster share the similarity in sen- timent polarity and topic distribution, and they belong to the same category with a high pos- sibility. In our framework, in order to com- pare with the representative examples, all spy ex- amples are firstly clustered into n micro-clusters (U S 1 , U S 2 , . . . , U S n ) based on LDA and K- means. Then, for every spy example x in one micro-cluster U S i , we tags with temporary label by finding its most similar representative example. Finally, we can get the similarity weights for a spy example x in micro-cluster U S i , their probability pertaining to the positive class and negative class can be represented by the following formula:</p><formula xml:id="formula_5">p pop(x) = |positive| |U S i | n pop(x) = |negative| |U S i |<label>(5)</label></formula><p>where |U S i | represents the number of all examples in micro-cluster U S i , |positive| means the num- ber of the examples which is called temporary pos- itive in U S i , and |negative| means the number of the examples which is called temporary negative in U S i . For example, <ref type="figure" target="#fig_0">Figure 1</ref> shows the part (C1, C2, C3, C4) of the clustering results for the spy exam- ples based on LDA and K-means, the examples x in C4 are assigned with weights p pop(x) = 4 9 , n pop(x) = 5 9 , the examples x in C1 are as- signed with weights p pop(x) = 1, n pop(x) = 0. The advantage of population property lies in the fact that it considers the similar relationship be- tween the examples, from which the same micro- cluster are assigned the same similarity weight. However, it cannot distinguish the difference of examples in one micro-cluster. In fact, the simi- larity weights of examples from the same micro- cluster can be different, since they are located physically different. For example, for the spy ex- ample y and z in micro-cluster C4, it is apparent- ly unreasonable that we assign the same similarity weights to them. So we should join the local in- formation (individual property) when we are com- puting the similarity weights for a spy example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Individual Property</head><p>Individual property is taken into account to mea- sure the relationship between every spy example and all representative ones. Specifically, for ex- ample x, we firstly compute its similarity to each of the representative examples, and then the prob- ability of the example x belonging to the positive class and negative class can be calculated using the following formula:</p><formula xml:id="formula_6">p ind(x) = ∑ n k=1 sim(x, p k ) ∑ n k=1 (sim(x, p k ) + sim(x, n k )) n ind(x) = ∑ n k=1 sim(x, n k ) ∑ n k=1 (sim(x, p k ) + sim(x, n k ))<label>(6)</label></formula><p>In the above formula,</p><formula xml:id="formula_7">sim(x, y) = x · y ||x|| · ||y||</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Similarity Weights</head><p>A scheme mixing population and individual prop- erty is designed to generate the similarity weights of spy examples. Specifically, for spy example x, their similarity weights can be obtained by the fol- lowing formula:</p><formula xml:id="formula_8">p + (x) = λ · p pop(x) + (1 − λ) · p ind(x) p − (x) = λ · n pop(x) + (1 − λ) · n ind(x)<label>(7)</label></formula><p>Where λ is a parameter to balance the informa- tion from population property and individual prop- erty. In the remaining section, we will examine the impact of the parameter λ on overall perfor- mance. Meanwhile, it can be easily proved that p + (x) + p − (x) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Constructing SVM Classifier</head><p>After performing the third step, each spy example x is assigned two similarity weights: p + (x) and p − (x). In this section, we will extend the formu- lation of SVM by incorporating the examples in positive set P , reliable negative set N S, spy ex- amples set U S and their similarity weights into a SVM-based learning model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Primal Problem</head><p>Since the similarity weights p + (x) and p − (x) in- dicate the probability for a spy example x belong- ing to the positive class and the negative class, re- spectively. The optimization formula (1) can be rewritten as the following optimization problem:</p><formula xml:id="formula_9">min F (w, b, ϵ) = 1 2 ||w|| 2 + C 1 |P | ∑ i=1 ϵ i + C 2 · |U S| ∑ j=1 p + (x (j) )ϵ j + C 3 |U S| ∑ m=1 p − (x (m) )ϵ m +C 4 |N S| ∑ n=1 ϵ n s.t. y (i) (w T x (i) + b) ≥ 1 − ϵ i , x (i) ∈ P y (j) (w T x (j) + b) ≥ 1 − ϵ j , x (j) ∈ U S y (m) (w T x (m) + b) ≥ 1 − ϵ m , x (m) ∈ U S y (n) (w T x (n) + b) ≥ 1 − ϵ n , x (n) ∈ N S ϵ i ≥ 0, ϵ j ≥ 0, ϵ m ≥ 0, ϵ n ≥ 0<label>(8)</label></formula><p>Where C 1 , C 2 , C 3 and C 4 are penalty factors con- trolling the tradeoff between the hyperplane mar- gin and the errors, ϵ i , ϵ j , ϵ m and ϵ n are the error terms. p + (x (j) )ϵ j and p − (x (m) )ϵ m can be consid- ered as errors with different weights. Note that, a bigger value of p + (x (j) ) can increase the effect of parameter ϵ j , so that the corresponding example x (j) becomes more significant towards the positive class. In the following, we will find the dual form to address the above optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Dual Problem</head><p>Assume α i and α j are Lagrange multipliers. To simplify the presentation, we redefine some nota- tions as follows:</p><formula xml:id="formula_10">C + i = { C 1 , x (i) ∈ P C 2 p + (x (j) ), x (j) ∈ U S C − j = { C 3 p − (x (m) ), x (m) ∈ U S C 4 , x (n) ∈ N S</formula><p>Based on the above definitions, we let T + = P ∪ U S, T − = U S ∪ N S and T * = T + ∪ T − . The Wolfe dual of primal formulation can be ob- tained as follows (Appendix A for the calculation process):</p><formula xml:id="formula_11">max W (α) = |T * | ∑ i=1 α i − 1 2 |T * | ∑ i=1,j=1 α i α j y (i) · y (j) &lt; x (i) , x (j) &gt; s.t. C + i ≥ α i ≥ 0, x (i) ∈ T + C − j ≥ α j ≥ 0, x (j) ∈ T − |T + | ∑ i=1 α i − |T − | ∑ j=1 α j = 0<label>(9)</label></formula><p>where &lt; x (i) , x (j) &gt; is the inner product of x (i) and x (j) . In order to get the better performance, we can replace them by using kernel function ϕ(x (i) ) and ϕ(x (j) ), respectively. The kernel track can convert the input space into a high-dimension fea- ture space. It can solve the uneven distribution of dataset and complex problem from heterogeneous data sources, which allows data to get a better ex- pression in the new space <ref type="bibr">(Lanckriet et al., 2004;</ref><ref type="bibr" target="#b23">Lee et al., 2007)</ref>. After solving the above problem, w can be ob- tained, then b can also be obtained by using KKT (Karush-Kuhn-Tucker) conditions. For a test ex- ample x, if w T x + b &gt; 0, it belongs to the positive class. Otherwise, it is negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We aim to evaluate whether our proposed PU learning can identify deceptive reviews properly. We firstly describe the gold-standard dataset, and then introduce the way to generate the positive examples P and unlabeled examples U . Finally we present human performance in gold-standard dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>There is very little progress in detection of de- ceptive reviews, one reason is the lack of stan- dard dataset for algorithm evaluation. The gold- standard dataset is created based on crowdsourc- ing platform <ref type="bibr" target="#b17">(Ott et al., 2011)</ref>, which is also adopt- ed as the experimental dataset in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Deceptive Reviews</head><p>Crowdsourcing services can carry out massive da- ta collection and annotation; it defines the task in the network platform, and paid for online anony- mous workers to complete the task.</p><p>Humans cannot be precisely distinguish decep- tive ones from existing reviews, but they can create deceptive reviews as one part of the dataset. <ref type="bibr" target="#b17">Ott et al. (2011)</ref> accomplish this work by AMT (Ama- zon Mechanical Turk). They set 400 tasks for 20 hotels, in which each hotel gets 20 tasks. Specif- ic task is: If you are a hotel market department employee, for each positive review you wrote for the benefit for hotel development, you may get one dollar. They collect 400 deceptive reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Truthful Reviews</head><p>For the collection of truthful reviews, they get 6977 reviews from TripAdvisor 1 based on the same 20 Chicago hotels, and remove some reviews on the basis of the following constraints:</p><p>• Delete all non-five star reviews;</p><p>• Delete all non-English reviews;</p><p>• Delete all reviews which are less than 75 characters;</p><p>• Delete all reviews written by first-time au- thors;</p><p>2124 reviews are gathered after filtering. 400 of them are chosen as truthful ones for balancing the number of deceptive reviews, as well as maintain- ing consistent with the distribution of the length of deceptive reviews. 800 reviews constitute whole gold-standard dataset at last.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experiment Setup</head><p>We conduct 10-fold cross-validation: the dataset is randomly split into ten folds, where nine fold- s are selected for training and the tenth fold for test. In training dataset, it contains 360 truthful reviews and 360 deceptive ones. This paper is in- tended to apply PU learning to identify deceptive reviews. We specially make the following setting: take 20% of the truthful reviews in training set as positive examples dataset P , all remaining truthful and deceptive reviews in training set as the unla- beled dataset U . Therefore, during one round of the algorithm, the training set contains 720 exam- ples including 72 positive examples (set P ) and 648 unlabeled examples (set U ), and the test set contains 80 examples including 40 positive and 40 negative ones. In order to verify the stability of the proposed method, we also experiment anoth- er two different settings, which account for 30% 1 http://www.tripadvisor.com and 40% of the truthful reviews in training set as positive examples dataset P respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Human Performance</head><p>Human performance reflects the degree of difficul- ty to address this task. The rationality of PU learn- ing is closely related to human performance.</p><p>We solicit the help of three volunteer students, who were asked to make judgments on test sub- set (corresponding to the tenth fold of our cross- validation experiments, contains 40 deceptive re- views and 40 truthful reviews). Additionally, to test the extent to which the individual human judges are biased, we evaluate the performance of two virtual meta-judges: one is the MAJORITY meta-judge when at last two out of three human judge believe the review to be deceptive, and the other is the SKEPTIC when any human judge be- lieves the review to be deceptive. It is apparent from the results that human judges are not par- ticularly effective at this task <ref type="table" target="#tab_0">(Table 1)</ref>. Inter- annotator agreement among the three judges, com- puted using Fleiss' kappa, is 0.09. <ref type="bibr" target="#b19">Landis and Koch (Landis and Koch, 1977)</ref> suggest that s- cores in the range (0.00, 0.20) correspond to "s- light agreemen" between annotators. The largest pairwise Cohen's kappa is 0.11 between JUDGE- 1 and JUDGE-3, far below generally accepted pairwise agreement levels. We can infer that the dataset which are annotated by people will include a lot of mislabeled examples. Identifying decep- tive reviews by simply using supervised learning methods is not appropriate. So we propose ad- dressing this issue by using PU learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Analysis</head><p>In order to verify the effectiveness of our proposed method, we perform two PU learning (LELC and SPUL) in the gold-standard dataset. <ref type="table" target="#tab_1">Table 2</ref> shows that the experimental results com- pared with different PU learning techniques. In <ref type="table" target="#tab_1">Table 2</ref>, P (20%) means that we randomly select 20 percentages of truthful reviews to form the pos- itive examples subset P . In our MPIPUL frame- work, we set λ = 0.3. We can see that our pro- posed method can obtain 83.91%, 85.43% and 86.69% in accuracy from different experimental settings, respectively. Compared to the curren- t best method (SPUL-global), the accuracy can be improved 2.06% on average. MPUPUL can im- prove 3.21% on average than LELC. The above discussion shows our proposed methods consis- tently outperform the other PU baselines. PU learning framework in this paper can obtain the better performance. Two factors contribute to the improved performance. Firstly, LDA can cap- ture the deeper information of the reviews in topic distribution. Secondly, strategies of mixing pop- ulation and individual property can generate the similarity weights for spy examples, and these ex- amples and their similarity weights are extended into SVM, which can build a more accurate clas- sifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Parameter Sensitivity</head><p>For the spy examples, the similarity weights are generated by population property and individual property. Should we select the more population information or individual information? In MPIP- UL, parameter λ is utilized to adjust this process. So we experiment with the different value of the parameter λ on MPUPUL performance <ref type="figure" target="#fig_1">(Figure 2</ref>). As showed in <ref type="figure" target="#fig_1">Figure 2</ref>, for P (20%), if λ &lt; 0.3, the performance increases linearly, if λ &gt; 0.3, the performance will decrease linearly. Mean- while, we can get the same trends for P (30%) and P (40%). Based on the above discussion, MPIP- UL can get the best performance when λ ≈ 0.3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>This paper proposes a novel PU learning (MPIP- UL) technique to identify deceptive reviews based on LDA and SVM. Firstly, the spy examples are assigned similarity weights by integrating the in- formation from the population property and in- dividual property. Then the spy examples and their similarity weights are incorporated into SVM learning phase to build an accurate classifier. Ex- perimental results on gold-standard dataset show the effectiveness of our method.</p><p>In future work, we will discuss the application of our proposed method in the massive dataset.</p><p>Yanshan Xiao, Bing Liu, Jie Yin, Longbing Cao, Chengqi Zhang, and Zhifeng Hao. 2011. Similarity-based approach for positive and unla- beled learning. In Proceeding of the 22nd Inter- national Joint Conference on Artifical Intelligence, page 1577-1582, Barcelona, Spain.</p><p>Zoltan Gyongyi, Hector Garcia-Molina, and Jan Pedesen. 2004. Combating web spam web with trustrank. In Proceedings of the 30th International Conference on Very Large Data Bases, page 576- 587, Toronto, Canada.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A</head><p>The optimization problem is as follows:</p><formula xml:id="formula_12">min F (w, b, ϵ) = 1 2 ||w|| 2 + C 1 |P | ∑ i=1 ϵ i + C 2 · |U S| ∑ j=1 p + (x (j) )ϵ j + C 3 |U S| ∑ m=1 p − (x (m) )ϵ m + C 4 |N S| ∑ n=1 ϵ n s.t. y (i) (w T x (i) + b) ≥ 1 − ϵ i , x (i) ∈ P y (j) (w T x (j) + b) ≥ 1 − ϵ j , x (j) ∈ U S y (m) (w T x (m) + b) ≥ 1 − ϵ m , x (m) ∈ U S y (n) (w T x (n) + b) ≥ 1 − ϵ n , x (n) ∈ N S ϵ i ≥ 0, ϵ j ≥ 0, ϵ m ≥ 0, ϵ n ≥ 0<label>(10)</label></formula><p>We construct the Lagrangian function for the above optimization problem, we have:</p><formula xml:id="formula_13">L(w, b, ϵ, α, γ) = F (w, b, ϵ) + |P | ∑ i=1 α i [−y (i) · (w T x (i) + b) + 1 − ϵ i ] + |U S| ∑ j=1 α j [−y (j) (w T x (j) + b) + 1 − ϵ j ] + |U S| ∑ m=1 α m [−y (m) (w T x (m) + b) + 1 −ϵ m ] + |N S| ∑ n=1 α n [−y (n) (w T x (n) + b) + 1 − ϵ n ]− |P | ∑ i=1 γ i ϵ i − |U S| ∑ j=1 γ j ϵ j − |U S| ∑ m=1 γ m ϵ m − |N S| ∑ n=1 γ n ϵ n<label>(11)</label></formula><p>Here, the α and γ are Lagrange multipliers. To find the dual form of the problem, we need to first minimize L(w, b, ϵ, α, γ) with respect to w and b, we will do by setting the derivatives of L with re- spect to w and b to zero, we have:</p><formula xml:id="formula_14">∂L(w, b, ϵ, α, γ) ∂w = w − |P | ∑ i=1 α i y (i) x (i) − |U S| ∑ j=1 α j y (j) x (j) − |U S| ∑ m=1 α m y (m) x (m) − |N S| ∑ n=1 α n y (n) · x (n) = 0<label>(12)</label></formula><p>This implies that</p><formula xml:id="formula_15">w = |P | ∑ i=1 α i y (i) x (i) + |U S| ∑ j=1 α j y (j) x (j) + |U S| ∑ m=1 α m · y (m) x (m) + |N S| ∑ n=1 α n y (n) x (n)<label>(13)</label></formula><p>Here, to simplify the presentation, we redefine some notations in the following:</p><formula xml:id="formula_16">T + = P ∪ U S, T − = U S ∪ N S, T * = T + ∪ T − C + i = { C 1 , x (i) ∈ P C 2 p + x (j) , x (j) ∈ U S C − j = { C 3 p − x (m) , x (m) ∈ U S C 4 , x (n) ∈ N S so we obtain w = |T * | ∑ i=1 α i y (i) x (i)<label>(14)</label></formula><p>As for the derivative with respect to b, we obtain</p><formula xml:id="formula_17">∂L(w, b, ϵ, α, γ) ∂b = − |P | ∑ i=1 α i y (i) − |U S| ∑ j=1 α j y (j) − |U S| ∑ m=1 α m y (m) − |N S| ∑ n=1 α n y (n) = 0<label>(15)</label></formula><p>We get:</p><formula xml:id="formula_18">|T * | ∑ i=1 α i y (i) = 0<label>(16)</label></formula><p>If we take Equation <ref type="formula" target="#formula_4">(14)</ref> and <ref type="formula" target="#formula_6">(16)</ref> back into the Lagrangian function <ref type="table" target="#tab_0">(Equation 11)</ref>, and simplify, we get</p><formula xml:id="formula_19">L(w, b, ϵ, α, γ) = |T * | ∑ i=1 α i − 1 2 |T * | ∑ i,j=1 y (i) y (j) α i · α j &lt; x (i) , x (j) &gt;<label>(17)</label></formula><p>To the primal optimization formula (10), we can obtain the following dual optimization problem:</p><formula xml:id="formula_20">max W (α) = |T * | ∑ i=1 α i − 1 2 |T * | ∑ i=1,j=1 α i α j y (i) · y (j) &lt; x (i) , x (j) &gt; s.t. C + i ≥ α i ≥ 0, x (i) ∈ T + C − j ≥ α j ≥ 0, x (j) ∈ T − |T + | ∑ i=1 α i − |T − | ∑ j=1 α j = 0<label>(18)</label></formula><p>where &lt; x (i) , x (j) &gt; is the inner product of x (i) and x (j) , we can replace them by using kernel function ϕ(x (i) ) and ϕ(x (j) ), respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of population property</figDesc><graphic url="image-1.png" coords="5,76.81,435.34,209.17,126.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Algorithm performance on different parameter</figDesc><graphic url="image-2.png" coords="8,312.09,62.61,208.66,156.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Human performance 
Methods 
Accuracy (%) 

Human 
JUDGE-1 
57.9 
JUDGE-2 
55.4 
JUDGE-3 
61.7 

META 
MAJORITY 
58.3 
SKEPTIC 
62.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Accuracy on the different PU learning 
Baselines 
P(20%) P(30%) P(40%) 
LELC 
81.12 
82.08 
83.21 
SPUL-local 
81.43 
82.71 
84.09 
SPUL-global 
81.89 
83.24 
84.73 
MPIPUL (0.3) 83.91 
85.43 
86.69 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the anonymous reviewer-s for their thoughtful comments. This work is supported by the State Key Program of National Natural Science Foundation of China (Grant No.61133012), the National Natural Sci-ence Foundation of China (Grant No.61173062, 61373108) and the National Philosophy Social Science Major Bidding Project of China (Grant No. 11&amp;ZD189).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Detecting spam web pages through content analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Ntoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Najork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Fetterly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on World Wide Web</title>
		<meeting>the 15th International Conference on World Wide Web<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spotting opinion spammers using behavioral footprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meichun</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malu</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riddhiman</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 19th</title>
		<meeting>eeding of the 19th</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">ACM SIGKDD International Conference on Knowledge Discovery and Data Ming</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="632" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spotting fake reviewer groups in consumer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalie</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 21st International Conference on World Wide Web</title>
		<meeting>eeding of the 21st International Conference on World Wide Web<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>USA</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
			<pubPlace>San Rafael, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Partially supervised classification of text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><forename type="middle">Sun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Machine Learning</title>
		<meeting>the 19th International Conference on Machine Learning<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Building text classifiers using positive and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd IEEE International Conference on Data Ming</title>
		<meeting>the 3rd IEEE International Conference on Data Ming<address><addrLine>Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="179" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Noto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Ming</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Ming<address><addrLine>Las Vegas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The effect of adding relevance information in a relevance feedback environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chirs</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bgrard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International SIGIR Conference on Research and Development Retrieval</title>
		<meeting>the 17th Annual International SIGIR Conference on Research and Development Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="292" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple probabilistic approach to learning from positive and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dell</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Annual UK Workshop on Computational Intelligence</title>
		<meeting>the 5th Annual UK Workshop on Computational Intelligence</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="83" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to identify review spam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangtao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 22nd International Joint Conference on Artificial Intelligence</title>
		<meeting>eeding of the 22nd International Joint Conference on Artificial Intelligence<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2488" to="2493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Opinion formation under costly express</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bernardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligence System Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning the kernel matrix with seim-difinit programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Gert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nello</forename><surname>Lanckeriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="27" to="72" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Support vector machines for spam categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1048" to="1054" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>Vapnik</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Support kernel machines for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumar</forename><surname>Ankita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sminchisescu</forename><surname>Cristian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 11th International Conference on Computer Vision</title>
		<meeting>the IEEE 11th International Conference on Computer Vision<address><addrLine>Rio de Janeiro, Brzail</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finding deceptive opinion spam by any stretch of the imagination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Caridie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technoloies</title>
		<meeting>eeding of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technoloies<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="309" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Opinion spam and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 1st ACM International Conference on Web Search and Data Mining</title>
		<meeting>eeding of the 1st ACM International Conference on Web Search and Data Mining<address><addrLine>California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Distributional footprints of deceptive product reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longfei</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Gogar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 6th International AAAI Conference on WebBlogs and Social Media</title>
		<meeting>eeding of the 6th International AAAI Conference on WebBlogs and Social Media<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Syntactic stylometry for deception detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritwik</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 50th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>eeding of the 50th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="171" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
			<pubPlace>New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Kernel combination versus classifier combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanjui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Verzakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Multiple Classifier Systems</title>
		<meeting>the 7th International Workshop on Multiple Classifier Systems<address><addrLine>Rrague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Positive unlabeled learning for data stream classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">See</forename><forename type="middle">Kiong</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIAM International Conference on Data Ming</title>
		<meeting>the SIAM International Conference on Data Ming<address><addrLine>Nevada, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="257" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Finding deceptive opinion spam by correcting the mislabled instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Journal of Electronics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="702" to="707" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deceptive reviews detection based on language structure and sentiment polarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Frontiers of Computer Science and Technology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="320" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
