<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Margin Neural Language Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaji</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ping</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Research</orgName>
								<address>
									<settlement>Sunnyvale</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="institution">Oregon State University</orgName>
								<address>
									<settlement>Corvallis</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Margin Neural Language Model</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1183" to="1191"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We propose a large margin criterion for training neural language models. Conventionally, neural language models are trained by minimizing perplexity (PPL) on grammatical sentences. However, we demonstrate that PPL may not be the best metric to optimize in some tasks, and further propose a large margin formulation. The proposed method aims to enlarge the margin between the &quot;good&quot; and &quot;bad&quot; sentences in a task-specific sense. It is trained end-to-end and can be widely applied to tasks that involve re-scoring of generated text. Compared with minimum-PPL training, our method gains up to 1.1 WER reduction for speech recognition and 1.0 BLEU increase for machine translation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Language models (LMs) estimate the likelihood of a symbol sequence {x t } T t=0 , based on the joint probability, p(x 0 , . . . , x T ) = p(x 0 ) T t=1 p(x t |x 0 , . . . , x t−1 ).</p><p>(1)</p><p>To measure the quality of an LM, a commonly adopted metric is perplexity (PPL), defined as</p><formula xml:id="formula_0">PPL exp − 1 T T t=0</formula><p>log p(x t |x 0 , . . . , x t−1 ) , A good language model has a small PPL, being able to assign higher likelihoods to sentences that are more likely to appear.</p><p>LMs are widely applied in automatic speech recognition (ASR) ( <ref type="bibr" target="#b23">Yu and Deng, 2014</ref>) and ma- chine translation (MT) <ref type="bibr" target="#b6">(Koehn, 2009)</ref>. Follow- ing <ref type="bibr" target="#b6">Koehn (2009)</ref>, one may interpret the language * Contributions were made while at Baidu Research. model as prior knowledge on the text to be in- ferred, which provides information complemen- tary to the ASR or MT system itself. In prac- tice, there are several ways to incorporate the lan- guage model. The simplest way may be re-scoring an n-best list returned by the ASR or MT sys- tem ( <ref type="bibr" target="#b13">Mikolov et al., 2010;</ref><ref type="bibr" target="#b20">Sundermeyer et al., 2012)</ref>. A slightly more sophisticated way is to jointly consider the ASR/MT and language model in a beam search decoder ( <ref type="bibr">Amodei et al., 2016)</ref>. Specifically, at each time step, the decoder ap- pends every symbol in the vocabulary to each se- quence in the current candidate set. For every hypothesis, a score is calculated as a linear com- bination of the log-likelihoods given by both the ASR/MT and language models. Then, only the top K hypotheses with the highest scores are re- tained, as an updated candidate set. More recently, <ref type="bibr" target="#b3">Gulcehre et al. (2015)</ref> and <ref type="bibr" target="#b19">Sriram et al. (2017)</ref> pro- pose to predict the next symbol based on a fusion of the hidden states in the ASR/MT and language models. A gating mechanism is jointly trained to determine how much the language model should contribute.</p><p>The afore-discussed language models are gen- erative in the sense that they merely model the joint distribution of a symbol sequence (Eq. <ref type="formula">(1)</ref>). While the research community is mostly focused on pushing the limit of PPL (e.g., <ref type="bibr" target="#b5">Jozefowicz et al., 2016)</ref>, very limited attention has been paid to the discrimination power of language models when they are applied to real tasks, such as ASR and MT ( <ref type="bibr" target="#b8">Li and Khudanpur, 2008)</ref>. By contrast, dis- criminative language modeling aims at enhancing the performance in downstream applications. For example, existing works ( <ref type="bibr" target="#b16">Roark et al., 2004</ref><ref type="bibr" target="#b15">Roark et al., , 2007</ref>) often target at improving ASR accuracy. The key motivation underlying them is that the model should be able to discriminate between "good" and "bad" sentences in a task-specific sense, instead of just modeling grammatical ones. The com- mon methodology ( <ref type="bibr">Dikic et al., 2013</ref>) is to build a binary classifier upon hand-crafted features ex- tracted from the sentences. However, it is not ob- vious how these methods can utilize large unanno- tated corpus, which is often easily available, and the hand-crafted features are also ad hoc and may result in suboptimal performance.</p><p>In this work, we study how to improve the dis- crimination ability of a recurrent network-based neural language model (RNNLM). The goal is to enlarge the difference between the log-likelihoods of "good" and "bad" sentences. In an contrast to the existing works <ref type="bibr" target="#b16">(Roark et al., 2004</ref><ref type="bibr" target="#b15">(Roark et al., , 2007</ref>, our method does not rely on hand-crafted features, and is trained in end-to-end manner and able to take advantage of large external text corpus. In fact, it is a general training criterion that is transparent to the network architecture of the RNNLM, and can be applied to various text generation tasks, in- cluding ASR and MT. Experiments on state-of-art ASR and MT systems show its significant advan- tage over an LM trained by minimizing PPL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background on RNNLM</head><p>We first give some background knowledge on RNNLMs. The prototypical RNNLM ( <ref type="bibr" target="#b13">Mikolov et al., 2010)</ref> has one layer of recurrent cell and works as follows. Denote a sentence as x = [x 0 , . . . , x t , . . . ], where the x t 's are words. Let x t be the embedding vector for x t . The recurrent cell takes in the embedding and produces a hidden state h t by</p><formula xml:id="formula_1">h t = σ(U x t + V h t−1 ),</formula><p>where σ(z) = 1 1+e −z is sigmoid activation func- tion. h t−1 is the hidden state at the last timestep. U and V are learnable parameters. The h t is then passed into a multi-way classifier to produce a probability distribution over the vocabulary (for the next word),</p><formula xml:id="formula_2">p = softmax(W h t + b).</formula><p>The W and b are also trainable parameters. The training objective is to maximize the log- likelihood of the next word, and the parameters are learned by back-propagation algorithm.</p><p>The vanilla recurrent cell can also be re- placed by one or multiple layers of LSTM cells, which produces better results ( <ref type="bibr">Zaremba et al., 2014</ref>). In a more general form, the RNNLM can be represented as a conditional probability, p θ (x t |x 0 , . . . , x t−1 ), parameterized by θ. In the prototypical case, θ = [U, V, W, b]. We could de- fine the LM-score of a sentence x as LM-score(x) log p θ (x) = t log p θ (x t |x 0 , . . . , x t−1 ).</p><p>The RNNLM is trained by maximizing the aver- age LM-score over all the x's in a corpus, or equiv- alently, minimizing the PPL on the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>We motivate and formulate a large margin training criterion in this section. Suppose for every ref- erence sentence x i , we have a collection of hy- potheses x i,j , j = 1, . . . , K, usually obtained as the top-K candidates by a beam search decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A Motivating Example</head><p>An RNNLM trained by minimizing PPL cannot guarantee a higher score on the "gold" reference than the inferior hypothesis, which is undesirable. One example is given in Tab. 1. The reference is taken from the text labels of dev93' set of Wall Street Journal (WSJ) dataset. The hypothesis is generated by a CTC-based ( <ref type="bibr" target="#b2">Graves et al., 2006</ref>) ASR system trained on WSJ training set. Words in red are mistakes made by the hypothesis. We then train an RNNLM on Common Crawl 1 co- pora by minimizing PPL. Training follows a typi- cal setup <ref type="bibr" target="#b5">(Jozefowicz et al., 2016</ref>) with a vocabu- lary of 400K the most frequent words. Any out-of- vocabulary word is replaced by an UNK token. The RNNLM is then employed to score the sen- tences. The LM-score of the erroneous hypothesis is higher than that of the reference. In fact, this is reasonable as "a decade as concerns" seems to be a more common phrase. In the training corpus, we find that "a decade as concerns" appears once, but "its defeat is confirmed" does not appear. More- over, "a decade as" appears 2,280 times, but "its defeat is" appears only 24 times. However, this is undesirable because if there is another hypothesis that happens to be the same as reference, which will not be ranked as the best candidate.</p><p>It would be helpful if the LM can also learn from the imperfect hypotheses so that it can tell Sentence LM-score reference coniston declined to discuss its plans for its defeat is confirmed but indicated that it doesn't plan to simply walk away -116.52 hypothesis coniston declined to discuss its plans for a decade as concerns but indicated that it doesn't plan to simply walk away -112.65  apart "good" and "bad" candidates. With this motivation, we train to assign larger LM-scores for the x i 's but smaller ones for the (imper- fect) x i,j 's. A quantity of particular interest is log p(x i ) − log p(x i,j ), the margin/difference be- tween the LM-scores of the references and the (imperfect) hypotheses. The intuition is that the more positive the margin, the better the LM is at discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Straightforward but Failed Formulation</head><p>Without loss of generality, we assume that all the x i,j 's are imperfect and different from x i . A straightforward way is to adopt the following ob- jective:</p><formula xml:id="formula_3">min θ 1 N N i=1   − log p θ (x i ) + 1 K K j=1 log p θ (x i,j )   .</formula><p>(2) Similar formulation is also seen in ( <ref type="bibr" target="#b21">Tachioka and Watanabe, 2015)</ref>, where they only utilize one beam candidate, i.e., K = 1. Optimization can be carried out by mini-batch stochastic gradient de- scent (SGD). Each iteration, SGD randomly sam- ples a batch of i's and j's, computes stochastic gradient w.r.t. θ, and takes an update step. How- ever, a potential problem with this formulation is that the second term (corresponding to the infe- rior hypotheses) may dominate the optimization. Specifically, the training is almost always driven by the x i,j 's, but does not effectively enhance the discrimination. We illustrate this fact in the fol- lowing experiment.</p><p>Using the ASR system in section 3.1, we extract 256 beam candidates for every training example in Wall Street Journal (WSJ) dataset. Warm started from the pre-trained RNNLM in section 3.1, we apply SGD to minimize the loss in Eq. (2), with a mini-batch size of 128. The training loss is shown in <ref type="figure">Fig. 1a</ref>. We observe that the learning dynamic is very unstable, and deceases to be neg- ative. The unbound decreasing is due to the second term in Eq. (2) being negative and dominating the training process. Next, we inspect log p θ (x i ) − log p θ (x i,j ), the margin between the scores of a ground-truth and a candidate. In <ref type="figure" target="#fig_0">Fig. 2a</ref>, we his- togram the margins for all the i, j's in a dev set. The distribution appears to be symmetric around zero, which indicates poor discrimination ability. Given these facts, we conclude that the straight- forward formulation in Eq. <ref type="formula">(2)</ref> is not effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Large Margin Formulation</head><p>To effectively utilize all the imperfect beam candi- dates, we propose the following objective,</p><formula xml:id="formula_4">min θ N i=1 B j=1 max 0, τ −(log p θ (x i )−log p θ (x i,j )) ,<label>(3)</label></formula><p>where log p θ (x i ) − log θ (x i,j ) is the margin be- tween the scores of a ground-truth x i and a can-didate x i,j . The hinge loss on the margin encour- ages the log-likelihood of the ground-truth to be at least τ larger than that of the imperfect hypothesis. We call an LM trained by the above formulation as Large Margin Language Model (LMLM).</p><p>We repeat the same experiment in section 3.2, but change the objective function to Eq. (3) and set τ = 1. <ref type="figure">Fig. 1b</ref> shows the training loss, which steadily decreases and approaches zero rapidly. Compared with the learning curve of naive formu- lation <ref type="figure">(Fig. 1a)</ref>, the large margin based training is much more stable. In <ref type="figure" target="#fig_0">Fig. 2b</ref>, we also examine the histogram of log p θ (x i ) − log p θ (x i,j ), where p θ (·) is now the LM learned by LMLM. Compared with the histogram by the conventional RNNLM, LMLM significantly moves the distribution to the positive side, indicating more discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ranking Loss Type Formulation</head><p>In most cases, all beam candidates are imperfect. It may be beneficial to exploit the information that some candidates are relatively better than the others. We consider ranking them according to some metrics w.r.t. the ground-truth sentences. For ASR, the metric is WER, and for MT, the metric is BLEU score. We define x i,0 x i and assume that the candidates {x i,j } K j=1 are sorted such that</p><formula xml:id="formula_5">WER(x i , x i,j−1 ) &lt; WER(x i , x i,j )</formula><p>for ASR, and</p><formula xml:id="formula_6">BLEU(x i , x i,j−1 ) &gt; BLEU(x i , x i,j )</formula><p>for MT. In other words, x i,j−1 has better quality than x i,j . We then enforce the "better" sentences to have a score at least τ larger than those "worse" ones. This leads to the following formulation,</p><formula xml:id="formula_7">min θ N i=1 B−1 j=0 B k=j+1 max 0, τ − (log p θ (x i,j ) − log θ (x i,k )), .<label>(4)</label></formula><p>Compared with LMLM formulation Eq. (3), the above introduces more comparisons among the candidates, and hence more computational cost during training. We call this formulation ranking- loss-based LMLM (rLMLM).</p><p>To summarize this section, we have proposed LMLM and rLMLM that aim at discriminating be- tween hypotheses in a task-specific (e.g., WER or BLEU) sense, instead of minimizing PPL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments on ASR</head><p>We apply the LMs trained under different criteria to rescore the beams in various ASR systems. In particular, we are interested in knowing which of the two training mechanisms is better: minimizing PPL (e.g., the RNNLM in Section 3.1), or fitting to the WER metric by the proposed methods.</p><p>Adapting an RNNLM to a specific domain has been of interest, especially to the speech commu- nity ( <ref type="bibr" target="#b14">Park et al., 2010;</ref><ref type="bibr">Chen et al., 2015;</ref><ref type="bibr" target="#b11">Ma et al., 2017</ref>). We adopt <ref type="bibr" target="#b11">Ma et al. (2017)</ref> that fine-tune the softmax layer of RNNLM by minimizing the PPL on the text labels of training set. According to <ref type="bibr" target="#b11">Ma et al. (2017)</ref>, the reason not to fine-tune all the layers is due to the limited text labels in the tar- get domain. Indeed, we also observe overfitting if adapting all layers, but adapting only the softmax layer effectively decreases the PPL on the text la- bels of dev sets. We refer to this fine-tuning as RNNLM-adapted in the following sections.</p><p>To make a fair comparison with the adapted model, we also use the RNNLM as an initializa- tion for our LMLM and rLMLM. In total, there are four language models for rescoring the beams. RNNLM and its adapted version that aim at reduc- ing PPL; and the two proposed methods, LMLM and rLMLM that try to fit to WER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">WSJ Dataset</head><p>The WSJ corpora consists of about 80 hours of read speech with texts drawn from a machine- readable corpus of Wall Street Journal news. We use the standard configuration of train si284 dataset for training, dev93 for development and eval92 for testing.</p><p>Our ASR model has one convolution layer, fol- lowed by 5 bidirectional RNNs and one fully con- nected layer, with a CTC loss on top. The text labels of the training set are used to train a 4-gram language model, which is employed in the ASR decoder. The beam search decoder has a beam width of 2000. Before beam rescoring, this ASR system achieves a WER of 12.16 on dev93 set and 7.69 on eval92 set. To put this into perspective, we list some previous state-of-the-art system in Tab. 2. Compared with them, our baseline is al- ready very competitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">WERs and PPLs</head><p>The out-of-vocabulary rate of WSJ text is only 0.28%, making the RNNLM reasonable to use.</p><p>We apply the RNNLM, RNNLM-adapted ( <ref type="bibr" target="#b11">Ma et al., 2017)</ref>, LMLM and rLMLM to rescore the beams on dev and test set. The final score assigned to a beam is a weighted sum of the ASR and lan- guage model scores. The weight is found by min- imizing the WER on the dev set.</p><p>Tab. 3 reports the WERs on dev93 and eval92 sets. All methods reduce the WER over the baseline without rescoring. However, LMLM and rLMLM are notably better than the other two methods. Moreover, although RNNLM and RNNLM-adapted achieve smaller PPLs on the text labels, the advantage does not transfer to WER.   <ref type="table">Table 3</ref>: Rescore 2000-best list of WSJ dev93 and eval92 set. Digits in bold are the best and ital- ics are the runner-ups. Lower PPL does not corre- spond to lower WER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ASR Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Correlation between scores and WERs</head><p>To better understand the proposed methods, we calculate the correlation coefficients between the hypotheses' WERs and their scores (by different language models). In specific, for every utterance in the test set, we have a set of beam candidates, their word level accuracies (100-WER) and scores given by an LM, from which a Pearson correla- tion coefficient can be calculated. We calculate the coefficients for all the utterances in the test set, and boxplot these coefficients in <ref type="figure" target="#fig_1">Fig. 3</ref>. to be higher than RNNLM and RNNLM-adapted. This indicates that LMLM and rLMLM are more aligned with the goal of reducing WER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Case Study</head><p>Tab. 4 posts some examples from the test set. The first column lists the ground-truth labels, and their corresponding best candidates as re-ranked by the four LMs (see notes in the second column). Words in red are mistakes made by the candidate sen- tences. Scores of these sentences are listed in the last four columns. We have the following observa- tions:</p><p>1. LMLM and rLMLM give worse scores on the ground-truth labels than RNNLM and RNNLM-adapted, which explains their higher PPL in Tab. 3.</p><p>2. In the first example, RNNLM and RNNLM- adapted assign higher scores to a shorter sen- tence. This is reasonable (though not neces- sarily desirable) as LM-score is a summation of log-probabilities, each of which is nega- tive. In contrast, LMLM and rLMLM are able to assign higher scores to longer and bet- ter candidates.</p><p>3. In the other two examples, LMLM and rLMLM seem to favor more sensible sen- tences, though they are not more grammatical than those picked by RNNLM and RNNLM- adapted.  <ref type="table">Table 4</ref>: Some "gold" references and best hypotheses (after rescoring by different language models) for eval92 set. In red are errors or missing word (denoted as ' '). some weakness in the ASR, which is not achieved by RNNLM and RNNLM-adapted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">10K Speech Dataset</head><p>We further validate our methods on a larger noisy dataset collected by <ref type="bibr" target="#b9">Liu et al. (2017)</ref>. The dataset has about 10K hours of spontaneous speech. The utterances are corrupted by background noise, and a large portion of them are accented. Therefore it is much more challenging than WSJ. We adopt the same training-dev-test split as in <ref type="bibr" target="#b9">Liu et al. (2017)</ref>. In specific, there are 5.4M utterances for training, 2,066 for development and 2,054 for testing.  <ref type="table">Table 5</ref>: Rescore 2000-best list of our internal dev and test set. Digits in bold are the best and italics are the runner-ups.</p><p>The ASR we build has the same architecture as in <ref type="bibr" target="#b9">Liu et al. (2017)</ref>, except that its decoder inte- grates an in-domain 5-gram language model. This system achieves a WER of 19.17 on dev set, bet- ter than the reported 19.77 baseline in <ref type="bibr" target="#b9">Liu et al. (2017)</ref>. Based on the ASR, we repeat the same experiments in section 4.1. Tab. 5 reports WERs and PPLs on dev and test sets. Both LMLM and rLMLM outperform the other methods in WER, although their PPLs are higher. This trend is simi- lar to that in Tab. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments on NMT</head><p>In this section, we experiment the large-margin criterion trained LM with a competitive Chinese- to-English NMT system. The NMT model is trained from 2M parallel sentence pairs. Follow- ing <ref type="bibr" target="#b18">Shen et al. (2016)</ref>, we use NIST 06 newswire portion (616 sentences) for development and NIST 08 newswire portion (691 sentences) for testing. We use OpenNMT-py 2 package with the default configuration to train the model: batch size is 64; word embedding size is 500; dropout rate is 0.3; target vocabulary size is 50K; number of epochs is 20, after which a minimum dev perplexity of 7.72 is achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">BLEUs and PPLs</head><p>We use a beam size of 10 for decoding, and re- port case-insensitive 4-reference BLEU-4 scores (by calling "multi bleu.perl" 3 ). The NMT model achieves 35.18 BLEU score on dev set and 31.52 on test set (see <ref type="table" target="#tab_6">table 6</ref>). To put this into per- spective, <ref type="bibr" target="#b18">Shen et al. (2016)</ref> trains their models on 2.56M pairs of sentences and reports a dev BLEU score of 32.7 (via MOSES) or 30.7 (via RNNsearch, beam size of 10). So our NMT model is already very competitive.</p><p>To construct the training data for LMLM and rLMLM, 10 beam candidates are extracted for ev- ery sentence in the training set. We then fol- low the same experimental steps outlined in sec- tion 4.1, except that the ASR score is now changed to NMT score. In addition, we also find that nor- malizing the LM score by sentence length can improve the re-scoring performance substantially. Tab. 6 compares the BLEU score after re-ranking by the different LMs. LMLM and rLMLM both improve upon the baseline significantly, and out- perform RNNLM and RNNLM-adapted by a no- table margin. We also observe that the PPLs of LMLM and rLMLM are much larger than those of RNNLM and RNNLM-adapted, suggesting that the PPL metric may be very poorly correlated with BLEU.</p><p>Interestingly, RNNLM-adapted does not show any gain in BLEU score over RNNLM. To under- stand this, we recall that NMT is trained by min- imizing PPL on target text. Its decoder is implic- itly an RNNLM on target language. We conjecture that adapting an LM to the target domain can only duplicate the functionality of the NMT decoder, which does not bring any additional benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Correlation between scores and BLEUs</head><p>We measure the correlation between the LM scores and BLUEs. The calculation is done on dev06 set in the same way as Section 4.1.2, but now we change the WERs to BLEUs. The box- plot of the correlation coefficients are shown in <ref type="figure" target="#fig_2">Fig. 4</ref>. Compared with the boxplot in <ref type="figure" target="#fig_1">Fig. 3</ref>   and rLMLM, however, is considerably higher than those by RNNLM and RNNLM-adapted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>"Language modeling is an art of determining the probability of a sequence of words" <ref type="bibr" target="#b1">(Goodman, 2001</ref>). In the past decades, there has been a trend of increasing the context that an LM can condition on. N-gram models <ref type="bibr">(Chen and Goodman, 1996)</ref> assume that each symbol depends on the previ- ous N − 1 symbols. Feed forward neural network based LMs ( <ref type="bibr">Bengio et al., 2003)</ref> are not count based but they inherit the restrictive assumption. To model longer-term dependencies, RNNLMs ( <ref type="bibr" target="#b13">Mikolov et al., 2010</ref>) are proposed. RNNLMs of- ten achieve smaller PPLs than the N-gram coun- terparts ( <ref type="bibr" target="#b20">Sundermeyer et al., 2012;</ref><ref type="bibr">Zaremba et al., 2014;</ref><ref type="bibr" target="#b5">Jozefowicz et al., 2016)</ref>. This paper focuses on RNNLM-type architectures.</p><p>While these works all adopt PPL as the metric to optimize, sometimes one may optimize a task- specific objective. For example, <ref type="bibr" target="#b7">Kuo et al. (2002)</ref>; <ref type="bibr" target="#b15">Roark et al. (2007)</ref> and <ref type="bibr">Dikic et al. (2013)</ref> pro- pose discriminative LMs to improve speech recog- nition. The common methodology therein is to fit a probabilistic model, e.g., conditional random field ( <ref type="bibr" target="#b16">Roark et al., 2004</ref>), to the space of text can- didates, and maximize the probability at the de- sired candidate. The problem is often solved by perceptron algorithm. However, these methods all rely on ad-hoc choice of features, e.g., counts of n-grams where n varies in a small range (e.g.,1 to 3). Moreover, it is also not clear how these methods would take advantage of an existing lan- guage model (trained on large unsupervised cor- pus). Nevertheless, the same methodology can be extended to RNNLMs, thus avoiding the afore- mentioned limitations. For example, <ref type="bibr">Auli and Gao (2014)</ref> train an RNNLM by favoring sentences with high BLEU scores and integrate it into a phrase-based MT decoder.</p><p>If we cast the problem of picking the best text sequence as a ranking problem, the aforemen- tioned works can be considered as "pointwise" learning-to-rank approaches <ref type="bibr">(Cossock and Zhang, 2008)</ref>. In contrast, the proposed method is a "pair- wise" approach ( <ref type="bibr" target="#b10">Liu, 2009)</ref>, as it learns a neural language model by comparison between pairs of sentences. Earlier works in this fashion may date back to <ref type="bibr">(Collins and Koo, 2005</ref>), which improves a semantic parser. Learning "by pairwise compari- son" is also seen in several MT literatures. For ex- ample, <ref type="bibr" target="#b4">Hopkins and May (2011)</ref> propose to train a phrase-based MT system by minimizing a pair- wise ranking loss. <ref type="bibr" target="#b22">Wiseman and Rush (2016)</ref> op- timize the beam search process in a Neural Ma- chine Translation (NMT) system. They enforce the score of a reference to be higher than that of its decoded k-th candidate by at least a unit mar- gin.</p><p>Rather than optimizing the MT system itself, this work proposes a general method of training recurrent neural language models, which can ben- efit various text generation tasks, including speech recognition and machine translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 1: Training losses of (a) straightforward formulation Eq. (2); and (b) large margin formulation Eq. (3)</figDesc><graphic url="image-1.png" coords="3,77.46,454.81,98.22,73.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Correlation coefficients between word level accuracy (1 − WER/100) and LM-scores by the different LMs, higher is better. Red horizontal lines are medians. Green dots are means. Whiskers are 5% and 95% quantiles. Lower and upper box boundaries are 25% and 75% quantiles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Correlation coefficients between BLEUs and LM-scores by the different LMs, higher is better. Red horizontal lines are medians. Green dots are means. Whiskers are 5% and 95% quantiles. Lower and upper box boundaries are 25% and 75% quantiles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Reference and one hypothesis, scored by 
an RNNLM. Words in red are mistakes in the hy-
pothesis. The RNNLM is trained on Common 
Crawl copora by minimizing PPL. We want the 
reference to be higher scored than the hypothesis, 
but it does not happen here. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Published WERs on WSJ dev93 and 
eval92 set 

rescoring 
WER 
PPL 
language model dev93 eval92 dev93 eval92 
baseline 
12.16 7.69 N/A 
N/A 
(no rescore) 
RNNLM 
10.71 6.59 207.43 205.00 
RNNLM-adapted 10.11 6.34 159.50 157.85 
LMLM 
9.44 5.56 575.83 563.69 
rLMLM 
9.63 5.48 345.60 348.32 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Rescore 10-best list for dev (nist 06) and 
test (nist 08) set. Digits in bold are the best and 
italics are the runner-ups. 

</table></figure>

			<note place="foot" n="1"> http://web-language-models. s3-website-us-east-1.amazonaws.com/ wmt16/deduped/en-new.xz</note>

			<note place="foot" n="2"> https://github.com/OpenNMT/OpenNMT-py</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have proposed a large margin criterion for training recurrent neural language models. Rather than minimizing PPL, the proposed criterion is based on comparison between pairs of sen-tences. We have formulated two algorithms that implement the training criterion. One com-pares between references and imperfect hypothe-ses (LMLM), the other compares between all pairs of hypotheses (rLMLM). We applied the language models trained by these two algorithms to speech recognition and machine translation. Both of them demonstrate superior performance over their minimum-PPL counterparts. However, the perfor-mance gain from LMLM to rLMLM is small, al-though rLMLM is built on more pairwise compar-isons and requires more training efforts. The ef-ficiency with respect to the number of pairs is a future research topic. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">asr. IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="291" to="300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A bit of progress in language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">T</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="403" to="434" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huei-Chi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.03535</idno>
		<title level="m">On using monolingual corpora in neural machine translation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tuning as ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative training of language models for speech recognition in acoustics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Kwang Jeff</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Fosler-Lussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Hui</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Large-scale discriminative n-gram language models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AMTA</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gram-ctc: Automatic unit selection and target decomposition for sequence labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hairong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to rank for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Approaches for neural-network language model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Nirschl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fadi</forename><surname>Biadsy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajie</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Gowayyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Automatic Speech Recognition and Understanding</title>
		<imprint>
			<publisher>ASRU</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaňjaň</forename><surname>Cernock´ycernock´y</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved neural network based language modelling and adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><forename type="middle">C</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discriminative n-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><surname>Saraclar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="373" to="392" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Discriminative language modeling with conditional random fields and the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><surname>Saraclar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael Collins Mark</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">42</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Annual Meeting on Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Minimum risk training for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongjun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Cold fusion: Training seq2seq models together with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewoo</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.06426</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lstm neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminative method for recurrent neural network language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuuki</forename><surname>Tachioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICASSP</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Sequence-to-sequence learning as beam-search optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In EMNLP</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Automatic Speech Recognition: A Deep Learning Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer Publish-ing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2329</idno>
		<title level="m">Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
