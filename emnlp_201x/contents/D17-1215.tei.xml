<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial Examples for Evaluating Reading Comprehension Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
							<email>robinjia@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
							<email>pliang@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department</orgName>
								<orgName type="department" key="dep2">Computer Science Department</orgName>
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adversarial Examples for Evaluating Reading Comprehension Systems</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2021" to="2031"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities , we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adver-sarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this ad-versarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Quantifying the extent to which a computer sys- tem exhibits intelligent behavior is a longstanding problem in AI <ref type="bibr" target="#b13">(Levesque, 2013)</ref>. Today, the stan- dard paradigm is to measure average error across a held-out test set. However, models can succeed in this paradigm by recognizing patterns that hap- pen to be predictive on most of the test examples, while ignoring deeper, more difficult phenomena ( <ref type="bibr" target="#b26">Rimell et al., 2009;</ref><ref type="bibr" target="#b22">Paperno et al., 2016)</ref>.</p><p>In this work, we propose adversarial evaluation for NLP, in which systems are instead evaluated on adversarially-chosen inputs. We focus on the The BiDAF Ensemble model originally gets the answer correct, but is fooled by the addition of an adversarial distracting sentence (in blue).</p><p>SQuAD reading comprehension task <ref type="bibr" target="#b25">(Rajpurkar et al., 2016)</ref>, in which systems answer questions about paragraphs from Wikipedia. Reading com- prehension is an appealing testbed for adversarial evaluation, as existing models appear successful by standard average-case evaluation metrics: the current state-of-the-art system achieves 84.7% F1 score, while human performance is just 91.2%. 1 Nonetheless, it seems unlikely that existing sys- tems possess true language understanding and rea- soning capabilities.</p><p>Carrying out adversarial evaluation on SQuAD requires new methods that adversarially alter read- ing comprehension examples. Prior work in com- puter vision adds imperceptible adversarial pertur- bations to input images, relying on the fact that such small perturbations cannot change an image's true label ( <ref type="bibr" target="#b30">Szegedy et al., 2014;</ref><ref type="bibr" target="#b9">Goodfellow et al., 2015)</ref>. In contrast, changing even one word of a paragraph can drastically alter its meaning. In- stead of relying on semantics-preserving perturba- tions, we create adversarial examples by adding distracting sentences to the input paragraph, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We automatically generate these sentences so that they confuse models, but do not contradict the correct answer or confuse humans. For our main results, we use a simple set of rules to generate a raw distractor sentence that does not answer the question but looks related; we then fix grammatical errors via crowdsourc- ing. While adversarially perturbed images punish model oversensitivity to imperceptible noise, our adversarial examples target model overstability- the inability of a model to distinguish a sentence that actually answers the question from one that merely has words in common with it.</p><p>Our experiments demonstrate that no published open-source model is robust to the addition of ad- versarial sentences. Across sixteen such models, adding grammatical adversarial sentences reduces F1 score from an average of 75% to 36%. On a smaller set of four models, we run additional experiments in which the adversary adds non- grammatical sequences of English words, causing average F1 score to drop further to 7%. To encour- age the development of new models that under- stand language more precisely, we have released all of our code and data publicly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The SQuAD Task and Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task</head><p>The SQuAD dataset <ref type="bibr" target="#b25">(Rajpurkar et al., 2016</ref>) con- tains 107,785 human-generated reading compre- hension questions about Wikipedia articles. Each question refers to one paragraph of an article, and the corresponding answer is guaranteed to be a span in that paragraph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Models</head><p>When developing and testing our methods, we focused on two published model architectures: BiDAF ( <ref type="bibr" target="#b27">Seo et al., 2016)</ref> and Match-LSTM ( <ref type="bibr" target="#b31">Wang and Jiang, 2016)</ref>. Both are deep learning architec- tures that predict a probability distribution over the correct answer. Each model has a single and an ensemble version, yielding four systems in total.</p><p>We also validate our major findings on twelve other published models with publicly available test-time code: ReasoNet Single and Ensem- ble versions <ref type="bibr" target="#b28">(Shen et al., 2017)</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, Mnemonic</head><p>Reader Single and Ensemble versions ( , Structural Embedding of Dependency Trees (SEDT) Single and Ensemble versions ( <ref type="bibr" target="#b15">Liu et al., 2017</ref>), jNet ( <ref type="bibr" target="#b35">Zhang et al., 2017)</ref>, <ref type="bibr">Ruminating Reader (Gong and Bowman, 2017)</ref>, Multi- Perspective Context Matching (MPCM) Single version ( ), RaSOR ( <ref type="bibr" target="#b12">Lee et al., 2017)</ref>, Dynamic Chunk Reader (DCR) ( <ref type="bibr" target="#b34">Yu et al., 2016)</ref>, and the Logistic Regression Baseline <ref type="bibr" target="#b25">(Rajpurkar et al., 2016</ref>). We did not run these models during development, so they serve as a held-out set that validates the generality of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Standard Evaluation</head><p>Given a model f that takes in paragraph-question pairs (p, q) and outputs an answerâanswerˆanswerâ, the standard accuracy over a test set D test is simply</p><formula xml:id="formula_0">Acc(f ) def = 1 |D test | (p,q,a)∈Dtest v((p, q, a), f ),</formula><p>where v is the F1 score between the true answer a and the predicted answer f (p, q) (see <ref type="bibr" target="#b25">Rajpurkar et al. (2016)</ref> for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Adversarial Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General Framework</head><p>A model that relies on superficial cues without understanding language can do well according to average F1 score, if these cues happen to be predictive most of the time. <ref type="bibr" target="#b33">Weissenborn et al. (2017)</ref> argue that many SQuAD questions can be answered with heuristics based on type and keyword-matching. To determine whether exist- ing models have learned much beyond such simple patterns, we introduce adversaries that confuse de- ficient models by altering test examples. Consider the example in <ref type="figure" target="#fig_0">Figure 1</ref>: the BiDAF Ensemble model originally gives the right answer, but gets confused when an adversarial distracting sentence is added to the paragraph.</p><p>We define an adversary A to be a function that takes in an example (p, q, a), optionally with a model f , and returns a new example (p , q , a ). The adversarial accuracy with respect to A is</p><formula xml:id="formula_1">Adv(f ) def = 1 |D test | (p,q,a)∈Dtest v(A(p, q, a, f ), f )).</formula><p>While standard test error measures the fraction of the test distribution over which the model gets the correct answer, the adversarial accuracy measures the fraction over which the model is robustly cor- rect, even in the face of adversarially-chosen alter- ations. For this quantity to be meaningful, the ad- versary must satisfy two basic requirements: first, it should always generate (p , q , a ) tuples that are valid-a human would judge a as the correct an- swer to q given p . Second, (p , q , a ) should be somehow "close" to the original example (p, q, a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantics-preserving Adversaries</head><p>In image classification, adversarial examples are commonly generated by adding an imperceptible amount of noise to the input ( <ref type="bibr" target="#b30">Szegedy et al., 2014;</ref><ref type="bibr" target="#b9">Goodfellow et al., 2015</ref>). These perturbations do not change the semantics of the image, but they can change the predictions of models that are over- sensitive to semantics-preserving changes. For language, the direct analogue would be to para- phrase the input ( <ref type="bibr" target="#b17">Madnani and Dorr, 2010)</ref>. How- ever, high-precision paraphrase generation is chal- lenging, as most edits to a sentence do actually change its meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Concatenative Adversaries</head><p>Instead of relying on paraphrasing, we use pertur- bations that do alter semantics to build concatena- tive adversaries, which generate examples of the form (p + s, q, a) for some sentence s. In other words, concatenative adversaries add a new sen- tence to the end of the paragraph, and leave the question and answer unchanged. Valid adversarial examples are precisely those for which s does not contradict the correct answer; we refer to such sen- tences as being compatible with (p, q, a). We use semantics-altering perturbations to that ensure that s is compatible, even though it may have many words in common with the question q. Existing models are bad at distinguishing these sentences from sentences that do in fact address the question, indicating that they suffer not from oversensitivity but from overstability to semantics-altering edits. <ref type="table">Table 1</ref> summarizes this important distinction. The decision to always append s to the end of p is somewhat arbitrary; we could also prepend it to the beginning, though this would violate the expectation of the first sentence being a topic sen- tence. Both are more likely to preserve the validity of the example than inserting s in the middle of p, which runs the risk of breaking coreference links. Now, we describe two concrete concatenative adversaries, as well as two variants. ADDSENT, our main adversary, adds grammatical sentences that look similar to the question. In contrast, ADDANY adds arbitrary sequences of English words, giving it more power to confuse models. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates these two main adversaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">ADDSENT</head><p>ADDSENT uses a four-step procedure to generate sentences that look similar to the question, but do not actually contradict the correct answer. Refer to <ref type="figure" target="#fig_1">Figure 2</ref> for an illustration of these steps.</p><p>In Step 1, we apply semantics-altering perturba- tions to the question, in order to guarantee that the resulting adversarial sentence is compatible. We replace nouns and adjectives with antonyms from WordNet <ref type="bibr" target="#b4">(Fellbaum, 1998)</ref>, and change named en- tities and numbers to the nearest word in GloVe word vector space 2 ( <ref type="bibr" target="#b24">Pennington et al., 2014</ref>) with the same part of speech. 3 If no words are changed during this step, the adversary gives up and im- mediately returns the original example. For exam- ple, given the question "What ABC division han- dles domestic television distribution?", we would change "ABC" to "NBC" (a nearby word in vec- tor space) and "domestic" to "foreign" (a WordNet antonym), resulting in the question, "What NBC division handles foreign television distribution?"</p><p>In Step 2, we create a fake answer that has the same "type" as the original answer. We define a set  of 26 types, corresponding to NER and POS tags from Stanford CoreNLP ( , plus a few custom categories (e.g., abbreviations), and manually associate a fake answer with each type. Given the original answer to a question, we compute its type and return the corresponding fake answer. In our running example, the correct an- swer was not tagged as a named entity, and has the POS tag NNP, which corresponds to the fake answer "Central Park."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Article: Nikola Tesla Paragraph: "In January 1880, two of Tesla's uncles put together enough money to help him leave Gospić for Prague where he was to study. Unfortunately, he arrived too late to enroll at Charles-Ferdinand University; he never studied Greek, a required subject; and he was illiterate in Czech, another required subject. Tesla did, however, attend lectures at the university, although, as an auditor, he did not receive grades for the courses." Question: "What city did Tesla move to in 1880?" Answer: Prague</head><p>In Step 3, we combine the altered question and fake answer into declarative form, using a set of roughly 50 manually-defined rules over CoreNLP constituency parses. For example, "What ABC di- vision handles domestic television distribution?" triggers a rule that converts questions of the form "what/which NP 1 VP 1 ?" to "The NP 1 of [Answer] VP 1 ". After incorporating the alter- ations and fake answer from the previous steps, we generate the sentence, "The NBC division of Cen- tral Park handles foreign television distribution."</p><p>The raw sentences generated by Step 3 can be ungrammatical or otherwise unnatural due to the incompleteness of our rules and errors in con- stituency parsing. Therefore, in Step 4, we fix er- rors in these sentences via crowdsourcing. Each sentence is edited independently by five workers on Amazon Mechanical Turk, resulting in up to five sentences for each raw sentence. Three addi- tional crowdworkers then filter out sentences that are ungrammatical or incompatible, resulting in a smaller (possibly empty) set of human-approved sentences. The full ADDSENT adversary runs the model f as a black box on every human-approved sentence, and picks the one that makes the model give the worst answer. If there are no human- approved sentences, the adversary simply returns the original example.</p><p>A model-independent adversary. ADDSENT requires a small number of queries to the model under evaluation. To explore the possibility of an adversary that is completely model-independent, we also introduce ADDONESENT, which adds a random human-approved sentence to the para- graph. In contrast with prior work in computer vision ( <ref type="bibr" target="#b23">Papernot et al., 2017;</ref><ref type="bibr" target="#b21">Narodytska and Kasiviswanathan, 2016;</ref><ref type="bibr" target="#b20">Moosavi-Dezfooli et al., 2017</ref>), ADDONESENT does not require any access to the model or to any training data: it generates adversarial examples based solely on the intuition that existing models are overly stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">ADDANY</head><p>For ADDANY, the goal is to choose any sequence of d words, regardless of grammaticality. We use local search to adversarially choose a distracting sentence s = w 1 w 2 . . . w d . <ref type="figure" target="#fig_1">Figure 2</ref> shows an example of ADDANY with d = 5 words; in our experiments, we use d = 10.</p><p>We first initialize words w 1 , . . . , w d randomly from a list of common English words. <ref type="bibr">4</ref> Then, we run 6 epochs of local search, each of which iterates over the indices i ∈ {1, . . . , d} in a random order.</p><note type="other">For each i, we randomly generate a set of candi- date words W as the union of 20 randomly sam- pled common words and all words in q. For each x ∈ W , we generate the sentence with x in the i-th position and w j in the j-th position for each j = i. We try adding each sentence to the paragraph and query the model for its predicted probability distri- bution over answers. We update w i to be the x that minimizes the expected value of the F1 score over the model's output distribution. We return imme- diately if the model's argmax prediction has 0 F1 score. If we do not stop after 3 epochs, we ran- domly initialize 4 additional word sequences, and search over all of these random initializations in parallel.</note><p>ADDANY requires significantly more model ac- cess than ADDSENT: not only does it query the model many times during the search process, but it also assumes that the model returns a probabil- ity distribution over answers, instead of just a sin- gle prediction. Without this assumption, we would have to rely on something like the F1 score of the argmax prediction, which is piecewise constant and therefore harder to optimize. "Probabilistic" query access is still weaker than access to gradi- ents, as is common in computer vision ( <ref type="bibr" target="#b30">Szegedy et al., 2014;</ref><ref type="bibr" target="#b9">Goodfellow et al., 2015</ref>).</p><p>We do not do anything to ensure that the sen- tences generated by this search procedure do not contradict the original answer. In practice, the generated "sentences" are gibberish that use many question words but have no semantic content (see <ref type="figure" target="#fig_1">Figure 2</ref> for an example).</p><p>Finally, we note that both ADDSENT and ADDANY try to incorporate words from the ques- tion into their adversarial sentences. While this is an obvious way to draw the model's attention, we were curious if we could also distract the model without such a straightforward approach. To this end, we introduce a variant of ADDANY called ADDCOMMON, which is exactly like ADDANY except it only adds common words.   </p><note type="other">Match Match BiDAF BiDAF Single Ens. Single Ens. Original 71.4 75.4 75.5 80.0 ADDSENT 27.3 29.4 34.</note><note type="other">ADDSENT ADDONESENT ReasoNet-E 81.1 39.4 49.8 SEDT-E 80.1 35.0 46.5 BiDAF-E 80.0 34.2 46.9 Mnemonic-E 79.1 46.2 55.3 Ruminating 78.8 37.4 47.7 jNet 78.6 37.9 47.0 Mnemonic-S 78.5 46.6 56.0 ReasoNet-S 78.2 39.4 50.3 MPCM-S 77.0 40.3 50.0 SEDT-S 76.9 33.9 44.8 RaSOR 76.2 39.5 49.5 BiDAF-S 75.5 34.3 45.7 Match-E 75.4 29.4 41.8 Match-S 71.4 27.3 39.0 DCR 69.3 37.8 45.1 Logistic 50.4 23.2 30.4</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>For all experiments, we measure adversarial F1 score ( <ref type="bibr" target="#b25">Rajpurkar et al., 2016</ref>) across 1000 ran- domly sampled examples from the SQuAD devel- opment set (the test set is not publicly available). Downsampling was helpful because ADDANY and ADDCOMMON can issue thousands of model queries per example, making them very slow. As the effect sizes we measure are large, this down- sampling does not hurt statistical significance.  age F1 score to fall to 46.1%, despite only adding common words. We also verified that our adversaries were gen- eral enough to fool models that we did not use dur- ing development. We ran ADDSENT on twelve published models for which we found publicly available test-time code; we did not run ADDANY on these models, as not all models exposed out- put distributions. As seen in <ref type="table" target="#tab_4">Table 3</ref>, no model was robust to adversarial evaluation; across the sixteen total models tested, average F1 score fell from 75.4% to 36.4% under ADDSENT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Experiments</head><p>It is noteworthy that the Mnemonic Reader models ( ) outperform the other models by about 6 F1 points. We hypothesize that Mnemonic Reader's self-alignment layer, which helps model long-distance relationships between parts of the paragraph, makes it better at locating all pieces of evidence that support the correct an- swer. Therefore, it can be more confident in the correct answer, compared to the fake answer in- serted by the adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Human Evaluation</head><p>To ensure our results are valid, we verified that humans are not also fooled by our adversarial ex- amples. As ADDANY requires too many model queries to run against humans, we focused on ADDSENT. We presented each original and ad- versarial paragraph-question pair to three crowd- workers, and asked them to select the correct an- swer by copy-and-pasting from the paragraph. We then took a majority vote over the three responses (if all three responses were different, we picked one at random). These results are shown in Ta- ble 4. On original examples, our humans are actually slightly better than the reported number of 91.2 F1 on the entire development set. On ADDSENT, human accuracy drops by 13.1 F1 points, much less than the computer systems.</p><p>Moreover, much of this decrease can be ex- plained by mistakes unrelated to our adversarial sentences. Recall that ADDSENT picks the worst case over up to five different paragraph-question pairs. Even if we showed the same original exam- ple to five sets of three crowdworkers, chances are that at least one of the five groups would make a mistake, just because humans naturally err. There- fore, it is more meaningful to evaluate humans on ADDONESENT, on which their accuracy drops by only 3.4 F1 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis</head><p>Next, we sought to better understand the behavior of our four main models under adversarial evalua- tion. To highlight errors caused by the adversary, we focused on examples where the model origi- nally predicted the (exact) correct answer. We di- vided this set into "model successes"-examples where the model continued being correct during adversarial evaluation-and "model failures"- examples where the model gave a wrong answer during adversarial evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Manual verification</head><p>First, we verified that the sentences added by ADDSENT are actually grammatical and compat- ible. We manually checked 100 randomly cho- sen BiDAF Ensemble failures. We found only one where the sentence could be interpreted as an- swering the question: in this case, ADDSENT re- placed the word "Muslim" with the related word "Islamic", so the resulting adversarial sentence still contradicted the correct answer. Addition- ally, we found 7 minor grammar errors, such as subject-verb disagreement (e.g., "The Alaskan Archipelago are made up almost entirely of ham- sters.") and misuse of function words (e.g., "The gas of nitrogen makes up 21.8 % of the Mars's at- mosphere."), but no errors that materially impeded understanding of the sentence.</p><p>We also verified compatibility for ADDANY. We found no violations out of 100 randomly cho- sen BiDAF Ensemble failures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Error analysis</head><p>Next, we wanted to understand what types of er- rors the models made on the ADDSENT examples. In 96.6% of model failures, the model predicted a span in the adversarial sentence. The lengths of the predicted answers were mostly similar to those of correct answers, but the BiDAF models occa- sionally predicted very long spans. The BiDAF Single model predicted an answer of more than 29 words-the length of the longest answer in the SQuAD development set-on 5.0% of model fail- ures; for BiDAF Ensemble, this number was 1.6%.</p><p>Since the BiDAF models independently predict the start and end positions of the answer, they can predict very long spans when the end pointer is in- fluenced by the adversarial sentence, but the start pointer is not. Match-LSTM has a similar struc- ture, but also has a hard-coded rule that stops it from predicting very long answers.</p><p>We also analyzed human failures-examples where the humans were correct originally, but wrong during adversarial evaluation. Humans predicted from the adversarial sentence on only 27.3% of these error cases, which confirms that many errors are normal mistakes unrelated to ad- versarial sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Categorizing ADDSENT sentences</head><p>We then manually examined sentences generated by ADDSENT. In 100 BiDAF Ensemble fail- ures, we found 75 cases where an entity name was changed in the adversarial sentence, 17 cases where numbers or dates were changed, and 33 cases where an antonym of a question word was used. 5 Additionally, 7 sentences had other mis- cellaneous perturbations made by crowdworkers during Step 4 of ADDSENT. For example, on a question about the "Kalven Report", the adver- sarial sentence discussed "The statement Kalven cited" instead; in another case, the question, "How does Kenya curb corruption?" was met by the unhelpful sentence, "Tanzania is curbing corrup- tion" (the model simply answered, "corruption").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4">Reasons for model successes</head><p>Finally, we sought to understand the factors that influence whether the model will be robust to ad- versarial perturbations on a particular example. First, we found that models do well when the ques- tion has an exact n-gram match with the original paragraph. <ref type="figure" target="#fig_2">Figure 3</ref> plots the fraction of exam- ples for which an n-gram in the question appears verbatim in the original passage; this is much higher for model successes. For example, 41.5% of BiDAF Ensemble successes had a 4-gram in common with the original paragraph, compared to only 21.0% of model failures.</p><p>We also found that models succeeded more of- ten on short questions. <ref type="figure" target="#fig_3">Figure 4</ref> shows the dis- For each model and each value of n, successes are more likely to have an n-gram match than failures.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Transferability across Models</head><p>In computer vision, adversarial examples that fool one model also tend to fool other models ( <ref type="bibr" target="#b30">Szegedy et al., 2014;</ref><ref type="bibr" target="#b20">Moosavi-Dezfooli et al., 2017)</ref>; we investigate whether the same pattern holds for us. Examples from ADDONESENT clearly do transfer across models, since ADDONESENT always adds the same adversarial sentence regardless of model. <ref type="table" target="#tab_8">Table 5</ref> shows the results of evaluating the four main models on adversarial examples gen- erated by running either ADDSENT or ADDANY against each model. ADDSENT adversarial ex- amples transfer between models quite effectively; in particular, they are harder than ADDONESENT examples, which implies that examples that fool one model are more likely to fool other mod- els. The ADDANY adversarial examples exhibited more limited transferability between models. For both ADDSENT and ADDANY, examples trans- ferred slightly better between single and ensemble versions of the same model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Training on Adversarial Examples</head><p>Finally, we tried training on adversarial examples, to see if existing models can learn to become more robust. Due to the prohibitive cost of running ADDSENT or ADDANY on the entire training set, we instead ran only Steps 1-3 of ADDSENT (ev- erything except crowdsourcing) to generate a raw adversarial sentence for each training example. We then trained the BiDAF model from scratch on  the union of these examples and the original train- ing data. As a control, we also trained a second BiDAF model on the original training data alone. <ref type="bibr">6</ref> The results of evaluating these models are shown in <ref type="table" target="#tab_10">Table 6</ref>. At first glance, training on ad- versarial data seems effective, as it largely protects against ADDSENT. However, further investigation shows that training on these examples has only limited utility. To demonstrate this, we created a variant of ADDSENT called ADDSENTMOD, which differs from ADDSENT in two ways: it uses a different set of fake answers (e.g., PERSON named entities map to "Charles Babbage" instead of "Jeff Dean"), and it prepends the adversarial sentence to the beginning of the paragraph in- stead of appending it to the end. The retrained model does almost as badly as the original one on ADDSENTMOD, suggesting that it has just learned to ignore the last sentence and reject the fake an- swers that ADDSENT usually proposed. In order for training on adversarial examples to actually improve the model, more care must be taken to ensure that the model cannot overfit the adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Related Work</head><p>Despite appearing successful by standard evalu- ation metrics, existing machine learning systems for reading comprehension perform poorly un- der adversarial evaluation. Standard evaluation is overly lenient on models that rely on superficial cues. In contrast, adversarial evaluation reveals that existing models are overly stable to perturba- tions that alter semantics.</p><p>To optimize adversarial evaluation metrics, we may need new strategies for training models. For certain classes of models and adversaries, efficient training strategies exist: for example, <ref type="bibr" target="#b6">Globerson and Roweis (2006)</ref> train classifiers that are opti- mally robust to adversarial feature deletion. Ad-versarial training <ref type="bibr" target="#b9">(Goodfellow et al., 2015)</ref> can be used for any model trained with stochastic gra- dient descent, but it requires generating new ad- versarial examples at every iteration; this is fea- sible for images, where fast gradient-based adver- saries exist, but is infeasible for domains where only slower adversaries are available.</p><p>We contrast adversarial evaluation, as studied in this work, with generative adversarial models. While related in name, the two have very different goals. Generative adversarial models pit a gen- erative model, whose goal is to generate realis- tic outputs, against a discriminative model, whose goal is to distinguish the generator's outputs from real data <ref type="bibr" target="#b29">(Smith, 2012;</ref>). <ref type="bibr">Bowman et al. (2016)</ref> and <ref type="bibr" target="#b14">Li et al. (2017)</ref> used such a setup for sentence and dialogue generation, respectively. Our setup also involves a genera- tor and a discriminator in an adversarial relation- ship; however, our discriminative system is tasked with finding the right answer, not distinguishing the generated examples from real ones, and our goal is to evaluate the discriminative system, not to train the generative one.</p><p>While we use adversaries as a way to evalu- ate language understanding, robustness to adver- sarial attacks may also be its own goal for tasks such as spam detection. <ref type="bibr" target="#b3">Dalvi et al. (2004)</ref> formu- lated such tasks as a game between a classifier and an adversary, and analyzed optimal strategies for each player. <ref type="bibr" target="#b16">Lowd and Meek (2005)</ref> described an efficient attack by which an adversary can reverse- engineer the weights of a linear classifier, in or- der to then generate adversarial inputs. In contrast with these methods, we do not make strong struc- tural assumptions about our classifiers.</p><p>Other work has proposed harder test datasets for various tasks. <ref type="bibr" target="#b13">Levesque (2013)</ref> proposed the Winograd Schema challenge, in which comput- ers must resolve coreference resolution problems that were handcrafted to require extensive world knowledge. <ref type="bibr" target="#b22">Paperno et al. (2016)</ref> constructed the LAMBADA dataset, which tests the ability of lan- guage models to handle long-range dependencies. Their method relies on the availability of a large initial dataset, from which they distill a difficult subset; such initial data may be unavailable for many tasks. <ref type="bibr" target="#b26">Rimell et al. (2009)</ref> showed that de- pendency parsers that seem very accurate by stan- dard metrics perform poorly on a subset of the test data that has unbounded dependency construc- tions. Such evaluation schemes can only test mod- els on phenomena that are moderately frequent in the test distribution; by perturbing test examples, we can introduce out-of-distribution phenomena while still leveraging prior data collection efforts.</p><p>While concatenative adversaries are well-suited to reading comprehension, other adversarial meth- ods may prove more effective on other tasks. As discussed previously, paraphrase generation sys- tems ( <ref type="bibr" target="#b17">Madnani and Dorr, 2010)</ref> could be used for adversarial evaluation on a wide range of language tasks. Building on our intuition that existing mod- els are overly stable, we could apply meaning- altering perturbations to inputs on tasks like ma- chine translation, and adversarially choose ones for which the model's output does not change. We could also adversarially generate new examples by combining multiple existing ones, in the spirit of Data Recombination <ref type="bibr" target="#b11">(Jia and Liang, 2016)</ref>. The Build It, Break It shared task <ref type="bibr" target="#b0">(Bender et al., 2017</ref>) encourages researchers to adversarially de- sign minimal pairs to fool sentiment analysis and semantic role labeling systems.</p><p>Progress on building systems that truly under- stand language is only possible if our evaluation metrics can distinguish real intelligent behavior from shallow pattern matching. To this end, we have released scripts to run ADDSENT on any SQuAD system, as well as code for ADDANY. We hope that our work will motivate the development of more sophisticated models that understand lan- guage at a deeper level.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example from the SQuAD dataset. The BiDAF Ensemble model originally gets the answer correct, but is fooled by the addition of an adversarial distracting sentence (in blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An illustration of the ADDSENT and ADDANY adversaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>nFigure 3 :</head><label>3</label><figDesc>Figure 3: Fraction of model successes and failures on ADDSENT for which the question has an exact n-gram match with the original paragraph. For each model and each value of n, successes are more likely to have an n-gram match than failures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: For model successes and failures on ADDSENT, the cumulative distribution function of the number of words in the question (for each k, what fraction of questions have ≤ k words). Successes are more likely to involve short questions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>income other reached Adversary Adds: tesla move move other george Model Predicts: george Repeat many times Randomly initialize d words:</head><label></label><figDesc></figDesc><table>Model Predicts: Prague 

Tadakatsu moved the city of 
Chicago to in 1881. 

Chicago 

What city did Tesla move to 
in 1880? 

What city did Tadakatsu move to 
in 1881? 

Prague 

Adversary Adds: Tadakatsu moved to the city 
of Chicago in 1881. 
Model Predicts: Chicago 

(Step 1) 
Mutate 
question 

(Step 3) 
Convert into 
statement 

(Step 4) 
Fix errors with 
crowdworkers, 
verify resulting 
sentences with 
other crowdworkers 

AddSent 

spring attention income getting reached 

spring attention AddAny 

Greedily change one word 

(Step 2) 
Generate 
fake answer 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Adversarial evaluation on the Match-
LSTM and BiDAF systems. All four systems can 
be fooled by adversarial examples. 

Model 
Original </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>ADDSENT and ADDONESENT on all six-
teen models, sorted by F1 score the original exam-
ples. S = single, E = ensemble. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 2 shows</head><label>2</label><figDesc></figDesc><table>the performance of the Match-
LSTM and BiDAF models against all four adver-
saries. Each model incurred a significant accu-
racy drop under every form of adversarial evalua-
tion. ADDSENT made average F1 score across the 
four models fall from 75.7% to 31.3%. ADDANY 
was even more effective, making average F1 score 
fall to 6.7%. ADDONESENT retained much of the 
effectiveness of ADDSENT, despite being model-
independent. Finally, ADDCOMMON caused aver-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Human evaulation on adversarial exam-
ples. Human accuracy drops on ADDSENT mostly 
due to unrelated errors; the ADDONESENT num-
bers show that humans are robust to adversarial 
sentences. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Transferability of adversarial examples 
across models. Each row measures performance 
on adversarial examples generated to target one 
particular model; each column evaluates one (pos-
sibly different) model on these examples. 

tribution of question length on model successes 
and failures; successes tend to involve shorter 
questions. For example, 32.7% of the questions 
in BiDAF Ensemble successes were 8 words or 
shorter, compared to only 11.8% for model fail-
ures. This effect arises because ADDSENT always 
changes at least one word in the question. For 
long questions, changing one word leaves many 
others unchanged, so the adversarial sentence still 
has many words in common with the question. For 
short questions, changing one content word may 
be enough to make the adversarial sentence com-
pletely irrelevant. 

2027 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Effect of training the BiDAF Single 
model on the original training data alone (first 
column) versus augmenting the data with raw 
ADDSENT examples (second column). 

</table></figure>

			<note place="foot" n="1"> https://rajpurkar.github.io/ SQuAD-explorer/</note>

			<note place="foot" n="2"> We use 100-dimensional GloVe vectors trained on Wikipedia and Euclidean distance to define nearby words. 3 We choose the nearest word whose most common gold POS tag in the Penn Treebank (Marcus et al., 1999) matches the predicted POS tag of the original word, according to CoreNLP. If none of the nearest 100 words satisfy this, we just return the single closest word.</note>

			<note place="foot" n="4"> We define common words as the 1000 most frequent words in the Brown corpus (Francis and Kucera, 1979).</note>

			<note place="foot" n="5"> These numbers add up to more than 100 because more than one word can be altered per example.</note>

			<note place="foot" n="6"> All previous experiments used parameters released by Seo et al. (2016)</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Build it, break it: The language edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rothschild</surname></persName>
		</author>
		<ptr target="https://bibinlp.umiacs.umd.edu/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2029</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adversarial classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mausam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sanghai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">N</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kucera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Brown Corpus Manual</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nightmare at test time: robust learning by feature deletion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="353" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Ruminating reader: Reasoning with gated multi-hop attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Mnemonic reader for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning recurrent span representations for extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On our best behaviour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06547</idno>
		<title level="m">Adversarial learning for neural dialogue generation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Structural embedding of syntactic trees for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nyberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generating phrasal and sentential paraphrases: A survey of data-driven methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="387" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The stanford coreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL system demonstrations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
<note type="report_type">Treebank-3</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universal adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Narodytska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Kasiviswanathan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.06299</idno>
		<title level="m">Simple black-box adversarial perturbations for deep networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The LAMBADA dataset: Word prediction requiring a broad discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">N</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pezzelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fernandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Practical black-box attacks against deep learning systems using adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Celik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Asia Conference on Computer and Communications Security</title>
		<meeting>the ACM Asia Conference on Computer and Communications Security</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unbounded dependency recovery for parser evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rimell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>arXiv</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reasonet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adversarial evaluation for models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0245</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<title level="m">Machine comprehension using match-LSTM and answer pointer</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Multi-perspective context matching for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seiffe</surname></persName>
		</author>
		<title level="m">Making neural qa as simple as possible but not simpler. arXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">End-to-end answer chunk extraction and ranking for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Exploring question understanding and adaptation in neural-network-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>arXiv</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
