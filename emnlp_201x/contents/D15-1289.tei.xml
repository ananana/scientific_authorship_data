<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T11:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ERSOM: A Structural Ontology Matching Approach Using Automatically Learned Entity Representation 1 Introductions</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuncheng</forename><surname>Xiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingsong</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ministry of Education School of Electronics Engineering and Computer Science</orgName>
								<orgName type="laboratory">Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University Collaborative Innovation Center for Language Ability</orgName>
								<address>
									<postCode>221009</postCode>
									<settlement>Xuzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ERSOM: A Structural Ontology Matching Approach Using Automatically Learned Entity Representation 1 Introductions</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As a key representation model of knowledge , ontology has been widely used in a lot of NLP related tasks, such as semantic parsing, information extraction and text mining etc. In this paper, we study the task of ontology matching, which concentrates on finding semantically related entities between different ontologies that describe the same domain, to solve the semantic heterogeneity problem. Previous works exploit different kinds of descriptions of an entity in ontology directly and separately to find the correspondences without considering the higher level correlations between the descriptions. Besides, the structural information of ontology haven&apos;t been utilized adequately for ontology matching. We propose in this paper an ontology matching approach, named ERSOM, which mainly includes an unsupervised representation learning method based on the deep neural networks to learn the general representation of the entities and an iterative similarity propagation method that takes advantage of more abundant structure information of the ontology to discover more mappings. The experimental results on the datasets from Ontology Alignment Evaluation Initiative (OAEI 1) show that ER-SOM achieves a competitive performance compared to the state-of-the-art ontology matching systems. 1 The OAEI is an international initiative organizing annual campaigns for evaluating ontology matching systems. All of the ontologies provided by OAEI are described in OWL-DL language, and like most of the other participates our ERSOM also manages the OWL ontology in its current version. OAEI:</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introductions</head><p>In the recent years, it becomes evident that one of the most important directions of improvement in natural language processing (NLP) tasks, like word sense disambiguation, coreference resolu- tion, relation extraction, and other tasks related to knowledge extraction, is by exploiting seman- tics resources ( <ref type="bibr" target="#b4">Bryl et al., 2010)</ref>. Nowadays, the Semantic Web made available a large amount of logically encoded information (e.g. ontologies, RDF(S)-data, linked data, etc.), which constitutes a valuable source of semantics. However, extend- ing the state-of-the-art natural language applica- tions to use these resources is not a trivial task mainly due to the heterogeneity and the ambiguity of the schemes adopted by the different resources of the Semantic Web. How to utilize these re- sources in NLP tasks comprehensively rather than choose just one of them has attracted much atten- tion in recent years.</p><p>An effective solution to the ontology hetero- geneity problem is ontology matching <ref type="bibr" target="#b11">(Euzenat et al., 2007;</ref><ref type="bibr" target="#b31">Shvaiko and Euzenat, 2013)</ref>, whose main task is to establish semantic correspondences between entities (i.e., classes, properties or in- stances) from different ontologies.</p><p>Ontology matching is usually done by measur- ing the similarity between two entities from two different ontologies. To effectively calculate the similarities, almost all types of descriptions of an entity should be used. In previous works, given the different nature of different kinds of descriptions, similarities are normally measured separately with different methods and then aggregated with some kind of combination strategy to compute the final similarity score. For example, <ref type="bibr" target="#b25">Mao et al. (2010)</ref> defined three single similarities (i.e., Name simi- larity, Profile similarity and Structural similarity) based on the descriptions of an entity, then they employed a harmony-based method to aggregate the single similarities to get a final similarity for extracting the final mappings. However, treating different kinds of descriptions of an entity sepa- rately suffers from two limitations. First, it lim- its the capacity of modeling the interactions be- tween different descriptions. For example, entity's label is always a specific substitution of its ID; en- tity's comment is a semantic definition for its ID; a class can be characterized with its related prop- erties, and a property is usually restricted by its domain and range. These potential correlations of the descriptions are very important to measure the similarity between entities since they can be treat- ed as some potential features describing an entity. Second, it is difficult to estimate how many and which kind of single similarities are needed for an aggregation method to get a satisfactory result.</p><p>On the other hand, in order to find more map- pings, many structural ontology matching meth- ods are proposed. To the best of our knowledge, previous structural methods are either local meth- ods ( <ref type="bibr" target="#b21">Le et al., 2004;</ref><ref type="bibr" target="#b33">Sunna and Cruz, 2007)</ref> or global (i.e. iterative) methods but only use part of the structure information of the ontology ( <ref type="bibr" target="#b22">Li et al., 2009;</ref><ref type="bibr" target="#b28">Ngo and Bellahsene, 2012</ref>). For ex- ample, the ontology matching system YAM++ (N- go and Bellahsene, 2012) utilizes a global struc- tural method but it only uses the structure informa- tion of classes and properties to create the propa- gation graph to find mappings between classes and properties. A large amount of instances and their relations to classes and properties in the ontology haven't been exploited in this system.</p><p>To overcome the existing limitations, we pro- pose in this paper a representation learning method to capture the interactions among entity's descrip- tions; then we present our global structural method which exploits more abundant structure informa- tion of the ontology. We summarize our contribu- tions as follows.</p><p>• We propose to use the deep neural network model to learn the high-level abstract repre- sentations of classes and properties from their descriptions to acquire the potential corre- lations for the computing of the similarities between classes and properties. Moreover, there is no need to select and aggregate differ- ent single similarities in the similarity com- putation.</p><p>• We propose a global similarity propagation method that utilizes more abundant structure information including all kinds of entities and their relations in the ontology, to find more mappings.</p><p>To evaluate the effectiveness of our approach, we conduct experiments on the public datasets from OAEI campaign (We select the OAEI data sets mainly because evaluation metrics have been well defined on these data sets and comparision can be easily made). The experimental result- s show that our matching approach can achieve a competitive matching performance compared to the state-of-the-art systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Statement</head><p>Ontology is a formal, explicit specification of a shared conceptualization in terms of classes, prop- erties and relations <ref type="bibr" target="#b12">(Euzenat et al., 2004</ref>). The pro- cess of ontology matching is to find mappings (or correspondences) between entities (classes, prop- erties or individuals) from two ontologies. A map- ping is defined as a four-tuple as written in Eq. <ref type="formula" target="#formula_0">(1)</ref>, where e 1 and e 2 represent the entity in ontology O 1 and O 2 respectively, r is a kind of matching relation (e.g., equivalent, subsume) and k → <ref type="bibr">[0,</ref><ref type="bibr">1]</ref> is the degree of confidence of matching relation between e 1 and e 2 ( <ref type="bibr" target="#b25">Mao et al., 2010)</ref>.</p><formula xml:id="formula_0">m =&lt; e 1 , e 2 , r, k &gt;<label>(1)</label></formula><p>Similar with most of the OAEI systems ( <ref type="bibr" target="#b22">Li et al., 2009;</ref><ref type="bibr" target="#b28">Ngo and Bellahsene, 2012;</ref><ref type="bibr" target="#b6">Cheatham and Hitzler, 2013b)</ref>, we focus on discovering only e- quivalent mappings between classes and proper- ties with cardinality 1:1. That is, one class (prop- erty) in ontology O 1 can be matched to at most one class (property) in ontology O 2 and vise versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ERSOM: Entity Representation and Structure based Ontology Matching</head><p>In this paper, we propose a structural ontology matching approach using automatically learned entity representation, which we call ERSOM. <ref type="figure">Fig.1</ref> shows the architecture of our approach. The details of its major modules are given in the fol- lowing sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning the representation of entity</head><p>In this section, we present how to learn the high- level abstract representations for ontology entities. The motivations are: 1) we regard different kinds of the descriptions of an entity as a whole to avoid <ref type="figure">Figure 1</ref>: The architecture of ERSOM. Given the two to-be-matched ontologies, we first extract the descriptive information for each entity, then learn the entity's abstract representation based on its de- scriptions, and finally utilize the representations to compute the similarities between entities to initial- ize the similarity propagation method to find final mappings.</p><p>separatively calculating the similarities and aggre- gating them later with a combination method; 2) the learned representation can not only express the meaning of the original descriptions of an entity but also captures the interactions among different descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Creating term vector for entity</head><p>We first generate a combination of the entity's de- scriptions (CDs for short) and then create a term vector for each entity. In particular, the CDs of a class = the class's ID + label + comments + it- s properties' descriptions + its instances' descrip- tions. The CDs of a property = the property's ID + label + its domain + its range (or its textual val- ue when the property is a datatype property). And the CDs of an instance = the instance's ID + la- bel + its properties' values. A binary term vector is created for each entity with the pre-processing that consists of tokenizing, removing stop words, stemming and deleting superfluous words. In the binary term vectors, element 1 and 0 refer to the existence and inexistence of a specific word, re- spectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Learning entity representations</head><p>In the ontology matching area, training data usual- ly refers to a pair of ontologies with correct map- pings created by domain experts between their en- tities. The acquisition of such dataset is time- consuming and laborious. We state in this sec- tion how to learn the abstract representations for entities from their binary term vectors with an un- supervised way. The deep neural network (DNN) ( <ref type="bibr">Hinton et al., 2006;</ref><ref type="bibr" target="#b2">Bengio et al., 2007</ref>) is a multi- layer learning model. It is mainly used for learning the high-level abstract representations of original input data. Given the generalization and the ab- straction introduced in the representation learning procedure, DNN allows us to better model the in- teractions among different kinds of input features, and measure the similarity at a more general lev- el. Inspired by the work in <ref type="bibr" target="#b16">(Hinton, 2007;</ref><ref type="bibr" target="#b1">Bengio et al., 2012;</ref><ref type="bibr" target="#b15">He et al., 2013;</ref><ref type="bibr" target="#b9">Cui et al., 2014</ref>), we use auto-encoder ( <ref type="bibr" target="#b3">Bourlard and Kamp, 1988;</ref><ref type="bibr" target="#b17">Hinton and Zemel, 1994)</ref> to learn the representations for classes and properties. The auto-encoder is one of the neural network variants that can automati- cally discover interesting abstractions to represent an unlabeled dataset. As shown in <ref type="figure" target="#fig_0">Fig.2</ref>, the input to the auto-encoder is denoted as x, which indicates a binary term vec- tor of a class or a property. Auto-encoder tries to learn an approximation to the identity function h(x), so as to output</p><p>x that is similar to x. More specifically, the auto-encoder consists of an encod- ing process h(</p><formula xml:id="formula_1">x) = f (W x + b 1 ) and a decod- ing process g(h(x)) = f (W T h(x) + b 2 ),</formula><p>where f is a activation function like the sigmoid func- tion f (x) = 1/(1 + exp(−x)), W is the weight matrix and b is the bias term. The goal of the auto-encoder is to minimize the reconstruction er- ror L(x, g(h(x))) = |x−g(h(x))| 2 , thus retaining maximum information. Through the combination and transformation, auto-encoder learns the ab- stract representation h(x) of the input binary term vector. The representation is a real vector with val- ues between 0 and 1.</p><p>In consideration of the large number of units in the hidden layer (as marked in <ref type="figure" target="#fig_0">Fig.2</ref>), a sparsity constraint is imposed on the hidden units to hold the capacity to discover interesting structure in the data. We use sparse auto-encoder  to learn the correlations between descrip- tions from their binary term vectors. The sparse auto-encoder attempts to minimize the following loss function:</p><formula xml:id="formula_2">J(W, b) = m i=1 x (i) − x (i) 2 + λ (W 1 F + W 2 F ) + β h∈H KL (ρ ρ h )<label>(2)</label></formula><p>where x (i) is the binary term vector of the ith en- tity (a class or a property),  </p><formula xml:id="formula_3">x (i) is the reconstruc- tion of x (i) , λ is a regularization parameter, orig- inal · F is the</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Learning higher level representations</head><p>The auto-encoder which only has one hidden layer may not be enough to learn the complex interac- tions between input features. Inspired by the work of <ref type="bibr" target="#b34">Vincent et al. (2010)</ref> and <ref type="bibr" target="#b15">He et al. (2013)</ref>, we build multi-layer model to learn more abstract en- tity representations. To achieve this, we repeatedly stack new sparse auto-encoder on top of the previ- ously learned h(x) (i.e., the higher level represen- tations are formed by combination of lower lev- el representations). This model is called Stacked Auto-Encoder (SAE) by <ref type="bibr" target="#b2">Bengio et al. (2007)</ref>. In this way, when we input the binary term vector to the network, we can get its abstract represen- tations in different levels. In other words, with the layer-by-layer learning, we obtain different level- s of representations. The top-level representation, which models the final interactions of the original descriptions, can be used to measure the similarity between classes and properties. The prototype of Stacked Auto-Encoder (SAE) is shown in <ref type="figure" target="#fig_2">Fig.3</ref>, where f (h(x)) (m) denotes the final representation learned by the top-level hidden layer and superscript m means the SAE consists of m sparse auto-encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimizing with the ontology structure</head><p>The above method can only consider the local de- scriptions (such as ID, label and comments etc.) of entities in ontology. According to the study in ( <ref type="bibr" target="#b26">Melnik et al., 2002</ref>), we present our struc- tural method or called Similarity Propagation (SP) method, which exploits more abundant structure information of the ontology to discover more map- pings globally. The intuition behind the propaga- tion idea is that the similarity between two entities is not only about their neighbor entities, but it is about all other entities (neighbor entities' neigh- bor entities) in the ontologies. This idea has also been used in the ontology matching systems Ri- MOM( <ref type="bibr" target="#b22">Li et al., 2009</ref>) and YAM++ <ref type="bibr" target="#b28">(Ngo and Bellahsene, 2012</ref>) in order to find mappings between classes and properties. But the nodes in their propagation graph are just limited to class pairs and property pairs, and the propagation edges are transformed from relations between two classes, two properties or a class and a property. The dif- ference of our SP method is that we consider the instances and its relations with classes and prop- erties when creating the propagation graph even if we also only find mappings between classes and properties. This is because (1) the similar degree of two classes will be increased if they have some of similar instances; (2) the similar degree of two properties will be increased if the instances that own these properties are similar. The propagation graph in our SP method will be much more com- plete compared with the previous ones. Algorithm 1 presents the procedures of our SP method. In the first two steps of it, we repre- sent each to-be-matched ontology to a Directed Labeled Graph (DLG). Each edge in the DLG has format (s, p, o), where s and o are the source and target nodes (each node represents a class, a property or an instance), and the edge's label p comes from one of the seven ontology relation- s including HasSubClass, HasSubProperty, Ha- sObjectProperty, HasDataProperty, HasInstance, HasDomain, HasRange. Then we create a Pair- wise Connectivity Graph (PCG) from two DLGs by merging edges having the same labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Our SP Algorithm</head><p>Input: The to-be-matched ontologies, O R and O T ; The initial similarity matrix, M 0 ; The edges' weight matrix, W ; Output: The updated similarity matrix,</p><formula xml:id="formula_4">M 1 ; 1 DLG 1 ← T ransf orm(O R ); 2 DLG 2 ← T ransf orm(O T ); 3 P CG ← M erge(DLG 1 , DLG 2 ); 4 IP G ← Initiate(P CG, M 0 , W ); 5 M 1 ← P ropagation(IP G, N ormalized);</formula><p>In the fourth step of Algorithm 1, for a PCG, we assign weight values to edges as the inverse of the number of out-linking relationships of it- s source node ( <ref type="bibr" target="#b26">Melnik et al., 2002</ref>). For the n- odes that consist of two classes or two properties, we assign them values calculated with the cosine similarity between their representations learned in section 2.1.3. For the node consisting of two in- stances, the similarity value assigned to it is mea- sured with the ScaledLevenstein 2 between the IDs of instances. In this way, we construct an Induced Propagation Graph (IPG) on which the propaga- tion algorithm will run iteratively. Let σ(x, y) de- notes the similarity score between entities x and y for node (x, y) in the IPG. At the (i + 1)th itera- tion, the similarity score is updated as follows:</p><formula xml:id="formula_5">σ i+1 = 1 z σ 0 + σ i + ϕ(σ 0 + σ i ) ,<label>(3)</label></formula><formula xml:id="formula_6">ϕ σ 0 + σ i = m j=1 σ 0 + σ i j w j (4)</formula><p>where z is the normalization factor defined as z = max</p><p>x ∈IP G σ i+1 . σ 0 and σ i are similarities at the initial time and ith iterations, respectively. ϕ() is the function to compute the similarities propa- gated from the adjacent node σ i j connected to n- ode (x, y) in the (i + 1)th iteration. And w j is the weight of edge between the node (x, y) and its jth neighboring node.</p><p>During each iteration in the final step of Algo- rithm 1, only the similarity value between two en- tities in the node will be updated. At the end of each iteration, all similarity values are normalized by a Normalized function to all in range <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>. The iteration stops after a predefined number of steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Mapping selection</head><p>Similar with the work in ( <ref type="bibr" target="#b35">Wang and Xu, 2007;</ref><ref type="bibr" target="#b18">Huang et al., 2007;</ref><ref type="bibr" target="#b28">Ngo and Bellahsene, 2012)</ref>, we use the Stable Marriage (SM) algorithm <ref type="bibr" target="#b26">(Melnik et al., 2002</ref>) to choose the 1:1 mappings from the M rows and N columns similarity matrix, where M and N is the number of classes and properties in ontologies O 1 and O 2 , respectively. In addition, before we run the SM algorithm we set the value of cell [i, j] of the similarity matrix to zero if i and j correspond to different types of entities. Thus, we remove lots of redundant data and only find the mappings between classes or properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data sets and evaluation criteria</head><p>The annual OAEI campaign is an authoritative contest in the area of ontology matching, we choose the data from OAEI in our experiments, because the evaluation metrics have been well de- fined and the comparision can be easily made. We observe strong structure similarities lies be- tween OAEI ontologies and ontologies used in NLP tasks, such as WordNet and HowNet for WS- D ( <ref type="bibr" target="#b23">Li et al., 1995;</ref><ref type="bibr" target="#b0">Agirre et al., 2009)</ref>, and Free- base, YAGO, and knowledge graph for IE, text mining and QA (Yao and Van Durme, 2014; ), both describe entities and their rela- tions with class, properties and instances.</p><p>Development dataset: the Standard Bench- mark 2012 dataset that OAEI provides for devel- opers to test their system before participating in the competition is used as the development dataset in our experiments. This dataset contains one ref- erence ontology and 109 target ontologies. We use this dataset to test various values for the parame- ters in our ERSOM and apply the best ones to the experiments on the testing datasets.</p><p>Testing dataset: (1) the Benchmark-Biblio 2012 dataset which contains one reference ontol- ogy and 94 target ontologies; (2) the Benchmark- Biblioc 2013 dataset which has five sub-datasets and there are one reference ontology and 93 target ontologies in each sub-dataset. We use these two datasets to evaluate the performance of our ER- SOM approach.</p><p>In the matching scenario, each target ontolo- gy should be mapped to the reference ontology. We followed the standard evaluation criteria from the OAEI, calculating the precision, recall and f- measure over each test. The version computed here is the harmonic mean of precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental design and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Evaluation for representation learning</head><p>We first use Jena 3 parsing the ontologies and ex- tract descriptions for entities according to the de- scription in section 2.1.1, then we create a vocabu- lary based on the dataset and denote each class and property as a binary term vector. We apply the L- BFGS algorithm <ref type="bibr" target="#b27">(Ngiam et al., 2011</ref>) to train the stacked auto-encoder described in section 2.1.3. The size of the input layer is equals to the length of the vocabulary created from the dataset. We fix the parameters λ = 1e − 4, β = 3 and ρ = 0.25 in Eq.2, and set the size of the first and second hidden layer of the stacked auto-encoder to 200 and 100, respectively, by experience. The number of itera- tions of the L-BFGS algorithm is set to 500. We use the learned representations to measure the sim- ilarities between classes and properties and apply the strategy presented in section 2.3 to extract final mappings. The matching results of our Unsuper- vised Representation Learning (URL) method on the development dataset and testing datasets are shown in <ref type="table" target="#tab_1">Table 1 and Table 2</ref>, respectively.  <ref type="table">Table 1</ref>: Representation learning on dev. dataset.</p><p>In <ref type="table">Table 1</ref>, TV denotes the matcher in which the similarities are calculated between binary ter- m vectors of classes and properties by using co- sine measure. URL(i), where i ∈ {1, 2}, repre- sents that we use the representations learned by the ith hidden layer of the stacked auto-encoder to measure the similarities between classes and prop- erties to find mappings. <ref type="table">Table 1</ref> shows that on the development dataset, the F-measure of TV is 0.748 and it is improved 9.6% and 12.8% when we use the representations learned by the single- layer and double-layer auto-encoder to find the mappings, respectively. It illustrates that we have learned some useful information from the term vectors, which can be explained as the interactions between descriptions of entities. From the last two rows in <ref type="table">Table 1</ref>, we can find that the F-measure im- proved by 2.9% when we use the representations learned by the second hidden layer (i.e., URL <ref type="formula" target="#formula_2">(2)</ref>) to measure the similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark-Biblio 2012</head><p>Benchmark-Biblioc 2013 Prec.</p><p>Rec  From <ref type="table" target="#tab_1">Table 2</ref> we can see that the F-measures are increased on both of the testing datasets when we use the learned representations to measure simi- larities between classes and properties compared with using term vectors, but the amount of im- provements are less than that on the development dataset. This is because we estimate the parame- ters of the representation learning model on the de- velopment dataset and then apply them on the test tasks directly. The precision is reduced when we use URL method, this may be due to the learned representations of entities are too general. In ad- dition, in the parameter adjustment process, we try to make the F value maximization, but not to care about mapping precision. This is because we usually compare the performance of the systems based on their matching F values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Comparison with aggregation methods</head><p>Aggregating different similarities is pervasive in ontology matching systems that contain mul- tiple single matchers, for example, Falcon- AO( <ref type="bibr" target="#b30">Qu et al., 2006</ref>), <ref type="bibr">RiMOM(Li et al., 2009</ref>), YAM++(Ngo and Bellahsene, 2012), etc. Since our representation learning method also combines all descriptions of an entity together in an unsu-pervised way, we compare it with previous unsu- pervised aggregation strategies, that is, Max, Av- erage, Sigmoid, Weighted( <ref type="bibr" target="#b8">Cruz et al., 2010</ref>) and Harmony( <ref type="bibr" target="#b24">Mao et al., 2008</ref><ref type="bibr" target="#b25">Mao et al., , 2010</ref>. As the work in ( <ref type="bibr" target="#b25">Mao et al., 2010;</ref><ref type="bibr" target="#b28">Ngo and Bellahsene, 2012)</ref>, we first define three context profiles including in- dividual profile, semantic profile and external pro- file for each class and property (this equivalent to divide the collection of descriptions of a class or a property into three different parts). Then we ap- ply a vector space model with TFIDF weighting scheme and cosine similarity measure to compute similarity scores between profiles. And finally, we aggregate these three single similarities using dif- ferent aggregation methods.   <ref type="table" target="#tab_2">Table 3</ref> shows the F-measure of the single matchers and aggregation methods on the devel- opment dataset (Dev. for short) and two test- ing datasets (i.e., Tes.1 and Tes.2, which refer to the Benchmark-Biblio 2012 dataset and the Benchmark-Biblioc 2013 dataset, respectively). First, the performance of single matcher is poor, the highest F-measures are 0.668, 0.612 and 0.611 on the datasets Dev., Tes.1 and Tes.2, respective- ly. And when we use external profile to calcu- late the similarities, the F-measures are reduced to 22%. Second, the performance is dramatical- ly boosted by aggregation methods and they al- l achieve F-measures higher than 0.7, so the ag- gregation methods are very effective in improving the performance of mapping approaches that re- ly on measuring multiple similarities. And finally, our Unsupervised Representation Learning (URL) method holds the highest F-measure both on the development dataset and on the testing datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Evaluation for our structural method</head><p>In this experiment, we compare our Similarity Propagation (SP) method to other structure based methods, that is, ADJACENTS and ASCOPATH in ( <ref type="bibr" target="#b21">Le et al., 2004</ref>); DSI and SSC in <ref type="bibr" target="#b33">(Sunna and Cruz, 2007</ref>); Li's SP ( <ref type="bibr" target="#b22">Li et al., 2009</ref>) and Ngo's SP ( <ref type="bibr" target="#b28">Ngo and Bellahsene, 2012)</ref>. We first use enti- ty's ID to compute the similarity between classes and properties to provide an unified initial simi- larity matrix as input (or initialization) for our SP and other structural methods. Then, a new similar- ity matrix will be created and updated by consid- ering the initial similarities and different structure information. And finally, we extract the mappings from the newly created similarity matrix with the strategy described in section 2.3.  In ADJACENTS method, the parameter W k , where k ∈ {1, 2, 3}, is set to 1/3. The parameter MCP in the methods DSI and SSC is set to 0.75 as reported in their work. The iterative times to SP al- gorithm are fixed to 50. <ref type="table" target="#tab_3">Table 4</ref> reports the match- ing F-measures of these structure based methods on the development dataset (Dev. for short) and testing datasets (Tes.1, Tes.2 for short).</p><p>From table 4 we can see that the local-structure based methods (i.e., ADJACENTS, ASCOPATH, DSI and SSC) provide low matching quality. It means that these methods did not discover enough additional correct mappings or even find some in- correct mappings. For example, the F-measure even reduced on the development dataset when use ASCOPATH method. This is because if two enti- ties don't have any common entity in their ances- tors, their similarity is equal to 0. Whereas, Li's SP and Ngo's SP are global-structure based meth- ods, and they seem to work well. The F-measure has even improved by 21.9% when using the N- go's SP compared with the initial matcher. This is because in the SP method, the similarity score of a pair of entities depends on not only their cur- rent status but also on the status of the other pairs. That explains why SP outperforms all other local based structural methods. In our SP, all instances and their relations to other entities in ontology are exploited to help find the mappings between class- es and properties, therefore the matching quality is distinctly improved.</p><p>The last two rows of <ref type="table" target="#tab_3">Table 4</ref> shows that when we use the learned representations to cre- ate the initial similarity matrix to initialize our SP method, the matching quality is significantly im- proved. For example, the F-measure is improved from 0.810 to 0.903 on the development dataset. This illustrates that the initialization step is very important to the SP method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Comparison with other ontology matching systems</head><p>We compare our ontology matching approach, called ERSOM, with other multi-strategy match- ing systems on the testing datasets. <ref type="figure" target="#fig_6">Fig.4</ref> lists the results of top five matching systems according to their F-measures on the Benchmark-Biblio 2012 dataset and Benchmark-Biblioc 2013 dataset.</p><p>As shown in <ref type="figure" target="#fig_6">Fig.4</ref>, ERSOM outperforms most of the participates except the systems YAM++ and CroMatcher whose F-measures are 0.89 and 0.88 in 2013, respectively. CroMatcher achieves the same level of recall as YAM++ but with consis- tently lower precision ( <ref type="bibr" target="#b14">Grau et al., 2014</ref>). Un- like MapSSS, our approach does not use any exter- nal resources such as Google queries in its current version. In YAM++ approach, the gold standard datasets that taken from Benchmark dataset pub- lished in OAEI 2009 are used to generate training data to train a decision tree classifier. And in the classifying phase, each pair of elements from two to-be-matched ontologies is predicted as matched or not according to its attributes. However, ER- SOM is an unsupervised approach, but it does not exclude using external resources and training da- ta to help learning the representations of entities and provide the initial similarity matrix for the SP method to further improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>There are many studies on Ontology Matching ( <ref type="bibr" target="#b11">Euzenat et al., 2007;</ref><ref type="bibr" target="#b31">Shvaiko and Euzenat, 2013)</ref>. Currently, almost all ontology matching system- s exploit various kinds of information provided in Pirró and Talia <ref type="formula" target="#formula_0">(2010)</ref> is a generic schema matching system. It exploits Max, Min, Average and Weighted strategies for the combination. The weighted method assigns a relative weight to each similarity matrix, and calculates a weighted sum of similarity for all similarity matrixes. The Aver- age method is a special case of Weighted, which considers each similarity matrix equally important in the combination. Max and Min are two extreme cases that return the highest and lowest similari- ties in all similarity matrixes respectively. <ref type="bibr" target="#b20">Ji et al. (2011)</ref> use the Ordered Weighted Average (OWA) to combine different matchers. It is a kind of ontology-independent combination method which can assign weights to the entity level, i.e., it use a specific ordered position rather than a weight as- sociated with a specific similarity matrix to aggre- gate multiple matchers. <ref type="bibr" target="#b19">Jean-Mary et al. (2009)</ref> combines different matchers by using a weighted sum strategy that adjusts weights empirically, or based on some static rules. This approach cannot automatically combine different matchers in vari- ous matching tasks.</p><p>There are several works which exploit the su- pervised machine learning techniques for ontolo- gy matching. <ref type="bibr" target="#b10">Eckert et al. (2009)</ref>, string-based, linguistic and structural measures (in total 23 fea- tures) were used as input to train a SVM clas- sifier to align ontologies. CSR (Classification- based learning of Subsumption Relations) is a generic method for automatic ontology matching between concepts based on supervised machine learning ( <ref type="bibr" target="#b32">Spiliopoulos et al., 2010)</ref>. It specifically focusses on discovering subsumption correspon-dences. SMB (Schema Matcher Boosting) is an approach to combining matchers into ensembles <ref type="bibr" target="#b13">(Gal, 2011)</ref>. It is based on a machine learning technique called boosting, that is able to selec- t (presumably the most appropriate) matchers that participate in an ensemble.</p><p>The difference of our work is that the textual descriptions are not been directly used to measure the similarities between entities. We learn a rep- resentation for each ontology entity in an unsuper- vised way to capture the interactions among the descriptions, which avoid the problem of selecting and aggregating different individual similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>The successful ontology matching is very impor- tant to link heterogeneous ontologies for NLP. In this paper, we have proposed an ontology match- ing approach, ERSOM, which describes the class- es and properties in ontology with abstract repre- sentations learned from their descriptions and im- proves the overall matching quality using an it- erative Similarity Propagation (SP) method based on more abundant structure information. Experi- mental results on the datasets from OAEI demon- strate that our approach performs better than most of the participants and achieves a competitive per- formance. In our future work, we will consid- er to use the ontology matching approach to the matching between different NLP-oriented ontolo- gies such as wordnet, Freebase, YAGO, etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Unsupervised representation learning.</figDesc><graphic url="image-2.png" coords="3,307.28,412.88,226.78,137.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Frobenius norm, β controls the weight of the sparsity penalty term, H is the set of hidden units, and ρ is the sparsity parameter. For- mally, KL (ρ ρ h ) = ρ log ρ y h + (1 − ρ) log 1−ρ 1− y h is the Kullback-Leibler (KL) divergence between a Bernoulli random variable with mean ρ and a Bernoulli random variable with mean y h .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Learning higher level representations.</figDesc><graphic url="image-3.png" coords="4,72.00,498.27,226.78,126.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Comparison with other OAEI systems.</figDesc><graphic url="image-4.png" coords="8,307.28,62.81,226.78,147.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Representation learning on test datasets.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 : Comparison with aggregation methods.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 : Comparison with structural methods.</head><label>4</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> The OAEI is an international initiative organizing annual campaigns for evaluating ontology matching systems. All of the ontologies provided by OAEI are described in OWL-DL language, and like most of the other participates our ERSOM also manages the OWL ontology in its current version. OAEI: http://oaei.ontologymatching.org/</note>

			<note place="foot" n="2"> http://sourceforge.net/projects/ secondstring/. ScaledLevenstein is a good method for computing string similarity (Cheatham and Hitzler, 2013a), of course, it can be replaced by other methods.</note>

			<note place="foot" n="3"> https://jena.apache.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge-based wsd and specific domains: Performing better than generic supervised wsd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>De Lacalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fakultatea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1501" to="1506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Unsupervised feature learning and deep learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>CoRR abs/1206.5538</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larochelle</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Autoassociation by multilayer perceptrons and singular value decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bourlard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="291" to="294" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Supporting natural language processing with background knowledge: Coreference resolution case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bryl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Giuliano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Serafini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tymoshenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="80" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">String similarity metrics for ontology alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hitzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web-ISWC 2013</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="294" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Stringsauto and mapsss results for oaei 2013. Ontology Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheatham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hitzler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">146</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using agreementmaker to align ontologies for oaei 2010</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">F</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Caimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmonari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">C</forename><surname>Keles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC International Workshop on Ontology Matching (OM). CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">689</biblScope>
			<biblScope unit="page" from="118" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning topic representation for smt with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving ontology matching using meta-level learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meilicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web: Research and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="158" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shvaiko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">State of the art on ontology alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Barrasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bouquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>De Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dieng-Kuntz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ehrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hauswirth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jarrar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
	<note>Knowledge Web Deliverable D</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Uncertain schema matching. Synthesis Lectures on Data Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Results of the ontology alignment evaluation initiative 2013</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Grau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dragisic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Granada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jiménezruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kempf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lambrix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Ontology Matching, collocated with the 12th International Semantic Web Conference-ISWC 2013</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning entity representation for entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="30" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning multiple layers of representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="428" to="434" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Autoencoders, minimum description length, and helmholtz free energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="3" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ontology matching using an artificial neural network to learn weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Huhns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI Workshop on Semantic Web for Collaborative Knowledge Acquisition (SWeCKa-07)</title>
		<meeting>IJCAI Workshop on Semantic Web for Collaborative Knowledge Acquisition (SWeCKa-07)<address><addrLine>India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ontology matching with semantic verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Jean-Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Shironoshita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Kabuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="251" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Combination of similarity measures in ontology matching using the owa operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Developments in the Ordered Weighted Averaging Operators: Theory and Practice</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="281" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dieng-Kuntz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<title level="m">On ontology matching problems. ICEIS (4)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="236" to="243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rimom: A dynamic multistrategy ontology alignment framework. Knowledge and Data Engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1218" to="1232" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A wordnet-based algorithm for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szpakowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="1368" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A harmony based adaptive ontology mapping approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SWWS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="336" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An adaptive ontology mapping approach with neural network based constraint satisfaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="25" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Similarity flooding: A versatile graph matching algorithm and its application to schema matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Melnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 18th International Conference on</title>
		<meeting>18th International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
	<note>Data Engineering</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On optimization methods for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Prochnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Yam++: a multi-strategy based approach for ontology matching task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bellahsene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Engineering and Knowledge Management</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="421" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ufome: An ontology mapping system with strategy prediction capabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pirró</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Talia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="444" to="471" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Constructing virtual documents for ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th international conference on World Wide Web</title>
		<meeting>the 15th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="23" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ontology matching: state of the art and future challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shvaiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Euzenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="158" to="176" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Knowledge and Data Engineering</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the discovery of subsumption relations for the alignment of ontologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spiliopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Vouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karkaletsis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="88" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Structure-based methods to enhance geospatial ontology alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sunna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">F</forename><surname>Cruz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GeoSpatial Semantics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="82" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stacked denoising 2428 autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Lily: the results for the ontology alignment contest oaei</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Ontology Matching</title>
		<meeting>the Second International Workshop on Ontology Matching</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="179" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Freebase qa: Information extraction or semantic parsing? ACL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">82</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Information extraction over structured data: Question answering with freebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
