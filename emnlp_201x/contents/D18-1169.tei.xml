<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CARD-660: Cambridge Rare Word Dataset-a Reliable Benchmark for Infrequent Word Representation Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 31-November 4, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taher</forename><surname>Pilehvar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Theoretical and Applied Linguistics</orgName>
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Kartsaklis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Theoretical and Applied Linguistics</orgName>
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Prokhorov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Theoretical and Applied Linguistics</orgName>
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Theoretical and Applied Linguistics</orgName>
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CARD-660: Cambridge Rare Word Dataset-a Reliable Benchmark for Infrequent Word Representation Models</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels, Belgium</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1391" to="1401"/>
							<date type="published">October 31-November 4, 2018. 2018</date>
						</imprint>
					</monogr>
					<note>1391</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Rare word representation has recently enjoyed a surge of interest, owing to the crucial role that effective handling of infrequent words can play in accurate semantic understanding. However, there is a paucity of reliable benchmarks for evaluation and comparison of these techniques. We show in this paper that the only existing benchmark (the Stanford Rare Word dataset) suffers from low-confidence annotations and limited vocabulary; hence, it does not constitute a solid comparison framework. In order to fill this evaluation gap, we propose CAmbridge Rare word Dataset (CARD-660), an expert-annotated word similarity dataset which provides a highly reliable, yet challenging , benchmark for rare word representation techniques. Through a set of experiments we show that even the best mainstream word embeddings, with millions of words in their vocabularies, are unable to achieve performances higher than 0.43 (Pearson correlation) on the dataset, compared to a human-level upperbound of 0.90. We release the dataset and the annotation materials at https:// pilehvar.github.io/card-660/.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Words in a corpus of natural language utterances approximately follow a Zipfian distribution with their majority, in the "long tail" of frequency dis- tribution, occurring rarely. The prominent distri- butional approach to semantic representation re- lies on enormous occurrences for each individ- ual word; therefore, it falls short of learning ac- curate representations for rare words in the long tail. Moreover, it is unreasonable to expect that all words in the vocabulary of a language are ob- served in a text corpus, even if it is massive in size. Out-of-vocabulary (OOV) words pose one of the major ongoing challenges for word embedding techniques. Given that effective handling of rare and OOV words is crucial to accurate natural lan- guage understanding, several studies have focused on the topic during the past few years, resulting in a wide range of techniques.</p><p>However, despite the popularity of rare and sub- word semantic representation, the field of research has suffered from the lack of high quality generic evaluation benchmarks. A task-based evaluation, i.e., one which directly verifies the impact of rep- resentation models in a downstream NLP system, despite being very important, does not provide a solid base for comparing different models, given that small variations in the architecture, parameter setting, or initialisation can lead to performance differences. Moreover, such an evaluation would reflect the "suitability" of representations for that specific configuration and for that particular task, and might not be conclusive for other settings.</p><p>As far as generic evaluation is concerned, exist- ing benchmarks generally target frequent words. An exception is the Stanford Rare Word (RW) Similarity dataset ( <ref type="bibr" target="#b21">Luong et al., 2013</ref>) which has been the standard evaluation benchmark for rare word representation techniques for the past few years. In Section 2.1, we will provide an in-depth analysis of RW and highlight that crowdsourcing the annotations, with no rigorous checkpoints, has compromised the reliability of the dataset. This is mainly reflected by the low inter-annotator agree- ment (IAA), a performance ceiling which is easily surpassed by many existing models.</p><p>To overcome this barrier and to fill the gap for a reliable benchmark for the evaluation of subword and rare word representation techniques, we in- troduce a new dataset, called CARD-660: Cam- bridge Rare Word Dataset. Compared to exist- ing benchmarks, CARD-660 provides multiple ad- vantages: (1) thanks to a manual curation by ex- perts, we report IAA of around 0.90 (see <ref type="table" target="#tab_2">Table 3</ref>) which is substantially higher than those for exist-ing datasets; (2) word pairs are selected manually from a wide range of domains and, unlike exist- ing datasets, are not bound to a specific resource; (3) word pairs in the dataset are balanced across the similarity scale; and (4) the huge gap between state of the art and IAA (more than 0.50 in terms of Spearman correlation) promises a challenging dataset with lots of potential for future research.</p><p>The paper is structured as follows. The follow- ing Section covers the related work, highlighting some of the issues with the RW dataset. Section 3 details the construction procedure for CARD-660. In Section 4, we analyse the dataset from different aspects, showing how it improves existing bench- marks. Section 5 reports our evaluation of main- stream word embeddings and recent word repre- sentation techniques on the dataset. Finally, con- cluding remarks are mentioned in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Word similarity datasets have been one of the old- est, still most prominent, benchmarks for the eval- uation and comparison of semantic representation techniques. As a result, several word similar- ity datasets have been constructed during the past few decades; to name a few: RG-65 <ref type="bibr" target="#b28">(Rubenstein and Goodenough, 1965)</ref>, <ref type="bibr">WordSim-353 (Finkelstein et al., 2002</ref>), YP-130 ( <ref type="bibr" target="#b33">Yang and Powers, 2005</ref>), MEN-3K ( <ref type="bibr" target="#b6">Bruni et al., 2014</ref>), SimLex-999 ( <ref type="bibr" target="#b13">Hill et al., 2015)</ref>, and SimVerb-3500 ( <ref type="bibr" target="#b10">Gerz et al., 2016</ref>). Many of these English word similarity datasets have been translated to other languages to create frameworks for multilingual <ref type="bibr" target="#b18">(Leviant and Reichart, 2015)</ref> or crosslingual <ref type="bibr">(CamachoCollados et al., 2017</ref>) semantic representation techniques. However, these datasets mostly target words that occur frequently in generic texts and, as a result, are not suitable for the evaluation of subword or rare word representation models.</p><p>One may opt for transforming a frequent-word benchmarks into an artificial rare word dataset by downsampling the dataset's words in the underly- ing training corpus ( <ref type="bibr" target="#b30">Sergienya and Schütze, 2015)</ref>. However, this benchmark might not properly sim- ulate a real-world rare word representation sce- nario (cf. Section 3.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Stanford RW Dataset</head><p>The Stanford Rare Word Similarity (RW) dataset is an exception as it is dedicated to evaluating in- frequent word representations. The dataset has <ref type="figure">Figure 1</ref>: Distribution of relation types ("hypernymy", "similar to", and others) across four quartiles (sorted by gold similarity scores) of the Stanford Rare Word Similarity dataset. The distribution of pairs with hy- pernymy relation is almost uniform across the quartiles, whereas one would expect many more pairs in the top quartiles (Q4 and Q3), given the high semantic similar- ity of hypernym-hyponyms.</p><p>been regarded as the de facto standard evaluation benchmark for subword and rare word represen- tation techniques. However, our analysis shows that RW suffers from multiple issues: (1) skewed distribution of the scores, (2) low-quality and in- consistent scores, and as a consequence, (3) low inter-annotator agreement.</p><p>The RW dataset comprises 2034 word pairs (i.e., word 1 -word 2 ). Candidates for word 1 were randomly sampled from Wikipedia docu- ments, distributed across a wide range of frequen- cies (from 5 to 10,000) to ensure the inclusion of infrequent words. Given this automatic sam- pling, a measure was required to avoid noisy or junk words. To this end, a sampled word was checked in WordNet <ref type="bibr">(Fellbaum, 1998)</ref> and was in- cluded only if it appeared in at least one synset. Hence, the vocabulary of the dataset is bound to that of WordNet. Words for word 2 were randomly picked from synsets that were directly connected to a synset of word 1 , through various relations, such as hypernymy, holonymy, and attributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Distribution of scores</head><p>These word pairs were assigned similarity scores in <ref type="bibr">[0,</ref><ref type="bibr">10]</ref>. Given that all word pairs in the dataset are semantically-related according to WordNet, the scores form a skewed distribution biased to- wards the upper bound (see <ref type="figure" target="#fig_0">Figure 2</ref> and Section 4.1 for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Consistency of annotations</head><p>The scoring of the pairs has been carried out through crowdsourcing: (Amazon Mechanical) Turkers have provided ten scores for each word pair. The raters were restricted to only US-based workers and they were asked to self-certify them- selves by indicating if they "knew" the word; this was used to "discard unreliable pairs." However, our analysis of the dataset clearly indicates that the above measures have not been adequate for guaranteeing quality annotations. For instance, the word bluejacket is paired with submariner in the dataset. According to WordNet (v3.0), a sub- mariner ("a member of the crew of a submarine") is a bluejacket ("a serviceman in the navy"; a navy man, sailor), hence a hypernymy relation- ship. One would expect a word to have high se- mantic similarity with its hypernym. However, the gold score for this pair is just 0.43 in the scale <ref type="bibr">[0,</ref><ref type="bibr">10]</ref>. Other examples include "untruth" (a false statement) vs. "statement" (again, with a hyper- nymy relationship) with a low similarity of 1.22. Apart from not being a rigorous evaluation, the self-certification does not verify if the annotator had knowledge of various possible meanings of a word. For instance, decomposition could refer to the analysis of vectors in algebra; but, when paired with algebra, the assigned score is only 0.75. Such examples clearly indicate that the an- notators were not aware of specialised senses of some words (e.g., the algebraic meaning of de- composition), despite "knowing" the word.</p><p>In fact, there are numerous such pairs in the dataset. According to our estimate, 78% of the 2034 word pairs in the dataset are in a hypernymy or similar to relationship. One would expect most of these (semantically similar) pairs to have been assigned high similarity scores which are closer to the upper bound of the similarity scale <ref type="bibr">[0,</ref><ref type="bibr">10]</ref>. However, as shown in <ref type="figure">Figure 1</ref>, these pairs are spread across the similarity scale, spanning from complete unrelatedness (lower bound) to identical semantics (synonymy). Having the words in the dataset sorted by their assigned gold scores, re- spectively, 66%, 79%, 83%, and 85% of the pairs in the first to fourth quartiles contain either "hy- pernymy" or "similar to" relations (whereas one would expect most of these semantically-similar pairs to appear in the top quartiles).</p><p>Additionally, the dataset suffers from incon- sistent annotations. For instance, the two al- most identical pairs tricolour-flag and tricolor- flag were assigned substantially different scores, i.e., 5.80 and 0.71, respectively. This inconsis- tency is also reflected by high variances across an- notators scores (cf. Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Inter-Annotator Agreement (IAA)</head><p>This validity metric reflects the homogeneity of the annotators' ratings and it is generally accepted as the upper bound for machine performance. IAA is widely used as a standard evaluation metric for the quality of word similarity datasets. A low IAA indicates a defective similarity scale or unreliable annotations.</p><p>In the RW dataset, "up to 10" annotations have been provided for the 2034 word pairs, each with a similarity score in <ref type="bibr">[0,</ref><ref type="bibr">10]</ref> range. More precisely, 214 of the pairs are not provided with 10 scores, with the minimum number of scores for a pair being 7. The authors did not report IAA statis- tics for this dataset. Given that the annotators are not known for each pair in the released dataset, it is not straightforward to compute IAA. 1 Accord- ing to a rough calculation, the average pairwise Spearman correlation between annotators' scores is 0.40, which is a significantly low figure com- pared to other existing word similarity datasets. We report an impressive IAA of 0.89 for our dataset (cf. Section 4.2).</p><p>benchmark that can represent the challenging na- ture of the task: (1) it is unable to control the im- pact of second-order associations (words that fre- quently co-occur with the downsampled word) and cannot represent a real-world setting with novel rare usages; (2) given that morphological varia- tions of a word (such as plural forms) are kept intact in this procedure, a subword technique can easily resort to these forms to compute the em- bedding for downsampled words; and (3) a con- strained evaluation configuration in which the task is to estimate the embedding for a (rare) word us- ing one or few occurrences (contexts) of it, lim- its the benchmark to a subset of corpus-based rare word representation techniques only. Moreover, the evaluation would require the comparison of the computed embeddings for rare words with a set of reference embeddings (computed on the full data). This dependency limits the ability of the benchmark in providing a direct evaluation of the rare word representation technique, independently from the impact of the model used to compute the reference embeddings.</p><p>The CARD-660 dataset aims at filling the gap for rigorous generic evaluation of rare word and subword representation models. In what follows in this section, we will detail the construction pro- cedure of the dataset which was carefully planned to guarantee a challenging and reliable dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Construction Procedure</head><p>The following four-phase procedure was used to construct the dataset:</p><p>(1) A set of 660 rare words were carefully se- lected from a wide range of domains; (2) For each of these initial words, a pairing word was manually selected according to a randomly sampled score from the similarity scale (Section 3.2.2); (3) All pairs were scored by 8 annotators; (4) A final adjudication was performed to ad- dress disagreements (Section 3.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Similarity scale</head><p>We adopted the five-point Likert scale used for the annotation of the datasets in SemEval-2017 Task 2 (Camacho-Collados et al., 2017). The task re- ported high IAA scores which reflects the well- definedness and clarity of the scale. We provided annotators with the concise guideline shown in <ref type="table" target="#tab_0">Ta- ble 1</ref>, along with several examples. Given the con- tinuity of the scale, the annotators were given flex- ibility to select values in between the five points, whenever appropriate, with a step size of 0.5. The annotators were asked in the guidelines to make sure they were familiar with all common meanings of the word (as defined by WordNet or other online dictionaries). To facilitate the anno- tation, the annotators were provided with the def- initions of some of the words that were defined in WordNet or named entities that had Wikipedia pages. For others, we asked the annotators to check the word in online dictionaries, such as WordNet browser <ref type="bibr">3</ref> and Wiktionary 4 , or encyclo- pediae, such as Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Word pair selection</head><p>Unlike previous work ( <ref type="bibr" target="#b21">Luong et al., 2013</ref>), we did not rely on random sampling (pruned by fre- quency) of initial words from a specific dictionary, to prevent the dataset from being restricted to a specific resource or vocabulary. Instead, we care- fully hand-picked word pairs from a wide range of domains. To construct the 660 pairs of the dataset (each pair is denoted as w 1 − w 2 ), we first picked 660 w 1 words. Our aim was to have a dataset that can ideally reflect the performance of rare word representation techniques in down- stream NLP tasks. To this end, we picked initial words (w 1 s) from different common NLP datasets and resources, listed in <ref type="table" target="#tab_1">Table 2</ref>. For each text- based resource, a frequency list was obtained and rare words were carefully picked from the long tail of the list, cross-checking the frequency of words in the Google News dataset. For the other re- sources (such as Wiktionary), we checked a word against a large frequency list to ensure they are not frequent words. The list was computed on the 2.8B token ukWaC+WaCkypedia corpus ( <ref type="bibr" target="#b1">Baroni et al., 2009</ref>) and comprised 16.5M unique words.</p><p>In order to have a balanced distribution of scores in the dataset, we first assigned random in- teger scores in <ref type="bibr">[0 − 4]</ref> to the 660 initial w 1 s. Then, with the corresponding score in mind, a pairing word (w 2 ) was selected for each w 1 . We show in Section 4.1 that this strategy resulted in a uni- formly distributed set of scores in the dataset.</p><p>The dataset comprises words from a wide range of genres and domains, including slang in so-</p><note type="other">Score Interpretation Example pair 4</note><p>Synonyms. The two words are different ways of referring to the same concept car automobile 3</p><p>Similar. The two words are of the same nature, but slightly different in details car truck 2</p><p>Related. The two words are closely related but they are not similar in their nature car driver 1</p><p>Same domain or slight relation. The two words have distant relationship car tarmac 0</p><p>Completely unrelated. The two words have nothing in common. car sky  cial media (e.g., 2mrw and Mnhttn), named enti- ties (e.g., Stephen Hawking and Ursa Major), and domain specific terms (e.g., erythroleukemia and NetMeeting). Moreover, to have a rigorous testbed for subword representation techniques that empha- sises the importance of semantic (rather than shal- low) understanding of the words, the dataset con- tains several word pairs that have similar surface forms (hence, high string similarity) while being semantically distant, e.g., infection-inflection and currency-concurrency. There are also many com- pound words (e.g., skyglow, musclebike, and log- boat) which makes the dataset particularly inter- esting for evaluating compositionality as well as for subword representation techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Scoring and adjudication</head><p>Once the 660 word pairs were manually selected (by the first author), the initial scores were dis- carded and the words were shuffled (vertically and horizontally) to dispense any potential bias from the initial round of creation. Then, the pairs were assigned to 8 annotators (including all but first au- thors) who independently scored each and every pair according to the annotation guidelines (see Section 3.2.1). All annotators were PhD gradu- ates or students in Computational Linguistics or related fields and were either native or fluent En- glish speakers.</p><p>Once all pairs were scored by the annotators, we checked for disagreements. This check was in- tended to improve the dataset's quality through re- solving simple annotation mistakes. For each an- notator, we marked the i th pair if for the assigned score s i : s i ≥ µ i + 1 or s i ≤ µ i − 1, where µ i is the average of the other seven annotators' scores for s i . The annotator was then asked to (more carefully) re-score the marked pair by checking for its possible meanings. They were asked to keep their initial score if not convinced otherwise. The adjudication revealed that most disagreements were due to an annotator having misread a word or not been familiar with a specific meaning of it, or missing annotations. By average, 13.8% of the pairs were re-scored by each annotator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis</head><p>In this section we provide an analysis on the qual- ity of CARD-660 from three different perspec- tives: distribution of scores, inter-annotator agree- ment, and consistency among annotators. We benchmark CARD-660 against the Stanford RW dataset and two standard word similarity datasets (cf. Section 2): SimVerb-3500 (SV-3500) and SimLex-999 (SL-999). The latter two datasets do not target rare words; however, given that their construction strategy is similar to that employed for creating RW (based on crowdsourcing), we in- cluded them in our analysis experiments to pro- vide better insights. For the purpose of this evalu- ation, all the datasets were scaled to <ref type="bibr">[0,</ref><ref type="bibr">10]</ref> to make them comparable. <ref type="figure" target="#fig_0">Figure 2</ref> shows the distribution of pairs across the similarity scale, for CARD-660 and the three other datasets. As discussed in Section 2.1, RW is heav- ily biased towards the upper bound of the similar-  ity scale (with around 72% of the pairs in the up- per half, i.e., <ref type="bibr">[5,</ref><ref type="bibr">10]</ref>). The skewed distribution in this dataset can be attributed to the automatic word pair selection from semantically-related words in WordNet (cf. Section 2.1). SV-3500 and SL- 999 are skewed towards the lower bound, but to a smaller degree (around 59% of the pairs in [0, 5)). Thanks to the manual creation of CARD-660, we have a balanced set of pairs across the similarity scale (50-50% across the two halves).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Score Distribution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Inter-Annotator Agreement</head><p>As mentioned in Section 2.1, IAA has been exten- sively used as a quality metric for word similar- ity datasets. Following standard practise, we mea- sure two sets of IAA scores: (1) Pairwise is the averaged pairwise correlation between all possible rater pairings, and (2) Mean is the averaged corre- lation of each rater against the average of others.  <ref type="table" target="#tab_2">Table 3</ref>: Inter-annotator agreement (IAA) scores be- fore (initial) and after (final) adjudication (± standard deviation). IAA is shown in terms of Pearson r and Spearman ρ percentage correlations. The final scores are representative of the dataset's quality.</p><p>the dataset are very high, placing it among the best word similarity datasets in the literature. This is particularly interesting considering that, compared to standard word similarity datasets which con- tain mostly common words, our dataset comprises words that are semantically difficult to annotate due to their rare nature. The pairwise IAA score of 88.9 is significantly higher than the crowdsourced RW, with the estimated pairwise IAA score of around 40.0 (cf. Section 2.1). The same ap- plies to other recent crowdsourced word similarity datasets for common words which usually report pairwise IAA scores below 70.0 (e.g., ρ = 67.0 for SL-999) <ref type="bibr">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Consistency of Annotations</head><p>Despite being suitable for measuring linear rela- tionships between scores, correlation cannot fully reflect the consistency between annotators. Two annotators can have perfect correlation, i.e., 1.0, even if they consistently provide different scores for the same pairs (therefore, having different av- erage assigned scores). To check the consistency among annotators, i.e., if they had the same inter- pretation of the similarity scale, we compute vari- ance across annotators for individual pairs. The box and whisker (over scatter) plot in <ref type="figure" target="#fig_1">Fig- ure 3</ref> shows the distribution of annotator vari- ances for the pairs in different datasets. Clearly, the score variances for CARD-660 are signifi- cantly lower than those for the two crowdsourced datasets, i.e., SimVerb-3500 and RW. <ref type="bibr">6</ref> Specifi- cally, for the majority of pairs in CARD-660 the annotation variance is lower than the other two datasets' first quartile (bottom of the blue square   <ref type="table">Table 4</ref>: Pearson r and Spearman ρ correlation percentage performance of mainstream pre-trained word em- beddings on the RW and CARD-660 datasets. Column |V | shows the size of vocabulary for the corresponding embedding set.</p><p>which splits the lower 25% of the data from the top 75%). This indicates that our annotators had significantly higher degrees of agreement, reflect- ing the well-definedness of the similarity scale as well as the reliability of expert-based annotation (as opposed to crowdsourcing).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluations</head><p>In the remainder of this paper, we provide two sets of experiments to showcase the challenging nature of our dataset. Specifically, in Section 5.1 we report the performance of common pretrained word embeddings on CARD-660, and in Section 5.2 we provide experimental results for state-of- the-art rare word representation techniques. In all experiments, we used the cosine similarity for comparing pairs of word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Pre-trained Embeddings</head><p>As was mentioned earlier in the Introduction, it is not possible to enumerate the entire vocabulary of a natural language, even if massive corpora are used. A challenging rare word benchmark should ideally reflect this phenomenon. To verify this in our dataset, we experimented with a set of com- monly used word embeddings trained on corpora with billions of tokens. <ref type="table">Table 4</ref> provides correlation performance re- sults for different embedding sets on the RW and CARD-660 datasets. Specifically, we considered different variants of Word2vec 7 (Mikolov et al., <ref type="bibr">7</ref> https://code.google.com/archive/p/word2vec/ 2013) and Glove 8 ( <ref type="bibr" target="#b24">Pennington et al., 2014</ref>), two commonly-used word embeddings that are trained on massively large text corpora; Dependency- based embeddings <ref type="bibr">9</ref> ( <ref type="bibr" target="#b19">Levy and Goldberg, 2014</ref>) which extends the Skip-gram model to han- dle dependency-based contexts; LexVec <ref type="bibr">10 (Salle et al., 2016</ref>) which improves the Skip-gram model to better handle frequent words; and ConceptNet Numberbatch 11 <ref type="bibr" target="#b32">(Speer et al., 2017</ref>) which exploits lexical knowledge from multiple resources, such as Wiktionary and WordNet, and was the best per- forming system in SemEval 2017 Task 2. In the last two rows of the Table we also report results for two hybrid embeddings constructed by combining the pre-trained Freebase Word2vec, which mostly comprises named entities, with two of the best performing embeddings evaluated on the dataset. Given that the word embeddings are not compara- ble across two different spaces, we only compute the similarity between a pair only if both words are covered in the same space (with priority given to the non-Freebase embedding).</p><p>As can be seen in the Table, many of the em- beddings yield high coverage for the RW dataset, with those trained on the Common Crawl (CC) corpus providing near full coverage. This high- lights the limited vocabulary of the dataset (which is bound to that of WordNet). Also, many of the embeddings attain performance around 40.0 on RW, which is higher than the estimated IAA of the dataset. In contrast, CARD-660 proves to be sig- nificantly more challenging, with the highest cov- erage model (Glove CC and Word2vec Freebase hybrid model) missing around 40% of the pairs. Also, the best performance of 42.6 (r) and 32.7 (ρ) are substantially (around 50.0) lower than the IAA for the dataset (see <ref type="table" target="#tab_2">Table 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Rare Word Representation Techniques</head><p>Rare and unseen word representation has been an active field of research during the past few years, with many different techniques proposed. In this experiment, we evaluate the performance of some of recent models on our dataset. These techniques can be broadly classified into two categories. The first group exploits the knowledge encoded for a rare word in external lexical resources (Section 5.2.1), whereas the second induces embeddings for rare words by extending the semantics of its subword units (Section 5.2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Resource-based models</head><p>The basic assumption here is that a lexical re- source, such as dictionary, provides high cover- age for words in a language, even if they are rare.</p><p>Resource-based models usually rely on WordNet as their external resource and estimate the em- bedding for a rare word by exploiting different types of lexical knowledge encoded for it in the re- source. The definition centroid model of <ref type="bibr" target="#b17">Lazaridou et al. (2017)</ref> takes WordNet word glosses (def- initions) as semantic clue. An embedding is in- duced for an unseen word by averaging the content words' embeddings in its definition. <ref type="bibr">12</ref> The defi- nition LSTM strategy of <ref type="bibr" target="#b0">Bahdanau et al. (2017)</ref> extends the centroid model by encoding the def- inition using an LSTM network <ref type="bibr" target="#b14">(Hochreiter and Schmidhuber, 1997)</ref>, in order to better capture the semantics and word order in the definition. <ref type="bibr">SemLand (Pilehvar and Collier, 2017</ref>) also uses Word- Net, but takes a different approach which benefits from the graph structure of WordNet. For an un- seen word, SemLand extracts the set of its seman- tically related words from WordNet and induces an embedding for the unseen word by combining pre-trained embeddings for the related words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Subword models</head><p>Resource-based models fall short of inducing em- beddings for words that are not covered in the lex- ical resource. Subword models alleviate this limi- tation by breaking the word into its subword <ref type="bibr" target="#b26">(Pinter et al., 2017;</ref><ref type="bibr" target="#b3">Bojanowski et al., 2017)</ref> or mor- phological units ( <ref type="bibr" target="#b21">Luong et al., 2013;</ref><ref type="bibr" target="#b5">Botha and Blunsom, 2014;</ref><ref type="bibr" target="#b31">Soricut and Och, 2015)</ref> and in- duce an embedding by composing the informa- tion available for these. <ref type="bibr">FastText (Bojanowski et al., 2017</ref>) is one of the popular approaches of this type. The model first splits the unseen word into character ngrams (by default, 3-to 6-grams) and then computes the unseen word's embedding as the centroid of the embeddings of these char- acter n-grams (which are available as a result of a specific training). We also report results for Mim- ick ( <ref type="bibr" target="#b26">Pinter et al., 2017)</ref>, one of the most recent subword models. The technique learns a map- ping function from strings to embeddings by train- ing a Bi-LSTM network that encodes character se- quences of a word to its pre-trained embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental Setup</head><p>We report results for the five techniques discussed in Sections 5.2.2 and 5.2.1. We used two of the best performing embedding sets, i.e., Glove cased CC and ConceptNet Numberbatch, to train the models (except FastText for which we use the pre-trained WikiNews subword embeddings 13 ). In fact, the models were expected to provide im- provements over these baseline embeddings by filling their gaps for unseen words.</p><p>Mimick was trained with the default parame- ters, 14 except for the hidden units which we set to 100, instead of the original 50, since the tar- get embeddings in our experiments were larger (300d compared to 128d of the original model).</p><p>For the Definition LSTM model, the input defini- tions were represented as sequences of 50d word embeddings, encoded using an LSTM layer of 100 units, and then passed to a dense layer with 300 neurons with linear activation function. The train- ing was carried out with Mean Squared Error loss and the RMSprop optimizer, for 100 epochs with batch size 64.  <ref type="table">Table 5</ref>: Correlation performance of different rare and unseen word representation techniques on the Stanford RW and CARD-660 datasets (the best performance in each batch shown in bold; the overall best underlined). <ref type="table">Table 5</ref> reports the performance of different rare word representation techniques. Both pre-trained embeddings outperform the IAA of RW, with Glove covering 98% of the pairs. This severely limits the room for further meaningful experi- ments on the dataset. In contrast, on CARD-660 and similarly to the previous experiment, there are substantial gaps between IAA (cf. <ref type="table" target="#tab_2">Table 3</ref>) and the best-performing models: SemLand and Mim- ick, with the respective figures of 45.5 (r) and 53.3 (ρ). These gaps suggest a difficult dataset which can serve future research in subword and rare word representation as a reliable benchmark. The definition centroid model proves effective, despite its simplicity, whereas the WordNet-based SemLand provides the best results in most of the settings. Being constrained to the vocabulary of WordNet, the RW dataset does not constitute a challenging benchmark for WordNet-based mod- els, with most of them providing near full cover- age. However, these techniques are not as effec- tive on our dataset, with the best WordNet-based model still missing around 33% of the pairs (with Glove pre-trained embeddings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Experimental Results</head><p>The CARD-660 dataset also proves a very diffi- cult benchmark for subword models. Despite pro- viding near full coverage, these models are unable to consistently improve the pre-trained word em- bedding baseline. This would suggest that the sim- ple strategy of backing off to a word's characters might not always provide reliable means of esti- mating its semantics (e.g., the single-morpheme word galaxy, or the exocentric compound honey- moon). The results encourage further research on a more semantically-oriented handling of subwords, through learning more effective splitting and com- position techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Thanks to a carefully designed procedure and an expert-based curation, CARD-660 provides multi- ple advantages over existing benchmarks, includ- ing a very high IAA (average pairwise correlation of around 0.90). A series of experiments was car- ried out on the dataset, leading to two main con- clusions: (1) the dataset proved a very challenging benchmark, with the best pre-trained embedding model still missing around 40% of the word pairs and the best rare word representation model hardly crossing into 40.0s (correlation performance); and (2) knowledge-based models are not enough to provide high coverage whereas subword models, which provide near-full coverage, are not seman- tically as effective. The significant gap between state of the art and IAA (around 50.0) encourages future research to take this dataset as a challeng- ing, yet reliable, evaluation benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The distribution of word pairs across the four quartiles of the similarity scale for different datasets. A perfectly balanced dataset would have four equally sized slices.</figDesc><graphic url="image-2.png" coords="6,74.51,62.81,213.25,79.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Annotation variance for word pairs across different datasets. Average variance for CARD-660 is 1.47, which is significantly lower than those for SV3500 and RW: 5.64 and 6.34, respectively.</figDesc><graphic url="image-3.png" coords="6,82.68,218.31,196.92,168.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Embedding</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>The five-point Likert similarity scale used for the annotation of the dataset. 

Task. Resource 

Text classification. BBC (Greene and Cunningham, 
2006) 
Sentiment analysis. IMDB (Maas et al., 2011), Multi-
Domain Sentiment Dataset (Blitzer et al., 2007) 
Machine Translation. Europarl (Koehn, 2005) 
Question Answering. AQUA-RAT (Ling et al., 2017), 
SQuAD (Rajpurkar et al., 2016) 
BioMedical (entity recognition). JNLPBA corpus (Kim 
et al., 2004) 
Social media. Twitter 
Ontologies and online glossaries. WordNet, Wiktionary 
Named entities. Freebase (Bollacker et al., 2008) 
Veracity assessment. FakeNews 2 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Various datasets and resources used for rare 
word selection in CARD-660. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 reports</head><label>3</label><figDesc>IAA statistics for CARD-660. Thanks to the manual scoring of the pairs by ex- perts (as opposed to turkers), the IAA values for</figDesc><table>Mean 
Pairwise 

r 
ρ 
r 
ρ 

Initial 88.0±2.3 87.9±1.9 80.2±2.9 80.6±2.6 
Final 93.5±1.4 93.1±1.2 88.9±1.7 88.9±1.7 

</table></figure>

			<note place="foot" n="3"> The CARD-660 Dataset 3.1 Motivation Due to a lack of reliable evaluation benchmarks, research in rare word representation has often resorted to artificial experimental setups such as corpus downsampling (Sergienya and Schütze, 2015; Herbelot and Baroni, 2017; Lazaridou et al., 2017). To this end, in order to simulate a rare word scenario, the rare word representation model is provided with only a limited number of occurrences for the target set of words, for instance by means of replacing the dataset&apos;s words with some other sequences of characters (e.g., by augmenting &quot;UNK&quot;, such as &quot;skyglowUNK&quot; for &quot;skyglow&quot;) in the training corpus. The computed representations on the &quot;downsampled&quot; training data are then either evaluated on a standard word similarity dataset (Sergienya and Schütze, 2015), such as RG-65, or compared against reference embeddings computed on a large training corpus (Herbelot and Baroni, 2017; Lazaridou et al., 2017). However, due to the following three reasons, downsampling does not constitute a reliable 1 The scores are further pruned down to only those that were within one standard deviation of the mean. This results in a further imbalanced set of scores, making the computation of IAA more challenging.</note>

			<note place="foot" n="2"> http://www.fakenewschallenge.org</note>

			<note place="foot" n="3"> http://wordnetweb.princeton.edu/perl/webwn 4 www.wiktionary.org</note>

			<note place="foot" n="5"> SimVerb-3500 reports a pairwise ρ of 84.0; however, our calculation did not agree with this figure. Personal communication with the authors revealed an issue in the computation of their IAA. The correct figure is instead 61.2. 6 We are not able to report results for SimLex-999 since individual annotators&apos; scores are not released for this dataset.</note>

			<note place="foot" n="8"> https://nlp.stanford.edu/projects/glove/ 9 http://u.cs.biu.ac.il/ ∼ yogo/data/syntemb/deps.words.bz2 10 https://github.com/alexandres/lexvec 11 https://github.com/commonsense/ conceptnet-numberbatch</note>

			<note place="foot" n="12"> The original model is multimodal (text and images). Given that our focus is on texts, we follow Herbelot and Baroni (2017) and use the text modality only.</note>

			<note place="foot" n="13"> https://fasttext.cc/docs/en/english-vectors.html 14 https://github.com/yuvalpinter/Mimick/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We gratefully acknowledge the funding support of EPSRC (N. Collier and D. Kartsaklis-Grant No. EP/M005089/1) and MRC (M. T. Pilehvar) Grant No. MR/M025160/1 for PheneBank. We would also like to thank Andreas Chatzistergiou, Costanza Conforti, Gamal Crichton, Milan Gritta, and Ehsan Shareghi for their contribution in creat-ing the dataset.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Bosc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Learning to compute word embeddings on the fly. CoRR, abs/1706.00286</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The WaCky wide web: a collection of very large linguistically processed web-crawled corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Compositional Morphology for Word Representations and Language Modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Botha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1899" to="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multimodal distributional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semeval2017 task 2: Multilingual and cross-lingual semantic word similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taher</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval2017)</title>
		<meeting>the 11th International Workshop on Semantic Evaluation (SemEval2017)<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Placing search in context: The concept revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabrilovich</forename><surname>Evgenly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>Yossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rivlin</forename><surname>Ehud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solan</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfman</forename><surname>Gadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruppin</forename><surname>Eytan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions of Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Simverb-3500: A largescale evaluation set of verb similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Gerz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2173" to="2182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Practical solutions to the problem of diagonal dominance in kernel document clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pádraig</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd International Conference on Machine learning (ICML&apos;06)</title>
		<meeting>23rd International Conference on Machine learning (ICML&apos;06)</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">High-risk learning: acquiring new word vectors from tiny data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélie</forename><surname>Herbelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="304" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SimLex-999: Evaluating semantic models with (genuine) similarity estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="695" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Introduction to the bio-entity recognition task at JNLPBA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications</title>
		<meeting>the International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="70" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Europarl: A Parallel Corpus for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Proceedings: the tenth Machine Translation Summit</title>
		<meeting><address><addrLine>Phuket, Thailand. AAMT, AAMT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multimodal word meaning induction from minimal exposure to natural text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">S4</biblScope>
			<biblScope unit="page" from="677" to="705" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Judgment language matters: Multilingual vector space models for judgment language aware lexical semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno>abs/1508.00106</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Program induction by rationale generation: Learning to solve and explain algebraic word problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Yogatama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="158" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Better word representations with recursive neural networks for morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="104" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-HLT</title>
		<meeting>ACL-HLT<address><addrLine>Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
	<note>Portland</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop at ICLR</title>
		<meeting><address><addrLine>Scottsdale, Arizona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2014</title>
		<meeting>EMNLP 2014<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Inducing embeddings for rare and unseen words by leveraging lexical resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="388" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mimicking word embeddings using subword rnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Pinter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Guthrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="102" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Contextual correlates of synonymy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">B</forename><surname>Goodenough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="627" to="633" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Matrix factorization using window sampling and negative sampling for improved word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Salle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Villavicencio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Idiart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="419" to="424" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning better embeddings for rare words using distributional representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Sergienya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="280" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised morphology induction using word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT<address><addrLine>Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1627" to="1637" />
		</imprint>
	</monogr>
	<note>Denver</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ConceptNet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Measuring semantic similarity in the taxonomy of WordNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Powers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-eighth Australasian Conference on Computer Science</title>
		<meeting>the Twenty-eighth Australasian Conference on Computer Science<address><addrLine>Newcastle, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="315" to="322" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
