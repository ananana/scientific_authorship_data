<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:13+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Confidence-based Rewriting of Machine Translation Output</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Marie</surname></persName>
							<email>benjamin.marie@limsi.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
							<email>aurelien.max@limsi.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">LIMSI-CNRS</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Lingua et Machina</orgName>
								<address>
									<settlement>Le Chesnay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">LIMSI-CNRS</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Univ. Paris Sud</orgName>
								<address>
									<settlement>Orsay</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Confidence-based Rewriting of Machine Translation Output</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1261" to="1272"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Numerous works in Statistical Machine Translation (SMT) have attempted to identify better translation hypotheses obtained by an initial decoding using an improved, but more costly scoring function. In this work, we introduce an approach that takes the hypotheses produced by a state-of-the-art, reranked phrase-based SMT system , and explores new parts of the search space by applying rewriting rules selected on the basis of posterior phrase-level confidence. In the medical domain , we obtain a 1.9 BLEU improvement over a reranked baseline exploiting the same scoring function, corresponding to a 5.4 BLEU improvement over the original Moses baseline. We show that if an indication of which phrases require rewriting is provided, our automatic rewriting procedure yields an additional improvement of 1.5 BLEU. Various analyses, including a manual error analysis, further illustrate the good performance and potential for improvement of our approach in spite of its simplicity.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The standard configuration of modern phrase- based Statistical Machine Translation (SMT) ( <ref type="bibr" target="#b17">Koehn et al., 2003</ref>) systems can produce very ac- ceptable results on some tasks. However, early integration of better features to guide the search for the best hypothesis can result in significant im- provements, an expression of the complexity of modeling translation quality. For instance, im- provements have been obtained by integrating fea- tures into decoding that better model semantic co- herence at the sentence level <ref type="bibr" target="#b15">(Hasan and Ney, 2009)</ref> or syntactic well-formedness ( <ref type="bibr" target="#b32">Schwartz et al., 2011</ref>). However, early use of such complex features typically comes at a high computational cost. Moreover, some informative features require or are better computed when complete translation hypotheses are available. This is addressed in nu- merous works on reranking of the highest scored sub-space of hypotheses, on so-called n-best lists ( <ref type="bibr" target="#b40">Zhang et al., 2006;</ref><ref type="bibr" target="#b6">Carter and Monz, 2011</ref>) or output lattices ( <ref type="bibr" target="#b33">Schwenk et al., 2006;</ref><ref type="bibr" target="#b4">Blackwood et al., 2010)</ref>, where many works specifically target the inclusion of better language modelling capabilities, a well-known weakness of current automatic generation approaches <ref type="bibr" target="#b16">(Knight, 2007)</ref>.</p><p>Another way to improve translation a posteriori can be done by rewriting initial hypotheses, for in- stance in a greedy fashion by including new mod- els ( <ref type="bibr" target="#b18">Langlais et al., 2007;</ref><ref type="bibr" target="#b14">Hardmeier et al., 2012)</ref>, or by specifically modeling a task of automatic post-editing targeting a specific system <ref type="bibr" target="#b34">(Simard et al., 2007;</ref><ref type="bibr" target="#b11">Dugast et al., 2007)</ref>. While such auto- matic post-editing may seem to be too limited, no- tably because of the limited initial diversity con- sidered and the fact that it may be in some in- stances agnostic to the internals of the initial sys- tem, it has been shown to potentially improve ac- curacy of the new translation hypotheses ( <ref type="bibr" target="#b28">Parton et al., 2012</ref>) and to offer very high oracle perfor- mance <ref type="bibr" target="#b25">(Marie and Max, 2013)</ref>.</p><p>However, an important issue for such ap- proaches is their capacity to only rewrite incor- rect parts of the translation hypotheses and to use appropriate replacement candidates. Many works have tackled the issue of word to n-gram confi- dence estimation in SMT output ( <ref type="bibr" target="#b39">Zens and Ney, 2006</ref>; <ref type="bibr" target="#b37">Ueffing and Ney, 2007;</ref><ref type="bibr" target="#b3">Bach et al., 2011;</ref><ref type="bibr" target="#b10">de Gispert et al., 2013)</ref>, and some attempts have been made to exploit confidence estimates for lat- tice rescoring <ref type="bibr" target="#b4">(Blackwood et al., 2010)</ref> or n-best reranking ( <ref type="bibr" target="#b3">Bach et al., 2011;</ref><ref type="bibr" target="#b23">Luong et al., 2014b)</ref>.</p><p>In this work, we present an approach in which new complete hypotheses are produced by rewrit- ing existing hypotheses, and are scored using com- plex models that could not be used during the ini- tial decoding. We will use as competitive baselines systems that rerank the output of an initial decoder using the complete set of available features, and will show that we manage to improve their trans- lation. The difference between our approach and the reranking baseline lies in the manner in which we expand our training data, as well as in our use of high-confidence rewritings to obtain new trans- lation hypotheses. Importantly, this work will only exploit simple confidence estimates corresponding to phrase-based posteriors, which do not require that large sets of human-annotated data be avail- able as in other works ( <ref type="bibr" target="#b3">Bach et al., 2011;</ref><ref type="bibr" target="#b23">Luong et al., 2014b</ref>). The remainder of this paper is organized as fol- lows. Section 2 is devoted to the description of our approach, with details on our rewriting ap- proach (2.1), additional features (2.2), rewriting phrase table (2.3), and training examples (2.4). Section 3 presents experiments. We first describe our experimental setup (3.1) and our baseline sys- tems (3.2). We then report results when naive rewriting is performed and then with confidence- based rewriting (3.3). We next devote a significant part of the paper in section 4 to report further re- sults and analyses: an analysis of the performance of our system depending on the quality of initial hypotheses (4.1); a semi-oracle experiment where correct phrases are known (4.2); an oracle exper- iment where only correct rewriting decisions are made (4.3); a manual error analysis of the main configurations studied in this work (4.4); and, fi- nally, a study of the performance of our approach on a more difficult translation task (4.5). Related work is discussed in section 5 and we conclude and introduce our future work in section 6.</p><p>2 Description of the approach 2.1 Rewriting of translation hypotheses <ref type="bibr" target="#b18">Langlais et al (2007)</ref> proposed a greedy search procedure to improve translations by reusing the same translation table and scoring function that were used during an initial phrase-based decoding. In our approach, we rewrite hypotheses by using the same greedy search algorithm, adding more complex models and using the most-confident bi- phrases according to the initial decoder's search space. To select the hypothesis to rewrite for each sentence, we produce a n-best list of the ini- tial decoder and rerank this list with a new, bet- ter informed scoring function (see section 2.2). The one-best hypothesis obtained after rerank- ing is then rewritten by our system (denoted as rewriter). In this way, we ensure that the hy- pothesis that was rewritten had been so far the best one according to the initial decoding best sub- space and the new models used.</p><p>At each iteration, new hypotheses are obtained from a current hypothesis by applying one rewrit- ing operation on bi-phrases. The set of all new hy- potheses is called the neighborhood of the current hypothesis. Focusing in this work on local rewrit- ing, we used the following set of operations (N de- notes the number of bi-phrases, T the maximum number of entries per source phrase in a rewriting phrase table (see 2.3), and S the average number of tokens per source phrase) 1 :</p><p>1. replace (O(N.T )): replaces the transla- tion of a source phrase with another transla- tion from the rewriting phrase table;</p><p>2. split (O(N.S.T 2 )): splits a source phrase into all possible sets of two (contiguous) phrases, and uses replace on each of the resulting phrases;</p><p>3. merge (O(T.N )): merges two contiguous source phrases and uses replace on the re- sulting new phrase.</p><p>This rewriting algorithm is described in pseudo- code in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 rewriter Algorithm</head><p>Require: source a sentence to translate</p><formula xml:id="formula_0">nbestList ← TRANSLATE(source) oneBest ← RERANK(nbestList) sCurrent ← GET SCORE(oneBest) loop hypothesesSet ← NEIGHBORHOOD(oneBest) newOneBest ← RANK(hypothesesSet) s ← GET SCORE(newOneBest) if s ≤ sCurrent then return oneBest else oneBest ← newOneBest sCurrent ← s end if end loop</formula><p>The produced hypotheses are then ranked ac- cording to a new, better informed scoring function (see 2.2). At the next iteration, the hypothesis now ranked at the top of the list is rewritten, and search terminates when no better hypothesis is found.</p><p>Such a greedy search has several obvious lim- itations, in particular it can only perform a lim- ited exploration of the search space, a situation that can be improved by using a beam (see Sec- tion 3.3). However, associated with a small and precise rewriting phrase table, this approach only visits small numbers of more-confident hypothe- ses, which is a critical property given the cost of computing the new scoring function used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Reranking and features</head><p>The rerankings of the hypotheses sets de- scribe in this work are all performed with kb-mira (Cherry and Foster, 2012) using the ini- tial features set of the decoder in conjunction with the following additional features: 2</p><p>• SOUL models: SOUL models are structured output layer neural network language mod- els (LMs) which have been shown to be use- ful in reranking tasks, for instance for WMT evaluations <ref type="bibr">(Allauzen et al., 2013;</ref><ref type="bibr" target="#b29">Pécheux et al., 2014</ref>). SOUL scoring being too costly to be integrated during decoding, it fits perfectly the reranker scenario, which furthermore enables to use larger contexts for n-grams. We used both monolingual (Le et al., 2011) and bilingual ( <ref type="bibr" target="#b20">Le et al., 2012</ref>) SOUL 10-gram models, which were trained on the WMT'12 data.</p><p>• POS language model: part-of-speech (POS) LMs have been shown to yield improvements in n-best list reranking ( <ref type="bibr" target="#b6">Carter and Monz, 2011)</ref>. In this work, we trained a 6-gram POS LM using Witten-Bell smoothing.</p><p>• IBM1 : the IBM1 scores (p(e|f ) and p(f |e)) of the complete hypothesis ( ).</p><p>• phrase-based confidence score : bi-phrases are associated to a posterior probability, in- spired from n-gram posterior probability esti- mation as defined in (de <ref type="bibr" target="#b10">Gispert et al., 2013)</ref>. Let E be the set of all hypotheses in the space of translation hypotheses defined by the n-best list used for source sentence f , and E α be the subset of E such that word align- ments in sentence pairs (e , f ), ∀e ∈ E α , allow us to extract bi-phrase α. Let also H(e, f ) be the score assigned by a base- line decoder (denoted as 1-pass Moses henceforth) to sentence pair (e, f ). We use the following posterior probability for α:</p><formula xml:id="formula_1">P (α|F ) = e ∈Eα exp(H(e , f )) e ∈E exp(H(e , f ))<label>(1)</label></formula><p>Then, the logarithms of each phrase's con- fidence score are summed to use as a confi- dence score for the complete hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Rewriting phrase table</head><p>Taking the whole translation table of the decoder as a rewriting phrase table to perform the greedy search produces very large neighborhoods that rewriter cannot handle due to the cost of the models that have to be computed. We tried two different approaches to extract a rewriting phrase table from the translation table of the system. We first tried a naive approach where the rewrit- ing phrase table of rewriter for the test set uses the phrase table of 1-pass Moses, filtered to keep the k best entries according to the direct translation model. We denote such a configuration rptkpef.</p><p>Our second approach consists in extracting the rewriting phrase table containing bi-phrases that were the most probable according to the set of all models used in 1-pass Moses. Selection of bi- phrases for each sentence is done in a binary fash- ion, depending on their presence in k-best lists of 1-pass Moses for a given value of k. This con- figuration will be denoted confk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training examples</head><p>We tried several sets of examples to train the ranker of rewriter. We used the 1,000-best list of the development set produced by 1-pass Moses during its tuning. In other configurations we mixed a) the neighborhood of the reranker n-best hypotheses computed by our system on the development set using a rewriting phrase table containing the bi-phrases found in the k-best list produced by 1-pass Moses; and b) the neigh- borhood of the one-best hypotheses of reranker using a rewriting phrase table containing the 10- best translations from the 1-pass Moses trans- lation table according to the direct translation model. Both neighborhoods are produced by a single iteration of rewriter. We denote re- spectively these sets of hypotheses n-bestNeigh and 10PefNeigh. Our intuition behind the consti- tution of these training sets is that the ranker of rewriter needs, in order to perform well, train- ing examples that will be similar to hypotheses that it actually generates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental setup</head><p>We used two datasets from two different domains: the data provided for the WMT'14 medical trans- lation task <ref type="bibr">3</ref> (Medical) and a smaller task using the TED talks 4 (TED Talks) data of the IWSLT evaluation campaigns. For the Medical task we used only the English to French translation di- rection, and both translation directions, English to French and French to English, for the TED Talks task. In this work, the main part of our ex- periments uses Medical, and TED Talks will be used at a later stage to study a lower-quality situation (cf. 4.5). For the Medical task, initial decodings were produced using a LM trained on all WMT'14 monolingual and bilingual medical data, while for the TED Talks task we used a much larger LM trained on all the data provided for WMT'13 5 . Both are 4-gram LMs estimated with Kneser-Ney smoothing <ref type="bibr" target="#b7">(Chen and Goodman, 1998</ref>). For the 6-gram POS LMs used (see 2.2), we used the same data as used for the token-based LM for Medical, and the concatenation of the News Commentaries and Europarl sub-parts of the WMT'13 data for TED Talks.  <ref type="table" target="#tab_0">Table 1</ref>: Corpora used in this work.</p><p>We first built a state-of-the-art phrase-based SMT system using Moses ( <ref type="bibr" target="#b17">Koehn et al., 2003</ref>) with standard settings. We tuned its parameters to- wards BLEU ( <ref type="bibr" target="#b27">Papineni et al., 2002</ref>) on the tuning dataset using the kb-mira implementation avail- able in Moses with default parameters.</p><p>Our results will be compared using BLEU and TER <ref type="bibr" target="#b35">(Snover et al., 2006</ref>) to a) the initial best translation produced by the Moses decoder (1-pass Moses) and b) the best translation ob- tained by reranking the 1,000-best list of 1-pass Moses (reranker). Since reranker imple- ments a well-documented approach and uses types of features commonly used in reranking tasks we will consider it as our main baseline. It was trained using kb-mira on the 1,000-best of the develop- ment data decoded by 1-pass Moses.</p><p>In our experiments, rewriter rewrites the one-best hypothesis 6 produced by reranker using the operators Replace, Split and Merge as described in section 2.1. <ref type="table" target="#tab_2">Table 2</ref> gives the results of the 1-pass Moses decoding for the Medical task and the rerank- ing results of reranker applied to the 1-pass Moses 1,000-best list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline results</head><p>1-pass Moses obtains a score of 38.2 BLEU on the test set, which can be considered as a good baseline system. 7 reranker outper- forms 1-pass Moses by 3.5 BLEU, indicating a strong performance of the features used on this task. In particular, SOUL is known to be a use- ful feature for reranking n-best lists on highly- inflected languages such as French. Note also that the SOUL models we used were trained on the WMT'12 monolingual and bilingual data and so were better informed than the models used dur- ing the 1-pass Moses decoding. <ref type="bibr">8</ref> Moreover, as can be seen on <ref type="figure" target="#fig_0">Figure 1</ref>, the 1,000-best ora- cle reveals a large potential for improvement over the one-best (+12.4 BLEU). We further observe that the reranked list of reranker shows a much faster potential for translation improvement. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">rewriter results</head><p>Results for the different rewriting phrase tables and training examples are given in <ref type="table" target="#tab_2">Table 2</ref>. First, concerning the rewriting phrase table, for the k=5 (rpt5pef) and k=10 (rpt10pef) con- figurations 9 a decrease of 0.7-0.8 BLEU over reranker is obtained. This illustrates that naive rewritings applied on the test set cannot be used with our training regime to improve translation quality.</p><p>In the next experiments, we used a confk rewriting table. <ref type="table" target="#tab_0">Table 2 10</ref> shows the results of rewriter when rewriting the one-best hypothe- sis from reranker for various values of k to de- fine the k-best list from which the rewriting table is built. Various training sets are also considered in the table.</p><p>The 1-pass Moses 1,000-best configuration reused the same set of hypotheses used to train reranker. For this configuration, rewriter loses 2.6 BLEU over reranker on the test set with conf10k. Of course, this training data set is of a quite different nature compared to the hy- potheses built by rewriter.</p><p>In the 10pefNeigh training, the ranker is trained with the neighborhoods produced by the first itera- tion of rewriter on the development set with a rewriting phrase table containing only the k-best translations for each source phrase according to the direct translation model. This configuration <ref type="bibr">9</ref> We did not experiment with higher values of k because of the computationnal cost of the features used by reranker. Indeed, adding more phrase translations increases the size of the neighborhoods corresponding to many additional n-grams to score by SOUL, the most expensive model. <ref type="bibr">10</ref> In <ref type="table" target="#tab_2">Table 2</ref> the number of unique bi-phrases for the rpt rewriting phrase tables is computed by considering only source phrases appearing in the test set, for the n-best Neigh- borhood configurations we merged the phrase tables of each sentence into one and count just as one unique entry bi- phrases appearing several times.</p><p>improves over the previous one by 1.7 BLEU, but is still 0.9 BLEU below reranker. Adding the neighborhoods of the reranker n-best hypothe- ses produced with a conf10k rewriting phrase table to the training data does not improve over the previous situation for n = 10, but increasing n to 30 and then 50 produces strong improvements on the test set (resp. +1.4 and +1.6 BLEU). Con- sidering a larger neighborhood obtained by rewrit- ing the best n = 90 hypotheses does not yield further gains. We denote from now on opti our best configuration thus far, considering the performance on the development set and having the largest confidence-based rewriting phrase ta- ble considered.</p><p>Letting rewriter perform a beam search on the 10-best hypotheses of the test set, further gains are obtained, corresponding now to an improve- ment of +1.9 BLEU over our reranker base- line, or +5.4 BLEU over 1-pass Moses. 11 Fur- thermore, although taking the bi-phrases from the 10,000-best is our best configuration, it is inter- esting to note that taking bi-phrases from the 10- best only already yields a moderate improvement of +0.6 BLEU over reranker. <ref type="figure" target="#fig_2">Figure 2a</ref> shows that up to k = 10, 000 higher value of k to ex- tract the rewriting phrase table increase the BLEU score on the test set. <ref type="bibr">12</ref> We did not experiment with higher values of k, but plan to use the output lat- tice produced by 1-pass Moses to compute ef- ficiently posteriors for larger sets of bi-phrases (de <ref type="bibr" target="#b10">Gispert et al., 2013)</ref>.</p><p>As illustrated on <ref type="figure" target="#fig_2">Figure 2b</ref>, rewriter mostly improves the BLEU score during the three first iterations and then converges at the ninth iteration. However, it is important to note that not all sentences are actually improved by our system. As illustrated on <ref type="figure" target="#fig_3">Figure 3a</ref>, opti improves 40.8% of the sentences of the test set but degrades 29.2% of them according to sentence-BLEU ( <ref type="bibr" target="#b21">Lin and Och, 2004</ref>). It is certainly the case that more informative confidence features may help idenfity more precisely which fragments of the translations should really undergo rewriting. We will investigate the exploitation of an oracle phrase-based confidence measure in Section 4.2.     The first question we address in our analysis of rewriter is whether its performance depends on the difficulty of each individual sentence. As a proxy of sentence difficulty we used sentence- BLEU of 1-pass Moses, and used it to di- vide the sentences of the test set into quartiles. <ref type="figure" target="#fig_4">Figure 4</ref> shows that reranker improves more over 1-pass Moses and that at the same time rewriter improves more over reranker as the sentences are more difficult. In particular, rewriter obtains a 8.6 BLEU improvement over 1-pass Moses on the more difficult quar- tile, but only a 1.3 BLEU improvement on the least difficult quartile. We hypothesize that better per- formance may be achieved if adapting the training and rewriting of rewriter to sentences of vary- ing quality, which may, for instance, be estimated with off-the-shelf estimators (Specia et al., 2013).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Semi-oracle experiments: rewriting only incorrect fragments</head><p>We observed in section 3.3 that our opti con- figuration, which obtains strong improvements in translation quality (as given by corpus-BLEU), in fact degrades (as given by sentence-BLEU) a significant proportion of sentences. To fur- ther analyze these results, we simulate a situa- tion where oracle confidence information is avail- able at the phrase-level: in particular, rewriter is prevented from rewriting bi-phrases whose tar- get phrase appears exactly in the reference transla-  tion. 13 Furthermore, this "freezing" of bi-phrases can be repeated after each iteration of rewriter. Thus, we now have an oracle situation for choosing which source phrases may be rewrit- ten, but the rest of the rewriting procedure is still fully automatic. Moreover, we purposefully did not adapt the training procedure to this new configuration, and reused opti as is. Results, reported in <ref type="table">Table 3</ref>, indicate that an additional 1.5 BLEU is obtained from opti, or 3.1 BLEU from reranker and 6.6 BLEU from 1-pass Moses. The use of a larger beam of size 10 did not improve those results any further. At the first iteration, rewriter "froze" approx- imatively 65.6% of the bi-phrases, and 70.5% at the last iteration, demonstrating the ability of rewriter to find good rewritings that match the reference translation. Looking at <ref type="figure" target="#fig_3">Figure 3b</ref>, we now find that, as expected, only a limited num- ber of sentences are now degraded by rewriter. The large improvements obtained clearly under- lines the important role that better confidence esti- mates could play in our framework.  <ref type="table">Table 3</ref>: Results for the semi-oracle using opti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Oracle experiments: making only the correct decisions</head><p>We now turn to the situation where only rewrit- ings that actually improve translation performance would be made. In practice, we use a sim- ple solution: we resort to greedy oracle search (GOS) <ref type="bibr" target="#b25">(Marie and Max, 2013)</ref>, where sentence- BLEU is maximized using rewritings from the opti phrase table. At each iteration the rewrit- ing in the neighborhood that maximizes sentence- BLEU is selected until convergence. Results for this greedy search oracle appear in the last column of <ref type="table" target="#tab_2">Table 2</ref> and allow us to put in perspective the individual potential of the var-ious tested configurations. We can first notice that the rpt5pef phrase table allows the ora- cle to reach 50.6 BLEU, 8.1 BLEU below the oracle value obtained with conf10k, although rpt5pef contains twice as many bi-phrases. The same conclusion can be made about rpt10pef, which is 3.9 BLEU higher than rpt5pef but con- tains nearly twice as many bi-phrases. Finally, al- though conf10k contains approximatively four times fewer bi-phrases than rpt10pef, its ora- cle value is 4.2 BLEU higher. This points out the fact that conf10k is a lot more precise rewrit- ing phrase table for the translations to rewrite, as well as the fact that rpt5pef and rpt10pef are much noisier and consequently difficult to use efficiently by our automatic rewriting procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Manual error analysis</head><p>In the previous sections, we have shown that our automatic rewriting procedure can improve trans- lation quality over both an initial Moses baseline, and a reranked baseline using the same features as our procedure. We have further shown in sec- tion 4.3 that much larger improvements could be obtained by using an oracle procedure.</p><p>We now focus on the four following con- figurations:</p><p>1-pass Moses, reranker, rewriter and GOS. Although this four configu- rations are well separated both in terms of BLEU and TER scores, it is informative to look more precisely into what makes their results different. We performed a small-scale manual error analysis of these four configurations. A French native speaker annotated 70 translation hypotheses using an error typology adapted from <ref type="bibr" target="#b38">(Vilar et al., 2006</ref>).</p><p>Results of the manual error analysis are re- ported in <ref type="table" target="#tab_5">Table 4</ref>. The most significant results are for the disamb(iguation) and form error types, the former being more related to translation accu- racy, and the later to fluency. In both cases, we first observe a strong reduction of errors between 1-pass Moses and reranker, which demon- strates the positive impact of the features used on these levels. Then, another, similar reduction is obtained between reranker and rewriter, demonstrating that our reranking procedure man- ages to identify more precise and fluent hypothe- ses. Finally, a further reduction is found between rewriter and GOS, indicating that our proposed local, greedy rewriting can still be improved, no- tably by using more informative features and bet- ter confidence estimates.</p><p>The other types of error categories are less in- formative. We find no clear differences in er- ror types attributable to style issues, which seem to be irrecoverable even for GOS. reranker and rewriter both improve on order-related er- rors over 1-pass Moses, but our local rewrit- ing unsurprisingly did not fix any of these errors. Finally, reranker and rewriter decreased slightly the number of extra words from 1-pass Moses, while GOS sometimes artificially intro- duces extra words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Lower-quality SMT experiments</head><p>We now turn to the question of how our rewrit- ing system fares on a more difficult task, and used TED Talks, 6 BLEU below Medical for the English to French direction, for this purpose. In the same way as we did for Medical, we first tried to find the best training configuration for the ranker of the rewriting system. For this task, mix- ing the n-best neighborhood and 10pefNeigh with n=10 seemed to be sufficient to have no more im- provement on the development set by increasing n for both language directions, so we used this train- ing configuration. As for the rewriting phrase table used on the test set, we simply selected conf10k as in the Medical task. Results are reported in <ref type="table">Table 5</ref> for French to English and English to French.</p><p>We first observe that reranker performed similarly for the two translation directions, by improving 1-pass Moses by 0.5 BLEU. The smaller improvements may be partly attributed to the better LM used in 1-pass Moses, implying a better early modeling of grammaticality, but also by the fact that models such as SOUL and POS LMs rely on accurate contexts and are therefore more apt to help in choosing translations among generally better candidates.</p><p>Finally, rewriter obtains smaller but consis- tent improvements over reranker: +0.4 BLEU for translation into English, and +0.9 BLEU for translation into French. The smaller improvement in the former situation may be attributed to the na- ture of the target language which has a simpler agreement system. Consequently, the form-related errors discussed in Section 4.4 are possibly less subject to improvement here.    <ref type="table">Table 5</ref>: Results for the baselines, our best configuration and the semi-oracle for the TED Talks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Reranking of translation hypotheses n-best list reranking was extensively studied in ), using features not used in the initial decoder such as IBM1 scores (which also proved useful for word-level confidence estimation ( <ref type="bibr" target="#b5">Blatz et al., 2004)</ref>) and generative syntactic models. While the experiments in ( ) did not show any clear contribution of syntactic in- formation used in this manner, the later work by <ref type="bibr" target="#b6">Carter and Monz (2011)</ref> managed to successfully exploit syntactic features using discriminative lan- guage modeling for n-best reranking. <ref type="bibr" target="#b13">Gimpel et al. (2013)</ref> outperformed n-best reranking by gen- erating, with an expensive but simple method, di- verse hypotheses used as training data. Recently, <ref type="bibr" target="#b23">Luong et al. (2014b)</ref> reranked n-best lists using confidence scores at the hypothesis level com- puted from word-level confidence measures learnt from roughly 10,000 SMT system outputs anno- tated by humans. <ref type="bibr" target="#b18">Langlais et al. (2007)</ref> described a greedy search decoder, first introduced in ( <ref type="bibr" target="#b12">Germann et al., 2001</ref>), able to improve translations produced by a dynamic pro- gramming decoder using the same scoring func- tion and translation table. However, the more re- cent work by <ref type="bibr" target="#b1">Arun et al. (2010)</ref> using a Gibbs sampler for approximating maximum translation decoding showed the adequacy of the approxima- tions made by state-of-the-art decoders for finding the best translation in their search space. Other works were more directly targeted at automatic post-editing of SMT output, and approached the problem as one of second-pass translation be- tween automatic predictions and correct transla- tions ( <ref type="bibr" target="#b34">Simard et al., 2007;</ref><ref type="bibr" target="#b11">Dugast et al., 2007)</ref>. The recent work of <ref type="bibr" target="#b41">Zhu et al. (2013)</ref> attempts to repair translations by exploiting confidence esti- mates for examples derived from the similarity between source words in the input text and in training examples. <ref type="bibr" target="#b22">Luong et al. (2014a)</ref> obtained improvements by computing word confidence es- timation, trained on human annotated data, and large sets of lexical, syntactic and semantic fea- tures, for the words in the n-best list produced during a first-pass decoding, and performing a second-pass decoding exploiting these new scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rewriting of translation hypotheses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidence estimation of Machine Translation</head><p>The Word Posterior Probability (WPP) proposed by <ref type="bibr" target="#b37">Ueffing and Ney (2007)</ref>, derived from informa- tion from the n-best list produced by a decoder, proved to be useful for estimating word-level con- fidence. <ref type="bibr" target="#b3">Bach et al. (2011)</ref> worked on the issue of predicting sentence-level and word-level MT errors by using WPP and other features derived from the source context, the source-target align- ment, and dependency structures, but relied on a significantly large manually annotated corpus of MT errors. De <ref type="bibr" target="#b10">Gispert et al. (2013)</ref> calculate k-gram posterior probabilities from n-best lists or word lattices, and demonstrated that they were rea- sonably accurate indications of whether specific k- grams would be found or not in human reference translations. Finally, the work of <ref type="bibr" target="#b4">Blackwood et al. (2010)</ref> proposed to segment translation lattices according to confidence measures over the maxi- mum likelihood translation hypothesis to focus on regions with potential translation errors. Hypothe- sis space constraints based on monolingual cover- age are then applied to the low confidence regions to improve translation fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and perspectives</head><p>In this paper, we have described an approach that improves translations a posteriori by applying simple local rewritings. We have shown that the quality of phrase-level confidence estimates has a direct impact of the amplitude of the improve- ments that can be obtained, as well as the initial quality of the rewritten hypotheses. We have used a very simple definition for confidence estimates under the form of phrase posteriors estimated from n-best lists from an initial decoder, which obtained good empirical performance, in spite of not requir- ing large human-annotated datasets as in other ap- proaches ( <ref type="bibr" target="#b3">Bach et al., 2011;</ref><ref type="bibr" target="#b23">Luong et al., 2014b)</ref>.</p><p>Our work could be extended in several direc- tions. First, we could use a larger set of rewrit- ing operations ( <ref type="bibr" target="#b18">Langlais et al., 2007)</ref>, including the rewrite (sic) operation introduced in <ref type="bibr" target="#b25">(Marie and Max, 2013</ref>) that paraphrases source phrases and then translates them.</p><p>We could also possibly consider any phrase seg- mentation compatible with a specific word align- ment rather than rely on specific phrase segmenta- tions. This would allow us to attain faster some rewritings that could otherwise require several rewriting iterations and may never be attained by the greedy procedure.</p><p>More features could also be used, for instance to model more fine-grained syntax <ref type="bibr" target="#b31">(Post, 2011)</ref> or document-level lexical coherence <ref type="bibr" target="#b14">(Hardmeier et al., 2012</ref>). However, anticipating that some features might be very expensive to compute, we could adapt our procedure to work in several passes: initial passes would tend to restrict the search space more and more using an initial set of features, before a more expensive pass would concentrate on a limited number of hypotheses. <ref type="figure" target="#fig_0">Figure 1</ref> indeed already showed a much faster or- acle improvement between 1-pass Moses and reranker for n-best list of small sizes.</p><p>Another avenue for improvement lies in the pos- sibility to perform the training of our rewriter by providing it with more reference translations. As these are typically not readily available, we could resort to targeted paraphrasing <ref type="bibr" target="#b24">(Madnani and Dorr, 2013)</ref> to rewrite reference translations into acceptable paraphrases that reuse n-grams from the best hypotheses of the system so far. Contrarily to <ref type="bibr" target="#b24">(Madnani and Dorr, 2013)</ref>, we could bias the paraphrasing table so that it only con- tains paraphrases that correspond to target phrases of high confidence values, which would add new n-grams likely of being produced by rewriter.</p><p>It is furthermore worth noticing that our work proposes a potential answer to an original ques- tion: contrarily to typical works on sub-sentencial MT confidence estimation, which predict whether a word or phrase is correct or not, our rewriter system could be used to determine automatically whether a rewriting system could (if asked to) at- tempt to improve locally a translation, or whether a human post-editor should already tackle work- ing on improving it. As we showed in our manual error analysis in section 4.4, there are in fact many instances of errors that could not be recovered by our approach, be it because of its local rewriting strategy or of the bilingual resources or models used, so that some knowledge would have to be provided as hard constraints by a human transla- tor, as hinted in ( <ref type="bibr" target="#b9">Crego et al., 2010</ref>). We could then finally have our rewriter system work in a turn-based fashion in collaboration with a human translator, fixing errors or making improvements that are being made possible by the last edits from the translator.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: n-best list oracle for 1-pass Moses and reranker</figDesc><graphic url="image-1.png" coords="5,72.00,62.81,226.76,108.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(</head><label></label><figDesc>a) Results of rewriter with rpt5pef, rpt10pef and dif- ferent values of k for confk (b) Iterations of rewriter on test with opti and two beam sizes : 1 and 10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance of rewriter depending on the type of the rewriting phrase table and the number of iterations and beam sizes.</figDesc><graphic url="image-3.png" coords="6,312.19,62.81,204.09,112.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: sBLEU delta, for each sentence, between the reranker one-best to rewrite and its automatic (3a) or semi-oracle (3b) rewriting computed by rewriter with the opti configuration.</figDesc><graphic url="image-6.png" coords="7,90.43,281.70,181.42,181.81" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Source sentences were divided into quartiles according to sBLEU of the 1-pass Moses system. For each quartile we reported the performance of 1-pass Moses, reranker, rewriter, GOS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>semi-oracle, beam 1 44.9 (+1.5) 39.2 (−1.2) semi-oracle, beam 10 44.9 (+1.5) 39.0 (−1.4)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 provides relevant statistics about the data used.</head><label>1</label><figDesc></figDesc><table>Tasks 
Corpus Sentences Tokens (en-fr) 

Medical 
train 
4.9M 
78M -91M 
dev 
500 
10k -12k 
test 
1,000 
21k -26k 
LM 
-146M 

TED Talks 
train 
107 758 
2M -2.2M 
dev 
934 
20k -20k 
test 
1,664 
31k -34k 
LM 
6B -2.5B 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>table and the</head><label>and</label><figDesc></figDesc><table>number 
of iterations and beam sizes. 

baseline 
dev 
test 
BLEU 
BLEU 
TER 
GOS BLEU 

1-pass Moses 
40.9 
38.3 
44.6 
reranker 
44.1 
41.8 
41.6 

training data 
rewriting 
unique 
beam 
phrase table bi-phrases 
size 

1-pass Moses 1 000-best 
conf10k 
38 455 
1 
44.1 
39.2 (−2.6) 43.8 (+2.2) 
58.7 

10pefNeigh 
conf10k 
38 455 
1 
43.9 
40.9 (−0.9) 41.2 (−0.4) 
58.7 
10-bestNeigh + 10pefNeigh 
conf10k 
38 455 
1 
43.8 
40.9 (−0.9) 41.2 (−0.4) 
58.7 
30-bestNeigh + 10pefNeigh 
conf10k 
38 455 
1 
44.2 
43.2 (+1.4) 40.6 (−1.0) 
58.7 
50-bestNeigh + 10pefNeigh 
rpt5pef 
85 530 
1 
44.5 
41.0 (−0.8) 42.0 (+0.4) 
50.6 
= 
rpt10pef 
149 887 
1 
44.5 
41.1 (−0.7) 42.1 (+0.5) 
54.5 
= 
conf10 
21 398 
1 
44.5 
42.4 (+0.6) 41.0 (−0.6) 
45.9 
= 
conf100 
28 730 
1 
44.5 
42.9 (+1.1) 40.8 (−0.8) 
50.2 
= 
conf1k 
33 929 
1 
44.5 
43.0 (+1.2) 40.6 (−1.0) 
53.3 
= (opti) 
conf10k 
38 455 
1 
44.5 
43.4 (+1.6) 40.4 (−1.2) 
58.7 
= 
conf10k 
38 455 
10 
44.5 
43.7 (+1.9) 40.1 (−1.5) 
59.6 
90-bestNeigh + 10pefNeigh 
conf10k 
38 455 
1 
44.4 
43.4 (+1.6) 40.4 (−1.2) 
58.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Results on Medical for different training configurations, rewriting phrase tables and beam sizes. opti denotes our optimal configuration for rewriter.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results for manual error analysis for the first 70 test sentences. 

System 
fr-en 
en-fr 
BLEU 
TER 
BLEU 
TER 

1-pass Moses 
32.5 
47.7 
32.3 
49.9 
reranker 
33.0 
47.3 
32.8 
49.4 

rewriter 
33.4 (+0.4) 47.4 (+0.1) 33.7 (+0.9) 49.3 (−0.1) 
semi-oracle 34.1 (+1.1) 46.6 (−0.7) 34.2 (+1.4) 48.6 (−0.8) 

</table></figure>

			<note place="foot" n="1"> Complexity is expressed in terms of the maximum number of hypotheses that will be considered given some hypothesis to rewrite.</note>

			<note place="foot" n="2"> Note that we did not try to explore the independant contribution of each feature in this work.</note>

			<note place="foot" n="3"> http://www.statmt.org/wmt14/ medical-task/ 4 https://wit3.fbk.eu/mt.php?release= 2013-01 5 http://www.statmt.org/wmt13</note>

			<note place="foot" n="6"> Note that we will also provide results where a beam of k-best hypotheses are rewritten. 7 Distribution of error types on a sub-part of the test set will be provided in section 4.4. 8 However, SOUL considers only a small sample of the training data for training. For instance, the training of the French monolingual model used roughly only 1% (895K sentences) of all the WMT&apos;12 data.</note>

			<note place="foot" n="11"> Using a beam becomes quickly prohibitive: using 12 threads, 25 mn vs. 3h were needed for the test set for the configurations of size 1 and 10, respectively. 12 Note that even for k = 10, 000 the computed neighborhoods are still quite small with an average of 116 hypotheses for each hypothesis to rewrite per iteration, against an average of 788 hypotheses for the rpt10pef configuration.</note>

			<note place="foot" n="13"> This is obviously not an optimal solution.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank the anonymous re-viewers and Guillaume Wisniewski for their use-ful remarks. Additional thanks go to Hai Son Le for "anticipating" the need for a large and effi-cient cache in his SOUL implementation, Quoc Khanh Do for his assistance on using SOUL, and Li Gong and Nicolas Pécheux for providing the authors with data used in the experiments. The work of the first author is supported by a CIFRE grant from French ANRT.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hai-son Le, and François Yvon. 2013. LIMSI @ WMT13</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Pécheux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">Khanh</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Dinarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Monte Carlo inference and maximization for phrasebased translation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Goodness: A Method for Measuring Machine Translation Confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fluency Constraints for Minimum Bayes-Risk Decoding of Statistical Machine Translation Lattices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Blackwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Confidence Estimation for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simona</forename><surname>Gandrabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Alberto Sanchis, and Nicola Ueffing</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Syntactic Discriminative Language Model Rerankers for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="339" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An Empirical Study of Smoothing Techniques for Language Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
		<idno>TR-10-98</idno>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Group, Harvard University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Batch Tuning Strategies for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Local lexical adaptation in Machine Translation through triangulation: SMT helping SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Josep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">N-gram posterior probability confidence measures for statistical machine translation: an empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Adrì A De Gispert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Blackwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="114" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Statistical Post-Editing on SYSTRANs Rule-Based Translation System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo¨ıclo¨ıc</forename><surname>Dugast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fast Decoding and Optimal Decoding for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jahr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Systematic Exploration of Diversity in Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Seatlle, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Document-Wide Decoding for PhraseBased Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorg</forename><surname>Tiedeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Comparison of Extended Lexicon Models in Search and Rescoring for SMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saša</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>short papers</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Automatic Language Translation Generation Help Needs Badly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT Summit (invited talk)</title>
		<meeting><address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Statistical Phrase-Based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Greedy Decoder for Phrase-Based Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Patry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Gotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference on Theoretical and Methodological Issues in Machine Translation (TMI)</title>
		<meeting>Conference on Theoretical and Methodological Issues in Machine Translation (TMI)<address><addrLine>Skovde, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structured Output Layer Neural Network Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Son</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Oparin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeanluc</forename><surname>Gauvain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP</title>
		<meeting>ICASSP<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Continuous Space Translation Models with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Son</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">ORANGE: a method for evaluating automatic evaluation metrics for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An Efficient Two-Pass Decoder for SMT Using Word Confidence Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Quang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lecouteux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EAMT</title>
		<meeting>EAMT<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Word Confidence Estimation for SMT N-best List Re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Quang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Besacier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lecouteux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Humans and Computer-assisted Translation (HaCaT)</title>
		<meeting>the Workshop on Humans and Computer-assisted Translation (HaCaT)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generating Targeted Paraphrases for Improved Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology, special issue on Paraphrasing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A Study in Greedy Oracle Improvement of Translation Hypotheses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Max</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT</title>
		<meeting>IWSLT<address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Smorgasbord of Features for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Eng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Boston, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BLEU: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Can Automatic Post-editing Make MT more Meaningful?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Parton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Gispert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EAMT</title>
		<meeting>EAMT<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Pécheux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">Khanh</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Ivanishcheva</surname></persName>
		</author>
		<idno>LIMSI @ WMT&apos;14</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Aurélien Max, and François Yvon</publisher>
			<pubPlace>Alexander Allauzen, Thomas Lavergne</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Medical Translation Task</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>Baltimore, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Judging Grammaticality with Tree Substitution Grammar Derivations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, short papers</title>
		<meeting>ACL, short papers<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Incremental Syntactic Language Models for Phrase-based Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lane</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Continuous Space Language Models for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Déchelotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Luc</forename><surname>Gauvain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
		<meeting>COLING-ACL<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Statistical Phrase-based Post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Isabelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL<address><addrLine>Rochester, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Study of Translation Edit Rate with Targeted Human Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AMTA</title>
		<meeting>AMTA<address><addrLine>Cambridge, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">QuEst-A Translation Quality Estimation Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">G C</forename><surname>De Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL, System Demonstrations</title>
		<meeting>ACL, System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">WordLevel Confidence Estimation for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Ueffing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Error Analysis of Statistical Machine Translation Output</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Fernando D&amp;apos;haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">N-Gram Posterior Probabilities for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WMT</title>
		<meeting>WMT<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distributed Language Modeling for Nbest List Re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Almut</forename><surname>Silja Hildebrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Repairing Incorrect Translation with Examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junguo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP<address><addrLine>Nagoya, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
