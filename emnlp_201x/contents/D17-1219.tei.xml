<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:22+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Where to Focus in Reading Comprehension for Neural Question Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Where to Focus in Reading Comprehension for Neural Question Generation</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="2067" to="2073"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>A first step in the task of automatically generating questions for testing reading comprehension is to identify question-worthy sentences, i.e. sentences in a text passage that humans find it worthwhile to ask questions about. We propose a hierarchical neural sentence-level sequence tagging model for this task, which existing approaches to question generation have ignored. The approach is fully data-driven-with no sophisticated NLP pipelines or any hand-crafted rules/features-and compares favorably to a number of base-lines when evaluated on the SQuAD data set. When incorporated into an existing neural question generation system, the resulting end-to-end system achieves state-of-the-art performance for paragraph-level question generation for reading comprehension .</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>Automatically generating questions for test- ing reading comprehension is a challenging task ( <ref type="bibr" target="#b15">Mannem et al., 2010;</ref><ref type="bibr" target="#b21">Rus et al., 2010</ref>). First and foremost, the question generation system must determine which concepts in the associated text passage are important, i.e. are worth asking a ques- tion about.</p><p>The little previous work that exists in this area currently circumvents this critical step in passage- level question generation by assuming that such sentences have already been identified. In par- ticular, prior work focuses almost exclusively on sentence-level question generation: given a text passage, assume that all sentences contain a question-worthy concept and generate one or more questions for each <ref type="bibr" target="#b10">(Heilman and Smith, 2010;</ref><ref type="bibr" target="#b8">Du et al., 2017;</ref><ref type="bibr" target="#b27">Zhou et al., 2017)</ref>.</p><p>In contrast, we study the task of passage-level question generation (QG). Inspired by the large body of research in text summarization on iden- tifying sentences that contain "summary-worthy" content (e.g. <ref type="bibr" target="#b16">Mihalcea (2005)</ref>, <ref type="bibr" target="#b1">Berg-Kirkpatrick et al. (2011)</ref>, ), we develop a method to identify the question-worthy sen- tences in each paragraph of a reading compre- hension passage. Inspired further by the success of neural sequence models for many natural lan- guage processing tasks (e.g. named entity recog- nition <ref type="bibr" target="#b5">(Collobert et al., 2011</ref>), sentiment classi- fication ( <ref type="bibr" target="#b23">Socher et al., 2013)</ref>, machine transla- tion ( <ref type="bibr" target="#b24">Sutskever et al., 2014</ref>), dependency pars- ing <ref type="bibr" target="#b2">(Chen and Manning, 2014)</ref>), including very re- cently document-level text summarization <ref type="bibr" target="#b4">(Cheng and Lapata, 2016)</ref>, we propose a hierarchical neural sentence-level sequence tagging model for question-worthy sentence identification.</p><p>We employ the SQuAD reading comprehen- sion data set ( <ref type="bibr" target="#b20">Rajpurkar et al., 2016</ref>) for evalua- tion and show that our sentence selection approach compares favorably to a number of baselines in- cluding the feature-rich sentence selection model of <ref type="bibr" target="#b4">Cheng and Lapata (2016)</ref> proposed in the con- text of extract-based summarization, and the con- volutional neural network model of <ref type="bibr" target="#b12">Kim (2014)</ref> that achieves state-of-the-art results on a variety of sentence classification tasks.</p><p>We also incorporate our sentence selection com- ponent into the neural question generation sys- tem of <ref type="bibr" target="#b8">Du et al. (2017)</ref> and show, again us- ing SQuAD, that our resulting end-to-end system achieves state-of-the-art performance for the chal- lenging task of paragraph-level question genera- tion for reading comprehension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>In this section, we define the tasks of impor- tant (i.e. question-worthy) sentence selection and sentence-level question generation (QG). Our full paragraph-level QG system includes both of these components. For the sentence selection task, given a paragraph D consisting of a sequence of sen- tences {s 1 , ..., s m }, we aim to select a subset of k question-worthy sentences (k &lt; m). The goal is defined as finding y = {y 1 , ..., y m }, such that,</p><formula xml:id="formula_0">y = arg max y log P 1 (y|D) = arg max y |y| t=1 log P 1 (y t |D)<label>(1)</label></formula><p>where log P (y|D) is the conditional log- likelihood of the label sequence y; and y i = 1 means sentence i is question-worthy (contains at least one answer), otherwise y i = 0. For sentence-level QG, the goal is to find the best word sequence z (a question of arbitrary length) that maximizes the conditional likelihood given the input sentence x and satisfies:</p><formula xml:id="formula_1">z = arg max z log P 2 (z|x) = arg max z |z| t=1 log P 2 (z t |x, z &lt;t )<label>(2)</label></formula><p>where P 2 (z|x) is modeled with a global attention mechanism (Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Important Sentence Selection Our general idea for the hierarchical neural network architecture is illustrated in <ref type="figure">Figure 1</ref>. First, we perform the encoding using sum operation or convolu- tion+maximum pooling operation <ref type="bibr" target="#b12">(Kim, 2014;</ref><ref type="bibr" target="#b7">dos Santos and Zadrozny, 2014</ref>) over the word vectors comprising each sentence in the input paragraph.</p><p>For simplicity and consistency, we denote the sen- tence encoding process as ENC. Given the t th sen- tence x = {x 1 , ..., x n } in the paragraph, we have its encoding:</p><formula xml:id="formula_2">s t = ENC([x 1 , ..., x n ])<label>(3)</label></formula><p>Then we use a bidirectional LSTM <ref type="bibr" target="#b11">(Hochreiter and Schmidhuber, 1997</ref>) to encode the paragraph,</p><formula xml:id="formula_3">… … … … … í µí± " í µí± # í µí± $ í µí± % í µí± &amp; í µí±¦ $ í µí±¦ % í µí±¦ &amp; í µí±¦ # í µí±¦ "</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Encoder</head><p>Figure 1: Hierarchical neural network architecture for sentence-level sequence labeling. The input is a paragraph consisting of sentences, whose en- coded representation is fed into each hidden unit.</p><formula xml:id="formula_4">− → h t = − −−− → LSTM s t , −− → h t−1 ← − h t = ← −−− − LSTM s t , ←− − h t+1</formula><p>We use the concatenation of the two, namely,</p><formula xml:id="formula_5">[ − → h t ; ← − h t ]</formula><p>, as the hidden state h t at time stamp t, and feed it to the upper layers to get the probability distribution of y t (∈ {0, 1}),</p><formula xml:id="formula_6">P 1 (y t |D; θ) = softmax MLP tanh [ − → h t ; ← − h t ]</formula><p>where MLP is multi-layer neural network and tanh is the activation function.  <ref type="bibr" target="#b12">(Kim, 2014)</ref> 68 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Generation</head><formula xml:id="formula_7">(p &lt; 0.005).)</formula><p>The decoder is another LSTM that uses global attention over the encoder hidden states. The en- tire encoder-decoder structure learns the probabil- ity of generating a question given a sentence, as indicated by equation 2. To be more specific,</p><formula xml:id="formula_8">P 2 (z t |x, z &lt;t ) = softmax (W s tanh (W t [h t ; c t ]))</formula><p>where W s , W t are parameter matrices; h t is the hidden state of the decoder LSTM; and c t is the context vector created dynamically by the encoder LSTM -the weighted sum of the hidden states computed for the source sentence:</p><formula xml:id="formula_9">c t = i=1,..,|x| a i,t q i</formula><p>The attention weights a i,t are calculated via a bilinear scoring function and softmax normaliza- tion:</p><formula xml:id="formula_10">a i,t = exp(h T t W b q i ) j exp(h T t W b q j )</formula><p>Apart from the bilinear score, alternative options for computing the attention can also be used (e.g. dot product). Readers can refer to <ref type="bibr" target="#b14">Luong et al. (2015)</ref> for more details.</p><p>During inference, beam search is used to predict the question. The decoded UNK token at time step t, is replaced with the token in the input sentence with the highest attention score, the index of which is arg max i a i,t .</p><p>Henceforth, we will refer to our sentence-level Neural Question Generation system as NQG.</p><p>Note that generating answer-specific questions would be easy for this architecture -we can ap- pend answer location features to the vectors of to- kens in the sentence. To better mimic the real life case (where questions are generated with no prior knowledge of the desired answers), we do not use such location features in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Implementation Details</head><p>We use the SQuAD dataset ( <ref type="bibr" target="#b20">Rajpurkar et al., 2016</ref>) for training and evaluation for both impor- tant sentence selection and sentence-level NQG. The dataset contains 536 curated Wikipedia arti- cles with over 100k questions posed about the ar- ticles. The authors employ Amazon Mechanical Turk crowd-workers to generate questions based on the article paragraphs and to annotate the corre- sponding answer spans in the text. Later, to make the evaluation of the dataset more robust, other crowd-workers are employed to provide additional answers to the questions.</p><p>We split the public portion of the dataset into training (∼80%), validation (∼10%) and test (∼10%) sets at the paragraph level. For the sen- tence selection task, we treat sentences that con- tain at least one answer span (question-worthy sentences) as positive examples (y = 1); all re- maining sentences are considered negative (y = 0). Not surprisingly, the training set is unbalanced: 52332 (∼60%) sentences contain answers, while 29693 sentences do not. Because of the variabil-   <ref type="table">Table 2</ref>: Results for the full QG systems using BLEU 1-4, METEOR. The first stage of the two pipeline systems are the feature-rich linear model (LREG) and our best performing selection model respectively.</p><p>ity of human choice in generating questions, it is the case that many sentences labeled as negative examples might actually contain concepts worth asking a question about. For the related impor- tant sentence detection task in text summarization,  therefore propose a two-stage approach ( <ref type="bibr" target="#b13">Lee and Liu, 2003;</ref><ref type="bibr" target="#b9">Elkan and Noto, 2008)</ref> to augment the set of known summary- worthy sentences. In contrast, we adopt a con- servative approach rather than predict too many sentences as being question-worthy: we pair up source sentences with their corresponding ques- tions, and use just these sentence-question pairs to training the encoder-decoder model. We use the glove.840B.300d pre-trained embeddings ( <ref type="bibr" target="#b19">Pennington et al., 2014</ref>) for ini- tialization of the embedding layer for our sen- tence selection model and the full NQG model. glove.6B.100d embeddings are used for cal- culating sentence similarity feature of the baseline linear model (LREG). Tokens outside the vocabu- lary list are replaced by the UNK symbol. Hyper- parameters for all models are tuned on the valida- tion set and results are reported on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sentence Selection Results</head><p>We compare to a number of baselines. The Ran- dom baseline assigns a random label to each sentence. The Majority baseline assumes that all sentences are question-worthy. The convolu- tional neural networks (CNN) sentence classifi- cation model <ref type="bibr" target="#b12">(Kim, 2014</ref>) has similar structure to our CNN sentence encoder, but the classifica- tion is done only at the sentence-level rather than jointly at paragraph-level. LREG w/ BOW is the logistic regression model with bag-of-words fea- tures. LREG w/ para.-level is the feature-rich LREG model designed by <ref type="bibr" target="#b4">Cheng and Lapata (2016)</ref>; the features include: sentence length, position of sen- tence, number of named entities in the sentence, number of sentences in the paragraph, sentence-to- sentence cohesion, and sentence-to-paragraph rel- evance. Sentence-to-sentence cohesion is obtained  <ref type="table">Table 3</ref>: For a source sentence in SQuAD, given the prediction from the sentence selection system and the corresponding NQG output, we provide conservative and liberal evaluations.</p><p>by calculating the embedding space similarity be- tween it and every other sentence in the paragraph (similar for sentence-to-paragraph relevance). In document summarization, graph-based extractive summarization models (e.g. TGRAPH <ref type="bibr" target="#b18">Parveen et al. (2015)</ref> and URANK <ref type="bibr" target="#b25">Wan (2010)</ref>) focus on global optimization and extract sentences con- tributing to topical coherent summaries. Because this does not really fit our task -a summary- worthy sentence might not necessarily contain enough information for generating a good ques- tion -we do not include these as comparisons.</p><p>Results are displayed in <ref type="table" target="#tab_2">Table 1</ref>. Our models with sum or CNN as the sentence encoder signif- icantly outperform the feature-rich LREG as well as the other baselines in terms of F-measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation of the full QG system</head><p>To evaluate the full systems for paragraph-level QG, we introduce in <ref type="table">Table 3</ref> the "conservative" and "liberal" evaluation strategies. Given an input source sentence, there will be in total four possi- bilities: if both the gold standard data and predic- tion include the sentence, then we use its n-gram matching score (by BLEU ( <ref type="bibr" target="#b17">Papineni et al., 2002</ref>) and METEOR <ref type="bibr" target="#b6">(Denkowski and Lavie, 2014)</ref>); if neither the gold data nor prediction include the sentence, then the sentence is discarded from the evaluation; if the gold data includes the sentence while the prediction does not, we assign a score of 0 for it; and if gold data does not include the sen- tence while prediction does, the generated ques- tion gets a 0 for conservative, while it gets full arnold schwarzenegger has been involved with the special olympics for many years after they were founded by his ex-mother-in-law , eunice kennedy shriver . after they were founded by his ex-mother-in-law , eunice kennedy shriver . in 2007 , schwarzenegger was the official spokesperson for the special olympics which were held in shanghai , china .</p><p>::::::::::::</p><p>schwarzenegger ::: was :: the :::::: official :::::::::: spokesperson ::: for :: the :::::: special ::::::: olympics ::::: which :::: were ::: held :: in ::::::: shanghai, ::::: china : .</p><p>schwarzenegger believes that quality school opportunities should be made available to children who might not normally be able to access them. in 1995 , he founded the inner city games foundation -lrb-icg -rrb-which provides cultural , Our questions: Q1: who founded the special olympics ? Q2: who was the official adviser for the special olympics ? Q3: when was the inner city games foundation founded ? Q4: how many schools does icg have ? Gold questions: Q1: schwarzenegger was the spokesperson for the special olympic games held in what city in china ? Q2: what nonprofit did schwarzenegger found in 1995 ? Q3: about how many schools across the country is icg active in ?</p><p>Figure 2: Sample output from our full NQG system, the four questions correspond to the four highlighted sentences in the paragraph in the same order. Darkness indicates sentence importance, the score for deciding the darkness is obtained from the softmax results. Wave-lined sentences bear label y = 1, and 0 otherwise. The three gold questions also correspond to the wave-lined sentences in the same order. Please refer to the appendix for sample output on more Wikipedia articles.</p><p>score for liberal evaluation. <ref type="table">Table 2</ref> shows that the QG system incorporating our best performing sen- tence extractor outperforms its LREG counterpart across metrics. Note that to calculate the score for the matching case, similar to our earlier work ( <ref type="bibr" target="#b8">Du et al., 2017)</ref>, we adapt the image captioning eval- uation scripts of <ref type="bibr" target="#b3">Chen et al. (2015)</ref> since there can be several gold standard questions for a single in- put sentence.</p><p>In <ref type="figure">Figure 2</ref>, we provide questions generated by the full NQG system (Q1-4) and according to the gold standard (Q1-3) for the selected Wikipedia paragraph. The sentences they were drawn from are shown with wavy lines (gold standard) and via highlighting (our system). Darkness of the high- lighting is proportional to the softmax score pro- vided by the sentence extractor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work we introduced the task of identify- ing important sentences -good sentences to ask a question about -in the reading comprehen- sion setting. We proposed a hierarchical neural sentence labeling model and investigated encod- ing sentences with sum and convolution opera- tions. The question generation system that uses our sentence selection model consistently outper- forms previous approaches and achieves state-of- the-art paragraph-level question generation perfor- mance on the SQUAD data set.</p><p>In future work, we would like to investigate approaches to identify question-worth concepts rather than question-worthy sentences. It would also be interesting to see if the generated questions can be used to help improve question answering systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Model</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>:</head><label></label><figDesc>in :::: 1995 : , :: he ::::::: founded :: the ::::: inner ::: city ::::: games :::::::: foundation :::: -lrb-:: icg :::: -rrb-::::: which ::::::: provides :::::: cultural , :::::::: educational ::: and ::::::::: community ::::::::: enrichment :::::::::: programming :: to :::: youth : . icg is active in 15 cities around the country and serves over 250,000 children in over 400 schools countrywide . :: icg :: is ::::: active : in ::: 15 :::: cities ::::: around ::: the :::::: country ::: and ::::: serves ::: over ::::::: 250,000 :::::: children :: in :::: over ::: 400 :::::: schools ::::::::: countrywide : . he has also been involved with after-school all-stars , and founded the los angeles branch in 2002 . asas is an after school program provider , educating youth about health , fitness and nutrition .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>BLEU 1 BLEU 2 BLEU 3 BLEU 4 METEOR</head><label>1</label><figDesc></figDesc><table>Conservative 
LREG(C&amp;L) + NQG 
38.30 
23.15 
15.64 
10.97 
15.09 
Ours + NQG 
40.08 
24.26 
16.39 
11.50 
15.67 

Liberal 
LREG(C&amp;L) + NQG 
51.55 
40.17 
34.35 
30.59 
24.17 
Ours + NQG 
52.89 
41.16 
35.15 
31.25 
24.76 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for helpful comments and Victoria Litvinova for proofreading.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations Workshop (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Jointly learning to extract and compress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P11-1049" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="481" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1082" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Microsoft coco captions: Data collection and evaluation server</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.00325</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="484" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meteor universal: Language specific translation evaluation for any target language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Denkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-3348" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation. Association for Computational Linguistics</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation. Association for Computational Linguistics<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="376" to="380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning character-level representations for part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bianca</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1818" to="1826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to ask: Neural question generation for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinya</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Noto</surname></persName>
		</author>
		<idno type="doi">10.1145/1401890.1401920</idno>
		<ptr target="https://doi.org/10.1145/1401890.1401920" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>New York, NY, USA, KDD &apos;08</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Good question! statistical ranking for question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N10-1086" />
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting><address><addrLine>Los Angeles, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="609" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1181" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning with positive and unlabeled examples using weighted logistic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Wee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Conference on International Conference on Machine Learning. AAAI Press, ICML&apos;03</title>
		<meeting>the Twentieth International Conference on International Conference on Machine Learning. AAAI Press, ICML&apos;03</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Question generation from paragraphs at upenn: Qgstec system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashanth</forename><surname>Mannem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of QG2010: The Third Workshop on Question Generation</title>
		<meeting>QG2010: The Third Workshop on Question Generation</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="84" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Language independent extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="doi">10.3115/1225753.1225766</idno>
		<ptr target="https://doi.org/10.3115/1225753.1225766" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Interactive Poster and Demonstration Sessions. Association for Computational Linguistics</title>
		<meeting>the ACL Interactive Poster and Demonstration Sessions. Association for Computational Linguistics<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="49" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="doi">10.3115/1073083.1073135</idno>
		<ptr target="https://doi.org/10.3115/1073083.1073135" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Topical coherence for graph-based extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daraksha</forename><surname>Parveen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hans-Martin Ramsl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strube</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1226" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1949" to="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The first question generation shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Vasile Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Wyse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Piwek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lintean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Stoyanchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moldovan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<title level="m">Proceedings of the 6th International Natural Language Generation Conference. Association for Computational Linguistics</title>
		<meeting>the 6th International Natural Language Generation Conference. Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="251" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D13-1170" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards a unified approach to simultaneous single-document and multi-document summarizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/C10-1128" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1137" to="1145" />
		</imprint>
	</monogr>
	<note>Coling 2010 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Detecting (un)important content for single-document news summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/E17-2112" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01792</idno>
		<title level="m">Neural question generation from text: A preliminary study</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
