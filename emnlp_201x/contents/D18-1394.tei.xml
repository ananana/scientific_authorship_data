<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying the sentiment styles of YouTube&apos;s vloggers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 31-November 4, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
							<email>b.a.r.kleinberg@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology University of Amsterdam Department of Security and Crime Science</orgName>
								<orgName type="department" key="dep2">Department of Informatics Technical</orgName>
								<orgName type="department" key="dep3">Department of Security and Crime Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Munich</orgName>
								<orgName type="institution" key="instit3">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Mozes</surname></persName>
							<email>mozes@cs.tum.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology University of Amsterdam Department of Security and Crime Science</orgName>
								<orgName type="department" key="dep2">Department of Informatics Technical</orgName>
								<orgName type="department" key="dep3">Department of Security and Crime Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Munich</orgName>
								<orgName type="institution" key="instit3">University College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Van Der Vegt</surname></persName>
							<email>isabelle.vegt.17@ucl.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology University of Amsterdam Department of Security and Crime Science</orgName>
								<orgName type="department" key="dep2">Department of Informatics Technical</orgName>
								<orgName type="department" key="dep3">Department of Security and Crime Science</orgName>
								<orgName type="institution" key="instit1">University College London</orgName>
								<orgName type="institution" key="instit2">University of Munich</orgName>
								<orgName type="institution" key="instit3">University College London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying the sentiment styles of YouTube&apos;s vloggers</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Brussels; Belgium</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="3581" to="3590"/>
							<date type="published">October 31-November 4, 2018</date>
						</imprint>
					</monogr>
					<note>3581</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Vlogs provide a rich public source of data in a novel setting. This paper examined the continuous sentiment styles employed in 27,333 vlogs using a dynamic intra-textual approach to sentiment analysis. Using unsupervised clustering, we identified seven distinct continuous sentiment trajectories characterized by fluctuations of sentiment throughout a vlog&apos;s narrative time. We provide a taxonomy of these seven continuous sentiment styles and found that vlogs whose sentiment builds up towards a positive ending are the most prevalent in our sample. Gender was associated with preferences for different continuous sentiment trajectories. This paper discusses the findings with respect to previous work and concludes with an outlook towards possible uses of the corpus, method and findings of this paper for related areas of research.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Vlogging or video-blogging has become one of the most popular video formats on social media platforms like YouTube. Vlogs have been referred to as 'conversational video-blogs' <ref type="bibr">(Biel and GaticaPerez, 2010</ref>) or 'monologue-like' videos ( <ref type="bibr" target="#b0">Aran et al., 2014)</ref>, and are officially defined in the Cambridge dictionary of English as "a record of your thoughts, opinions or experiences that you film and publish on the internet" <ref type="bibr">1</ref> . The vast amount of vlogs on YouTube comprises a rich body of visual and textual data, usually covering a vlogger's daily life. The transcripts of vlogs provide researchers with ample opportunity to examine natural language in this young field of communication. Nevertheless, little attention has thus far been paid to investigating the language used in YouTube vlogs.</p><p>Much of the literature concerning Youtube vlogs focuses on the visual modality ( <ref type="bibr" target="#b0">Aran et al., 2014)</ref> or meta-indicators such as views and subscriber counts ( <ref type="bibr" target="#b3">Borghol et al., 2012</ref>). With the current study, we aim to address this gap in the literature by automatically analyzing the linguistic styles used by YouTube's vloggers. Building on a novel approach to examining the continuous sentiment structure, we seek to shed light on the different temporal trajectories used by vloggers, and, by doing so, we expect to gain a deeper understanding of language use in vlogs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Previous research on vlogs</head><p>Research on YouTube vlogs has thus far mainly focused on metadata indicators and how they impact video popularity. For example, a pronounced "rich-get-richer" effect regarding video popularity is often found. When controlling for the content, previous views are the best predictor of later video popularity ( <ref type="bibr" target="#b3">Borghol et al., 2012</ref>). In addition, video age also predicts popularity: when the content is similar, early uploaders have an advantage over later uploaders in terms of popularity ( <ref type="bibr" target="#b3">Borghol et al., 2012</ref>). Furthermore, related video recommendations shown during or after a playing video also serve as an important indicator of the view count for YouTube videos ( <ref type="bibr" target="#b27">Zhou et al., 2010)</ref>.</p><p>Another strand of research has examined the visual content of vlogs. Across 2,268 single-person YouTube videos, four clusters of user activity level (e.g., stationary or in motion), editing choices, and video quality were identified ( <ref type="bibr" target="#b0">Aran et al., 2014</ref>). Videos from a cluster with highly edited, active vlogs received more views than simple conversational videos in which the vlogger is stationary in front of the camera. Concerning audio data, videos in which the vlogger is "talking more, faster, and using few pauses" receive more views on average <ref type="bibr" target="#b2">(Biel and Gatica-Perez, 2010)</ref>. Similarly, the distance of the vlogger to the camera, looking time, and 'looking-while-speaking' were also found to significantly correlate with view count. It has been suggested that these nonverbal characteristics might be related to specific personality traits that promote effective communication and video popularity <ref type="bibr" target="#b2">(Biel and Gatica-Perez, 2010</ref>). Lastly, a smaller line of research examines the linguistic content of YouTube vlogs. For example, a manual inspection of a random sample of 100 vlogs suggests that female vloggers are more likely than male vloggers to vlog about personal matters ( <ref type="bibr" target="#b14">Molyneaux et al., 2008)</ref>. In contrast, male YouTubers focused more on entertainment and technology. Research on the linguistic content of vlogs is scarce, which is why the present paper presents a novel methodology and corpus for examining the text modality. In the next section, the proposed method is explained in conjunction with previous research utilizing intra- textual sentiment analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Continuous sentiment trajectories</head><p>With increasing amounts of textual data available online, diverse methods for examining natural language and its linguistic style and content are applied on a large scale. Applications range from the automated detection of fake reviews <ref type="bibr" target="#b16">(Ott et al., 2013)</ref>, fake news ( <ref type="bibr">Thorne et al., 2018;</ref><ref type="bibr" target="#b17">PÃ©rez-Rosas et al., 2018</ref>) and lies and truths <ref type="bibr" target="#b13">(Mihalcea and Strapparava, 2009;</ref>) to detecting political sentiments <ref type="bibr" target="#b5">(Cambria, 2016)</ref>.</p><p>One important strand of computational linguistics examines the sentiment of texts (i.e., how positive or negative the emotional valence of the content is). Typically, a sentiment score is reported for a piece or section of text (e.g., a sentence or a whole text). However, a recently emerged literature examines shifts in emotional valence throughout a text (hence intra-textual) to assess sentiment over time. This focus on the temporal dimension resembles work on storyline extraction, where the timeline of events is considered, including events that give rise to a 'climax' of a story <ref type="bibr" target="#b6">(Caselli and Vossen, 2016)</ref>. With intra-textual sentiment analysis, it is also possible to visualize language use leading to a climax in (positive or negative) sentiment. This method has thus far been applied to extract the intra-textual sentiment dynamics in novels ( <ref type="bibr" target="#b7">Gao et al., 2016)</ref> and was used to identify key narrative moments. Within this same context, Jockers (2015a) analyzed the intra-textual sentiments of over 40.000 novels using hierarchical clustering and observed six shapes, each representing a common sentiment structure in novels (e.g., a 'man-in-hole' structure showcasing a positive-negative-positive sentiment).</p><p>A few studies have further examined emotional plot shapes in different bodies of text. Six common emotional arcs were found to underlie 1,327 fictional stories, termed the 'rags to riches' (i.e., a rise in sentiment), 'tragedy' or 'riches to rags' (i.e., a fall in sentiment), 'man in hole' (i.e., fall-rise), 'Icarus' (i.e., rise-fall), 'Cinderella' (i.e., rise-fall- rise), and 'Oedipus' styles (i.e., fall-rise-fall; see <ref type="bibr">Reagan et al., 2016)</ref>. Comparing these emotional arcs to the number of downloads for each of the fiction titles, the authors suggest that 'Icarus', 'Oedipus', and 'Man in a hole' are the most successful plot shapes.</p><p>In a different study IBM's Watson Tone Analyzer was used to examine the continuous trajectories (i.e., in terms of emotion: e.g., joy; language: e.g., analytical language, and personality: e.g., extraversion) in public speaking ( <ref type="bibr" target="#b22">Tanveer et al., 2018)</ref>. The authors investigated the audience's perception of linguistic structures of 2,007 publicly available TED talks. After identifying clusters and comparing these to ratings on the TED website, they found that 'flat' (i.e., less diverse) plot shapes are more likely to be rated as 'long-winded', emphasizing the importance of narrative variety for speech success. Furthermore, the majority of speeches showed a positive ending. While specific linguistic (or visual) characteristics of a video may not be accessible prior to watching a video, its style and structure may play a role in capturing and holding on to the attention of a viewer. Since video streaming services tend to only consider "quality views" (i.e., longer than X amount of time, <ref type="bibr" target="#b24">(YouTube.com, 2018)</ref>, examining the continuous sentiment styles over narrative time may be a worthwhile endeavor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">The current study</head><p>This investigation aims to use intra-textual sentiment analysis to examine the continuous sentiment styles used in YouTube vlogs. Specifically, we primarily aim to identify distinct trajectories of continuous sentiment. In addition, we explore the sentiment styles' relationship to gender and their overall prevalence on YouTube. Besides these aims, we introduce a novel method of extracting sentiment that is sensitive to valence shifters but can be used on non-punctuated data (e.g., YouTube vlogs). We also present a publicly available corpus of YouTube vlog transcripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data and code used to produce the analysis and data in this paper are publicly available. 2 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vlog selection</head><p>Vlogs were selected by choosing vlog channels (i.e., where YouTubers post their videos) from a list of the top 250 YouTube channels (ranked by subscriber count) in the 'People &amp; Blogs' category (retrieved from www.socialblade.com on 29 March 2018). Channels were selected for inclusion if the videos on the channel were in English and the channel solely focused on vlogs -excluding channels with gaming, music and prank videos. The aim was to select a sample of 20 female and 20 male vloggers from the list of 250 YouTube channels. However, the majority of channels in this list were male or family vloggers, resulting in a somewhat unbalanced sample. After inspecting all 250 channels in the list, 37 channels that satisfied the aforementioned criteria remained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Scraping vlog transcripts</head><p>To obtain vlog transcripts, we accessed all videos published on the selected YouTube channels and used www.downsub.com to access video transcripts. That website downloads and returns YouTube transcripts for a specified video URL directly in the browser. We developed a python script that takes video URLs as input and communicates indirectly with YouTube via downsub.com to request and retrieve video transcripts. We did not differentiate between manually-added and automatically-generated  but encountered several cases in which neither was available for a certain video. In this case, we ignored the affected video and proceeded without considering it further in the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Preprocessing</head><p>The retrieved transcripts were XML-encoded, and the preprocessing included the removal of all XML tags to provide human-readable sequences. Furthermore, each row of the XML transcripts contained the word sequence of the vlog with its corresponding start and end time. Since the YouTube transcripts do not include any punctuation information, we decoded each row by removing the XML tags and merged the resulting human-readable sequences to one continuous string for each vlog.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Feature extraction</head><p>The primary aim of this investigation was to examine the continuous sentiment structures of popular vlogs. Taking inspiration from previous work on the narrative arcs of novels ( <ref type="bibr" target="#b7">Gao et al., 2016)</ref>, we wanted to analyze how the sentiment of the spoken content of a vlog moves dynamically throughout the vlog's narrative time. When conducting sentiment extraction, an important consideration is the treatment of valence shifters that influence the meaning of a sentiment. For example, an utterance such as "this was not a bad day" should be rated as a positive sentiment since the valence of "bad" is shifted through the negator "not". Existing methods of extracting sentiment, however, either ignore valence shifters (Jockers, 2015b) or are sentence-based (i.e., they provide weighted sentiments only per sentence, e.g., the R- package sentimentr, Rinker, 2018b). Since the scraped transcripts are non-punctuated, but we also wanted to account for valence shifters, we built a "naÃ¯ve context" sentiment extractor that is sensitive to negators (e.g., not, doesn't), [de-]amplifiers (e.g., really, hardly), and adversative conjunctions (e.g., but, however). The rationale is inspired by the algorithm behind sentimentr (Rinker, 2018b) but extends that approach to data that are non- punctuated or very brief.</p><p>Specifically, our algorithm identifies each sentiment as matched with the 'Jockers &amp; Rinker Polarity Lookup <ref type="table">Table'</ref> from the lexicon R package <ref type="bibr" target="#b20">(Rinker, 2018a)</ref> and then constructs a "naÃ¯ve context" cluster (i.e., without relying on punctuation or other structure) around that sentiment (here: two words before and after the sentiment). For each context cluster, the raw sentiment is then weighted by the presence of valence shifters. For example, "this was not a bad day in the sun" would result in a cluster around the identified sentiment word "bad" of (not a bad day in). The weights assigned to the valence shifters in this study (Negator: -1.00, Amplifier: 1.50, De- amplifier: 0.50, Adversative conjunction: 0.25) are motivated by those in the similar software package sentimentr. <ref type="bibr">4</ref> Lastly, the sentiment word in the cluster is replaced by its sentiment value: <ref type="figure">(-1, 1, - 0.75, 1, 1)</ref>. We can then calculate the product of all vector elements and retrieve the weighted sentiment of that cluster (e.g., 0.75 for "not a bad day in").</p><p>We performed the naÃ¯ve sentiment extraction on each vlog transcript resulting in a vector consisting of zeros (for words that did not match the sentiment lookup table) and weighted sentiment values. That vector was transformed to a standardized narrative time from 0 to 100 using the discrete cosine transformation from the syuzhet R package (Jockers, 2015b). The sentiment values were scaled from -1 (lowest sentiment per vlog transcript) to +1 (highest sentiment per vlog transcript). The transformation yielded a vector of 100 sentiment coordinates for each transcript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus statistics</head><p>The final corpus consisted of the transcripts of 27,333 vlogs from 24 vloggers with a total corpus size of 40,318,924 words and vlogs accounting for more than 24 billion views. These are all vlogs of which we were able to retrieve a transcript of at least ten words. <ref type="table">Table 1</ref> shows that female vloggers were underrepresented in the sample. More than half of the vlogs stem from male vloggers and a third from families who vlog. Since view count is highly dependent on the number of days the vlog is online, we corrected the view count for each vlog by dividing it by the number of days it was online. We then excluded 462 vlogs (1.69%) that were considered view count outliers (i.e., more than <ref type="bibr">4</ref> Consensus on values for valence shifter weights has yet to emerge in literature. The algorithm is available as an R- implementation to modify these values. three standard deviations above the mean). All subsequent analyses were conducted on the final sample with these outliers excluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Identifying continuous sentiment styles</head><p>The primary aim of this paper was to examine whether the narrative structure of vlogs can be captured by a few overarching sentiment styles. We used the binned sentiments extracted for each vlog in an unsupervised non-hierarchical k-means cluster analysis. Using the within-cluster-sum-of- squares in a scree plot for 1 to 30 clusters, we observed an inflection after seven clusters and therefore decided to build a k-means model with k=7 <ref type="figure" target="#fig_2">(Figure 1 and 2)</ref>.</p><p>The k-means model assigned one cluster to each vlog transcript, and we subsequently averaged the continuous sentiment structure of all vlogs belonging to each cluster. <ref type="figure">Figure 1</ref> and 2 show the distinct average shapes of the continuous sentiment structures of each cluster. The dotted red lines indicate the upper and lower boundaries of the sentiment shape +/-one standard deviation; the blue lines show the 99% confidence intervals. The seven plot shapes represent the average sentiment of all vlogs in that shape cluster in each bin of standardized narrative time (1-100). For example, for the first shape <ref type="figure">(Figure 1</ref>, second plot), the sentiment starts highly positive in the first quantile of the narrative time and then quickly dips below zero to moderately negative sentiment. Halfway through the narrative time, the sentiment neutralizes and becomes negative again until the last quantile from which it gradually becomes less negative and ends in a nearly neutral sentiment. <ref type="table" target="#tab_2">Table 2</ref> proposes a taxonomy of these seven continuous sentiment styles of YouTube vlogs and provides descriptive statistics for each. We used a linear mixed effects model to test for an effect of the clusters on the view count and transcript length. To account for dependence in the data (i.e., that we have multiple transcripts per vlogger), we included the vlogger as a random effect in the model. The analysis indicated that there was no significant difference in the corrected view count between the clusters; non-standardized b-coefficient of cluster = 6.78, se = 7.40, t(451.25) = 0.92, p = .360. Nor was there a difference in transcript length; b = - 1.23, se = 2.07, t(114.10) = -0.60, p = .552. Thus, it is not statistically justified to argue that one particular narrative style attracted more views than others. Nor do these results provide support for a relationship between a vlog's length (as measured by the number of words in its transcript) and a particular sentiment style (e.g., that lengthier vlogs contain more sentiment shifts).</p><p>A one-sided Chi-square test revealed that the number of vlogs was not uniform per cluster, X 2 (6) = 720.61, p &lt; .001. The observed frequencies of vlogs in each cluster deviated significantly from the frequency that is expected if the vlogs were distributed uniformly (n = 3832, 14.29%). Standardized residuals (z-scores) of the observed relative to the expected frequencies can be used to examine which observations deviated in which direction. There were significantly more vlogs than expected in the "downhill-from-here" cluster (z = 8.30), the "rags-to-riches" cluster (z = 7.64), and  the "end-on-a-high-note" cluster (z = 19.21). The clusters "mood swings" (z = -11.45), "riches-to- rags" (z = -9.02), "bump-in-the-road" (z = -3.86), and "twin peaks" (z = -10.82) were significantly underrepresented. Aside from the considerable overrepresentation of the "end-on-a-high-note" cluster and underrepresentation of the "mood swings" and "twin peaks" clusters, the distribution is rather harmonious. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Additional analysis: Sentiment styles and gender</head><p>We also assess whether there is a relationship between gender and the continuous sentiment style. There was significant association as indicated with a 3 (male, female, family) by 7 (clusters) Chi-square test, X 2 (12) = 134.82, p &lt; .001. <ref type="table">Table 3</ref> shows that family vloggers used the "twin peaks" style significantly more often than expected and used the "end-on-a-high-note" style significantly less often than expected (* = significant at p &lt; .01). For female vloggers, the most used continuous sentiment style was "riches to rags", while they used "end-on-a-high-note" less often than expected. Male vloggers preferred the "end-on-a-high-note" style while they used the styles "downhill from here" and "twin peaks" less often. Since we did not ascertain a balanced gender <ref type="bibr">5</ref> The appendix provides a list of URLs to vlogs and vlog channels typical of a particular style. distribution, these findings should be treated cautiously and subjected to replications on datasets more suitable for gender analysis.  <ref type="table">Table 3</ref>. Standardized residuals for the cluster-by- gender association. <ref type="figure">Figure 1</ref>. Scree plot and average sentiment style shapes for clusters 1-3. Note: Dotted red lines = +/-1 SD; blue lines = 99% CI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cluster</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In this paper, we examined the continuous sentiment structures of a new corpus of YouTube vlog transcripts using intra-textual sentiment analysis. We were able to identify seven distinct continuous sentiment styles. The "rags to riches", "riches to rags" and the "end-on-a-high-note" styles displayed an alternating pattern with one shift between predominantly positive and negative content. By contrast, the "bump in the road" and "twin peaks" styles show a marked negative middle part of the vlog and an overall positive sentiment with a slightly negative beginning and end, respectively. The most volatile styles were the "downhill from here" and the "mood swings" styles with both showing three shifts in sentiment. While no continuous sentiment style was related to higher view counts, we observed that the "end- on-a-high-note" style was the most common in our corpus. The pattern of this particular style suggests that vloggers build up their content towards a positive ending following the idea to 'end strong', possibly to engage their viewers to keep watching subsequent videos. A similar trajectory was found for TED speeches <ref type="bibr" target="#b22">(Tanveer et al., 2018)</ref>, suggesting that YouTube vloggers may employ strategies similar to those of prolific public speakers. However, since the "downhill from here" style is second most frequent in our dataset, these findings do not indicate any tendency to a general sentiment development over time. In fact, the "downhill from here" and "end on a high note" styles exhibit a somewhat opposing behavior since the first gradually decreases the sentiment over time whereas the second aims at developing a positive sentiment towards the end of the video. When projecting this observation to the gender- specific findings, one can see that the differences between family, female and male vloggers might account for these contradictory findings. Both family and female vloggers (representing 45.83% of all vloggers) used the "downhill from here" more often than male vloggers, whereas male vloggers used the "end on a high note" style most often.</p><p>Gender differences might help further understand vlog style choice: family vloggers used the "twin peaks" style more often than female or male vloggers, with the latter significantly under- using that style. Female vloggers resorted to the "riches to rags" style most often, while male vloggers preferred the "end-on-a-high-note" style. Vlogs made by females started with a definite positive buildup followed by a marked dip towards clear negative sentiment and a gradual increase towards the positive near the end of the vlog. Family vloggers were the only ones who preferred a style that ended with a sentiment leading toward the negative. Contrary to the findings of Tanveer et al. <ref type="formula">(2018)</ref>, we did not find support for the notion that diverse styles characterized by higher sentiment volatility are more popular: both YouTuber's themselves, as well as the audience, did not show a preference for the most volatile narrative styles. The intra-textual analysis approach helped us to uncover dynamics in the sentiment of vlogs that would otherwise have been blurred by an overall sentiment score. In many cases (e.g., for the "rags to riches" and "riches to rags" styles) the sentiment dynamics would have canceled each other out to a neutral sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Limitations</head><p>Despite the interesting initial findings using the new corpus of vlog transcripts and the linguistic- temporal analysis, the current study is not without its limitations. First, we partially relied on automated transcription of the vlogs, so the retrieved transcripts consisted of texts generated with YouTube's speech recognition software. Although recent advancements in machine learning research provide promising improvements to speech recognition ( <ref type="bibr" target="#b11">LeCun et al., 2015;</ref><ref type="bibr" target="#b26">Zhang et al., 2017b;</ref><ref type="bibr" target="#b25">Zhang et al., 2017a</ref>) and contributed to an accuracy increase of fifty percent for YouTube's automatic captions in English <ref type="bibr" target="#b15">(Official YouTube Blog, 2017)</ref>, the automatic generation of YouTube video captions remains a challenging task ( <ref type="bibr" target="#b12">Liao et al., 2013</ref>). It could be that potential inaccuracies might have affected our findings and future studies could set out to replicate our results using user- provided high-quality vlog transcripts.</p><p>Second, the sample consisted of YouTubers that already are successful concerning subscriber count, and we might, therefore, have painted a skewed picture of the vlogging landscape. For future studies, it would be interesting to look at potential moderating variables such as the vloggers 'vlogging age' or the vlog's topic. Possibly, the use of sentiment (and other linguistic dimensions) might differ between starting YouTubers and those who are more prolific and regularly attract millions of views.</p><p>Third, by using vlog transcripts, we resorted solely to the linguistic modality of vlogs and did not look at the use of visual aspects in the vlogs. Using a similar dynamic method, future studies could look at how the use of visual content behaves and interacts with language use over the narrative time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Future work</head><p>Using the corpus, method, and findings presented here as a starting point, we hope that future research can extend this exploratory work.</p><p>â¢ For example, it would be interesting to perform unsupervised clustering analyses on the vlog level to find "vlog-twins" or even "vlogger-twins". Using observations that are similar in a multidimensional feature space could be exploited for semi-experimental studies where the effects of individual variables (e.g., a change in vlogging style) can be isolated towards drawing conclusions of causal nature.</p><p>â¢ Moreover, the sentiment is only one dimension of the linguistic aspects of vlogs, and the current analysis might be extended to different constructs. For example, a significant challenge lies in detecting extremist content on social media platforms like YouTube <ref type="bibr" target="#b4">(Burgess, 2017)</ref> and the dynamic approach might help uncover extremist parts in videos and enable a more fine-grained inspection of vlogs.</p><p>â¢ The temporal aspect of narrative time could be broadened so that the evolution of the narrative style across videos of individual vloggers can be captured. This would be a useful method to identify changes in vlogging strategy.</p><p>â¢ Finally, the intra-textual method might help in detecting online misinformation or deception within texts. A major challenge, for example, for linguistic deception detection lies in identifying lies embedded within a mostly truthful statement ( <ref type="bibr" target="#b1">Bachenko et al., 2008)</ref>. Similarly, it would be interesting to examine whether a dynamic linguistic- temporal approach as used here can aid in the detection of misinformation online (e.g., <ref type="bibr" target="#b17">PÃ©rez-Rosas et al., 2018</ref>). The method used here and in a few related studies <ref type="bibr" target="#b8">(Jockers, 2015a;</ref><ref type="bibr" target="#b7">Gao et al., 2016)</ref> could, therefore, also be of interest to researchers across disciplines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Vlogging is a unique and novel means of communication. We explored the transcripts of vlogs as a source for linguistic analysis, and, by looking at intra-textual sentiment dynamics of each vlog, we identified seven distinct continuous sentiment styles. Vlogs ending on a positive note were the most prevalent, and we observed that gender was associated with different vlogging style preferences. The current paper presented an initial glimpse at the rich data source of vlogs, and a dynamic sentiment analysis approach helped uncover continuous sentiment structures. As such we hope the corpus, method, and findings presented here function as an impetus towards more analyses on this emerging means of online communication.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2 Data and code for vlog scraping: https://github.com/ben- aaron188/narrative_structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Average sentiment style shapes for clusters 4-7. Note: Dotted red lines = +/-1 SD; blue lines = 99% CI.</figDesc><graphic url="image-2.png" coords="7,72.24,72.24,217.80,594.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Narrative styles taxonomy and descriptive statistics.</figDesc><table></table></figure>

			<note place="foot" n="1"> https://dictionary.cambridge.org/ dictionary/english/vlog</note>

			<note place="foot" n="3"> Code for feature extraction algorithm: https://github.com/benaaron188/naive_context_sentiment</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Broadcasting oneself: Visual discovery of vlogging styles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan-Isaac</forename><surname>Oya Aran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Biel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="201" to="215" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Verification and implementation of language-based deception indicators in civil and criminal narratives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bachenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eileen</forename><surname>Fitzpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schonwetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vlogcast yourself: Nonverbal behavior and attention in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan-Isaac</forename><surname>Biel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gatica-Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page">50</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The untold story of the clones: content-agnostic factors that impact YouTube video popularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youmna</forename><surname>Borghol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Ardon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Eager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Mahanti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 18th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1186" to="1194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Google&apos;s using a combination of AI and humans to remove extremist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Burgess</surname></persName>
		</author>
		<ptr target="http://www.wired.co.uk/article/google-youtube-ai-extremist-content" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Affective computing and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="102" to="107" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Storyline Annotation and Representation Scheme (StaR): A Proposal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Computing News Storylines (CNS 2016)</title>
		<meeting>the 2nd Workshop on Computing News Storylines (CNS 2016)<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A multiscale theory for the dynamical evolution of sentiment in novels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">L</forename><surname>Jockers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Laudun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Tangherlini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Behavioral, Economic and Socio-cultural Computing (BESC), 2016 International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Revealing Sentiment and Plot Arcs with the Syuzhet Package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jockers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Syuzhet: Extract Sentiment and Plot Arcs from Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Jockers</surname></persName>
		</author>
		<ptr target="https://github.com/mjockers/syuzhet" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automated verbal credibility assessment of intentions: The model statement technique and predictive modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaloe</forename><surname>Van Der Toolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldert</forename><surname>Vrij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnoud</forename><surname>Arntz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Verschuere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="354" to="366" />
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Large scale deep neural network acoustic modeling with semi-supervised training data for YouTube video transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hank</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="368" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The lie detector: Explorations in the automatic recognition of deceptive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACLIJCNLP 2009 Conference Short Papers</title>
		<meeting>the ACLIJCNLP 2009 Conference Short Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="309" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Exploring the gender divide on YouTube: An analysis of the creation and reception of vlogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heather</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerri</forename><surname>Donnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janice</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Communication Journal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">One billion captioned videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Official Youtube</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blog</surname></persName>
		</author>
		<ptr target="https://youtube.googleblog.com/2017/02/one-billion-captioned-videos.html" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Negative deceptive opinion spam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">T</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLTNAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="497" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic detection of fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>PÃ©rez-Rosas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Reagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilan</forename><surname>Kiley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Danforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">Sheridan</forename><surname>Dodds</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The emotional arcs of stories are dominated by six basic shapes</title>
	</analytic>
	<monogr>
		<title level="j">EPJ Data Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Rinker</surname></persName>
		</author>
		<ptr target="http://github.com/trinker/lexicon" />
		<title level="m">lexicon: Lexicon Data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">sentimentr: Calculate Text Polarity Sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Rinker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Awe the Audience: How the Narrative Trajectories Affect Audience Perception in Public Speaking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Iftekhar</forename><surname>Tanveer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samiha</forename><surname>Samrose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raiyan</forename><surname>Abdul Baten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Ehsan</forename><surname>Hoque</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2018 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Thorne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05355</idno>
		<idno>arXiv: 1803.05355</idno>
		<title level="m">Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. FEVER: a large-scale dataset for Fact Extraction and VERification</title>
		<imprint>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">How video views are countedYouTube Help</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">Com</forename><surname>Youtube</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Pezeshki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">PhilÃ©mon</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><surname>Laurent Yoshua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02720</idno>
		<title level="m">Towards end-to-end speech recognition with deep convolutional neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4845" to="4849" />
		</imprint>
	</monogr>
	<note>2017 IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The impact of YouTube recommendation system on video views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samamon</forename><surname>Khemmarat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th ACM SIGCOMM conference on Internet measurement</title>
		<meeting>the 10th ACM SIGCOMM conference on Internet measurement</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="404" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
