<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HUME: Human UCCA-Based Evaluation of Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
							<email>a.birch@ed.ac.uk, oabend@cs.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
							<email>bojar@ufal.mff.cuni.cz, bhaddow@inf.ed.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">HUME: Human UCCA-Based Evaluation of Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1264" to="1274"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Human evaluation of machine translation normally uses sentence-level measures such as relative ranking or adequacy scales. However, these provide no insight into possible errors, and do not scale well with sentence length. We argue for a semantics-based evaluation, which captures what meaning components are retained in the MT output, thus providing a more fine-grained analysis of translation quality , and enabling the construction and tuning of semantics-based MT. We present a novel human semantic evaluation measure, Human UCCA-based MT Evaluation (HUME), building on the UCCA semantic representation scheme. HUME covers a wider range of semantic phenomena than previous methods and does not rely on semantic annotation of the potentially garbled MT output. We experiment with four language pairs, demonstrating HUME&apos;s broad applicability, and report good inter-annotator agreement rates and correlation with human adequacy scores.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Human judgement should be the ultimate test of the quality of an MT system. Nevertheless, common measures for human MT evaluation, such as ade- quacy and fluency judgements or the relative rank- ing of possible translations, are problematic in two ways. First, as the quality of translation is multi- faceted, it is difficult to quantify the quality of the entire sentence in a single number. This is indeed * * All authors contributed equally to this <ref type="bibr">work.</ref> reflected in the diminishing inter-annotator agree- ment (IAA) rates of human ranking measures with the sentence length <ref type="bibr" target="#b5">(Bojar et al., 2011</ref>). Second, a sentence-level quality score does not indicate what parts of the sentence are badly translated, and so cannot inform developers in repairing these errors.</p><p>These problems are partially addressed by mea- sures that decompose over parts of the evaluated translation, often words or n-grams (see §2 for a brief survey of previous work). A promising line of research decomposes metrics over semantically defined units, quantifying the similarity of the out- put and the reference in terms of their verb argu- ment structure; the most notable of these measures is HMEANT ( <ref type="bibr" target="#b19">Lo and Wu, 2011)</ref>.</p><p>We propose the HUME metric, a human evalua- tion measure that decomposes over UCCA semantic units. UCCA <ref type="bibr" target="#b0">(Abend and Rappoport, 2013</ref>) is an appealing candidate for semantic analysis, due to its cross-linguistic applicability, support for rapid anno- tation, and coverage of many fundamental semantic phenomena, such as verbal, nominal and adjectival argument structures and their inter-relations. HUME operates by aggregating human assess- ments of the translation quality of individual seman- tic units in the source sentence. We are thus avoiding the semantic annotation of machine-generated text, which is often garbled or semantically unclear. This also allows the re-use of the source semantic anno- tation for measuring the quality of different transla- tions of the same source sentence and avoids relying on reference translations, which have been shown to bias annotators ( <ref type="bibr" target="#b13">Fomicheva and Specia, 2016)</ref>.</p><p>After a brief review ( §2), we describe HUME in detail ( §3). Our experiments with four language pairs: English to Czech, German, Polish and Roma- nian ( §4) document HUME's inter-annotator agree- ment and efficiency (time of annotation). We further empirically compare HUME with direct assessment of human adequacy ratings ( §5), and conclude by discussing the differences with HMEANT ( §6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>MT Evaluation. Human evaluation is generally done by ranking the outputs of multiple systems e.g., in the WMT tasks , or by assigning adequacy/fluency scores to each transla- tion, a procedure recently improved by <ref type="bibr" target="#b15">Graham et al. (2015b)</ref> under the title Direct Assessment. We use this latter method to compare and contrast with HUME later in the paper. HTER <ref type="bibr" target="#b29">(Snover et al., 2006</ref>) is another widely used human evaluation met- ric which uses edit distance metrics to compare a translation and its human post-edition. HTER suf- fers from the problem that small edits in the transla- tion could in fact be serious flaws in accuracy, e.g., deleting a negation. Some manual measures ask an- notators to explicitly mark errors, but this has been found to have even lower agreement than ranking ( <ref type="bibr" target="#b21">Lommel et al., 2014</ref>). However, while providing the gold standard for MT evaluation, human evaluation is not a scalable solution. Scalability is addressed by employing au- tomatic and semi-automatic approximations of hu- man judgements. Commonly, such scores decom- pose over the sub-parts of the translation, and quan- tify how many of these sub-parts appear in a manu- ally created reference translation. This decomposi- tion allows system developers to localize the errors. The most commonly used measures decompose over n-grams or individual words, e.g., <ref type="bibr">BLEU (Papineni et al., 2002</ref>), NIST <ref type="bibr" target="#b12">(Doddington, 2002</ref>) and ME- TEOR ( <ref type="bibr" target="#b2">Banerjee and Lavie, 2005</ref>). Another com- mon approach is to determine the similarity between the reference and translation in terms of string edits <ref type="bibr" target="#b29">(Snover et al., 2006</ref>). While these measures stimu- lated much progress in MT research by allowing the evaluation of massive-scale experiments, the focus on words and n-grams does not provide a good esti- mate of semantic correctness, and may favour shal- low string-based MT models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L Linker</head><p>A Participant H Parallel Scene R Relater P Process C Centre <ref type="figure">Figure 1</ref>: Sample UCCA annotation. Leaves correspond to words and nodes to units. The dashed edge indicates that "Tom" is also a participant in the "moved to Amer- ica" Scene. Edge labels mark UCCA categories.</p><p>In order to address this shortcoming, more recent work quantified the similarity of the reference and translation in terms of their structure. <ref type="bibr" target="#b18">Liu and Gildea (2005)</ref> took a syntactic approach, using dependency grammar, and <ref type="bibr" target="#b26">Owczarzak et al. (2007)</ref> took a sim- ilar approach using Lexical Functional Grammar structures. <ref type="bibr">Giménez and Màrquez (2007)</ref> proposed to combine multiple types of information, captur- ing the overlap between the translation and refer- ence in terms of their semantic (predicate-argument structures), lexical and morphosyntactic features. <ref type="bibr" target="#b22">Macháček and Bojar (2015)</ref> divided the source sen- tences into shorter segments, defined using a phrase structure parse, and applied human ranking to the resulting segments.</p><p>Perhaps the most notable attempt at semantic MT evaluation is MEANT and its human variant HMEANT (Lo and Wu, 2011), which quantifies the similarity between the reference and translation in terms of the overlap in their verbal argument struc- tures and associated semantic roles. We discuss the differences between HMEANT and HUME in §6.</p><p>Semantic Representation. UCCA (Universal Conceptual Cognitive Annotation) <ref type="bibr" target="#b0">(Abend and Rappoport, 2013</ref>) is a cross-linguistically applicable scheme for semantic annotation. Formally, an UCCA structure is a directed acyclic graph (DAG), whose leaves correspond to the words of the text. The graph's nodes, called units, are either terminals or several elements jointly viewed as a single entity according to some semantic or cognitive considera- tion. Edges bear a category, indicating the role of the sub-unit in the structure the unit represents.</p><p>UCCA's basic inventory of distinctions (its foun- dational layer) focuses on argument structures (ad-jectival, nominal, verbal and others) and relations between them. The most basic notion is the Scene, which describes a movement, an action or a state which persists in time. Each Scene contains one main relation and zero or more participants. For ex- ample, the sentence "After graduation, Tom moved to America" contains two Scenes, whose main rela- tions are "graduation" and "moved". The participant "Tom" is a part of both Scenes, while "America" only of the latter <ref type="figure">(Figure 1</ref>). Further categories ac- count for inter-scene relations and the sub-structures of participants and relations.</p><p>The use of UCCA for semantic MT evaluation has several motivations. First, UCCA's foundational layer can be annotated by non-experts after a short training ( <ref type="bibr" target="#b0">Abend and Rappoport, 2013;</ref><ref type="bibr" target="#b23">Marinotti, 2014)</ref>. Second, UCCA is cross-linguistically appli- cable, seeking to represent what is shared between languages by building on linguistic typological the- ory <ref type="bibr" target="#b10">(Dixon, 2010b;</ref><ref type="bibr" target="#b9">Dixon, 2010a;</ref><ref type="bibr" target="#b11">Dixon, 2012)</ref>. Its cross-linguistic applicability has so far been tested in annotations of English, French, German and Czech. Third, the scheme has been shown to be stable across translations: UCCA annotations of translated text usually contain the same set of relations ( <ref type="bibr" target="#b30">Sulem et al., 2015)</ref>, indicating that UCCA reflects a layer of representation that in a correct translation is mostly shared between the translation and the source.</p><p>The Abstract Meaning Representation (AMR) ( <ref type="bibr" target="#b1">Banarescu et al., 2013</ref>) shares UCCA's motivation for defining a more complete semantic annotation. However, using AMR is not optimal for defining a decomposition of a sentence into semantic units as it does not anchor its semantic symbols in the text, and thus does not provide clear decomposition of the sentence into sub-spans. Also, AMR is more fine- grained than UCCA and consequently harder to an- notate. Other approaches represent semantic struc- tures as bi-lexical dependencies ( <ref type="bibr" target="#b28">Sgall et al., 1986;</ref><ref type="bibr" target="#b17">Hajič et al., 2012;</ref><ref type="bibr" target="#b24">Oepen and Lønning, 2006</ref>), which are indeed anchored in the text, but are less suitable for MT evaluation as they require linguistic exper- tise for their annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The HUME Measure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Annotation Procedure</head><p>This section summarises the manual annotation procedure used to compute the HUME measure. We denote the source sentence as s and the translation as t. The procedure involves two manual steps: (1) UCCA-annotating s, (2) HUME-annotation: human judgements as to the translation quality of each se- mantic unit of s relative to t, where units are defined according to the UCCA annotation. UCCA annota- tion is performed once for every source sentence, ir- respective of the number of its translations we wish to evaluate, and requires proficiency in the source language only. HUME annotation requires the em- ployment of bilingual annotators. 1 UCCA Annotation. We begin by creating UCCA annotations for the source sentence, following the UCCA guidelines. <ref type="bibr">2</ref> A UCCA annotation for a sen- tence s is a labeled DAG G, whose leaves are the words of s. For every node in G, we define its yield to be its leaf descendants. The semantic units for s according to G are the yields of nodes in G.</p><p>Translation Evaluation. HUME annotation is done by traversing the semantic units of the source sentence, which correspond to the arguments and re- lations expressed in the text, and marking the ex- tent to which they have been correctly translated. HUME aggregates the judgements of the users into a composite score, which reflects the overall extent to which the semantic content of s is preserved in t.</p><p>Annotation of the semantic units requires first de- ciding whether a unit is structural, i.e., has meaning- bearing sub-units in the target language, or atomic. In most cases, atomic units correspond to individual words, but they may also correspond to multi-word expressions that translate as one unit. For instance, the expression "took a shower" is translated into the German "duschte", while its individual words do not correspond to any sub-part of the German transla- tion, motivating the labeling the entire expression as an atomic node. When a multi-word unit is labeled as atomic, its sub-units' annotations are ignored in the evaluation.</p><p>Atomic units can be labelled as "Green" (G, cor- rect), "Orange" (O, partially correct) and "Red" (R, incorrect). Green means that the meaning of the word or phrase has been largely preserved. Orange means that the essential meaning of the unit has been preserved, but some part of the translation is wrong. This is often be due to the translated word having the wrong inflection, in a way that impacts little on the understandability of the sentence. Red means that the essential meaning of the unit has not been cap- tured.</p><p>Structural units have sub-units (children in the UCCA graph), which are themselves atomic or structural. Structural units are labeled as "Adequate" (A) or "Bad" (B), meaning that the relation between the sub-units went wrong 3 . We will use the exam- ple "man bites dog" to illustrate typical examples of why a structural node should be labelled as "Bad": incorrect ordering ("dog bites man"), deletion ("man bites") and insertion ("man bites biscuit dog"). HUME labels reflect adequacy, rather than flu- ency judgements. Specifically, annotators are in- structed to label a unit as Adequate if its translation is understandable and preserves the meaning of the source unit, even if its fluency is impaired. <ref type="figure" target="#fig_0">Figure 2</ref> presents an example of a HUME annota- tion, where the translation is in English for ease of comprehension. When evaluating "to America" the annotator looks at the translation and sees the word "stateside". This word captures the whole phrase and so we mark this non-leaf node with an atomic la- bel. Here we choose Orange since it approximately captures the meaning in this context. The ability to mark non-leaves with atomic labels allows the an- notator to account for translations which only cor- respond at the phrase level. Another feature high- lighted in this example is that by separating struc- tural and atomic units, we are able to define where an error occurs, and localise the error to its point of origin. The linker "After" is translated incorrectly as "by" which changes the meaning of the entire sen- tence. This error is captured at the atomic level, and it is labelled Red. The sentence still contains two Scenes and a Linker and therefore we mark the root node as structurally correct, Adequate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Composite Score</head><p>We proceed to detailing how judgements on the semantic units of the source are aggregated into a composite score. We start by taking a very sim- ple approach and compute an accuracy score. Let Green(s, t), Adequate(s, t) and Orange(s, t) be the number of Green, Adequate and Orange units, re- spectively. Let Units(s) be the number of units marked with any of the labels. Then HUME's com- posite score is: HUME(s, t) = Green(s, t) + Adequate(s, t) + 0.5 · Orange(s, t) Units(s) <ref type="figure">Figure 3</ref> shows the HUME annotation interface 4 . One source sentence and one translation are pre- sented at a time. The user is asked to select a label for each source semantic unit, by clicking the "A", "B", Green, Orange, or Red buttons to the right of the unit's box. Units with multiple parents (as with "Tom" in <ref type="figure" target="#fig_0">Figure 2</ref>) are displayed twice, once under each of their parents, but are only annotatable in one of their instances, to avoid double counting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Annotation Interface</head><p>The interface presents, for each unit, the transla- tion segment aligned with it. This allows the user, especially in long sentences, to focus her attention on the parts that are most likely to be relevant for her judgement. As the alignments are automatically de- rived, and therefore noisy, the annotator is instructed to treat the aligned text is a cue, but to ignore the alignment if it is misleading, and instead make a <ref type="figure">Figure 3</ref>: The HUME annotation tool. The top orange box contains the translation. The source sentence is directly below it, followed by the tree of the source semantic units. Alignments between the source and translation are in italics and unaligned intervening words are in red (see text). judgement according to the full translation. Con- cretely, let s be a source sentence, t a translation, and A ⊂ 2 s ×2 t a many-to-many word alignment. If u is a semantic unit in s, whose yield is yld(u), we define the aligned text in t to be (xs,xt)∈A∧xs∩yld(u) =∅ x t . Where the aligned text is discontinuous in t, words between the left and right boundaries which are not contained in it (intervening words) are pre- sented in a smaller red font. Intervening words are likely to change the meaning of the translation of u, and thus should be attended to when considering whether the translation is correct or not.</p><p>For example, in <ref type="figure">Figure 3</ref>, "ongoing pregnancy" is translated to "Schwangerschaft ... laufenden" (lit. "pregnancy ... ongoing"). This alone seems accept- able but the interleaving words in red notify the an- notator to check the whole translation, in which the meaning of the expression is not preserved <ref type="bibr">5</ref> . The annotator should thus mark this structural node as Bad.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In order to validate the HUME metric, we ran an an- notation experiment with one source language (En- glish), and four target languages (Czech, German, Polish and Romanian), using text from the public health domain. Semantically accurate translation is paramount in this domain, which makes it particu- larly suitable for semantic MT evaluation. HUME is evaluated in terms of its consistency (inter-annotator <ref type="bibr">5</ref> The interleaving words are "... und beide berichtet berichteten ..." (lit. "... and both report reported ..."), which doesn't form any coherent relation with the rest of the sentence. agreement), efficiency (time of annotation) and va- lidity (by comparing it with crowd-sourced ade- quacy judgements).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Translation Systems</head><p>For each of the four language pairs under con- sideration we built phrase-based MT systems using Moses ( <ref type="bibr">Koehn et al., 2007</ref>). These were trained on large parallel data sets extracted from OPUS ( <ref type="bibr" target="#b31">Tiedemann, 2009)</ref>, and the data sets released for the WMT14 medical translation task ( <ref type="bibr" target="#b6">Bojar et al., 2014)</ref>, giving between 45 and 85 million sentences of training data, depending on the language pair. These translation systems were used to translate texts derived from both NHS 24 6 and Cochrane 7 into the four languages. NHS 24 is a public body provid- ing healthcare and health-service related informa- tion in Scotland; Cochrane is an international NGO which provides independent systematic reviews on health-related research. NHS 24 texts come from the "Health A-Z" section in the NHS Inform website, and Cochrane texts come from their plain language summaries and abstracts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">HUME Annotation Statistics</head><p>The source sentences are all in English, and their UCCA annotation was performed by four computa- tional linguists and one linguist. For the annotation of the MT output, we recruited two annotators for each of German, Romanian and Polish and one main annotator for Czech. For computing Czech IAA, several further annotators worked on a small number of sentences each. We treat these further annotators  as one annotator, resulting in two annotators for each language pair. The annotators were all native speak- ers of the respective target languages and fluent in English. They completed a three hour on-line train- ing session which included a description of UCCA and the HUME task, followed by walking through a few examples. <ref type="table">Table 1</ref> shows the total number of sentences and units annotated by each annotator. Not all units in all sentences were annotated, often due to the annotator accidentally missing a node.</p><p>Efficiency. We estimate the annotation time us- ing the timestamps provided by the annotation tool, which are recorded whenever an annotated sentence is submitted. Annotators are not able to re-open a sentence once submitted. To estimate the annota- tion time, we compute the time difference between successive sentences, and discard outlying times, assuming annotation was not continuous in these cases. From inspection of histograms of annotation times, we set the upper threshold at 500 seconds. Median annotation times are presented in <ref type="table">Table 2</ref>, indicating that the annotation of a sentence takes around 2-4 minutes, with some variation between annotators.</p><p>Inter-Annotator Agreement. In order to assess the consistency of the annotation, we measure the Inter-Annotator Agreement (IAA) using Cohen's Kappa on the multiply-annotated units.   Adequate or Bad). As expected and confirmed by confusion matrices in <ref type="figure" target="#fig_2">Figure 4</ref>, there is generally lit- tle confusion between the two types of units. This results in the Kappa for all units being considerably higher than the Kappa over the atomic units or struc- tural units, where there is more internal confusion. To assess HUME reliability for long sentences, we binned the sentences according to length and measured Kappa on each bin ( <ref type="figure" target="#fig_3">Figure 5</ref>). We see no discernible reduction of IAA with sentence length. <ref type="table" target="#tab_1">Table 3</ref> also shows that the overall IAA is similar for all languages, presenting good agreement (0.6- 0.7). However, there are differences observed when we break down by node type. Specifically, we see a contrast between Czech and Polish, where the IAA is higher for atomic than for structural units, and German and Romanian, where the reverse is true. We also observe low IAA (around 0.3) in the cases of German atomic units, and Polish and Czech struc- tural units.</p><p>Looking more closely at the areas of disagree- ment, we see that for the Polish structural units, the proportion of As was quite different between the two annotators (53% vs. 71%), whereas for other lan- guages the annotators agree in the proportions. We believe that this was because one of the Polish an- notators did not fully understand the guidelines for structural units, and percolated errors up the tree, creating more Bs. For German atomic and Czech structural units, where Kappa is also around 0.3, the proportion of such units being marked as "correct" is relatively high, meaning that the class distribution is more skewed, so the expected agreement used in the Kappa calculation is high, lowering Kappa. Finally we note some evidence of domain-specific disagree- ments, for instance the German MT system normally translated "review" (as in "systematic review" -a frequent term in the Cochrane texts) as "Überprü- fung", which one annotator marked correct, and the other (a Cochrane employee) as incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Comparison with Direct Assessment</head><p>Recent research ( <ref type="bibr" target="#b15">Graham et al., 2015b;</ref><ref type="bibr" target="#b14">Graham et al., 2015a;</ref><ref type="bibr" target="#b16">Graham, 2015)</ref> has proposed a new ap- proach for collecting accuracy ratings, direct assess- ment (DA). Statistical interpretation of a large num- ber of crowd-sourced adequacy judgements for each candidate translation on a fine-grained scale of 0 to 100 results in reliable aggregate scores, that corre- late very strongly with one another. We attempted to follow <ref type="bibr" target="#b15">Graham et al. (2015b)</ref> but struggled to get enough crowd-sourced judgements for our target languages. We ended up with 10 ade- quacy judgements on most of the HUME annotated translations for German and Romanian but insuffi- cient data for Czech and Polish. We see this as a severe practical limitation of DA. <ref type="figure" target="#fig_4">Figure 6</ref> plots the HUME score for each sentence against its DA score. HUME and Direct Assessment scores correlate reasonably well. The Pearson corre- lation for en-ro (en-de) is 0.70 (0.58), or 0.78 (0.74) if only doubly HUME-annotated points are consid- ered. This confirms that HUME is consistent with an accepted human evaluation method, despite their conceptual differences. While DA is a valuable tool, HUME has two advantages: it returns fine-grained semantic information about the quality of transla- tions and it only requires very few annotators. Di- rect assessment returns a single opaque score, and (as also noted by <ref type="bibr">Graham et al.)</ref> requires a large crowd which may not be available or reliable. <ref type="figure" target="#fig_5">Figure 7</ref> presents an analysis of HUME's corre- lations with DA by HUME unit type, an analysis enabled by HUME's semantic decomposition. For both target languages, correlation is highest in the 'all' case, supporting our claim for the value of ag- gregating over a wide range of semantic phenom- ena. Some types of nodes predict the DA scores bet- ter than others. HUME scores on As correlate more strongly with DA than scores on Scene Main Rela- tions (P+S). Center nodes (C) are also more corre- lated than elaborator nodes (E), which is expected given that Centers are defined to be more semanti- cally dominant. Future work will construct an aggre- gate HUME score which weights the different node types according to their semantic prominence. HUME and DA are conceputally very different metrics: while DA standardises and averages scores across annotators to denoise the crowd-sourced raw data, thus obtaining a single aggregate score, HUME decomposes over a combinatorial structure, thus al- lowing to localize the translation errors. We now turn to comparing HUME to a more conceptually- related measure, namely HMEANT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Comparison with HMEANT</head><p>HMEANT is a human MT evaluation metric that measures the overlap between the translation a ref- erence in terms of their SRL annotations. In this section we present a qualitative comparison between HUME and HMEANT, using examples from our ex- perimental data. The German translation is largely correct, except that the main verb "sein" ("be") is omitted. While this may be interpreted as a minor error, HMEANT will assign the sentence a very low score, as it failed to translate the main verb.</p><p>It is also relatively common that verbal construc- tions are translated as non-verbal ones or vice versa. The German translation is largely correct, despite the grammatical divergence, namely that the English verb "tend" is translated into the German preposi- tional phrase "in der Regel" ("as a rule"). HMEANT will consider the translation to be of poor quality as there is no German verb to align with the English one.</p><p>We conducted an analysis of the English UCCA Wikipedia corpus (5324 sentences) in order to assess the pervasiveness of three phenomena that are not well supported by HMEANT. 8 First, copula clauses are treated in HMEANT simply as instances of the main verb "be", which generally does not convey the meaning of these clauses. They appear in 21.7% of the sentences, according to conservative estimates that only consider non-auxiliary instances of "be". Second, nominal argument structures, ignored by HMEANT, are in fact highly pervasive, appearing in 48.7% of the sentences. Third, linkers that ex- press inter-relations between clauses (mainly dis- course markers and conjunctions) appear in 56% of the sentences, but are again ignored by HMEANT. For instance, linkers are sometimes omitted in trans- lation, but these omissions are not penalized by HMEANT. The following is such an example from our experimental dataset: Source However, this review was restricted to ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transl. Diese Überprüfung bescränkte sich</head><p>auf ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gloss</head><p>This review was restricted to ...</p><p>We note that some of these issues were already observed in previous applications of HMEANT to languages other than English. See <ref type="bibr" target="#b3">Birch et al. (2013)</ref> for German, Bojar and Wu (2012) for Czech and <ref type="bibr" target="#b8">Chuchunkov et al. (2014)</ref> for Russian.</p><p>One Structure or Two. HUME only annotates the source, while HMEANT relies on two indepen- dently constructed structural annotations, one for the reference and one for the translation. Not annotat- ing the translation is appealing as it is often impos- sible to assign a semantic structure to a low quality translation. On the other hand, HUME may be ar- tificially boosting the perceived understandability of the translation by allowing access to the source.</p><p>Alignment. In HMEANT, the alignment between the reference and translation structures is a key part of the manual annotation. If the alignment cannot be created, the translation is heavily penalized. Bo- jar and Wu (2012) and <ref type="bibr" target="#b8">Chuchunkov et al. (2014)</ref> argue that the structures of the reference and of an accurate translation may still diverge, for instance due to a different interpretation of a PP-attachment, or the verb having an additional modifier in one of the structures. It would be desirable to allow mod- ifications to the SRL annotations at the alignment fied using the NLTK standard tagger. Nominal argument struc- tures are here Scenes whose Main Relation is headed by a noun. stage, to avoid unduly penalizing such spurious di- vergences.</p><p>The same issue is noted by <ref type="bibr" target="#b20">Lo and Wu (2014)</ref>: the IAA on SRL dropped from 90% to 61% when the two aligned structures were from two different an- notators. HUME uses automatic (word-level) align- ment, which only serves as a cue for directing the attention of the annotators. The user is expected to mentally correct the alignment as needed, thus cir- cumventing this difficulty.</p><p>Monolingual vs. Bilingual Evaluation. HUME diverges from HMEANT and from shallower mea- sures like BLEU, in not requiring a reference. In- stead, it directly compares the source and the trans- lation. This requires the employment of bilingual annotators, but has the benefit of avoiding using a reference, which is never uniquely defined, and may thus lead to unjustly low scores where the transla- tion is a paraphrase of the reference. If only mono- lingual annotators are available, the HUME evalua- tion could be performed with a reference sentence instead of with the source. This, however, would risk inaccurate judgements due to the naturally oc- curring differences between the source and its refer- ence translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We have introduced HUME, a human semantic MT evaluation measure which addresses a wide range of semantic phenomena. We have shown that it can be reliably and efficiently annotated in multi- ple languages, and that annotation quality is robust to sentence length. Comparison to direct assess- ments further support HUME's validity. We be- lieve that HUME, and a future automated version of HUME, allows for a finer-grained analysis of trans- lation quality, and will be useful in informing the de- velopment of a more semantically aware approach to MT.</p><p>All annotation data gathered in this project, to- gether with analysis scripts, is available online 9 .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: HUME annotation of an UCCA tree with a word-aligned example translation shown below. Atomic units are labelled using traffic lights (Red, Orange, Green) and structural units are marked A or B.</figDesc><graphic url="image-2.png" coords="4,103.50,57.82,163.81,109.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>cs</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Confusion matrices for each language pair.</figDesc><graphic url="image-6.png" coords="6,315.93,303.20,113.38,77.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Kappa versus sentence length for structural and atomic units. (Node counts in bins on top of each bar.)</figDesc><graphic url="image-10.png" coords="7,74.73,173.48,107.71,80.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: HUME vs DA scores. DA score have been standardised for each crowdsourcing annotator and averaged across exactly 10 annotators. HUME scores are averaged where there were two annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Pearson correlation of HUME vs. DA scores for en-ro and en-de. Each bar represents a correlation between DA and an aggregate HUME score based on a sub-set of the units (#nodes for the en-de/en-ro setting in brackets): all units ("all", 8624/10885), atomic ("atomic", 5417/6888) and structural units ("struct", 3207/3997), and units by UCCA categories: Scene main relations (i.e, Process and State units; "P and S", 954/1178), Parallel Scenes ("H", 656/784), Participants ("A", 1348/1746), Centres ("C", 1904/2474), elaborators ("E", 1608/2031) and linkers ("L", 261/315).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Verbal Structures Only? HMEANT focuses on verbal argument structures, ignoring other pervasive phenomena such as non-verbal predicates and inter- clausal relations. Consider the following example: Source a coronary angioplasty may not be technically possible Transl. eine koronare Angioplastie kann nicht technisch möglich Gloss a coronary angioplasty can not techni- cally possible</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 re</head><label>3</label><figDesc>- ports the number of units which have two annota- tions from different annotators and the correspond- ing Kappas. We report the overall Kappa, as well as separate Kappas on atomic units (annotated as Red, Orange or Green) and structural units (annotated as</figDesc><table>cs 
de 
pl 
ro 
Sentences 
181 
102 
334 
217 
All units 
4686 2793 8384 5604 
Kappa 
0.64 0.61 0.58 0.69 
Atomic units 
2982 1724 5386 3570 
Kappa 
0.54 0.29 0.54 0.50 
Structural units 1602 1040 2655 1989 
Kappa 
0.31 0.44 0.33 0.58 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>IAA for the multiply-annotated units, measured 
by Cohen's Kappa. 

</table></figure>

			<note place="foot" n="1"> Where bilingual annotators are not available, the evaluation could be based on the UCCA structure for the reference translation. See discussion in §6. 2 All UCCA-related resources can be found here: http: //www.cs.huji.ac.il/~oabend/ucca.html</note>

			<note place="foot" n="3"> Three labels are used with atomic units, as opposed to two labels with structural units, as atomic units are more susceptible to slight errors.</note>

			<note place="foot" n="4"> A demo of HUME can be found in www.cs.huji.ac. il/~oabend/hume_demo.html</note>

			<note place="foot" n="6"> http://www.nhs24.com/ 7 http://www.cochrane.org/</note>

			<note place="foot" n="8"> Argument structures and linkers are explicitly marked in UCCA. Non-auxiliary instances of &quot;be&quot; and nouns are identi</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This project has received funding from the European Union's Horizon 2020 research and innovation pro-gramme under grant agreement 644402 (HimL). <ref type="bibr">9</ref> https://github.com/bhaddow/hume-emnlp16</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Universal conceptual cognitive annotation (ucca)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="228" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>Linguistic Annotation Workshop and Interoperability with Discourse</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, MI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The feasibility of HMEANT as a human MT evaluation metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Nadejde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth Workshop on Statistical Machine Translation</title>
		<meeting>the Eighth Workshop on Statistical Machine Translation<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="52" to="61" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards a PredicateArgument Evaluation for MT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>the Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation<address><addrLine>Jeju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07" />
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A grain of salt for the WMT manual evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miloš</forename><surname>Ercegovčevi´ercegovčevi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">F</forename><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Findings of the 2014 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saintamand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Tamchyna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation</title>
		<meeting>the Ninth Workshop on Statistical Machine Translation<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
		<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1" to="46" />
		</imprint>
	</monogr>
	<note>Findings of the 2015 workshop on statistical machine translation</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Applying HMEANT to EnglishRussian Translations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Chuchunkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Tarelkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Galinskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="43" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Grammatical Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Further Grammatical Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram co-occurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second international conference on Human Language Technology Research</title>
		<meeting>the second international conference on Human Language Technology Research<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="138" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Linguistic features for automatic evaluation of heterogenous mt systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Fomicheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">54th Annual Meeting of the Association for Computational Linguistics, ACL</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="264" />
		</imprint>
	</monogr>
	<note>Proceedings of the Second Workshop on Statistical Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Can machine translation systems be evaluated by the crowd alone?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accurate evaluation of segment-level machine translation metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitika</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1183" to="1191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving evaluation of machine translation quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1804" to="1813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hajičová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarmila</forename><surname>Panevová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Sgall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Fučíková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Mikulová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Pajas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Popelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Semecký</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Šindlerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Štěpánek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Toman ; Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Companion Volume Proceedings of the Demo and Poster Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics, Companion Volume the Demo and Poster Sessions<address><addrLine>Istanbul, Turkey, May. ELRA; Alexandra Birch; Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Proceedings of the Eighth International Language Resources and Evaluation Conference (LREC&apos;12). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Syntactic features for evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2005 Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structured vs. flat semantic role representations for machine translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation</title>
		<meeting>the Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="10" to="20" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the Reliability and Inter-Annotator Agreement of Human Semantic MT Evaluation via HMEANT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrafn</forename><surname>Loftsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Joseph Mariani, Asuncion Moreno, Jan Odijk; Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Nicoletta Calzolari (Conference Chair). European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Assessing Inter-Annotator Agreement for Translation Error Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Arle Richard Lommel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljoscha</forename><surname>Popovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burchardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MTE: Workshop on Automatic and Manual Metrics for Operational Translation Evaluation. LREC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating Machine Translation Quality Using Short Segments Annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matouš</forename><surname>Macháček</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="85" to="110" />
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Measuring semantic preservation in machine translation with HCOMET: human cognitive metric for evaluating translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Marinotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Discriminant-based MRS banking</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<biblScope unit="page" from="1250" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evaluating machine translation with LFG dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Owczarzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Way</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Translation</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="95" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Meaning of the Sentence and Its Semantic and Pragmatic Aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Sgall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Hajičová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarmila</forename><surname>Panevová</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A study of translation edit rate with targeted human annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnea</forename><surname>Micciulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Makhoul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of association for machine translation in the Americas</title>
		<meeting>association for machine translation in the Americas</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="223" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Conceptual annotations preserve structure across translations: A French-English case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2015 Workshop on Semantics-Driven Statistical Machine Translation (S2MT)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">News from OPUS-a collection of multilingual parallel corpora with tools and interfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing</title>
		<meeting><address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
