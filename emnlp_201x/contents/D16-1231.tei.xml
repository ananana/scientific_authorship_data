<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:24+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Addressee and Response Selection for Multi-Party Conversation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>November 1-5, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Ouchi</surname></persName>
							<email>ouchi.hiroki.nt6@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Nara Institute of Science and Technology</orgName>
								<orgName type="institution" key="instit2">IBM Research -Tokyo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Tsuboi</surname></persName>
							<email>yutat@jp.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Nara Institute of Science and Technology</orgName>
								<orgName type="institution" key="instit2">IBM Research -Tokyo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Addressee and Response Selection for Multi-Party Conversation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Austin, Texas</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2133" to="2143"/>
							<date type="published">November 1-5, 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>To create conversational systems working in actual situations, it is crucial to assume that they interact with multiple agents. In this work, we tackle addressee and response selection for multi-party conversation, in which systems are expected to select whom they address as well as what they say. The key challenge of this task is to jointly model who is talking about what in a previous context. For the joint modeling, we propose two model-ing frameworks: 1) static modeling and 2) dynamic modeling. To show benchmark results of our frameworks, we created a multi-party conversation corpus. Our experiments on the dataset show that the recurrent neural network based models of our frameworks robustly predict addressees and responses in conversations with a large number of agents.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Short text conversation (STC) has been gaining pop- ularity: given an input message, predict an appropri- ate response in a single-round, two-party conversa- tion ( <ref type="bibr" target="#b28">Wang et al., 2013;</ref><ref type="bibr" target="#b22">Shang et al., 2015)</ref>. Model- ing STC is simpler than modeling a complete con- versation, but instantly helps applications such as chat-bots and automatic short-message replies <ref type="bibr" target="#b7">(Ji et al., 2014</ref>).</p><p>Beyond two-party conversations, there is also a need for modeling multi-party conversation, a form of conversation with several interlocutors convers- ing with each other <ref type="bibr" target="#b24">(Traum, 2003;</ref><ref type="bibr" target="#b3">Dignum and Vreeswijk, 2003;</ref><ref type="bibr" target="#b25">Uthus and Aha, 2013)</ref>. For exam- ple, in the Ubuntu Internet Relay Chat (IRC), sev- eral users cooperate to find a solution for a techni- cal issue contributed by another user. Each agent might have one part of the solution, and these pieces have to be combined through conversation in order to come up with the whole solution.</p><p>A unique issue of such multi-party conversations is addressing, a behavior whereby interlocutors in- dicate to whom they are speaking <ref type="bibr" target="#b8">(Jovanovi´cJovanovi´c and Akker, 2004;</ref><ref type="bibr" target="#b0">Akker and Traum, 2009)</ref>. In face- to-face communication, the basic clue for speci- fying addressees is turning one's face toward the addressee. In contrast, in voice-only or text- based communication, the explicit declaration of ad- dressee's names is more common.</p><p>In this work, we tackle addressee and response selection for multi-party conversation: given a con- text, predict an addressee and response. As Fig- ure 1 shows, a system is required to select an ad- dressee from the agents appearing in the previous context and a response from a fixed set of candidate responses (Section 3).</p><p>The key challenge for predicting appropriate ad- dressees and responses is to jointly capture who is talking about what at each time step in a con- text. For jointly modeling the speaker-utterance in- formation, we present two modeling frameworks: 1) static modeling and 2) dynamic modeling (Sec- tion 5). While speakers are represented as fixed vectors in the static modeling, they are represented as hidden state vectors that dynamically change with time steps in the dynamic modeling. In prac- tice, our models trained for the task can be applied to retrieval-based conversation systems, which re- trieves candidate responses from a large-scale repos- itory with the matching model and returns the high- est scoring one with the ranking model ( <ref type="bibr" target="#b28">Wang et al., 2013;</ref><ref type="bibr" target="#b7">Ji et al., 2014;</ref><ref type="bibr" target="#b29">Wang et al., 2015)</ref>. Our trained models work as the ranking model and allow the conversation system to produce addressees as well as responses.</p><p>To evaluate the trained models, we provide a cor- pus and dataset. By exploiting Ubuntu IRC Logs 1 , we build a large-scale multi-party conversation cor- pus, and create a dataset from it (Section 6). Our experiments on the dataset show the models instanti- ated by the static and dynamic modeling outperform a strong baseline. In particular, the model based on the dynamic modeling robustly predicts appropriate addressees and responses even if the number of in- terlocutors in a conversation increases. <ref type="bibr">2</ref> We make three contributions in this work:</p><p>1. We formalize the task of addressee and re- sponse selection for multi-party conversation.</p><p>2. We present modeling frameworks and the per- formance benchmarks for the task.</p><p>3. We build a large-scale multi-party conversation corpus and dataset for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This work follows in the footsteps of <ref type="bibr" target="#b20">Ritter et al. (2011)</ref>, who tackled the response generation prob- lem: given a context, generate an appropriate re- sponse. While previous response generation ap-https://github.com/hiroki13/response-ranking proaches utilize statistical models on top of heuris- tic rules or templates ( <ref type="bibr" target="#b12">Levin et al., 2000;</ref><ref type="bibr" target="#b32">Young et al., 2010;</ref><ref type="bibr" target="#b27">Walker et al., 2003)</ref>, they apply statistical machine translation based techniques without such heuristics, which leads to recent work utilizing the SMT-based techniques with neural networks <ref type="bibr" target="#b22">(Shang et al., 2015;</ref><ref type="bibr" target="#b26">Vinyals and Le, 2015;</ref><ref type="bibr" target="#b23">Sordoni et al., 2015;</ref><ref type="bibr" target="#b21">Serban et al., 2016)</ref>. As another popular approach, retrieval-based techniques are used to retrieve candidate responses from a repository and return the highest scoring one with the ranking model ( <ref type="bibr" target="#b7">Ji et al., 2014;</ref><ref type="bibr" target="#b29">Wang et al., 2015;</ref><ref type="bibr" target="#b6">Hu et al., 2014;</ref><ref type="bibr" target="#b28">Wang et al., 2013;</ref>. Stemming from this approach, the next utter- ance classification (NUC) task has been proposed, in which a system is required to select an appropriate response from a fixed set of candidates ( <ref type="bibr" target="#b14">Lowe et al., 2015;</ref><ref type="bibr" target="#b10">Kadlec et al., 2015)</ref>. The NUC is regarded as focusing on the ranking problem of retrieval-based system, since it omits the candidate retrieving step. The merit of NUC is that it allows us to easily evalu- ate the model performance on the basis of accuracy.</p><p>Our proposed addressee and response selection task is an extension of the NUC. We generalize the task by integrating the addressee detection, which has been regarded as a problematic issue in multi- party conversation <ref type="bibr" target="#b24">(Traum, 2003;</ref><ref type="bibr" target="#b8">Jovanovi´cJovanovi´c and Akker, 2004;</ref><ref type="bibr" target="#b25">Uthus and Aha, 2013)</ref>. Basically, the addressee detection has been tackled in the spoken/multimodal dialog system research, and the models largely rely on acoustic signal or gaze infor- mation <ref type="bibr" target="#b9">(Jovanovi´cJovanovi´c et al., 2006;</ref><ref type="bibr" target="#b0">Akker and Traum, 2009;</ref><ref type="bibr" target="#b19">Ravuri and Stolcke, 2014</ref>). This current work is different from such previous work in that our mod- els predict addressees with only textual information.</p><p>For predicting addressees or responses, how the context is encoded is crucial. In single-round con- versation, a system is expected to encode only one utterance as a context <ref type="bibr" target="#b20">(Ritter et al., 2011;</ref><ref type="bibr" target="#b28">Wang et al., 2013)</ref>. In contrast, in multi-turn conversation, a system is expected to encode multiple utterances ( <ref type="bibr" target="#b22">Shang et al., 2015;</ref><ref type="bibr" target="#b14">Lowe et al., 2015)</ref>. Very re- cently, individual personalities have been encoded as distributed embeddings used for response genera- tion in two-party conversation ( <ref type="bibr" target="#b13">Li et al., 2016)</ref>. Our work is different from that work in that our proposed personality-independent representation allows us to handle new agents unseen in the training data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Addressee and Response Selection</head><p>We propose and formalize the task of addressee and response selection (ARS) for multi-party conversa- tion. The ARS task assumes the situation where a responding agent gives a response to an addressee following a context. 3</p><p>Notation <ref type="table">Table 1</ref> shows the notations for the formalization. We denote vectors with bold lower-case (e.g. x t , h), matrices with bold upper-case (e.g. W, H a ), scalars with italic lower-case or upper-case (e.g. a m , Q), and sets with bold italic lower-case or cursive upper- case (e.g. x, C) letters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Formalization</head><p>Given an input conversational situation x, an ad- dressee a and a response r are predicted:</p><formula xml:id="formula_0">GIVEN : x = (a res , C, R) PREDICT : a, r</formula><p>where a res is a responding agent, C is a context and R is a set of candidate responses. The context C is a sequence of previous utterances up to the current time step T :</p><formula xml:id="formula_1">C = (u a 1 ,1 , · · · , u a T ,T )</formula><p>where u at,t is an utterance given by an agent a t at a time step t. Each utterance u at,t is a sequence of N t tokens:</p><formula xml:id="formula_2">u at,t = (w at,t,1 , · · · , w at,t,Nt )</formula><p>where w at,t,n is a token index in the vocabulary V.</p><p>To predict an addressee a as a target output, we select an agent from a set of the agents appearing in a context A(C). Note that a ground-truth addressee is always included in A(C). To predict an appropri- ate response r, we select a response from a set of candidate responses R, which consists of Q candi- dates:</p><formula xml:id="formula_3">R = {r 1 , · · · , r Q } r q = (w q,1 , · · · , w q,Nq )</formula><p>where r q is a candidate response, which consists of N q tokens, and w q,n is an token index in the vocab- ulary V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dual Encoder Models</head><p>Our proposed models are extensions of the dual encoder (DE) model in ( <ref type="bibr" target="#b14">Lowe et al., 2015</ref>). The DE model consists of two recurrent neural networks (RNN) that respectively compute the vector repre- sentation of an input context and candidate response.</p><p>A generic RNN, with input x t ∈ R dw and recur- rent state h t ∈ R d h , is defined as:</p><formula xml:id="formula_4">h t = f (h t−1 , x t ) = π(W h h t−1 + W x x t ) (1)</formula><p>where π is a non-linear function, W x ∈ R d h ×dw is a parameter matrix for x t , W h ∈ R d h ×d h is a param- eter matrix for h t−1 , and the recurrence is seeded with the 0 vector, i.e. h 0 = 0. The recurrent state h t acts as a compact summary of the inputs seen up to time step t.</p><p>In the DE model, each word vector of the con- text C and the response r q is consumed by each RNN, and is then summarized into the context vec- tor h c ∈ R d h and the response vector h q ∈ R d h . Us- ing these vectors, the model calculates the probabil- ity that the given candidate response is the ground- truth response given the context as follows:</p><formula xml:id="formula_5">P r(y(r q ) = 1|C, r q ) = σ(h T c W h q ) (2)</formula><p>where y is a binary function mapping from r q to {0, 1}, in which 1 represents the ground-truth sam- ple and 0 represents the false one, σ is the logistic sigmoid function, and W ∈ R d h ×d h is a parameter matrix. As extensions of this model, we propose our multi-party encoder models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Multi-Party Encoder Models</head><p>For capturing multi-party conversational streams, we jointly encode who is speaking what at each time step. Each agent and its utterance are integrated into the hidden states of an RNN. We present two multi-party modeling frame- works: (i) static modeling and (ii) dynamic mod- eling, both of which jointly utilize agent and ut- terance representation for encoding multiple-party conversation. What distinguishes the models is that while the agent representation in the static modeling framework is fixed, the one in the dynamic modeling framework changes along with each time step t in a conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling Frameworks</head><p>As an instance of the static modeling, we propose a static model to capture the speaking-orders of agents in conversation. As an instance of the dynamic mod- eling, we propose a dynamic model using an RNN to track agent states. Note that the agent represen- tations are independent of each personality (unique user). The personality-independent representation allows us to handle new agents unseen in the training data.</p><p>Formally, similar to Eq. 2, both of the models calculate the probability that the addressee a p or re- sponse r q is the ground-truth given the input x:</p><formula xml:id="formula_6">P r(y(a p ) = 1|x) = σ ([a res ; h c ] T W a a p ) (3) P r(y(r q ) = 1|x) = σ ([a res ; h c ] T W r h q ) (4)</formula><p>where y is a binary function mapping from a p or r q to {0, 1}, in which 1 represents the ground-truth sample and 0 represents the false one. The func- tion σ is the logistic sigmoid function. a res ∈ R da is a responding agent vector, a p ∈ R da is a candi- date addressee vector, h c ∈ R d h is a context vector, h q ∈ R d h is a candidate response vector. These vec- tors are respectively defined in each model. W a ∈ R (da+d h )×d h is a parameter matrix for the addressee selection probability, and W r ∈ R (da+d h )×d h is a parameter matrix for the response selection proba- bility. These model parameters are learned during training.</p><p>On the basis of Eqs. 3 and 4, a resulting addressee </p><formula xml:id="formula_7">ˆ a = argmax ap∈A(C) P r(y(a p ) = 1|x)<label>(5)</label></formula><formula xml:id="formula_8">ˆ r = argmax rq∈R P r(y(r q ) = 1|x)<label>(6)</label></formula><p>wherê a is the highest probability addressee of a set of agents in the context A(C), andˆrandˆ andˆr is the highest probability response of a set of candidate responses R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">A Static Model</head><p>In the static model, agent matrix A is defined for the agent vectors in Eqs. 3 and 4. This agent matrix can be defined arbitrarily. We define the agent matrix A on the basis of agents' speaking orders. Intuitively, the agents that spoke in recent time steps are more likely to be an addressee. Our static model captures such property.</p><p>The static model is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. First, agents in the context A(C) and a responding agent a res are sorted in descending order based on each latest speaking time. Then the order is assigned as an agent index a m ∈ (1, · · · , |A(C)|) to each agent. In the table shown in <ref type="figure" target="#fig_1">Figure 2</ref>, the responding agent (represented as SYSTEM) has the agent index 1 be- cause he spoke at the most recent time step t = 6. Similarly, User 1 has the index 2 because he spoke at the second most recent time step t = 5, and User 2 has the index 3 because he spoke at the third t = 3.</p><p>Each speaking-order index a m is associated with the a m -th column of the agent matrix A: </p><formula xml:id="formula_9">a m = A[ * , a m ]</formula><note type="other">Similarly, a responding agent vector a res and a can- didate addressee vector a p in Eqs. 3 and 4 are re- spectively extracted from A, i.e. a res = A[ * , a res ] and a</note><formula xml:id="formula_10">p = A[ * , a p ].</formula><p>Consuming the agent vectors, an RNN updates its hidden state. For example, at the time step t = 1 in <ref type="figure" target="#fig_1">Figure 2</ref>, the agent vector a 1 of User 1 is extracted from A on the basis of agent index 2 and then con- sumed by the RNN. Then, the RNN consumes each word vector w of User 1's utterance. By consum- ing the agent vector before word vectors, the model can capture which agent speaks the utterance. The last state of the RNN is regarded as h c . As the tran- sition function f of RNN (Eq. 1), we use the Gated Recurrent Unit (GRU) ( <ref type="bibr" target="#b2">Chung et al., 2014</ref>).</p><p>For the candidate response vector h q , each word vector (w q,1 , · · · , w q,Nq ) in the response r q is sum- marized with the RNN. Using these vectors a res , a p , h c , and h q , we predict a next addressee and response with the Eqs. 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">A Dynamic Model</head><p>In the static model, agent representation A is a fixed matrix that does not change in a conversational stream. In contrast, in the dynamic model, agent representation A t tracks each agent's hidden state which dynamically changes with time steps t. <ref type="figure" target="#fig_2">Figure 3</ref> shows the overview of the dynamic model. Initially, we set a zero matrix as initial agent state A 0 , and each column vector of the agent matrix corresponds to an agent hidden state vector. Then, each agent state is updated by consuming the utter- ance vector at each time step. Note that the states of the agents that are not speaking at the time are updated by zero vectors.</p><p>Formally, each column of A t corresponds to an agent state vector:</p><formula xml:id="formula_11">a m,t = A t [ * , a m ]</formula><p>where an agent state vector a m,t of an agent a m at a time step t is the a m -th column of the agent matrix A t .</p><p>Each vector of the matrix is updated at each time step, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. An agent state vector a m,t ∈ R da for each agent a m at each time step t is recurrently computed:</p><formula xml:id="formula_12">a m,t = g(a m,t−1 , u m,t ), a m,0 = 0</formula><p>where u m,t ∈ R dw is a summary vector of an ut- terance of an agent a m and computed with an RNN. As the transition function g, we use the GRU. For example, at a time step t = 2 in <ref type="figure" target="#fig_2">Figure 3</ref>, the agent state vector a 1,2 is influenced by its utterance vector u 1,2 and updated from the previous state a 1,1 .</p><p>The agent matrix updated up to the time step T is denoted as A T , which is max-pooled and used as a summarized context vector:</p><formula xml:id="formula_13">h c = max i A T [i]</formula><p>The agent matrix A T is also used for a responding agent vector a res and a candidate addressee vector a p , i.e. a res = A T [ * , a res ] and a p = A T [ * , a p ]. r q is summarized into a response vector h q in the same way as the static model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Learning</head><p>We train the model parameters by minimizing the joint loss function:</p><formula xml:id="formula_14">L(θ) = α L a (θ) + (1 − α) L r (θ) + λ 2 ||θ|| 2</formula><p>where L a is the loss function for the addressee selec- tion, L r is the loss function for the response selec- tion, α is the hyper-parameter for the interpolation, and λ is the hyper-parameter for the L2 weight de- cay. For addressee and response selection, we use the cross-entropy loss functions:</p><formula xml:id="formula_15">L a (θ) = − ∑ n [ log P r(y(a + ) = 1|x) + log (1 − P r(y(a − ) = 1|x) ] L r (θ) = − ∑ n [ log P r(y(r + ) = 1|x) + log (1 − P r(y(r − ) = 1|x) ]</formula><p>where x is the input set for the task, i.e. x = (a res , C, R), a + is a ground-truth addressee, a − is a false addressee, r + is a ground-truth response, and r − is a false response. As a false addressee a − , we pick up and use the addressee with the high- est probability from the set of candidate addressees except the ground-truth one (A(C) \ a + ). As a false response, we randomly pick up and use a re- sponse from the set of candidate responses except the ground-truth one (R \ r + ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Corpus and Dataset</head><p>Our goal is to provide a multi-party conversation corpus/dataset that can be used over a wide range of conversation research, such as turn-taking model- ing <ref type="bibr" target="#b18">(Raux and Eskenazi, 2009</ref>) and disentanglement modeling <ref type="bibr" target="#b4">(Elsner and Charniak, 2010)</ref>, as well as for the ARS task. <ref type="figure" target="#fig_3">Figure 4</ref> shows the flow of the cor- pus and dataset creation process. We firstly crawl Ubuntu IRC Logs and preprocess the obtained logs.  Then, from the logs, we extract and add addressee information to the corpus. In the final step, we set candidate responses and labels as the dataset. <ref type="table" target="#tab_2">Table  2</ref> shows the statistics of the corpus and dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Ubuntu IRC Logs</head><p>The Ubuntu IRC Logs is a collection of logs from Ubuntu-related chat rooms. In each chat room, a number of users chat on and discuss various topics, mainly related to technical support with Ubuntu is- sues.</p><p>The logs are put together into one file per day for each room. Each file corresponds to a document D. In a document, one line corresponds to one log given by a user. Each log consists of three items (Time, UserID, Utterance). Using such informa- tion, we create a multi-party conversation corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Multi-Party Conversation Corpus</head><p>To pick up only the documents written in En- glish, we use a language detection library <ref type="bibr" target="#b16">(Nakatani, 2010)</ref>. Then, we remove the system logs from each document and leave only user logs. For segmenting the words in each utterance, we use a word tokenizer (TreebankWordTokenizer) of the Natural Language Toolkit <ref type="bibr">4</ref> . Using the preprocessed docu- ments, we create a corpus, whose row consists of the three items (UserID, Addressee, Utterance).</p><p>First, the IDs of the users in a document are col- lected into the user ID list by referring to the UserID in each log. Then, as the addressee user ID, we ex- tract the first word of each utterance. In the Ubuntu IRC Logs, users follow the name mention conven- tion ( <ref type="bibr" target="#b25">Uthus and Aha, 2013)</ref>, in which they express their addressee by mentioning the addressee's user ID at the beginning of the utterance. By exploiting the name mentions, if the first word of each utter- ance is identical to a user ID in the user ID list, we extract the addressee ID and then create a table con- sisting of (UsetID, Addressee, Utterance). In the case that addressee IDs are not explicitly men- tioned at the beginning of the utterance, we do not extract anything.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">The ARS Dataset</head><p>By exploiting the corpus, we create a dataset for the ARS task. If the line of the corpus includes an addressee ID, we regard it as a sample for the task. As the ground truth addressees and responses, we straightforwardly use the obtained addressee IDs and the preprocessed utterances.</p><p>As false responses, we sample utterances else- where within a document. This document-within sampling method makes the response selection task more difficult than the random sampling method <ref type="bibr">5</ref> . One reason for this is that common or similar top- ics in a document are often discussed and the used words tend to be similar, which makes the word- based features for the task less effective. We par- titioned the dataset randomly into a training set (90%), a development set (5%) and a test set (5%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>We provide performance benchmarks of our learn- ing architectures on the addressee and response se- lection (ARS) task for multi-party conversation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We use the created dataset for the experiments. The number of candidate responses RES-CAND (|R|) is set to 2 or 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>We evaluate performance by accuracies on three aspects: addressee-response pair selection (ADR-RES), addressee selection (ADR), and re- sponse selection (RES). In the addressee-response pair selection, we regard the answer as correct if both the addressee and the response are correctly <ref type="bibr">5</ref> Lowe et al. (2015) adopted the random sampling method. selected. In the addressee/response selection, we re- gard the answer as correct if the addressee/response is correctly selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization</head><p>The models are trained by backpropagation through time <ref type="bibr" target="#b30">(Werbos, 1990;</ref><ref type="bibr" target="#b5">Graves and Schmidhuber, 2005</ref>). For the backpropagation, we use stochastic gradient descent (SGD) with a mini-batch training method. The mini-batch size is set to 128. The hyper-parameter α for the interpolation between the two loss functions (Section 5.3) is set to 0.5. For the L2 weight decay, the hyper-parameter λ is selected from {0.001, 0.0005, 0.0001}.</p><p>Parameters of the models are randomly ini- tialized over a uniform distribution with support [−0.01, 0.01]. To update parameters, we use Adam ( <ref type="bibr" target="#b11">Kingma and Ba, 2014</ref>) with the default setting sug- gested by the authors. As the word embeddings, we used the 300 dimension vectors pre-trained by GloVe 6 ( <ref type="bibr" target="#b17">Pennington et al., 2014</ref>). To avoid over- fitting, the word vectors are fixed across all exper- iments. The hidden dimensions of parameters are set to d w = 300 and d h = 50 in the both models, and d a is set to 300 in the static model and 50 in the dynamic model.</p><p>To identify the best training epoch and model con- figuration, we use the early stopping method ( <ref type="bibr" target="#b31">Yao et al., 2007)</ref>. In this method, if the best accuracy of ADR-RES on the development set has not been up- dated for consecutive 5 epochs, training is stopped and the best performing model is picked up. The max epochs is set to 30, which is sufficient for con- vergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>For computational efficiency, we limit the length of a context C as</p><formula xml:id="formula_16">C T −Nc+1:T = (u T −Nc+1 , · · · , u T ),</formula><p>where N c , called context window, is the number of utterances prior to a time step t. We set N c to {5, 10, 15}. In addition, we truncate the utterances and responses at a maximum of 20 words. For batch processing, we zero-pad them so that the number of words is constant. Out-of-vocabulary words are re- placed with &lt;unk&gt;, whose vector is the averaged vector over all word vectors.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RES-CAND = 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RES-CAND = 10 N c ADR-RES ADR RES ADR-RES ADR RES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Model</head><p>We set a baseline using the term frequency-inverse document frequency (TF-IDF) retrieval model for the response selection ( <ref type="bibr" target="#b14">Lowe et al., 2015)</ref>. We firstly compute two TF-IDF vectors, one for a context win- dow and one for a candidate response. Then, we compute a cosine similarity for these vectors, and select the highest scoring candidate response as a result. For the addressee selection, we adopt a rule- based method: to determine the agent that gives an utterance most recently except a responding agent, which captures the tendency that agents often re- spond to the other that spoke immediately before. <ref type="table" target="#tab_4">Table 3</ref> shows the empirical benchmark results. The dynamic model achieves the best results in all the metrics. The static model outperforms the baseline, but is inferior to the dynamic model. In addressee selection (ADR), the baseline model achieves around 55% in accuracy. This means that if you select the agents that spoke most recently as an addressee, the half of them are correct. Compared with the baseline, our proposed models achieve bet- ter results, which suggests that the models can se- lect the correct addressees that spoke at more pre- vious time steps. In particular, the dynamic model achieves 68% in accuracy, which is 7 point higher than the accuracy of static model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall Performance</head><p>In response selection (RES), our models outper- form the baseline. Compared with the static model, the dynamic model achieves around 0.5 point higher in accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of the Context Window</head><p>In response selection, a performance boost of our proposed models is observed for the context win- dow N c = 10 over N c = 5. Comparing the results of the models with the context window N c = 10 and N c = 15, the performance is improved but relatively small, which suggests that the performance almost reaches the convergence. In addressee selection, the performance improvements of the static model with the broader context window is limited. In contrast, in the dynamic model, a steady performance boost is observed, yielding an increase of over 5 points be- tween N c = 15 and N c = 5, <ref type="bibr">No. of Agents 2-5 6-10 11-15 16-20 21-30 31-100 101-305 No.</ref>   Effects of the Sample Size <ref type="figure" target="#fig_4">Figure 5</ref> shows the accuracy curves of addressee- response selection (ADR-RES) for different train- ing sample sizes. We use 1/2, 1/4, and 1/8 of the whole training samples for training. The results show that as the amount of the data increases, the performance of our models are improved and grad- ually approaches the convergence. Remarkably, the performance of the dynamic models using the 1/8 samples is comparable to that of the static model us- ing the whole samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of the Number of Participants</head><p>To shed light on the relationship between the model performance and the number of agents in multi-party conversation, we investigate the effect of the num- ber of agents participating in each context. <ref type="table" target="#tab_6">Table 4</ref> compares the performance of the models for differ- ent numbers of agents in a context. In addressee selection, the performance of all models gradually gets worse as the number of agents in the context increases. However, compared with the baseline, our proposed models suppress the per- formance degradation. In particular, the dynamic model predicts correct addressees most robustly.</p><p>In response selection, unexpectedly, the perfor- mance of all the models gets better as the number of agents increases. Detailed investigation on the in- teraction between the number of agents and the re- sponse selection complexity is an interesting line of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We proposed addressee and response selection for multi-party conversation. Firstly, we provided the formal definition of the task, and then created a cor- pus and dataset. To present benchmark results, we proposed two modeling frameworks, which jointly model speakers and their utterances in a context. Experimental results showed that our models of the frameworks outperform a baseline.</p><p>Our future objective to tackle the task of predict- ing whether to respond to a particular utterance. In this work, we assume that the situations where there is a specific addressee that needs an appropriate re- sponse and a system is required to respond. In actual multi-party conversation, however, a system some- times has to wait and listen to the conversation that other participants are engaging in without needless interruption. Hence, the prediction of whether to respond in a multi-party conversation would be an important next challenge.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Addressee and response selection for multi-party conversation. A SYSTEM is required to select an appropriate addressee from the interlocutors in the conversational context and an appropriate response from the fixed set of candidates.</figDesc><graphic url="image-1.png" coords="1,327.39,237.86,198.36,104.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustrative example of our static model.</figDesc><graphic url="image-2.png" coords="4,320.30,57.82,212.60,148.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustrative example of our dynamic model.</figDesc><graphic url="image-3.png" coords="5,79.10,57.82,212.60,148.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The flow of the corpus and dataset creation. From the original logs, we extract addressee IDs and add them to the corpus. As the dataset, we add candidate responses and the labels.</figDesc><graphic url="image-4.png" coords="6,79.10,57.81,212.52,165.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Accuracies in addressee-response selection using different amount of samples for training.</figDesc><graphic url="image-5.png" coords="8,320.30,261.51,212.58,159.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Statistics of the corpus and dataset. "Docs" is docu-

ments, "Utters" is utterances, "W. / U." is the number of words 

per utterance, "A. / D." is the number of agents per document. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Benchmark results: accuracies on addressee-response selection (ADR-RES), addressee selection (ADR), and response 

selection (RES). Nc is the context window. Bolded are the best per column. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Performance comparison for different numbers of agents appearing in the context. The numbers are accuracies on the test 

set with the number of candidate responses CAND-RES = 2 and the context window Nc = 15. 

</table></figure>

			<note place="foot" n="1"> http://irclogs.ubuntu.com/ 2 Our code, corpus, and dataset are publicly available at</note>

			<note place="foot" n="3"> In actual situations, responses can be addressed to multiple agents. In this work, we assume the situation where one specific agent can be the addressee of a response.</note>

			<note place="foot" n="4"> http://www.nltk.org/</note>

			<note place="foot" n="6"> http://nlp.stanford.edu/projects/glove/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Graham Neubig, Yuya Taguchi, Ryosuke Kohita, Ander Martinez, the members of the NAIST Computational Linguistics Laboratory, the members of IBM Research-Tokyo, Long Duong, and the re-viewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comparison of addressee detection methods for multiparty conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rieks</forename><surname>Akker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on the Semantics and Pragmatics of Dialogue</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<title level="m">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards a testbed for multi-party dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dignum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Gerard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vreeswijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Agent Communication</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="212" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Disentangling chat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="389" to="409" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingcai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An information retrieval approach to short text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongcheng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.6988</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards automatic addressee identification in multiparty dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasa</forename><surname>Jovanovi´cjovanovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Op Den Rieks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Akker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGDIAL</title>
		<meeting>SIGDIAL</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Addressee identification in face-to-face meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasa</forename><surname>Jovanovi´cjovanovi´c</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">op den Rieks Akker, and Anton Nijholt</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Proceedings of EACL</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03753</idno>
		<title level="m">Improved deep learning baselines for ubuntu corpus dialogs</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A stochastic model of human-machine interaction for learning dialog strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esther</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Pieraccini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Eckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="page" from="11" to="23" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A persona-based neural conversation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iulian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGDIAL</title>
		<meeting>SIGDIAL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A deep architecture for matching short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Language detection library for java</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyo</forename><surname>Nakatani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A finite-state turn-taking model for spoken dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="629" to="637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural network models for lexical addressee detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Suman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="298" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Data-driven response generation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNL</title>
		<meeting>EMNL</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="583" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Iulian Vlad Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/IJCNLP</title>
		<meeting>ACL/IJCNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A neural network approach to context-sensitive generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL/HLT</title>
		<meeting>NAACL/HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="196" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Issues in multiparty dialogues. Advances in Agent communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Traum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="201" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiparticipant chat analysis: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Uthus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="106" to="121" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V. Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<title level="m">A neural conversational model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A trainable generator for recommendations in multimodal dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marilyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A dataset for research on short-text conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="935" to="945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Syntax-based deep matching of short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1354" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul J Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On early stopping in gradient descent learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Caponnetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Constructive Approximation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="289" to="315" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for pomdp-based spoken dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="page" from="150" to="174" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
