<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T12:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-disclosure topic model for classifying and analyzing Twitter conversations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-29, 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyeong</forename><surname>Bak</surname></persName>
							<email>jy.bak@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">KAIST Daejeon</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<addrLine>Beijing 100080</addrLine>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Oh</surname></persName>
							<email>alice.oh@kaist.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">KAIST Daejeon</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-disclosure topic model for classifying and analyzing Twitter conversations</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="1986" to="1996"/>
							<date type="published">October 25-29, 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Self-disclosure, the act of revealing oneself to others, is an important social behavior that strengthens interpersonal relationships and increases social support. Although there are many social science studies of self-disclosure, they are based on manual coding of small datasets and questionnaires. We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations , a semi-supervised machine learning algorithm, and a computational analysis of the effects of self-disclosure on subsequent conversations. We use a longitudinal dataset of 17 million tweets, all of which occurred in conversations that consist of five or more tweets directly replying to the previous tweet, and from dyads with twenty of more conversations each. We develop self-disclosure topic model (SDTM), a variant of latent Dirichlet allocation (LDA) for automatically classifying the level of self-disclosure for each tweet. We take the results of SDTM and analyze the effects of self-disclosure on subsequent conversations. Our model significantly outperforms several comparable methods on classifying the level of self-disclosure, and the analysis of the longitudinal data using SDTM uncovers significant and positive correlation between self-disclosure and conversation frequency and length.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Self-disclosure is an important and pervasive so- cial behavior. People disclose personal informa- tion about themselves to improve and maintain * This work was done when JinYeong Bak was a visiting student at Microsoft Research, <ref type="bibr">Beijing, China.</ref> relationships <ref type="bibr" target="#b12">(Jourard, 1971;</ref><ref type="bibr" target="#b10">Joinson and Paine, 2007)</ref>. A common instance of self-disclosure is the start of a conversation with an exchange of names and additional self-introductions. Another example of self-disclosure, shown in <ref type="figure" target="#fig_0">Figure 1c</ref>, where the information disclosed about a family member's serious illness, is much more personal than the exchange of names. In this paper, we seek to understand this important social behavior using a large-scale Twitter conversation data, automati- cally classifying the level of self-disclosure using machine learning and correlating the patterns with conversational behaviors which can serve as prox- ies for measuring intimacy between two conversa- tional partners.</p><p>Twitter conversation data, explained in more detail in section 4.1, enable an extremely large scale study of naturally-occurring self-disclosure behavior, compared to traditional social science studies. One challenge of such large scale study, though, remains in the lack of labeled ground- truth data of self-disclosure level.</p><p>That is, naturally-occurring Twitter conversations do not come tagged with the level of self-disclosure in each conversation. To overcome that challenge, we propose a semi-supervised machine learning approach using probabilistic topic modeling. Our self-disclosure topic model (SDTM) assumes that self-disclosure behavior can be modeled using a combination of simple linguistic features (e.g., pronouns) with automatically discovered seman- tic themes (i.e., topics). For instance, an utterance "I am finally through with this disastrous relation- ship" uses a first-person pronoun and contains a topic about personal relationships.</p><p>In comparison with various other models, SDTM shows the highest accuracy, and the result- ing conversation frequency and length patterns on self-disclosure are shown different over time. Our contributions to the research community include the following:</p><p>• We present key features and prior knowl- edge for identifying self-disclosure level, and show relevance of it with experiment results (Sec. 2).</p><p>• We present a topic model that explicitly in- cludes the level of self-disclosure in a conver- sation using linguistic features and the latent semantic topics (Sec. 3).</p><p>• We collect a large dataset of Twitter conver- sations over three years and annotate a small subset with self-disclosure level (Sec. 4).</p><p>• We compare the classification accuracy of SDTM with other models and show that it performs the best (Sec. 5).</p><p>• We correlate the self-disclosure patterns and conversation behaviors to show that there is significant relationship over time (Sec. 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Self-Disclosure</head><p>In this section, we look at social science literature for definition of the levels of self-disclosure. Us- ing that definition, we devise an approach to au- tomatically identify the levels of self-disclosure in a large corpus of OSN conversations. We dis- cuss three approaches, first, using first-person pro- noun features, and second, extracting seed words and phrases from the Twitter conversation cor- pus, and third, extracting seed words and phrases from an external corpus of anonymously posted secrets, and we demonstrate the efficacy of those approaches with an annotated corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Self-disclosure (SD) level</head><p>To analyze self-disclosure, researchers categorize self-disclosure language into three levels: G (gen- eral) for no disclosure, M for medium disclosure, and H for high disclosure <ref type="bibr" target="#b27">(Vondracek and Vondracek, 1971;</ref><ref type="bibr" target="#b1">Barak and Gluck-Ofri, 2007</ref>). Ut- terances that contain general (non-sensitive) in- formation about the self or someone close (e.g., a family member) are categorized as M. Exam- ples are personal events, past history, or future plans. Utterances about age, occupation and hob- bies are also included. Utterances that contain sensitive information about the self or someone close are categorized as H. Sensitive information includes personal characteristics, problematic be- haviors, physical appearance and wishful ideas. Generally, these are thoughts and information that one would keep as secrets to himself. All other utterances, those that do not contain information about the self or someone close are categorized as G. Examples include gossip about celebrities or factual discourse about current events. <ref type="figure" target="#fig_0">Figure  1</ref> shows Twitter conversation examples with G, M and H levels from annotated dataset (see Sec- tion 4.2 for a detailed description of the annotated dataset).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">G Level of Self-Disclosure</head><p>An obvious clue of self-disclosure is the use of first-person pronouns. For example, phrases such as 'I live' or 'My name is' indicate that the ut- terance contains personal information. In pre- vious research, the simple method of counting first-person pronouns was used to measure the de- gree of self-disclosure <ref type="bibr" target="#b11">(Joinson, 2001;</ref><ref type="bibr" target="#b1">Barak and Gluck-Ofri, 2007)</ref>. Consequently, the absence of a first-person pronoun signals that the utterance be- longs in the G level of self-disclosure. We ver- ify this pattern with a dataset of Tweets annotated with G, M, and H levels. We divide the annotated Tweets into two classes, G and M/H. Then we com- pute mutual information of each unigram, bigram, or trigram feature to see which features are most discriminative. As <ref type="table">Table 1</ref> shows, 18 out of 30</p><p>Category Words/Expressions Unigram my, I, I'm, I'll, but, was, I've, love, dad, have Bigram I love, I was, I have, my dad, go to, my mom, with my, have to, to go, my mum Trigram I have a, is going to, to go to, want to go, and I was, going to miss, I love him, I think I, I was like, I wish I <ref type="table">Table 1</ref>: High ranked words and expressions by mutual information between G and M/H level in annotated conversations.</p><p>most highly ranked discriminative features contain a first-person pronoun.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">M Level of Self-Disclosure</head><p>Utterances with M level include two types: 1) information related with past events and future plans, and 2) general information about self <ref type="bibr" target="#b1">(Barak and Gluck-Ofri, 2007)</ref>. For the former, we add as seed trigrams 'I have been' and 'I will'.</p><p>For the latter, we use seven types of information generally accepted to be personally identifiable in- formation <ref type="bibr" target="#b17">(McCallister, 2010)</ref>, as listed in the left column of <ref type="table" target="#tab_0">Table 2</ref>. To find the appropriate tri- grams for those, we take Twitter conversation data (described in Section 4.1) and look for trigrams that begin with 'I' and 'my' and occur more than 200 times. We then check each one to see whether it is related with any of the seven types listed in the table. As a result, we find 57 seed trigrams for M level.  <ref type="table" target="#tab_0">Table 2</ref>: Example seed trigrams for identifying M level of SD. There are 51 of these used in SDTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">H Level of Self-Disclosure</head><p>Utterances with H level express secretive wishes or sensitive information that exposes self or some- one close <ref type="bibr" target="#b1">(Barak and Gluck-Ofri, 2007</ref>  call this external dataset SECRET. Unlike G and M levels, evidence of H level of self-disclosure tends to be topical, such as physical appearance, mental and physical illnesses, and family problems, so we take an approach of fitting a topic model driven by seed words. A similar approach has been success- ful in sentiment classification ( <ref type="bibr" target="#b9">Jo and Oh, 2011;</ref><ref type="bibr" target="#b13">Kim et al., 2013)</ref>.</p><p>A critical component of this approach is the set of seed words with which to drive the discovery of topics that are most indicative of H level self- disclosure. To extract the seed words that express secretive personal information, we compute mu- tual information <ref type="bibr" target="#b16">(Manning et al., 2008</ref>) with SE- CRET and 24,610 randomly selected tweets. We select 1,000 words with high mutual information and filter out stop words. <ref type="table" target="#tab_2">Table 3</ref> shows some of these words. To extract seed trigrams of secretive wishes, we again look for trigrams that start with 'I' or 'my', occur more than 200 times, and select trigrams of wishful thinking, such as 'I want to', and 'I wish I'. In total, there are 88 seed words and 8 seed trigrams for H.</p><p>Since SECRET is quite different from Twitter, we must show that posts in SECRET are seman- tically similar to the H level Tweets. Rather than directly comparing SECRET posts and Tweets, we use the same method of extracting discriminative word features from the annotated H level Tweets (see Section 4.2). <ref type="table" target="#tab_2">Table 3</ref> shows the seed words extracted from SECRET as well as the annotated Tweets. Because the annotated dataset consists of only 200 conversations, the coverage of the topics seems narrower than the much larger SECRETS, but both datasets show similarities in the topics. This, combined with the results of the model with the two sets of seed words (see Section 5 for the results), shows that SECRETS is an effective and simple-to-obtain substitute for an annotated cor- pus of H level of self-disclosure. </p><formula xml:id="formula_0">K G ; K M ; K H Number of topics for {G; M; H} c; ct Conversation; tweet in conversation c yct SD level of tweet ct, G or M/H rct SD level of tweet ct, M or H zct</formula><p>Topic of tweet ct wctn n th word in tweet ct λ</p><p>Learned Maximum entropy parameters xct First-person pronouns features ωct  </p><formula xml:id="formula_1">Distribution over SD level of tweet ct πc SD level proportion of conversation c θ G c ; θ M c ; θ H c Topic proportion of {G; M; H} in con- versation c φ G ; φ M ; φ H Word distribution of {G; M; H} α; γ Dirichlet prior for θ; π β G , β M ; β H Dirichlet prior for φ G ; φ M ; φ H n cl</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Self-Disclosure Topic Model</head><p>This section describes our model, the self- disclosure topic model (SDTM), for classifying self-disclosure level and discovering topics for each self-disclosure level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model</head><p>In section 2, we discussed different approaches to identifying each level of self-disclosure, based on social science literature, annotated and unan- notated Tweets, and an external corpus of se- cret posts. In this section, we describe our self-disclosure topic model, based on the widely used latent Dirichlet allocation ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>, which incorporates those approaches. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the graphical model of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">For each level l ∈ {G, M, H}:</head><p>For each topic k ∈ {1, . . . , K l }:</p><formula xml:id="formula_2">Draw φ l k ∼ Dir(β l ) 2. For each conversation c ∈ {1, . . . , C}: (a) Draw θ G c ∼ Dir(α) (b) Draw θ M c ∼ Dir(α) (c) Draw θ H c ∼ Dir(α) (d) Draw π c ∼ Dir(γ) (e) For each message t ∈ {1, . . . , T }: i. Observe first-person pronouns features x ct ii. Draw ω ct ∼ M axEnt(x ct , λ) iii. Draw y ct ∼ Bernoulli(ω ct ) iv. If y ct = 0 which is G level: A. Draw z ct ∼ M ult(θ G c ) B. For each word n ∈ {1, . . . , N }: Draw word w ctn ∼ M ult(φ G zct ) Else which can be M or H level: A. Draw r ct ∼ M ult(π c ) B. Draw z ct ∼ M ult(θ rct c ) C. For each word n ∈ {1, . . . , N }: Draw word w ctn ∼ M ult(φ rct zct )</formula><p>Figure 3: Generative process of SDTM.</p><p>SDTM and how those approaches are embodied in it. The first approach based on the first-person pronouns is implemented by the observed vari- able x ct and the parameters λ from a maximum entropy classifier for G vs. M/H level. The ap- proach of seed words and phrases for levels M and H is implemented by the three separate word-topic probability vectors for the three levels of SD: φ l which has a Bayesian informative prior β l where l ∈ {G, M, H}, the three levels of self-disclosure. <ref type="table" target="#tab_3">Table 4</ref> lists the notations used in the model and the generative process, and <ref type="figure">Figure 3</ref> describes the generative process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Classifying G vs M/H levels</head><p>Classifying the SD level for each tweet is done in two parts, and the first part classifies G vs. M/H levels with first-person pronouns (I, my, me). In the graphical model, y is the latent variable that represents this classification, and ω is the distri- bution over y. x is the observation of the first- person pronoun in the tweets, and λ are the param- eters learned from the maximum entropy classifier. With the annotated Twitter conversation dataset (described in Section 4.2), we experimented with several classifiers (Decision tree, Naive Bayes) and chose the maximum entropy classifier because it performed the best, similar to other joint topic models ( <ref type="bibr" target="#b29">Zhao et al., 2010;</ref><ref type="bibr" target="#b18">Mukherjee et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Classifying M vs H levels</head><p>The second part of the classification, the M and the H level, is driven by informative priors with seed words and seed trigrams. In the graphical model, r is the latent variable that represents this classi- fication, and π is the distribution over r. γ is a non-informative prior for π, and β l is an informa- tive prior for each SD level by seed words. For example, we assign a high value for the seed word 'acne' for β H , and a low value for 'My name is'. This approach is the same as joint models of topic and sentiment ( <ref type="bibr" target="#b9">Jo and Oh, 2011;</ref><ref type="bibr" target="#b13">Kim et al., 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inference</head><p>For posterior inference of SDTM, we use col- lapsed Gibbs sampling which integrates out la- tent random variables ω, π, θ, and φ. Then we only need to compute y, r and z for each tweet. We compute full conditional distribution p(y ct = j , r ct = l , z ct = k |y −ct , r −ct , z −ct , w, x) for tweet ct as follows:</p><formula xml:id="formula_3">p(y ct = 0, z ct = k |y −ct , r −ct , z −ct , w, x) ∝ exp(λ 0 · x ct ) 1 j=0 exp(λ j · x ct ) g(c, t, l , k ), p(y ct = 1, r ct = l , z ct = k |y −ct , r −ct , z −ct , w, x) ∝ exp(λ 1 · x ct ) 1 j=0 exp(λ j · x ct ) (γ l + n (−ct) cl ) g(c, t, l , k ),</formula><p>where z −ct , r −ct , y −ct are z, r, y without tweet ct, m ctk (·) is the marginalized sum over word v of m ctk v and the function g(c, t, l , k ) as follows:</p><formula xml:id="formula_4">g(c, t, l , k ) = Γ( V v=1 β l v + n l −(ct) k v ) Γ( V v=1 β l v + n l −(ct) k v + m ctk (·) ) α k + n l (−ct) ck K k=1 α k + n l ck V v=1 Γ(β l v + n l −(ct) k v + m ctk v ) Γ(β l v + n l −(ct) k v</formula><p>) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data Collection and Annotation</head><p>To test our self-disclosure topic model, we use a large dataset of conversations consisting of Tweets over three years such that we can analyze the re- lationship between self-disclosure behavior and conversation frequency and length over time. We chose to crawl Twitter because it offers a prac- tical and large source of conversations ( <ref type="bibr" target="#b22">Ritter et al., 2010)</ref>. Others have also analyzed Twitter con- versations for natural language and social media Users <ref type="table" target="#tab_2">Dyads  Conv's  Tweets  101,686 61,451 1,956,993 17,178,638   Table 5</ref>: Dataset of Twitter conversations. We chose conversations consisting of five or more tweets each. We chose dyads with twenty or more conversations.</p><p>research (boyd et al., 2010; Danescu-Niculescu- Mizil et al., 2011), but we collect conversations from the same set of dyads over several months for a unique longitudinal dataset. We also make sure that each conversation is at least five tweets, and that each dyad has at least twenty conversations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Collecting Twitter conversations</head><p>We define a Twitter conversation as a chain of tweets where two users are consecutively reply- ing to each other's tweets using the Twitter reply button. We initialize the set of users by randomly sampling thirteen users who reply to other users in English from the Twitter public streams <ref type="bibr">3</ref> . Then we crawl each user's public tweets, and look at users who are mentioned in those tweets. It is a breadth-first search in the network defined by users as nodes and edges as conversations. We run this search for dyads until the depth of four, and filter out users who tweet in a non-English language. We use an open source tool for de- tecting English tweets <ref type="bibr">4</ref> . To protect users' privacy, we replace Twitter userid, usernames and url in tweets with random strings. This dataset consists of 101,686 users, 61,451 dyads, 1,956,993 conver- sations and 17,178,638 tweets which were posted between August 2007 to July 2013. <ref type="table">Table 5</ref> sum- marizes the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Annotating self-disclosure level</head><p>To measure the accuracy of our model, we ran- domly sample 301 conversations, each with ten or fewer tweets, and ask three judges, fluent in En- glish and graduate students/researchers, to anno- tate each tweet with the level of self-disclosure. Judges first read and discussed the definitions and examples of self-disclosure level shown in <ref type="bibr" target="#b1">(Barak and Gluck-Ofri, 2007</ref>), then they worked sepa- rately on a Web-based platform.</p><p>As a result of annotation, there are 122 G level converstaions, 147 M level and 32 H level con- versations, and inter-rater agreement using Fleiss kappa <ref type="bibr" target="#b7">(Fleiss, 1971</ref>) is 0.68, which is substantial agreement result <ref type="bibr" target="#b14">(Landis and Koch, 1977)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Classification of Self-Disclosure Level</head><p>This section describes experiments and results of SDTM as well as several other methods for classi- fication of self-disclosure level.</p><p>We first start with the annotated dataset in sec- tion 4.2 in which each tweet is annotated with SD level. We then aggregate all of the tweets of a conversation, and we compute the proportions of tweets in each SD level. When the proportion of tweets at M or H level is equal to or greater than 0.2, we take the level of the larger proportion and assign that level to the conversation. When the proportions of tweets at M or H level are both less than 0.2, we assign G to the SD level. The reason for setting 0.2 as the threshold is that a conversa- tion containing tweets with H or M level of self- disclosure usually starts with a greeting or a gen- eral comment, and contains one or more questions or comments before or after the self-disclosure tweet.</p><p>We compare SDTM with the following methods for classifying conversations for SD level:</p><p>• LDA ( <ref type="bibr" target="#b2">Blei et al., 2003)</ref>: A Bayesian topic model. Each conversation is treated as a doc- ument. Used in previous work ( <ref type="bibr" target="#b0">Bak et al., 2012</ref>).</p><p>• MedLDA (Zhu et al., 2012): A super- vised topic model for document classifica- tion. Each conversation is treated as a doc- ument and response variable can be mapped to a SD level.</p><p>• LIWC ( <ref type="bibr" target="#b24">Tausczik and Pennebaker, 2010)</ref>: Word counts of particular categories <ref type="bibr">5</ref> . Used in previous work <ref type="bibr" target="#b8">(Houghton and Joinson, 2012</ref>).</p><p>• Bag of Words + Bigrams + Trigrams (BOW+): A bag of words, bigram and tri- gram features. We exclude features that ap- pear only once or twice.</p><p>• Seed words and trigrams (SEED): Occur- rences of seed words/trigrams from SECRET which are described in section 3.3.</p><p>• SDTM with seed words from annotated Tweets (SDTM−): To compare with SDTM below using seed words from SECRET, this uses seed words from the annotated data de- scribed in section 2.4.</p><p>• ASUM ( <ref type="bibr" target="#b9">Jo and Oh, 2011</ref>): A joint model of sentiments and topics. We map each SD level to one sentiment and use the same seed words/trigrams from SECRET as in SDTM below. Used in previous work ( <ref type="bibr" target="#b0">Bak et al., 2012</ref>).</p><p>• First-person pronouns (FirstP): Occurrence of first-person pronouns which are described in section 3.2. To identify first-person pro- nouns, we tagged parts of speech in each tweet with the Twitter POS tagger ( <ref type="bibr" target="#b20">Owoputi et al., 2013</ref>).</p><p>• First-person pronouns + Seed words/trigrams (FP+SE1): First-person pronouns and seed words/trigrams from SECRET.</p><p>• Two stage classifier with First-person pro- nouns + Seed words/trigrams (FP+SE2): A</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Acc  two stage classifier with first-person pro- nouns and seed words/trigrams from SE- CRET. In the first stage, the classifier identi- fies G with first-person pronouns. Then in the second stage, the classifier uses seed words and trigrams to identify M and H levels.</p><formula xml:id="formula_5">G F 1 M F 1 H F 1 Avg F 1 LDA 49.2</formula><p>• SDTM: Our model with first-person pro- nouns and seed words/trigrams from SE- CRET.</p><p>SEED, LIWC, LDA and FirstP cannot be used directly for classification, so we use Maximum en- tropy model with outputs of each of those models as features <ref type="bibr">6</ref> . BOW+ uses SVM with a radial ba- sis kernel which performs better than all other set- tings tried including maximum entropy. We split the data randomly into 80/20 for train/test. We run MedLDA, ASUM and SDTM 20 times each and compute the average accuracies and F-measure for each level. We run LDA and MedLDA with var- ious number of topics from 80 to 140, and 120 topics shows best outputs. So we set 120 topics for LDA, MedLDA and ASUM, 60; 40; 40 topics for SDTM K G , K M and K H respectively which is best perform from 40; 40; 40 to 60; 60; 60 top- ics. We assume that a conversation has few topics and self-disclosure levels, so we set α = γ = 0.1 ( <ref type="bibr" target="#b23">Tang et al., 2014</ref>). To incorporate the seed words and trigrams into ASUM and SDTM, we initial- ize β G , β M and β H differently. We assign a high value of 2.0 for each seed word and trigram for that level, and a low value of 10 −6 for each word that is a seed word for another level, and a default value of 0.01 for all other words. This approach is the same as previous papers ( <ref type="bibr" target="#b9">Jo and Oh, 2011;</ref><ref type="bibr" target="#b13">Kim et al., 2013</ref>).</p><p>As <ref type="table" target="#tab_5">Table 6</ref> shows, SDTM performs better than the other methods for accuracy as well as F- measure. LDA and MedLDA generally show the lowest performance, which is not surprising given these models are quite general and not tuned specifically for this type of semi-supervised clas- sification task. BOW which is simple word fea- tures also does not perform well, showing espe- cially low F-measure for the H level. LIWC and SEED perform better than LDA, but these have quite low F-measure for G and H levels. ASUM shows better performance for classifying H level than others, confirming the effectiveness of a topic modeling approach to this difficult task, but not as well as SDTM. FirstP shows good F-measure for the G level, but the H level F-measure is quite low, even lower than SEED. Combining first-person pronouns and seed words and trigrams (FP+SE1) shows better than each feature alone, and the two stage classifier (FP+SE2) which is a similar ap- proach taken in SDTM shows better results. Fi- nally, SDTM classifies G and M level at a similar accuracy with FirstP, FP+SE1 and FP+SE2, but it significantly improves accuracy for the H level compared to all other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Relations of Self-Disclosure and Conversation Behaviors</head><p>In this section, we investigate whether there is a relationship between self-disclosure and con- versation behaviors over time. Self-disclosure is one way to maintain and improve relationships <ref type="bibr" target="#b12">(Jourard, 1971;</ref><ref type="bibr" target="#b10">Joinson and Paine, 2007)</ref>. So two people's intimacy changes over time has rela- tionship with self-disclosure in their conversation. However, it is hard to identify intimacy between users in large scale online social network. So we choose conversation behaviors such as conversa- tion frequency and length which can be treated as proxies for measuring intimacy between two peo- ple ( <ref type="bibr" target="#b6">Emmers-Sommer, 2004;</ref><ref type="bibr" target="#b0">Bak et al., 2012</ref>).</p><p>With SDTM, we can automatically classify the SD level of a large number of conversations, so we investigate whether there is a similar relation- ship between self-disclosure in conversations and subsequent conversation behaviors with the same partner on Twitter.</p><p>For comparing conversation behaviors over time, we divided the conversations into two sets for each dyad. For the initial period, we include conversations from the dyad's first conversation to 20 days later. And for the subsequent period, we include conversations during the subsequent 10 days. We compute proportions of conversation for each SD level for each dyad in the initial and subsequent periods.</p><p>More specifically, we ask the following three questions:</p><p>1. If a dyad shows high conversation frequency at a particular time period, would they dis- play higher SD in their subsequent conver- sations?</p><p>2. If a dyad displays high SD level in their con- versations at a particular time period, would their subsequent conversations be longer?</p><p>3. If a dyad displays high overall SD level, would their conversations increase in length over time more than dyads with lower overall SD level?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Experiment Setup</head><p>We first run SDTM with all of our Twitter con- versation data with 150; 120; 120 topics for SDTM K G , K M and K H respectively. The hyper-parameters are the same as in section 5. To handle a large dataset, we employ a distributed al- gorithm <ref type="bibr" target="#b19">(Newman et al., 2009)</ref>, and run with 28 threads. <ref type="table" target="#tab_8">Table 7</ref> shows some of the topics that were prominent in each SD level by KL-divergence. As expected, G level includes general topics such as food, celebrity, soccer and IT devices, M level in- cludes personal communication and birthday, and finally, H level includes sickness and profanity.</p><p>We define a new measurement, SD level score for a dyad in the period, which is a weighted sum of each conversation with SD levels mapped to 1, 2, and 3, for the levels G, M, and H, respectively.  <ref type="figure">Figure 5</ref>: Relationship between initial conversa- tion frequency and subsequent SD level. The solid line is the linear regression line, and the co- efficient is 0.0020 with p &lt; 0.0001, which shows a significant positive relationship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Does high frequency of conversation lead to more self-disclosure?</head><p>We investigate whether the initial conversation frequency is correlated with the SD level in the subsequent period. We run linear regression with the initial conversation frequency as the indepen- dent variable, and SD level in the subsequent pe- riod as the dependent variable.</p><p>The regression coefficient is 0.0020 with low p- value (p &lt; 0.0001). <ref type="figure">Figure 5</ref> shows the scatter plot. We can see that the slope of the regression line is positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Does high self-disclosure lead to longer conversations?</head><p>Now we investigate the effect of the self- disclosure level to conversation length. We run linear regression with the intial SD level score as the independent variable, and the rate of change in conversation length between initial period and subsequent period as the dependent variable. Conversation length is measured by the number of tweets in a conversation.</p><p>The result of regression is that the independent variable's coefficient is 0.048 with a low p-value (p &lt; 0.0001). <ref type="figure" target="#fig_6">Figure 6</ref> shows the scatter plot with the regression line, and we can see that the slope of regression line is positive.   <ref type="table" target="#tab_0">H level  101  184  176  36  104  82  113  33  19  chocolate  obama  league  send  twitter  going  ass  better  lips  butter  he's  win  email  follow  party  bitch  sick  kisses  good  romney  game  i'll  tumblr  weekend  fuck  feel  love  cake  vote  season  sent  tweet  day  yo  throat smiles  peanut  right  team  dm  following  night  shit  cold  softly  milk  president  cup  address  account  dinner  fucking hope  hand  sugar  people  city  know  fb  birthday  lmao  pain  eyes  cream  good  arsenal  check  followers tomorrow  shut  good  neck  make  going  chelsea  link  facebook  come  dick  cough</ref>    Now we investigate the conversation length changes over time with three groups, low, medium, and high, by overall SD level. Then we investigate changes in conversation length over time. <ref type="figure" target="#fig_7">Figure 7</ref> shows the results of this investigation. First, conversations are generally lengthier when SD level is high. This phenomenon is also ob- served in <ref type="figure" target="#fig_6">figure 6</ref>, but here we can see it as a long-term persistent pattern. Second, conversation length increases consistently and significantly for the high and medium groups, but for the low SD group, there is not a significant increase of conver- sation length over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Prior work on quantitatively analyzing self- disclosure has relied on user surveys <ref type="bibr" target="#b15">(Ledbetter et al., 2011;</ref><ref type="bibr" target="#b26">Trepte and Reinecke, 2013)</ref> or human annotation ( <ref type="bibr" target="#b1">Barak and Gluck-Ofri, 2007;</ref><ref type="bibr" target="#b4">Courtney Walton and Rice, 2013)</ref>. These methods con- sume much time and effort, so they are not suit- able for large-scale studies. In prior work clos- est to ours, <ref type="bibr" target="#b0">Bak et al. (2012)</ref> showed that a topic model can be used to identify self-disclosure, but that work applies a two-step process in which a basic topic model is first applied to find the top- ics, and then the topics are post-processed for bi- nary classification of self-disclosure. We improve upon this work by applying a single unified model of topics and self-disclosure for high accuracy in classifying the three levels of self-disclosure. Subjectivity which is aspect of expressing opin- ions ( <ref type="bibr" target="#b21">Pang and Lee, 2008;</ref><ref type="bibr" target="#b28">Wiebe et al., 2004</ref>) is related with self-disclosure, but they are different dimensions of linguistic behavior. Because there indeed are many high self-disclosure tweets that are subjective, but there are also counter examples in annotated dataset. The tweet "England manager is Roy Hodgson." is low self-disclosure and low subjectivity, "I have barely any hair left." is high self-disclosure but low subjectivity, and "Senator stop lying!" is low self-disclosure but high subjec- tivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion and Future Work</head><p>In this paper, we have presented the self-disclosure topic model (SDTM) for discovering topics and classifying SD levels from Twitter conversation data. We devised a set of effective seed words and trigrams, mined from a dataset of secrets. We also annotated Twitter conversations to make a ground-truth dataset for SD level. With anno- tated data, we showed that SDTM outperforms previous methods in classification accuracy and F- measure. We publish the source code of SDTM and the dataset include annotated Twitter conver- sations and SECRET publicly <ref type="bibr">7</ref> .</p><p>We also analyzed the relationship between SD level and conversation behaviors over time. We found that there is a positive correlation be- tween initial SD level and subsequent conversa- tion length. Also, dyads show higher level of SD if they initially display high conversation fre- quency. Finally, dyads with overall medium and high SD level will have longer conversations over time. These results support previous results in so-cial psychology research with more robust results from a large-scale dataset, and show the effective- ness of computationally analyzing at SD behavior.</p><p>There are several future directions for this re- search. First, we can improve our modeling for higher accuracy and better interpretability. For instance, SDTM only considers first-person pro- nouns and topics. Naturally, there are other lin- guistic patterns that can be identified by humans but not captured by pronouns and topics. Sec- ond, the number of topics for each level is varied, and so we can explore nonparametric topic mod- els ( <ref type="bibr" target="#b25">Teh et al., 2006</ref>) which infer the number of topics from the data. Third, we can look at the relationship between self-disclosure behavior and general online social network usage beyond con- versations. We will explore these directions in our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of a Twitter conversation (from annotated dataset) with G, M and H level of self-disclosure.</figDesc><graphic url="image-3.png" coords="2,307.56,239.86,217.68,73.46" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Graphical model of SDTM Notation Description G; M ; H {general; medium; high} SD level C; T ; N Number of conversations; tweets; words K G ; K M ; K H Number of topics for {G; M; H} c; ct Conversation; tweet in conversation c yct SD level of tweet ct, G or M/H rct SD level of tweet ct, M or H zct Topic of tweet ct wctn n th word in tweet ct λ Learned Maximum entropy parameters xct First-person pronouns features ωct Distribution over SD level of tweet ct πc SD level proportion of conversation c θ G c ; θ M c ; θ H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Number of tweets assigned SD level l in conversation c n l ck Number of tweets assigned SD level l and topic k in conversation c n l kv Number of instances of word v assigned SD level l and topic k m ctkv Number of instances of word v assigned topic k in tweet ct</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Screenshot of annotation web-based platform. Annotators read a Twitter conversation and annotate self-disclosure level to each tweet.</figDesc><graphic url="image-4.png" coords="6,72.00,62.81,222.24,266.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Relationship between initial SD level and conversation length changes over time. The solid line is the linear regression line, and the coefficient is 0.048 with p &lt; 0.0001, which shows a significant positive relationship.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Changes in conversation length over time. We divide dyads into three groups by SD level score as low, medium, and high. Conversation length noticeably increases over time in the medium and high groups, but only slight in the low group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 shows several examples.</head><label>2</label><figDesc></figDesc><table>Type 
Trigram 
Name 
My name is, My last name 
Birthday 
My birthday is, My birthday party 
Location 
I live in, I lived in, I live on 
Contact 
My email address, My phone number 
Occupation My job is, My new job 
Education 
My high school, My college is 
Family 
My dad is, My mom is, My family is 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Example words for identifying H level of 
SD from secret posts (2nd column) and annotated 
data (3rd column). Categories are hand-labeled. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 : Summary of notations used in SDTM</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>SD level classification accuracies and F-
measures using annotated data. Acc is accuracy, 
and G F 1 is F-measure for classifying the G level. 
Avg F 1 is the macroaveraged value of G F 1 , M F 1 
and H F 1 . SDTM outperforms all other methods 
compared. The difference between SDTM and 
FirstP is statistically significant (p-value &lt; 0.05 
for accuracy, &lt; 0.0001 for Avg F 1 ). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>High ranked topics in each level by comparing KL-divergence with other level's topics 

1.0 
1.5 
2.0 
2.5 
3.0 

Initial SD level 

0.10 

0.05 

0.00 

0.05 

0.10 

0.15 

# Tweets in conversation changes proportion over time 

</table></figure>

			<note place="foot" n="1"> http://www.sixbillionsecrets.com 2 This site is regularly monitored for spam.</note>

			<note place="foot" n="3"> https://dev.twitter.com/docs/api/ streaming 4 https://github.com/shuyo/ldig</note>

			<note place="foot" n="5"> personal pronouns, 3rd person singular words, family words, human words, sexual words, etc</note>

			<note place="foot" n="6"> It performs better than other classifiers (C4.5, NaiveBayes, SVM with linear kernel, polynomial kernel and radial basis)</note>

			<note place="foot" n="7"> http://uilab.kaist.ac.kr/research/ EMNLP2014</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Jing Liu and Wayne Xin Zhao for inspiring discussions, and the anony-mous reviewers for helpful comments. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Selfdisclosure and relationship strength in twitter conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyeong</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Degree and reciprocity of self-disclosure in online forums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azy</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orit</forename><surname>Gluck-Ofri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CyberPsychology &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="417" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Tweet, tweet, retweet: Conversational aspects of retweeting on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Danah Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilad</forename><surname>Golder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lotan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HICSS</title>
		<meeting>HICSS</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mediated disclosure on twitter: The roles of gender and identity in boundary impermeability, valence, disclosure, and stage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">E</forename><surname>Rice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1465" to="1474" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mark my words!: Linguistic style accommodation in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The effect of communication quality and quantity indicators on intimacy and relational satisfaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara M Emmers-</forename><surname>Sommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Social and Personal Relationships</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="411" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Measuring nominal scale agreement among many raters. Psychological bulletin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joseph L Fleiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">378</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Linguistic markers of secrets and sensitive selfdisclosure in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam N Joinson</forename><surname>Houghton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HICSS</title>
		<meeting>HICSS</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Aspect and sentiment unification model for online review analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Selfdisclosure, privacy and the internet. The Oxford handbook of Internet psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carina</forename><forename type="middle">B</forename><surname>Adam N Joinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="237" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Self-disclosure in computer-mediated communication: The role of self-awareness and visual anonymity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam N Joinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Social Psychology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="192" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Self-disclosure: An experimental analysis of the transparent self</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sidney M Jourard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A hierarchical aspect-sentiment model for online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixia</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Attitudes toward online social connection and self-disclosure as predictors of facebook communication and relational closeness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Ledbetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><forename type="middle">M</forename><surname>Mazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">R</forename><surname>Degroot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuping</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swafford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communication Research</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="53" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press Cambridge</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Guide to protecting the confidentiality of personally identifiable information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erika</forename><surname>Mccallister</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>DIANE Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Public dialogue: Analysis of tolerance in online discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Meraz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed algorithms for topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Asuncion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1801" to="1828" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improved part-of-speech tagging for online conversational text with word clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olutobi</forename><surname>Owoputi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Oconnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised modeling of twitter conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL</title>
		<meeting>HLT-NAACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Understanding the limiting factors of topic modeling via posterior contraction analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoshi</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanlong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: Liwc and computerized text analysis methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hierarchical dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the american statistical association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The reciprocal effects of social network site use and the disposition for self-disclosure: A longitudinal study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Trepte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Reinecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1102" to="1112" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The manipulation and measurement of self-disclosure in preadolescents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sarah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">W</forename><surname>Vondracek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vondracek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Merrill-Palmer Quarterly of Behavior and Development</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning subjective language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="308" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Jointly modeling aspects and opinions with a maxent-lda hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Medlda: maximum margin supervised topic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2237" to="2278" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
