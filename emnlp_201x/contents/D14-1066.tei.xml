<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lexical Substitution for the Medical Domain</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>October 25-29, 2014. 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
							<email>riedl@cs.tu-darmstadt.de, {mrglass,gliozzo}@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department">CS Dept</orgName>
								<orgName type="institution" key="instit1">FG Language Technology</orgName>
								<orgName type="institution" key="instit2">TU Darmstadt</orgName>
								<address>
									<postCode>64289</postCode>
									<settlement>Darmstadt</settlement>
									<country>Germany (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM T.J. Watson Research</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfio</forename><surname>Gliozzo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM T.J. Watson Research</orgName>
								<address>
									<postCode>10598</postCode>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lexical Substitution for the Medical Domain</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
						<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) <address><addrLine>Doha, Qatar. c</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="610" to="614"/>
							<date type="published">October 25-29, 2014. 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>In this paper we examine the lexical substitution task for the medical domain. We adapt the current best system from the open domain, which trains a single classifier for all instances using delexicalized features. We show significant improvements over a strong baseline coming from a distributional thesaurus (DT). Whereas in the open domain system, features derived from WordNet show only slight improvements , we show that its counterpart for the medical domain (UMLS) shows a significant additional benefit when used for feature generation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of lexical substitution <ref type="bibr" target="#b12">(McCarthy and Navigli, 2009</ref>) deals with the substitution of a target term within a sentence with words having the same meaning. Thus, the task divides into two subtasks:</p><p>• Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable for a given target term.</p><p>• Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity <ref type="bibr">(Bär et al., 2012</ref>), textual entailment ( <ref type="bibr" target="#b6">Dagan et al., 2013</ref>) or plagiarism detection ( <ref type="bibr" target="#b5">Chong and Specia, 2011)</ref>. Datasets provided by <ref type="bibr" target="#b12">McCarthy and Navigli (2009)</ref> and <ref type="bibr" target="#b2">Biemann (2012)</ref> offer manually annotated substi- tutes for a given set of target words within a context (sentence). Contrary to these two datasets in <ref type="bibr" target="#b10">Kremer et al. (2014)</ref> a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain.</p><p>But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, pro- vided by <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>, to the medical domain. Additionally, we do not make use of WordNet <ref type="bibr" target="#b14">(Miller, 1995)</ref> to provide similar terms, but rather employ a Dis- tributional Thesaurus (DT), computed on medical texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>For the general domain, the lexical substitution task was initiated by a <ref type="bibr">Semeval-2007 Task (McCarthy and</ref><ref type="bibr" target="#b12">Navigli, 2009)</ref>. This task was won by an unsupervised method ( <ref type="bibr" target="#b9">Giuliano et al., 2007)</ref>, which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams ( <ref type="bibr" target="#b3">Brants and Franz, 2006</ref>) <ref type="bibr">1</ref> to rank the substitutes.</p><p>The currently best system, to our knowledge, is pro- posed by <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>. This is a supervised ap- proach, where a single classifier is trained using delex- icalized features for all substitutes and can thus be ap- plied even to previously unseen substitutes. Although there have been many approaches for solving the task for the general domain, only slight effort has been done in adapting it to different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>To perform lexical substitution, we follow the delex- icalization framework of <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>. We automatically build Distributional Thesauri (DTs) for the medical domain and use features from the Uni- fied Medical Language System (UMLS) ontology. The dataset for supervised lexical substitution consists of sentences, containing an annotated target word t. Con- sidering the sentence being the context for the target word, the target word might have different meanings. Thus annotated substitute candidates s g1 . . . s gn ∈ s g , need to be provided for each context. The negative ex- amples are substitute candidates that either are incor- rect for the target word, do not fit into the context or both. We will refer to these substitutes as false substi- tute candidates s f1 . . . s fm ∈ s f with s f ∩ s g = ∅.</p><p>For the generation of substitute candidates we do not use WordNet, as done in previous works ( <ref type="bibr" target="#b15">Szarvas et al., 2013</ref>), but use only substitutes from a DT. To train a single classifier, features that distinguishing the mean- ing of words in different context need to be considered. Such features could be e.g. n-grams, features from dis- tributional semantics or features which are extracted relative to the target word, such as the ratio between frequencies of the substitute candidate and the target word. After training, we apply the algorithm to un- seen substitute candidates and rank them according to their positive probabilities, given by the classifier. Con- trary to <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>, we do not use any weight- ing in the training if a substitute has been supplied by many annotators, as we could not observe any improve- ments. Additionally, we use logistic regression <ref type="bibr" target="#b8">(Fan et al., 2008)</ref> as classifier 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Resources</head><p>For the substitutes and for the generation of delexical- ized features, we rely on DTs, the UMLS and Google Web1T.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Distributional thesauri (DTs)</head><p>We computed two different DTs using the framework proposed in <ref type="bibr" target="#b1">Biemann and Riedl (2013)</ref>  <ref type="bibr">3</ref> .</p><p>The first DT is computed based on Medline 4 ab- stracts. This thesaurus uses the left and the right word as context features. To include multi-word expressions, we allow the number of tokens that form a term to be up to the length of three.</p><p>The second DT is based on dependencies as context features from a English Slot Grammar (ESG) parser <ref type="bibr" target="#b13">(McCord et al., 2012</ref>) modified to handle medical data. The ESG parser is also capable of finding multi-word expressions. As input data we use 3.3 GB of texts from medical textbooks, encyclopedias and clinical ref- erence material as well as selected journals. This DT is also used for the generation of candidates supplied to annotators when creating the gold standard and there- fore is the main resource to provide substitute candi- dates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">UMLS</head><p>The Unified Medical Language System (UMLS) is an ontology for the medical domain. In contrast to <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>, which uses WordNet <ref type="bibr" target="#b14">(Miller, 1995)</ref> to generate substitute candidates and also for generating features, we use UMLS solely for feature generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Google Web1T</head><p>We use the Google Web1T to generate n-gram features as we expect this open domain resource to have consid- erable coverage for most specific domains as well. For accessing the resource, we use JWeb1T 5 ( <ref type="bibr" target="#b9">Giuliano et al., 2007</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Lexical Substitution dataset</head><p>Besides the lexical substitution data sets for the open domain <ref type="bibr" target="#b12">(McCarthy and Navigli, 2009;</ref><ref type="bibr" target="#b2">Biemann, 2012;</ref><ref type="bibr" target="#b10">Kremer et al., 2014</ref>) there is no dataset available that can be used for the medical domain. Therefore, we constructed an annotation task for the medical domain using a medical corpus and domain experts.</p><p>In order to provide the annotators with a clear task, we presented a question, and a passage that contains the correct answer to the question. We restricted this to a subset of passages that were previously annotated as justifying the answer to the question. This is related to a textual entailment task, essentially the passage entails the question with the answer substituted for the focus of the question. We instructed the annotators to first iden- tify the terms that were relevant for the entailment rela- tion. For each relevant term we randomly extracted 10 terms from the ESG-based DT within the top 100 most similar terms. Using this list of distributionally similar terms, the annotators selected those terms that would preserve the entailment relation if substituted. This re- sulted in a dataset of 699 target terms with substitutes. On average from the 10 terms 0.846 are annotated as correct substitutes. Thus, the remaining terms can be used as false substitute candidates.</p><p>The agreement on this task by Fleiss Kappa was 0.551 indicating "moderate agreement" <ref type="bibr" target="#b11">(Landis and Koch, 1977)</ref>. On the metric of pairwise agreement, as defined in the SemEval lexical substitution task, we achieve 0.627. This number is not directly comparable to the pairwise agreement score of 0.277 for the Se- mEval lexical substitution task (McCarthy and Navigli, 2009) since in our task the candidates are given. How- ever, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintain- ing entailment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) ( <ref type="bibr" target="#b4">Buckley and Voorhees, 2004</ref>) scores. The P@1 score indicates how often the first substitute of the system matches the gold standard. The MAP score is the mean of all AP from 1 to the number of all substitutes.</p><p>• Google Web 1T:</p><p>We use the same Google n-gram features, as used in <ref type="bibr" target="#b9">Giuliano et al. (2007)</ref> and <ref type="bibr" target="#b15">Szarvas et al. (2013)</ref>. These are frequencies of n-grams formed by the substitute candidate s i and the left and right words, taken from the context sentence, normal- ized by the frequency of the same context n-gram with the target term t. Additionally, we add the same features, normalized by the frequency sum of all n-grams of the substitute candidates. An- other feature is generated using the frequencies where t and s are listed together using the words and, or and "," as separator and also add the left and right words of that phrase as context. Then we normalize this frequency by the frequency of the context occurring only with t.</p><p>• DT features: To characterize if t and s i have similar words in common, and therefore are similar, we com- pute the percentage of words their thesauri en- tries share, considering the top n words in each entry with n = 1, 5, 20, 50, 100, 200. During the DT calculation we also calculate the signif- icances between each word and its context fea- tures (see Section 4.1). Using this information, we compute if the words in the sentences also occur as context features for the substitute can- didate. A third feature group relying on DTs is created by the overlapping context features for the top m entries of t and s i with m = 1, 5, 20, 50, 100, 1000, which are ranked regard- ing their significance score. Whereas, the simi- larities between the trigram-based and the ESG- based DT are similar, the context features are dif- ferent. Both feature types can be applied to the two DTs. Additionally, we extract the thesaurus entry for the target word t and generate a feature indicating whether the substitute s i is within the top k entries with k = 1, 5, 10, 20, 100 entries 6 .</p><p>• Part-of-speech n-grams: To identify the context of the word we use the POS-tag (only the first letter) of s i and t as feature and POS-tag combinations of up to three neigh- boring words.</p><p>• UMLS: Considering UMLS we look up all concept unique identifiers (CUIs) for s i and t. The first two fea- tures are the number of CUIs for s i and t. The next features compute the number of CUIs that s i and t share, starting from the minimal to the maximum number of CUIs. Additionally, we use a feature indicating that s i and t do not share any CUI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Substitute candidates</head><p>The candidates for the substitution are taken from the ESG based DT. For each target term we use the gold substitute candidates as correct instances and add all possible substitutes for the same target term occurring in a different context and do not have been annotated as valid in the present context as false instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>Running the experiment, we get the results as shown in <ref type="table">Table 1</ref>. As baseline system we use the ranking of the ESG-based DT. As can be seen, the baseline is al- ready quite high, which can be attributed to the fact that this resource was used to generate substitutes und thus contains all positive instances. Using the super- vised approach, we can beat the baseline by 0.10 for the MAP score and by 0.176 for the P@1 score, which is a significant improvement (p &lt; 0.0001, using a two tailed permutation test  <ref type="table">Table 1</ref>: Results for the evaluation using substitute can- didates from the DT.</p><p>bution of individual feature types, we perform an abla- tion test. We observe that the most prominent features are coming from the two DTs as we only achieve re- sults below the baseline, when removing DT features. We still obtain significant improvements over the base- line when removing other feature groups. The second most important feature comes from the UMLS. Fea- tures coming from the Google n-grams improve the system only slightly. The lowest improvement is de- rived from the part-of-speech features. This leads us to summarize that a hybrid approach for feature gen- eration using manually created resources (UMLS) and unsupervised features (DTs) leads to the best result for lexical substitution for the medical domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Analysis</head><p>For a better insight into the lexical substitution we ana- lyzed how often we outperform the baseline, get equal results or get decreased scores. According to <ref type="table" target="#tab_2">Table 2</ref>   Looking inside the data, the largest error class is caused by antonyms. A sub-class of this error are multi-word expressions having an adjective modifier. This problems might be solved by additional features using the UMLS resource. An example is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. For feature generation, we currently lookup multi- word expressions as one term, both in the DT and the UMLS resource and do not split them into their sin- gle tokens. This error also suggests considering the single words inside the multi-word expression, espe- cially adjectives, and looking them up in a resource (e.g. UMLS) to detect synonymy and antonymy. <ref type="figure" target="#fig_1">Figure 2</ref> shows the case, where the ranking is per- formed correctly, but the precise substitute is not an- notated as a correct one. The term nail plate might be even more precise in the context as the manual anno- tated term nail bed. Due to the missing annotation the Here the ranking from the system is correct, but the first substitute from the system was not annotated as such.</p><p>baseline gets better scores then the result from the sys- tem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In summary, we have examined the lexical substitution task for the medical domain and could show that a sys- tem for open domain text data can be applied to the medical domain. We can show that following a hybrid approach using features from UMLS and distributional semantics leads to the best results. In future work, we will work on integrating DTs using other context fea- tures, as we could see an impact of using two different DTs. Furthermore, we want to incorporate features us- ing n-grams computed on a corpus from the domain and include co-occurrence features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example sentence for the target term mild thrombocytopenia. The system returns a wrong ranking, as the adjective changes the meaning and turns the first ranked term into an antonym.</figDesc><graphic url="image-1.png" coords="4,72.00,63.80,226.77,162.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example sentence for the target term nails. Here the ranking from the system is correct, but the first substitute from the system was not annotated as such.</figDesc><graphic url="image-2.png" coords="4,72.00,470.53,226.78,136.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>). To get insights of the contri-</figDesc><table>System 
MAP 
P@1 
Baseline 
0.6408 0.5365 
ALL 
0.7048 0.6366 
w/o DT 
0.5798 0.4835 
w/o UMLS 
0.6618 0.5651 
w/o Ngrams 0.7009 0.6252 
w/o POS 
0.7027 0.6323 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Error analysis for the task respectively to the 
MAP score. 

around 26% of the cases we observe a decreased MAP 
score, which is on average 0.16 smaller then the scores 
achieved with the baseline. On the other hand, we see 
improvements in around 39% of the cases: an average 
improvements of 0.26, which is much higher then the 
loss. For the remaining 25% of cases we observe the 
same score. 
</table></figure>

			<note place="foot" n="1"> http://catalog.ldc.upenn.edu/ LDC2006T13</note>

			<note place="foot" n="2"> We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/ ˜ cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3 We use Lexicographer&apos;s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (p = 1000) features per term. 4 http://www.nlm.nih.gov/bsd/licensee/ 2014_stats/baseline_med_filecount.html 5 https://code.google.com/p/jweb1t/</note>

			<note place="foot" n="6"> Whereas in Szarvas et al. (2013) only k = 100 is used, we gained an improvement in performance when also adding smaller values of k.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Adam Lally, Eric Brown, Edward A. Epstein, Chris Biemann and Faisal Chowdhury for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">UKP: Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bär</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation, held in conjunction with the 1st Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the 6th International Workshop on Semantic Evaluation, held in conjunction with the 1st Joint Conference on Lexical and Computational Semantics<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="435" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Text: Now in 2D! A Framework for Lexical Expansion with Contextual Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language Modelling</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="95" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Web 1t 5gram corpus version 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Franz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
	<note>Google Research</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Retrieval evaluation with incomplete information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;04</title>
		<meeting>the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;04<address><addrLine>Sheffield, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lexical generalisation for word-level matching in plagiarism detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miranda</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing</title>
		<meeting><address><addrLine>Hissar, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="704" to="709" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recognizing Textual Entailment: Models and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">M</forename><surname>Sammons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zanzotto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Human Language Technologies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="220" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">Evert</forename></persName>
		</author>
		<title level="m">The Statistics of Word Cooccurrences: Word Pairs and Collocations</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Institut für maschinelle Sprachverarbeitung, University of Stuttgart</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fbk-irst: Lexical substitution task exploiting domain and syntagmatic coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Giuliano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfio</forename><surname>Gliozzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval &apos;07</title>
		<meeting>the 4th International Workshop on Semantic Evaluations, SemEval &apos;07<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="145" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What Substitutes Tell Us-Analysis of an</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Kremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014)</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="540" to="549" />
		</imprint>
	</monogr>
	<note>All-Words&quot; Lexical Substitution Corpus</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The measurement of observer agreement for categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The English lexical substitution task. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="139" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep Parsing in Watson</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">William</forename><surname>Mccord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branimir</forename><forename type="middle">K</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM J. Res. Dev</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="278" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">WordNet: A Lexical Database for English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Supervised All-Words Lexical Substitution using Delexicalized Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">György</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013)<address><addrLine>Atlanta, GA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1131" to="1141" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
