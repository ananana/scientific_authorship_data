<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T13:01+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scientific Information Extraction with Semi-supervised Neural Tagging</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>September 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scientific Information Extraction with Semi-supervised Neural Tagging</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="2641" to="2651"/>
							<date type="published">September 7-11, 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper addresses the problem of extracting keyphrases from scientific articles and categorizing them as corresponding to a task, process, or material. We cast the problem as sequence tagging and introduce semi-supervised methods to a neu-ral tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unanno-tated articles. Both inductive and trans-ductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As a research community grows, more and more papers are published each year. As a result there is increasing demand for improved methods for finding relevant papers and automatically under- standing the key ideas in those papers. However, due to the large variety of domains and extremely limited annotated resources, there has been rel- atively little work on scientific information ex- traction. Previous research has focused on unsu- pervised approaches such as bootstrapping ( <ref type="bibr" target="#b16">Gupta and Manning, 2011;</ref><ref type="bibr" target="#b47">Tsai et al., 2013)</ref>, where hand-designed templates are used to extract sci- entific keyphrases, and more templates are added through bootstrapping.</p><p>Very recently a new challenge on Scientific Information Extraction (ScienceIE) ( ) 1 provides a dataset consisting of 500 scientific paragraphs with keyphrase annotations for three categories: TASK, PROCESS, MATERIAL across three scientific domains, Computer Science (CS), Material Science (MS), and Physics (Phy), as in <ref type="figure" target="#fig_0">Figure 1</ref>. This dataset enables the use of more advanced approaches such as neural network (NN) models. To that end, we cast the keyphrase extraction task as a sequence tagging problem, and build on recent progress in another informa- tion extraction task: Named Entity Recognition (NER) ( <ref type="bibr" target="#b23">Lample et al., 2016;</ref><ref type="bibr" target="#b41">Peng and Dredze, 2015)</ref>. Like named entities, keyphrases can be identified by their linguistic context, e.g. re- searchers "use" methods. In addition, keyphrases can be associated with different categories in dif- ferent contexts. For example, 'semantic parsing' can be labeled as a TASK in one article and as a PROCESS in another. Scientific keyphrases dif- fer in that they can include both noun phrases and verb phrases and in that non-standard "words" (equations, chemical compounds, references) can provide important cues.</p><p>Since the scale of the data is still small for su- pervised training of neural systems, we introduce semi-supervised methods to the neural tagging model in order to take advantage of the large quan- tity of unlabeled scientific articles. This is par- ticularly important because of the differences in keyphrases across domains. Our semi-supervised learning algorithm uses a graph-based label prop- agation scheme to estimate the posterior proba- bilities of unlabeled data. It additionally extends the training objective to leverage the confidence of the estimated posteriors. The new training treats low confidence tokens as missing labels and com- putes the sentence-level score by marginalizing over them.</p><p>Our experiments show that our neural tagging model achieves state-of-the-art results in the Se- mEval Science IE task. We further show that both inductive and transductive semi-supervised strate- gies significantly improve the performance. Fi- nally, we provide in-depth analysis of domain dif- ferences as well as analysis of failure cases.</p><p>The key contributions of our work include: i) achieving state of the art in scientific infor- mation extraction SEMEVAL Task 10 by ex- tending recent advances in neural tagging mod- els; ii) introducing a semi-supervised learning al- gorithm that uses graph-based label propagation and confidence-aware data selection, iii) explor- ing different alternatives for taking advantage of large, multi-domain unannotated data including both unsupervised embedding initialization and semi-supervised model training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There has been growing interest in research on au- tomatic methods to help researchers search and extract useful information from scientific litera- ture. Past research has addressed citation sen- timent (Athar and Teufel, 2012b,a), citation net- works <ref type="bibr" target="#b20">(Kas, 2011;</ref><ref type="bibr" target="#b14">Gabor et al., 2016;</ref><ref type="bibr" target="#b44">Sim et al., 2012;</ref><ref type="bibr" target="#b13">Do et al., 2013;</ref><ref type="bibr" target="#b19">Jaidka et al., 2014</ref>), summa- rization (Abu-Jbara and Radev, 2011) and some analysis of research community <ref type="bibr" target="#b48">(Vogel and Jurafsky, 2012;</ref><ref type="bibr" target="#b2">Anderson et al., 2012;</ref><ref type="bibr" target="#b34">Luan et al., 2012</ref><ref type="bibr" target="#b37">Luan et al., , 2014b</ref><ref type="bibr" target="#b24">Levow et al., 2014</ref>). However, due to scarce hand-annotated data resources, previ- ous work on information extraction (IE) for sci- entific literature is very limited. Gupta and Man- ning (2011) first proposed a task that defines sci- entific terms for 474 abstracts from the ACL an- thologhy ( <ref type="bibr" target="#b8">Bird et al., 2008</ref>) into three aspects: domain, technique and focus and apply template- based bootstrapping to tackle the problem. Based on this study, <ref type="bibr" target="#b47">Tsai et al. (2013)</ref> improve the per- formance by introducing hand-designed features from NER ( <ref type="bibr" target="#b10">Collins and Singer, 1999</ref>) to the boot- strapping framework. QasemiZadeh and Schu- mann (2012) compile a dataset of scientific terms into 7 fine-grained categories for 171 abstracts of ACL anothology. Similar to our work, very re- cently Augenstein and SÃ¸gaard (2017) also eval- uated on ScienceIE dataset, but use multi-task learning to improve the performance of a super- vised neural approach. Instead, we introduce a semi-supervised neural tagging approach that leverages unlabeled data.</p><p>Neural tagging models have been recently in- troduced to tagging problems such as NER. For example, <ref type="bibr" target="#b11">Collobert et al. (2011)</ref> use a CNN over a sequence of word embeddings and apply a CRF layer on top. <ref type="bibr" target="#b18">Huang et al. (2015)</ref> use hand-crafted features with LSTMs to improve performance. There is currently great interest in using character- based embeddings in neural models. ( <ref type="bibr" target="#b9">Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b23">Lample et al., 2016;</ref><ref type="bibr" target="#b7">Ballesteros et al., 2015;</ref><ref type="bibr" target="#b38">Ma and Hovy, 2016)</ref>. Our approach also takes advantage of neural tagging models and character-based embeddings for IE in scientific ar- ticles.</p><p>Previous work on semi-supervised learning for neural models has mainly focused on transfer learning <ref type="bibr" target="#b12">(Dai and Le, 2015;</ref><ref type="bibr" target="#b33">Luan et al., 2014a;</ref>) or initializing the model with pre-trained word embeddings ( <ref type="bibr" target="#b40">Mikolov et al., 2013;</ref><ref type="bibr" target="#b42">Pennington et al., 2014;</ref><ref type="bibr" target="#b25">Levy and Goldberg, 2014;</ref><ref type="bibr" target="#b32">Luan et al., 2016b</ref><ref type="bibr" target="#b31">Luan et al., , 2016a</ref>). In our work, we use pre-training but also use more powerful methods including graph-based semi- supervision ( <ref type="bibr" target="#b45">Subramanya and Bilmes, 2011;</ref><ref type="bibr" target="#b26">Liu and Kirchhoff, 2013</ref>,b) and a method for leveraging partially labeled data ( <ref type="bibr" target="#b21">Kim et al., 2015)</ref>. We show that the combination of these techniques gives better results than any one alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Definition and Data</head><p>The purpose of this work is to extract phrases that can answer questions that researchers usually face when reading a paper: What TASK has the paper addressed? What PROCESS or method has the pa- per used or compared to? What MATERIALS has the paper utilized in experiments? While these fundamental concepts are important in a wide vari- ety of scientific disciplines, the terms that are used in specific disciplines can be substantially differ-ent. For example, MATERIALS in computer sci- ence might be a text corpus, while they would be physical materials in physics or materials science.</p><p>Data We use the SemEval 2017 Task 10 Sci- enceIE dataset. <ref type="figure" target="#fig_0">Fig. 1</ref> provides examples that il- lustrate the variation in domains, but also show that there are common cues such as "the task of", "using", "technique," etc. A challenge with this dataset is that the size of the training data is very small. It is built from ScienceDirect open access publications and consists of 500 journal articles, but only one paragraph of each article is manu- ally labeled. Therefore, we use a large amount of external data to leverage the continuous-space rep- resentation of language in neural network model. We explore the effect of pre-training word embed- ding with two different external resources: i) a data set of Wikipedia articles as a general English resource, and ii) a data set of 50k Computer Sci- ence papers from ACM. 2 Tagging Problem Formulation The task re- quires detecting the exact span of a keyphrase. In order to be able to distinguish spans of two consec- utive keyphrases of the same type, we assign labels to every word in a sentence, indicating position in the phrase and the type of phrase. We formulate the problem as an IOBES (Inside, Outside, Begin- ning, End and Singleton) tagging problem where every token is labeled either as: B, if it is at the beginning of a keyphrase; E, if it ends the phrase; I, if it is inside a keyphrase but not the first or last token; S, if it is a single-word keyphrase; or O, oth- erwise. For example, "named entity recognition" in first sentence of <ref type="figure" target="#fig_0">Fig. 1</ref> is labeled as "B-Task I- task E-task".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Neural Architecture Model</head><p>We introduce an end-to-end model to categorize scientific keyphrases, building on a neural named entity recognition model ( <ref type="bibr" target="#b23">Lample et al., 2016</ref>) and adding a feature-based embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model</head><p>We develop a 3-layer hierarchical neural model to tag tokens of the documents (details of the to- kenization is in Sec. 6). <ref type="formula" target="#formula_0">(1)</ref> The token repre- sentation layer concatenates three components for each token: a bi-directional character-based em- bedding, a word embedding, and an embedding as- sociated with orthographic and part-of-speech fea- tures. <ref type="formula" target="#formula_1">(2)</ref> The token LSTM layer uses a bidirec- tional LSTM to incorporate contextual cues from surrounding tokens to derive intermediate token embeddings. <ref type="formula">(3)</ref> The CRF tagging layer models token-level tagging decisions jointly using a CRF objective function to incorporate dependencies be- tween tags.</p><p>Character-Based Embedding. The embedding for a token is derived from its characters as the concatenation of forward and backward represen- tations from a bidirectional LSTM. The charac- ter lookup table is initialized at random. The ad- vantage of building a character-based embedding layer is that it can handle out-of-vocabulary words and equations, which are frequent in this data, all of which are mapped to "UNK" tokens in the Word Embedding Layer. Word Embedding. Words from a fixed vocab- ulary (plus the unknown word token) are mapped to a vector space, initialized using Word2vec pre- training with different combinations of corpora. Feature Embedding. We map features to a vec- tor space: capitalization (all capital, first capital, all lower, any capital but first letter) and Part-of- Speech tags. <ref type="bibr">3</ref> We randomly initialize feature vec- tors and train them together as other parameters. Token LSTM Layer We apply a bidirectional LSTM at the token level taking the concatenated character-word-feature embedding as input. The token representation obtained by stacking the for- ward and backward LSTM hidden states is passed as input to a linear layer that project the dimension to the size of label type space and is used as input to CRF layer. CRF Layer Keyphrase categorization is a task where there is strong dependencies across out- put labels (e.g., I-TASK cannot follow B-Process). Therefore, instead of making independent tag- ging decisions for each output, we model them jointly using conditional random field ( <ref type="bibr" target="#b22">Lafferty et al., 2001</ref>). For an input sentence x = (x 1 , x 2 , x 3 , . . . , x n ), we consider P to be the ma- trix of scores output by the bidirectional LSTM network. P is of size n Ã m, where n is the num- ber of tokens in a sentence, and m is the number of distinct tags. P t,i corresponds to the score of the i-th tag of the t-th word in a sentence. We use a first-order Markov Model and define a transition matrix T where T i,j represents the score from tag i to tag j. We also add y 0 and y n as the start and end tags of a sentence. Therefore T becomes a square matrix of dimension m + 2. Given one possible output y, and neural network parameters Î¸ we define the score as</p><formula xml:id="formula_0">Ï(y; x, Î¸) = n t=0 T yt,y t+1 + n t=1 P t,yt<label>(1)</label></formula><p>The probability of sequence y is obtained by ap- plying a softmax over all possible tag sequences</p><formula xml:id="formula_1">p Î¸ (y|x) = exp(Ï(y; x, Î¸)) y âY exp(Ï(y ; x, Î¸))<label>(2)</label></formula><p>where Y denotes all possible tag sequences. The normalization term is efficiently computed using the forward algorithm.</p><p>Supervised Training During training, we max- imize the log-probability L(Y ; X, Î¸) of the cor- rect tag sequence given the corpus {X, Y }. Back- propagation is done based on a gradient computed using sentence-level scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Semi-supervised Learning</head><p>We develop a semi-supervised algorithm that ex- tends self-training by estimating the labels of un- labeled data and then using those labels for re- training. Specifically, we use a graph-based al- gorithm to estimate the posterior probabilities of unlabeled data and develop a new CRF training to take the uncertainty of the estimated labels into ac- count while optimizing the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Graph-based Posterior Estimates</head><p>Our semi-supervised algorithm uses the following steps to estimate the posterior. It first constructs a graph of tokens based on their semantic similar- ity, then uses the CRF marginal as a regularization term to do label propagation on the graph. The smoothed posterior is then used to either interpo- late with the CRF marginal or as an additional fea- ture to the neural network. Graph Construction Vertices in the graph cor- respond to tokens, and edges are distance between token features which capture semantic similarity. The total size of the graph is equal to the num- ber of tokens in both labeled data V l and unlabeled data V u . The tokens are modelled with a concate- nation of pre-trained word embeddings (with di- mension d) of 5-gram centered by the current to- ken, the word embedding of the closest verb, and a set of discrete features including part-of-speech tags and capitalization (43 and 4 dimension one- hot features). The resulting feature vector with dimension of 5d + d + 43 + 4 is then projected down to 100 dimensions using PCA. We define the weight w uv of the edge between nodes u and v as follows:</p><formula xml:id="formula_2">w uv = d e (u, v) if v â K(u) or u â K(v)</formula><p>, where K(u) is the set of k-nearest neigh- bors of u and d e (u, v) is the Euclidean distance between any two nodes u and v in the graph. An example of our graph is in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>For every node i in the graph, we compute the marginal probabilities {q i } using the forward- backward algorithm. Let Î¸ i represent the estimate of the CRF parameters after the n-th iteration, we compute the marginal probabilitiesËpprobabilitiesË probabilitiesËp (j,t) = p(y j t |x; Î¸ i ) over IOBES tags for every token posi- tion t in sentence j in labeled and unlabeled data. Label Propagation We use prior-regularized measure propagation ( <ref type="bibr" target="#b27">Liu and Kirchhoff, 2014;</ref><ref type="bibr" target="#b45">Subramanya and Bilmes, 2011</ref>) to propagate la- bels from the annotated data to their neighbors in the graph. The algorithm aims for the label distri- bution between neighboring nodes to be as similar to each other as possible by optimizing an objec- tive function that minimizes the Kullback-Leibler distances between: i) the empirical distribution r u of labeled data and the predicted label distribution q u for all labeled nodes in the graph; ii) the distri- butions q u and q v for all nodes u in the graph and their neighbors v; iii) the distributions q u and the CRF marginalsËpmarginalsË marginalsËp u for all nodes. The third term regularizes the predicted distribution toward the CRF prediction if the node is not connected to a labeled vertex, ensuring the algorithm performs at least as well as standard self-training.</p><p>Posterior Estimates We develop two strategies to estimate the new posteriorsËpposteriorsË posteriorsËp(y t |x; Î¸), which can then be used in the CRF training.</p><p>The first strategy (called GRAPHINTERP) is the commonly used approach ( <ref type="bibr" target="#b46">Subramanya et al., 2010;</ref><ref type="bibr" target="#b1">Aliannejadi et al., 2014</ref>) that interpolates the smoothed posterior {q} with CRF marginals p:</p><formula xml:id="formula_3">Ë p(y t |x; Î¸) = Î±p(y t |x; Î¸) + (1 â Î±)q(y) (3)</formula><p>where Î± is a mixing coefficient.</p><p>A second strategy introduced here (called GRAPHFEAT) uses the smoothed posterior {q} as features and learns it with other parameters in the neural network. Given a sentence {x 1 , . . . , x n }, let Q = {q 1 , . . . , q n } be the predicted label distri- bution from the graph. We then use Q as a feature input to neural network asËPasË asËP = P + M Q where P is the n Ã m matrix output by the bidirectional LSTM network as in Eq. 1, and M is m Ã m ma- trix and is learned together with other parameters of neural network. We modify Eq. 1 by replacing P t,yt withËPwithË withËP t,yt . Note that GRAPHFEAT can only be done in a transductive way since it requires out- put Q from the graph at test time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">CRF training with Uncertain Labels</head><p>A standard approach to self-training is to make hard decisions for labeling tokens based on the estimated posteriors and retrain the model. How- ever, the estimated posteriors in our task are noisy due to the difficulty and variety of the ScienceIE task. Instead, we extend the CRF training to lever- age the confidence of the estimated posteriors. The new CRF training (called Uncertain Label Marginalizing (ULM)) treats low confidence to- kens as missing labels and computes the sentence- level score by marginalizing over them. A similar idea has been previously used in treating partially labeled data ( <ref type="bibr" target="#b21">Kim et al., 2015)</ref>.</p><p>Specifically, given a sentence x we define a con- strained lattice Y(x), where at each position t the allowed label types Y(x t ) are:</p><formula xml:id="formula_4">Y(x t ) = {y t }, if p(y t |x; Î¸) &gt; Î· All label types, otherwise<label>(4)</label></formula><p>where Î· is the confidence threshold, y t is the pre- diction of posterior decoding and p(y t |x; Î¸) is its CRF token marginal. The new neural network pa- rameters Î¸ are estimated by maximizing the log- likelihood of p Î¸ (Y(x k )|x k ) for every input sen- tence x k , where</p><formula xml:id="formula_5">p Î¸ (Y(x k )|x k ) = y k âY(x k ) exp(Ï(y k ; x k , Î¸)) y âY exp(Ï(y ; x, Î¸))</formula><p>where y k is an instance sequence of lattice Y(x), and k is the sentence index in the training set. Ex- treme cases are when all tokens are uncertain then the likelihood would be equal to 1, when all to- kens of a sequence are confident, it would be equal to Eq. 2 where only one possible sequence, as in <ref type="figure" target="#fig_2">Fig. 3</ref>. Inductive and Transductive Learning The semi-supervised training process is summarized as follow: It first computes marginals over the un- labeled data given a set of CRF parameters. It then uses the marginals as a regularization term for label propagation. The smoothed posteriors from the graph are then interpolated with the CRF marginal in GRAPHINTERP or used as an addi- tional feature in GRAPHFEAT. It then uses the estimated labels for the unlabeled data combined with the labeled data to retrain the CRF using ei- ther the hard decision CRF training objective as Eq. 2 or the ULM data selection objective.</p><p>In the inductive setting, we only use the unla- beled data from the development set for the semi- supervision. In the transductive setting we also use the unlabeled data of the test set to construct the graph. In both cases, the parameters are tuned only on the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Setup</head><p>Data The SemEval ScienceIE (SE) corpus con- sists of 500 journal articles; one paragraph of each   Comparisons We compare our system with two template matching baselines and the state-of-the- art on the SemEval Science IE task. The first baseline ( <ref type="bibr" target="#b16">Gupta and Manning, 2011</ref>) is an un- supervised method to extract keyphrases by ini- tially using seed patterns in a dependency tree, and then adding to seed patterns through bootstrap- ping. The second baseline <ref type="bibr" target="#b47">(Tsai et al., 2013</ref>) im- proves the work of <ref type="bibr" target="#b16">Gupta and Manning (2011)</ref> by adding Named Entity Features and use different set of seed patterns.</p><p>Implementation details All parameters are tuned on the dev set performance, the best pa- rameters are selected and fixed for model switch- ing and semi-supervised systems. The word em- bedding dimension is 250; the token-level hidden dimension is 100; the character-level hidden di- mension is 25; and the optimization algorithm is SGD with a learning rate of 0.05. For building the graph, the best pre-trained embeddings for the supervised system (Sec. 7.2) are used in each do- main. Two special tokens BOS and EOS are added when pre-training, indicating the begin and end of a sentence. The number of the graph vertices is 2M in tranductive setting and 1.4M in inductive setting. The ULM parameter Î· in Eq. 4 is tuned from 0.1 to 0.9, the best Î· is 0.4. The best pa- rameters of label propagation are Âµ = 10 â6 and Î½ = 10 â5 . The interpolation parameter Î± in Eq. 3 is tuned from 0.1 to 0.9, the best Î± is 0.3. We do iteration of semi-supervised learning until we ob- tain the best result on the dev set, which is mostly achieved in the second round.</p><p>We use Stanford CoreNLP ( ) tokenizer to tokenize words. The tokenizer is augmented with a few hand-designed rules to handle equations (e.g. "fs(B,t)=Spel(t)S" is a sin- gle token) and other non-standard word phenom- ena (Cu40Zn, 20MW/m2) in scientific literature. We use Approximate Nearest Neighbor Searching (ANN) <ref type="bibr">4</ref> to calculate the k-nearest neighbors. For all experiments in this paper, k = 10.</p><p>Setup We evaluate our system in both inductive and transductive settings. The systems with a * superscript in the table are transductive. The in- ductive setting uses 400 full articles in ScienceIE training and dev sets, while the transductive set- ting uses 500 full articles including the test set. In both settings parameters are tuned over the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results</head><p>We evaluate our NN-CRF model in both super- vised and semi-supervised settings. We also per- form ablations and try different variants to best un- derstand our model. <ref type="table" target="#tab_1">Table 1</ref> reports the results of our neural sequence tagging model NN-CRF in both supervised and semi-supervised learning (ULM and graph-based), and compares them with the baselines and the state-of-the-art (best SemEval System (Augen- stein et al., 2017)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Best Case System Performance</head><p>Augenstein and SÃ¸gaard (2017) use a multi-task learning strategy to improve the performance of supervised keyphrase classification, but they only report dev set performance on SemEval Task 10, we also include their result here and refer it as MULTITASK. We report results for both span identification (SemEval SubTask A) and span clas- sification into TASK, PROCESS and MATERIAL (SemEval Subtask B). <ref type="bibr">5</ref> The results show that our neural sequence tag- ging models significantly outperforms the state of the art and both baselines. It confirms that our neural tagging model outperforms other non- neural and neural models for the SemEval Scien- ceIE challenge <ref type="bibr">6</ref> . It further shows that our system achieves significant boost from semi-supervised learning using unlabeled data. <ref type="table" target="#tab_7">Table 5</ref> shows the detailed analysis of the system across different cat- egories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Supervised Learning</head><p>Impact of Neural Model Components <ref type="table" target="#tab_2">Table 2</ref> provides the results of an ablation study on the dev set showing the impact of different components of our NN-CRF on the Scientific IE task. For the ba- sic model, the word embeddings are initialized by word2vec trained on the 350 full journal articles in the SE training set together with Wikipedia and ScienceIE data. The feature layer, character layer, and bi-LSTM word layers all improves the perfor- mance. Moreover, we observe a large improve- ment (20.6% relative) in the scientific IE task by adding the CRF layer. Initialization  mains. We explore different word embedding pre- training with ScienceIE training set alone (SE), and adding other external resources including Wikipedia (wiki) and Computer Science articles (ACM). All alternatives use word2vec. Compared with using SE alone, introduction of all external data sources improve performance. Moreover, we observe that with the introduction of the ACM dataset, the performance on the CS domain is in- creased significantly in both the dev and test sets. Adding Wikipedia data benefits all three domains, with more significant improvement on the MS and Physics domains.</p><p>Based on these observations, we select the best model on each domain according to the dev set and use the combined result as our best suprevised sys- tem (called NN-CRF(supervised)). The F1 score improves from 39.4 to 40.2 when applying model switching strategy. The best model on the dev set is used for each domain: for MS and physics do- main, we pretrain word embeddings with the SE and Wiki, and for the CS domain, we pretrain with the SE and ACM. <ref type="table" target="#tab_6">Table 4</ref> reports the results of the semi-supervised learning algorithms in different settings. In par- ticular we ablate incorporating the graph-based methods of computing the posterior and CRF training (ULM vs. hard decision). The table shows incorporating graph-based methods for computing posterior and ULM for CRF training outperforms their counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Semi-Supervision Learning</head><p>For computing the posterior, we explore two different strategies of the graph-based meth- ods: i) GRAPHINTERP that interpolates the smoothed posterior from label propagation with CRF marginals; For inductive setting, GRAPHIN- TERP only uses un-annotated data from the dev set and uses the best model for decoding at test time. For transductive setting, GRAPHINTERP * uses un- annoated data from test set to build the graph as   well, and tune the parameters on the dev set. ii) GRAPHFEAT uses the smoothed posterior from la- bel propagation as additional feature to neural net- work and only has transductive setting. As expected, the transductive approaches con- sistently outperform inductive approaches on the test set. With around the same performance on dev set, GRAPHINTERP* seems to generalize bet- ter on test set with 1.6% relative improvement over GRAPHINTERP. We observe higher improvement with GRAPHFEAT* compared to GRAPHINTERP. This is mainly because automatically learning the weight matrix M between neural network scores and graph outputs adds more flexibility compared to tuning an interpolation weight Î±. The perfor- mance is further improved by applying data selec- tion through modifying the objective to ULM. The best inductive system is ULM+GRAPHINTERP with 5.6% relative improvement over pure Self- Training that makes hard decisions, and the best transductive system is ULM+GRAPHFEAT* with 8.6% relative improvement. <ref type="table" target="#tab_7">Table 5</ref> details the performance of our method on the three categories at the span and token level. We observe significant improvement by using ULM+GRAPHINTERP and ULM+GRAPHFEAT over best SemEval and our best supervised sys- tem on all three categories at both token and span levels. We further observe that systems' per- formance on TASK classification is much lower than PROCESS and MATERIAL. This is in part because TASK is much less frequent than the other types. In addition, TASK keyphrases of- ten include verb phrases while the other two do- mains mainly consists of noun phrases. An anal- ysis of confusion patterns show that the most frequent type confusions are between PROCESS and MATERIAL. However, we observe that ULM+GRAPHFEAT* can greatly reduce the con- fusion, with 3.5% relative improvement of PRO- CESS and 3.6% relative improvement of PROCESS over ULM+GRAPHINTERP on token level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Category and Span Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Error Analysis</head><p>We provide examples of typical errors that our sys- tem makes in <ref type="table">Table 6</ref>. As described in the previ- ous subsection, TASK is the hardest type to iden- tify with our system. Row 1 shows a failure to detect the verb phrase following 'to' as part of the TASK, but detect 'enantiopure products' as MA- TERIAL. The system prefers to predict PROCESS or MATERIAL since those classes have more sam- ples than TASK. Row 2 illustrates the problem of identifying general terms as keyphrases due to similar context, such as 'receptors' and 'drug ac- tion'. A third common error involves incorrectly labeling adjectives, such as 'neighbouring' in Row 3, which leads to span errors. Another common cause of error is insufficient context: in the last example, a larger context is needed to determine whether 'SWE' is a PROCESS or MATERIAL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper casts the scientific information extrac- tion task as a sequence tagging problem and in- troduces a hierarchical LSTM-CRF neural tag- ging model for this task, building on recent results in NER. We introduced a semi-supervised learn- ing algorithm that incorporates graph-based label propagation and confidence-aware data selection. We show the introduction of semi-supervision sig- nificantly outperforms the performance of the su- pervised LSTM-CRF tagging model. We addi- tionally show that external resources are useful for initializing word embeddings. Both induc- tive and transductive semi-supervised strategies  <ref type="table">Table 6</ref>: Common errors, where blue means golden label our system misses, red means falsely predicted results, and green means correctly predicted spans.</p><p>achieve state-of-the-art performance in SemEval 2017 ScienceIE task. We also conducted a detailed analysis of the system and point out common error cases.</p><p>In our experiments, we observe that including in-domain data only for semi-supervised learning has slightly better performance than using cross- domain data. Reducing the amount of in-domain data hurts performance. Therefore, adding more in-domain unlabeled data may help when com- bined with selection schemes such as the ULM al- gorithms proposed here. It would be useful to as- sess the impact of matched unlabeled data for the physics and material science domain. Other future work includes leveraging global context, informa- tion of citation network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Annotated ScienceIE examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Label propagation. Gray nodes indicates labeled data while white nodes are unlabeled. Bold font word indicates the current token. The assumption is if two instances are similar according to the graph, the output labels should be similar.</figDesc><graphic url="image-1.png" coords="4,72.00,62.81,226.77,106.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Lattice representation of ULM. Dashed box is the uncertain token which is going to be marginalized over. Arrows and grey nodes are paths to be summed over during training. When all tokens are confident, the score of only one path is calculated.</figDesc><graphic url="image-2.png" coords="5,72.00,62.81,226.77,98.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Overall span-level F1 results for keyphrase identification (SemEval Subtask A) and classification (SemEval Subtask 

B).  *  indicates tranductive setting. + indicates not documented as either transductive or inductive. -indicates score not reported 
or not applied. 

Model 
P 
R 
F1 

NN-CRF(supervised) 46.2 48.2 47.2 

No features 
44.2 46.1 45.1 
No bi-LSTM 
45.2 44.7 44.9 
No CRF 
36.7 38.2 37.4 
No char 
45.7 46.2 45.9 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Ablation study showing impact of neural network 

configurations of our NN-CRF(supervised) model on the dev 
set. 

article is randomly selected and annotated. The 
complete unlabeled articles and their metadata are 
provided together with the labeled data. The train-
ing data consists of 350 documents; 50 are kept for 
development and 100 for testing. The 500 articles 
come from 82 different journals evenly distributed 
in three domains. We manually labeled 82 journal 
names in the dataset into the three domains and do 
analysis based on the domain partitions. The 500 
full articles contains 2M words and is 30 times the 
size of the annotated data. 

Additionally, we use two external resources for 
pretraining word embeddings: i) WIKI, as for 
Wikipedia articles, specifically a full Wikipedia 
dump from 2012 containing 46M words, and 
ii) ACM, a collection of CS papers, containing 
108M words. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 reports our NN-CRF performance when pretrained on different do-</head><label>3</label><figDesc></figDesc><table>Dev 
Test 
Initialization MS 
Phy 
CS 
MS 
Phy 
CS 

SE 
49.4 39.4 45.0 42.9 33.0 30.5 
+wiki 
52.9 40.5 47.9 46.1 39.2 31.0 
+ACM 
50.3 39.8 49.5 42.2 37.8 34.2 
+wiki+ACM 50.5 40.3 48.9 43.1 37.9 34.4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 :</head><label>3</label><figDesc>F1 score on the dev and test sets for using different sources of data for pretraining.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>F1 scores of semi-supervised Learning ap-
proaches; * shows transductive models. 

Span Level 
T 
P 
M 
K 

Best SemEval 
19 
44 
48 
55 
supervised 
13.3 40.5 
43.7 
52.1 
ULM+GRAPHINTERP 17.0 45.4 
49.4 
56.9 
ULM+GRAPHFEAT* 
17.2 46.5 
50.7 
57.6 

Token Level 
T 
P 
M 
K 

supervised 
29.6 56.0 
59.3 
70.8 
ULM+GRAPHINTERP 40.0 60.7 
61.2 
77.0 
ULM+GRAPHFEAT* 
40.1 62.8 63.4 78.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>F1 score results on the test set for different cat-

egories: T indicates TASK, P indicates PROCESS, M is MA-
TERIAL and K is Keyword identification (SubTask A). * is 
transductive model. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>requirement in aiming to [achieve [enantiopure products] Material ] Task is therefore a means to [quantitate [the enantiometric excess]Process] Task . General terms Since the [receptors] Material in human biology mostly consist of [chiral molecules] Material , [drug action]Process mostly involves a specified enantiometric form.</head><label></label><figDesc></figDesc><table>Error types 

Annotation and System Output 

Verb phrases 
A key Falsely predicted adjec-
tives 
It has been shown that the most efficient forms of energy transfer between the two occurs when 
there is a [neighbouring carotenoid species] Material . 

Lack of context 
Other models use [SWEs ] Material 
Process but focus on the use of multi resolution grids or irregular 
mesh. 

</table></figure>

			<note place="foot" n="1"> SemEval (Task 10)https://scienceie.github. io/index.html</note>

			<note place="foot" n="2"> Due to the difficulty of data collection, experiments with external data from the other two domains is left to future work.</note>

			<note place="foot" n="3"> Dependency features were investigated but did not lead to performance gains.</note>

			<note place="foot" n="4"> https://www.cs.umd.edu/ Ë mount/ANN/</note>

			<note place="foot" n="5"> The evaluation script is provided by the challenge, with a modification to report 3 decimal precision results. 6 Best SemEval Numbers from https://scienceie.github.io/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgments</head><p>This research was supported by the NSF (IIS 1616112), Allen Institute for AI (66-9175), Allen Distinguished Investigator Award, and gifts from Google, Samsung, and Bloomberg. We thank the anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Coherent citation-based summarization of scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amjad</forename><surname>Abu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Jbara</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="500" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graphbased semi-supervised conditional random fields for spoken language understanding using unaligned data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Aliannejadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masoud</forename><surname>Kiaeeha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed Shiry</forename><surname>Ghidary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian Language Technology Association Workshop</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">98</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashton</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<title level="m">Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries</title>
		<meeting>the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="13" to="21" />
		</imprint>
	</monogr>
	<note>Towards a computational history of the ACL</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Contextenhanced citation sentiment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awais</forename><surname>Athar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 conference of the North American chapter of the Association for Computational Linguistics: Human language technologies. Association for Computational Linguistics</title>
		<meeting>the 2012 conference of the North American chapter of the Association for Computational Linguistics: Human language technologies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="597" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection of implicit citations for sentiment detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awais</forename><surname>Athar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Detecting Structure in Scholarly Discourse</title>
		<meeting>the Workshop on Detecting Structure in Scholarly Discourse</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinal</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lakshmi</forename><surname>Vikraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<title level="m">ScienceIE-extracting keyphrases and relations from scientific publications. Proceedings of SemEval</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multitask learning of keyphrase boundary classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>SÃ¸gaard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00514</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved transition-based parsing by modeling characters instead of words with LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bonnie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">Thomas</forename><surname>Bryan R Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwon</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Powley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Fan</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tan</surname></persName>
		</author>
		<title level="m">The ACL anthology reference corpus: A reference dataset for bibliographic research in computational linguistics</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>LREC</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In TACL</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unsupervised models for named entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the joint SIGDAT conference on empirical methods in natural language processing and very large corpora. Citeseer</title>
		<meeting>the joint SIGDAT conference on empirical methods in natural language processing and very large corpora. Citeseer</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="100" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">LÃ©on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3079" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Extracting and matching authors and affiliations in scholarly documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Hoang Nhat Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthu</forename><surname>Kumar Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><forename type="middle">Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM/IEEECS joint conference on Digital libraries</title>
		<meeting>the 13th ACM/IEEECS joint conference on Digital libraries</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="219" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic annotation of the ACL anthology corpus for the automatic analysis of scientific literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kata</forename><surname>Gabor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifa</forename><surname>Zargayouna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Buscaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Isabelle Tellier, and Thierry Charnois</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">France</forename><surname>Paris</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analyzing the dynamics of research by extracting key aspects of scientific papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNLP</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Driver prediction to improve interaction with in-vehicle hmi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bret</forename><surname>Harsham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Esenther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Hershey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Nikovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vamsi</forename><surname>Potluru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Digital Signal Processing for InVehicle Systems (DSP)</title>
		<meeting>Workshop on Digital Signal essing for InVehicle Systems (DSP)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kokil</forename><surname>Jaidka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthu</forename><surname>Kumar Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><forename type="middle">Fisas</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Molla-Aliod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Dragomir R Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ronzano</surname></persName>
		</author>
		<title level="m">The computational linguistics summarization pilot task. Proceedings of TAC</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Structures and statistics of citation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miray</forename><surname>Kas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>DTIC Document</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Weakly supervised slot tagging with partially labeled sequences from web search click logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Bum</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minwoo</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruhi</forename><surname>Sarikaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eighteenth international conference on machine learning</title>
		<meeting>the eighteenth international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recognition of stance strength and polarity in spontaneous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerie</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alena</forename><surname>Hrynkevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trang</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="236" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dependencybased word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="302" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised learning for phone and segment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Conference of the International Speech Communication Association</title>
		<meeting>Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Interspeech</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Graph-based semi-supervised acoustic modeling in DNN-based speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE SLT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Acoustic modeling with neural graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph-based semisupervised learning for acoustic modeling in automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1946" to="1956" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Novel frontend features based on neural graph embeddings for DNN-HMM and LSTM-CTC acoustic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Kirchhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Annual Conference of the International Speech Communication Association</title>
		<meeting>Annual Conference of the International Speech Communication Association</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Interspeech. ISCA</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiplicative representations for unsupervised semantic role induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 54th Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">118</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Lstm based conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09457</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semisupervised noise dictionary adaptation for exemplarbased noise robust speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosuke</forename><surname>Kashiwagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuaki</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keikichi</forename><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on. IEEE</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1745" to="1748" />
		</imprint>
	</monogr>
	<note>Acoustics, Speech and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Performance improvement of automatic pronunciation assessment in a noisy classroom</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Yamauchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuaki</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhei</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keikichi</forename><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spoken Language Technology Workshop (SLT</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">2012</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ieee</forename><surname>Ieee</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="428" to="431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficient learning for spoken language understanding tasks with word embedding based pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bret</forename><surname>Harsham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH. Citeseer</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1398" to="1402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Relating automatic vowel space estimates to talker intelligibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ginaanne</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional LSTM-CNNsCRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Christopher D Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (System Demonstrations)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Named entity recognition for chinese social media with jointly trained embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="548" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The acl rd-tec 2.0: A language resource for evaluating term extraction and entity recognition methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Qasemizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne-Kathrin</forename><surname>Schumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Discovering factions in the computational linguistics community</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchuan</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics</title>
		<meeting>the ACL2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with measure propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="3311" to="3370" />
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Efficient graph-based semisupervised learning of structured tagging models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amarnag</forename><surname>Subramanya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Concept-based analysis of scientific literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Tse</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gourab</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1733" to="1738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">He said, she said: Gender in the ACL anthology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics</title>
		<meeting>the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
