<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feature-Rich Two-Stage Logistic Regression for Monolingual Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date type="published" when="2015-09">September 2015. 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Md</roleName><forename type="first">Arafat</forename><surname>Sultan</surname></persName>
							<email>arafat.sultan@colorado.edu, bethard@cis.uab.edu,</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Cognitive Science and Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer and Information Sciences</orgName>
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Alabama at Birmingham</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Cognitive Science and Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer and Information Sciences</orgName>
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Alabama at Birmingham</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Sumner</surname></persName>
							<email>sumner@colorado.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Cognitive Science and Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer and Information Sciences</orgName>
								<orgName type="institution" key="instit1">University of Colorado Boulder</orgName>
								<orgName type="institution" key="instit2">University of Alabama at Birmingham</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Feature-Rich Two-Stage Logistic Regression for Monolingual Alignment</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
						<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Lisbon, Portugal</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="17" to="21"/>
							<date type="published" when="2015-09">September 2015. 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Monolingual alignment is the task of pair-ing semantically similar units from two pieces of text. We report a top-performing supervised aligner that operates on short text snippets. We employ a large feature set to (1) encode similarities among semantic units (words and named entities) in context, and (2) address cooperation and competition for alignment among units in the same snippet. These features are deployed in a two-stage logistic regression framework for alignment. On two benchmark data sets, our aligner achieves F 1 scores of 92.1% and 88.5%, with statistically significant error reductions of 4.8% and 7.3% over the previous best aligner. It produces top results in extrinsic evaluation as well.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Computer applications frequently require seman- tic comparison between short snippets of natural language text. Such comparisons are key to para- phrase detection <ref type="bibr" target="#b8">(Das and Smith, 2009;</ref><ref type="bibr" target="#b19">Madnani et al., 2012)</ref>, textual similarity identification ( <ref type="bibr" target="#b1">Agirre et al., 2015;</ref><ref type="bibr" target="#b30">Sultan et al., 2015</ref>) and recognition of textual entailment ( <ref type="bibr" target="#b7">Dagan and Glickman, 2004;</ref><ref type="bibr" target="#b24">Padó et al., 2015</ref>). And they underpin applications such as short answer grading <ref type="bibr" target="#b21">(Mohler et al., 2011</ref>), question answering ( <ref type="bibr" target="#b17">Hixon et al., 2015)</ref>, machine translation evaluation <ref type="bibr" target="#b23">(Padó et al., 2009)</ref>, and ma- chine reading <ref type="bibr" target="#b10">(de Marneffe et al., 2007)</ref>.</p><p>A central problem underlying all text compari- son tasks is that of alignment: pairing related se- mantic units (i.e. words and phrases) across the two snippets ( <ref type="bibr" target="#b18">MacCartney et al., 2008;</ref><ref type="bibr" target="#b32">Thadani and McKeown, 2011;</ref><ref type="bibr" target="#b33">Thadani et al., 2012;</ref><ref type="bibr" target="#b35">Yao et al., 2013a;</ref><ref type="bibr" target="#b36">Yao et al., 2013b;</ref><ref type="bibr" target="#b28">Sultan et al., 2014a</ref>). Studies have shown that such tasks can benefit from an explicit alignment component <ref type="bibr" target="#b16">(Hickl and Bensley, 2007;</ref><ref type="bibr" target="#b29">Sultan et al., 2014b;</ref><ref type="bibr" target="#b30">Sultan et al., 2015)</ref>. However, alignment is still an open research prob- lem. We present a supervised monolingual aligner that produces top results in several intrinsic and extrinsic evaluation experiments. We pinpoint a set of key challenges for alignment and design a model with components targeted at each.</p><p>Lexical and phrasal alignments can both be rep- resented as pairs of words -in the form of many- to-many mappings among the two phrases' com- ponent words in the latter case. Thus without loss of generality, we formulate alignment as a binary classification task where given all word pairs across two sentences, the goal is to assign each a class la- bel in {aligned, not aligned}. However, this is not a straightforward classification scenario where each word pair can be treated independently -words in the same snippet can play both mutually cooper- ating and competing roles in complex ways. For example, semantically similar words in a snippet can be in competition for alignment with a word in the other snippet, whereas words that constitute a phrase can provide supporting evidence for one another (e.g. in named entity alignments such as Watson ↔ John Hamish Watson). To han- dle such interdependencies, we employ a two-stage logistic regression model -stage 1 computes an alignment probability for each word pair based solely on its own feature values, and stage 2 assigns the eventual alignment labels to all pairs following a comparative assessment of stage 1 probabilities of cooperating and competing pairs.</p><p>On two alignment data sets reported in <ref type="bibr" target="#b4">(Brockett, 2007)</ref> and ( <ref type="bibr" target="#b33">Thadani et al., 2012)</ref>, our aligner demonstrates respective F 1 scores of 92.1% and 88.5%, with statistically significant error reduc- tions of 4.8% and 7.3% over the previous best aligner ( <ref type="bibr" target="#b28">Sultan et al., 2014a</ref>). We also present ex- trinsic evaluation of the aligner within two text comparison tasks, namely sentence similarity iden- tification and paraphrase detection, where it demon- strates state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>British 1 armor 2 crashed 3</head><p>into 4 a 5 jail 6 to 7 free 8 two 9 soldiers 10 arrested 11 by 12 Iraqi 13 police 14</p><p>. 15</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">2 3 4 5 6 7 8 9</head><p>Figure 1: A human-aligned sentence pair from the MSR alignment corpus. The shaded cells depict the alignment, which can also be represented as the set of word index pairs {(1, 1), (2, 2), (3, 3), (4, 3), (5, 4), . . . , (15, 9)}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Alignment: Key Pieces of the Puzzle</head><p>We illustrate with examples key pieces of the align- ment puzzle and discuss techniques used by exist- ing aligners to solve them. We use the term 'unit' to refer to both words and phrases in a snippet. <ref type="figure">Figure 1</ref> shows a shortened version of sentence pair 712 in the MSR alignment corpus dev set <ref type="bibr" target="#b4">(Brockett, 2007</ref>) with related units aligned by hu- man annotators. Evident from these alignments is the fact that aligned units are typically semantically similar or related. Existing aligners utilize a variety of resources and techniques for computing simi- larity between units: WordNet ( <ref type="bibr" target="#b18">MacCartney et al., 2008;</ref><ref type="bibr" target="#b32">Thadani and McKeown, 2011</ref>), PPDB ( <ref type="bibr" target="#b36">Yao et al., 2013b;</ref><ref type="bibr" target="#b28">Sultan et al., 2014a</ref>), distributional similarity measures ( <ref type="bibr" target="#b18">MacCartney et al., 2008;</ref><ref type="bibr" target="#b36">Yao et al., 2013b</ref>) and string similarity measures <ref type="bibr" target="#b18">(MacCartney et al., 2008;</ref><ref type="bibr" target="#b35">Yao et al., 2013a</ref>). Recent work on neural word embeddings ( <ref type="bibr" target="#b20">Mikolov et al., 2013;</ref>) have advanced the state of distributional similarity, but remain largely un- explored in the context of alignment.</p><p>Lexical or phrasal similarity does not entail align- ment, however. Consider function words: the align- ment (5, 4) in <ref type="figure">Figure 1</ref> exists not just because both units are the word a, but also because they modify semantically equivalent units: jail and police station. The influence of context on content word alignment becomes salient particu- larly in the presence of competing words. In <ref type="bibr">Figure 1, (soldiers(10)</ref>, troops(2)) are not aligned despite the two words' semantic equiva- lence in isolation, due to the presence of a compet- ing pair, (armor(2), troops <ref type="formula" target="#formula_7">(2)</ref>), which is a better fit in context.</p><p>The above examples reveal a second aligner re- quirement: the ability to incorporate context into similarity calculations. Existing supervised align- ers use various contextual features within a learning algorithm for this purpose. Such features include both shallow surface measures (e.g., the relative positions of the tokens being aligned in the respec- tive sentences, similarities in the immediate left or right words) ( <ref type="bibr" target="#b18">MacCartney et al., 2008;</ref><ref type="bibr" target="#b32">Thadani and McKeown, 2011;</ref><ref type="bibr" target="#b35">Yao et al., 2013a</ref>) and syn- tactic measures like typed dependencies ( <ref type="bibr" target="#b32">Thadani and McKeown, 2011;</ref><ref type="bibr" target="#b33">Thadani et al., 2012)</ref>. <ref type="bibr" target="#b28">Sultan et al. (2014a)</ref> design an unsupervised model that more directly encodes context, via surface and dependency-based neighbors which allow contex- tual similarity to be represented as a weighted sum of lexical similarity. But their model lacks a key structural advantage of supervised models: to be able to use an arbitrarily large feature set to robustly encode lexical and/or contextual similarity.</p><p>The third and final key component of an aligner is a mechanism to combine lexical/phrasal and con- textual similarities to produce alignments. This task is non-trivial due to the presence of cooperat- ing and competing units. We first discuss compet- ing units: semantically similar units in one snippet, each of which is a potential candidate for alignment with one or more units in the other snippet. At least three different possible scenarios of varying diffi- culty exist concerning such units:</p><p>• Scenario 1: No competing units. In <ref type="figure">Figure 1</ref>  <ref type="formula" target="#formula_7">(2)</ref>) and (soldiers(10), troops(2)) are in such competition.</p><p>• Scenario 3: Many-to-many competition:</p><p>when similar units in one snippet have multi- ple potential alignments in the other snippet.</p><p>Groups of mutually cooperating units can also exist where one unit provides supporting evidence for the alignment of other units in the group. Ex- amples (besides named entities) include individual words in one snippet that are grouped together in the other snippet (e.g., state of the art ↔ state-of-the-art or headquarters in Paris ↔ Paris-based).</p><p>We briefly discuss the working principles of ex- isting aligners to show how they respsond to these challenges. <ref type="bibr" target="#b18">MacCartney et al. (2008)</ref>, <ref type="bibr" target="#b32">Thadani and McKeown (2011)</ref> and <ref type="bibr" target="#b33">Thadani et al. (2012)</ref> frame alignment as a set of phrase edit (insertion, deletion and substitution) operations that transform one snippet into the other. Each edit operation is scored as a weighted sum of feature values (in- cluding lexical and contextual similarity features), and an optimal set of edits is computed. <ref type="bibr" target="#b35">Yao et al. (2013a;</ref><ref type="bibr" target="#b36">2013b</ref>) take a sequence labeling ap- proach: input snippets are considered sequences of units and for each unit in one snippet, units in the other snippet are considered potential labels. A first order conditional random field is used for prediction. <ref type="bibr" target="#b28">Sultan et al. (2014a)</ref> treat alignment as a bipartite matching problem and use a greedy al- gorithm to perform one-to-one word alignment. A weighted sum of two words' lexical and contextual similarities serves as the pair's edge weight.</p><p>Noticeable in the designs of the supervised align- ers is a lack of attention to the scenarios competing units can pose -alignment of a unit depends only on its own feature values. While the unsupervised aligner by <ref type="bibr" target="#b28">Sultan et al. (2014a)</ref> employs techniques to deal with such scenarios, it allows only one-to- one alignment, which fundamentally limits the set of reachable alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>We primarily focus on word alignment, which <ref type="bibr" target="#b36">Yao et al. (2013b)</ref> report to cover more than 95% of all alignments in multiple human-annotated cor- pora. Named entities are the only phrasal units we consider for alignment; in a later section we dis- cuss how our techniques can be extended to general phrasal alignment. <ref type="figure" target="#fig_1">Figure 2</ref> shows our two-stage logistic regres- sion model. We address the first two challenges, namely identifying lexical and contextual simi- larities, in stage 1 of the model. Given input text snippets</p><formula xml:id="formula_0">T (1) = (T (1) 1 , ..., T (1) n ) and T (2) = (T (2) 1 , ..., T (2) m ) where T (t)</formula><p>k is the k-th word of snip- pet T (t) , the goal of this stage is to assign each word pair of the form (T</p><formula xml:id="formula_1">(1) i , T (2) j ) an alignment í µí² í µí±í µí± (1) í µí² 11</formula><p>(1) í µí² í µí±í µí± <ref type="bibr">(1)</ref> í µí¼ í µí±í µí± í µí¼ <ref type="bibr">11</ref> í µí¼ í µí±í µí± í µí¼ í µí±í µí± í µí¼ í µí±í µí± í µí°´íµí°´í µí±í µí±</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>… …</head><p>í µí¼½ í µí±¡ <ref type="bibr">11</ref> (1) í µí¼½ í µí±¡ í µí±í µí±</p><formula xml:id="formula_2">(2) … … … … í µí¼½ í µí±¡ í µí±í µí± (1)</formula><p>í µí¼½ í µí±¡ í µí±í µí± <ref type="bibr">(1)</ref> í µí±´íµí±´í µí¼ í µí±º í µí±¤ (see Section 4.1). Stage 2 assigns each pair a label A ij ∈ {aligned, not aligned} based on its own φ, the φ of its cooperat- ing and competing pairs, a max-weighted bipartite matching M φ with all φ values as edge weights, the semantic similarities S w of the pair's words and words in all cooperating pairs, and learned weights θ probability φ ij , based on the pair's lexical and con- textual similarity features. We discuss our stage 1 features in Section 4.1.</p><p>We categorize each word along two different di- mensions: (1) whether or not it is part of a named entity, and (2) which of the following groups it belongs to: content words, function words, and punctuation marks. This distinction is important because, (1) certain features apply only to certain types of words (e.g., acronymy applies only to named entities; punctuation marks do not partici- pate in dependency relationships), and (2) certain features can be more important for certain types of words (e.g., the role of a function word depends heavily on its surrounding words and therefore con- textual features can be more important for function words). Combined, the two above dimensions form a domain of six possible values which can be repre- sented as the Cartesian product {non-named entity, named entity} × {content word, function word, punctuation mark}. Each member of this set is a word type in our model; for instance, named entity function word is a word type. This notion of types is then extended to word pairs in T (1) × T (2) : the type of pair (T</p><formula xml:id="formula_3">(1) i , T (2) j )</formula><p>is the union of the types of T j . Given 951 the pair's stage 1 feature vector f <ref type="bibr">(1)</ref> ij and the stage 1 weight vector θ (1) t ij for its type t ij , we compute its stage 1 alignment probability φ ij as:</p><formula xml:id="formula_4">φ ij = 1 1 + e −θ (1) t ij ·f (1) ij</formula><p>The weight vector θ</p><p>(1) t for word pair type t is derived by minimizing the L1-regularized loss:</p><formula xml:id="formula_5">J(θ (1) t ) = − 1 N t Nt p=1 y (p) t log(φ (p) t ) + (1 − y (p) t ) log(1 − φ (p) t ) + λθ (1) t 1</formula><p>where N t is the number of word pairs of type t over all sentence pairs in the training data, y</p><p>t is the gold label for pair p of type t (1 = aligned, 0 = not aligned), and φ (p) t is its stage 1 alignment probability.</p><p>Stage 2 of the model assigns the final alignment label</p><formula xml:id="formula_7">A ij ∈ {0, 1} to (T (1) i , T<label>(2)</label></formula><p>j ). Like stage 1, it uses L1-regularized logistic regression to compute an alignment probability for each word pair, but additionally assigns a final 0/1 label using a 0.5 threshold. Stage 2 factors in the stage 1 probabil- ities of cooperating and competing pairs as well as a maximum-weighted matching M φ between T (1) and T <ref type="bibr">(2)</ref> , where word pairs in T (1) × T (2) are weighted by their stage 1 φ values. Such global knowledge is useful in addressing cooperation and competition among words. We describe our stage 2 features in Section 4.2.</p><p>The two stages are trained separately, each as n standard logistic regression models where n is the number of word pair types for which at least one instance per class is observed in the training data. The stage 1 models are first trained and used to make predictions for each training sentence pair (for each training pair, all other training pairs are used to train the model). Given all the stage 1 align- ment probabilities and the other stage 2 features, the stage 2 models are then trained. At test time, the two sets of trained models (i.e. stage 1 and 2 models) are successively applied to each input sentence pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Features</head><p>As mentioned above, we train a separate model for each individual word pair type. Our feature set is largely the same across word pair types, with some differences. In the two following sections, we discuss these features and indicate the associated word pair types. We assume alignment of the two words T</p><p>(1) i ∈ T (1) and T (2) j ∈ T (2) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Stage 1: Assessing Pairs Individually</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Word Similarity Features</head><p>Our first feature combines neural word embed- dings, used previously for word similarity predic- tion ( <ref type="bibr" target="#b20">Mikolov et al., 2013;</ref>), with a paraphrase database ( <ref type="bibr" target="#b12">Ganitkevitch et al., 2013)</ref>. Our feature is the output of a ridge regres- sion model trained on human annotations of word similarity <ref type="bibr" target="#b26">(Radinsky et al., 2011;</ref><ref type="bibr" target="#b13">Halawi et al., 2012;</ref><ref type="bibr" target="#b5">Bruni et al., 2014</ref>) with two features: the cosine similarity between the neural embedding vectors of the two words (using a publicly avail- able set of 400-dimensional word vectors ( ), and the presence/absence of the word pair in the PPDB XXXL database. This regression model produces similarities (sim henceforth) in <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, though we only consider similarities above 0.5 as lower scores are often noisy. To deal with single-letter spelling errors, we consider T to be an exact match if exactly one of the two is correctly spelled and their Levenshtein distance is 1 (words of length ≥ 3 only).</p><p>We also use the following semantic and string similarity features: a boolean feature that is 1 iff one of T is hyphenated and the other is identical to a hyphen-delimited part of the first, the same feature for highly similar (sim ≥ 0.9) words, two features that show what proportion of the characters of one word is covered by the other if the latter is a prefix or a suffix of the former and zero otherwise (length &lt; 3 words are discarded).</p><p>For named entities, we (1) consider acronymy as exact match, (2) use membership in two lists of alternative country names and country-nationality pairs (from Wikipedia) as features, and (3) include a feature that encodes whether T (1) i and T (2) j be- long to the same named entity (determined by one mention containing all words of the other, e.g., Einstein and Albert Einstein).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Contextual Features</head><p>Effective identification of contextual similarity calls for a robust representation of word context in a sentence. Our contextual features are based on two different sentence representations. The word-Günter Grass won the Nobel Prize. based representation treats each individual word as a semantic unit whereas the entity-based rep- resentation (1) groups together words in a multi- word named entity, and (2) treats non-name words as individual entities. <ref type="figure" target="#fig_6">Figure 3</ref> shows an exam- ple. The two representations are complementary - the entity-based representation can capture equiva- lences between mentions of different lengths of a named entity, while the word-based representation allows the use of similarity resources for named entity words. Non-name words are treated iden- tically. For simplicity we only discuss our word- based features below, but each feature also has an entity-based variant.</p><p>Dependency-based context. These features ap- ply only if neither of T  <ref type="formula">)</ref>). Equivalent dependency types (Sultan et al., 2014a) are included in the above computation, which encode semantic equivalences between typed dependencies (e.g., nsubjpass and dobj). We employ separate features for identicality and similarity. Similar features are also computed for a dependency neighborhood of size 2 (parents, grandparents, children and grandchildren), where we consider only content word neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency neighbors of T</head><p>(1) i and T (2) j that are less similar (0.9 &gt; sim ≥ 0.5; e.g., (gas, energy) or (award, winner)) can also con- tain useful semantic information for an aligner. To accommodate this relatively large range of word similarities, rather than counting such pairs, we find a maximum-weighted bipartite matching of T (1) i and T (2) j neighbors in a neighborhood of size 2 us- ing the primal-dual algorithm (content words only), where word similarities across the two neighbor- hoods serve as edge weights. We use as a feature the sum of similarities between the matched neigh- bors, normalized by the total number of content words in the two neighborhoods.</p><p>Surface-form context. We draw several contex- tual features from nearby words of T (1) i and T (2) j in the surface forms of T (1) and T (2) : (1) whether the left and/or the right word/lemma is identical , (2) whether the two are highly similar (sim ≥ 0.9), (3) the longest common word/lemma sequence con- taining T</p><p>(1) i and T (2) j such that at least one word in the sequence is a content word, (4) proportion of identical and highly similar (sim ≥ 0.9) words in a neighborhood of 3 content words to the left and 3 content words to the right; we use two versions of this feature, one compares neighbors only in the same direction (i.e. left with left, right with right) and the other compares neighbors across the two di- rections, (5) similarly to dependency-based context, similarity in a max-weighted matching of all neigh- bors with sim ∈ [0.5, 0.9) in the above <ref type="bibr">[−3, 3]</ref> window. For punctuation mark pairs, we use an additional feature indicating whether or not they both mark the end of their respective sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Stage 2: Cooperation and Competition</head><p>We consider two groups of mutually cooperating words in a sentence: (1) words that belong to the same named entity, and (2) words in a sentence that are joined together to form a larger word in the other sentence (e.g., state-of-the-art). Speaking in terms of T <ref type="formula">(1)</ref> i , the goal is to be able to use any evidence present for a (T j . With a reversal of word order and appro- priate substitution of indexes, the above discussion equally holds for T <ref type="bibr">(2)</ref> j . Given sets of stage 1 probabilities Φ cop ij and Φ cmp ij of cooperating and competing pairs for the pair (T</p><formula xml:id="formula_8">(1) i , T<label>(2)</label></formula><p>j ), we employ three features to deal with scenario 2 of Section 2: (1) max(φ ij , max(Φ cop ij )): the greater of the pair's own stage 1 alignment probability and the high- est among all cooperating pair probabilities, (2) max(Φ cmp ij ): the highest of all competing pair probabilities, and (3) a binary feature indicating which of the two above is larger.</p><p>To address scenario 3, we construct a weighted bipartite graph: nodes represent words in T (1) and T <ref type="bibr">(2)</ref> and the weight of each edge represents the stage 1 alignment probability of a word pair in T (1) × T <ref type="bibr">(2)</ref> . We find a max-weighted bipartite matching M φ of word pairs in this graph. For each word pair, we employ a feature indicating whether or not it is in M φ . The presence of (T  <ref type="table" target="#tab_1">Table 1</ref>). Our observation of the aligner's be- havior on the dev set of the MSR alignment cor- pus <ref type="bibr" target="#b4">(Brockett, 2007)</ref> suggests that this happens primarily due to highly similar word pairs being left unaligned even in the absence of competing pairs because of relatively low contextual evidence. Consequently, aligner performance suffers in sen- tences with few common or similar words. To promote high recall, we employ the higher of a word pair's own lexical similarity and the lexical similarity of the cooperating pair with the highest stage 1 probability as a stage 2 feature.</p><p>The stage 2 feature set is identical across word pair types, but as in stage 1, we train individual models for different pair types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">System Evaluation</head><p>We report evaluation on two alignment data sets and extrinsic evaluation on two tasks: sentence similarity identification and paraphrase detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Alignment</head><p>We adopt the evaluation procedure for aligners re- ported in prior work ( <ref type="bibr" target="#b18">MacCartney et al., 2008;</ref><ref type="bibr" target="#b32">Thadani and McKeown, 2011;</ref><ref type="bibr" target="#b35">Yao et al., 2013a)</ref>. <ref type="formula" target="#formula_7">(2011)</ref>   Evaluation metrics. Our primary evaluation metrics are macro-averaged precision (P), recall (R) and F 1 score. A fourth metric E measures the proportion of sentence pairs for which the system alignments are identical to the gold alignments.</p><formula xml:id="formula_9">Aligner P % R % F1 % E % MSR</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MacCartney et al. (2008) 85.4 85.3 85.3 21.3 Thadani &amp; McKeown</head><p>Model setup. For each corpus, we train our model using the dev set and evaluate on the test set. We use the logistic regression implementation of Scikit-learn ( <ref type="bibr" target="#b25">Pedregosa et al., 2011</ref>) and use leave- one-out cross-validation on the dev pairs to set the regularization parameter C.</p><p>Results. <ref type="table" target="#tab_1">Table 1</ref> shows the performance of dif- ferent aligners on the two test sets. Our aligner demonstrates the best overall performance in terms of both F 1 and E. Wilcoxon signed-rank tests (with Pratt's treatment for zero-difference pairs) show that the improvements in F 1 over the previous best aligner (Sultan et al., 2014a) are statistically significant at p &lt; 0.01 for both test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Identification of Sentence Similarity</head><p>Given two input sentences, the goal in this task, known also as Semantic Textual Similarity (STS), is to output a real-valued semantic similarity score.   Data. To be able to directly compare with past aligners, we select three data sets (headlines: pairs of news headlines; OnWN, FNWN: gloss pairs) from the 2013 *SEM STS corpus ( <ref type="bibr" target="#b0">Agirre et al., 2013)</ref>, containing 1500 sentence pairs in total. <ref type="bibr" target="#b28">Sultan et al. (2014a)</ref> reports the performance of two state-of-the-art aligners on these pairs. Evaluation metric. At SemEval, STS systems output a similarity score in <ref type="bibr">[0,</ref><ref type="bibr">5]</ref>. For each individ- ual test set, the Pearson product-moment correla- tion coefficient (Pearson's r) is computed between system scores and human annotations. The final evaluation metric is a weighted sum of r's over all test sets, where the weight assigned to a set is proportional to its number of pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pearson's r Rank</head><p>Method. Being a logistic regression model, stage 2 of our aligner assigns each word pair an alignment probability. For STS, we compute a length-normalized sum of alignment probabilities of content word pairs across the two sentences. We include all pairs with probability &gt; 0.5; the re- maining pairs are included in decreasing order of their probabilities and already included words are ignored. <ref type="bibr">Following (Sultan et al., 2014a</ref>), we nor- malize by dividing with the harmonic mean of the numbers of content words in the two sentences.</p><p>Results. <ref type="table" target="#tab_3">Table 2</ref> shows the performance of dif- ferent aligners on the three STS 2013 test sets. We also show the performance of the contest-winning system ( <ref type="bibr" target="#b14">Han et al., 2013</ref>). Our STS system demon- strates a weighted correlation of 67.8%, which is better than similar STS systems based on the two previous best aligners. The difference with the next best aligner is statistically significant at p &lt; 0.05 (two-sample one-tailed z-test). Overall, our system outperforms 86 of the 89 participating systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Paraphrase Detection</head><p>Given two input sentences, the goal in this task is to determine if their meanings are the same.</p><p>Data. The MSR paraphrase corpus ( <ref type="bibr" target="#b11">Dolan et al., 2004</ref>) contains 4076 dev and 1725 test sentence pairs; a paraphrase label (true/false) for each pair</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>A % P % R % F 1 % Madnani et al. <ref type="formula" target="#formula_7">(2012)</ref> 77.4 79.0 89.9 84.1 <ref type="bibr" target="#b35">Yao et al. (2013a)</ref> 70.0 72.6 88.1 79.6 <ref type="bibr" target="#b36">Yao et al. (2013b)</ref> 68  is provided by human annotators. Evaluation Metrics. We report performance in terms of: (1) accuracy in classifying the sentences into true and false classes (A), and (2) true class precision (P ), recall (R) and F 1 score.</p><p>Method. Following prior aligners <ref type="bibr" target="#b18">(MacCartney et al., 2008;</ref><ref type="bibr" target="#b36">Yao et al., 2013b;</ref><ref type="bibr" target="#b28">Sultan et al., 2014a</ref>), we output a true decision for a test sentence pair iff the length-normalized alignment score for the pair exceeds a threshold derived from the dev set.</p><p>Results. The top row of <ref type="table" target="#tab_5">Table 3</ref> shows the best result by any system on the MSR test set. Among all aligners (all other rows), ours achieves the best F 1 score and the second best accuracy.</p><p>We report paraphrase detection results primarily to allow comparison with past aligners. However, this simplistic application to a complex task only gives a ballpark estimate of an aligner's quality.  <ref type="table">Table 4</ref>: Performance with and without stage 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation</head><p>We perform ablation tests to find out how important (1) the two-stage framework, and (2) the different features are for our aligner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Results without Stage 2</head><p>Stage 1 of our aligner can operate as an aligner by itself by mapping each alignment probability to a 0/1 alignment decision based on a threshold of 0.5. From a design perspective, this is an aligner that does not address scenarios 2 and 3 of Section 2. The performance of the aligner with and without stage 2 is shown in <ref type="table">Table 4</ref>. On each test set, the F 1 and E scores increase with the addition of stage 2. On the MSR test set, performance improves along all dimensions. On the Edinburgh++ test set, the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MSR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EDB++</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features</head><p>P % R % F1 % P % R % F1 % All Features 95.4 89.0 92.1 92.1 85.2 88.5 -Lexical 95.1 82.8 88.5 90.9 84.0 87.3 -Resources 96.0 87.0 91.3 92.2 84.3 88.1 -Contextual 89.0 79.2 83.9 89.9 66.3 76.3 -Dependency 95.3 88.2 91.6 91.9 84.9 88.3 -Surface 94.4 85.6 89.8 90.6 76.9 83.2 -Word-Based 94.6 87.7 91.0 92.0 85.1 88.4 -Entity-Based 95.5 89.0 92.1 92.1 85.1 88.5  precision drops a little, but this effect is offset by a larger improvement in recall. These results show that stage 2 is central to the aligner's success.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Without Different Stage 1 Features</head><p>We exclude different stage 1 features (which fall into one of two groups: lexical and contextual) and examine the resulting model's performance. <ref type="table" target="#tab_6">Table  5</ref> shows the results. The subtraction sign represents the exclusion of the corresponding feature.</p><p>Without any lexical feature (i.e., if the model re- lies only on contextual features), both precision and recall decrease, resulting in a considerable overall performance drop. Exclusion of word similarity resources (i.e. embeddings and PPDB) improves precision, but again harms overall performance.</p><p>Without any contextual features, the model suf- fers badly in both precision and recall. The extreme overall performance degradation indicates that con- textual features are more important for the aligner than lexical features. Leaving out surface-form neighbors results in a larger performance drop than when dependency-based neighbors are excluded, pointing to a more robust role of the former group in representing context. Finally, our entity-based representation of context neither helps nor harms system performance, but relying only on entity- based neighbors has detrimental effects. Factoring in semantic similarities of named entities should improve the utility of these features.  <ref type="figure">Figure 4</ref>: % distribution of aligned word pair types; nne: non-named entity, ne: named entity, c: content word, f : function word, p: punctuation mark.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Without Different Stage 2 Features</head><formula xml:id="formula_10">MSR EDB++ Pair Type P % R % F1 % P % R % F1 % {nne-c</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Error Analysis</head><p>We examine the aligner's performance on different word pair types. <ref type="figure">Figure 4</ref> shows the % distribution of word pair types with at least 20 aligned instances in at least one test set. These six types account for more than 99% of all alignments in both test sets. <ref type="table" target="#tab_10">Table 7</ref> shows the results. We ignore punctua- tion mark pairs in the following discussion. Per- formance is worst on the two rarest types: {nne-c, nne-f } and {nne-c, ne-c}, due primarily to very low recall. A relatively low availability of posi- tive examples in the training sets (in the hundreds, in contrast to thousands of examples for each of the other three types) is a primary factor affect- ing classifier performance on these two pair types. The {nne-c, nne-f } pairs, nonetheless, are intrin- sically the most difficult type for a word aligner because they occur frequently as part of phrasal alignments. On {nne-c, ne-c} pairs, errors also oc- cur due to failure in recognition of certain named entity types (e.g., acronyms and multiword named entities) and the aligner's lack of world knowledge (e.g., in daughter ↔ Chelsea).</p><p>Low recall remains the primary issue, albeit to a much lesser extent, for {nne-c, nne-c} and {nne-f, nne-f } pairs. For the former, two major sources of error are: (1) inability to utilize contextual ev- idence outside the local neighborhood examined by the aligner, and (2) failure to address one-to- many alignments. Low recall for the latter follows naturally, as function word alignment is heavily dependent on related content word alignment. On {ne-c, ne-c} pairs the aligner performs the best, but still suffers from the two above issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>We mentioned major standalone monolingual align- ers and briefly discussed their working principles in Section 2. There are, however, at least two ad- ditional groups of related work which can inform future research on monolingual alignment. First, alignment is often performed in the context of ex- trinsic tasks, e.g., textual entailment recognition ( <ref type="bibr" target="#b34">Wang and Manning, 2010)</ref>, question answering <ref type="bibr" target="#b15">(Heilman and Smith, 2010)</ref>, discourse generation ( <ref type="bibr" target="#b27">Roth and Frank, 2012)</ref> and redundancy detection <ref type="bibr" target="#b31">(Thadani and McKeown, 2008)</ref>. Such systems may contain useful design elements yet to be utilized by standalone aligners. Second, a large body of work exists in the bilingual alignment literature <ref type="bibr" target="#b22">(Och and Ney, 2003;</ref><ref type="bibr" target="#b3">Blunsom and Cohn, 2006;</ref><ref type="bibr" target="#b6">Chang et al., 2014</ref>), elements of which (such as the machine learning models) can be useful for monolingual aligners (see <ref type="bibr" target="#b35">(Yao et al., 2013a</ref>) for an example).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>We present a two-stage classification framework for monolingual alignment that demonstrates top results in intrinsic and extrinsic evaluation experi- ments. While our work focuses primarily on word alignment, given a mechanism to compute phrasal similarity, the notion of cooperating words can be exploited to extend our model for phrasal align- ment. Another important future direction is the con- struction of a robust representation of context, as our model currently utilizes contextual information only within a local neighborhood of a predefined size and therefore fails to utilize long-distance se- mantic relationships between words. Incorporating a single background model which is trained on all word pair types might also improve performance, especially on types that are rare in the training data. Finally, studying the explicit requirements of dif- ferent extrinsic tasks can shed light on the design of a robust aligner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, the aligned pair (British(1), UK(1)) represents this scenario. • Scenario 2: Many-to-one competition: when multiple units in one snippet are similar to a single unit in the other snippet. In Fig- ure 1, pairs (armors(2), troops</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Two-stage logistic regression for alignment. Stage 1 computes an alignment probability φ ij for each word pair based on local features f (1) ij</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Word and entity-based representations of a sentence. Words in the same named entity are grouped together in the latter representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>We compute the proportion of identical and highly similar (sim ≥ 0.9) parents and children of T (1) i and T (2) j in the dependency trees of T (1) and T (2) (Stanford collapsed dependencies (de Marn- effe et al., 2006</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>lj</head><label></label><figDesc>) in M φ , where all four words are similar, is a potential indicator that (T) are no longer viable alignments. Low recall has traditionally been the primary weakness of supervised aligners (as we later show in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Han</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 :</head><label>1</label><figDesc>800 dev and 800 test sentence pairs from the PASCAL RTE 2006 challenge. Each pair is aligned by three human annotators; Fleiss Kappa agreement of about 0.73 ("substantial agreement") is reported on both sets. Following prior work, we only consider the sure alignments, take the majority opinion on each word pair, and leave out three-way disagreements. The Edinburgh++ corpus (Thadani et al., 2012) contains 714 training and 306 test sentence pairs. Each test pair is aligned by two annotators and the final gold alignments consist of a random but even selection of the two sets of annotations.</figDesc><table>Performance on two alignment data sets. 
Improvements in F 1 are statistically significant. 

Data. The MSR alignment corpus (Brockett, 
2007) contains </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 : STS results.</head><label>2</label><figDesc></figDesc><table>Performances of past systems 
are reported by Sultan et al. (2014a). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Paraphrase results. Performances of past 
systems are taken from (Sultan et al., 2014a). 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Results without different stage 1 features. 

MSR 
EDB++ 
Features P % R % F1 % P % R % F1 % 
All Features 95.4 89.0 92.1 92.1 85.2 88.5 
-φ values 
87.3 90.7 88.9 86.4 86.9 86.7 
-Matching 95.3 87.9 91.5 92.3 84.6 88.3 
-Word Sim 95.5 88.4 91.8 92.7 84.7 88.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 6 :</head><label>6</label><figDesc>Results without different stage 2 features.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 6 shows</head><label>6</label><figDesc></figDesc><table>the aligner's performance after the 
exclusion of different stage 2 features. Leaving out 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Performance on different word pair types. 

the stage 1 alignment probabilities harms overall 
performance the most by causing a large drop in 
precision. Exclusion of the maximum-weighted 
bipartite matching feature results in worse recall 
and overall performance. The lexical similarity 
feature improves overall results only on the MSR 
test set but increases recall on both test sets. 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based in part upon work supported by the National Science Foundation under Grant Numbers EHR/0835393 and EHR/0835381.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">*SEM 2013 Shared Task: Semantic Textual Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalezagirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Joint Conference on Lexical and Computational Semantics, *SEM &apos;13</title>
		<meeting>the Second Joint Conference on Lexical and Computational Semantics, *SEM &apos;13<address><addrLine>Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="32" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">and Pilot on Interpretability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmen</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iñigo</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Montse</forename><surname>Maritxalar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larraitz</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>English, Spanish; Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="252" to="263" />
		</imprint>
	</monogr>
	<note>SemEval-2015 Task 2: Semantic Textual Similarity</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Don&apos;t Count, Predict! A Systematic Comparison of Context-Counting vs. Context-Predicting Semantic Vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgiana</forename><surname>Dinu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Kruszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics, ACL &apos;14<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="238" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discriminative Word Alignment with Conditional Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL<address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<publisher>Australia</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Aligning the RTE 2006 Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
		<idno>MSR-TR-2007-77</idno>
		<imprint>
			<date type="published" when="2007" />
			<pubPlace>Microsoft Research</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elia</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Khanh</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimodal Distributional Semantics. Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Constrained Viterbi Relaxation for Bidirectional Word Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Denero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">14811490</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Glickman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the PASCAL Workshop on Learning Methods for Text Understanding and Mining</title>
		<meeting>the PASCAL Workshop on Learning Methods for Text Understanding and Mining<address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="468" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generating Typed Dependency Parses from Phrase Structure Parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation</title>
		<meeting>the International Conference on Language Resources and Evaluation<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="449" to="454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Aligning Semantic Graphs for Textual Inference and Machine Reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chlo</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Spring Symposium</title>
		<meeting>the AAAI Spring Symposium<address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="468" to="476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computational Linguistics</title>
		<meeting>the International Conference on Computational Linguistics<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="350" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">PPDB: The Paraphrase Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Large-Scale Learning of Word Relatedness with Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Halawi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1406" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">UMBC EBIQUITY-CORE: Semantic Textual Similarity Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lushan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhay</forename><surname>Kashyap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Joint Conference on Lexical and Computational Semantics, *SEM &apos;13</title>
		<meeting>the Second Joint Conference on Lexical and Computational Semantics, *SEM &apos;13<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="44" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tree Edit Models for Recognizing Textual Entailments, Paraphrases, and Answers to Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2010 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Los Angeles, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">10111019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Discourse Commitment-Based Framework for Recognizing Textual Entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hickl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Bensley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing</title>
		<meeting>the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="171" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Knowledge Graphs for Question Answering through Conversational Dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Hixon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Phrase-Based Alignment Model for Natural Language Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="802" to="811" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Re-examining Machine Translation Metrics for Paraphrase Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitin</forename><surname>Madnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Chodorow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2012 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>2012 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="182" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations Workshop</title>
		<meeting>the International Conference on Learning Representations Workshop<address><addrLine>Scottsdale, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to Grade Short Answer Questions Using Semantic Similarity Measures and Dependency Graph Alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="752" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Systematic Comparison of Various Statistical Alignment Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1951</biblScope>
			<date type="published" when="2003" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust Machine Translation Evaluation with Entailment Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="297" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Design and Realization of a Modular Architecture for Textual Entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Gil</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asher</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zanoli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="200" />
			<date type="published" when="2015" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Word at a Time: Computing Word Relatedness using Temporal Semantic Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on World Wide Web</title>
		<meeting>the 20th International Conference on World Wide Web<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page">171182</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Back to Basics for Monolingual Alignment: Exploiting Word Similarity and Contextual Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Md Arafat Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sumner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="219" to="230" />
			<date type="published" when="2014-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DLS@CU: Sentence Similarity from Word Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Md Arafat Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sumner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">DLS@CU: Sentence Similarity from Word Alignment and Semantic Vector Composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Md Arafat Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sumner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
		<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, Colorado, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="148" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Framework for Identifying Textual Redundancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">873880</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimal and Syntactically-Informed Decoding for Monolingual Phrase-Based Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="254" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Joint Phrasal and Dependency Model for Paraphrase Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kapil</forename><surname>Thadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012<address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1229" to="1238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Probabilistic Tree-Edit Models with Structured Latent Variables for Textual Entailment and Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">11641172</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Lightweight and High Performance Monolingual Word Aligner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="702" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semi-Markov Phrase-based Monolingual Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="590" to="600" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
