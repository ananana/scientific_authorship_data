<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /home/ana/installs/grobid/grobid-0.5.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-04-18T10:48+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Morey</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IRIT</orgName>
								<orgName type="institution" key="instit2">Université Toulouse &amp; CNRS</orgName>
								<orgName type="institution" key="instit3">Univ. Paul Sabatier</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Muller</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IRIT</orgName>
								<orgName type="institution" key="instit2">Université Toulouse &amp; CNRS</orgName>
								<orgName type="institution" key="instit3">Univ. Paul Sabatier</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IRIT</orgName>
								<orgName type="institution" key="instit2">Université Toulouse &amp; CNRS</orgName>
								<orgName type="institution" key="instit3">Univ. Paul Sabatier</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">How much progress have we made on RST discourse parsing? A replication study of recent results on the RST-DT</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1319" to="1324"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This article evaluates purported progress over the past years in RST discourse parsing. Several studies report a relative error reduction of 24 to 51% on all met-rics that authors attribute to the introduction of distributed representations of discourse units. We replicate the standard evaluation of 9 parsers, 5 of which use distributed representations, from 8 studies published between 2013 and 2017, using their predictions on the test set of the RST-DT. Our main finding is that most recently reported increases in RST discourse parser performance are an artefact of differences in implementations of the evaluation procedure. We evaluate all these parsers with the standard Parseval procedure to provide a more accurate picture of the actual RST discourse parsers performance in standard evaluation settings. Under this more stringent procedure, the gains attributable to distributed representations represent at most a 16% relative error reduction on fully-labelled structures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While several theories of discourse structure for text exist, discourse parsing work has largely concentrated on Rhetorical Structure Theory (RST) ( <ref type="bibr" target="#b13">Mann and Thompson, 1988)</ref> and the RST Discourse Treebank (RST-DT) <ref type="bibr" target="#b4">(Carlson et al., 2003)</ref>, which is the largest corpus of texts anno- tated with full discourse structures. The RST-DT, annotated in the style of RST, consists of 385 news articles from the Penn Treebank, split into a train- ing and test sets of 347 and 38 documents.The standard evaluation procedure for RST discourse parsing, RST-Parseval, proposed by <ref type="bibr" target="#b14">Marcu (2000)</ref>, adapts the Parseval procedure for syntactic pars- ing ( <ref type="bibr" target="#b0">Black et al., 1991)</ref>. RST-Parseval computes scores on discourse structures with no label (S for Span) or labelled with nuclearity (N), relation (R) or both (F for Full). The semantic nature of discourse relations makes discourse parsing a dif- ficult task. However, the recent introduction of distributed representations of discourse units has seemingly led to significant improvements, with a claimed relative error reduction of 51% on fully labelled structures. As part of a broader study of methods and evaluation metrics for discourse pars- ing, we collected predictions from nine RST dis- course parsers and reimplemented RST-Parseval. In section 2, we present these RST parsers and re- port their published scores on RST-Parseval. In section 3, we replicate their evaluation and show that most of the heterogeneity in performance across RST parsers arises from differences in their evaluation procedures. In section 4, we replace RST-Parseval with the standard Parseval proce- dure and obtain a more accurate picture of the ac- tual performance of RST parsers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A sample of RST discourse parsers</head><p>Almost all RST discourse parsers are evaluated on the test section of the RST-DT using manually seg- mented Elementary Discourse Units (EDUs). We contacted by email the main or corresponding au- thor of each recently <ref type="bibr">(2013)</ref><ref type="bibr">(2014)</ref><ref type="bibr">(2015)</ref><ref type="bibr" target="#b3">(2016)</ref><ref type="bibr">(2017)</ref> published, text- level RST discourse parser evaluated in this set- ting and asked the authors to provide us with the predictions they used in their study or a proce- dure that would enable us to reproduce identical or at least similar predictions. When our attempts were unsuccessful we tried to reproduce similar predictions from published materiel (source code, binaries, model). We managed to obtain or re- produce predictions for 9 parsers from 8 stud- ies. The first parser, denoted HHN16 HILDA, is a reimplementation ( <ref type="bibr" target="#b6">Hayashi et al., 2016</ref>) of the classic, bottom-up, greedy HILDA parser with a linear SVM model <ref type="bibr" target="#b8">(Hernault et al., 2010)</ref> ; this parser serves as a reference point to evaluate the progress made by more recent parsers. SHV15 D is a variant of the HILDA parser with different models (perceptron for attachment of discourse units, logistic regression for relation labelling) and a slightly different feature set adapted to use pre- dicted syntactic dependency trees ( <ref type="bibr" target="#b16">Surdeanu et al., 2015)</ref>. JCN15 1S-1S is a two stage (sentence- then document-level) CKY chart parser with Dy- namic Conditional Random Field (DCRF) mod- els, in its 1 sentence -1 subtree (1S-1S) vari- ant that builds a document-level RST tree on top of sentence-level subtrees built for each sentence independently ( <ref type="bibr" target="#b11">Joty et al., 2013</ref><ref type="bibr" target="#b10">Joty et al., , 2015</ref>. FH14 gCRF is a two stage (sentence-then document- level) bottom-up, greedy parser with linear-chain CRF models <ref type="bibr" target="#b5">(Feng and Hirst, 2014</ref>). We use the version of the parser available on the author's web- page, that lacks post-editing and contextual fea- tures. BPS16 is a sequence-to-sequence parser, heuristically constrained to build trees, with a hi- erarchical neural network model (hierarchical bi- LSTM) <ref type="bibr">(Braud et al., 2016</ref>). LLC16 is a CKY chart parser with a hierarchical neural network model (attention-based hierarchical bi-LSTM) ( <ref type="bibr" target="#b12">Li et al., 2016)</ref>. BCS17 mono, BCS17 cross+dev are two variants of a transition-based parser that uses a feed-forward neural network model <ref type="bibr" target="#b1">(Braud et al., 2017)</ref>. JE14 DPLP is a shift-reduce parser that uses an SVM model <ref type="bibr" target="#b9">(Ji and Eisenstein, 2014</ref>). We use predictions provided by the author, from an improved, unpublished version of the parser.</p><p>The first four parsers (HHN16 HILDA, SHV15 D, JCN15 1S-1S, FH14 gCRF) use, as features, only localist representations of the input and pars- ing state, i.e. surface-form and syntactic informa- tion: length of discourse units (DUs), distance be- tween DUs, n-grams of words and POS tags, rela- tions of syntactic dominance between DUs. . . The last five parsers (BPS16, LLC16, BCS17 mono and cross+dev, JE14 DPLP concat) build dis- tributed representations of DUs, complemented with a subset of localist representations.</p><p>The authors used various implementations of RST-Parseval, but all applied a right-heavy bi- narization procedure to the reference RST trees: Each node of arity greater than 2 is replaced with a right-branching cascade of binary nodes. In the publications, the tables of results provide a unique score for labeled structures, corresponding to ei- ther the R or F metric, with no explicit distinc- tion. The F 1 scores published in the literature for the parsers in our sample are reported in <ref type="table">Table 1</ref>, where an en-dash (-) indicates missing scores. We also report the scores of human agreement, com- puted and reported by <ref type="bibr" target="#b10">Joty (2015)</ref>, over the doubly annotated subset of the RST-DT consisting of 53 documents (48 from train, 5 from test). The parsers in the second group seem to per- form markedly better than the parsers in the first group, especially on the hardest subtasks of pre- dicting (partly or fully) labelled structures (N and R or F). Collectively, the parsers in the sec- ond group claim absolute improvements over the parsers in the first group by 0.9, 3.2 and 4.2 points, corresponding to a relative error reduction of 24% on S, 41% on N and 51% on R or F, compared to human agreement. While discourse parsing is a difficult, semantic task with relatively little an- notated training data, authors attribute these sig- nificant gains to the capacity of distributed repre- sentations to capture latent semantic information and generalize over a long tail of alternative sur- face forms. As a preliminary step towards probing these claims, we replicated the evaluation of these parsers' predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>We collected or reproduced predictions from each parser and replicated the evaluation procedure <ref type="bibr">1</ref> . The predictions came in various formats: brack- eted strings as in the RST-DT, lists of span de- scriptions, trees or lists of attachment decisions. We wrote custom functions to load and normalize the predictions from each parser into RST trees. While we favor evaluating against the original, non binarized reference RST trees, we conformed in this replicative study to the de facto standard in the RST parsing literature: We transformed the reference RST trees into right-branching binary trees and used these binary trees as reference in all our evaluation procedures. We also examined the source code from the evaluation procedures provided by the authors to determine whether the published scores corresponded to the R or F met- ric. In so doing we noticed a potentially impor- tant discrepancy in the various implementations of the RST-Parseval procedure: the implemen- tations used to evaluate the parsers in the first group compute micro-averaged F 1 scores, as is standard practice in the syntactic parsing commu- nity, whereas the implementations used to evaluate the parsers in the second group compute macro- averaged F 1 scores across documents. The micro- averaged F 1 score is computed globally over the predicted and reference spans from all documents ; the macro-averaged F 1 score across documents is the average of F 1 scores computed independently for each document.</p><p>We implemented both strategies and report the corresponding scores in two separate tables. Parsers originally evaluated with micro-averaging scores are in the top half of each table, parsers originally evaluated with macro-averaged scores in the bottom half. An asterisk (*) marks parsers for which we reproduced predictions using code and material made available by the authors, al- though the experimental settings are not guar- anteed to match exactly those from the original study. A double asterisk (**) marks a parser for which we used predictions generated by the au- thor using an improved, unpublished version of the parser posterior to the original study. Lines with no asterisk in <ref type="table" target="#tab_2">Tables 2 to 4</ref> correspond to parsers whose authors sent us their original predictions. Replicated scores expected to match scores in Ta- ble 1 are underlined. <ref type="table" target="#tab_2">Table 2</ref> contains the micro-averaged F 1 scores on each metric (S, N, R, F). As expected, parsers in the first group obtain micro-averaged scores equal or close to their published scores reported in Ta- ble 1. More strikingly, the micro-averaged scores for the parsers in the second group are much lower than their published scores 2 and most of their claimed advantages over the parsers in the first <ref type="bibr">2</ref> The milder decrease of the DPLP scores, especially on S, is directly attributable to improvements in the latest, un- published version of the parser.    <ref type="table" target="#tab_3">Table 3</ref> contains the macro-averaged F 1 scores. Parsers in the first group obtain macro-averaged scores markedly higher than the micro-averaged scores from <ref type="table" target="#tab_2">Table 2</ref>. Parsers in the second group obtain macro-averaged scores that are equal or close to the published scores reported in <ref type="table">Table 1</ref>, which confirms our analysis of the source code of their evaluation procedures. The global picture on macro-averaged scores is consistent with that on micro-averaged scores: On S and N, parsers in the second group do not improve over parsers the first group and the best parser brings an absolute im- provement of 0.9 and 1.4 points on R and F. On each metric, the two lowest scores are obtained by parsers from the second group.</p><p>To sum up, parsers in the first group have iden- tical scores in <ref type="table" target="#tab_2">Tables 1 and 2</ref>, except for slight dif- ferences between our evaluation procedure and the authors', or between the predictions used in our evaluation compared to the original study. The second group of parsers have identical scores in <ref type="table" target="#tab_3">Tables 1 and 3</ref>, modulo the same factors. The (ex- actly or nearly) matching entries between <ref type="table" target="#tab_2">Tables 1,  2 and 3, underlined in Tables 2 and 3</ref>, are evidence of the two averaging strategies (micro in <ref type="table" target="#tab_2">Table 2</ref>, macro in <ref type="table" target="#tab_3">Table 3</ref>) used by the authors in their pub- lications <ref type="table">(Table 1)</ref>. A comparison between Ta- bles 2 and 3 reveals that the averaging strategy similarly affects both groups of parsers. As a re- sult, the performance level among recent RST dis- course parsers is much more homogeneous than the situation depicted in the literature. The dis- tributed representations of DUs computed and used in JE14 DPLP ( <ref type="bibr" target="#b9">Ji and Eisenstein, 2014</ref>) and possibly BCS17 cross+dev ( <ref type="bibr" target="#b1">Braud et al., 2017)</ref> plausibly capture semantic information that helps with predicting discourse relations and structure, but the current experimental results do not pro- vide a similarly strong support for BPS16 ( <ref type="bibr">Braud et al., 2016</ref>), LLC16 ( <ref type="bibr" target="#b12">Li et al., 2016</ref>) and BCS17 mono ( <ref type="bibr" target="#b1">Braud et al., 2017</ref>).</p><p>More generally, it is important that authors compute and report scores that accord with stan- dard practice, unless duly motivated. The standard practice in syntactic parsing is to report micro- averaged scores for overall performance, often complemented with macro-averaged scores over classes to gain valuable insight into the average performance of parsers across labels, especially infrequent ones. Early work in RST discourse parsing follows this practice, reporting micro- averaged scores for global performance, plus dis- tinct scores for each relation class or macro- averaged scores over all relation classes <ref type="bibr" target="#b8">(Hernault et al., 2010;</ref><ref type="bibr" target="#b5">Feng and Hirst, 2014)</ref>. The latter should not be confused with the scores published for BPS16, LLC16, BCS17 (mono, cross+dev) and JE14 DPLP, which are macro-averaged over documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Elements for a fairer evaluation</head><p>RST-Parseval crucially relies on an encoding of RST trees into constituency trees such that the rhetorical relation names are placed on the chil- dren nodes, and the nuclei of mononuclear re- lations are conventionally labelled SPAN. RST- Parseval resembles the original Parseval, except it considers a larger set of nodes to collect all nu- clearity and relation labels in this encoding: the root node (whose label and nuclearity are fixed by convention) is excluded and the leaves, the EDUs, are included. On the one hand, RST-Parseval can handle discourse units of arity greater than 2, in particular those consisting of a nucleus indepen- dently modified by two satellites through distinct mononuclear relations. This avoids introducing discourse units that were not part of the origi- nal annotation, which a preliminary binarization of trees would have induced. On the other hand, RST-Parseval considers approximately twice as many nodes as the original Parseval would on bi- narized trees (at most 2n − 2 nodes for n EDUs, compared to n − 1 attachments in a binary tree), and the relation labels of most nuclei are redun- dant with the nuclearity of a node and its sis- ter (SPAN for a nucleus whose sisters are satel- lites, and the same label as its sisters for a nucleus whose sisters are nuclei). Both aspects artificially raise the level of agreement between RST trees, especially when using manual EDU segmentation.</p><p>However, all the parsers in our sample except <ref type="bibr" target="#b15">(Sagae, 2009;</ref><ref type="bibr" target="#b7">Heilman and Sagae, 2015)</ref> predict binary trees over manually segmented EDUs and evaluate them against right-heavy binarized refer- ence trees. In this setting, Marcu's encoding of RST trees RST-Parseval are no longer motivated. We can thus revert to using the standard Parseval procedure on a representation of binary RST trees where each internal node is a labelled attachment decision to obtain a more accurate evaluation of RST parser performance. <ref type="figure" target="#fig_0">Figure 1</ref> represents (a) an original RST tree using Marcu's encoding, (b) its right-heavy binarized version, (c) the tree of la- belled attachment decisions for the right-heavy bi- narized tree. To the best of our knowledge, we are the first to explicitly use an evaluation procedure for RST parsing closer to the original Parseval for syntax, although the trees of labelled attach- ment decisions we use directly correspond to the trees built by many RST parsers, eg. shift-reduce parsers. <ref type="table" target="#tab_5">Table 4</ref> provides the micro-averaged F 1 Parseval is more stringent than RST-Parseval, with the best system obtaining 46.3 on fully la- belled structures (F). Parsers in the first group are competitive with parsers in the second group, out- performing them on S and to a lesser extent on N. Parsers in the second group reduce relative error by 8% on R and 16% on F, much lower than the published figures in the literature.</p><formula xml:id="formula_0">(, R) (explanation, S) π4 (span, N) (List, N) π3 (List, N) π2 (List, N) π1 (a) Original RST tree (, R) (explanation, S) π4 (span, N) (List, N) (List, N) π3 (List, N) π2 (List, N)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We replicated standard evaluation procedures in RST discourse parsing for 9 parsers and showed that most gains reported in recent publications are an artefact of implicit differences in evalua-  tion procedures. We also showed how to use the standard Parseval procedure instead of Marcu's adaptation RST-Parseval, which artificially raises scores. Overall, the recent gains attributable to distributed representations represent at most a rel- ative error reduction of 16%. Our study reveals an urgent need for the RST discourse parsing com- munity to re-examine and standardize their evalu- ation procedures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Original RST tree, right-heavy binarization and labelled attachment decisions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Micro-averaged F 1 scores. 

group has vanished. On S and N, parsers in the 
second group do not improve over parsers in the 
first group ; on R and F the best parser in the sec-
ond group provides an absolute improvement of 
0.9 and 1.4 points. This improvement corresponds 
to a relative error reduction of 11% on R and 16% 
on F, much lower than the 51% claimed in the lit-
erature. 3 

parser 
S 
N 
R 
F 

HHN16 HILDA 
85.9 72.1 60.0 59.4 
SHV15 D * 
85.1 71.1 59.8 59.1 
JCN15 1S-1S 
85.7 73.0 60.9 60.2 
FH14 gCRF * 
87.0 74.1 61.1 60.5 

BPS16 
83.6 69.8 55.4 55.1 
LLC16 
85.4 70.8 58.4 57.6 
BCS17 mono 
85.0 72.3 60.8 60.1 
BCS17 cross+dev 85.1 73.1 61.6 61.4 
JE14 DPLP ** 
85.0 71.6 62.0 61.9 

human 
89.6 78.3 66.7 65.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Macro-averaged F 1 scores. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Micro-averaged F 1 scores on labelled 
attachment decisions (original Parseval). 

</table></figure>

			<note place="foot" n="1"> The source code and material are available at https: //github.com/irit-melodi/rst-eval</note>

			<note place="foot" n="3"> Our replicated scores for human agreement are 0.4 points lower than those published on S, N, R, possibly due to different approaches in handling divergences in EDU segmentation on the doubly annotated subset of documents.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by ERC Advanced Grant n. 269427. We thank the authors of the parsers who made their predictions and evalua-tion scripts available, and the reviewers for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Procedure for quantitatively comparing the syntactic coverage of english grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gdaniec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ingria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strzalkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Speech and Natural Language, HLT &apos;91</title>
		<meeting>the Workshop on Speech and Natural Language, HLT &apos;91</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="306" to="311" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cross-lingual rst discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloé</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximin</forename><surname>Coavoux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="292" to="304" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloé</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-view and multi-task training of rst discourse parsers</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1903" to="1913" />
		</imprint>
	</monogr>
	<note>The COLING 2016 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Building a discourse-tagged corpus in the framework of rhetorical structure theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ellen</forename><surname>Okurowski</surname></persName>
		</author>
		<editor>Jan van Kuppevelt and Ronnie Smith, editors</editor>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Kluwer Academic Publishers</publisher>
			<biblScope unit="page" from="85" to="112" />
		</imprint>
	</monogr>
	<note>Current Directions in Discourse and Dialogue</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A lineartime bottom-up discourse parser with constraints and post-editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Vanessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graeme</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="511" to="521" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Empirical comparison of dependency conversions for rst discourse trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katsuhiko</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsutomu</forename><surname>Hirao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue<address><addrLine>Los Angeles</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="128" to="136" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.02425</idno>
		<title level="m">Fast Rhetorical Structure Theory Discourse Parsing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">HILDA: A Discourse Parser Using Support Vector Machine Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Hernault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Prendinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dialogue and Discourse</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Representation learning for text-level discourse parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Codra: A novel discriminative framework for rhetorical analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="385" to="435" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining intra-and multisentential rhetorical parsing for document-level discourse analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Shafiq R Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carenini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehdad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="486" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discourse parsing with attention-based hierarchical neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="362" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rhetorical Structure Theory: Towards a Functional Theory of Text Organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><forename type="middle">A</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Text</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="281" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The theory and practice of discourse parsing and summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Analysis of discourse structure with syntactic dependencies and data-driven shiftreduce parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Sagae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Parsing Technologies, IWPT &apos;09</title>
		<meeting>the 11th International Conference on Parsing Technologies, IWPT &apos;09<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="81" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Two practical rhetorical structure theory parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco A</forename><surname>Valenzuela-Escárcega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
